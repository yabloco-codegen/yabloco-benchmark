{"79D9B4DB619F85EB": {"calls": [{"id": "2D57CE778BDD1AD4", "name": "btVector3::operator+=", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 159, "col": 2}, "end": {"line": 171, "col": 2}, "code": "\t{\n\t\tm_floats[0] += v.m_floats[0];\n\t\tm_floats[1] += v.m_floats[1];\n\t\tm_floats[2] += v.m_floats[2];\n\t\treturn *this;\n\t}\n\n\t/**@brief Subtract a vector from this one\n   * @param The vector to subtract */\n\tSIMD_FORCE_INLINE btVector3& operator-=(const btVector3& v)\n\t{\n\t\tm_floats[0] -= v.m_floats[0];\n\t\tm_floats[1] -= v.m_floats[1];\n\t\tm_floats[2] -= v.m_floats[2];\n\t\treturn *this;\n\t}\n\n\t/**@brief Scale the vector\n   * @param s Scale factor */\n\tSIMD_FORCE_INLINE btVector3& operator*=(const btScalar& s)\n\t{\n\t\tm_floats[0] *= s;\n\t\tm_floats[1] *= s;\n\t\tm_floats[2] *= s;\n\t\treturn *this;\n\t}\n\n\t/**@brief Inversely scale the vector \n   * @param s Scale factor to divide by */\n\tSIMD_FORCE_INLINE btVector3& operator/=(const btScalar& s)\n\t{\n\t\tbtFullAssert(s != btScalar(0.0));\n\n\t\treturn *this *= btScalar(1.0) / s;\n\t}\n\n\t/**@brief Return the dot product\n   * @param v The other vector in the dot product */\n\tSIMD_FORCE_INLINE btScalar dot(const btVector3& v) const\n\t{\n\t\treturn m_floats[0] * v.m_floats[0] +\n\t\t\t   m_floats[1] * v.m_floats[1] +\n\t\t\t   m_floats[2] * v.m_floats[2];\n\t}\n\n\t/**@brief Return the length of the vector squared */\n\tSIMD_FORCE_INLINE btScalar length2() const\n\t{\n\t\treturn dot(*this);\n\t}\n\n\t/**@brief Return the length of the vector */\n\tSIMD_FORCE_INLINE btScalar length() const\n\t{\n\t\treturn btSqrt(length2());\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar norm() const\n\t{\n\t\treturn length();\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar safeNorm() const\n\t{\n\t\tbtScalar d = length2();\n\t\t//workaround for some clang/gcc issue of sqrtf(tiny number) = -INF\n\t\tif (d > SIMD_EPSILON)\n\t\t\treturn btSqrt(d);\n\t\treturn btScalar(0);\n\t}\n\n\t/**@brief Return the distance squared between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance2(const btVector3& v) const;\n\n\t/**@brief Return the distance between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance(const btVector3& v) const;\n\n\tSIMD_FORCE_INLINE btVector3& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\t//triNormal.normalize();\n\t\tif (l2 >= SIMD_EPSILON * SIMD_EPSILON)\n\t\t{\n\t\t\t(*this) /= btSqrt(l2);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsetValue(1, 0, 0);\n\t\t}\n\t\treturn *this;\n\t}\n\n\t/**@brief Normalize this vector \n   * x^2 + y^2 + z^2 = 1 */\n\tSIMD_FORCE_INLINE btVector3& normalize()\n\t{\n\t\tbtAssert(!fuzzyZero());\n\n"}, {"id": "59B042508A191BEC", "name": "operator*", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 769, "col": 1}, "end": {"line": 782, "col": 1}, "code": "operator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "04B117264A0880F9", "name": "operator*", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 835, "col": 1}, "end": {"line": 839, "col": 1}, "code": "operator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}], "code": "\tSIMD_FORCE_INLINE void internalApplyImpulse(const btVector3& linearComponent, const btVector3& angularComponent, const btScalar impulseMagnitude)\n\t{\n\t\tif (m_originalBody)\n\t\t{\n\t\t\tm_deltaLinearVelocity += linearComponent * impulseMagnitude * m_linearFactor;\n\t\t\tm_deltaAngularVelocity += angularComponent * (impulseMagnitude * m_angularFactor);\n\t\t}\n\t}\n"}, "C74CEE60AF732A54": {"calls": [], "code": "\tSIMD_FORCE_INLINE btVector3& operator*=(const btVector3& v)\n\t{\n\t\tm_floats[0] *= v.m_floats[0];\n\t\tm_floats[1] *= v.m_floats[1];\n\t\tm_floats[2] *= v.m_floats[2];\n\t\treturn *this;\n\t}\n"}, "4B732A7D4583F1B9": {"calls": [], "code": "\tB3_FORCE_INLINE const b3Vector3& operator[](int i) const\n\t{\n\t\tb3FullAssert(0 <= i && i < 3);\n\t\treturn m_el[i];\n\t}\n"}, "C334444305D77C87": {"calls": [], "code": "\tB3_FORCE_INLINE void setValue(const b3Scalar& _x, const b3Scalar& _y, const b3Scalar& _z, const b3Scalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n"}, "CF0FB37FEFB6B1E9": {"calls": [{"id": "37EBA8A425FD4EEE", "name": "btVector3::operator*=", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 191, "col": 2}, "end": {"line": 205, "col": 2}, "code": "\t{\n\t\tm_floats[0] *= s;\n\t\tm_floats[1] *= s;\n\t\tm_floats[2] *= s;\n\t\treturn *this;\n\t}\n\n\t/**@brief Inversely scale the vector \n   * @param s Scale factor to divide by */\n\tSIMD_FORCE_INLINE btVector3& operator/=(const btScalar& s)\n\t{\n\t\tbtFullAssert(s != btScalar(0.0));\n\n\t\treturn *this *= btScalar(1.0) / s;\n\t}\n\n\t/**@brief Return the dot product\n   * @param v The other vector in the dot product */\n\tSIMD_FORCE_INLINE btScalar dot(const btVector3& v) const\n\t{\n\t\treturn m_floats[0] * v.m_floats[0] +\n\t\t\t   m_floats[1] * v.m_floats[1] +\n\t\t\t   m_floats[2] * v.m_floats[2];\n\t}\n\n\t/**@brief Return the length of the vector squared */\n\tSIMD_FORCE_INLINE btScalar length2() const\n\t{\n\t\treturn dot(*this);\n\t}\n\n\t/**@brief Return the length of the vector */\n\tSIMD_FORCE_INLINE btScalar length() const\n\t{\n\t\treturn btSqrt(length2());\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar norm() const\n\t{\n\t\treturn length();\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar safeNorm() const\n\t{\n\t\tbtScalar d = length2();\n\t\t//workaround for some clang/gcc issue of sqrtf(tiny number) = -INF\n\t\tif (d > SIMD_EPSILON)\n\t\t\treturn btSqrt(d);\n\t\treturn btScalar(0);\n\t}\n\n\t/**@brief Return the distance squared between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance2(const btVector3& v) const;\n\n\t/**@brief Return the distance between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance(const btVector3& v) const;\n\n\tSIMD_FORCE_INLINE btVector3& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\t//triNormal.normalize();\n\t\tif (l2 >= SIMD_EPSILON * SIMD_EPSILON)\n\t\t{\n\t\t\t(*this) /= btSqrt(l2);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsetValue(1, 0, 0);\n\t\t}\n\t\treturn *this;\n\t}\n\n\t/**@brief Normalize this vector \n   * x^2 + y^2 + z^2 = 1 */\n\tSIMD_FORCE_INLINE btVector3& normalize()\n\t{\n\t\tbtAssert(!fuzzyZero());\n\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a normalized version of this vector */\n\tSIMD_FORCE_INLINE btVector3 normalized() const;\n\n\t/**@brief Return a rotated version of this vector\n   * @param wAxis The axis to rotate about \n   * @param angle The angle to rotate by */\n\tSIMD_FORCE_INLINE btVector3 rotate(const btVector3& wAxis, const btScalar angle) const;\n\n\t/**@brief Return the angle between this and another vector\n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btScalar angle(const btVector3& v) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * v.length2());\n\t\tbtFullAssert(s != btScalar(0.0));\n\t\treturn btAcos(dot(v) / s);\n\t}\n\n\t/**@brief Return a vector with the absolute values of each element */\n\tSIMD_FORCE_INLINE btVector3 absolute() const\n\t{\n\t\treturn btVector3(\n\t\t\tbtFabs(m_floats[0]),\n\t\t\tbtFabs(m_floats[1]),\n\t\t\tbtFabs(m_floats[2]));\n\t}\n\n\t/**@brief Return the cross product between this and another vector \n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btVector3 cross(const btVector3& v) const\n\t{\n"}], "code": "\tSIMD_FORCE_INLINE btVector3& operator/=(const btScalar& s)\n\t{\n\t\tbtFullAssert(s != btScalar(0.0));\n\n\t\treturn *this *= btScalar(1.0) / s;\n\t}\n"}, "0C3929BA6041DA4C": {"calls": [{"id": "89E43FD867A9FBB5", "name": "btHashedOverlappingPairCache::needsBroadphaseCollision", "path": "bullet3/src/BulletCollision/BroadphaseCollision/btOverlappingPairCache.h", "start": {"line": 108, "col": 2}, "end": {"line": 117, "col": 2}, "code": "\t{\n\t\tif (m_overlapFilterCallback)\n\t\t\treturn m_overlapFilterCallback->needBroadphaseCollision(proxy0, proxy1);\n\n\t\tbool collides = (proxy0->m_collisionFilterGroup & proxy1->m_collisionFilterMask) != 0;\n\t\tcollides = collides && (proxy1->m_collisionFilterGroup & proxy0->m_collisionFilterMask);\n\n\t\treturn collides;\n\t}\n\n\t// Add a pair and return the new pair. If the pair already exists,\n\t// no new pair is created and the old one is returned.\n\tvirtual btBroadphasePair* addOverlappingPair(btBroadphaseProxy * proxy0, btBroadphaseProxy * proxy1)\n\t{\n\t\tif (!needsBroadphaseCollision(proxy0, proxy1))\n\t\t\treturn 0;\n\n\t\treturn internalAddPair(proxy0, proxy1);\n\t}\n\n\tvoid cleanProxyFromPairs(btBroadphaseProxy * proxy, btDispatcher * dispatcher);\n\n\tvirtual void processAllOverlappingPairs(btOverlapCallback*, btDispatcher * dispatcher);\n\n\tvirtual void processAllOverlappingPairs(btOverlapCallback * callback, btDispatcher * dispatcher, const struct btDispatcherInfo& dispatchInfo);\n\n\tvirtual btBroadphasePair* getOverlappingPairArrayPtr()\n\t{\n\t\treturn &m_overlappingPairArray[0];\n\t}\n\n\tconst btBroadphasePair* getOverlappingPairArrayPtr() const\n\t{\n\t\treturn &m_overlappingPairArray[0];\n\t}\n\n\tbtBroadphasePairArray& getOverlappingPairArray()\n\t{\n\t\treturn m_overlappingPairArray;\n\t}\n\n\tconst btBroadphasePairArray& getOverlappingPairArray() const\n\t{\n\t\treturn m_overlappingPairArray;\n\t}\n\n\tvoid cleanOverlappingPair(btBroadphasePair & pair, btDispatcher * dispatcher);\n\n\tbtBroadphasePair* findPair(btBroadphaseProxy * proxy0, btBroadphaseProxy * proxy1);\n\n\tint GetCount() const { return m_overlappingPairArray.size(); }\n\t//\tbtBroadphasePair* GetPairs() { return m_pairs; }\n\n\tbtOverlapFilterCallback* getOverlapFilterCallback()\n\t{\n\t\treturn m_overlapFilterCallback;\n\t}\n\n\tvoid setOverlapFilterCallback(btOverlapFilterCallback * callback)\n\t{\n\t\tm_overlapFilterCallback = callback;\n\t}\n\n\tint getNumOverlappingPairs() const\n\t{\n\t\treturn m_overlappingPairArray.size();\n\t}\n\nprivate:\n\tbtBroadphasePair* internalAddPair(btBroadphaseProxy * proxy0, btBroadphaseProxy * proxy1);\n\n\tvoid growTables();\n\n\tSIMD_FORCE_INLINE bool equalsPair(const btBroadphasePair& pair, int proxyId1, int proxyId2)\n\t{\n\t\treturn pair.m_pProxy0->getUid() == proxyId1 && pair.m_pProxy1->getUid() == proxyId2;\n\t}\n\n\t/*\n\t// Thomas Wang's hash, see: http://www.concentric.net/~Ttwang/tech/inthash.htm\n\t// This assumes proxyId1 and proxyId2 are 16-bit.\n\tSIMD_FORCE_INLINE int getHash(int proxyId1, int proxyId2)\n\t{\n\t\tint key = (proxyId2 << 16) | proxyId1;\n\t\tkey = ~key + (key << 15);\n\t\tkey = key ^ (key >> 12);\n\t\tkey = key + (key << 2);\n\t\tkey = key ^ (key >> 4);\n\t\tkey = key * 2057;\n\t\tkey = key ^ (key >> 16);\n\t\treturn key;\n\t}\n\t*/\n\n\tSIMD_FORCE_INLINE unsigned int getHash(unsigned int proxyId1, unsigned int proxyId2)\n\t{\n\t\tunsigned int key = proxyId1 | (proxyId2 << 16);\n\t\t// Thomas Wang's hash\n\n\t\tkey += ~(key << 15);\n\t\tkey ^= (key >> 10);\n\t\tkey += (key << 3);\n\t\tkey ^= (key >> 6);\n\t\tkey += ~(key << 11);\n\t\tkey ^= (key >> 16);\n\t\treturn key;\n\t}\n\n\tSIMD_FORCE_INLINE btBroadphasePair* internalFindPair(btBroadphaseProxy * proxy0, btBroadphaseProxy * proxy1, int hash)\n\t{\n\t\tint proxyId1 = proxy0->getUid();\n\t\tint proxyId2 = proxy1->getUid();\n#if 0  // wrong, 'equalsPair' use unsorted uids, copy-past devil striked again. Nat.\n\t\tif (proxyId1 > proxyId2) \n\t\t\tbtSwap(proxyId1, proxyId2);\n#endif\n\n\t\tint index = m_hashTable[hash];\n"}, {"id": "1BF3499F7DD83262", "name": "btHashedOverlappingPairCache::internalAddPair", "path": "bullet3/src/BulletCollision/BroadphaseCollision/btOverlappingPairCache.h", "start": {"line": 178, "col": 2}, "end": {"line": 178, "col": 90}, "code": "\n\tvoid growTables();\n\n\tSIMD_FORCE_INLINE bool equalsPair(const btBroadphasePair& pair, int proxyId1, int proxyId2)\n\t{\n\t\treturn pair.m_pProxy0->getUid() == proxyId1 && pair.m_pProxy1->getUid() == proxyId2;\n\t}\n\n\t/*\n\t// Thomas Wang's hash, see: http://www.concentric.net/~Ttwang/tech/inthash.htm\n\t// This assumes proxyId1 and proxyId2 are 16-bit.\n\tSIMD_FORCE_INLINE int getHash(int proxyId1, int proxyId2)\n\t{\n\t\tint key = (proxyId2 << 16) | proxyId1;\n\t\tkey = ~key + (key << 15);\n\t\tkey = key ^ (key >> 12);\n\t\tkey = key + (key << 2);\n\t\tkey = key ^ (key >> 4);\n\t\tkey = key * 2057;\n\t\tkey = key ^ (key >> 16);\n\t\treturn key;\n\t}\n\t*/\n\n\tSIMD_FORCE_INLINE unsigned int getHash(unsigned int proxyId1, unsigned int proxyId2)\n\t{\n\t\tunsigned int key = proxyId1 | (proxyId2 << 16);\n\t\t// Thomas Wang's hash\n\n\t\tkey += ~(key << 15);\n\t\tkey ^= (key >> 10);\n\t\tkey += (key << 3);\n\t\tkey ^= (key >> 6);\n\t\tkey += ~(key << 11);\n\t\tkey ^= (key >> 16);\n\t\treturn key;\n\t}\n\n\tSIMD_FORCE_INLINE btBroadphasePair* internalFindPair(btBroadphaseProxy * proxy0, btBroadphaseProxy * proxy1, int hash)\n\t{\n\t\tint proxyId1 = proxy0->getUid();\n\t\tint proxyId2 = proxy1->getUid();\n#if 0  // wrong, 'equalsPair' use unsorted uids, copy-past devil striked again. Nat.\n\t\tif (proxyId1 > proxyId2) \n\t\t\tbtSwap(proxyId1, proxyId2);\n#endif\n\n\t\tint index = m_hashTable[hash];\n\n\t\twhile (index != BT_NULL_PAIR && equalsPair(m_overlappingPairArray[index], proxyId1, proxyId2) == false)\n\t\t{\n\t\t\tindex = m_next[index];\n\t\t}\n\n\t\tif (index == BT_NULL_PAIR)\n\t\t{\n\t\t\treturn NULL;\n\t\t}\n\n\t\tbtAssert(index < m_overlappingPairArray.size());\n\n\t\treturn &m_overlappingPairArray[index];\n\t}\n\n\tvirtual bool hasDeferredRemoval()\n\t{\n\t\treturn false;\n\t}\n\n\tvirtual void setInternalGhostPairCallback(btOverlappingPairCallback * ghostPairCallback)\n\t{\n\t\tm_ghostPairCallback = ghostPairCallback;\n\t}\n\n\tvirtual void sortOverlappingPairs(btDispatcher * dispatcher);\n};\n\n///btSortedOverlappingPairCache maintains the objects with overlapping AABB\n///Typically managed by the Broadphase, Axis3Sweep or btSimpleBroadphase\nclass btSortedOverlappingPairCache : public btOverlappingPairCache\n{\nprotected:\n\t//avoid brute-force finding all the time\n\tbtBroadphasePairArray m_overlappingPairArray;\n\n\t//during the dispatch, check that user doesn't destroy/create proxy\n\tbool m_blockedForChanges;\n\n\t///by default, do the removal during the pair traversal\n\tbool m_hasDeferredRemoval;\n\n\t//if set, use the callback instead of the built in filter in needBroadphaseCollision\n\tbtOverlapFilterCallback* m_overlapFilterCallback;\n\n\tbtOverlappingPairCallback* m_ghostPairCallback;\n\npublic:\n\tbtSortedOverlappingPairCache();\n\tvirtual ~btSortedOverlappingPairCache();\n\n\tvirtual void processAllOverlappingPairs(btOverlapCallback*, btDispatcher* dispatcher);\n\n\tvoid* removeOverlappingPair(btBroadphaseProxy* proxy0, btBroadphaseProxy* proxy1, btDispatcher* dispatcher);\n\n\tvoid cleanOverlappingPair(btBroadphasePair& pair, btDispatcher* dispatcher);\n\n\tbtBroadphasePair* addOverlappingPair(btBroadphaseProxy* proxy0, btBroadphaseProxy* proxy1);\n\n\tbtBroadphasePair* findPair(btBroadphaseProxy* proxy0, btBroadphaseProxy* proxy1);\n\n\tvoid cleanProxyFromPairs(btBroadphaseProxy* proxy, btDispatcher* dispatcher);\n\n\tvoid removeOverlappingPairsContainingProxy(btBroadphaseProxy* proxy, btDispatcher* dispatcher);\n\n\tinline bool needsBroadphaseCollision(btBroadphaseProxy* proxy0, btBroadphaseProxy* proxy1) const\n\t{\n\t\tif (m_overlapFilterCallback)\n\t\t\treturn m_overlapFilterCallback->needBroadphaseCollision(proxy0, proxy1);\n\n\t\tbool collides = (proxy0->m_collisionFilterGroup & proxy1->m_collisionFilterMask) != 0;\n\t\tcollides = collides && (proxy1->m_collisionFilterGroup & proxy0->m_collisionFilterMask);\n\n\t\treturn collides;\n\t}\n\n\tbtBroadphasePairArray& getOverlappingPairArray()\n\t{\n\t\treturn m_overlappingPairArray;\n\t}\n\n\tconst btBroadphasePairArray& getOverlappingPairArray() const\n\t{\n\t\treturn m_overlappingPairArray;\n\t}\n\n\tbtBroadphasePair* getOverlappingPairArrayPtr()\n\t{\n\t\treturn &m_overlappingPairArray[0];\n\t}\n\n\tconst btBroadphasePair* getOverlappingPairArrayPtr() const\n\t{\n\t\treturn &m_overlappingPairArray[0];\n\t}\n\n\tint getNumOverlappingPairs() const\n\t{\n\t\treturn m_overlappingPairArray.size();\n\t}\n\n\tbtOverlapFilterCallback* getOverlapFilterCallback()\n\t{\n\t\treturn m_overlapFilterCallback;\n\t}\n\n\tvoid setOverlapFilterCallback(btOverlapFilterCallback* callback)\n\t{\n\t\tm_overlapFilterCallback = callback;\n\t}\n\n\tvirtual bool hasDeferredRemoval()\n\t{\n\t\treturn m_hasDeferredRemoval;\n\t}\n\n\tvirtual void setInternalGhostPairCallback(btOverlappingPairCallback* ghostPairCallback)\n\t{\n\t\tm_ghostPairCallback = ghostPairCallback;\n\t}\n\n\tvirtual void sortOverlappingPairs(btDispatcher* dispatcher);\n};\n\n///btNullPairCache skips add/removal of overlapping pairs. Userful for benchmarking and unit testing.\nclass btNullPairCache : public btOverlappingPairCache\n{\n\tbtBroadphasePairArray m_overlappingPairArray;\n\npublic:\n"}], "code": "\tvirtual btBroadphasePair* addOverlappingPair(btBroadphaseProxy * proxy0, btBroadphaseProxy * proxy1)\n\t{\n\t\tif (!needsBroadphaseCollision(proxy0, proxy1))\n\t\t\treturn 0;\n\n\t\treturn internalAddPair(proxy0, proxy1);\n\t}\n"}, "8F2E01C42FED29A6": {"calls": [{"id": "678D90D4888987CC", "name": "b3AlignedObjectArray::destroy", "path": "bullet3/src/Bullet3Common/b3AlignedObjectArray.h", "start": {"line": 91, "col": 2}, "end": {"line": 98, "col": 2}, "code": "\t{\n\t\tint i;\n\t\tfor (i = first; i < last; i++)\n\t\t{\n\t\t\tm_data[i].~T();\n\t\t}\n\t}\n\n\tB3_FORCE_INLINE void* allocate(int size)\n\t{\n\t\tif (size)\n\t\t\treturn m_allocator.allocate(size);\n\t\treturn 0;\n\t}\n\n\tB3_FORCE_INLINE void deallocate()\n\t{\n\t\tif (m_data)\n\t\t{\n\t\t\t//PCK: enclosed the deallocation in this block\n\t\t\tif (m_ownsMemory)\n\t\t\t{\n\t\t\t\tm_allocator.deallocate(m_data);\n\t\t\t}\n\t\t\tm_data = 0;\n\t\t}\n\t}\n\npublic:\n\tb3AlignedObjectArray()\n\t{\n\t\tinit();\n\t}\n\n\t~b3AlignedObjectArray()\n\t{\n\t\tclear();\n\t}\n\n\t///Generally it is best to avoid using the copy constructor of an b3AlignedObjectArray, and use a (const) reference to the array instead.\n\tb3AlignedObjectArray(const b3AlignedObjectArray& otherArray)\n\t{\n\t\tinit();\n\n\t\tint otherSize = otherArray.size();\n\t\tresize(otherSize);\n\t\t//don't use otherArray.copy, it can leak memory\n\t\tfor (int i = 0; i < otherSize; i++)\n\t\t{\n\t\t\tm_data[i] = otherArray[i];\n\t\t}\n\t}\n\n\t/// return the number of elements in the array\n\tB3_FORCE_INLINE int size() const\n\t{\n\t\treturn m_size;\n\t}\n\n\tB3_FORCE_INLINE const T& at(int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& at(int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE const T& operator[](int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& operator[](int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\t///clear the array, deallocated memory. Generally it is better to use array.resize(0), to reduce performance overhead of run-time memory (de)allocations.\n\tB3_FORCE_INLINE void clear()\n\t{\n\t\tdestroy(0, size());\n\n\t\tdeallocate();\n\n\t\tinit();\n\t}\n\n\tB3_FORCE_INLINE void pop_back()\n\t{\n"}, {"id": "03AD431AA4ABCB2E", "name": "b3AlignedObjectArray::size", "path": "bullet3/src/Bullet3Common/b3AlignedObjectArray.h", "start": {"line": 146, "col": 2}, "end": {"line": 149, "col": 2}, "code": "\t{\n\t\treturn m_size;\n\t}\n\n\tB3_FORCE_INLINE const T& at(int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& at(int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE const T& operator[](int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& operator[](int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\t///clear the array, deallocated memory. Generally it is better to use array.resize(0), to reduce performance overhead of run-time memory (de)allocations.\n\tB3_FORCE_INLINE void clear()\n\t{\n\t\tdestroy(0, size());\n\n\t\tdeallocate();\n\n\t\tinit();\n\t}\n\n\tB3_FORCE_INLINE void pop_back()\n\t{\n\t\tb3Assert(m_size > 0);\n\t\tm_size--;\n\t\tm_data[m_size].~T();\n\t}\n\n\t///resize changes the number of elements in the array. If the new size is larger, the new elements will be constructed using the optional second argument.\n\t///when the new number of elements is smaller, the destructor will be called, but memory will not be freed, to reduce performance overhead of run-time memory (de)allocations.\n\tB3_FORCE_INLINE void resizeNoInitialize(int newsize)\n\t{\n\t\tint curSize = size();\n\n\t\tif (newsize < curSize)\n\t\t{\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (newsize > size())\n\t\t\t{\n\t\t\t\treserve(newsize);\n\t\t\t}\n\t\t\t//leave this uninitialized\n\t\t}\n\t\tm_size = newsize;\n\t}\n\n\tB3_FORCE_INLINE void resize(int newsize, const T& fillData = T())\n\t{\n\t\tint curSize = size();\n\n\t\tif (newsize < curSize)\n\t\t{\n\t\t\tfor (int i = newsize; i < curSize; i++)\n\t\t\t{\n\t\t\t\tm_data[i].~T();\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (newsize > size())\n\t\t\t{\n\t\t\t\treserve(newsize);\n\t\t\t}\n"}, {"id": "45AFB0BEE53661F8", "name": "b3AlignedObjectArray::deallocate", "path": "bullet3/src/Bullet3Common/b3AlignedObjectArray.h", "start": {"line": 107, "col": 2}, "end": {"line": 118, "col": 2}, "code": "\t{\n\t\tif (m_data)\n\t\t{\n\t\t\t//PCK: enclosed the deallocation in this block\n\t\t\tif (m_ownsMemory)\n\t\t\t{\n\t\t\t\tm_allocator.deallocate(m_data);\n\t\t\t}\n\t\t\tm_data = 0;\n\t\t}\n\t}\n\npublic:\n\tb3AlignedObjectArray()\n\t{\n\t\tinit();\n\t}\n\n\t~b3AlignedObjectArray()\n\t{\n\t\tclear();\n\t}\n\n\t///Generally it is best to avoid using the copy constructor of an b3AlignedObjectArray, and use a (const) reference to the array instead.\n\tb3AlignedObjectArray(const b3AlignedObjectArray& otherArray)\n\t{\n\t\tinit();\n\n\t\tint otherSize = otherArray.size();\n\t\tresize(otherSize);\n\t\t//don't use otherArray.copy, it can leak memory\n\t\tfor (int i = 0; i < otherSize; i++)\n\t\t{\n\t\t\tm_data[i] = otherArray[i];\n\t\t}\n\t}\n\n\t/// return the number of elements in the array\n\tB3_FORCE_INLINE int size() const\n\t{\n\t\treturn m_size;\n\t}\n\n\tB3_FORCE_INLINE const T& at(int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& at(int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE const T& operator[](int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& operator[](int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\t///clear the array, deallocated memory. Generally it is better to use array.resize(0), to reduce performance overhead of run-time memory (de)allocations.\n\tB3_FORCE_INLINE void clear()\n\t{\n\t\tdestroy(0, size());\n\n\t\tdeallocate();\n\n\t\tinit();\n\t}\n\n\tB3_FORCE_INLINE void pop_back()\n\t{\n\t\tb3Assert(m_size > 0);\n\t\tm_size--;\n\t\tm_data[m_size].~T();\n\t}\n\n\t///resize changes the number of elements in the array. If the new size is larger, the new elements will be constructed using the optional second argument.\n\t///when the new number of elements is smaller, the destructor will be called, but memory will not be freed, to reduce performance overhead of run-time memory (de)allocations.\n\tB3_FORCE_INLINE void resizeNoInitialize(int newsize)\n\t{\n\t\tint curSize = size();\n\n\t\tif (newsize < curSize)\n\t\t{\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (newsize > size())\n\t\t\t{\n\t\t\t\treserve(newsize);\n\t\t\t}\n\t\t\t//leave this uninitialized\n\t\t}\n\t\tm_size = newsize;\n\t}\n\n\tB3_FORCE_INLINE void resize(int newsize, const T& fillData = T())\n\t{\n\t\tint curSize = size();\n\n\t\tif (newsize < curSize)\n\t\t{\n\t\t\tfor (int i = newsize; i < curSize; i++)\n\t\t\t{\n\t\t\t\tm_data[i].~T();\n\t\t\t}\n\t\t}\n"}, {"id": "0FB6077E4419F3D0", "name": "b3AlignedObjectArray::init", "path": "bullet3/src/Bullet3Common/b3AlignedObjectArray.h", "start": {"line": 83, "col": 2}, "end": {"line": 90, "col": 2}, "code": "\t{\n\t\t//PCK: added this line\n\t\tm_ownsMemory = true;\n\t\tm_data = 0;\n\t\tm_size = 0;\n\t\tm_capacity = 0;\n\t}\n\tB3_FORCE_INLINE void destroy(int first, int last)\n\t{\n\t\tint i;\n\t\tfor (i = first; i < last; i++)\n\t\t{\n\t\t\tm_data[i].~T();\n\t\t}\n\t}\n\n\tB3_FORCE_INLINE void* allocate(int size)\n\t{\n\t\tif (size)\n\t\t\treturn m_allocator.allocate(size);\n\t\treturn 0;\n\t}\n\n\tB3_FORCE_INLINE void deallocate()\n\t{\n\t\tif (m_data)\n\t\t{\n\t\t\t//PCK: enclosed the deallocation in this block\n\t\t\tif (m_ownsMemory)\n\t\t\t{\n\t\t\t\tm_allocator.deallocate(m_data);\n\t\t\t}\n\t\t\tm_data = 0;\n\t\t}\n\t}\n\npublic:\n\tb3AlignedObjectArray()\n\t{\n\t\tinit();\n\t}\n\n\t~b3AlignedObjectArray()\n\t{\n\t\tclear();\n\t}\n\n\t///Generally it is best to avoid using the copy constructor of an b3AlignedObjectArray, and use a (const) reference to the array instead.\n\tb3AlignedObjectArray(const b3AlignedObjectArray& otherArray)\n\t{\n\t\tinit();\n\n\t\tint otherSize = otherArray.size();\n\t\tresize(otherSize);\n\t\t//don't use otherArray.copy, it can leak memory\n\t\tfor (int i = 0; i < otherSize; i++)\n\t\t{\n\t\t\tm_data[i] = otherArray[i];\n\t\t}\n\t}\n\n\t/// return the number of elements in the array\n\tB3_FORCE_INLINE int size() const\n\t{\n\t\treturn m_size;\n\t}\n\n\tB3_FORCE_INLINE const T& at(int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& at(int n)\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE const T& operator[](int n) const\n\t{\n\t\tb3Assert(n >= 0);\n\t\tb3Assert(n < size());\n\t\treturn m_data[n];\n\t}\n\n\tB3_FORCE_INLINE T& operator[](int n)\n\t{\n\t\tb3Assert(n >= 0);\n"}], "code": "\tB3_FORCE_INLINE void clear()\n\t{\n\t\tdestroy(0, size());\n\n\t\tdeallocate();\n\n\t\tinit();\n\t}\n"}, "66E0B8EAE18BD73F": {"calls": [{"id": "B89086F5141E62B0", "name": "btQuaternion::operator*=", "path": "bullet3/src/LinearMath/btQuaternion.h", "start": {"line": 234, "col": 2}, "end": {"line": 249, "col": 2}, "code": "\t{\n\t\tm_floats[0] *= s;\n\t\tm_floats[1] *= s;\n\t\tm_floats[2] *= s;\n\t\tm_floats[3] *= s;\n\t\treturn *this;\n\t}\n\n\t/**@brief Multiply this quaternion by q on the right\n   * @param q The other quaternion \n   * Equivilant to this = this * q */\n\tbtQuaternion& operator*=(const btQuaternion& q)\n\t{\n\t\tsetValue(\n\t\t\tm_floats[3] * q.x() + m_floats[0] * q.m_floats[3] + m_floats[1] * q.z() - m_floats[2] * q.y(),\n\t\t\tm_floats[3] * q.y() + m_floats[1] * q.m_floats[3] + m_floats[2] * q.x() - m_floats[0] * q.z(),\n\t\t\tm_floats[3] * q.z() + m_floats[2] * q.m_floats[3] + m_floats[0] * q.y() - m_floats[1] * q.x(),\n\t\t\tm_floats[3] * q.m_floats[3] - m_floats[0] * q.x() - m_floats[1] * q.y() - m_floats[2] * q.z());\n\t\treturn *this;\n\t}\n\t/**@brief Return the dot product between this quaternion and another\n   * @param q The other quaternion */\n\tbtScalar dot(const btQuaternion& q) const\n\t{\n\t\treturn m_floats[0] * q.x() +\n\t\t\t   m_floats[1] * q.y() +\n\t\t\t   m_floats[2] * q.z() +\n\t\t\t   m_floats[3] * q.m_floats[3];\n\t}\n\n\t/**@brief Return the length squared of the quaternion */\n\tbtScalar length2() const\n\t{\n\t\treturn dot(*this);\n\t}\n\n\t/**@brief Return the length of the quaternion */\n\tbtScalar length() const\n\t{\n\t\treturn btSqrt(length2());\n\t}\n\tbtQuaternion& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\tif (l2 > SIMD_EPSILON)\n\t\t{\n\t\t\tnormalize();\n\t\t}\n\t\treturn *this;\n\t}\n\t/**@brief Normalize the quaternion \n   * Such that x^2 + y^2 + z^2 +w^2 = 1 */\n\tbtQuaternion& normalize()\n\t{\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a scaled version of this quaternion\n   * @param s The scale factor */\n\tSIMD_FORCE_INLINE btQuaternion\n\toperator*(const btScalar& s) const\n\t{\n\t\treturn btQuaternion(x() * s, y() * s, z() * s, m_floats[3] * s);\n\t}\n\n\t/**@brief Return an inversely scaled versionof this quaternion\n   * @param s The inverse scale factor */\n\tbtQuaternion operator/(const btScalar& s) const\n\t{\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn *this * (btScalar(1.0) / s);\n\t}\n\n\t/**@brief Inversely scale this quaternion\n   * @param s The scale factor */\n\tbtQuaternion& operator/=(const btScalar& s)\n\t{\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn *this *= btScalar(1.0) / s;\n\t}\n\n\t/**@brief Return a normalized version of this quaternion */\n\tbtQuaternion normalized() const\n\t{\n\t\treturn *this / length();\n\t}\n\t/**@brief Return the ***half*** angle between this quaternion and the other\n   * @param q The other quaternion */\n\tbtScalar angle(const btQuaternion& q) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * q.length2());\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn btAcos(dot(q) / s);\n\t}\n\n\t/**@brief Return the angle between this quaternion and the other along the shortest path\n\t* @param q The other quaternion */\n\tbtScalar angleShortestPath(const btQuaternion& q) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * q.length2());\n\t\tbtAssert(s != btScalar(0.0));\n\t\tif (dot(q) < 0)  // Take care of long angle case see http://en.wikipedia.org/wiki/Slerp\n\t\t\treturn btAcos(dot(-q) / s) * btScalar(2.0);\n\t\telse\n\t\t\treturn btAcos(dot(q) / s) * btScalar(2.0);\n\t}\n\n\t/**@brief Return the angle [0, 2Pi] of rotation represented by this quaternion */\n\tbtScalar getAngle() const\n\t{\n\t\tbtScalar s = btScalar(2.) * btAcos(m_floats[3]);\n\t\treturn s;\n\t}\n\n\t/**@brief Return the angle [0, Pi] of rotation represented by this quaternion along the shortest path */\n\tbtScalar getAngleShortestPath() const\n\t{\n\t\tbtScalar s;\n\t\tif (m_floats[3] >= 0)\n\t\t\ts = btScalar(2.) * btAcos(m_floats[3]);\n\t\telse\n\t\t\ts = btScalar(2.) * btAcos(-m_floats[3]);\n\t\treturn s;\n\t}\n\n"}], "code": "\tbtQuaternion& operator/=(const btScalar& s)\n\t{\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn *this *= btScalar(1.0) / s;\n\t}\n"}, "79C981CD07A529F7": {"calls": [{"id": "19DA9BDF8F1A8055", "name": "b3Matrix3x3::setValue", "path": "bullet3/src/Bullet3Common/b3Matrix3x3.h", "start": {"line": 190, "col": 2}, "end": {"line": 197, "col": 2}, "code": "\t\t\t\t  const b3Scalar& yx, const b3Scalar& yy, const b3Scalar& yz,\n\t\t\t\t  const b3Scalar& zx, const b3Scalar& zy, const b3Scalar& zz)\n\t{\n\t\tm_el[0].setValue(xx, xy, xz);\n\t\tm_el[1].setValue(yx, yy, yz);\n\t\tm_el[2].setValue(zx, zy, zz);\n\t}\n\n\t/** @brief Set the matrix from a quaternion\n\t*  @param q The Quaternion to match */\n\tvoid setRotation(const b3Quaternion& q)\n\t{\n\t\tb3Scalar d = q.length2();\n\t\tb3FullAssert(d != b3Scalar(0.0));\n\t\tb3Scalar s = b3Scalar(2.0) / d;\n\n\t\tb3Scalar xs = q.getX() * s, ys = q.getY() * s, zs = q.getZ() * s;\n\t\tb3Scalar wx = q.getW() * xs, wy = q.getW() * ys, wz = q.getW() * zs;\n\t\tb3Scalar xx = q.getX() * xs, xy = q.getX() * ys, xz = q.getX() * zs;\n\t\tb3Scalar yy = q.getY() * ys, yz = q.getY() * zs, zz = q.getZ() * zs;\n\t\tsetValue(\n\t\t\tb3Scalar(1.0) - (yy + zz), xy - wz, xz + wy,\n\t\t\txy + wz, b3Scalar(1.0) - (xx + zz), yz - wx,\n\t\t\txz - wy, yz + wx, b3Scalar(1.0) - (xx + yy));\n\t}\n\n\t/** @brief Set the matrix from euler angles using YPR around YXZ respectively\n\t*  @param yaw Yaw about Y axis\n\t*  @param pitch Pitch about X axis\n\t*  @param roll Roll about Z axis \n\t*/\n\tvoid setEulerYPR(const b3Scalar& yaw, const b3Scalar& pitch, const b3Scalar& roll)\n\t{\n\t\tsetEulerZYX(roll, pitch, yaw);\n\t}\n\n\t/** @brief Set the matrix from euler angles YPR around ZYX axes\n\t* @param eulerX Roll about X axis\n\t* @param eulerY Pitch around Y axis\n\t* @param eulerZ Yaw aboud Z axis\n\t* \n\t* These angles are used to produce a rotation matrix. The euler\n\t* angles are applied in ZYX order. I.e a vector is first rotated \n\t* about X then Y and then Z\n\t**/\n\tvoid setEulerZYX(b3Scalar eulerX, b3Scalar eulerY, b3Scalar eulerZ)\n\t{\n\t\t///@todo proposed to reverse this since it's labeled zyx but takes arguments xyz and it will match all other parts of the code\n\t\tb3Scalar ci(b3Cos(eulerX));\n\t\tb3Scalar cj(b3Cos(eulerY));\n\t\tb3Scalar ch(b3Cos(eulerZ));\n\t\tb3Scalar si(b3Sin(eulerX));\n\t\tb3Scalar sj(b3Sin(eulerY));\n\t\tb3Scalar sh(b3Sin(eulerZ));\n\t\tb3Scalar cc = ci * ch;\n\t\tb3Scalar cs = ci * sh;\n\t\tb3Scalar sc = si * ch;\n\t\tb3Scalar ss = si * sh;\n\n\t\tsetValue(cj * ch, sj * sc - cs, sj * cc + ss,\n\t\t\t\t cj * sh, sj * ss + cc, sj * cs - sc,\n\t\t\t\t -sj, cj * si, cj * ci);\n\t}\n\n\t/**@brief Set the matrix to the identity */\n\tvoid setIdentity()\n\t{\n\t\tsetValue(b3Scalar(1.0), b3Scalar(0.0), b3Scalar(0.0),\n\t\t\t\t b3Scalar(0.0), b3Scalar(1.0), b3Scalar(0.0),\n\t\t\t\t b3Scalar(0.0), b3Scalar(0.0), b3Scalar(1.0));\n\t}\n\n\tstatic const b3Matrix3x3& getIdentity()\n\t{\n\t\tstatic const b3Matrix3x3\n\t\t\tidentityMatrix(\n\t\t\t\tb3Scalar(1.0), b3Scalar(0.0), b3Scalar(0.0),\n\t\t\t\tb3Scalar(0.0), b3Scalar(1.0), b3Scalar(0.0),\n\t\t\t\tb3Scalar(0.0), b3Scalar(0.0), b3Scalar(1.0));\n\t\treturn identityMatrix;\n\t}\n\n\t/**@brief Fill the rotational part of an OpenGL matrix and clear the shear/perspective\n\t* @param m The array to be filled */\n\tvoid getOpenGLSubMatrix(b3Scalar * m) const\n\t{\n\t\tm[0] = b3Scalar(m_el[0].getX());\n\t\tm[1] = b3Scalar(m_el[1].getX());\n\t\tm[2] = b3Scalar(m_el[2].getX());\n\t\tm[3] = b3Scalar(0.0);\n\t\tm[4] = b3Scalar(m_el[0].getY());\n\t\tm[5] = b3Scalar(m_el[1].getY());\n\t\tm[6] = b3Scalar(m_el[2].getY());\n\t\tm[7] = b3Scalar(0.0);\n\t\tm[8] = b3Scalar(m_el[0].getZ());\n\t\tm[9] = b3Scalar(m_el[1].getZ());\n\t\tm[10] = b3Scalar(m_el[2].getZ());\n\t\tm[11] = b3Scalar(0.0);\n\t}\n"}], "code": "\tvoid setIdentity()\n\t{\n\t\tsetValue(b3Scalar(1.0), b3Scalar(0.0), b3Scalar(0.0),\n\t\t\t\t b3Scalar(0.0), b3Scalar(1.0), b3Scalar(0.0),\n\t\t\t\t b3Scalar(0.0), b3Scalar(0.0), b3Scalar(1.0));\n\t}\n"}, "DC2BD5D0EA380700": {"calls": [{"id": "B2E6A2621E997AD7", "name": "btQuadWord::x", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 113, "col": 2}, "end": {"line": 113, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n"}, {"id": "9E7A9B47DED95E24", "name": "btQuadWord::y", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 115, "col": 2}, "end": {"line": 115, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n"}, {"id": "8746EBDA7420066D", "name": "btQuadWord::z", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 117, "col": 2}, "end": {"line": 117, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n"}], "code": "\tbtScalar dot(const btQuaternion& q) const\n\t{\n\t\treturn m_floats[0] * q.x() +\n\t\t\t   m_floats[1] * q.y() +\n\t\t\t   m_floats[2] * q.z() +\n\t\t\t   m_floats[3] * q.m_floats[3];\n\t}\n"}, "D6632F6A4CB0E08B": {"calls": [{"id": "BD95C9FCB356CDF8", "name": "btQuaternion::length2", "path": "bullet3/src/LinearMath/btQuaternion.h", "start": {"line": 364, "col": 2}, "end": {"line": 367, "col": 2}, "code": "\t{\n\t\treturn dot(*this);\n\t}\n\n\t/**@brief Return the length of the quaternion */\n\tbtScalar length() const\n\t{\n\t\treturn btSqrt(length2());\n\t}\n\tbtQuaternion& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\tif (l2 > SIMD_EPSILON)\n\t\t{\n\t\t\tnormalize();\n\t\t}\n\t\treturn *this;\n\t}\n\t/**@brief Normalize the quaternion \n   * Such that x^2 + y^2 + z^2 +w^2 = 1 */\n\tbtQuaternion& normalize()\n\t{\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a scaled version of this quaternion\n   * @param s The scale factor */\n\tSIMD_FORCE_INLINE btQuaternion\n\toperator*(const btScalar& s) const\n\t{\n\t\treturn btQuaternion(x() * s, y() * s, z() * s, m_floats[3] * s);\n\t}\n\n\t/**@brief Return an inversely scaled versionof this quaternion\n   * @param s The inverse scale factor */\n\tbtQuaternion operator/(const btScalar& s) const\n\t{\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn *this * (btScalar(1.0) / s);\n\t}\n\n\t/**@brief Inversely scale this quaternion\n   * @param s The scale factor */\n\tbtQuaternion& operator/=(const btScalar& s)\n\t{\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn *this *= btScalar(1.0) / s;\n\t}\n\n\t/**@brief Return a normalized version of this quaternion */\n\tbtQuaternion normalized() const\n\t{\n\t\treturn *this / length();\n\t}\n\t/**@brief Return the ***half*** angle between this quaternion and the other\n   * @param q The other quaternion */\n\tbtScalar angle(const btQuaternion& q) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * q.length2());\n\t\tbtAssert(s != btScalar(0.0));\n\t\treturn btAcos(dot(q) / s);\n\t}\n\n\t/**@brief Return the angle between this quaternion and the other along the shortest path\n\t* @param q The other quaternion */\n\tbtScalar angleShortestPath(const btQuaternion& q) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * q.length2());\n\t\tbtAssert(s != btScalar(0.0));\n\t\tif (dot(q) < 0)  // Take care of long angle case see http://en.wikipedia.org/wiki/Slerp\n\t\t\treturn btAcos(dot(-q) / s) * btScalar(2.0);\n\t\telse\n\t\t\treturn btAcos(dot(q) / s) * btScalar(2.0);\n\t}\n\n\t/**@brief Return the angle [0, 2Pi] of rotation represented by this quaternion */\n\tbtScalar getAngle() const\n\t{\n\t\tbtScalar s = btScalar(2.) * btAcos(m_floats[3]);\n\t\treturn s;\n\t}\n\n\t/**@brief Return the angle [0, Pi] of rotation represented by this quaternion along the shortest path */\n\tbtScalar getAngleShortestPath() const\n\t{\n\t\tbtScalar s;\n\t\tif (m_floats[3] >= 0)\n\t\t\ts = btScalar(2.) * btAcos(m_floats[3]);\n\t\telse\n\t\t\ts = btScalar(2.) * btAcos(-m_floats[3]);\n\t\treturn s;\n\t}\n\n\t/**@brief Return the axis of the rotation represented by this quaternion */\n\tbtVector3 getAxis() const\n\t{\n\t\tbtScalar s_squared = 1.f - m_floats[3] * m_floats[3];\n\n\t\tif (s_squared < btScalar(10.) * SIMD_EPSILON)  //Check for divide by zero\n\t\t\treturn btVector3(1.0, 0.0, 0.0);           // Arbitrary\n\t\tbtScalar s = 1.f / btSqrt(s_squared);\n\t\treturn btVector3(m_floats[0] * s, m_floats[1] * s, m_floats[2] * s);\n\t}\n\n\t/**@brief Return the inverse of this quaternion */\n\tbtQuaternion inverse() const\n\t{\n\t\treturn btQuaternion(-m_floats[0], -m_floats[1], -m_floats[2], m_floats[3]);\n\t}\n\n\t/**@brief Return the sum of this quaternion and the other \n   * @param q2 The other quaternion */\n\tSIMD_FORCE_INLINE btQuaternion\n\toperator+(const btQuaternion& q2) const\n\t{\n\t\tconst btQuaternion& q1 = *this;\n\t\treturn btQuaternion(q1.x() + q2.x(), q1.y() + q2.y(), q1.z() + q2.z(), q1.m_floats[3] + q2.m_floats[3]);\n\t}\n\n\t/**@brief Return the difference between this quaternion and the other \n   * @param q2 The other quaternion */\n\tSIMD_FORCE_INLINE btQuaternion\n\toperator-(const btQuaternion& q2) const\n\t{\n\t\tconst btQuaternion& q1 = *this;\n\t\treturn btQuaternion(q1.x() - q2.x(), q1.y() - q2.y(), q1.z() - q2.z(), q1.m_floats[3] - q2.m_floats[3]);\n\t}\n\n\t/**@brief Return the negative of this quaternion \n   * This simply negates each element */\n\tSIMD_FORCE_INLINE btQuaternion operator-() const\n\t{\n\t\tconst btQuaternion& q2 = *this;\n\t\treturn btQuaternion(-q2.x(), -q2.y(), -q2.z(), -q2.m_floats[3]);\n\t}\n\t/**@todo document this and it's use */\n\tSIMD_FORCE_INLINE btQuaternion farthest(const btQuaternion& qd) const\n\t{\n\t\tbtQuaternion diff, sum;\n\t\tdiff = *this - qd;\n\t\tsum = *this + qd;\n\t\tif (diff.dot(diff) > sum.dot(sum))\n\t\t\treturn qd;\n\t\treturn (-qd);\n\t}\n\n\t/**@todo document this and it's use */\n\tSIMD_FORCE_INLINE btQuaternion nearest(const btQuaternion& qd) const\n\t{\n\t\tbtQuaternion diff, sum;\n\t\tdiff = *this - qd;\n\t\tsum = *this + qd;\n\t\tif (diff.dot(diff) < sum.dot(sum))\n\t\t\treturn qd;\n\t\treturn (-qd);\n\t}\n\n\t/**@brief Return the quaternion which is the result of Spherical Linear Interpolation between this and the other quaternion\n   * @param q The other quaternion to interpolate with \n   * @param t The ratio between this and q to interpolate.  If t = 0 the result is this, if t=1 the result is q.\n   * Slerp interpolates assuming constant velocity.  */\n\tbtQuaternion slerp(const btQuaternion& q, const btScalar& t) const\n\t{\n\t\tconst btScalar magnitude = btSqrt(length2() * q.length2());\n\t\tbtAssert(magnitude > btScalar(0));\n\n\t\tconst btScalar product = dot(q) / magnitude;\n\t\tconst btScalar absproduct = btFabs(product);\n\n\t\tif (absproduct < btScalar(1.0 - SIMD_EPSILON))\n\t\t{\n\t\t\t// Take care of long angle case see http://en.wikipedia.org/wiki/Slerp\n\t\t\tconst btScalar theta = btAcos(absproduct);\n\t\t\tconst btScalar d = btSin(theta);\n\t\t\tbtAssert(d > btScalar(0));\n\n\t\t\tconst btScalar sign = (product < 0) ? btScalar(-1) : btScalar(1);\n\t\t\tconst btScalar s0 = btSin((btScalar(1.0) - t) * theta) / d;\n\t\t\tconst btScalar s1 = btSin(sign * t * theta) / d;\n\n\t\t\treturn btQuaternion(\n\t\t\t\t(m_floats[0] * s0 + q.x() * s1),\n\t\t\t\t(m_floats[1] * s0 + q.y() * s1),\n\t\t\t\t(m_floats[2] * s0 + q.z() * s1),\n\t\t\t\t(m_floats[3] * s0 + q.w() * s1));\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn *this;\n\t\t}\n\t}\n\n\tstatic const btQuaternion& getIdentity()\n\t{\n\t\tstatic const btQuaternion identityQuat(btScalar(0.), btScalar(0.), btScalar(0.), btScalar(1.));\n\t\treturn identityQuat;\n\t}\n\n\tSIMD_FORCE_INLINE const btScalar& getW() const { return m_floats[3]; }\n\n\tSIMD_FORCE_INLINE void serialize(struct btQuaternionData& dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btQuaternionFloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btQuaternionDoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btQuaternionFloatData& dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btQuaternionFloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btQuaternionDoubleData& dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btQuaternionDoubleData& dataIn);\n};\n\n/**@brief Return the product of two quaternions */\nSIMD_FORCE_INLINE btQuaternion\noperator*(const btQuaternion& q1, const btQuaternion& q2)\n{\n\treturn btQuaternion(\n\t\tq1.w() * q2.x() + q1.x() * q2.w() + q1.y() * q2.z() - q1.z() * q2.y(),\n\t\tq1.w() * q2.y() + q1.y() * q2.w() + q1.z() * q2.x() - q1.x() * q2.z(),\n\t\tq1.w() * q2.z() + q1.z() * q2.w() + q1.x() * q2.y() - q1.y() * q2.x(),\n\t\tq1.w() * q2.w() - q1.x() * q2.x() - q1.y() * q2.y() - q1.z() * q2.z());\n}\n\nSIMD_FORCE_INLINE btQuaternion\noperator*(const btQuaternion& q, const btVector3& w)\n{\n"}, {"id": "B2E6A2621E997AD7", "name": "btQuadWord::x", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 113, "col": 2}, "end": {"line": 113, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n"}, {"id": "9E7A9B47DED95E24", "name": "btQuadWord::y", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 115, "col": 2}, "end": {"line": 115, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n"}, {"id": "8746EBDA7420066D", "name": "btQuadWord::z", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 117, "col": 2}, "end": {"line": 117, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n"}, {"id": "553A25B232CAF39C", "name": "btQuadWord::w", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 119, "col": 2}, "end": {"line": 119, "col": 68}, "code": "\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n};\n\n"}, {"id": "6D2AEE26376389B2", "name": "btMatrix3x3::setValue", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 204, "col": 2}, "end": {"line": 211, "col": 2}, "code": "\t\t\t\t  const btScalar& yx, const btScalar& yy, const btScalar& yz,\n\t\t\t\t  const btScalar& zx, const btScalar& zy, const btScalar& zz)\n\t{\n\t\tm_el[0].setValue(xx, xy, xz);\n\t\tm_el[1].setValue(yx, yy, yz);\n\t\tm_el[2].setValue(zx, zy, zz);\n\t}\n\n\t/** @brief Set the matrix from a quaternion\n\t*  @param q The Quaternion to match */\n\tvoid setRotation(const btQuaternion& q)\n\t{\n\t\tbtScalar d = q.length2();\n\t\tbtFullAssert(d != btScalar(0.0));\n\t\tbtScalar s = btScalar(2.0) / d;\n\n\t\tbtScalar xs = q.x() * s, ys = q.y() * s, zs = q.z() * s;\n\t\tbtScalar wx = q.w() * xs, wy = q.w() * ys, wz = q.w() * zs;\n\t\tbtScalar xx = q.x() * xs, xy = q.x() * ys, xz = q.x() * zs;\n\t\tbtScalar yy = q.y() * ys, yz = q.y() * zs, zz = q.z() * zs;\n\t\tsetValue(\n\t\t\tbtScalar(1.0) - (yy + zz), xy - wz, xz + wy,\n\t\t\txy + wz, btScalar(1.0) - (xx + zz), yz - wx,\n\t\t\txz - wy, yz + wx, btScalar(1.0) - (xx + yy));\n\t}\n\n\t/** @brief Set the matrix from euler angles using YPR around YXZ respectively\n\t*  @param yaw Yaw about Y axis\n\t*  @param pitch Pitch about X axis\n\t*  @param roll Roll about Z axis \n\t*/\n\tvoid setEulerYPR(const btScalar& yaw, const btScalar& pitch, const btScalar& roll)\n\t{\n\t\tsetEulerZYX(roll, pitch, yaw);\n\t}\n\n\t/** @brief Set the matrix from euler angles YPR around ZYX axes\n\t* @param eulerX Roll about X axis\n\t* @param eulerY Pitch around Y axis\n\t* @param eulerZ Yaw about Z axis\n\t* \n\t* These angles are used to produce a rotation matrix. The euler\n\t* angles are applied in ZYX order. I.e a vector is first rotated \n\t* about X then Y and then Z\n\t**/\n\tvoid setEulerZYX(btScalar eulerX, btScalar eulerY, btScalar eulerZ)\n\t{\n\t\t///@todo proposed to reverse this since it's labeled zyx but takes arguments xyz and it will match all other parts of the code\n\t\tbtScalar ci(btCos(eulerX));\n\t\tbtScalar cj(btCos(eulerY));\n\t\tbtScalar ch(btCos(eulerZ));\n\t\tbtScalar si(btSin(eulerX));\n\t\tbtScalar sj(btSin(eulerY));\n\t\tbtScalar sh(btSin(eulerZ));\n\t\tbtScalar cc = ci * ch;\n\t\tbtScalar cs = ci * sh;\n\t\tbtScalar sc = si * ch;\n\t\tbtScalar ss = si * sh;\n\n\t\tsetValue(cj * ch, sj * sc - cs, sj * cc + ss,\n\t\t\t\t cj * sh, sj * ss + cc, sj * cs - sc,\n\t\t\t\t -sj, cj * si, cj * ci);\n\t}\n\n\t/**@brief Set the matrix to the identity */\n\tvoid setIdentity()\n\t{\n\t\tsetValue(btScalar(1.0), btScalar(0.0), btScalar(0.0),\n\t\t\t\t btScalar(0.0), btScalar(1.0), btScalar(0.0),\n\t\t\t\t btScalar(0.0), btScalar(0.0), btScalar(1.0));\n\t}\n    \n    /**@brief Set the matrix to the identity */\n    void setZero()\n    {\n        setValue(btScalar(0.0), btScalar(0.0), btScalar(0.0),\n                 btScalar(0.0), btScalar(0.0), btScalar(0.0),\n                 btScalar(0.0), btScalar(0.0), btScalar(0.0));\n    }\n\n\tstatic const btMatrix3x3& getIdentity()\n\t{\n\t\tstatic const btMatrix3x3\n\t\t\tidentityMatrix(\n\t\t\t\tbtScalar(1.0), btScalar(0.0), btScalar(0.0),\n\t\t\t\tbtScalar(0.0), btScalar(1.0), btScalar(0.0),\n\t\t\t\tbtScalar(0.0), btScalar(0.0), btScalar(1.0));\n\t\treturn identityMatrix;\n\t}\n\n\t/**@brief Fill the rotational part of an OpenGL matrix and clear the shear/perspective\n\t* @param m The array to be filled */\n\tvoid getOpenGLSubMatrix(btScalar * m) const\n\t{\n\t\tm[0] = btScalar(m_el[0].x());\n\t\tm[1] = btScalar(m_el[1].x());\n\t\tm[2] = btScalar(m_el[2].x());\n\t\tm[3] = btScalar(0.0);\n\t\tm[4] = btScalar(m_el[0].y());\n\t\tm[5] = btScalar(m_el[1].y());\n\t\tm[6] = btScalar(m_el[2].y());\n\t\tm[7] = btScalar(0.0);\n\t\tm[8] = btScalar(m_el[0].z());\n\t\tm[9] = btScalar(m_el[1].z());\n\t\tm[10] = btScalar(m_el[2].z());\n\t\tm[11] = btScalar(0.0);\n\t}\n"}], "code": "\tvoid setRotation(const btQuaternion& q)\n\t{\n\t\tbtScalar d = q.length2();\n\t\tbtFullAssert(d != btScalar(0.0));\n\t\tbtScalar s = btScalar(2.0) / d;\n\n\t\tbtScalar xs = q.x() * s, ys = q.y() * s, zs = q.z() * s;\n\t\tbtScalar wx = q.w() * xs, wy = q.w() * ys, wz = q.w() * zs;\n\t\tbtScalar xx = q.x() * xs, xy = q.x() * ys, xz = q.x() * zs;\n\t\tbtScalar yy = q.y() * ys, yz = q.y() * zs, zz = q.z() * zs;\n\t\tsetValue(\n\t\t\tbtScalar(1.0) - (yy + zz), xy - wz, xz + wy,\n\t\t\txy + wz, btScalar(1.0) - (xx + zz), yz - wx,\n\t\t\txz - wy, yz + wx, btScalar(1.0) - (xx + yy));\n\t}\n"}, "79D5D5A1A2CF7D89": {"calls": [{"id": "553A25B232CAF39C", "name": "btQuadWord::w", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 119, "col": 2}, "end": {"line": 119, "col": 68}, "code": "\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n};\n\n"}, {"id": "B2E6A2621E997AD7", "name": "btQuadWord::x", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 113, "col": 2}, "end": {"line": 113, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n"}, {"id": "9E7A9B47DED95E24", "name": "btQuadWord::y", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 115, "col": 2}, "end": {"line": 115, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n"}, {"id": "8746EBDA7420066D", "name": "btQuadWord::z", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 117, "col": 2}, "end": {"line": 117, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n"}], "code": "SIMD_FORCE_INLINE btQuaternion\noperator*(const btQuaternion& q1, const btQuaternion& q2)\n{\n\treturn btQuaternion(\n\t\tq1.w() * q2.x() + q1.x() * q2.w() + q1.y() * q2.z() - q1.z() * q2.y(),\n\t\tq1.w() * q2.y() + q1.y() * q2.w() + q1.z() * q2.x() - q1.x() * q2.z(),\n\t\tq1.w() * q2.z() + q1.z() * q2.w() + q1.x() * q2.y() - q1.y() * q2.x(),\n\t\tq1.w() * q2.w() - q1.x() * q2.x() - q1.y() * q2.y() - q1.z() * q2.z());\n}\n"}, "8490AC97765F1D6C": {"calls": [{"id": "7F4443C3A387A915", "name": "btMatrix3x3::getRotation", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 420, "col": 2}, "end": {"line": 520, "col": 2}, "code": "\t{\n\t\tbtScalar trace = m_el[0].x() + m_el[1].y() + m_el[2].z();\n\n\t\tbtScalar temp[4];\n\n\t\tif (trace > btScalar(0.0))\n\t\t{\n\t\t\tbtScalar s = btSqrt(trace + btScalar(1.0));\n\t\t\ttemp[3] = (s * btScalar(0.5));\n\t\t\ts = btScalar(0.5) / s;\n\n\t\t\ttemp[0] = ((m_el[2].y() - m_el[1].z()) * s);\n\t\t\ttemp[1] = ((m_el[0].z() - m_el[2].x()) * s);\n\t\t\ttemp[2] = ((m_el[1].x() - m_el[0].y()) * s);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tint i = m_el[0].x() < m_el[1].y() ? (m_el[1].y() < m_el[2].z() ? 2 : 1) : (m_el[0].x() < m_el[2].z() ? 2 : 0);\n\t\t\tint j = (i + 1) % 3;\n\t\t\tint k = (i + 2) % 3;\n\n\t\t\tbtScalar s = btSqrt(m_el[i][i] - m_el[j][j] - m_el[k][k] + btScalar(1.0));\n\t\t\ttemp[i] = s * btScalar(0.5);\n\t\t\ts = btScalar(0.5) / s;\n\n\t\t\ttemp[3] = (m_el[k][j] - m_el[j][k]) * s;\n\t\t\ttemp[j] = (m_el[j][i] + m_el[i][j]) * s;\n\t\t\ttemp[k] = (m_el[k][i] + m_el[i][k]) * s;\n\t\t}\n\t\tq.setValue(temp[0], temp[1], temp[2], temp[3]);\n\t}\n\n\t/**@brief Get the matrix represented as euler angles around YXZ, roundtrip with setEulerYPR\n\t* @param yaw Yaw around Y axis\n\t* @param pitch Pitch around X axis\n\t* @param roll around Z axis */\n\tvoid getEulerYPR(btScalar & yaw, btScalar & pitch, btScalar & roll) const\n\t{\n\t\t// first use the normal calculus\n\t\tyaw = btScalar(btAtan2(m_el[1].x(), m_el[0].x()));\n\t\tpitch = btScalar(btAsin(-m_el[2].x()));\n\t\troll = btScalar(btAtan2(m_el[2].y(), m_el[2].z()));\n\n\t\t// on pitch = +/-HalfPI\n\t\tif (btFabs(pitch) == SIMD_HALF_PI)\n\t\t{\n\t\t\tif (yaw > 0)\n\t\t\t\tyaw -= SIMD_PI;\n\t\t\telse\n\t\t\t\tyaw += SIMD_PI;\n\n\t\t\tif (roll > 0)\n\t\t\t\troll -= SIMD_PI;\n\t\t\telse\n\t\t\t\troll += SIMD_PI;\n\t\t}\n\t};\n\n\t/**@brief Get the matrix represented as euler angles around ZYX\n\t* @param yaw Yaw around Z axis\n\t* @param pitch Pitch around Y axis\n\t* @param roll around X axis \n\t* @param solution_number Which solution of two possible solutions ( 1 or 2) are possible values*/\n\tvoid getEulerZYX(btScalar & yaw, btScalar & pitch, btScalar & roll, unsigned int solution_number = 1) const\n\t{\n\t\tstruct Euler\n\t\t{\n\t\t\tbtScalar yaw;\n\t\t\tbtScalar pitch;\n\t\t\tbtScalar roll;\n\t\t};\n\n\t\tEuler euler_out;\n\t\tEuler euler_out2;  //second solution\n\t\t//get the pointer to the raw data\n\n\t\t// Check that pitch is not at a singularity\n\t\tif (btFabs(m_el[2].x()) >= 1)\n\t\t{\n\t\t\teuler_out.yaw = 0;\n\t\t\teuler_out2.yaw = 0;\n\n\t\t\t// From difference of angles formula\n\t\t\tbtScalar delta = btAtan2(m_el[0].x(), m_el[0].z());\n\t\t\tif (m_el[2].x() > 0)  //gimbal locked up\n\t\t\t{\n\t\t\t\teuler_out.pitch = SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out2.pitch = SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out.roll = euler_out.pitch + delta;\n\t\t\t\teuler_out2.roll = euler_out.pitch + delta;\n\t\t\t}\n\t\t\telse  // gimbal locked down\n\t\t\t{\n\t\t\t\teuler_out.pitch = -SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out2.pitch = -SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out.roll = -euler_out.pitch + delta;\n\t\t\t\teuler_out2.roll = -euler_out.pitch + delta;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\teuler_out.pitch = -btAsin(m_el[2].x());\n\t\t\teuler_out2.pitch = SIMD_PI - euler_out.pitch;\n\n\t\t\teuler_out.roll = btAtan2(m_el[2].y() / btCos(euler_out.pitch),\n\t\t\t\t\t\t\t\t\t m_el[2].z() / btCos(euler_out.pitch));\n\t\t\teuler_out2.roll = btAtan2(m_el[2].y() / btCos(euler_out2.pitch),\n\t\t\t\t\t\t\t\t\t  m_el[2].z() / btCos(euler_out2.pitch));\n\n\t\t\teuler_out.yaw = btAtan2(m_el[1].x() / btCos(euler_out.pitch),\n\t\t\t\t\t\t\t\t\tm_el[0].x() / btCos(euler_out.pitch));\n\t\t\teuler_out2.yaw = btAtan2(m_el[1].x() / btCos(euler_out2.pitch),\n\t\t\t\t\t\t\t\t\t m_el[0].x() / btCos(euler_out2.pitch));\n\t\t}\n\n\t\tif (solution_number == 1)\n\t\t{\n\t\t\tyaw = euler_out.yaw;\n\t\t\tpitch = euler_out.pitch;\n\t\t\troll = euler_out.roll;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tyaw = euler_out2.yaw;\n\t\t\tpitch = euler_out2.pitch;\n\t\t\troll = euler_out2.roll;\n\t\t}\n\t}\n\n\t/**@brief Create a scaled copy of the matrix \n\t* @param s Scaling vector The elements of the vector will scale each column */\n\n\tbtMatrix3x3 scaled(const btVector3& s) const\n\t{\n\t\treturn btMatrix3x3(\n\t\t\tm_el[0].x() * s.x(), m_el[0].y() * s.y(), m_el[0].z() * s.z(),\n\t\t\tm_el[1].x() * s.x(), m_el[1].y() * s.y(), m_el[1].z() * s.z(),\n\t\t\tm_el[2].x() * s.x(), m_el[2].y() * s.y(), m_el[2].z() * s.z());\n\t}\n\n\t/**@brief Return the determinant of the matrix */\n\tbtScalar determinant() const;\n\t/**@brief Return the adjoint of the matrix */\n\tbtMatrix3x3 adjoint() const;\n\t/**@brief Return the matrix with all values non negative */\n\tbtMatrix3x3 absolute() const;\n\t/**@brief Return the transpose of the matrix */\n\tbtMatrix3x3 transpose() const;\n\t/**@brief Return the inverse of the matrix */\n\tbtMatrix3x3 inverse() const;\n\n\t/// Solve A * x = b, where b is a column vector. This is more efficient\n\t/// than computing the inverse in one-shot cases.\n\t///Solve33 is from Box2d, thanks to Erin Catto,\n\tbtVector3 solve33(const btVector3& b) const\n\t{\n\t\tbtVector3 col1 = getColumn(0);\n\t\tbtVector3 col2 = getColumn(1);\n\t\tbtVector3 col3 = getColumn(2);\n\n\t\tbtScalar det = btDot(col1, btCross(col2, col3));\n\t\tif (btFabs(det) > SIMD_EPSILON)\n\t\t{\n\t\t\tdet = 1.0f / det;\n\t\t}\n\t\tbtVector3 x;\n\t\tx[0] = det * btDot(b, btCross(col2, col3));\n\t\tx[1] = det * btDot(col1, btCross(b, col3));\n\t\tx[2] = det * btDot(col1, btCross(col2, b));\n\t\treturn x;\n\t}\n\n\tbtMatrix3x3 transposeTimes(const btMatrix3x3& m) const;\n\tbtMatrix3x3 timesTranspose(const btMatrix3x3& m) const;\n\n\tSIMD_FORCE_INLINE btScalar tdotx(const btVector3& v) const\n\t{\n\t\treturn m_el[0].x() * v.x() + m_el[1].x() * v.y() + m_el[2].x() * v.z();\n\t}\n\tSIMD_FORCE_INLINE btScalar tdoty(const btVector3& v) const\n\t{\n\t\treturn m_el[0].y() * v.x() + m_el[1].y() * v.y() + m_el[2].y() * v.z();\n\t}\n\tSIMD_FORCE_INLINE btScalar tdotz(const btVector3& v) const\n\t{\n\t\treturn m_el[0].z() * v.x() + m_el[1].z() * v.y() + m_el[2].z() * v.z();\n\t}\n\n\t///extractRotation is from \"A robust method to extract the rotational part of deformations\"\n\t///See http://dl.acm.org/citation.cfm?doid=2994258.2994269\n\t///decomposes a matrix A in a orthogonal matrix R and a\n\t///symmetric matrix S:\n\t///A = R*S.\n\t///note that R can include both rotation and scaling.\n\tSIMD_FORCE_INLINE void extractRotation(btQuaternion & q, btScalar tolerance = 1.0e-9, int maxIter = 100)\n\t{\n\t\tint iter = 0;\n\t\tbtScalar w;\n\t\tconst btMatrix3x3& A = *this;\n\t\tfor (iter = 0; iter < maxIter; iter++)\n\t\t{\n\t\t\tbtMatrix3x3 R(q);\n\t\t\tbtVector3 omega = (R.getColumn(0).cross(A.getColumn(0)) + R.getColumn(1).cross(A.getColumn(1)) + R.getColumn(2).cross(A.getColumn(2))) * (btScalar(1.0) / btFabs(R.getColumn(0).dot(A.getColumn(0)) + R.getColumn(1).dot(A.getColumn(1)) + R.getColumn(2).dot(A.getColumn(2))) +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  tolerance);\n\t\t\tw = omega.norm();\n\t\t\tif (w < tolerance)\n\t\t\t\tbreak;\n\t\t\tq = btQuaternion(btVector3((btScalar(1.0) / w) * omega), w) *\n\t\t\t\tq;\n\t\t\tq.normalize();\n\t\t}\n\t}\n\n\t/**@brief diagonalizes this matrix by the Jacobi method.\n\t* @param rot stores the rotation from the coordinate system in which the matrix is diagonal to the original\n\t* coordinate system, i.e., old_this = rot * new_this * rot^T.\n\t* @param threshold See iteration\n\t* @param iteration The iteration stops when all off-diagonal elements are less than the threshold multiplied\n\t* by the sum of the absolute values of the diagonal, or when maxSteps have been executed.\n\t*\n\t* Note that this matrix is assumed to be symmetric.\n\t*/\n\tvoid diagonalize(btMatrix3x3 & rot, btScalar threshold, int maxSteps)\n\t{\n\t\trot.setIdentity();\n\t\tfor (int step = maxSteps; step > 0; step--)\n\t\t{\n\t\t\t// find off-diagonal element [p][q] with largest magnitude\n\t\t\tint p = 0;\n\t\t\tint q = 1;\n\t\t\tint r = 2;\n\t\t\tbtScalar max = btFabs(m_el[0][1]);\n\t\t\tbtScalar v = btFabs(m_el[0][2]);\n\t\t\tif (v > max)\n\t\t\t{\n\t\t\t\tq = 2;\n\t\t\t\tr = 1;\n\t\t\t\tmax = v;\n\t\t\t}\n\t\t\tv = btFabs(m_el[1][2]);\n\t\t\tif (v > max)\n\t\t\t{\n\t\t\t\tp = 1;\n\t\t\t\tq = 2;\n\t\t\t\tr = 0;\n\t\t\t\tmax = v;\n\t\t\t}\n\n\t\t\tbtScalar t = threshold * (btFabs(m_el[0][0]) + btFabs(m_el[1][1]) + btFabs(m_el[2][2]));\n\t\t\tif (max <= t)\n\t\t\t{\n\t\t\t\tif (max <= SIMD_EPSILON * t)\n\t\t\t\t{\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tstep = 1;\n\t\t\t}\n\n\t\t\t// compute Jacobi rotation J which leads to a zero for element [p][q]\n\t\t\tbtScalar mpq = m_el[p][q];\n\t\t\tbtScalar theta = (m_el[q][q] - m_el[p][p]) / (2 * mpq);\n\t\t\tbtScalar theta2 = theta * theta;\n\t\t\tbtScalar cos;\n\t\t\tbtScalar sin;\n\t\t\tif (theta2 * theta2 < btScalar(10 / SIMD_EPSILON))\n\t\t\t{\n\t\t\t\tt = (theta >= 0) ? 1 / (theta + btSqrt(1 + theta2))\n\t\t\t\t\t\t\t\t : 1 / (theta - btSqrt(1 + theta2));\n\t\t\t\tcos = 1 / btSqrt(1 + t * t);\n\t\t\t\tsin = cos * t;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// approximation for large theta-value, i.e., a nearly diagonal matrix\n\t\t\t\tt = 1 / (theta * (2 + btScalar(0.5) / theta2));\n\t\t\t\tcos = 1 - btScalar(0.5) * t * t;\n\t\t\t\tsin = cos * t;\n\t\t\t}\n\n\t\t\t// apply rotation to matrix (this = J^T * this * J)\n\t\t\tm_el[p][q] = m_el[q][p] = 0;\n\t\t\tm_el[p][p] -= t * mpq;\n\t\t\tm_el[q][q] += t * mpq;\n\t\t\tbtScalar mrp = m_el[r][p];\n\t\t\tbtScalar mrq = m_el[r][q];\n\t\t\tm_el[r][p] = m_el[p][r] = cos * mrp - sin * mrq;\n\t\t\tm_el[r][q] = m_el[q][r] = cos * mrq + sin * mrp;\n\n\t\t\t// apply rotation to rot (rot = rot * J)\n\t\t\tfor (int i = 0; i < 3; i++)\n\t\t\t{\n\t\t\t\tbtVector3& row = rot[i];\n\t\t\t\tmrp = row[p];\n\t\t\t\tmrq = row[q];\n\t\t\t\trow[p] = cos * mrp - sin * mrq;\n\t\t\t\trow[q] = cos * mrq + sin * mrp;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**@brief Calculate the matrix cofactor \n\t* @param r1 The first row to use for calculating the cofactor\n\t* @param c1 The first column to use for calculating the cofactor\n\t* @param r1 The second row to use for calculating the cofactor\n\t* @param c1 The second column to use for calculating the cofactor\n\t* See http://en.wikipedia.org/wiki/Cofactor_(linear_algebra) for more details\n\t*/\n\tbtScalar cofac(int r1, int c1, int r2, int c2) const\n\t{\n\t\treturn m_el[r1][c1] * m_el[r2][c2] - m_el[r1][c2] * m_el[r2][c1];\n\t}\n\n\tvoid serialize(struct btMatrix3x3Data & dataOut) const;\n\n\tvoid serializeFloat(struct btMatrix3x3FloatData & dataOut) const;\n\n\tvoid deSerialize(const struct btMatrix3x3Data& dataIn);\n\n\tvoid deSerializeFloat(const struct btMatrix3x3FloatData& dataIn);\n\n\tvoid deSerializeDouble(const struct btMatrix3x3DoubleData& dataIn);\n};\n\nSIMD_FORCE_INLINE btMatrix3x3&\nbtMatrix3x3::operator*=(const btMatrix3x3& m)\n{\n\tsetValue(\n\t\tm.tdotx(m_el[0]), m.tdoty(m_el[0]), m.tdotz(m_el[0]),\n\t\tm.tdotx(m_el[1]), m.tdoty(m_el[1]), m.tdotz(m_el[1]),\n\t\tm.tdotx(m_el[2]), m.tdoty(m_el[2]), m.tdotz(m_el[2]));\n\treturn *this;\n}\n\nSIMD_FORCE_INLINE btMatrix3x3&\nbtMatrix3x3::operator+=(const btMatrix3x3& m)\n{\n\tsetValue(\n\t\tm_el[0][0] + m.m_el[0][0],\n\t\tm_el[0][1] + m.m_el[0][1],\n\t\tm_el[0][2] + m.m_el[0][2],\n\t\tm_el[1][0] + m.m_el[1][0],\n\t\tm_el[1][1] + m.m_el[1][1],\n\t\tm_el[1][2] + m.m_el[1][2],\n\t\tm_el[2][0] + m.m_el[2][0],\n\t\tm_el[2][1] + m.m_el[2][1],\n\t\tm_el[2][2] + m.m_el[2][2]);\n\treturn *this;\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator*(const btMatrix3x3& m, const btScalar& k)\n{\n"}], "code": "\tbtQuaternion getRotation() const\n\t{\n\t\tbtQuaternion q;\n\t\tm_basis.getRotation(q);\n\t\treturn q;\n\t}\n"}, "644AC9DDE70BF687": {"calls": [{"id": "12CBC3C0D037A75B", "name": "btQuadWord::setValue", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 170, "col": 2}, "end": {"line": 176, "col": 2}, "code": "\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n};\n\n"}, {"id": "B2E6A2621E997AD7", "name": "btQuadWord::x", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 113, "col": 2}, "end": {"line": 113, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n"}, {"id": "8746EBDA7420066D", "name": "btQuadWord::z", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 117, "col": 2}, "end": {"line": 117, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n"}, {"id": "9E7A9B47DED95E24", "name": "btQuadWord::y", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 115, "col": 2}, "end": {"line": 115, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btQuadWord& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btQuadWord& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set x,y,z and zero w \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = 0.f;\n\t}\n\n\t/*\t\tvoid getValue(btScalar *m) const \n\t\t{\n\t\t\tm[0] = m_floats[0];\n\t\t\tm[1] = m_floats[1];\n\t\t\tm[2] = m_floats[2];\n\t\t}\n*/\n\t/**@brief Set the values \n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n"}], "code": "\tbtQuaternion& operator*=(const btQuaternion& q)\n\t{\n\t\tsetValue(\n\t\t\tm_floats[3] * q.x() + m_floats[0] * q.m_floats[3] + m_floats[1] * q.z() - m_floats[2] * q.y(),\n\t\t\tm_floats[3] * q.y() + m_floats[1] * q.m_floats[3] + m_floats[2] * q.x() - m_floats[0] * q.z(),\n\t\t\tm_floats[3] * q.z() + m_floats[2] * q.m_floats[3] + m_floats[0] * q.y() - m_floats[1] * q.x(),\n\t\t\tm_floats[3] * q.m_floats[3] - m_floats[0] * q.x() - m_floats[1] * q.y() - m_floats[2] * q.z());\n\t\treturn *this;\n\t}\n"}, "6DB4903CDE3D2E8D": {"calls": [{"id": "8D689A25C0394ED1", "name": "btMatrix3x3::cofac", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 801, "col": 2}, "end": {"line": 804, "col": 2}, "code": "\t{\n\t\treturn m_el[r1][c1] * m_el[r2][c2] - m_el[r1][c2] * m_el[r2][c1];\n\t}\n\n\tvoid serialize(struct btMatrix3x3Data & dataOut) const;\n\n\tvoid serializeFloat(struct btMatrix3x3FloatData & dataOut) const;\n\n\tvoid deSerialize(const struct btMatrix3x3Data& dataIn);\n\n\tvoid deSerializeFloat(const struct btMatrix3x3FloatData& dataIn);\n\n\tvoid deSerializeDouble(const struct btMatrix3x3DoubleData& dataIn);\n};\n\nSIMD_FORCE_INLINE btMatrix3x3&\nbtMatrix3x3::operator*=(const btMatrix3x3& m)\n{\n\tsetValue(\n\t\tm.tdotx(m_el[0]), m.tdoty(m_el[0]), m.tdotz(m_el[0]),\n\t\tm.tdotx(m_el[1]), m.tdoty(m_el[1]), m.tdotz(m_el[1]),\n\t\tm.tdotx(m_el[2]), m.tdoty(m_el[2]), m.tdotz(m_el[2]));\n\treturn *this;\n}\n\nSIMD_FORCE_INLINE btMatrix3x3&\nbtMatrix3x3::operator+=(const btMatrix3x3& m)\n{\n\tsetValue(\n\t\tm_el[0][0] + m.m_el[0][0],\n\t\tm_el[0][1] + m.m_el[0][1],\n\t\tm_el[0][2] + m.m_el[0][2],\n\t\tm_el[1][0] + m.m_el[1][0],\n\t\tm_el[1][1] + m.m_el[1][1],\n\t\tm_el[1][2] + m.m_el[1][2],\n\t\tm_el[2][0] + m.m_el[2][0],\n\t\tm_el[2][1] + m.m_el[2][1],\n\t\tm_el[2][2] + m.m_el[2][2]);\n\treturn *this;\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator*(const btMatrix3x3& m, const btScalar& k)\n{\n\treturn btMatrix3x3(\n\t\tm[0].x() * k, m[0].y() * k, m[0].z() * k,\n\t\tm[1].x() * k, m[1].y() * k, m[1].z() * k,\n\t\tm[2].x() * k, m[2].y() * k, m[2].z() * k);\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator+(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn btMatrix3x3(\n\t\tm1[0][0] + m2[0][0],\n\t\tm1[0][1] + m2[0][1],\n\t\tm1[0][2] + m2[0][2],\n\n\t\tm1[1][0] + m2[1][0],\n\t\tm1[1][1] + m2[1][1],\n\t\tm1[1][2] + m2[1][2],\n\n\t\tm1[2][0] + m2[2][0],\n\t\tm1[2][1] + m2[2][1],\n\t\tm1[2][2] + m2[2][2]);\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator-(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn btMatrix3x3(\n\t\tm1[0][0] - m2[0][0],\n\t\tm1[0][1] - m2[0][1],\n\t\tm1[0][2] - m2[0][2],\n\n\t\tm1[1][0] - m2[1][0],\n\t\tm1[1][1] - m2[1][1],\n\t\tm1[1][2] - m2[1][2],\n\n\t\tm1[2][0] - m2[2][0],\n\t\tm1[2][1] - m2[2][1],\n\t\tm1[2][2] - m2[2][2]);\n}\n\nSIMD_FORCE_INLINE btMatrix3x3&\nbtMatrix3x3::operator-=(const btMatrix3x3& m)\n{\n\tsetValue(\n\t\tm_el[0][0] - m.m_el[0][0],\n\t\tm_el[0][1] - m.m_el[0][1],\n\t\tm_el[0][2] - m.m_el[0][2],\n\t\tm_el[1][0] - m.m_el[1][0],\n\t\tm_el[1][1] - m.m_el[1][1],\n\t\tm_el[1][2] - m.m_el[1][2],\n\t\tm_el[2][0] - m.m_el[2][0],\n\t\tm_el[2][1] - m.m_el[2][1],\n\t\tm_el[2][2] - m.m_el[2][2]);\n\treturn *this;\n}\n\nSIMD_FORCE_INLINE btScalar\nbtMatrix3x3::determinant() const\n{\n\treturn btTriple((*this)[0], (*this)[1], (*this)[2]);\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::absolute() const\n{\n\treturn btMatrix3x3(\n\t\tbtFabs(m_el[0].x()), btFabs(m_el[0].y()), btFabs(m_el[0].z()),\n\t\tbtFabs(m_el[1].x()), btFabs(m_el[1].y()), btFabs(m_el[1].z()),\n\t\tbtFabs(m_el[2].x()), btFabs(m_el[2].y()), btFabs(m_el[2].z()));\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::transpose() const\n{\n\treturn btMatrix3x3(m_el[0].x(), m_el[1].x(), m_el[2].x(),\n\t\t\t\t\t   m_el[0].y(), m_el[1].y(), m_el[2].y(),\n\t\t\t\t\t   m_el[0].z(), m_el[1].z(), m_el[2].z());\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::adjoint() const\n{\n\treturn btMatrix3x3(cofac(1, 1, 2, 2), cofac(0, 2, 2, 1), cofac(0, 1, 1, 2),\n\t\t\t\t\t   cofac(1, 2, 2, 0), cofac(0, 0, 2, 2), cofac(0, 2, 1, 0),\n\t\t\t\t\t   cofac(1, 0, 2, 1), cofac(0, 1, 2, 0), cofac(0, 0, 1, 1));\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::inverse() const\n{\n\tbtVector3 co(cofac(1, 1, 2, 2), cofac(1, 2, 2, 0), cofac(1, 0, 2, 1));\n\tbtScalar det = (*this)[0].dot(co);\n\t//btFullAssert(det != btScalar(0.0));\n\tbtAssert(det != btScalar(0.0));\n\tbtScalar s = btScalar(1.0) / det;\n\treturn btMatrix3x3(co.x() * s, cofac(0, 2, 2, 1) * s, cofac(0, 1, 1, 2) * s,\n\t\t\t\t\t   co.y() * s, cofac(0, 0, 2, 2) * s, cofac(0, 2, 1, 0) * s,\n\t\t\t\t\t   co.z() * s, cofac(0, 1, 2, 0) * s, cofac(0, 0, 1, 1) * s);\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::transposeTimes(const btMatrix3x3& m) const\n{\n\treturn btMatrix3x3(\n\t\tm_el[0].x() * m[0].x() + m_el[1].x() * m[1].x() + m_el[2].x() * m[2].x(),\n\t\tm_el[0].x() * m[0].y() + m_el[1].x() * m[1].y() + m_el[2].x() * m[2].y(),\n\t\tm_el[0].x() * m[0].z() + m_el[1].x() * m[1].z() + m_el[2].x() * m[2].z(),\n\t\tm_el[0].y() * m[0].x() + m_el[1].y() * m[1].x() + m_el[2].y() * m[2].x(),\n\t\tm_el[0].y() * m[0].y() + m_el[1].y() * m[1].y() + m_el[2].y() * m[2].y(),\n\t\tm_el[0].y() * m[0].z() + m_el[1].y() * m[1].z() + m_el[2].y() * m[2].z(),\n\t\tm_el[0].z() * m[0].x() + m_el[1].z() * m[1].x() + m_el[2].z() * m[2].x(),\n\t\tm_el[0].z() * m[0].y() + m_el[1].z() * m[1].y() + m_el[2].z() * m[2].y(),\n\t\tm_el[0].z() * m[0].z() + m_el[1].z() * m[1].z() + m_el[2].z() * m[2].z());\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::timesTranspose(const btMatrix3x3& m) const\n{\n\treturn btMatrix3x3(\n\t\tm_el[0].dot(m[0]), m_el[0].dot(m[1]), m_el[0].dot(m[2]),\n\t\tm_el[1].dot(m[0]), m_el[1].dot(m[1]), m_el[1].dot(m[2]),\n\t\tm_el[2].dot(m[0]), m_el[2].dot(m[1]), m_el[2].dot(m[2]));\n}\n\nSIMD_FORCE_INLINE btVector3\noperator*(const btMatrix3x3& m, const btVector3& v)\n{\n\treturn btVector3(m[0].dot(v), m[1].dot(v), m[2].dot(v));\n}\n\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btMatrix3x3& m)\n{\n\treturn btVector3(m.tdotx(v), m.tdoty(v), m.tdotz(v));\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator*(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn btMatrix3x3(\n\t\tm2.tdotx(m1[0]), m2.tdoty(m1[0]), m2.tdotz(m1[0]),\n\t\tm2.tdotx(m1[1]), m2.tdoty(m1[1]), m2.tdotz(m1[1]),\n\t\tm2.tdotx(m1[2]), m2.tdoty(m1[2]), m2.tdotz(m1[2]));\n}\n\n/*\nSIMD_FORCE_INLINE btMatrix3x3 btMultTransposeLeft(const btMatrix3x3& m1, const btMatrix3x3& m2) {\nreturn btMatrix3x3(\nm1[0][0] * m2[0][0] + m1[1][0] * m2[1][0] + m1[2][0] * m2[2][0],\nm1[0][0] * m2[0][1] + m1[1][0] * m2[1][1] + m1[2][0] * m2[2][1],\nm1[0][0] * m2[0][2] + m1[1][0] * m2[1][2] + m1[2][0] * m2[2][2],\nm1[0][1] * m2[0][0] + m1[1][1] * m2[1][0] + m1[2][1] * m2[2][0],\nm1[0][1] * m2[0][1] + m1[1][1] * m2[1][1] + m1[2][1] * m2[2][1],\nm1[0][1] * m2[0][2] + m1[1][1] * m2[1][2] + m1[2][1] * m2[2][2],\nm1[0][2] * m2[0][0] + m1[1][2] * m2[1][0] + m1[2][2] * m2[2][0],\nm1[0][2] * m2[0][1] + m1[1][2] * m2[1][1] + m1[2][2] * m2[2][1],\nm1[0][2] * m2[0][2] + m1[1][2] * m2[1][2] + m1[2][2] * m2[2][2]);\n}\n*/\n\n/**@brief Equality operator between two matrices\n* It will test all elements are equal.  */\nSIMD_FORCE_INLINE bool operator==(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn (m1[0][0] == m2[0][0] && m1[1][0] == m2[1][0] && m1[2][0] == m2[2][0] &&\n\t\t\tm1[0][1] == m2[0][1] && m1[1][1] == m2[1][1] && m1[2][1] == m2[2][1] &&\n\t\t\tm1[0][2] == m2[0][2] && m1[1][2] == m2[1][2] && m1[2][2] == m2[2][2]);\n}\n\n///for serialization\nstruct btMatrix3x3FloatData\n{\n\tbtVector3FloatData m_el[3];\n};\n\n///for serialization\nstruct btMatrix3x3DoubleData\n{\n\tbtVector3DoubleData m_el[3];\n};\n\nSIMD_FORCE_INLINE void btMatrix3x3::serialize(struct btMatrix3x3Data& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serialize(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::serializeFloat(struct btMatrix3x3FloatData& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serializeFloat(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerialize(const struct btMatrix3x3Data& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerialize(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeFloat(const struct btMatrix3x3FloatData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeFloat(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeDouble(const struct btMatrix3x3DoubleData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeDouble(dataIn.m_el[i]);\n}\n\n"}, {"id": "DAD82A67BFB09730", "name": "btVector3::dot", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 229, "col": 2}, "end": {"line": 248, "col": 2}, "code": "\t{\n\t\treturn m_floats[0] * v.m_floats[0] +\n\t\t\t   m_floats[1] * v.m_floats[1] +\n\t\t\t   m_floats[2] * v.m_floats[2];\n\t}\n\n\t/**@brief Return the length of the vector squared */\n\tSIMD_FORCE_INLINE btScalar length2() const\n\t{\n\t\treturn dot(*this);\n\t}\n\n\t/**@brief Return the length of the vector */\n\tSIMD_FORCE_INLINE btScalar length() const\n\t{\n\t\treturn btSqrt(length2());\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar norm() const\n\t{\n\t\treturn length();\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar safeNorm() const\n\t{\n\t\tbtScalar d = length2();\n\t\t//workaround for some clang/gcc issue of sqrtf(tiny number) = -INF\n\t\tif (d > SIMD_EPSILON)\n\t\t\treturn btSqrt(d);\n\t\treturn btScalar(0);\n\t}\n\n\t/**@brief Return the distance squared between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance2(const btVector3& v) const;\n\n\t/**@brief Return the distance between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance(const btVector3& v) const;\n\n\tSIMD_FORCE_INLINE btVector3& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\t//triNormal.normalize();\n\t\tif (l2 >= SIMD_EPSILON * SIMD_EPSILON)\n\t\t{\n\t\t\t(*this) /= btSqrt(l2);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsetValue(1, 0, 0);\n\t\t}\n\t\treturn *this;\n\t}\n\n\t/**@brief Normalize this vector \n   * x^2 + y^2 + z^2 = 1 */\n\tSIMD_FORCE_INLINE btVector3& normalize()\n\t{\n\t\tbtAssert(!fuzzyZero());\n\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a normalized version of this vector */\n\tSIMD_FORCE_INLINE btVector3 normalized() const;\n\n\t/**@brief Return a rotated version of this vector\n   * @param wAxis The axis to rotate about \n   * @param angle The angle to rotate by */\n\tSIMD_FORCE_INLINE btVector3 rotate(const btVector3& wAxis, const btScalar angle) const;\n\n\t/**@brief Return the angle between this and another vector\n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btScalar angle(const btVector3& v) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * v.length2());\n\t\tbtFullAssert(s != btScalar(0.0));\n\t\treturn btAcos(dot(v) / s);\n\t}\n\n\t/**@brief Return a vector with the absolute values of each element */\n\tSIMD_FORCE_INLINE btVector3 absolute() const\n\t{\n\t\treturn btVector3(\n\t\t\tbtFabs(m_floats[0]),\n\t\t\tbtFabs(m_floats[1]),\n\t\t\tbtFabs(m_floats[2]));\n\t}\n\n\t/**@brief Return the cross product between this and another vector \n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btVector3 cross(const btVector3& v) const\n\t{\n\t\treturn btVector3(\n\t\t\tm_floats[1] * v.m_floats[2] - m_floats[2] * v.m_floats[1],\n\t\t\tm_floats[2] * v.m_floats[0] - m_floats[0] * v.m_floats[2],\n\t\t\tm_floats[0] * v.m_floats[1] - m_floats[1] * v.m_floats[0]);\n\t}\n\n\tSIMD_FORCE_INLINE btScalar triple(const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn m_floats[0] * (v1.m_floats[1] * v2.m_floats[2] - v1.m_floats[2] * v2.m_floats[1]) +\n\t\t\t   m_floats[1] * (v1.m_floats[2] * v2.m_floats[0] - v1.m_floats[0] * v2.m_floats[2]) +\n\t\t\t   m_floats[2] * (v1.m_floats[0] * v2.m_floats[1] - v1.m_floats[1] * v2.m_floats[0]);\n\t}\n\n\t/**@brief Return the axis with the smallest value \n   * Note return values are 0,1,2 for x, y, or z */\n\tSIMD_FORCE_INLINE int minAxis() const\n\t{\n\t\treturn m_floats[0] < m_floats[1] ? (m_floats[0] < m_floats[2] ? 0 : 2) : (m_floats[1] < m_floats[2] ? 1 : 2);\n\t}\n\n\t/**@brief Return the axis with the largest value \n   * Note return values are 0,1,2 for x, y, or z */\n\tSIMD_FORCE_INLINE int maxAxis() const\n\t{\n"}, {"id": "3348712AF01B8D6A", "name": "btVector3::x", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 575, "col": 2}, "end": {"line": 575, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "E68B2B787B1362BD", "name": "btVector3::y", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 577, "col": 2}, "end": {"line": 577, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "FB8E24EAC4F7FC28", "name": "btVector3::z", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 579, "col": 2}, "end": {"line": 579, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}], "code": "SIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::inverse() const\n{\n\tbtVector3 co(cofac(1, 1, 2, 2), cofac(1, 2, 2, 0), cofac(1, 0, 2, 1));\n\tbtScalar det = (*this)[0].dot(co);\n\t//btFullAssert(det != btScalar(0.0));\n\tbtAssert(det != btScalar(0.0));\n\tbtScalar s = btScalar(1.0) / det;\n\treturn btMatrix3x3(co.x() * s, cofac(0, 2, 2, 1) * s, cofac(0, 1, 1, 2) * s,\n\t\t\t\t\t   co.y() * s, cofac(0, 0, 2, 2) * s, cofac(0, 2, 1, 0) * s,\n\t\t\t\t\t   co.z() * s, cofac(0, 1, 2, 0) * s, cofac(0, 0, 1, 1) * s);\n}\n"}, "4D92A5C8ECB7C8E0": {"calls": [{"id": "E6264C99E329962B", "name": "btVector3::length2", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 251, "col": 2}, "end": {"line": 254, "col": 2}, "code": "\t{\n\t\treturn dot(*this);\n\t}\n\n\t/**@brief Return the length of the vector */\n\tSIMD_FORCE_INLINE btScalar length() const\n\t{\n\t\treturn btSqrt(length2());\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar norm() const\n\t{\n\t\treturn length();\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar safeNorm() const\n\t{\n\t\tbtScalar d = length2();\n\t\t//workaround for some clang/gcc issue of sqrtf(tiny number) = -INF\n\t\tif (d > SIMD_EPSILON)\n\t\t\treturn btSqrt(d);\n\t\treturn btScalar(0);\n\t}\n\n\t/**@brief Return the distance squared between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance2(const btVector3& v) const;\n\n\t/**@brief Return the distance between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance(const btVector3& v) const;\n\n\tSIMD_FORCE_INLINE btVector3& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\t//triNormal.normalize();\n\t\tif (l2 >= SIMD_EPSILON * SIMD_EPSILON)\n\t\t{\n\t\t\t(*this) /= btSqrt(l2);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsetValue(1, 0, 0);\n\t\t}\n\t\treturn *this;\n\t}\n\n\t/**@brief Normalize this vector \n   * x^2 + y^2 + z^2 = 1 */\n\tSIMD_FORCE_INLINE btVector3& normalize()\n\t{\n\t\tbtAssert(!fuzzyZero());\n\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a normalized version of this vector */\n\tSIMD_FORCE_INLINE btVector3 normalized() const;\n\n\t/**@brief Return a rotated version of this vector\n   * @param wAxis The axis to rotate about \n   * @param angle The angle to rotate by */\n\tSIMD_FORCE_INLINE btVector3 rotate(const btVector3& wAxis, const btScalar angle) const;\n\n\t/**@brief Return the angle between this and another vector\n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btScalar angle(const btVector3& v) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * v.length2());\n\t\tbtFullAssert(s != btScalar(0.0));\n\t\treturn btAcos(dot(v) / s);\n\t}\n\n\t/**@brief Return a vector with the absolute values of each element */\n\tSIMD_FORCE_INLINE btVector3 absolute() const\n\t{\n\t\treturn btVector3(\n\t\t\tbtFabs(m_floats[0]),\n\t\t\tbtFabs(m_floats[1]),\n\t\t\tbtFabs(m_floats[2]));\n\t}\n\n\t/**@brief Return the cross product between this and another vector \n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btVector3 cross(const btVector3& v) const\n\t{\n\t\treturn btVector3(\n\t\t\tm_floats[1] * v.m_floats[2] - m_floats[2] * v.m_floats[1],\n\t\t\tm_floats[2] * v.m_floats[0] - m_floats[0] * v.m_floats[2],\n\t\t\tm_floats[0] * v.m_floats[1] - m_floats[1] * v.m_floats[0]);\n\t}\n\n\tSIMD_FORCE_INLINE btScalar triple(const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn m_floats[0] * (v1.m_floats[1] * v2.m_floats[2] - v1.m_floats[2] * v2.m_floats[1]) +\n\t\t\t   m_floats[1] * (v1.m_floats[2] * v2.m_floats[0] - v1.m_floats[0] * v2.m_floats[2]) +\n\t\t\t   m_floats[2] * (v1.m_floats[0] * v2.m_floats[1] - v1.m_floats[1] * v2.m_floats[0]);\n\t}\n\n\t/**@brief Return the axis with the smallest value \n   * Note return values are 0,1,2 for x, y, or z */\n\tSIMD_FORCE_INLINE int minAxis() const\n\t{\n\t\treturn m_floats[0] < m_floats[1] ? (m_floats[0] < m_floats[2] ? 0 : 2) : (m_floats[1] < m_floats[2] ? 1 : 2);\n\t}\n\n\t/**@brief Return the axis with the largest value \n   * Note return values are 0,1,2 for x, y, or z */\n\tSIMD_FORCE_INLINE int maxAxis() const\n\t{\n\t\treturn m_floats[0] < m_floats[1] ? (m_floats[1] < m_floats[2] ? 2 : 1) : (m_floats[0] < m_floats[2] ? 2 : 0);\n\t}\n\n\tSIMD_FORCE_INLINE int furthestAxis() const\n\t{\n\t\treturn absolute().minAxis();\n\t}\n\n\tSIMD_FORCE_INLINE int closestAxis() const\n\t{\n\t\treturn absolute().maxAxis();\n\t}\n\n\tSIMD_FORCE_INLINE void setInterpolate3(const btVector3& v0, const btVector3& v1, btScalar rt)\n\t{\n"}, {"id": "990147EFEAB272D3", "name": "btSqrt", "path": "bullet3/src/LinearMath/btScalar.h", "start": {"line": 437, "col": 2}, "end": {"line": 440, "col": 2}, "code": "\t{\n\t\treturn sqrt(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btFabs(btScalar x) { return fabs(x); }\n\tSIMD_FORCE_INLINE btScalar btCos(btScalar x) { return cos(x); }\n\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sin(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tan(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn acos(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn asin(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atan(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return exp(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return log(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return pow(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmod(x, y); }\n\n#else//BT_USE_DOUBLE_PRECISION\n\n\tSIMD_FORCE_INLINE btScalar btSqrt(btScalar y)\n\t{\n\t\treturn sqrtf(y);\n\t}\n\tSIMD_FORCE_INLINE btScalar btFabs(btScalar x) { return fabsf(x); }\n\tSIMD_FORCE_INLINE btScalar btCos(btScalar x) { return cosf(x); }\n\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sinf(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn acosf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn asinf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2f(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return expf(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return logf(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return powf(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmodf(x, y); }\n\n\n#define SIMD_PI btScalar(3.1415926535897932384626433832795029)\n#define SIMD_2_PI (btScalar(2.0) * SIMD_PI)\n#define SIMD_HALF_PI (SIMD_PI * btScalar(0.5))\n#define SIMD_RADS_PER_DEG (SIMD_2_PI / btScalar(360.0))\n#define SIMD_DEGS_PER_RAD (btScalar(360.0) / SIMD_2_PI)\n#define SIMDSQRT12 btScalar(0.7071067811865475244008443621048490)\n#define btRecipSqrt(x) ((btScalar)(btScalar(1.0) / btSqrt(btScalar(x)))) /* reciprocal square root */\n#define btRecip(x) (btScalar(1.0) / btScalar(x))\n\n\t#define SIMD_EPSILON FLT_EPSILON\n\t#define SIMD_INFINITY FLT_MAX\n\t#define BT_ONE 1.0f\n\t#define BT_ZERO 0.0f\n\t#define BT_TWO 2.0f\n\t#define BT_HALF 0.5f\n\n// clang-format on\n\nSIMD_FORCE_INLINE btScalar btAtan2Fast(btScalar y, btScalar x)\n{\n\tbtScalar coeff_1 = SIMD_PI / 4.0f;\n\tbtScalar coeff_2 = 3.0f * coeff_1;\n\tbtScalar abs_y = btFabs(y);\n\tbtScalar angle;\n\tif (x >= 0.0f)\n\t{\n\t\tbtScalar r = (x - abs_y) / (x + abs_y);\n\t\tangle = coeff_1 - coeff_1 * r;\n\t}\n\telse\n\t{\n\t\tbtScalar r = (x + abs_y) / (abs_y - x);\n\t\tangle = coeff_2 - coeff_1 * r;\n\t}\n\treturn (y < 0.0f) ? -angle : angle;\n}\n\nSIMD_FORCE_INLINE bool btFuzzyZero(btScalar x) { return btFabs(x) < SIMD_EPSILON; }\n\nSIMD_FORCE_INLINE bool btEqual(btScalar a, btScalar eps)\n{\n\treturn (((a) <= eps) && !((a) < -eps));\n}\nSIMD_FORCE_INLINE bool btGreaterEqual(btScalar a, btScalar eps)\n{\n\treturn (!((a) <= eps));\n}\n\nSIMD_FORCE_INLINE int btIsNegative(btScalar x)\n{\n\treturn x < btScalar(0.0) ? 1 : 0;\n}\n\nSIMD_FORCE_INLINE btScalar btRadians(btScalar x) { return x * SIMD_RADS_PER_DEG; }\nSIMD_FORCE_INLINE btScalar btDegrees(btScalar x) { return x * SIMD_DEGS_PER_RAD; }\n\n#define BT_DECLARE_HANDLE(name) \\\n\ttypedef struct name##__     \\\n\t{                           \\\n\t\tint unused;             \\\n\t} * name\n\n"}], "code": "\tSIMD_FORCE_INLINE btScalar safeNorm() const\n\t{\n\t\tbtScalar d = length2();\n\t\t//workaround for some clang/gcc issue of sqrtf(tiny number) = -INF\n\t\tif (d > SIMD_EPSILON)\n\t\t\treturn btSqrt(d);\n\t\treturn btScalar(0);\n\t}\n"}, "8525E9B5122076A1": {"calls": [{"id": "A8A583866BA9EA0E", "name": "btFabs", "path": "bullet3/src/LinearMath/btScalar.h", "start": {"line": 441, "col": 2}, "end": {"line": 441, "col": 66}, "code": "\tSIMD_FORCE_INLINE btScalar btCos(btScalar x) { return cos(x); }\n\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sin(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tan(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn acos(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn asin(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atan(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return exp(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return log(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return pow(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmod(x, y); }\n\n#else//BT_USE_DOUBLE_PRECISION\n\n\tSIMD_FORCE_INLINE btScalar btSqrt(btScalar y)\n\t{\n\t\treturn sqrtf(y);\n\t}\n\tSIMD_FORCE_INLINE btScalar btFabs(btScalar x) { return fabsf(x); }\n\tSIMD_FORCE_INLINE btScalar btCos(btScalar x) { return cosf(x); }\n\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sinf(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn acosf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn asinf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2f(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return expf(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return logf(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return powf(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmodf(x, y); }\n\n\n#define SIMD_PI btScalar(3.1415926535897932384626433832795029)\n#define SIMD_2_PI (btScalar(2.0) * SIMD_PI)\n#define SIMD_HALF_PI (SIMD_PI * btScalar(0.5))\n#define SIMD_RADS_PER_DEG (SIMD_2_PI / btScalar(360.0))\n#define SIMD_DEGS_PER_RAD (btScalar(360.0) / SIMD_2_PI)\n#define SIMDSQRT12 btScalar(0.7071067811865475244008443621048490)\n#define btRecipSqrt(x) ((btScalar)(btScalar(1.0) / btSqrt(btScalar(x)))) /* reciprocal square root */\n#define btRecip(x) (btScalar(1.0) / btScalar(x))\n\n\t#define SIMD_EPSILON FLT_EPSILON\n\t#define SIMD_INFINITY FLT_MAX\n\t#define BT_ONE 1.0f\n\t#define BT_ZERO 0.0f\n\t#define BT_TWO 2.0f\n\t#define BT_HALF 0.5f\n\n// clang-format on\n\nSIMD_FORCE_INLINE btScalar btAtan2Fast(btScalar y, btScalar x)\n{\n\tbtScalar coeff_1 = SIMD_PI / 4.0f;\n\tbtScalar coeff_2 = 3.0f * coeff_1;\n\tbtScalar abs_y = btFabs(y);\n\tbtScalar angle;\n\tif (x >= 0.0f)\n\t{\n\t\tbtScalar r = (x - abs_y) / (x + abs_y);\n\t\tangle = coeff_1 - coeff_1 * r;\n\t}\n\telse\n\t{\n\t\tbtScalar r = (x + abs_y) / (abs_y - x);\n\t\tangle = coeff_2 - coeff_1 * r;\n\t}\n\treturn (y < 0.0f) ? -angle : angle;\n}\n\nSIMD_FORCE_INLINE bool btFuzzyZero(btScalar x) { return btFabs(x) < SIMD_EPSILON; }\n\nSIMD_FORCE_INLINE bool btEqual(btScalar a, btScalar eps)\n{\n\treturn (((a) <= eps) && !((a) < -eps));\n}\nSIMD_FORCE_INLINE bool btGreaterEqual(btScalar a, btScalar eps)\n{\n\treturn (!((a) <= eps));\n}\n\nSIMD_FORCE_INLINE int btIsNegative(btScalar x)\n{\n\treturn x < btScalar(0.0) ? 1 : 0;\n}\n\nSIMD_FORCE_INLINE btScalar btRadians(btScalar x) { return x * SIMD_RADS_PER_DEG; }\nSIMD_FORCE_INLINE btScalar btDegrees(btScalar x) { return x * SIMD_DEGS_PER_RAD; }\n\n#define BT_DECLARE_HANDLE(name) \\\n\ttypedef struct name##__     \\\n\t{                           \\\n\t\tint unused;             \\\n\t} * name\n\n"}, {"id": "3348712AF01B8D6A", "name": "btVector3::x", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 575, "col": 2}, "end": {"line": 575, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "E68B2B787B1362BD", "name": "btVector3::y", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 577, "col": 2}, "end": {"line": 577, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "FB8E24EAC4F7FC28", "name": "btVector3::z", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 579, "col": 2}, "end": {"line": 579, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}], "code": "SIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::absolute() const\n{\n\treturn btMatrix3x3(\n\t\tbtFabs(m_el[0].x()), btFabs(m_el[0].y()), btFabs(m_el[0].z()),\n\t\tbtFabs(m_el[1].x()), btFabs(m_el[1].y()), btFabs(m_el[1].z()),\n\t\tbtFabs(m_el[2].x()), btFabs(m_el[2].y()), btFabs(m_el[2].z()));\n}\n"}, "B5A502EC16994350": {"calls": [{"id": "22700CF7924B3CEC", "name": "btVector3::length", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 257, "col": 2}, "end": {"line": 260, "col": 2}, "code": "\t{\n\t\treturn btSqrt(length2());\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar norm() const\n\t{\n\t\treturn length();\n\t}\n\n\t/**@brief Return the norm (length) of the vector */\n\tSIMD_FORCE_INLINE btScalar safeNorm() const\n\t{\n\t\tbtScalar d = length2();\n\t\t//workaround for some clang/gcc issue of sqrtf(tiny number) = -INF\n\t\tif (d > SIMD_EPSILON)\n\t\t\treturn btSqrt(d);\n\t\treturn btScalar(0);\n\t}\n\n\t/**@brief Return the distance squared between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance2(const btVector3& v) const;\n\n\t/**@brief Return the distance between the ends of this and another vector\n   * This is symantically treating the vector like a point */\n\tSIMD_FORCE_INLINE btScalar distance(const btVector3& v) const;\n\n\tSIMD_FORCE_INLINE btVector3& safeNormalize()\n\t{\n\t\tbtScalar l2 = length2();\n\t\t//triNormal.normalize();\n\t\tif (l2 >= SIMD_EPSILON * SIMD_EPSILON)\n\t\t{\n\t\t\t(*this) /= btSqrt(l2);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsetValue(1, 0, 0);\n\t\t}\n\t\treturn *this;\n\t}\n\n\t/**@brief Normalize this vector \n   * x^2 + y^2 + z^2 = 1 */\n\tSIMD_FORCE_INLINE btVector3& normalize()\n\t{\n\t\tbtAssert(!fuzzyZero());\n\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a normalized version of this vector */\n\tSIMD_FORCE_INLINE btVector3 normalized() const;\n\n\t/**@brief Return a rotated version of this vector\n   * @param wAxis The axis to rotate about \n   * @param angle The angle to rotate by */\n\tSIMD_FORCE_INLINE btVector3 rotate(const btVector3& wAxis, const btScalar angle) const;\n\n\t/**@brief Return the angle between this and another vector\n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btScalar angle(const btVector3& v) const\n\t{\n\t\tbtScalar s = btSqrt(length2() * v.length2());\n\t\tbtFullAssert(s != btScalar(0.0));\n\t\treturn btAcos(dot(v) / s);\n\t}\n\n\t/**@brief Return a vector with the absolute values of each element */\n\tSIMD_FORCE_INLINE btVector3 absolute() const\n\t{\n\t\treturn btVector3(\n\t\t\tbtFabs(m_floats[0]),\n\t\t\tbtFabs(m_floats[1]),\n\t\t\tbtFabs(m_floats[2]));\n\t}\n\n\t/**@brief Return the cross product between this and another vector \n   * @param v The other vector */\n\tSIMD_FORCE_INLINE btVector3 cross(const btVector3& v) const\n\t{\n\t\treturn btVector3(\n\t\t\tm_floats[1] * v.m_floats[2] - m_floats[2] * v.m_floats[1],\n\t\t\tm_floats[2] * v.m_floats[0] - m_floats[0] * v.m_floats[2],\n\t\t\tm_floats[0] * v.m_floats[1] - m_floats[1] * v.m_floats[0]);\n\t}\n\n\tSIMD_FORCE_INLINE btScalar triple(const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn m_floats[0] * (v1.m_floats[1] * v2.m_floats[2] - v1.m_floats[2] * v2.m_floats[1]) +\n\t\t\t   m_floats[1] * (v1.m_floats[2] * v2.m_floats[0] - v1.m_floats[0] * v2.m_floats[2]) +\n\t\t\t   m_floats[2] * (v1.m_floats[0] * v2.m_floats[1] - v1.m_floats[1] * v2.m_floats[0]);\n\t}\n\n\t/**@brief Return the axis with the smallest value \n   * Note return values are 0,1,2 for x, y, or z */\n\tSIMD_FORCE_INLINE int minAxis() const\n\t{\n\t\treturn m_floats[0] < m_floats[1] ? (m_floats[0] < m_floats[2] ? 0 : 2) : (m_floats[1] < m_floats[2] ? 1 : 2);\n\t}\n\n\t/**@brief Return the axis with the largest value \n   * Note return values are 0,1,2 for x, y, or z */\n\tSIMD_FORCE_INLINE int maxAxis() const\n\t{\n\t\treturn m_floats[0] < m_floats[1] ? (m_floats[1] < m_floats[2] ? 2 : 1) : (m_floats[0] < m_floats[2] ? 2 : 0);\n\t}\n\n\tSIMD_FORCE_INLINE int furthestAxis() const\n\t{\n\t\treturn absolute().minAxis();\n\t}\n\n\tSIMD_FORCE_INLINE int closestAxis() const\n\t{\n\t\treturn absolute().maxAxis();\n\t}\n\n\tSIMD_FORCE_INLINE void setInterpolate3(const btVector3& v0, const btVector3& v1, btScalar rt)\n\t{\n\t\tbtScalar s = btScalar(1.0) - rt;\n\t\tm_floats[0] = s * v0.m_floats[0] + rt * v1.m_floats[0];\n\t\tm_floats[1] = s * v0.m_floats[1] + rt * v1.m_floats[1];\n\t\tm_floats[2] = s * v0.m_floats[2] + rt * v1.m_floats[2];\n\t\t//don't do the unused w component\n\t\t//\t\tm_co[3] = s * v0[3] + rt * v1[3];\n\t}\n\n\t/**@brief Return the linear interpolation between this and another vector \n"}, {"id": "A549E8F52C4EA59C", "name": "btSin", "path": "bullet3/src/LinearMath/btScalar.h", "start": {"line": 443, "col": 2}, "end": {"line": 443, "col": 64}, "code": "\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tan(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn acos(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn asin(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atan(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return exp(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return log(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return pow(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmod(x, y); }\n\n#else//BT_USE_DOUBLE_PRECISION\n\n\tSIMD_FORCE_INLINE btScalar btSqrt(btScalar y)\n\t{\n\t\treturn sqrtf(y);\n\t}\n\tSIMD_FORCE_INLINE btScalar btFabs(btScalar x) { return fabsf(x); }\n\tSIMD_FORCE_INLINE btScalar btCos(btScalar x) { return cosf(x); }\n\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sinf(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn acosf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn asinf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2f(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return expf(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return logf(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return powf(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmodf(x, y); }\n\n\n#define SIMD_PI btScalar(3.1415926535897932384626433832795029)\n#define SIMD_2_PI (btScalar(2.0) * SIMD_PI)\n#define SIMD_HALF_PI (SIMD_PI * btScalar(0.5))\n#define SIMD_RADS_PER_DEG (SIMD_2_PI / btScalar(360.0))\n#define SIMD_DEGS_PER_RAD (btScalar(360.0) / SIMD_2_PI)\n#define SIMDSQRT12 btScalar(0.7071067811865475244008443621048490)\n#define btRecipSqrt(x) ((btScalar)(btScalar(1.0) / btSqrt(btScalar(x)))) /* reciprocal square root */\n#define btRecip(x) (btScalar(1.0) / btScalar(x))\n\n\t#define SIMD_EPSILON FLT_EPSILON\n\t#define SIMD_INFINITY FLT_MAX\n\t#define BT_ONE 1.0f\n\t#define BT_ZERO 0.0f\n\t#define BT_TWO 2.0f\n\t#define BT_HALF 0.5f\n\n// clang-format on\n\nSIMD_FORCE_INLINE btScalar btAtan2Fast(btScalar y, btScalar x)\n{\n\tbtScalar coeff_1 = SIMD_PI / 4.0f;\n\tbtScalar coeff_2 = 3.0f * coeff_1;\n\tbtScalar abs_y = btFabs(y);\n\tbtScalar angle;\n\tif (x >= 0.0f)\n\t{\n\t\tbtScalar r = (x - abs_y) / (x + abs_y);\n\t\tangle = coeff_1 - coeff_1 * r;\n\t}\n\telse\n\t{\n\t\tbtScalar r = (x + abs_y) / (abs_y - x);\n\t\tangle = coeff_2 - coeff_1 * r;\n\t}\n\treturn (y < 0.0f) ? -angle : angle;\n}\n\nSIMD_FORCE_INLINE bool btFuzzyZero(btScalar x) { return btFabs(x) < SIMD_EPSILON; }\n\nSIMD_FORCE_INLINE bool btEqual(btScalar a, btScalar eps)\n{\n\treturn (((a) <= eps) && !((a) < -eps));\n}\nSIMD_FORCE_INLINE bool btGreaterEqual(btScalar a, btScalar eps)\n{\n\treturn (!((a) <= eps));\n}\n\nSIMD_FORCE_INLINE int btIsNegative(btScalar x)\n{\n\treturn x < btScalar(0.0) ? 1 : 0;\n}\n\nSIMD_FORCE_INLINE btScalar btRadians(btScalar x) { return x * SIMD_RADS_PER_DEG; }\nSIMD_FORCE_INLINE btScalar btDegrees(btScalar x) { return x * SIMD_DEGS_PER_RAD; }\n\n#define BT_DECLARE_HANDLE(name) \\\n\ttypedef struct name##__     \\\n\t{                           \\\n\t\tint unused;             \\\n\t} * name\n\n"}, {"id": "12CBC3C0D037A75B", "name": "btQuadWord::setValue", "path": "bullet3/src/LinearMath/btQuadWord.h", "start": {"line": 170, "col": 2}, "end": {"line": 176, "col": 2}, "code": "\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tSIMD_FORCE_INLINE btQuadWord()\n\t//\t:m_floats[0](btScalar(0.)),m_floats[1](btScalar(0.)),m_floats[2](btScalar(0.)),m_floats[3](btScalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tSIMD_FORCE_INLINE btQuadWord(const btScalar& _x, const btScalar& _y, const btScalar& _z, const btScalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btQuadWord& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another btQuadWord\n   * @param other The other btQuadWord to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btQuadWord& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.m_floats[3]);\n\t}\n};\n\n"}, {"id": "3348712AF01B8D6A", "name": "btVector3::x", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 575, "col": 2}, "end": {"line": 575, "col": 68}, "code": "\t/**@brief Return the y value */\n\tSIMD_FORCE_INLINE const btScalar& y() const { return m_floats[1]; }\n\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "E68B2B787B1362BD", "name": "btVector3::y", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 577, "col": 2}, "end": {"line": 577, "col": 68}, "code": "\t/**@brief Return the z value */\n\tSIMD_FORCE_INLINE const btScalar& z() const { return m_floats[2]; }\n\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "FB8E24EAC4F7FC28", "name": "btVector3::z", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 579, "col": 2}, "end": {"line": 579, "col": 68}, "code": "\t/**@brief Return the w value */\n\tSIMD_FORCE_INLINE const btScalar& w() const { return m_floats[3]; }\n\n\t//SIMD_FORCE_INLINE btScalar&       operator[](int i)       { return (&m_floats[0])[i];\t}\n\t//SIMD_FORCE_INLINE const btScalar& operator[](int i) const { return (&m_floats[0])[i]; }\n\t///operator btScalar*() replaces operator[], using implicit conversion. We added operator != and operator == to avoid pointer comparisons.\n\tSIMD_FORCE_INLINE operator btScalar*() { return &m_floats[0]; }\n\tSIMD_FORCE_INLINE operator const btScalar*() const { return &m_floats[0]; }\n\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "3EFEBC08E3877358", "name": "btCos", "path": "bullet3/src/LinearMath/btScalar.h", "start": {"line": 442, "col": 2}, "end": {"line": 442, "col": 64}, "code": "\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sin(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tan(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn acos(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1)) x = btScalar(-1);\n\t\tif (x > btScalar(1)) x = btScalar(1);\n\t\treturn asin(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atan(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return exp(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return log(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return pow(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmod(x, y); }\n\n#else//BT_USE_DOUBLE_PRECISION\n\n\tSIMD_FORCE_INLINE btScalar btSqrt(btScalar y)\n\t{\n\t\treturn sqrtf(y);\n\t}\n\tSIMD_FORCE_INLINE btScalar btFabs(btScalar x) { return fabsf(x); }\n\tSIMD_FORCE_INLINE btScalar btCos(btScalar x) { return cosf(x); }\n\tSIMD_FORCE_INLINE btScalar btSin(btScalar x) { return sinf(x); }\n\tSIMD_FORCE_INLINE btScalar btTan(btScalar x) { return tanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAcos(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn acosf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAsin(btScalar x)\n\t{\n\t\tif (x < btScalar(-1))\n\t\t\tx = btScalar(-1);\n\t\tif (x > btScalar(1))\n\t\t\tx = btScalar(1);\n\t\treturn asinf(x);\n\t}\n\tSIMD_FORCE_INLINE btScalar btAtan(btScalar x) { return atanf(x); }\n\tSIMD_FORCE_INLINE btScalar btAtan2(btScalar x, btScalar y) { return atan2f(x, y); }\n\tSIMD_FORCE_INLINE btScalar btExp(btScalar x) { return expf(x); }\n\tSIMD_FORCE_INLINE btScalar btLog(btScalar x) { return logf(x); }\n\tSIMD_FORCE_INLINE btScalar btPow(btScalar x, btScalar y) { return powf(x, y); }\n\tSIMD_FORCE_INLINE btScalar btFmod(btScalar x, btScalar y) { return fmodf(x, y); }\n\n\n#define SIMD_PI btScalar(3.1415926535897932384626433832795029)\n#define SIMD_2_PI (btScalar(2.0) * SIMD_PI)\n#define SIMD_HALF_PI (SIMD_PI * btScalar(0.5))\n#define SIMD_RADS_PER_DEG (SIMD_2_PI / btScalar(360.0))\n#define SIMD_DEGS_PER_RAD (btScalar(360.0) / SIMD_2_PI)\n#define SIMDSQRT12 btScalar(0.7071067811865475244008443621048490)\n#define btRecipSqrt(x) ((btScalar)(btScalar(1.0) / btSqrt(btScalar(x)))) /* reciprocal square root */\n#define btRecip(x) (btScalar(1.0) / btScalar(x))\n\n\t#define SIMD_EPSILON FLT_EPSILON\n\t#define SIMD_INFINITY FLT_MAX\n\t#define BT_ONE 1.0f\n\t#define BT_ZERO 0.0f\n\t#define BT_TWO 2.0f\n\t#define BT_HALF 0.5f\n\n// clang-format on\n\nSIMD_FORCE_INLINE btScalar btAtan2Fast(btScalar y, btScalar x)\n{\n\tbtScalar coeff_1 = SIMD_PI / 4.0f;\n\tbtScalar coeff_2 = 3.0f * coeff_1;\n\tbtScalar abs_y = btFabs(y);\n\tbtScalar angle;\n\tif (x >= 0.0f)\n\t{\n\t\tbtScalar r = (x - abs_y) / (x + abs_y);\n\t\tangle = coeff_1 - coeff_1 * r;\n\t}\n\telse\n\t{\n\t\tbtScalar r = (x + abs_y) / (abs_y - x);\n\t\tangle = coeff_2 - coeff_1 * r;\n\t}\n\treturn (y < 0.0f) ? -angle : angle;\n}\n\nSIMD_FORCE_INLINE bool btFuzzyZero(btScalar x) { return btFabs(x) < SIMD_EPSILON; }\n\nSIMD_FORCE_INLINE bool btEqual(btScalar a, btScalar eps)\n{\n\treturn (((a) <= eps) && !((a) < -eps));\n}\nSIMD_FORCE_INLINE bool btGreaterEqual(btScalar a, btScalar eps)\n{\n\treturn (!((a) <= eps));\n}\n\nSIMD_FORCE_INLINE int btIsNegative(btScalar x)\n{\n\treturn x < btScalar(0.0) ? 1 : 0;\n}\n\nSIMD_FORCE_INLINE btScalar btRadians(btScalar x) { return x * SIMD_RADS_PER_DEG; }\nSIMD_FORCE_INLINE btScalar btDegrees(btScalar x) { return x * SIMD_DEGS_PER_RAD; }\n\n#define BT_DECLARE_HANDLE(name) \\\n\ttypedef struct name##__     \\\n\t{                           \\\n\t\tint unused;             \\\n\t} * name\n\n"}], "code": "\tvoid setRotation(const btVector3& axis, const btScalar& _angle)\n\t{\n\t\tbtScalar d = axis.length();\n\t\tbtAssert(d != btScalar(0.0));\n\t\tbtScalar s = btSin(_angle * btScalar(0.5)) / d;\n\t\tsetValue(axis.x() * s, axis.y() * s, axis.z() * s,\n\t\t\t\t btCos(_angle * btScalar(0.5)));\n\t}\n"}, "2E7884C495DBA639": {"calls": [{"id": "709F415D25CCD233", "name": "btMatrix3x3::transpose", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 1048, "col": 1}, "end": {"line": 1082, "col": 1}, "code": "btMatrix3x3::transpose() const\n{\n\treturn btMatrix3x3(m_el[0].x(), m_el[1].x(), m_el[2].x(),\n\t\t\t\t\t   m_el[0].y(), m_el[1].y(), m_el[2].y(),\n\t\t\t\t\t   m_el[0].z(), m_el[1].z(), m_el[2].z());\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::adjoint() const\n{\n\treturn btMatrix3x3(cofac(1, 1, 2, 2), cofac(0, 2, 2, 1), cofac(0, 1, 1, 2),\n\t\t\t\t\t   cofac(1, 2, 2, 0), cofac(0, 0, 2, 2), cofac(0, 2, 1, 0),\n\t\t\t\t\t   cofac(1, 0, 2, 1), cofac(0, 1, 2, 0), cofac(0, 0, 1, 1));\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::inverse() const\n{\n\tbtVector3 co(cofac(1, 1, 2, 2), cofac(1, 2, 2, 0), cofac(1, 0, 2, 1));\n\tbtScalar det = (*this)[0].dot(co);\n\t//btFullAssert(det != btScalar(0.0));\n\tbtAssert(det != btScalar(0.0));\n\tbtScalar s = btScalar(1.0) / det;\n\treturn btMatrix3x3(co.x() * s, cofac(0, 2, 2, 1) * s, cofac(0, 1, 1, 2) * s,\n\t\t\t\t\t   co.y() * s, cofac(0, 0, 2, 2) * s, cofac(0, 2, 1, 0) * s,\n\t\t\t\t\t   co.z() * s, cofac(0, 1, 2, 0) * s, cofac(0, 0, 1, 1) * s);\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::transposeTimes(const btMatrix3x3& m) const\n{\n\treturn btMatrix3x3(\n\t\tm_el[0].x() * m[0].x() + m_el[1].x() * m[1].x() + m_el[2].x() * m[2].x(),\n\t\tm_el[0].x() * m[0].y() + m_el[1].x() * m[1].y() + m_el[2].x() * m[2].y(),\n\t\tm_el[0].x() * m[0].z() + m_el[1].x() * m[1].z() + m_el[2].x() * m[2].z(),\n\t\tm_el[0].y() * m[0].x() + m_el[1].y() * m[1].x() + m_el[2].y() * m[2].x(),\n\t\tm_el[0].y() * m[0].y() + m_el[1].y() * m[1].y() + m_el[2].y() * m[2].y(),\n\t\tm_el[0].y() * m[0].z() + m_el[1].y() * m[1].z() + m_el[2].y() * m[2].z(),\n\t\tm_el[0].z() * m[0].x() + m_el[1].z() * m[1].x() + m_el[2].z() * m[2].x(),\n\t\tm_el[0].z() * m[0].y() + m_el[1].z() * m[1].y() + m_el[2].z() * m[2].y(),\n\t\tm_el[0].z() * m[0].z() + m_el[1].z() * m[1].z() + m_el[2].z() * m[2].z());\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\nbtMatrix3x3::timesTranspose(const btMatrix3x3& m) const\n{\n\treturn btMatrix3x3(\n\t\tm_el[0].dot(m[0]), m_el[0].dot(m[1]), m_el[0].dot(m[2]),\n\t\tm_el[1].dot(m[0]), m_el[1].dot(m[1]), m_el[1].dot(m[2]),\n\t\tm_el[2].dot(m[0]), m_el[2].dot(m[1]), m_el[2].dot(m[2]));\n}\n\nSIMD_FORCE_INLINE btVector3\noperator*(const btMatrix3x3& m, const btVector3& v)\n{\n\treturn btVector3(m[0].dot(v), m[1].dot(v), m[2].dot(v));\n}\n\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btMatrix3x3& m)\n{\n\treturn btVector3(m.tdotx(v), m.tdoty(v), m.tdotz(v));\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator*(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn btMatrix3x3(\n\t\tm2.tdotx(m1[0]), m2.tdoty(m1[0]), m2.tdotz(m1[0]),\n\t\tm2.tdotx(m1[1]), m2.tdoty(m1[1]), m2.tdotz(m1[1]),\n\t\tm2.tdotx(m1[2]), m2.tdoty(m1[2]), m2.tdotz(m1[2]));\n}\n\n/*\nSIMD_FORCE_INLINE btMatrix3x3 btMultTransposeLeft(const btMatrix3x3& m1, const btMatrix3x3& m2) {\nreturn btMatrix3x3(\nm1[0][0] * m2[0][0] + m1[1][0] * m2[1][0] + m1[2][0] * m2[2][0],\nm1[0][0] * m2[0][1] + m1[1][0] * m2[1][1] + m1[2][0] * m2[2][1],\nm1[0][0] * m2[0][2] + m1[1][0] * m2[1][2] + m1[2][0] * m2[2][2],\nm1[0][1] * m2[0][0] + m1[1][1] * m2[1][0] + m1[2][1] * m2[2][0],\nm1[0][1] * m2[0][1] + m1[1][1] * m2[1][1] + m1[2][1] * m2[2][1],\nm1[0][1] * m2[0][2] + m1[1][1] * m2[1][2] + m1[2][1] * m2[2][2],\nm1[0][2] * m2[0][0] + m1[1][2] * m2[1][0] + m1[2][2] * m2[2][0],\nm1[0][2] * m2[0][1] + m1[1][2] * m2[1][1] + m1[2][2] * m2[2][1],\nm1[0][2] * m2[0][2] + m1[1][2] * m2[1][2] + m1[2][2] * m2[2][2]);\n}\n*/\n\n/**@brief Equality operator between two matrices\n* It will test all elements are equal.  */\nSIMD_FORCE_INLINE bool operator==(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn (m1[0][0] == m2[0][0] && m1[1][0] == m2[1][0] && m1[2][0] == m2[2][0] &&\n\t\t\tm1[0][1] == m2[0][1] && m1[1][1] == m2[1][1] && m1[2][1] == m2[2][1] &&\n\t\t\tm1[0][2] == m2[0][2] && m1[1][2] == m2[1][2] && m1[2][2] == m2[2][2]);\n}\n\n///for serialization\nstruct btMatrix3x3FloatData\n{\n\tbtVector3FloatData m_el[3];\n};\n\n///for serialization\nstruct btMatrix3x3DoubleData\n{\n\tbtVector3DoubleData m_el[3];\n};\n\nSIMD_FORCE_INLINE void btMatrix3x3::serialize(struct btMatrix3x3Data& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serialize(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::serializeFloat(struct btMatrix3x3FloatData& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serializeFloat(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerialize(const struct btMatrix3x3Data& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerialize(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeFloat(const struct btMatrix3x3FloatData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeFloat(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeDouble(const struct btMatrix3x3DoubleData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeDouble(dataIn.m_el[i]);\n}\n\n"}, {"id": "F6A836C41F42C50E", "name": "operator*", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 1214, "col": 1}, "end": {"line": 1222, "col": 1}, "code": "operator*(const btMatrix3x3& m, const btVector3& v)\n{\n\treturn btVector3(m[0].dot(v), m[1].dot(v), m[2].dot(v));\n}\n\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btMatrix3x3& m)\n{\n\treturn btVector3(m.tdotx(v), m.tdoty(v), m.tdotz(v));\n}\n\nSIMD_FORCE_INLINE btMatrix3x3\noperator*(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn btMatrix3x3(\n\t\tm2.tdotx(m1[0]), m2.tdoty(m1[0]), m2.tdotz(m1[0]),\n\t\tm2.tdotx(m1[1]), m2.tdoty(m1[1]), m2.tdotz(m1[1]),\n\t\tm2.tdotx(m1[2]), m2.tdoty(m1[2]), m2.tdotz(m1[2]));\n}\n\n/*\nSIMD_FORCE_INLINE btMatrix3x3 btMultTransposeLeft(const btMatrix3x3& m1, const btMatrix3x3& m2) {\nreturn btMatrix3x3(\nm1[0][0] * m2[0][0] + m1[1][0] * m2[1][0] + m1[2][0] * m2[2][0],\nm1[0][0] * m2[0][1] + m1[1][0] * m2[1][1] + m1[2][0] * m2[2][1],\nm1[0][0] * m2[0][2] + m1[1][0] * m2[1][2] + m1[2][0] * m2[2][2],\nm1[0][1] * m2[0][0] + m1[1][1] * m2[1][0] + m1[2][1] * m2[2][0],\nm1[0][1] * m2[0][1] + m1[1][1] * m2[1][1] + m1[2][1] * m2[2][1],\nm1[0][1] * m2[0][2] + m1[1][1] * m2[1][2] + m1[2][1] * m2[2][2],\nm1[0][2] * m2[0][0] + m1[1][2] * m2[1][0] + m1[2][2] * m2[2][0],\nm1[0][2] * m2[0][1] + m1[1][2] * m2[1][1] + m1[2][2] * m2[2][1],\nm1[0][2] * m2[0][2] + m1[1][2] * m2[1][2] + m1[2][2] * m2[2][2]);\n}\n*/\n\n/**@brief Equality operator between two matrices\n* It will test all elements are equal.  */\nSIMD_FORCE_INLINE bool operator==(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn (m1[0][0] == m2[0][0] && m1[1][0] == m2[1][0] && m1[2][0] == m2[2][0] &&\n\t\t\tm1[0][1] == m2[0][1] && m1[1][1] == m2[1][1] && m1[2][1] == m2[2][1] &&\n\t\t\tm1[0][2] == m2[0][2] && m1[1][2] == m2[1][2] && m1[2][2] == m2[2][2]);\n}\n\n///for serialization\nstruct btMatrix3x3FloatData\n{\n\tbtVector3FloatData m_el[3];\n};\n\n///for serialization\nstruct btMatrix3x3DoubleData\n{\n\tbtVector3DoubleData m_el[3];\n};\n\nSIMD_FORCE_INLINE void btMatrix3x3::serialize(struct btMatrix3x3Data& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serialize(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::serializeFloat(struct btMatrix3x3FloatData& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serializeFloat(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerialize(const struct btMatrix3x3Data& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerialize(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeFloat(const struct btMatrix3x3FloatData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeFloat(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeDouble(const struct btMatrix3x3DoubleData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeDouble(dataIn.m_el[i]);\n}\n\n"}, {"id": "3754B61C2A89D00D", "name": "operator-", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 805, "col": 1}, "end": {"line": 816, "col": 1}, "code": "operator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}], "code": "\tbtTransform inverse() const\n\t{\n\t\tbtMatrix3x3 inv = m_basis.transpose();\n\t\treturn btTransform(inv, inv * -m_origin);\n\t}\n"}, "CCEAF9ED3AB777D3": {"calls": [{"id": "AC7D602483438518", "name": "btMatrix3x3::getIdentity", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 350, "col": 2}, "end": {"line": 363, "col": 2}, "code": "\t{\n\t\tstatic const btMatrix3x3\n\t\t\tidentityMatrix(\n\t\t\t\tbtScalar(1.0), btScalar(0.0), btScalar(0.0),\n\t\t\t\tbtScalar(0.0), btScalar(1.0), btScalar(0.0),\n\t\t\t\tbtScalar(0.0), btScalar(0.0), btScalar(1.0));\n\t\treturn identityMatrix;\n\t}\n\n\t/**@brief Fill the rotational part of an OpenGL matrix and clear the shear/perspective\n\t* @param m The array to be filled */\n\tvoid getOpenGLSubMatrix(btScalar * m) const\n\t{\n\t\tm[0] = btScalar(m_el[0].x());\n\t\tm[1] = btScalar(m_el[1].x());\n\t\tm[2] = btScalar(m_el[2].x());\n\t\tm[3] = btScalar(0.0);\n\t\tm[4] = btScalar(m_el[0].y());\n\t\tm[5] = btScalar(m_el[1].y());\n\t\tm[6] = btScalar(m_el[2].y());\n\t\tm[7] = btScalar(0.0);\n\t\tm[8] = btScalar(m_el[0].z());\n\t\tm[9] = btScalar(m_el[1].z());\n\t\tm[10] = btScalar(m_el[2].z());\n\t\tm[11] = btScalar(0.0);\n\t}\n\n\t/**@brief Get the matrix represented as a quaternion \n\t* @param q The quaternion which will be set */\n\tvoid getRotation(btQuaternion & q) const\n\t{\n\t\tbtScalar trace = m_el[0].x() + m_el[1].y() + m_el[2].z();\n\n\t\tbtScalar temp[4];\n\n\t\tif (trace > btScalar(0.0))\n\t\t{\n\t\t\tbtScalar s = btSqrt(trace + btScalar(1.0));\n\t\t\ttemp[3] = (s * btScalar(0.5));\n\t\t\ts = btScalar(0.5) / s;\n\n\t\t\ttemp[0] = ((m_el[2].y() - m_el[1].z()) * s);\n\t\t\ttemp[1] = ((m_el[0].z() - m_el[2].x()) * s);\n\t\t\ttemp[2] = ((m_el[1].x() - m_el[0].y()) * s);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tint i = m_el[0].x() < m_el[1].y() ? (m_el[1].y() < m_el[2].z() ? 2 : 1) : (m_el[0].x() < m_el[2].z() ? 2 : 0);\n\t\t\tint j = (i + 1) % 3;\n\t\t\tint k = (i + 2) % 3;\n\n\t\t\tbtScalar s = btSqrt(m_el[i][i] - m_el[j][j] - m_el[k][k] + btScalar(1.0));\n\t\t\ttemp[i] = s * btScalar(0.5);\n\t\t\ts = btScalar(0.5) / s;\n\n\t\t\ttemp[3] = (m_el[k][j] - m_el[j][k]) * s;\n\t\t\ttemp[j] = (m_el[j][i] + m_el[i][j]) * s;\n\t\t\ttemp[k] = (m_el[k][i] + m_el[i][k]) * s;\n\t\t}\n\t\tq.setValue(temp[0], temp[1], temp[2], temp[3]);\n\t}\n\n\t/**@brief Get the matrix represented as euler angles around YXZ, roundtrip with setEulerYPR\n\t* @param yaw Yaw around Y axis\n\t* @param pitch Pitch around X axis\n\t* @param roll around Z axis */\n\tvoid getEulerYPR(btScalar & yaw, btScalar & pitch, btScalar & roll) const\n\t{\n\t\t// first use the normal calculus\n\t\tyaw = btScalar(btAtan2(m_el[1].x(), m_el[0].x()));\n\t\tpitch = btScalar(btAsin(-m_el[2].x()));\n\t\troll = btScalar(btAtan2(m_el[2].y(), m_el[2].z()));\n\n\t\t// on pitch = +/-HalfPI\n\t\tif (btFabs(pitch) == SIMD_HALF_PI)\n\t\t{\n\t\t\tif (yaw > 0)\n\t\t\t\tyaw -= SIMD_PI;\n\t\t\telse\n\t\t\t\tyaw += SIMD_PI;\n\n\t\t\tif (roll > 0)\n\t\t\t\troll -= SIMD_PI;\n\t\t\telse\n\t\t\t\troll += SIMD_PI;\n\t\t}\n\t};\n\n\t/**@brief Get the matrix represented as euler angles around ZYX\n\t* @param yaw Yaw around Z axis\n\t* @param pitch Pitch around Y axis\n\t* @param roll around X axis \n\t* @param solution_number Which solution of two possible solutions ( 1 or 2) are possible values*/\n\tvoid getEulerZYX(btScalar & yaw, btScalar & pitch, btScalar & roll, unsigned int solution_number = 1) const\n\t{\n\t\tstruct Euler\n\t\t{\n\t\t\tbtScalar yaw;\n\t\t\tbtScalar pitch;\n\t\t\tbtScalar roll;\n\t\t};\n\n\t\tEuler euler_out;\n\t\tEuler euler_out2;  //second solution\n\t\t//get the pointer to the raw data\n\n\t\t// Check that pitch is not at a singularity\n\t\tif (btFabs(m_el[2].x()) >= 1)\n\t\t{\n\t\t\teuler_out.yaw = 0;\n\t\t\teuler_out2.yaw = 0;\n\n\t\t\t// From difference of angles formula\n\t\t\tbtScalar delta = btAtan2(m_el[0].x(), m_el[0].z());\n\t\t\tif (m_el[2].x() > 0)  //gimbal locked up\n\t\t\t{\n\t\t\t\teuler_out.pitch = SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out2.pitch = SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out.roll = euler_out.pitch + delta;\n\t\t\t\teuler_out2.roll = euler_out.pitch + delta;\n\t\t\t}\n\t\t\telse  // gimbal locked down\n\t\t\t{\n\t\t\t\teuler_out.pitch = -SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out2.pitch = -SIMD_PI / btScalar(2.0);\n\t\t\t\teuler_out.roll = -euler_out.pitch + delta;\n\t\t\t\teuler_out2.roll = -euler_out.pitch + delta;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\teuler_out.pitch = -btAsin(m_el[2].x());\n\t\t\teuler_out2.pitch = SIMD_PI - euler_out.pitch;\n\n\t\t\teuler_out.roll = btAtan2(m_el[2].y() / btCos(euler_out.pitch),\n\t\t\t\t\t\t\t\t\t m_el[2].z() / btCos(euler_out.pitch));\n\t\t\teuler_out2.roll = btAtan2(m_el[2].y() / btCos(euler_out2.pitch),\n\t\t\t\t\t\t\t\t\t  m_el[2].z() / btCos(euler_out2.pitch));\n\n\t\t\teuler_out.yaw = btAtan2(m_el[1].x() / btCos(euler_out.pitch),\n\t\t\t\t\t\t\t\t\tm_el[0].x() / btCos(euler_out.pitch));\n\t\t\teuler_out2.yaw = btAtan2(m_el[1].x() / btCos(euler_out2.pitch),\n\t\t\t\t\t\t\t\t\t m_el[0].x() / btCos(euler_out2.pitch));\n\t\t}\n\n\t\tif (solution_number == 1)\n\t\t{\n\t\t\tyaw = euler_out.yaw;\n\t\t\tpitch = euler_out.pitch;\n\t\t\troll = euler_out.roll;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tyaw = euler_out2.yaw;\n\t\t\tpitch = euler_out2.pitch;\n\t\t\troll = euler_out2.roll;\n\t\t}\n\t}\n\n\t/**@brief Create a scaled copy of the matrix \n\t* @param s Scaling vector The elements of the vector will scale each column */\n\n\tbtMatrix3x3 scaled(const btVector3& s) const\n\t{\n\t\treturn btMatrix3x3(\n\t\t\tm_el[0].x() * s.x(), m_el[0].y() * s.y(), m_el[0].z() * s.z(),\n\t\t\tm_el[1].x() * s.x(), m_el[1].y() * s.y(), m_el[1].z() * s.z(),\n\t\t\tm_el[2].x() * s.x(), m_el[2].y() * s.y(), m_el[2].z() * s.z());\n\t}\n\n\t/**@brief Return the determinant of the matrix */\n\tbtScalar determinant() const;\n\t/**@brief Return the adjoint of the matrix */\n\tbtMatrix3x3 adjoint() const;\n\t/**@brief Return the matrix with all values non negative */\n\tbtMatrix3x3 absolute() const;\n\t/**@brief Return the transpose of the matrix */\n\tbtMatrix3x3 transpose() const;\n\t/**@brief Return the inverse of the matrix */\n\tbtMatrix3x3 inverse() const;\n\n\t/// Solve A * x = b, where b is a column vector. This is more efficient\n\t/// than computing the inverse in one-shot cases.\n\t///Solve33 is from Box2d, thanks to Erin Catto,\n\tbtVector3 solve33(const btVector3& b) const\n\t{\n\t\tbtVector3 col1 = getColumn(0);\n\t\tbtVector3 col2 = getColumn(1);\n\t\tbtVector3 col3 = getColumn(2);\n\n\t\tbtScalar det = btDot(col1, btCross(col2, col3));\n\t\tif (btFabs(det) > SIMD_EPSILON)\n\t\t{\n\t\t\tdet = 1.0f / det;\n\t\t}\n\t\tbtVector3 x;\n\t\tx[0] = det * btDot(b, btCross(col2, col3));\n\t\tx[1] = det * btDot(col1, btCross(b, col3));\n\t\tx[2] = det * btDot(col1, btCross(col2, b));\n\t\treturn x;\n\t}\n\n\tbtMatrix3x3 transposeTimes(const btMatrix3x3& m) const;\n\tbtMatrix3x3 timesTranspose(const btMatrix3x3& m) const;\n\n\tSIMD_FORCE_INLINE btScalar tdotx(const btVector3& v) const\n\t{\n\t\treturn m_el[0].x() * v.x() + m_el[1].x() * v.y() + m_el[2].x() * v.z();\n\t}\n\tSIMD_FORCE_INLINE btScalar tdoty(const btVector3& v) const\n\t{\n\t\treturn m_el[0].y() * v.x() + m_el[1].y() * v.y() + m_el[2].y() * v.z();\n\t}\n\tSIMD_FORCE_INLINE btScalar tdotz(const btVector3& v) const\n\t{\n\t\treturn m_el[0].z() * v.x() + m_el[1].z() * v.y() + m_el[2].z() * v.z();\n\t}\n\n\t///extractRotation is from \"A robust method to extract the rotational part of deformations\"\n\t///See http://dl.acm.org/citation.cfm?doid=2994258.2994269\n\t///decomposes a matrix A in a orthogonal matrix R and a\n\t///symmetric matrix S:\n\t///A = R*S.\n\t///note that R can include both rotation and scaling.\n\tSIMD_FORCE_INLINE void extractRotation(btQuaternion & q, btScalar tolerance = 1.0e-9, int maxIter = 100)\n\t{\n\t\tint iter = 0;\n\t\tbtScalar w;\n\t\tconst btMatrix3x3& A = *this;\n\t\tfor (iter = 0; iter < maxIter; iter++)\n\t\t{\n\t\t\tbtMatrix3x3 R(q);\n\t\t\tbtVector3 omega = (R.getColumn(0).cross(A.getColumn(0)) + R.getColumn(1).cross(A.getColumn(1)) + R.getColumn(2).cross(A.getColumn(2))) * (btScalar(1.0) / btFabs(R.getColumn(0).dot(A.getColumn(0)) + R.getColumn(1).dot(A.getColumn(1)) + R.getColumn(2).dot(A.getColumn(2))) +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  tolerance);\n\t\t\tw = omega.norm();\n\t\t\tif (w < tolerance)\n\t\t\t\tbreak;\n\t\t\tq = btQuaternion(btVector3((btScalar(1.0) / w) * omega), w) *\n\t\t\t\tq;\n\t\t\tq.normalize();\n\t\t}\n\t}\n\n\t/**@brief diagonalizes this matrix by the Jacobi method.\n\t* @param rot stores the rotation from the coordinate system in which the matrix is diagonal to the original\n\t* coordinate system, i.e., old_this = rot * new_this * rot^T.\n\t* @param threshold See iteration\n\t* @param iteration The iteration stops when all off-diagonal elements are less than the threshold multiplied\n\t* by the sum of the absolute values of the diagonal, or when maxSteps have been executed.\n\t*\n\t* Note that this matrix is assumed to be symmetric.\n"}], "code": "\tstatic const btTransform& getIdentity()\n\t{\n\t\tstatic const btTransform identityTransform(btMatrix3x3::getIdentity());\n\t\treturn identityTransform;\n\t}\n"}, "E3447F956B0DAA2A": {"calls": [{"id": "638333B760678A25", "name": "operator==", "path": "bullet3/src/LinearMath/btMatrix3x3.h", "start": {"line": 1366, "col": 1}, "end": {"line": 1387, "col": 1}, "code": "{\n\treturn (m1[0][0] == m2[0][0] && m1[1][0] == m2[1][0] && m1[2][0] == m2[2][0] &&\n\t\t\tm1[0][1] == m2[0][1] && m1[1][1] == m2[1][1] && m1[2][1] == m2[2][1] &&\n\t\t\tm1[0][2] == m2[0][2] && m1[1][2] == m2[1][2] && m1[2][2] == m2[2][2]);\n}\n\n///for serialization\nstruct btMatrix3x3FloatData\n{\n\tbtVector3FloatData m_el[3];\n};\n\n///for serialization\nstruct btMatrix3x3DoubleData\n{\n\tbtVector3DoubleData m_el[3];\n};\n\nSIMD_FORCE_INLINE void btMatrix3x3::serialize(struct btMatrix3x3Data& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serialize(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::serializeFloat(struct btMatrix3x3FloatData& dataOut) const\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].serializeFloat(dataOut.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerialize(const struct btMatrix3x3Data& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerialize(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeFloat(const struct btMatrix3x3FloatData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeFloat(dataIn.m_el[i]);\n}\n\nSIMD_FORCE_INLINE void btMatrix3x3::deSerializeDouble(const struct btMatrix3x3DoubleData& dataIn)\n{\n\tfor (int i = 0; i < 3; i++)\n\t\tm_el[i].deSerializeDouble(dataIn.m_el[i]);\n}\n\n"}, {"id": "3931D87A86260D22", "name": "btTransform::getBasis", "path": "bullet3/src/LinearMath/btTransform.h", "start": {"line": 111, "col": 2}, "end": {"line": 111, "col": 74}, "code": "\n\t/**@brief Return the origin vector translation */\n\tSIMD_FORCE_INLINE btVector3& getOrigin() { return m_origin; }\n\t/**@brief Return the origin vector translation */\n\tSIMD_FORCE_INLINE const btVector3& getOrigin() const { return m_origin; }\n\n\t/**@brief Return a quaternion representing the rotation */\n\tbtQuaternion getRotation() const\n\t{\n\t\tbtQuaternion q;\n\t\tm_basis.getRotation(q);\n\t\treturn q;\n\t}\n\n\t/**@brief Set from an array \n   * @param m A pointer to a 16 element array (12 rotation(row major padded on the right by 1), and 3 translation */\n\tvoid setFromOpenGLMatrix(const btScalar* m)\n\t{\n\t\tm_basis.setFromOpenGLSubMatrix(m);\n\t\tm_origin.setValue(m[12], m[13], m[14]);\n\t}\n\n\t/**@brief Fill an array representation\n   * @param m A pointer to a 16 element array (12 rotation(row major padded on the right by 1), and 3 translation */\n\tvoid getOpenGLMatrix(btScalar * m) const\n\t{\n\t\tm_basis.getOpenGLSubMatrix(m);\n\t\tm[12] = m_origin.x();\n\t\tm[13] = m_origin.y();\n\t\tm[14] = m_origin.z();\n\t\tm[15] = btScalar(1.0);\n\t}\n\n\t/**@brief Set the translational element\n   * @param origin The vector to set the translation to */\n\tSIMD_FORCE_INLINE void setOrigin(const btVector3& origin)\n\t{\n\t\tm_origin = origin;\n\t}\n\n\tSIMD_FORCE_INLINE btVector3 invXform(const btVector3& inVec) const;\n\n\t/**@brief Set the rotational element by btMatrix3x3 */\n\tSIMD_FORCE_INLINE void setBasis(const btMatrix3x3& basis)\n\t{\n\t\tm_basis = basis;\n\t}\n\n\t/**@brief Set the rotational element by btQuaternion */\n\tSIMD_FORCE_INLINE void setRotation(const btQuaternion& q)\n\t{\n\t\tm_basis.setRotation(q);\n\t}\n\n\t/**@brief Set this transformation to the identity */\n\tvoid setIdentity()\n\t{\n\t\tm_basis.setIdentity();\n\t\tm_origin.setValue(btScalar(0.0), btScalar(0.0), btScalar(0.0));\n\t}\n\n\t/**@brief Multiply this Transform by another(this = this * another) \n   * @param t The other transform */\n\tbtTransform& operator*=(const btTransform& t)\n\t{\n\t\tm_origin += m_basis * t.m_origin;\n\t\tm_basis *= t.m_basis;\n\t\treturn *this;\n\t}\n\n\t/**@brief Return the inverse of this transform */\n\tbtTransform inverse() const\n\t{\n\t\tbtMatrix3x3 inv = m_basis.transpose();\n\t\treturn btTransform(inv, inv * -m_origin);\n\t}\n\n\t/**@brief Return the inverse of this transform times the other transform\n   * @param t The other transform \n   * return this.inverse() * the other */\n\tbtTransform inverseTimes(const btTransform& t) const;\n\n\t/**@brief Return the product of this transform and the other */\n\tbtTransform operator*(const btTransform& t) const;\n\n\t/**@brief Return an identity transform */\n\tstatic const btTransform& getIdentity()\n\t{\n\t\tstatic const btTransform identityTransform(btMatrix3x3::getIdentity());\n\t\treturn identityTransform;\n\t}\n\n\tvoid serialize(struct btTransformData & dataOut) const;\n\n\tvoid serializeFloat(struct btTransformFloatData & dataOut) const;\n\n\tvoid deSerialize(const struct btTransformData& dataIn);\n\n\tvoid deSerializeDouble(const struct btTransformDoubleData& dataIn);\n\n\tvoid deSerializeFloat(const struct btTransformFloatData& dataIn);\n};\n\nSIMD_FORCE_INLINE btVector3\nbtTransform::invXform(const btVector3& inVec) const\n{\n\tbtVector3 v = inVec - m_origin;\n\treturn (m_basis.transpose() * v);\n}\n\nSIMD_FORCE_INLINE btTransform\nbtTransform::inverseTimes(const btTransform& t) const\n"}, {"id": "E4B85DD8DA7F7ADE", "name": "btVector3::operator==", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 589, "col": 2}, "end": {"line": 599, "col": 2}, "code": "\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}, {"id": "7B10E5552E77FB01", "name": "btTransform::getOrigin", "path": "bullet3/src/LinearMath/btTransform.h", "start": {"line": 116, "col": 2}, "end": {"line": 116, "col": 74}, "code": "\n\t/**@brief Return a quaternion representing the rotation */\n\tbtQuaternion getRotation() const\n\t{\n\t\tbtQuaternion q;\n\t\tm_basis.getRotation(q);\n\t\treturn q;\n\t}\n\n\t/**@brief Set from an array \n   * @param m A pointer to a 16 element array (12 rotation(row major padded on the right by 1), and 3 translation */\n\tvoid setFromOpenGLMatrix(const btScalar* m)\n\t{\n\t\tm_basis.setFromOpenGLSubMatrix(m);\n\t\tm_origin.setValue(m[12], m[13], m[14]);\n\t}\n\n\t/**@brief Fill an array representation\n   * @param m A pointer to a 16 element array (12 rotation(row major padded on the right by 1), and 3 translation */\n\tvoid getOpenGLMatrix(btScalar * m) const\n\t{\n\t\tm_basis.getOpenGLSubMatrix(m);\n\t\tm[12] = m_origin.x();\n\t\tm[13] = m_origin.y();\n\t\tm[14] = m_origin.z();\n\t\tm[15] = btScalar(1.0);\n\t}\n\n\t/**@brief Set the translational element\n   * @param origin The vector to set the translation to */\n\tSIMD_FORCE_INLINE void setOrigin(const btVector3& origin)\n\t{\n\t\tm_origin = origin;\n\t}\n\n\tSIMD_FORCE_INLINE btVector3 invXform(const btVector3& inVec) const;\n\n\t/**@brief Set the rotational element by btMatrix3x3 */\n\tSIMD_FORCE_INLINE void setBasis(const btMatrix3x3& basis)\n\t{\n\t\tm_basis = basis;\n\t}\n\n\t/**@brief Set the rotational element by btQuaternion */\n\tSIMD_FORCE_INLINE void setRotation(const btQuaternion& q)\n\t{\n\t\tm_basis.setRotation(q);\n\t}\n\n\t/**@brief Set this transformation to the identity */\n\tvoid setIdentity()\n\t{\n\t\tm_basis.setIdentity();\n\t\tm_origin.setValue(btScalar(0.0), btScalar(0.0), btScalar(0.0));\n\t}\n\n\t/**@brief Multiply this Transform by another(this = this * another) \n   * @param t The other transform */\n\tbtTransform& operator*=(const btTransform& t)\n\t{\n\t\tm_origin += m_basis * t.m_origin;\n\t\tm_basis *= t.m_basis;\n\t\treturn *this;\n\t}\n\n\t/**@brief Return the inverse of this transform */\n\tbtTransform inverse() const\n\t{\n\t\tbtMatrix3x3 inv = m_basis.transpose();\n\t\treturn btTransform(inv, inv * -m_origin);\n\t}\n\n\t/**@brief Return the inverse of this transform times the other transform\n   * @param t The other transform \n   * return this.inverse() * the other */\n\tbtTransform inverseTimes(const btTransform& t) const;\n\n\t/**@brief Return the product of this transform and the other */\n\tbtTransform operator*(const btTransform& t) const;\n\n\t/**@brief Return an identity transform */\n\tstatic const btTransform& getIdentity()\n\t{\n\t\tstatic const btTransform identityTransform(btMatrix3x3::getIdentity());\n\t\treturn identityTransform;\n\t}\n\n\tvoid serialize(struct btTransformData & dataOut) const;\n\n\tvoid serializeFloat(struct btTransformFloatData & dataOut) const;\n\n\tvoid deSerialize(const struct btTransformData& dataIn);\n\n\tvoid deSerializeDouble(const struct btTransformDoubleData& dataIn);\n\n\tvoid deSerializeFloat(const struct btTransformFloatData& dataIn);\n};\n\nSIMD_FORCE_INLINE btVector3\nbtTransform::invXform(const btVector3& inVec) const\n{\n\tbtVector3 v = inVec - m_origin;\n\treturn (m_basis.transpose() * v);\n}\n\nSIMD_FORCE_INLINE btTransform\nbtTransform::inverseTimes(const btTransform& t) const\n{\n\tbtVector3 v = t.getOrigin() - m_origin;\n\treturn btTransform(m_basis.transposeTimes(t.m_basis),\n\t\t\t\t\t   v * m_basis);\n}\n\nSIMD_FORCE_INLINE btTransform\n\tbtTransform::operator*(const btTransform& t) const\n{\n\treturn btTransform(m_basis * t.m_basis,\n"}], "code": "SIMD_FORCE_INLINE bool operator==(const btTransform& t1, const btTransform& t2)\n{\n\treturn (t1.getBasis() == t2.getBasis() &&\n\t\t\tt1.getOrigin() == t2.getOrigin());\n}\n"}, "638333B760678A25": {"calls": [{"id": "867379A3D97B7EF7", "name": "btVector3::operator const double *", "path": "bullet3/src/LinearMath/btVector3.h", "start": {"line": 587, "col": 2}, "end": {"line": 587, "col": 76}, "code": "\n\tSIMD_FORCE_INLINE bool operator==(const btVector3& other) const\n\t{\n\t\treturn ((m_floats[3] == other.m_floats[3]) &&\n\t\t\t\t(m_floats[2] == other.m_floats[2]) &&\n\t\t\t\t(m_floats[1] == other.m_floats[1]) &&\n\t\t\t\t(m_floats[0] == other.m_floats[0]));\n\t}\n\n\tSIMD_FORCE_INLINE bool operator!=(const btVector3& other) const\n\t{\n\t\treturn !(*this == other);\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMax(const btVector3& other)\n\t{\n\t\tbtSetMax(m_floats[0], other.m_floats[0]);\n\t\tbtSetMax(m_floats[1], other.m_floats[1]);\n\t\tbtSetMax(m_floats[2], other.m_floats[2]);\n\t\tbtSetMax(m_floats[3], other.w());\n\t}\n\n\t/**@brief Set each element to the min of the current values and the values of another btVector3\n   * @param other The other btVector3 to compare with \n   */\n\tSIMD_FORCE_INLINE void setMin(const btVector3& other)\n\t{\n\t\tbtSetMin(m_floats[0], other.m_floats[0]);\n\t\tbtSetMin(m_floats[1], other.m_floats[1]);\n\t\tbtSetMin(m_floats[2], other.m_floats[2]);\n\t\tbtSetMin(m_floats[3], other.w());\n\t}\n\n\tSIMD_FORCE_INLINE void setValue(const btScalar& _x, const btScalar& _y, const btScalar& _z)\n\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = btScalar(0.f);\n\t}\n\n\tvoid getSkewSymmetricMatrix(btVector3 * v0, btVector3 * v1, btVector3 * v2) const\n\t{\n\t\tv0->setValue(0., -z(), y());\n\t\tv1->setValue(z(), 0., -x());\n\t\tv2->setValue(-y(), x(), 0.);\n\t}\n\n\tvoid setZero()\n\t{\n\t\tsetValue(btScalar(0.), btScalar(0.), btScalar(0.));\n\t}\n\n\tSIMD_FORCE_INLINE bool isZero() const\n\t{\n\t\treturn m_floats[0] == btScalar(0) && m_floats[1] == btScalar(0) && m_floats[2] == btScalar(0);\n\t}\n\n\tSIMD_FORCE_INLINE bool fuzzyZero() const\n\t{\n\t\treturn length2() < SIMD_EPSILON * SIMD_EPSILON;\n\t}\n\n\tSIMD_FORCE_INLINE void serialize(struct btVector3Data & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3DoubleData& dataIn);\n\n\tSIMD_FORCE_INLINE void deSerialize(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeFloat(struct btVector3FloatData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeFloat(const struct btVector3FloatData& dataIn);\n\n\tSIMD_FORCE_INLINE void serializeDouble(struct btVector3DoubleData & dataOut) const;\n\n\tSIMD_FORCE_INLINE void deSerializeDouble(const struct btVector3DoubleData& dataIn);\n\n\t/**@brief returns index of maximum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The maximum dot product */\n\tSIMD_FORCE_INLINE long maxDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/**@brief returns index of minimum dot product between this and vectors in array[]\n         * @param array The other vectors \n         * @param array_count The number of other vectors \n         * @param dotOut The minimum dot product */\n\tSIMD_FORCE_INLINE long minDot(const btVector3* array, long array_count, btScalar& dotOut) const;\n\n\t/* create a vector as  btVector3( this->dot( btVector3 v0 ), this->dot( btVector3 v1), this->dot( btVector3 v2 ))  */\n\tSIMD_FORCE_INLINE btVector3 dot3(const btVector3& v0, const btVector3& v1, const btVector3& v2) const\n\t{\n\t\treturn btVector3(dot(v0), dot(v1), dot(v2));\n\t}\n};\n\n/**@brief Return the sum of two vectors (Point symantics)*/\nSIMD_FORCE_INLINE btVector3\noperator+(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] + v2.m_floats[0],\n\t\tv1.m_floats[1] + v2.m_floats[1],\n\t\tv1.m_floats[2] + v2.m_floats[2]);\n}\n\n/**@brief Return the elementwise product of two vectors */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] * v2.m_floats[0],\n\t\tv1.m_floats[1] * v2.m_floats[1],\n\t\tv1.m_floats[2] * v2.m_floats[2]);\n}\n\n/**@brief Return the difference between two vectors */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] - v2.m_floats[0],\n\t\tv1.m_floats[1] - v2.m_floats[1],\n\t\tv1.m_floats[2] - v2.m_floats[2]);\n}\n\n/**@brief Return the negative of the vector */\nSIMD_FORCE_INLINE btVector3\noperator-(const btVector3& v)\n{\n\treturn btVector3(-v.m_floats[0], -v.m_floats[1], -v.m_floats[2]);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btVector3& v, const btScalar& s)\n{\n\treturn btVector3(v.m_floats[0] * s, v.m_floats[1] * s, v.m_floats[2] * s);\n}\n\n/**@brief Return the vector scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator*(const btScalar& s, const btVector3& v)\n{\n\treturn v * s;\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v, const btScalar& s)\n{\n\tbtFullAssert(s != btScalar(0.0));\n\treturn v * (btScalar(1.0) / s);\n}\n\n/**@brief Return the vector inversely scaled by s */\nSIMD_FORCE_INLINE btVector3\noperator/(const btVector3& v1, const btVector3& v2)\n{\n\treturn btVector3(\n\t\tv1.m_floats[0] / v2.m_floats[0],\n\t\tv1.m_floats[1] / v2.m_floats[1],\n\t\tv1.m_floats[2] / v2.m_floats[2]);\n}\n\n/**@brief Return the dot product between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDot(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.dot(v2);\n}\n\n/**@brief Return the distance squared between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance2(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance2(v2);\n}\n\n/**@brief Return the distance between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtDistance(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.distance(v2);\n}\n\n/**@brief Return the angle between two vectors */\nSIMD_FORCE_INLINE btScalar\nbtAngle(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.angle(v2);\n}\n\n/**@brief Return the cross product of two vectors */\nSIMD_FORCE_INLINE btVector3\nbtCross(const btVector3& v1, const btVector3& v2)\n{\n\treturn v1.cross(v2);\n}\n\nSIMD_FORCE_INLINE btScalar\nbtTriple(const btVector3& v1, const btVector3& v2, const btVector3& v3)\n{\n\treturn v1.triple(v2, v3);\n}\n\n/**@brief Return the linear interpolation between two vectors\n * @param v1 One vector \n * @param v2 The other vector \n * @param t The ration of this to v (t = 0 => return v1, t=1 => return v2) */\nSIMD_FORCE_INLINE btVector3\nlerp(const btVector3& v1, const btVector3& v2, const btScalar& t)\n{\n\treturn v1.lerp(v2, t);\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance2(const btVector3& v) const\n{\n\treturn (v - *this).length2();\n}\n\nSIMD_FORCE_INLINE btScalar btVector3::distance(const btVector3& v) const\n{\n\treturn (v - *this).length();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::normalized() const\n{\n\tbtVector3 nrm = *this;\n\n\treturn nrm.normalize();\n}\n\nSIMD_FORCE_INLINE btVector3 btVector3::rotate(const btVector3& wAxis, const btScalar _angle) const\n{\n\t// wAxis must be a unit lenght vector\n\n\tbtVector3 o = wAxis * wAxis.dot(*this);\n\tbtVector3 _x = *this - o;\n\tbtVector3 _y;\n\n\t_y = wAxis.cross(*this);\n\n\treturn (o + _x * btCos(_angle) + _y * btSin(_angle));\n}\n\nSIMD_FORCE_INLINE long btVector3::maxDot(const btVector3* array, long array_count, btScalar& dotOut) const\n{\n"}], "code": "SIMD_FORCE_INLINE bool operator==(const btMatrix3x3& m1, const btMatrix3x3& m2)\n{\n\treturn (m1[0][0] == m2[0][0] && m1[1][0] == m2[1][0] && m1[2][0] == m2[2][0] &&\n\t\t\tm1[0][1] == m2[0][1] && m1[1][1] == m2[1][1] && m1[2][1] == m2[2][1] &&\n\t\t\tm1[0][2] == m2[0][2] && m1[1][2] == m2[1][2] && m1[2][2] == m2[2][2]);\n}\n"}, "D19B260C1600B5B7": {"calls": [{"id": "E22298857A5EB19E", "name": "b3Cos", "path": "bullet3/src/Bullet3Common/b3Scalar.h", "start": {"line": 407, "col": 1}, "end": {"line": 407, "col": 62}, "code": "B3_FORCE_INLINE b3Scalar b3Sin(b3Scalar x) { return sinf(x); }\nB3_FORCE_INLINE b3Scalar b3Tan(b3Scalar x) { return tanf(x); }\nB3_FORCE_INLINE b3Scalar b3Acos(b3Scalar x)\n{\n\tif (x < b3Scalar(-1))\n\t\tx = b3Scalar(-1);\n\tif (x > b3Scalar(1))\n\t\tx = b3Scalar(1);\n\treturn acosf(x);\n}\nB3_FORCE_INLINE b3Scalar b3Asin(b3Scalar x)\n{\n\tif (x < b3Scalar(-1))\n\t\tx = b3Scalar(-1);\n\tif (x > b3Scalar(1))\n\t\tx = b3Scalar(1);\n\treturn asinf(x);\n}\nB3_FORCE_INLINE b3Scalar b3Atan(b3Scalar x) { return atanf(x); }\nB3_FORCE_INLINE b3Scalar b3Atan2(b3Scalar x, b3Scalar y) { return atan2f(x, y); }\nB3_FORCE_INLINE b3Scalar b3Exp(b3Scalar x) { return expf(x); }\nB3_FORCE_INLINE b3Scalar b3Log(b3Scalar x) { return logf(x); }\nB3_FORCE_INLINE b3Scalar b3Pow(b3Scalar x, b3Scalar y) { return powf(x, y); }\nB3_FORCE_INLINE b3Scalar b3Fmod(b3Scalar x, b3Scalar y) { return fmodf(x, y); }\n\n\n#define B3_2_PI b3Scalar(6.283185307179586232)\n#define B3_PI (B3_2_PI * b3Scalar(0.5))\n#define B3_HALF_PI (B3_2_PI * b3Scalar(0.25))\n#define B3_RADS_PER_DEG (B3_2_PI / b3Scalar(360.0))\n#define B3_DEGS_PER_RAD (b3Scalar(360.0) / B3_2_PI)\n#define B3_SQRT12 b3Scalar(0.7071067811865475244008443621048490)\n\n#define b3RecipSqrt(x) ((b3Scalar)(b3Scalar(1.0) / b3Sqrt(b3Scalar(x)))) /* reciprocal square root */\n\n#define B3_EPSILON FLT_EPSILON\n#define B3_INFINITY FLT_MAX\n\nB3_FORCE_INLINE b3Scalar b3Atan2Fast(b3Scalar y, b3Scalar x)\n{\n\tb3Scalar coeff_1 = B3_PI / 4.0f;\n\tb3Scalar coeff_2 = 3.0f * coeff_1;\n\tb3Scalar abs_y = b3Fabs(y);\n\tb3Scalar angle;\n\tif (x >= 0.0f)\n\t{\n\t\tb3Scalar r = (x - abs_y) / (x + abs_y);\n\t\tangle = coeff_1 - coeff_1 * r;\n\t}\n\telse\n\t{\n\t\tb3Scalar r = (x + abs_y) / (abs_y - x);\n\t\tangle = coeff_2 - coeff_1 * r;\n\t}\n\treturn (y < 0.0f) ? -angle : angle;\n}\n\nB3_FORCE_INLINE bool b3FuzzyZero(b3Scalar x) { return b3Fabs(x) < B3_EPSILON; }\n\nB3_FORCE_INLINE bool b3Equal(b3Scalar a, b3Scalar eps)\n{\n\treturn (((a) <= eps) && !((a) < -eps));\n}\nB3_FORCE_INLINE bool b3GreaterEqual(b3Scalar a, b3Scalar eps)\n{\n\treturn (!((a) <= eps));\n}\n\nB3_FORCE_INLINE int b3IsNegative(b3Scalar x)\n{\n\treturn x < b3Scalar(0.0) ? 1 : 0;\n}\n\nB3_FORCE_INLINE b3Scalar b3Radians(b3Scalar x) { return x * B3_RADS_PER_DEG; }\nB3_FORCE_INLINE b3Scalar b3Degrees(b3Scalar x) { return x * B3_DEGS_PER_RAD; }\n\n#define B3_DECLARE_HANDLE(name) \\\n\ttypedef struct name##__     \\\n\t{                           \\\n\t\tint unused;             \\\n\t} * name\n\n"}, {"id": "7650A1EE42AAC987", "name": "b3Sin", "path": "bullet3/src/Bullet3Common/b3Scalar.h", "start": {"line": 408, "col": 1}, "end": {"line": 408, "col": 62}, "code": "B3_FORCE_INLINE b3Scalar b3Tan(b3Scalar x) { return tanf(x); }\nB3_FORCE_INLINE b3Scalar b3Acos(b3Scalar x)\n{\n\tif (x < b3Scalar(-1))\n\t\tx = b3Scalar(-1);\n\tif (x > b3Scalar(1))\n\t\tx = b3Scalar(1);\n\treturn acosf(x);\n}\nB3_FORCE_INLINE b3Scalar b3Asin(b3Scalar x)\n{\n\tif (x < b3Scalar(-1))\n\t\tx = b3Scalar(-1);\n\tif (x > b3Scalar(1))\n\t\tx = b3Scalar(1);\n\treturn asinf(x);\n}\nB3_FORCE_INLINE b3Scalar b3Atan(b3Scalar x) { return atanf(x); }\nB3_FORCE_INLINE b3Scalar b3Atan2(b3Scalar x, b3Scalar y) { return atan2f(x, y); }\nB3_FORCE_INLINE b3Scalar b3Exp(b3Scalar x) { return expf(x); }\nB3_FORCE_INLINE b3Scalar b3Log(b3Scalar x) { return logf(x); }\nB3_FORCE_INLINE b3Scalar b3Pow(b3Scalar x, b3Scalar y) { return powf(x, y); }\nB3_FORCE_INLINE b3Scalar b3Fmod(b3Scalar x, b3Scalar y) { return fmodf(x, y); }\n\n\n#define B3_2_PI b3Scalar(6.283185307179586232)\n#define B3_PI (B3_2_PI * b3Scalar(0.5))\n#define B3_HALF_PI (B3_2_PI * b3Scalar(0.25))\n#define B3_RADS_PER_DEG (B3_2_PI / b3Scalar(360.0))\n#define B3_DEGS_PER_RAD (b3Scalar(360.0) / B3_2_PI)\n#define B3_SQRT12 b3Scalar(0.7071067811865475244008443621048490)\n\n#define b3RecipSqrt(x) ((b3Scalar)(b3Scalar(1.0) / b3Sqrt(b3Scalar(x)))) /* reciprocal square root */\n\n#define B3_EPSILON FLT_EPSILON\n#define B3_INFINITY FLT_MAX\n\nB3_FORCE_INLINE b3Scalar b3Atan2Fast(b3Scalar y, b3Scalar x)\n{\n\tb3Scalar coeff_1 = B3_PI / 4.0f;\n\tb3Scalar coeff_2 = 3.0f * coeff_1;\n\tb3Scalar abs_y = b3Fabs(y);\n\tb3Scalar angle;\n\tif (x >= 0.0f)\n\t{\n\t\tb3Scalar r = (x - abs_y) / (x + abs_y);\n\t\tangle = coeff_1 - coeff_1 * r;\n\t}\n\telse\n\t{\n\t\tb3Scalar r = (x + abs_y) / (abs_y - x);\n\t\tangle = coeff_2 - coeff_1 * r;\n\t}\n\treturn (y < 0.0f) ? -angle : angle;\n}\n\nB3_FORCE_INLINE bool b3FuzzyZero(b3Scalar x) { return b3Fabs(x) < B3_EPSILON; }\n\nB3_FORCE_INLINE bool b3Equal(b3Scalar a, b3Scalar eps)\n{\n\treturn (((a) <= eps) && !((a) < -eps));\n}\nB3_FORCE_INLINE bool b3GreaterEqual(b3Scalar a, b3Scalar eps)\n{\n\treturn (!((a) <= eps));\n}\n\nB3_FORCE_INLINE int b3IsNegative(b3Scalar x)\n{\n\treturn x < b3Scalar(0.0) ? 1 : 0;\n}\n\nB3_FORCE_INLINE b3Scalar b3Radians(b3Scalar x) { return x * B3_RADS_PER_DEG; }\nB3_FORCE_INLINE b3Scalar b3Degrees(b3Scalar x) { return x * B3_DEGS_PER_RAD; }\n\n#define B3_DECLARE_HANDLE(name) \\\n\ttypedef struct name##__     \\\n\t{                           \\\n\t\tint unused;             \\\n\t} * name\n\n"}, {"id": "C334444305D77C87", "name": "b3QuadWord::setValue", "path": "bullet3/src/Bullet3Common/b3QuadWord.h", "start": {"line": 174, "col": 2}, "end": {"line": 180, "col": 2}, "code": "\t{\n\t\tm_floats[0] = _x;\n\t\tm_floats[1] = _y;\n\t\tm_floats[2] = _z;\n\t\tm_floats[3] = _w;\n\t}\n\t/**@brief No initialization constructor */\n\tB3_FORCE_INLINE b3QuadWord()\n\t//\t:m_floats[0](b3Scalar(0.)),m_floats[1](b3Scalar(0.)),m_floats[2](b3Scalar(0.)),m_floats[3](b3Scalar(0.))\n\t{\n\t}\n\n\t/**@brief Three argument constructor (zeros w)\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   */\n\tB3_FORCE_INLINE b3QuadWord(const b3Scalar& _x, const b3Scalar& _y, const b3Scalar& _z)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = 0.0f;\n\t}\n\n\t/**@brief Initializing constructor\n   * @param x Value of x\n   * @param y Value of y\n   * @param z Value of z\n   * @param w Value of w\n   */\n\tB3_FORCE_INLINE b3QuadWord(const b3Scalar& _x, const b3Scalar& _y, const b3Scalar& _z, const b3Scalar& _w)\n\t{\n\t\tm_floats[0] = _x, m_floats[1] = _y, m_floats[2] = _z, m_floats[3] = _w;\n\t}\n\n\t/**@brief Set each element to the max of the current values and the values of another b3QuadWord\n   * @param other The other b3QuadWord to compare with \n   */\n\tB3_FORCE_INLINE void setMax(const b3QuadWord& other)\n\t{\n\t\tb3SetMax(m_floats[0], other.m_floats[0]);\n\t\tb3SetMax(m_floats[1], other.m_floats[1]);\n\t\tb3SetMax(m_floats[2], other.m_floats[2]);\n\t\tb3SetMax(m_floats[3], other.m_floats[3]);\n\t}\n\t/**@brief Set each element to the min of the current values and the values of another b3QuadWord\n   * @param other The other b3QuadWord to compare with \n   */\n\tB3_FORCE_INLINE void setMin(const b3QuadWord& other)\n\t{\n\t\tb3SetMin(m_floats[0], other.m_floats[0]);\n\t\tb3SetMin(m_floats[1], other.m_floats[1]);\n\t\tb3SetMin(m_floats[2], other.m_floats[2]);\n\t\tb3SetMin(m_floats[3], other.m_floats[3]);\n\t}\n};\n\n"}, {"id": "06EE1E943F560D16", "name": "b3Quaternion::normalize", "path": "bullet3/src/Bullet3Common/b3Quaternion.h", "start": {"line": 356, "col": 2}, "end": {"line": 377, "col": 2}, "code": "\t{\n\t\treturn *this /= length();\n\t}\n\n\t/**@brief Return a scaled version of this quaternion\n   * @param s The scale factor */\n\tB3_FORCE_INLINE b3Quaternion\n\toperator*(const b3Scalar& s) const\n\t{\n\t\treturn b3Quaternion(getX() * s, getY() * s, getZ() * s, m_floats[3] * s);\n\t}\n\n\t/**@brief Return an inversely scaled versionof this quaternion\n   * @param s The inverse scale factor */\n\tb3Quaternion operator/(const b3Scalar& s) const\n\t{\n\t\tb3Assert(s != b3Scalar(0.0));\n\t\treturn *this * (b3Scalar(1.0) / s);\n\t}\n\n\t/**@brief Inversely scale this quaternion\n   * @param s The scale factor */\n\tb3Quaternion& operator/=(const b3Scalar& s)\n\t{\n\t\tb3Assert(s != b3Scalar(0.0));\n\t\treturn *this *= b3Scalar(1.0) / s;\n\t}\n\n\t/**@brief Return a normalized version of this quaternion */\n\tb3Quaternion normalized() const\n\t{\n\t\treturn *this / length();\n\t}\n\t/**@brief Return the angle between this quaternion and the other \n   * @param q The other quaternion */\n\tb3Scalar angle(const b3Quaternion& q) const\n\t{\n\t\tb3Scalar s = b3Sqrt(length2() * q.length2());\n\t\tb3Assert(s != b3Scalar(0.0));\n\t\treturn b3Acos(dot(q) / s);\n\t}\n\t/**@brief Return the angle of rotation represented by this quaternion */\n\tb3Scalar getAngle() const\n\t{\n\t\tb3Scalar s = b3Scalar(2.) * b3Acos(m_floats[3]);\n\t\treturn s;\n\t}\n\n\t/**@brief Return the axis of the rotation represented by this quaternion */\n\tb3Vector3 getAxis() const\n\t{\n\t\tb3Scalar s_squared = 1.f - m_floats[3] * m_floats[3];\n\n\t\tif (s_squared < b3Scalar(10.) * B3_EPSILON)  //Check for divide by zero\n\t\t\treturn b3MakeVector3(1.0, 0.0, 0.0);     // Arbitrary\n\t\tb3Scalar s = 1.f / b3Sqrt(s_squared);\n\t\treturn b3MakeVector3(m_floats[0] * s, m_floats[1] * s, m_floats[2] * s);\n\t}\n\n\t/**@brief Return the inverse of this quaternion */\n\tb3Quaternion inverse() const\n\t{\n\t\treturn b3Quaternion(-m_floats[0], -m_floats[1], -m_floats[2], m_floats[3]);\n\t}\n\n\t/**@brief Return the sum of this quaternion and the other \n   * @param q2 The other quaternion */\n\tB3_FORCE_INLINE b3Quaternion\n\toperator+(const b3Quaternion& q2) const\n\t{\n\t\tconst b3Quaternion& q1 = *this;\n\t\treturn b3Quaternion(q1.getX() + q2.getX(), q1.getY() + q2.getY(), q1.getZ() + q2.getZ(), q1.m_floats[3] + q2.m_floats[3]);\n\t}\n\n\t/**@brief Return the difference between this quaternion and the other \n   * @param q2 The other quaternion */\n\tB3_FORCE_INLINE b3Quaternion\n\toperator-(const b3Quaternion& q2) const\n\t{\n\t\tconst b3Quaternion& q1 = *this;\n\t\treturn b3Quaternion(q1.getX() - q2.getX(), q1.getY() - q2.getY(), q1.getZ() - q2.getZ(), q1.m_floats[3] - q2.m_floats[3]);\n\t}\n\n\t/**@brief Return the negative of this quaternion \n   * This simply negates each element */\n\tB3_FORCE_INLINE b3Quaternion operator-() const\n\t{\n\t\tconst b3Quaternion& q2 = *this;\n\t\treturn b3Quaternion(-q2.getX(), -q2.getY(), -q2.getZ(), -q2.m_floats[3]);\n\t}\n\t/**@todo document this and it's use */\n\tB3_FORCE_INLINE b3Quaternion farthest(const b3Quaternion& qd) const\n\t{\n\t\tb3Quaternion diff, sum;\n\t\tdiff = *this - qd;\n\t\tsum = *this + qd;\n\t\tif (diff.dot(diff) > sum.dot(sum))\n\t\t\treturn qd;\n\t\treturn (-qd);\n\t}\n\n\t/**@todo document this and it's use */\n\tB3_FORCE_INLINE b3Quaternion nearest(const b3Quaternion& qd) const\n\t{\n\t\tb3Quaternion diff, sum;\n\t\tdiff = *this - qd;\n\t\tsum = *this + qd;\n\t\tif (diff.dot(diff) < sum.dot(sum))\n\t\t\treturn qd;\n\t\treturn (-qd);\n\t}\n\n\t/**@brief Return the quaternion which is the result of Spherical Linear Interpolation between this and the other quaternion\n   * @param q The other quaternion to interpolate with \n   * @param t The ratio between this and q to interpolate.  If t = 0 the result is this, if t=1 the result is q.\n   * Slerp interpolates assuming constant velocity.  */\n\tb3Quaternion slerp(const b3Quaternion& q, const b3Scalar& t) const\n\t{\n\t\tb3Scalar magnitude = b3Sqrt(length2() * q.length2());\n\t\tb3Assert(magnitude > b3Scalar(0));\n\n\t\tb3Scalar product = dot(q) / magnitude;\n\t\tif (b3Fabs(product) < b3Scalar(1))\n\t\t{\n\t\t\t// Take care of long angle case see http://en.wikipedia.org/wiki/Slerp\n\t\t\tconst b3Scalar sign = (product < 0) ? b3Scalar(-1) : b3Scalar(1);\n\n\t\t\tconst b3Scalar theta = b3Acos(sign * product);\n\t\t\tconst b3Scalar s1 = b3Sin(sign * t * theta);\n\t\t\tconst b3Scalar d = b3Scalar(1.0) / b3Sin(theta);\n\t\t\tconst b3Scalar s0 = b3Sin((b3Scalar(1.0) - t) * theta);\n\n\t\t\treturn b3Quaternion(\n\t\t\t\t(m_floats[0] * s0 + q.getX() * s1) * d,\n\t\t\t\t(m_floats[1] * s0 + q.getY() * s1) * d,\n\t\t\t\t(m_floats[2] * s0 + q.getZ() * s1) * d,\n\t\t\t\t(m_floats[3] * s0 + q.m_floats[3] * s1) * d);\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn *this;\n\t\t}\n\t}\n\n\tstatic const b3Quaternion& getIdentity()\n\t{\n\t\tstatic const b3Quaternion identityQuat(b3Scalar(0.), b3Scalar(0.), b3Scalar(0.), b3Scalar(1.));\n\t\treturn identityQuat;\n\t}\n\n\tB3_FORCE_INLINE const b3Scalar& getW() const { return m_floats[3]; }\n};\n\n/**@brief Return the product of two quaternions */\nB3_FORCE_INLINE b3Quaternion\noperator*(const b3Quaternion& q1, const b3Quaternion& q2)\n{\n\treturn b3Quaternion(\n\t\tq1.getW() * q2.getX() + q1.getX() * q2.getW() + q1.getY() * q2.getZ() - q1.getZ() * q2.getY(),\n\t\tq1.getW() * q2.getY() + q1.getY() * q2.getW() + q1.getZ() * q2.getX() - q1.getX() * q2.getZ(),\n\t\tq1.getW() * q2.getZ() + q1.getZ() * q2.getW() + q1.getX() * q2.getY() - q1.getY() * q2.getX(),\n\t\tq1.getW() * q2.getW() - q1.getX() * q2.getX() - q1.getY() * q2.getY() - q1.getZ() * q2.getZ());\n}\n\nB3_FORCE_INLINE b3Quaternion\noperator*(const b3Quaternion& q, const b3Vector3& w)\n{\n\treturn b3Quaternion(\n\t\tq.getW() * w.getX() + q.getY() * w.getZ() - q.getZ() * w.getY(),\n\t\tq.getW() * w.getY() + q.getZ() * w.getX() - q.getX() * w.getZ(),\n\t\tq.getW() * w.getZ() + q.getX() * w.getY() - q.getY() * w.getX(),\n\t\t-q.getX() * w.getX() - q.getY() * w.getY() - q.getZ() * w.getZ());\n}\n\nB3_FORCE_INLINE b3Quaternion\noperator*(const b3Vector3& w, const b3Quaternion& q)\n"}], "code": "\tvoid setEulerZYX(const b3Scalar& yawZ, const b3Scalar& pitchY, const b3Scalar& rollX)\n\t{\n\t\tb3Scalar halfYaw = b3Scalar(yawZ) * b3Scalar(0.5);\n\t\tb3Scalar halfPitch = b3Scalar(pitchY) * b3Scalar(0.5);\n\t\tb3Scalar halfRoll = b3Scalar(rollX) * b3Scalar(0.5);\n\t\tb3Scalar cosYaw = b3Cos(halfYaw);\n\t\tb3Scalar sinYaw = b3Sin(halfYaw);\n\t\tb3Scalar cosPitch = b3Cos(halfPitch);\n\t\tb3Scalar sinPitch = b3Sin(halfPitch);\n\t\tb3Scalar cosRoll = b3Cos(halfRoll);\n\t\tb3Scalar sinRoll = b3Sin(halfRoll);\n\t\tsetValue(sinRoll * cosPitch * cosYaw - cosRoll * sinPitch * sinYaw,   //x\n\t\t\t\t cosRoll * sinPitch * cosYaw + sinRoll * cosPitch * sinYaw,   //y\n\t\t\t\t cosRoll * cosPitch * sinYaw - sinRoll * sinPitch * cosYaw,   //z\n\t\t\t\t cosRoll * cosPitch * cosYaw + sinRoll * sinPitch * sinYaw);  //formerly yzx\n\t\tnormalize();\n\t}\n"}, "1431A734ED055FA8": {"calls": [{"id": "D14AECEB8F4412C2", "name": "strlen", "path": "/usr/include/string.h", "start": {"line": 407, "col": 1}, "end": {"line": 408, "col": 33}}], "code": "static char *conf_get_string(const CONF *src_conf, const char *groups,\n                             const char *name)\n{\n    char *res = NULL;\n    const char *end = groups + strlen(groups);\n\n    while ((end = prev_item(groups, end)) != NULL) {\n        if ((res = app_conf_try_string(src_conf, opt_item, name)) != NULL)\n            return res;\n    }\n    return res;\n}\n"}, "368707342DE88F61": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}], "code": "size_t construct_key_exchange_tbs(SSL_CONNECTION *s, unsigned char **ptbs,\n                                  const void *param, size_t paramlen)\n{\n    size_t tbslen = 2 * SSL3_RANDOM_SIZE + paramlen;\n    unsigned char *tbs = OPENSSL_malloc(tbslen);\n\n    if (tbs == NULL) {\n        SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_CRYPTO_LIB);\n        return 0;\n    }\n    memcpy(tbs, s->s3.client_random, SSL3_RANDOM_SIZE);\n    memcpy(tbs + SSL3_RANDOM_SIZE, s->s3.server_random, SSL3_RANDOM_SIZE);\n\n    memcpy(tbs + SSL3_RANDOM_SIZE * 2, param, paramlen);\n\n    *ptbs = tbs;\n    return tbslen;\n}\n"}, "48267A0CCC9D9802": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}], "code": "int CRYPTO_ocb128_copy_ctx(OCB128_CONTEXT *dest, OCB128_CONTEXT *src,\n                           void *keyenc, void *keydec)\n{\n    memcpy(dest, src, sizeof(OCB128_CONTEXT));\n    if (keyenc)\n        dest->keyenc = keyenc;\n    if (keydec)\n        dest->keydec = keydec;\n    if (src->l) {\n        if ((dest->l = OPENSSL_malloc(src->max_l_index * 16)) == NULL)\n            return 0;\n        memcpy(dest->l, src->l, (src->l_index + 1) * 16);\n    }\n    return 1;\n}\n"}, "642B21019158955A": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}, {"id": "335FE7788DEBE05D", "name": "memset", "path": "/usr/include/string.h", "start": {"line": 61, "col": 1}, "end": {"line": 61, "col": 62}}], "code": "static int addr_expand(unsigned char *addr,\n                       const ASN1_BIT_STRING *bs,\n                       const int length, const unsigned char fill)\n{\n    if (bs->length < 0 || bs->length > length)\n        return 0;\n    if (bs->length > 0) {\n        memcpy(addr, bs->data, bs->length);\n        if ((bs->flags & 7) != 0) {\n            unsigned char mask = 0xFF >> (8 - (bs->flags & 7));\n\n            if (fill == 0)\n                addr[bs->length - 1] &= ~mask;\n            else\n                addr[bs->length - 1] |= mask;\n        }\n    }\n    memset(addr + bs->length, fill, length - bs->length);\n    return 1;\n}\n"}, "AE5043CE422C1C05": {"calls": [{"id": "6D739C895B768DE9", "name": "memcmp", "path": "/usr/include/string.h", "start": {"line": 64, "col": 1}, "end": {"line": 65, "col": 33}}], "code": "static int IPAddressFamily_cmp(const IPAddressFamily *const *a_,\n                               const IPAddressFamily *const *b_)\n{\n    const ASN1_OCTET_STRING *a = (*a_)->addressFamily;\n    const ASN1_OCTET_STRING *b = (*b_)->addressFamily;\n    int len = ((a->length <= b->length) ? a->length : b->length);\n    int cmp = memcmp(a->data, b->data, len);\n\n    return cmp ? cmp : a->length - b->length;\n}\n"}, "CD1542D0AEAA744A": {"calls": [{"id": "D14AECEB8F4412C2", "name": "strlen", "path": "/usr/include/string.h", "start": {"line": 407, "col": 1}, "end": {"line": 408, "col": 33}}, {"id": "6537D2A2101745F1", "name": "strcmp", "path": "/usr/include/string.h", "start": {"line": 156, "col": 12}, "end": {"line": 156, "col": 12}}], "code": "static int check_suffix(const char *str, const char *suffix)\n{\n    int str_len = strlen(str);\n    int suffix_len = strlen(suffix) + 1;\n    const char *p = NULL;\n\n    if (suffix_len >= str_len)\n        return -1;\n    p = str + str_len - suffix_len;\n    if (*p != ' '\n        || strcmp(p + 1, suffix) != 0)\n        return -1;\n    return p - str;\n}\n"}, "0EE32A0A9C311AAB": {"calls": [{"id": "D14AECEB8F4412C2", "name": "strlen", "path": "/usr/include/string.h", "start": {"line": 407, "col": 1}, "end": {"line": 408, "col": 33}}, {"id": "6537D2A2101745F1", "name": "strcmp", "path": "/usr/include/string.h", "start": {"line": 156, "col": 12}, "end": {"line": 156, "col": 12}}], "code": "static int check_end(const char *str, const char *end)\n{\n    size_t elen, slen;\n    const char *tmp;\n\n    elen = strlen(end);\n    slen = strlen(str);\n    if (elen > slen)\n        return 1;\n    tmp = str + slen - elen;\n    return strcmp(tmp, end);\n}\n"}, "620F31E815219213": {"calls": [{"id": "D9D6CBD6987440D9", "name": "ossl_qtx_set_msg_callback", "path": "openssl/ssl/quic/quic_record_tx.c", "start": {"line": 1067, "col": 1}, "end": {"line": 1072, "col": 1}, "code": "                               SSL *msg_callback_ssl)\n{\n    qtx->msg_callback = msg_callback;\n    qtx->msg_callback_ssl = msg_callback_ssl;\n}\n\nvoid ossl_qtx_set_msg_callback_arg(OSSL_QTX *qtx, void *msg_callback_arg)\n{\n    qtx->msg_callback_arg = msg_callback_arg;\n}\n\nuint64_t ossl_qtx_get_key_epoch(OSSL_QTX *qtx)\n{\n    OSSL_QRL_ENC_LEVEL *el;\n\n    el = ossl_qrl_enc_level_set_get(&qtx->el_set, QUIC_ENC_LEVEL_1RTT, 1);\n    if (el == NULL)\n        return 0;\n\n    return el->key_epoch;\n}\n"}, {"id": "92D618025718736A", "name": "ossl_quic_tx_packetiser_set_msg_callback", "path": "openssl/ssl/quic/quic_txp.c", "start": {"line": 3088, "col": 1}, "end": {"line": 3094, "col": 1}, "code": "                                              ossl_msg_cb msg_callback,\n                                              SSL *msg_callback_ssl)\n{\n    txp->msg_callback = msg_callback;\n    txp->msg_callback_ssl = msg_callback_ssl;\n}\n\nvoid ossl_quic_tx_packetiser_set_msg_callback_arg(OSSL_QUIC_TX_PACKETISER *txp,\n                                                  void *msg_callback_arg)\n{\n    txp->msg_callback_arg = msg_callback_arg;\n}\n\nQUIC_PN ossl_quic_tx_packetiser_get_next_pn(OSSL_QUIC_TX_PACKETISER *txp,\n                                            uint32_t pn_space)\n{\n    if (pn_space >= QUIC_PN_SPACE_NUM)\n        return UINT64_MAX;\n\n    return txp->next_pn[pn_space];\n}\n\nOSSL_TIME ossl_quic_tx_packetiser_get_deadline(OSSL_QUIC_TX_PACKETISER *txp)\n{\n    /*\n     * TXP-specific deadline computations which rely on TXP innards. This is in\n     * turn relied on by the QUIC_CHANNEL code to determine the channel event\n     * handling deadline.\n     */\n    OSSL_TIME deadline = ossl_time_infinite();\n    uint32_t enc_level, pn_space;\n\n    /*\n     * ACK generation is not CC-gated - packets containing only ACKs are allowed\n     * to bypass CC. We want to generate ACK frames even if we are currently\n     * restricted by CC so the peer knows we have received data. The generate\n     * call will take care of selecting the correct packet archetype.\n     */\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level)\n        if (ossl_qtx_is_enc_level_provisioned(txp->args.qtx, enc_level)) {\n            pn_space = ossl_quic_enc_level_to_pn_space(enc_level);\n            deadline = ossl_time_min(deadline,\n                                     ossl_ackm_get_ack_deadline(txp->args.ackm, pn_space));\n        }\n\n    /* When will CC let us send more? */\n    if (txp->args.cc_method->get_tx_allowance(txp->args.cc_data) == 0)\n        deadline = ossl_time_min(deadline,\n                                 txp->args.cc_method->get_wakeup_deadline(txp->args.cc_data));\n\n    return deadline;\n}\n"}, {"id": "D6F68C2FEA933704", "name": "ossl_qrx_set_msg_callback", "path": "openssl/ssl/quic/quic_record_rx.c", "start": {"line": 1347, "col": 1}, "end": {"line": 1352, "col": 1}, "code": "                               SSL *msg_callback_ssl)\n{\n    qrx->msg_callback = msg_callback;\n    qrx->msg_callback_ssl = msg_callback_ssl;\n}\n\nvoid ossl_qrx_set_msg_callback_arg(OSSL_QRX *qrx, void *msg_callback_arg)\n{\n    qrx->msg_callback_arg = msg_callback_arg;\n}\n"}], "code": "void ossl_quic_channel_set_msg_callback(QUIC_CHANNEL *ch,\n                                        ossl_msg_cb msg_callback,\n                                        SSL *msg_callback_ssl)\n{\n    ch->msg_callback = msg_callback;\n    ch->msg_callback_ssl = msg_callback_ssl;\n    ossl_qtx_set_msg_callback(ch->qtx, msg_callback, msg_callback_ssl);\n    ossl_quic_tx_packetiser_set_msg_callback(ch->txp, msg_callback,\n                                             msg_callback_ssl);\n    ossl_qrx_set_msg_callback(ch->qrx, msg_callback, msg_callback_ssl);\n}\n"}, "755C43F5B3FA4575": {"calls": [{"id": "5E62F499F09E2E88", "name": "ossl_quic_port_new", "path": "openssl/ssl/quic/quic_port.c", "start": {"line": 35, "col": 1}, "end": {"line": 52, "col": 1}, "code": "{\n    QUIC_PORT *port;\n\n    if ((port = OPENSSL_zalloc(sizeof(QUIC_PORT))) == NULL)\n        return NULL;\n\n    port->engine        = args->engine;\n    port->channel_ctx   = args->channel_ctx;\n    port->is_multi_conn = args->is_multi_conn;\n\n    if (!port_init(port)) {\n        OPENSSL_free(port);\n        return NULL;\n    }\n\n    return port;\n}\n\nvoid ossl_quic_port_free(QUIC_PORT *port)\n{\n    if (port == NULL)\n        return;\n\n    port_cleanup(port);\n    OPENSSL_free(port);\n}\n\nstatic int port_init(QUIC_PORT *port)\n{\n    size_t rx_short_dcid_len = (port->is_multi_conn ? INIT_DCID_LEN : 0);\n\n    if (port->engine == NULL || port->channel_ctx == NULL)\n        goto err;\n\n    if ((port->err_state = OSSL_ERR_STATE_new()) == NULL)\n        goto err;\n\n    if ((port->demux = ossl_quic_demux_new(/*BIO=*/NULL,\n                                           /*Short CID Len=*/rx_short_dcid_len,\n                                           get_time, port)) == NULL)\n        goto err;\n\n    ossl_quic_demux_set_default_handler(port->demux,\n                                        port_default_packet_handler,\n                                        port);\n\n    if ((port->srtm = ossl_quic_srtm_new(port->engine->libctx,\n                                         port->engine->propq)) == NULL)\n        goto err;\n\n    if ((port->lcidm = ossl_quic_lcidm_new(port->engine->libctx,\n                                           rx_short_dcid_len)) == NULL)\n        goto err;\n"}], "code": "QUIC_PORT *ossl_quic_engine_create_port(QUIC_ENGINE *qeng,\n                                        const QUIC_PORT_ARGS *args)\n{\n    QUIC_PORT_ARGS largs = *args;\n\n    if (ossl_list_port_num(&qeng->port_list) > 0)\n        /* TODO(QUIC MULTIPORT): We currently support only one port. */\n        return NULL;\n\n    if (largs.engine != NULL)\n        return NULL;\n\n    largs.engine = qeng;\n    return ossl_quic_port_new(&largs);\n}\n"}, "13E685EDA19828BF": {"calls": [{"id": "41D90C0C118C1A88", "name": "ssl_has_cert", "path": "openssl/ssl/ssl_local.h", "start": {"line": 2439, "col": 1}, "end": {"line": 2450, "col": 1}, "code": "{\n    if (idx < 0 || idx >= (int)s->ssl_pkey_num)\n        return 0;\n\n    /* If RPK is enabled for this SSL... only require private key */\n    if (ssl_has_cert_type(s, TLSEXT_cert_type_rpk))\n        return s->cert->pkeys[idx].privatekey != NULL;\n\n    return s->cert->pkeys[idx].x509 != NULL\n        && s->cert->pkeys[idx].privatekey != NULL;\n}\n\nstatic ossl_inline void tls1_get_peer_groups(SSL_CONNECTION *s,\n                                             const uint16_t **pgroups,\n                                             size_t *pgroupslen)\n{\n    *pgroups = s->ext.peer_supportedgroups;\n    *pgroupslen = s->ext.peer_supportedgroups_len;\n}\n\n# ifndef OPENSSL_UNIT_TEST\n\n__owur int ossl_ssl_init(SSL *ssl, SSL_CTX *ctx, const SSL_METHOD *method,\n                         int type);\n__owur SSL *ossl_ssl_connection_new_int(SSL_CTX *ctx, const SSL_METHOD *method);\n__owur SSL *ossl_ssl_connection_new(SSL_CTX *ctx);\nvoid ossl_ssl_connection_free(SSL *ssl);\n__owur int ossl_ssl_connection_reset(SSL *ssl);\n\n__owur int ssl_read_internal(SSL *s, void *buf, size_t num, size_t *readbytes);\n__owur int ssl_write_internal(SSL *s, const void *buf, size_t num,\n                              uint64_t flags, size_t *written);\nint ssl_clear_bad_session(SSL_CONNECTION *s);\n__owur CERT *ssl_cert_new(size_t ssl_pkey_num);\n__owur CERT *ssl_cert_dup(CERT *cert);\nvoid ssl_cert_clear_certs(CERT *c);\nvoid ssl_cert_free(CERT *c);\n__owur int ssl_generate_session_id(SSL_CONNECTION *s, SSL_SESSION *ss);\n__owur int ssl_get_new_session(SSL_CONNECTION *s, int session);\n__owur SSL_SESSION *lookup_sess_in_cache(SSL_CONNECTION *s,\n                                         const unsigned char *sess_id,\n                                         size_t sess_id_len);\n__owur int ssl_get_prev_session(SSL_CONNECTION *s, CLIENTHELLO_MSG *hello);\n__owur SSL_SESSION *ssl_session_dup(const SSL_SESSION *src, int ticket);\n__owur int ssl_cipher_id_cmp(const SSL_CIPHER *a, const SSL_CIPHER *b);\nDECLARE_OBJ_BSEARCH_GLOBAL_CMP_FN(SSL_CIPHER, SSL_CIPHER, ssl_cipher_id);\n__owur int ssl_cipher_ptr_id_cmp(const SSL_CIPHER *const *ap,\n                                 const SSL_CIPHER *const *bp);\n__owur STACK_OF(SSL_CIPHER) *ssl_create_cipher_list(SSL_CTX *ctx,\n                                                    STACK_OF(SSL_CIPHER) *tls13_ciphersuites,\n                                                    STACK_OF(SSL_CIPHER) **cipher_list,\n                                                    STACK_OF(SSL_CIPHER) **cipher_list_by_id,\n                                                    const char *rule_str,\n                                                    CERT *c);\n__owur int ssl_cache_cipherlist(SSL_CONNECTION *s, PACKET *cipher_suites,\n                                int sslv2format);\n__owur int ossl_bytes_to_cipher_list(SSL_CONNECTION *s, PACKET *cipher_suites,\n                                     STACK_OF(SSL_CIPHER) **skp,\n                                     STACK_OF(SSL_CIPHER) **scsvs, int sslv2format,\n                                     int fatal);\nvoid ssl_update_cache(SSL_CONNECTION *s, int mode);\n__owur int ssl_cipher_get_evp_cipher(SSL_CTX *ctx, const SSL_CIPHER *sslc,\n                                     const EVP_CIPHER **enc);\n__owur int ssl_cipher_get_evp(SSL_CTX *ctxc, const SSL_SESSION *s,\n                              const EVP_CIPHER **enc, const EVP_MD **md,\n                              int *mac_pkey_type, size_t *mac_secret_size,\n                              SSL_COMP **comp, int use_etm);\n__owur int ssl_cipher_get_overhead(const SSL_CIPHER *c, size_t *mac_overhead,\n                                   size_t *int_overhead, size_t *blocksize,\n                                   size_t *ext_overhead);\n__owur int ssl_cert_is_disabled(SSL_CTX *ctx, size_t idx);\n__owur const SSL_CIPHER *ssl_get_cipher_by_char(SSL_CONNECTION *ssl,\n                                                const unsigned char *ptr,\n                                                int all);\n__owur int ssl_cert_set0_chain(SSL_CONNECTION *s, SSL_CTX *ctx,\n                               STACK_OF(X509) *chain);\n__owur int ssl_cert_set1_chain(SSL_CONNECTION *s, SSL_CTX *ctx,\n                               STACK_OF(X509) *chain);\n__owur int ssl_cert_add0_chain_cert(SSL_CONNECTION *s, SSL_CTX *ctx, X509 *x);\n__owur int ssl_cert_add1_chain_cert(SSL_CONNECTION *s, SSL_CTX *ctx, X509 *x);\n__owur int ssl_cert_select_current(CERT *c, X509 *x);\n__owur int ssl_cert_set_current(CERT *c, long arg);\nvoid ssl_cert_set_cert_cb(CERT *c, int (*cb) (SSL *ssl, void *arg), void *arg);\n\n__owur int ssl_verify_cert_chain(SSL_CONNECTION *s, STACK_OF(X509) *sk);\n__owur int ssl_verify_rpk(SSL_CONNECTION *s, EVP_PKEY *rpk);\n__owur int ssl_build_cert_chain(SSL_CONNECTION *s, SSL_CTX *ctx, int flags);\n__owur int ssl_cert_set_cert_store(CERT *c, X509_STORE *store, int chain,\n                                   int ref);\n__owur int ssl_cert_get_cert_store(CERT *c, X509_STORE **pstore, int chain);\n\n__owur int ssl_security(const SSL_CONNECTION *s, int op, int bits, int nid,\n                        void *other);\n__owur int ssl_ctx_security(const SSL_CTX *ctx, int op, int bits, int nid,\n                            void *other);\nint ssl_get_security_level_bits(const SSL *s, const SSL_CTX *ctx, int *levelp);\n\n__owur int ssl_cert_lookup_by_nid(int nid, size_t *pidx, SSL_CTX *ctx);\n__owur const SSL_CERT_LOOKUP *ssl_cert_lookup_by_pkey(const EVP_PKEY *pk,\n                                                      size_t *pidx,\n                                                      SSL_CTX *ctx);\n__owur const SSL_CERT_LOOKUP *ssl_cert_lookup_by_idx(size_t idx, SSL_CTX *ctx);\n\nint ssl_undefined_function(SSL *s);\n__owur int ssl_undefined_void_function(void);\n__owur int ssl_undefined_const_function(const SSL *s);\n__owur int ssl_get_server_cert_serverinfo(SSL_CONNECTION *s,\n                                          const unsigned char **serverinfo,\n                                          size_t *serverinfo_length);\nvoid ssl_set_masks(SSL_CONNECTION *s);\n__owur STACK_OF(SSL_CIPHER) *ssl_get_ciphers_by_id(SSL_CONNECTION *sc);\n__owur int ssl_x509err2alert(int type);\nvoid ssl_sort_cipher_list(void);\nint ssl_load_ciphers(SSL_CTX *ctx);\n__owur int ssl_setup_sigalgs(SSL_CTX *ctx);\nint ssl_load_groups(SSL_CTX *ctx);\nint ssl_load_sigalgs(SSL_CTX *ctx);\n__owur int ssl_fill_hello_random(SSL_CONNECTION *s, int server,\n                                 unsigned char *field, size_t len,\n                                 DOWNGRADE dgrd);\n__owur int ssl_generate_master_secret(SSL_CONNECTION *s, unsigned char *pms,\n                                      size_t pmslen, int free_pms);\n__owur EVP_PKEY *ssl_generate_pkey(SSL_CONNECTION *s, EVP_PKEY *pm);\n__owur int ssl_gensecret(SSL_CONNECTION *s, unsigned char *pms, size_t pmslen);\n__owur int ssl_derive(SSL_CONNECTION *s, EVP_PKEY *privkey, EVP_PKEY *pubkey,\n                      int genmaster);\n__owur int ssl_decapsulate(SSL_CONNECTION *s, EVP_PKEY *privkey,\n                           const unsigned char *ct, size_t ctlen,\n                           int gensecret);\n__owur int ssl_encapsulate(SSL_CONNECTION *s, EVP_PKEY *pubkey,\n                           unsigned char **ctp, size_t *ctlenp,\n                           int gensecret);\n__owur EVP_PKEY *ssl_dh_to_pkey(DH *dh);\n__owur int ssl_set_tmp_ecdh_groups(uint16_t **pext, size_t *pextlen,\n                                   void *key);\n__owur unsigned int ssl_get_max_send_fragment(const SSL_CONNECTION *sc);\n__owur unsigned int ssl_get_split_send_fragment(const SSL_CONNECTION *sc);\n\n__owur const SSL_CIPHER *ssl3_get_cipher_by_id(uint32_t id);\n__owur const SSL_CIPHER *ssl3_get_cipher_by_std_name(const char *stdname);\n__owur const SSL_CIPHER *ssl3_get_cipher_by_char(const unsigned char *p);\n__owur int ssl3_put_cipher_by_char(const SSL_CIPHER *c, WPACKET *pkt,\n                                   size_t *len);\nint ssl3_init_finished_mac(SSL_CONNECTION *s);\n__owur int ssl3_setup_key_block(SSL_CONNECTION *s);\n__owur int ssl3_change_cipher_state(SSL_CONNECTION *s, int which);\nvoid ssl3_cleanup_key_block(SSL_CONNECTION *s);\n__owur int ssl3_do_write(SSL_CONNECTION *s, uint8_t type);\nint ssl3_send_alert(SSL_CONNECTION *s, int level, int desc);\n__owur int ssl3_generate_master_secret(SSL_CONNECTION *s, unsigned char *out,\n                                       unsigned char *p, size_t len,\n                                       size_t *secret_size);\n__owur int ssl3_get_req_cert_type(SSL_CONNECTION *s, WPACKET *pkt);\n__owur int ssl3_num_ciphers(void);\n__owur const SSL_CIPHER *ssl3_get_cipher(unsigned int u);\nint ssl3_renegotiate(SSL *ssl);\nint ssl3_renegotiate_check(SSL *ssl, int initok);\nvoid ssl3_digest_master_key_set_params(const SSL_SESSION *session,\n                                       OSSL_PARAM params[]);\n__owur int ssl3_dispatch_alert(SSL *s);\n__owur size_t ssl3_final_finish_mac(SSL_CONNECTION *s, const char *sender,\n                                    size_t slen, unsigned char *p);\n__owur int ssl3_finish_mac(SSL_CONNECTION *s, const unsigned char *buf,\n                           size_t len);\nvoid ssl3_free_digest_list(SSL_CONNECTION *s);\n__owur unsigned long ssl3_output_cert_chain(SSL_CONNECTION *s, WPACKET *pkt,\n                                            CERT_PKEY *cpk, int for_comp);\n__owur const SSL_CIPHER *ssl3_choose_cipher(SSL_CONNECTION *s,\n                                            STACK_OF(SSL_CIPHER) *clnt,\n                                            STACK_OF(SSL_CIPHER) *srvr);\n__owur int ssl3_digest_cached_records(SSL_CONNECTION *s, int keep);\n__owur int ssl3_new(SSL *s);\nvoid ssl3_free(SSL *s);\n__owur int ssl3_read(SSL *s, void *buf, size_t len, size_t *readbytes);\n__owur int ssl3_peek(SSL *s, void *buf, size_t len, size_t *readbytes);\n__owur int ssl3_write(SSL *s, const void *buf, size_t len, size_t *written);\n__owur int ssl3_shutdown(SSL *s);\nint ssl3_clear(SSL *s);\n__owur long ssl3_ctrl(SSL *s, int cmd, long larg, void *parg);\n__owur long ssl3_ctx_ctrl(SSL_CTX *s, int cmd, long larg, void *parg);\n__owur long ssl3_callback_ctrl(SSL *s, int cmd, void (*fp) (void));\n__owur long ssl3_ctx_callback_ctrl(SSL_CTX *s, int cmd, void (*fp) (void));\n\n__owur int ssl3_do_change_cipher_spec(SSL_CONNECTION *s);\n__owur OSSL_TIME ssl3_default_timeout(void);\n\n__owur int ssl3_set_handshake_header(SSL_CONNECTION *s, WPACKET *pkt,\n                                     int htype);\n__owur int tls_close_construct_packet(SSL_CONNECTION *s, WPACKET *pkt, int htype);\n__owur int tls_setup_handshake(SSL_CONNECTION *s);\n__owur int dtls1_set_handshake_header(SSL_CONNECTION *s, WPACKET *pkt, int htype);\n__owur int dtls1_close_construct_packet(SSL_CONNECTION *s, WPACKET *pkt, int htype);\n__owur int ssl3_handshake_write(SSL_CONNECTION *s);\n\n__owur int ssl_allow_compression(SSL_CONNECTION *s);\n\n__owur int ssl_version_cmp(const SSL_CONNECTION *s, int versiona, int versionb);\n__owur int ssl_version_supported(const SSL_CONNECTION *s, int version,\n                                 const SSL_METHOD **meth);\n\n__owur int ssl_set_client_hello_version(SSL_CONNECTION *s);\n__owur int ssl_check_version_downgrade(SSL_CONNECTION *s);\n__owur int ssl_set_version_bound(int method_version, int version, int *bound);\n__owur int ssl_choose_server_version(SSL_CONNECTION *s, CLIENTHELLO_MSG *hello,\n                                     DOWNGRADE *dgrd);\n__owur int ssl_choose_client_version(SSL_CONNECTION *s, int version,\n                                     RAW_EXTENSION *extensions);\n__owur int ssl_get_min_max_version(const SSL_CONNECTION *s, int *min_version,\n                                   int *max_version, int *real_max);\n\n__owur OSSL_TIME tls1_default_timeout(void);\n__owur int dtls1_do_write(SSL_CONNECTION *s, uint8_t type);\nvoid dtls1_set_message_header(SSL_CONNECTION *s,\n                              unsigned char mt,\n                              size_t len,\n                              size_t frag_off, size_t frag_len);\n\nint dtls1_write_app_data_bytes(SSL *s, uint8_t type, const void *buf_,\n                               size_t len, size_t *written);\n\n__owur int dtls1_read_failed(SSL_CONNECTION *s, int code);\n__owur int dtls1_buffer_message(SSL_CONNECTION *s, int ccs);\n__owur int dtls1_retransmit_message(SSL_CONNECTION *s, unsigned short seq,\n                                    int *found);\n__owur int dtls1_get_queue_priority(unsigned short seq, int is_ccs);\nint dtls1_retransmit_buffered_messages(SSL_CONNECTION *s);\nvoid dtls1_clear_received_buffer(SSL_CONNECTION *s);\nvoid dtls1_clear_sent_buffer(SSL_CONNECTION *s);\nvoid dtls1_get_message_header(const unsigned char *data,\n                              struct hm_header_st *msg_hdr);\n__owur OSSL_TIME dtls1_default_timeout(void);\n__owur int dtls1_get_timeout(const SSL_CONNECTION *s, OSSL_TIME *timeleft);\n__owur int dtls1_check_timeout_num(SSL_CONNECTION *s);\n__owur int dtls1_handle_timeout(SSL_CONNECTION *s);\nvoid dtls1_start_timer(SSL_CONNECTION *s);\nvoid dtls1_stop_timer(SSL_CONNECTION *s);\n__owur int dtls1_is_timer_expired(SSL_CONNECTION *s);\n__owur int dtls_raw_hello_verify_request(WPACKET *pkt, unsigned char *cookie,\n                                         size_t cookie_len);\n__owur size_t dtls1_min_mtu(SSL_CONNECTION *s);\nvoid dtls1_hm_fragment_free(hm_fragment *frag);\n__owur int dtls1_query_mtu(SSL_CONNECTION *s);\n\n__owur int tls1_new(SSL *s);\nvoid tls1_free(SSL *s);\nint tls1_clear(SSL *s);\n\n__owur int dtls1_new(SSL *s);\nvoid dtls1_free(SSL *s);\nint dtls1_clear(SSL *s);\nlong dtls1_ctrl(SSL *s, int cmd, long larg, void *parg);\n__owur int dtls1_shutdown(SSL *s);\n\n__owur int dtls1_dispatch_alert(SSL *s);\n\n__owur int ssl_init_wbio_buffer(SSL_CONNECTION *s);\nint ssl_free_wbio_buffer(SSL_CONNECTION *s);\n\n__owur int tls1_change_cipher_state(SSL_CONNECTION *s, int which);\n__owur int tls1_setup_key_block(SSL_CONNECTION *s);\n__owur size_t tls1_final_finish_mac(SSL_CONNECTION *s, const char *str,\n                                    size_t slen, unsigned char *p);\n__owur int tls1_generate_master_secret(SSL_CONNECTION *s, unsigned char *out,\n                                       unsigned char *p, size_t len,\n                                       size_t *secret_size);\n__owur int tls13_setup_key_block(SSL_CONNECTION *s);\n__owur size_t tls13_final_finish_mac(SSL_CONNECTION *s, const char *str, size_t slen,\n                                     unsigned char *p);\n__owur int tls13_change_cipher_state(SSL_CONNECTION *s, int which);\n__owur int tls13_update_key(SSL_CONNECTION *s, int send);\n__owur int tls13_hkdf_expand(SSL_CONNECTION *s,\n                             const EVP_MD *md,\n                             const unsigned char *secret,\n                             const unsigned char *label, size_t labellen,\n                             const unsigned char *data, size_t datalen,\n                             unsigned char *out, size_t outlen, int fatal);\n__owur int tls13_hkdf_expand_ex(OSSL_LIB_CTX *libctx, const char *propq,\n                                const EVP_MD *md,\n                                const unsigned char *secret,\n                                const unsigned char *label, size_t labellen,\n                                const unsigned char *data, size_t datalen,\n                                unsigned char *out, size_t outlen,\n                                int raise_error);\n__owur int tls13_derive_key(SSL_CONNECTION *s, const EVP_MD *md,\n                            const unsigned char *secret, unsigned char *key,\n                            size_t keylen);\n__owur int tls13_derive_iv(SSL_CONNECTION *s, const EVP_MD *md,\n                           const unsigned char *secret, unsigned char *iv,\n                           size_t ivlen);\n__owur int tls13_derive_finishedkey(SSL_CONNECTION *s, const EVP_MD *md,\n                                    const unsigned char *secret,\n                                    unsigned char *fin, size_t finlen);\nint tls13_generate_secret(SSL_CONNECTION *s, const EVP_MD *md,\n                          const unsigned char *prevsecret,\n                          const unsigned char *insecret,\n                          size_t insecretlen,\n                          unsigned char *outsecret);\n__owur int tls13_generate_handshake_secret(SSL_CONNECTION *s,\n                                           const unsigned char *insecret,\n                                           size_t insecretlen);\n__owur int tls13_generate_master_secret(SSL_CONNECTION *s, unsigned char *out,\n                                        unsigned char *prev, size_t prevlen,\n                                        size_t *secret_size);\n__owur int tls1_export_keying_material(SSL_CONNECTION *s,\n                                       unsigned char *out, size_t olen,\n                                       const char *label, size_t llen,\n                                       const unsigned char *p, size_t plen,\n                                       int use_context);\n__owur int tls13_export_keying_material(SSL_CONNECTION *s,\n                                        unsigned char *out, size_t olen,\n                                        const char *label, size_t llen,\n                                        const unsigned char *context,\n                                        size_t contextlen, int use_context);\n__owur int tls13_export_keying_material_early(SSL_CONNECTION *s,\n                                              unsigned char *out, size_t olen,\n                                              const char *label, size_t llen,\n                                              const unsigned char *context,\n                                              size_t contextlen);\n__owur int tls1_alert_code(int code);\n__owur int tls13_alert_code(int code);\n__owur int ssl3_alert_code(int code);\n\n__owur int ssl_check_srvr_ecc_cert_and_alg(X509 *x, SSL_CONNECTION *s);\n\nSSL_COMP *ssl3_comp_find(STACK_OF(SSL_COMP) *sk, int n);\n\n__owur const TLS_GROUP_INFO *tls1_group_id_lookup(SSL_CTX *ctx, uint16_t curve_id);\n__owur const char *tls1_group_id2name(SSL_CTX *ctx, uint16_t group_id);\n__owur int tls1_group_id2nid(uint16_t group_id, int include_unknown);\n__owur uint16_t tls1_nid2group_id(int nid);\n__owur int tls1_check_group_id(SSL_CONNECTION *s, uint16_t group_id,\n                               int check_own_curves);\n__owur uint16_t tls1_shared_group(SSL_CONNECTION *s, int nmatch);\n__owur int tls1_set_groups(uint16_t **pext, size_t *pextlen,\n                           int *curves, size_t ncurves);\n__owur int tls1_set_groups_list(SSL_CTX *ctx, uint16_t **pext, size_t *pextlen,\n                                const char *str);\n__owur EVP_PKEY *ssl_generate_pkey_group(SSL_CONNECTION *s, uint16_t id);\n__owur int tls_valid_group(SSL_CONNECTION *s, uint16_t group_id, int minversion,\n                           int maxversion, int isec, int *okfortls13);\n__owur EVP_PKEY *ssl_generate_param_group(SSL_CONNECTION *s, uint16_t id);\nvoid tls1_get_formatlist(SSL_CONNECTION *s, const unsigned char **pformats,\n                         size_t *num_formats);\n__owur int tls1_check_ec_tmp_key(SSL_CONNECTION *s, unsigned long id);\n\n__owur int tls_group_allowed(SSL_CONNECTION *s, uint16_t curve, int op);\nvoid tls1_get_supported_groups(SSL_CONNECTION *s, const uint16_t **pgroups,\n                               size_t *pgroupslen);\n\n__owur int tls1_set_server_sigalgs(SSL_CONNECTION *s);\n\n__owur SSL_TICKET_STATUS tls_get_ticket_from_client(SSL_CONNECTION *s,\n                                                    CLIENTHELLO_MSG *hello,\n                                                    SSL_SESSION **ret);\n__owur SSL_TICKET_STATUS tls_decrypt_ticket(SSL_CONNECTION *s,\n                                            const unsigned char *etick,\n                                            size_t eticklen,\n                                            const unsigned char *sess_id,\n                                            size_t sesslen, SSL_SESSION **psess);\n\n__owur int tls_use_ticket(SSL_CONNECTION *s);\n\nvoid ssl_set_sig_mask(uint32_t *pmask_a, SSL_CONNECTION *s, int op);\n\n__owur int tls1_set_sigalgs_list(CERT *c, const char *str, int client);\n__owur int tls1_set_raw_sigalgs(CERT *c, const uint16_t *psigs, size_t salglen,\n                                int client);\n__owur int tls1_set_sigalgs(CERT *c, const int *salg, size_t salglen,\n                            int client);\nint tls1_check_chain(SSL_CONNECTION *s, X509 *x, EVP_PKEY *pk,\n                     STACK_OF(X509) *chain, int idx);\nvoid tls1_set_cert_validity(SSL_CONNECTION *s);\n\n#  ifndef OPENSSL_NO_CT\n__owur int ssl_validate_ct(SSL_CONNECTION *s);\n#  endif\n\n__owur EVP_PKEY *ssl_get_auto_dh(SSL_CONNECTION *s);\n\n__owur int ssl_security_cert(SSL_CONNECTION *s, SSL_CTX *ctx, X509 *x, int vfy,\n                             int is_ee);\n__owur int ssl_security_cert_chain(SSL_CONNECTION *s, STACK_OF(X509) *sk,\n                                   X509 *ex, int vfy);\n\nint tls_choose_sigalg(SSL_CONNECTION *s, int fatalerrs);\n\n__owur long ssl_get_algorithm2(SSL_CONNECTION *s);\n__owur int tls12_copy_sigalgs(SSL_CONNECTION *s, WPACKET *pkt,\n                              const uint16_t *psig, size_t psiglen);\n__owur int tls1_save_u16(PACKET *pkt, uint16_t **pdest, size_t *pdestlen);\n__owur int tls1_save_sigalgs(SSL_CONNECTION *s, PACKET *pkt, int cert);\n__owur int tls1_process_sigalgs(SSL_CONNECTION *s);\n__owur int tls1_set_peer_legacy_sigalg(SSL_CONNECTION *s, const EVP_PKEY *pkey);\n__owur int tls1_lookup_md(SSL_CTX *ctx, const SIGALG_LOOKUP *lu,\n                          const EVP_MD **pmd);\n__owur size_t tls12_get_psigalgs(SSL_CONNECTION *s, int sent,\n                                 const uint16_t **psigs);\n__owur int tls_check_sigalg_curve(const SSL_CONNECTION *s, int curve);\n__owur int tls12_check_peer_sigalg(SSL_CONNECTION *s, uint16_t, EVP_PKEY *pkey);\n__owur int ssl_set_client_disabled(SSL_CONNECTION *s);\n__owur int ssl_cipher_disabled(const SSL_CONNECTION *s, const SSL_CIPHER *c,\n                               int op, int echde);\n\n__owur int ssl_handshake_hash(SSL_CONNECTION *s,\n                              unsigned char *out, size_t outlen,\n                              size_t *hashlen);\n__owur const EVP_MD *ssl_md(SSL_CTX *ctx, int idx);\nint ssl_get_md_idx(int md_nid);\n__owur const EVP_MD *ssl_handshake_md(SSL_CONNECTION *s);\n__owur const EVP_MD *ssl_prf_md(SSL_CONNECTION *s);\n\n/*\n * ssl_log_rsa_client_key_exchange logs |premaster| to the SSL_CTX associated\n * with |ssl|, if logging is enabled. It returns one on success and zero on\n * failure. The entry is identified by the first 8 bytes of\n * |encrypted_premaster|.\n */\n__owur int ssl_log_rsa_client_key_exchange(SSL_CONNECTION *s,\n                                           const uint8_t *encrypted_premaster,\n                                           size_t encrypted_premaster_len,\n                                           const uint8_t *premaster,\n                                           size_t premaster_len);\n\n/*\n * ssl_log_secret logs |secret| to the SSL_CTX associated with |ssl|, if\n * logging is available. It returns one on success and zero on failure. It tags\n * the entry with |label|.\n */\n__owur int ssl_log_secret(SSL_CONNECTION *s, const char *label,\n                          const uint8_t *secret, size_t secret_len);\n\n#define MASTER_SECRET_LABEL \"CLIENT_RANDOM\"\n#define CLIENT_EARLY_LABEL \"CLIENT_EARLY_TRAFFIC_SECRET\"\n#define CLIENT_HANDSHAKE_LABEL \"CLIENT_HANDSHAKE_TRAFFIC_SECRET\"\n#define SERVER_HANDSHAKE_LABEL \"SERVER_HANDSHAKE_TRAFFIC_SECRET\"\n#define CLIENT_APPLICATION_LABEL \"CLIENT_TRAFFIC_SECRET_0\"\n#define CLIENT_APPLICATION_N_LABEL \"CLIENT_TRAFFIC_SECRET_N\"\n#define SERVER_APPLICATION_LABEL \"SERVER_TRAFFIC_SECRET_0\"\n#define SERVER_APPLICATION_N_LABEL \"SERVER_TRAFFIC_SECRET_N\"\n#define EARLY_EXPORTER_SECRET_LABEL \"EARLY_EXPORTER_SECRET\"\n#define EXPORTER_SECRET_LABEL \"EXPORTER_SECRET\"\n\n__owur int srp_generate_server_master_secret(SSL_CONNECTION *s);\n__owur int srp_generate_client_master_secret(SSL_CONNECTION *s);\n__owur int srp_verify_server_param(SSL_CONNECTION *s);\n\n/* statem/statem_srvr.c */\n\n__owur int send_certificate_request(SSL_CONNECTION *s);\n\n/* statem/extensions_cust.c */\n\ncustom_ext_method *custom_ext_find(const custom_ext_methods *exts,\n                                   ENDPOINT role, unsigned int ext_type,\n                                   size_t *idx);\n\nvoid custom_ext_init(custom_ext_methods *meths);\n\nint ossl_tls_add_custom_ext_intern(SSL_CTX *ctx, custom_ext_methods *exts,\n                                   ENDPOINT role, unsigned int ext_type,\n                                   unsigned int context,\n                                   SSL_custom_ext_add_cb_ex add_cb,\n                                   SSL_custom_ext_free_cb_ex free_cb,\n                                   void *add_arg,\n                                   SSL_custom_ext_parse_cb_ex parse_cb,\n                                   void *parse_arg);\n__owur int custom_ext_parse(SSL_CONNECTION *s, unsigned int context,\n                            unsigned int ext_type,\n                            const unsigned char *ext_data, size_t ext_size,\n                            X509 *x, size_t chainidx);\n__owur int custom_ext_add(SSL_CONNECTION *s, int context, WPACKET *pkt, X509 *x,\n                          size_t chainidx, int maxversion);\n\n__owur int custom_exts_copy(custom_ext_methods *dst,\n                            const custom_ext_methods *src);\n__owur int custom_exts_copy_flags(custom_ext_methods *dst,\n                                  const custom_ext_methods *src);\nvoid custom_exts_free(custom_ext_methods *exts);\n\nvoid ssl_comp_free_compression_methods_int(void);\n\n/* ssl_mcnf.c */\nvoid ssl_ctx_system_config(SSL_CTX *ctx);\n\nconst EVP_CIPHER *ssl_evp_cipher_fetch(OSSL_LIB_CTX *libctx,\n                                       int nid,\n                                       const char *properties);\nint ssl_evp_cipher_up_ref(const EVP_CIPHER *cipher);\nvoid ssl_evp_cipher_free(const EVP_CIPHER *cipher);\nconst EVP_MD *ssl_evp_md_fetch(OSSL_LIB_CTX *libctx,\n                               int nid,\n                               const char *properties);\nint ssl_evp_md_up_ref(const EVP_MD *md);\nvoid ssl_evp_md_free(const EVP_MD *md);\n\nvoid tls_engine_finish(ENGINE *e);\nconst EVP_CIPHER *tls_get_cipher_from_engine(int nid);\nconst EVP_MD *tls_get_digest_from_engine(int nid);\nint tls_engine_load_ssl_client_cert(SSL_CONNECTION *s, X509 **px509,\n                                    EVP_PKEY **ppkey);\nint ssl_hmac_old_new(SSL_HMAC *ret);\nvoid ssl_hmac_old_free(SSL_HMAC *ctx);\nint ssl_hmac_old_init(SSL_HMAC *ctx, void *key, size_t len, char *md);\nint ssl_hmac_old_update(SSL_HMAC *ctx, const unsigned char *data, size_t len);\nint ssl_hmac_old_final(SSL_HMAC *ctx, unsigned char *md, size_t *len);\nsize_t ssl_hmac_old_size(const SSL_HMAC *ctx);\n\nint ssl_ctx_srp_ctx_free_intern(SSL_CTX *ctx);\nint ssl_ctx_srp_ctx_init_intern(SSL_CTX *ctx);\nint ssl_srp_ctx_free_intern(SSL_CONNECTION *s);\nint ssl_srp_ctx_init_intern(SSL_CONNECTION *s);\n\nint ssl_srp_calc_a_param_intern(SSL_CONNECTION *s);\nint ssl_srp_server_param_with_username_intern(SSL_CONNECTION *s, int *ad);\n\nvoid ssl_session_calculate_timeout(SSL_SESSION *ss);\n\n# else /* OPENSSL_UNIT_TEST */\n\n#  define ssl_init_wbio_buffer SSL_test_functions()->p_ssl_init_wbio_buffer\n\n# endif\n\n/* Some helper routines to support TSAN operations safely */\nstatic ossl_unused ossl_inline int ssl_tsan_lock(const SSL_CTX *ctx)\n{\n#ifdef TSAN_REQUIRES_LOCKING\n    if (!CRYPTO_THREAD_write_lock(ctx->tsan_lock))\n        return 0;\n#endif\n    return 1;\n}\n\nstatic ossl_unused ossl_inline void ssl_tsan_unlock(const SSL_CTX *ctx)\n{\n#ifdef TSAN_REQUIRES_LOCKING\n    CRYPTO_THREAD_unlock(ctx->tsan_lock);\n#endif\n}\n\nstatic ossl_unused ossl_inline void ssl_tsan_counter(const SSL_CTX *ctx,\n                                                     TSAN_QUALIFIER int *stat)\n{\n    if (ssl_tsan_lock(ctx)) {\n        tsan_counter(stat);\n        ssl_tsan_unlock(ctx);\n    }\n}\n\nint ossl_comp_has_alg(int a);\nsize_t ossl_calculate_comp_expansion(int alg, size_t length);\n\nvoid ossl_ssl_set_custom_record_layer(SSL_CONNECTION *s,\n                                      const OSSL_RECORD_METHOD *meth,\n                                      void *rlarg);\n\nlong ossl_ctrl_internal(SSL *s, int cmd, long larg, void *parg, int no_quic);\n\n/*\n * Options which no longer have any effect, but which can be implemented\n * as no-ops for QUIC.\n */\n#define OSSL_LEGACY_SSL_OPTIONS                 \\\n    (SSL_OP_NETSCAPE_REUSE_CIPHER_CHANGE_BUG  | \\\n     SSL_OP_MICROSOFT_BIG_SSLV3_BUFFER        | \\\n     SSL_OP_SSLEAY_080_CLIENT_DH_BUG          | \\\n     SSL_OP_TLS_D5_BUG                        | \\\n     SSL_OP_TLS_BLOCK_PADDING_BUG             | \\\n     SSL_OP_MSIE_SSLV2_RSA_PADDING            | \\\n     SSL_OP_SSLREF2_REUSE_CERT_TYPE_BUG       | \\\n     SSL_OP_MICROSOFT_SESS_ID_BUG             | \\\n     SSL_OP_NETSCAPE_CHALLENGE_BUG            | \\\n     SSL_OP_PKCS1_CHECK_1                     | \\\n     SSL_OP_PKCS1_CHECK_2                     | \\\n     SSL_OP_SINGLE_DH_USE                     | \\\n     SSL_OP_SINGLE_ECDH_USE                   | \\\n     SSL_OP_EPHEMERAL_RSA                     )\n\n/* This option is undefined in public headers with no-dtls1-method. */\n#ifndef SSL_OP_CISCO_ANYCONNECT\n# define SSL_OP_CISCO_ANYCONNECT 0\n#endif\n/*\n * Options which are no-ops under QUIC or TLSv1.3 and which are therefore\n * allowed but ignored under QUIC.\n */\n#define OSSL_TLS1_2_OPTIONS                     \\\n    (SSL_OP_CRYPTOPRO_TLSEXT_BUG              | \\\n     SSL_OP_DONT_INSERT_EMPTY_FRAGMENTS       | \\\n     SSL_OP_ALLOW_CLIENT_RENEGOTIATION        | \\\n     SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION | \\\n     SSL_OP_NO_COMPRESSION                    | \\\n     SSL_OP_NO_SSLv3                          | \\\n     SSL_OP_NO_TLSv1                          | \\\n     SSL_OP_NO_TLSv1_1                        | \\\n     SSL_OP_NO_TLSv1_2                        | \\\n     SSL_OP_NO_DTLSv1                         | \\\n     SSL_OP_NO_DTLSv1_2                       | \\\n     SSL_OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION | \\\n     SSL_OP_CISCO_ANYCONNECT                  | \\\n     SSL_OP_NO_RENEGOTIATION                  | \\\n     SSL_OP_NO_EXTENDED_MASTER_SECRET         | \\\n     SSL_OP_NO_ENCRYPT_THEN_MAC               | \\\n     SSL_OP_COOKIE_EXCHANGE                   | \\\n     SSL_OP_LEGACY_SERVER_CONNECT             | \\\n     SSL_OP_IGNORE_UNEXPECTED_EOF             )\n\n/* Total mask of connection-level options permitted or ignored under QUIC. */\n#define OSSL_QUIC_PERMITTED_OPTIONS_CONN        \\\n    (OSSL_LEGACY_SSL_OPTIONS                  | \\\n     OSSL_TLS1_2_OPTIONS                      | \\\n     SSL_OP_CIPHER_SERVER_PREFERENCE          | \\\n     SSL_OP_DISABLE_TLSEXT_CA_NAMES           | \\\n     SSL_OP_NO_TX_CERTIFICATE_COMPRESSION     | \\\n     SSL_OP_NO_RX_CERTIFICATE_COMPRESSION     | \\\n     SSL_OP_PRIORITIZE_CHACHA                 | \\\n     SSL_OP_NO_QUERY_MTU                      | \\\n     SSL_OP_NO_TICKET                         | \\\n     SSL_OP_NO_ANTI_REPLAY                    )\n\n/* Total mask of stream-level options permitted or ignored under QUIC. */\n#define OSSL_QUIC_PERMITTED_OPTIONS_STREAM      \\\n    (OSSL_LEGACY_SSL_OPTIONS                  | \\\n     OSSL_TLS1_2_OPTIONS                      | \\\n     SSL_OP_CLEANSE_PLAINTEXT                 )\n\n/* Total mask of options permitted on either connections or streams. */\n#define OSSL_QUIC_PERMITTED_OPTIONS             \\\n    (OSSL_QUIC_PERMITTED_OPTIONS_CONN |         \\\n     OSSL_QUIC_PERMITTED_OPTIONS_STREAM)\n\n#endif\n"}, {"id": "664D78D147446A97", "name": "check_cert_usable", "path": "openssl/ssl/t1_lib.c", "start": {"line": 3549, "col": 1}, "end": {"line": 3599, "col": 1}, "code": "                             X509 *x, EVP_PKEY *pkey)\n{\n    const SIGALG_LOOKUP *lu;\n    int mdnid, pknid, supported;\n    size_t i;\n    const char *mdname = NULL;\n    SSL_CTX *sctx = SSL_CONNECTION_GET_CTX(s);\n\n    /*\n     * If the given EVP_PKEY cannot support signing with this digest,\n     * the answer is simply 'no'.\n     */\n    if (sig->hash != NID_undef)\n        mdname = OBJ_nid2sn(sig->hash);\n    supported = EVP_PKEY_digestsign_supports_digest(pkey, sctx->libctx,\n                                                    mdname,\n                                                    sctx->propq);\n    if (supported <= 0)\n        return 0;\n\n    /*\n     * The TLS 1.3 signature_algorithms_cert extension places restrictions\n     * on the sigalg with which the certificate was signed (by its issuer).\n     */\n    if (s->s3.tmp.peer_cert_sigalgs != NULL) {\n        if (!X509_get_signature_info(x, &mdnid, &pknid, NULL, NULL))\n            return 0;\n        for (i = 0; i < s->s3.tmp.peer_cert_sigalgslen; i++) {\n            lu = tls1_lookup_sigalg(s, s->s3.tmp.peer_cert_sigalgs[i]);\n            if (lu == NULL)\n                continue;\n\n            /*\n             * This does not differentiate between the\n             * rsa_pss_pss_* and rsa_pss_rsae_* schemes since we do not\n             * have a chain here that lets us look at the key OID in the\n             * signing certificate.\n             */\n            if (mdnid == lu->hash && pknid == lu->sig)\n                return 1;\n        }\n        return 0;\n    }\n\n    /*\n     * Without signat_algorithms_cert, any certificate for which we have\n     * a viable public key is permitted.\n     */\n    return 1;\n}\n\n/*\n * Returns true if |s| has a usable certificate configured for use\n * with signature scheme |sig|.\n * \"Usable\" includes a check for presence as well as applying\n * the signature_algorithm_cert restrictions sent by the peer (if any).\n * Returns false if no usable certificate is found.\n */\nstatic int has_usable_cert(SSL_CONNECTION *s, const SIGALG_LOOKUP *sig, int idx)\n{\n    /* TLS 1.2 callers can override sig->sig_idx, but not TLS 1.3 callers. */\n    if (idx == -1)\n        idx = sig->sig_idx;\n    if (!ssl_has_cert(s, idx))\n        return 0;\n\n    return check_cert_usable(s, sig, s->cert->pkeys[idx].x509,\n                             s->cert->pkeys[idx].privatekey);\n}\n\n/*\n * Returns true if the supplied cert |x| and key |pkey| is usable with the\n * specified signature scheme |sig|, or false otherwise.\n */\nstatic int is_cert_usable(SSL_CONNECTION *s, const SIGALG_LOOKUP *sig, X509 *x,\n                          EVP_PKEY *pkey)\n{\n    size_t idx;\n\n    if (ssl_cert_lookup_by_pkey(pkey, &idx, SSL_CONNECTION_GET_CTX(s)) == NULL)\n        return 0;\n\n    /* Check the key is consistent with the sig alg */\n    if ((int)idx != sig->sig_idx)\n        return 0;\n\n    return check_cert_usable(s, sig, x, pkey);\n}\n\n/*\n * Find a signature scheme that works with the supplied certificate |x| and key\n * |pkey|. |x| and |pkey| may be NULL in which case we additionally look at our\n * available certs/keys to find one that works.\n */\nstatic const SIGALG_LOOKUP *find_sig_alg(SSL_CONNECTION *s, X509 *x,\n                                         EVP_PKEY *pkey)\n{\n    const SIGALG_LOOKUP *lu = NULL;\n    size_t i;\n    int curve = -1;\n    EVP_PKEY *tmppkey;\n    SSL_CTX *sctx = SSL_CONNECTION_GET_CTX(s);\n\n    /* Look for a shared sigalgs matching possible certificates */\n    for (i = 0; i < s->shared_sigalgslen; i++) {\n        lu = s->shared_sigalgs[i];\n\n        /* Skip SHA1, SHA224, DSA and RSA if not PSS */\n        if (lu->hash == NID_sha1\n            || lu->hash == NID_sha224\n            || lu->sig == EVP_PKEY_DSA\n            || lu->sig == EVP_PKEY_RSA)\n            continue;\n        /* Check that we have a cert, and signature_algorithms_cert */\n        if (!tls1_lookup_md(sctx, lu, NULL))\n            continue;\n        if ((pkey == NULL && !has_usable_cert(s, lu, -1))\n                || (pkey != NULL && !is_cert_usable(s, lu, x, pkey)))\n            continue;\n\n        tmppkey = (pkey != NULL) ? pkey\n                                 : s->cert->pkeys[lu->sig_idx].privatekey;\n\n        if (lu->sig == EVP_PKEY_EC) {\n            if (curve == -1)\n                curve = ssl_get_EC_curve_nid(tmppkey);\n            if (lu->curve != NID_undef && curve != lu->curve)\n                continue;\n        } else if (lu->sig == EVP_PKEY_RSA_PSS) {\n            /* validate that key is large enough for the signature algorithm */\n            if (!rsa_pss_check_min_key_size(sctx, tmppkey, lu))\n                continue;\n        }\n        break;\n    }\n\n    if (i == s->shared_sigalgslen)\n        return NULL;\n\n    return lu;\n}\n\n/*\n * Choose an appropriate signature algorithm based on available certificates\n * Sets chosen certificate and signature algorithm.\n *\n * For servers if we fail to find a required certificate it is a fatal error,\n * an appropriate error code is set and a TLS alert is sent.\n *\n * For clients fatalerrs is set to 0. If a certificate is not suitable it is not\n * a fatal error: we will either try another certificate or not present one\n * to the server. In this case no error is set.\n */\nint tls_choose_sigalg(SSL_CONNECTION *s, int fatalerrs)\n{\n    const SIGALG_LOOKUP *lu = NULL;\n    int sig_idx = -1;\n\n    s->s3.tmp.cert = NULL;\n    s->s3.tmp.sigalg = NULL;\n\n    if (SSL_CONNECTION_IS_TLS13(s)) {\n        lu = find_sig_alg(s, NULL, NULL);\n        if (lu == NULL) {\n            if (!fatalerrs)\n                return 1;\n            SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE,\n                     SSL_R_NO_SUITABLE_SIGNATURE_ALGORITHM);\n            return 0;\n        }\n    } else {\n        /* If ciphersuite doesn't require a cert nothing to do */\n        if (!(s->s3.tmp.new_cipher->algorithm_auth & SSL_aCERT))\n            return 1;\n        if (!s->server && !ssl_has_cert(s, s->cert->key - s->cert->pkeys))\n                return 1;\n\n        if (SSL_USE_SIGALGS(s)) {\n            size_t i;\n            if (s->s3.tmp.peer_sigalgs != NULL) {\n                int curve = -1;\n                SSL_CTX *sctx = SSL_CONNECTION_GET_CTX(s);\n\n                /* For Suite B need to match signature algorithm to curve */\n                if (tls1_suiteb(s))\n                    curve = ssl_get_EC_curve_nid(s->cert->pkeys[SSL_PKEY_ECC]\n                                                 .privatekey);\n\n                /*\n                 * Find highest preference signature algorithm matching\n                 * cert type\n                 */\n                for (i = 0; i < s->shared_sigalgslen; i++) {\n                    lu = s->shared_sigalgs[i];\n\n                    if (s->server) {\n                        if ((sig_idx = tls12_get_cert_sigalg_idx(s, lu)) == -1)\n                            continue;\n                    } else {\n                        int cc_idx = s->cert->key - s->cert->pkeys;\n\n                        sig_idx = lu->sig_idx;\n                        if (cc_idx != sig_idx)\n                            continue;\n                    }\n                    /* Check that we have a cert, and sig_algs_cert */\n                    if (!has_usable_cert(s, lu, sig_idx))\n                        continue;\n                    if (lu->sig == EVP_PKEY_RSA_PSS) {\n                        /* validate that key is large enough for the signature algorithm */\n                        EVP_PKEY *pkey = s->cert->pkeys[sig_idx].privatekey;\n\n                        if (!rsa_pss_check_min_key_size(sctx, pkey, lu))\n                            continue;\n                    }\n                    if (curve == -1 || lu->curve == curve)\n                        break;\n                }\n#ifndef OPENSSL_NO_GOST\n                /*\n                 * Some Windows-based implementations do not send GOST algorithms indication\n                 * in supported_algorithms extension, so when we have GOST-based ciphersuite,\n                 * we have to assume GOST support.\n                 */\n                if (i == s->shared_sigalgslen\n                    && (s->s3.tmp.new_cipher->algorithm_auth\n                        & (SSL_aGOST01 | SSL_aGOST12)) != 0) {\n                  if ((lu = tls1_get_legacy_sigalg(s, -1)) == NULL) {\n                    if (!fatalerrs)\n                      return 1;\n                    SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE,\n                             SSL_R_NO_SUITABLE_SIGNATURE_ALGORITHM);\n                    return 0;\n                  } else {\n                    i = 0;\n                    sig_idx = lu->sig_idx;\n                  }\n                }\n#endif\n                if (i == s->shared_sigalgslen) {\n                    if (!fatalerrs)\n                        return 1;\n                    SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE,\n                             SSL_R_NO_SUITABLE_SIGNATURE_ALGORITHM);\n                    return 0;\n                }\n            } else {\n                /*\n                 * If we have no sigalg use defaults\n                 */\n                const uint16_t *sent_sigs;\n                size_t sent_sigslen;\n\n                if ((lu = tls1_get_legacy_sigalg(s, -1)) == NULL) {\n                    if (!fatalerrs)\n                        return 1;\n                    SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE,\n                             SSL_R_NO_SUITABLE_SIGNATURE_ALGORITHM);\n                    return 0;\n                }\n\n                /* Check signature matches a type we sent */\n                sent_sigslen = tls12_get_psigalgs(s, 1, &sent_sigs);\n                for (i = 0; i < sent_sigslen; i++, sent_sigs++) {\n                    if (lu->sigalg == *sent_sigs\n                            && has_usable_cert(s, lu, lu->sig_idx))\n                        break;\n                }\n                if (i == sent_sigslen) {\n                    if (!fatalerrs)\n                        return 1;\n                    SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE,\n                             SSL_R_WRONG_SIGNATURE_TYPE);\n                    return 0;\n                }\n            }\n        } else {\n            if ((lu = tls1_get_legacy_sigalg(s, -1)) == NULL) {\n                if (!fatalerrs)\n                    return 1;\n                SSLfatal(s, SSL_AD_INTERNAL_ERROR,\n                         SSL_R_NO_SUITABLE_SIGNATURE_ALGORITHM);\n                return 0;\n            }\n        }\n    }\n    if (sig_idx == -1)\n        sig_idx = lu->sig_idx;\n    s->s3.tmp.cert = &s->cert->pkeys[sig_idx];\n    s->cert->key = s->s3.tmp.cert;\n    s->s3.tmp.sigalg = lu;\n    return 1;\n}\n\nint SSL_CTX_set_tlsext_max_fragment_length(SSL_CTX *ctx, uint8_t mode)\n{\n    if (mode != TLSEXT_max_fragment_length_DISABLED\n            && !IS_MAX_FRAGMENT_LENGTH_EXT_VALID(mode)) {\n        ERR_raise(ERR_LIB_SSL, SSL_R_SSL3_EXT_INVALID_MAX_FRAGMENT_LENGTH);\n        return 0;\n    }\n\n    ctx->ext.max_fragment_len_mode = mode;\n    return 1;\n}\n\nint SSL_set_tlsext_max_fragment_length(SSL *ssl, uint8_t mode)\n{\n    SSL_CONNECTION *sc = SSL_CONNECTION_FROM_SSL(ssl);\n\n    if (sc == NULL\n        || (IS_QUIC(ssl) && mode != TLSEXT_max_fragment_length_DISABLED))\n        return 0;\n\n    if (mode != TLSEXT_max_fragment_length_DISABLED\n            && !IS_MAX_FRAGMENT_LENGTH_EXT_VALID(mode)) {\n        ERR_raise(ERR_LIB_SSL, SSL_R_SSL3_EXT_INVALID_MAX_FRAGMENT_LENGTH);\n        return 0;\n    }\n\n    sc->ext.max_fragment_len_mode = mode;\n    return 1;\n}\n\nuint8_t SSL_SESSION_get_max_fragment_length(const SSL_SESSION *session)\n{\n    return session->ext.max_fragment_len_mode;\n}\n\n/*\n * Helper functions for HMAC access with legacy support included.\n */\nSSL_HMAC *ssl_hmac_new(const SSL_CTX *ctx)\n{\n    SSL_HMAC *ret = OPENSSL_zalloc(sizeof(*ret));\n    EVP_MAC *mac = NULL;\n\n    if (ret == NULL)\n        return NULL;\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->ext.ticket_key_evp_cb == NULL\n            && ctx->ext.ticket_key_cb != NULL) {\n        if (!ssl_hmac_old_new(ret))\n            goto err;\n        return ret;\n    }\n#endif\n    mac = EVP_MAC_fetch(ctx->libctx, \"HMAC\", ctx->propq);\n    if (mac == NULL || (ret->ctx = EVP_MAC_CTX_new(mac)) == NULL)\n        goto err;\n    EVP_MAC_free(mac);\n    return ret;\n err:\n    EVP_MAC_CTX_free(ret->ctx);\n    EVP_MAC_free(mac);\n    OPENSSL_free(ret);\n    return NULL;\n}\n\nvoid ssl_hmac_free(SSL_HMAC *ctx)\n{\n    if (ctx != NULL) {\n        EVP_MAC_CTX_free(ctx->ctx);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n        ssl_hmac_old_free(ctx);\n#endif\n        OPENSSL_free(ctx);\n    }\n}\n\nEVP_MAC_CTX *ssl_hmac_get0_EVP_MAC_CTX(SSL_HMAC *ctx)\n{\n    return ctx->ctx;\n}\n\nint ssl_hmac_init(SSL_HMAC *ctx, void *key, size_t len, char *md)\n{\n    OSSL_PARAM params[2], *p = params;\n\n    if (ctx->ctx != NULL) {\n        *p++ = OSSL_PARAM_construct_utf8_string(OSSL_MAC_PARAM_DIGEST, md, 0);\n        *p = OSSL_PARAM_construct_end();\n        if (EVP_MAC_init(ctx->ctx, key, len, params))\n            return 1;\n    }\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->old_ctx != NULL)\n        return ssl_hmac_old_init(ctx, key, len, md);\n#endif\n    return 0;\n}\n\nint ssl_hmac_update(SSL_HMAC *ctx, const unsigned char *data, size_t len)\n{\n    if (ctx->ctx != NULL)\n        return EVP_MAC_update(ctx->ctx, data, len);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->old_ctx != NULL)\n        return ssl_hmac_old_update(ctx, data, len);\n#endif\n    return 0;\n}\n\nint ssl_hmac_final(SSL_HMAC *ctx, unsigned char *md, size_t *len,\n                   size_t max_size)\n{\n    if (ctx->ctx != NULL)\n        return EVP_MAC_final(ctx->ctx, md, len, max_size);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->old_ctx != NULL)\n        return ssl_hmac_old_final(ctx, md, len);\n#endif\n    return 0;\n}\n\nsize_t ssl_hmac_size(const SSL_HMAC *ctx)\n{\n    if (ctx->ctx != NULL)\n        return EVP_MAC_CTX_get_mac_size(ctx->ctx);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->old_ctx != NULL)\n        return ssl_hmac_old_size(ctx);\n#endif\n    return 0;\n}\n\nint ssl_get_EC_curve_nid(const EVP_PKEY *pkey)\n{\n    char gname[OSSL_MAX_NAME_SIZE];\n\n    if (EVP_PKEY_get_group_name(pkey, gname, sizeof(gname), NULL) > 0)\n        return OBJ_txt2nid(gname);\n\n    return NID_undef;\n}\n\n__owur int tls13_set_encoded_pub_key(EVP_PKEY *pkey,\n                                     const unsigned char *enckey,\n                                     size_t enckeylen)\n{\n    if (EVP_PKEY_is_a(pkey, \"DH\")) {\n        int bits = EVP_PKEY_get_bits(pkey);\n\n        if (bits <= 0 || enckeylen != (size_t)bits / 8)\n            /* the encoded key must be padded to the length of the p */\n            return 0;\n    } else if (EVP_PKEY_is_a(pkey, \"EC\")) {\n        if (enckeylen < 3 /* point format and at least 1 byte for x and y */\n            || enckey[0] != 0x04)\n            return 0;\n    }\n\n    return EVP_PKEY_set1_encoded_public_key(pkey, enckey, enckeylen);\n}\n"}], "code": "static int has_usable_cert(SSL_CONNECTION *s, const SIGALG_LOOKUP *sig, int idx)\n{\n    /* TLS 1.2 callers can override sig->sig_idx, but not TLS 1.3 callers. */\n    if (idx == -1)\n        idx = sig->sig_idx;\n    if (!ssl_has_cert(s, idx))\n        return 0;\n\n    return check_cert_usable(s, sig, s->cert->pkeys[idx].x509,\n                             s->cert->pkeys[idx].privatekey);\n}\n"}, "76AA2B71A9EFE21D": {"calls": [{"id": "243F5367FD198E47", "name": "tls13_generate_secret", "path": "openssl/ssl/tls13_enc.c", "start": {"line": 163, "col": 1}, "end": {"line": 223, "col": 1}, "code": "                          const unsigned char *prevsecret,\n                          const unsigned char *insecret,\n                          size_t insecretlen,\n                          unsigned char *outsecret)\n{\n    size_t mdlen;\n    int mdleni;\n    int ret;\n    EVP_KDF *kdf;\n    EVP_KDF_CTX *kctx;\n    OSSL_PARAM params[7], *p = params;\n    int mode = EVP_PKEY_HKDEF_MODE_EXTRACT_ONLY;\n    const char *mdname = EVP_MD_get0_name(md);\n    /* ASCII: \"derived\", in hex for EBCDIC compatibility */\n    static const char derived_secret_label[] = \"\\x64\\x65\\x72\\x69\\x76\\x65\\x64\";\n    SSL_CTX *sctx = SSL_CONNECTION_GET_CTX(s);\n\n    kdf = EVP_KDF_fetch(sctx->libctx, OSSL_KDF_NAME_TLS1_3_KDF, sctx->propq);\n    kctx = EVP_KDF_CTX_new(kdf);\n    EVP_KDF_free(kdf);\n    if (kctx == NULL) {\n        SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_INTERNAL_ERROR);\n        return 0;\n    }\n\n    mdleni = EVP_MD_get_size(md);\n    /* Ensure cast to size_t is safe */\n    if (!ossl_assert(mdleni >= 0)) {\n        SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_INTERNAL_ERROR);\n        EVP_KDF_CTX_free(kctx);\n        return 0;\n    }\n    mdlen = (size_t)mdleni;\n\n    *p++ = OSSL_PARAM_construct_int(OSSL_KDF_PARAM_MODE, &mode);\n    *p++ = OSSL_PARAM_construct_utf8_string(OSSL_KDF_PARAM_DIGEST,\n                                            (char *)mdname, 0);\n    if (insecret != NULL)\n        *p++ = OSSL_PARAM_construct_octet_string(OSSL_KDF_PARAM_KEY,\n                                                 (unsigned char *)insecret,\n                                                 insecretlen);\n    if (prevsecret != NULL)\n        *p++ = OSSL_PARAM_construct_octet_string(OSSL_KDF_PARAM_SALT,\n                                                 (unsigned char *)prevsecret, mdlen);\n    *p++ = OSSL_PARAM_construct_octet_string(OSSL_KDF_PARAM_PREFIX,\n                                             (unsigned char *)label_prefix,\n                                             sizeof(label_prefix) - 1);\n    *p++ = OSSL_PARAM_construct_octet_string(OSSL_KDF_PARAM_LABEL,\n                                             (unsigned char *)derived_secret_label,\n                                             sizeof(derived_secret_label) - 1);\n    *p++ = OSSL_PARAM_construct_end();\n\n    ret = EVP_KDF_derive(kctx, outsecret, mdlen, params) <= 0;\n\n    if (ret != 0)\n        SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_INTERNAL_ERROR);\n\n    EVP_KDF_CTX_free(kctx);\n    return ret == 0;\n}\n\n/*\n * Given an input secret |insecret| of length |insecretlen| generate the\n * handshake secret. This requires the early secret to already have been\n * generated. Returns 1 on success  0 on failure.\n */\nint tls13_generate_handshake_secret(SSL_CONNECTION *s,\n                                    const unsigned char *insecret,\n                                    size_t insecretlen)\n{\n    /* Calls SSLfatal() if required */\n    return tls13_generate_secret(s, ssl_handshake_md(s), s->early_secret,\n                                 insecret, insecretlen,\n                                 (unsigned char *)&s->handshake_secret);\n}\n\n/*\n * Given the handshake secret |prev| of length |prevlen| generate the master\n * secret and store its length in |*secret_size|. Returns 1 on success  0 on\n * failure.\n */\nint tls13_generate_master_secret(SSL_CONNECTION *s, unsigned char *out,\n                                 unsigned char *prev, size_t prevlen,\n                                 size_t *secret_size)\n{\n    const EVP_MD *md = ssl_handshake_md(s);\n\n    *secret_size = EVP_MD_get_size(md);\n    /* Calls SSLfatal() if required */\n    return tls13_generate_secret(s, md, prev, NULL, 0, out);\n}\n\n/*\n * Generates the mac for the Finished message. Returns the length of the MAC or\n * 0 on error.\n */\nsize_t tls13_final_finish_mac(SSL_CONNECTION *s, const char *str, size_t slen,\n                             unsigned char *out)\n{\n    const EVP_MD *md = ssl_handshake_md(s);\n    const char *mdname = EVP_MD_get0_name(md);\n    unsigned char hash[EVP_MAX_MD_SIZE];\n    unsigned char finsecret[EVP_MAX_MD_SIZE];\n    unsigned char *key = NULL;\n    size_t len = 0, hashlen;\n    OSSL_PARAM params[2], *p = params;\n    SSL_CTX *sctx = SSL_CONNECTION_GET_CTX(s);\n\n    if (md == NULL)\n        return 0;\n\n    /* Safe to cast away const here since we're not \"getting\" any data */\n    if (sctx->propq != NULL)\n        *p++ = OSSL_PARAM_construct_utf8_string(OSSL_ALG_PARAM_PROPERTIES,\n                                                (char *)sctx->propq,\n                                                0);\n    *p = OSSL_PARAM_construct_end();\n\n    if (!ssl_handshake_hash(s, hash, sizeof(hash), &hashlen)) {\n        /* SSLfatal() already called */\n        goto err;\n    }\n\n    if (str == SSL_CONNECTION_GET_SSL(s)->method->ssl3_enc->server_finished_label) {\n        key = s->server_finished_secret;\n    } else if (SSL_IS_FIRST_HANDSHAKE(s)) {\n        key = s->client_finished_secret;\n    } else {\n        if (!tls13_derive_finishedkey(s, md,\n                                      s->client_app_traffic_secret,\n                                      finsecret, hashlen))\n            goto err;\n        key = finsecret;\n    }\n\n    if (!EVP_Q_mac(sctx->libctx, \"HMAC\", sctx->propq, mdname,\n                   params, key, hashlen, hash, hashlen,\n                   /* outsize as per sizeof(peer_finish_md) */\n                   out, EVP_MAX_MD_SIZE * 2, &len)) {\n        SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_INTERNAL_ERROR);\n        goto err;\n    }\n\n err:\n    OPENSSL_cleanse(finsecret, sizeof(finsecret));\n    return len;\n}\n\n/*\n * There isn't really a key block in TLSv1.3, but we still need this function\n * for initialising the cipher and hash. Returns 1 on success or 0 on failure.\n */\nint tls13_setup_key_block(SSL_CONNECTION *s)\n{\n    const EVP_CIPHER *c;\n    const EVP_MD *hash;\n\n    s->session->cipher = s->s3.tmp.new_cipher;\n    if (!ssl_cipher_get_evp(SSL_CONNECTION_GET_CTX(s), s->session, &c, &hash,\n                            NULL, NULL, NULL, 0)) {\n        /* Error is already recorded */\n        SSLfatal_alert(s, SSL_AD_INTERNAL_ERROR);\n        return 0;\n    }\n\n    ssl_evp_cipher_free(s->s3.tmp.new_sym_enc);\n    s->s3.tmp.new_sym_enc = c;\n    ssl_evp_md_free(s->s3.tmp.new_hash);\n    s->s3.tmp.new_hash = hash;\n\n    return 1;\n}\n\nstatic int derive_secret_key_and_iv(SSL_CONNECTION *s, const EVP_MD *md,\n                                    const EVP_CIPHER *ciph,\n                                    const unsigned char *insecret,\n                                    const unsigned char *hash,\n                                    const unsigned char *label,\n                                    size_t labellen, unsigned char *secret,\n                                    unsigned char *key, size_t *keylen,\n                                    unsigned char *iv, size_t *ivlen,\n                                    size_t *taglen)\n{\n    int hashleni = EVP_MD_get_size(md);\n    size_t hashlen;\n    int mode;\n\n    /* Ensure cast to size_t is safe */\n    if (!ossl_assert(hashleni >= 0)) {\n        SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_EVP_LIB);\n        return 0;\n    }\n    hashlen = (size_t)hashleni;\n\n    if (!tls13_hkdf_expand(s, md, insecret, label, labellen, hash, hashlen,\n                           secret, hashlen, 1)) {\n        /* SSLfatal() already called */\n        return 0;\n    }\n\n    *keylen = EVP_CIPHER_get_key_length(ciph);\n\n    mode = EVP_CIPHER_get_mode(ciph);\n    if (mode == EVP_CIPH_CCM_MODE) {\n        uint32_t algenc;\n\n        *ivlen = EVP_CCM_TLS_IV_LEN;\n        if (s->s3.tmp.new_cipher != NULL) {\n            algenc = s->s3.tmp.new_cipher->algorithm_enc;\n        } else if (s->session->cipher != NULL) {\n            /* We've not selected a cipher yet - we must be doing early data */\n            algenc = s->session->cipher->algorithm_enc;\n        } else if (s->psksession != NULL && s->psksession->cipher != NULL) {\n            /* We must be doing early data with out-of-band PSK */\n            algenc = s->psksession->cipher->algorithm_enc;\n        } else {\n            SSLfatal(s, SSL_AD_INTERNAL_ERROR, ERR_R_EVP_LIB);\n            return 0;\n        }\n        if (algenc & (SSL_AES128CCM8 | SSL_AES256CCM8))\n            *taglen = EVP_CCM8_TLS_TAG_LEN;\n         else\n            *taglen = EVP_CCM_TLS_TAG_LEN;\n    } else {\n"}, {"id": "D065F28527A23180", "name": "ssl_handshake_md", "path": "openssl/ssl/ssl_ciph.c", "start": {"line": 630, "col": 1}, "end": {"line": 633, "col": 1}, "code": "{\n    return ssl_md(SSL_CONNECTION_GET_CTX(s), ssl_get_algorithm2(s));\n}\n\nconst EVP_MD *ssl_prf_md(SSL_CONNECTION *s)\n{\n    return ssl_md(SSL_CONNECTION_GET_CTX(s),\n                  ssl_get_algorithm2(s) >> TLS1_PRF_DGST_SHIFT);\n}\n\n#define ITEM_SEP(a) \\\n        (((a) == ':') || ((a) == ' ') || ((a) == ';') || ((a) == ','))\n\nstatic void ll_append_tail(CIPHER_ORDER **head, CIPHER_ORDER *curr,\n                           CIPHER_ORDER **tail)\n{\n    if (curr == *tail)\n        return;\n    if (curr == *head)\n        *head = curr->next;\n    if (curr->prev != NULL)\n        curr->prev->next = curr->next;\n    if (curr->next != NULL)\n        curr->next->prev = curr->prev;\n    (*tail)->next = curr;\n    curr->prev = *tail;\n    curr->next = NULL;\n    *tail = curr;\n}\n\nstatic void ll_append_head(CIPHER_ORDER **head, CIPHER_ORDER *curr,\n                           CIPHER_ORDER **tail)\n{\n    if (curr == *head)\n        return;\n    if (curr == *tail)\n        *tail = curr->prev;\n    if (curr->next != NULL)\n        curr->next->prev = curr->prev;\n    if (curr->prev != NULL)\n        curr->prev->next = curr->next;\n    (*head)->prev = curr;\n    curr->next = *head;\n    curr->prev = NULL;\n    *head = curr;\n}\n\nstatic void ssl_cipher_collect_ciphers(const SSL_METHOD *ssl_method,\n                                       int num_of_ciphers,\n                                       uint32_t disabled_mkey,\n                                       uint32_t disabled_auth,\n                                       uint32_t disabled_enc,\n                                       uint32_t disabled_mac,\n                                       CIPHER_ORDER *co_list,\n                                       CIPHER_ORDER **head_p,\n                                       CIPHER_ORDER **tail_p)\n{\n    int i, co_list_num;\n    const SSL_CIPHER *c;\n\n    /*\n     * We have num_of_ciphers descriptions compiled in, depending on the\n     * method selected (SSLv3, TLSv1 etc).\n     * These will later be sorted in a linked list with at most num\n     * entries.\n     */\n\n    /* Get the initial list of ciphers */\n    co_list_num = 0;            /* actual count of ciphers */\n    for (i = 0; i < num_of_ciphers; i++) {\n        c = ssl_method->get_cipher(i);\n        /* drop those that use any of that is not available */\n        if (c == NULL || !c->valid)\n            continue;\n        if ((c->algorithm_mkey & disabled_mkey) ||\n            (c->algorithm_auth & disabled_auth) ||\n            (c->algorithm_enc & disabled_enc) ||\n            (c->algorithm_mac & disabled_mac))\n            continue;\n        if (((ssl_method->ssl3_enc->enc_flags & SSL_ENC_FLAG_DTLS) == 0) &&\n            c->min_tls == 0)\n            continue;\n        if (((ssl_method->ssl3_enc->enc_flags & SSL_ENC_FLAG_DTLS) != 0) &&\n            c->min_dtls == 0)\n            continue;\n\n        co_list[co_list_num].cipher = c;\n        co_list[co_list_num].next = NULL;\n        co_list[co_list_num].prev = NULL;\n        co_list[co_list_num].active = 0;\n        co_list_num++;\n    }\n\n    /*\n     * Prepare linked list from list entries\n     */\n    if (co_list_num > 0) {\n        co_list[0].prev = NULL;\n\n        if (co_list_num > 1) {\n            co_list[0].next = &co_list[1];\n\n            for (i = 1; i < co_list_num - 1; i++) {\n                co_list[i].prev = &co_list[i - 1];\n                co_list[i].next = &co_list[i + 1];\n            }\n\n            co_list[co_list_num - 1].prev = &co_list[co_list_num - 2];\n        }\n\n        co_list[co_list_num - 1].next = NULL;\n\n        *head_p = &co_list[0];\n        *tail_p = &co_list[co_list_num - 1];\n    }\n}\n\nstatic void ssl_cipher_collect_aliases(const SSL_CIPHER **ca_list,\n                                       int num_of_group_aliases,\n                                       uint32_t disabled_mkey,\n                                       uint32_t disabled_auth,\n                                       uint32_t disabled_enc,\n                                       uint32_t disabled_mac,\n                                       CIPHER_ORDER *head)\n{\n    CIPHER_ORDER *ciph_curr;\n    const SSL_CIPHER **ca_curr;\n    int i;\n    uint32_t mask_mkey = ~disabled_mkey;\n    uint32_t mask_auth = ~disabled_auth;\n    uint32_t mask_enc = ~disabled_enc;\n    uint32_t mask_mac = ~disabled_mac;\n\n    /*\n     * First, add the real ciphers as already collected\n     */\n    ciph_curr = head;\n    ca_curr = ca_list;\n    while (ciph_curr != NULL) {\n        *ca_curr = ciph_curr->cipher;\n        ca_curr++;\n        ciph_curr = ciph_curr->next;\n    }\n\n    /*\n     * Now we add the available ones from the cipher_aliases[] table.\n     * They represent either one or more algorithms, some of which\n     * in any affected category must be supported (set in enabled_mask),\n     * or represent a cipher strength value (will be added in any case because algorithms=0).\n     */\n    for (i = 0; i < num_of_group_aliases; i++) {\n        uint32_t algorithm_mkey = cipher_aliases[i].algorithm_mkey;\n        uint32_t algorithm_auth = cipher_aliases[i].algorithm_auth;\n        uint32_t algorithm_enc = cipher_aliases[i].algorithm_enc;\n        uint32_t algorithm_mac = cipher_aliases[i].algorithm_mac;\n\n        if (algorithm_mkey)\n            if ((algorithm_mkey & mask_mkey) == 0)\n                continue;\n\n        if (algorithm_auth)\n            if ((algorithm_auth & mask_auth) == 0)\n                continue;\n\n        if (algorithm_enc)\n            if ((algorithm_enc & mask_enc) == 0)\n                continue;\n\n        if (algorithm_mac)\n            if ((algorithm_mac & mask_mac) == 0)\n                continue;\n\n        *ca_curr = (SSL_CIPHER *)(cipher_aliases + i);\n        ca_curr++;\n    }\n\n    *ca_curr = NULL;            /* end of list */\n}\n\nstatic void ssl_cipher_apply_rule(uint32_t cipher_id, uint32_t alg_mkey,\n                                  uint32_t alg_auth, uint32_t alg_enc,\n                                  uint32_t alg_mac, int min_tls,\n                                  uint32_t algo_strength, int rule,\n                                  int32_t strength_bits, CIPHER_ORDER **head_p,\n                                  CIPHER_ORDER **tail_p)\n{\n    CIPHER_ORDER *head, *tail, *curr, *next, *last;\n    const SSL_CIPHER *cp;\n    int reverse = 0;\n\n    OSSL_TRACE_BEGIN(TLS_CIPHER) {\n        BIO_printf(trc_out,\n                   \"Applying rule %d with %08x/%08x/%08x/%08x/%08x %08x (%d)\\n\",\n                   rule, (unsigned int)alg_mkey, (unsigned int)alg_auth,\n                   (unsigned int)alg_enc, (unsigned int)alg_mac, min_tls,\n                   (unsigned int)algo_strength, (int)strength_bits);\n    }\n\n    if (rule == CIPHER_DEL || rule == CIPHER_BUMP)\n        reverse = 1;            /* needed to maintain sorting between currently\n                                 * deleted ciphers */\n\n    head = *head_p;\n    tail = *tail_p;\n\n    if (reverse) {\n        next = tail;\n        last = head;\n    } else {\n        next = head;\n        last = tail;\n    }\n\n    curr = NULL;\n    for (;;) {\n        if (curr == last)\n            break;\n\n        curr = next;\n\n        if (curr == NULL)\n            break;\n\n        next = reverse ? curr->prev : curr->next;\n\n        cp = curr->cipher;\n\n        /*\n         * Selection criteria is either the value of strength_bits\n         * or the algorithms used.\n         */\n        if (strength_bits >= 0) {\n            if (strength_bits != cp->strength_bits)\n                continue;\n        } else {\n            if (trc_out != NULL) {\n                BIO_printf(trc_out,\n                           \"\\nName: %s:\"\n                           \"\\nAlgo = %08x/%08x/%08x/%08x/%08x Algo_strength = %08x\\n\",\n                           cp->name,\n                           (unsigned int)cp->algorithm_mkey,\n                           (unsigned int)cp->algorithm_auth,\n                           (unsigned int)cp->algorithm_enc,\n                           (unsigned int)cp->algorithm_mac,\n                           cp->min_tls,\n                           (unsigned int)cp->algo_strength);\n            }\n            if (cipher_id != 0 && (cipher_id != cp->id))\n                continue;\n            if (alg_mkey && !(alg_mkey & cp->algorithm_mkey))\n                continue;\n            if (alg_auth && !(alg_auth & cp->algorithm_auth))\n                continue;\n            if (alg_enc && !(alg_enc & cp->algorithm_enc))\n                continue;\n            if (alg_mac && !(alg_mac & cp->algorithm_mac))\n                continue;\n            if (min_tls && (min_tls != cp->min_tls))\n                continue;\n            if ((algo_strength & SSL_STRONG_MASK)\n                && !(algo_strength & SSL_STRONG_MASK & cp->algo_strength))\n                continue;\n            if ((algo_strength & SSL_DEFAULT_MASK)\n                && !(algo_strength & SSL_DEFAULT_MASK & cp->algo_strength))\n                continue;\n        }\n\n        if (trc_out != NULL)\n            BIO_printf(trc_out, \"Action = %d\\n\", rule);\n\n        /* add the cipher if it has not been added yet. */\n        if (rule == CIPHER_ADD) {\n            /* reverse == 0 */\n            if (!curr->active) {\n                ll_append_tail(&head, curr, &tail);\n                curr->active = 1;\n            }\n        }\n        /* Move the added cipher to this location */\n        else if (rule == CIPHER_ORD) {\n            /* reverse == 0 */\n            if (curr->active) {\n                ll_append_tail(&head, curr, &tail);\n            }\n        } else if (rule == CIPHER_DEL) {\n            /* reverse == 1 */\n            if (curr->active) {\n                /*\n                 * most recently deleted ciphersuites get best positions for\n                 * any future CIPHER_ADD (note that the CIPHER_DEL loop works\n                 * in reverse to maintain the order)\n                 */\n                ll_append_head(&head, curr, &tail);\n                curr->active = 0;\n            }\n        } else if (rule == CIPHER_BUMP) {\n            if (curr->active)\n                ll_append_head(&head, curr, &tail);\n        } else if (rule == CIPHER_KILL) {\n            /* reverse == 0 */\n            if (head == curr)\n                head = curr->next;\n            else\n                curr->prev->next = curr->next;\n            if (tail == curr)\n                tail = curr->prev;\n            curr->active = 0;\n            if (curr->next != NULL)\n                curr->next->prev = curr->prev;\n            if (curr->prev != NULL)\n                curr->prev->next = curr->next;\n            curr->next = NULL;\n            curr->prev = NULL;\n        }\n    }\n\n    *head_p = head;\n    *tail_p = tail;\n\n    OSSL_TRACE_END(TLS_CIPHER);\n}\n\nstatic int ssl_cipher_strength_sort(CIPHER_ORDER **head_p,\n                                    CIPHER_ORDER **tail_p)\n{\n    int32_t max_strength_bits;\n    int i, *number_uses;\n    CIPHER_ORDER *curr;\n\n    /*\n     * This routine sorts the ciphers with descending strength. The sorting\n     * must keep the pre-sorted sequence, so we apply the normal sorting\n     * routine as '+' movement to the end of the list.\n     */\n    max_strength_bits = 0;\n    curr = *head_p;\n    while (curr != NULL) {\n        if (curr->active && (curr->cipher->strength_bits > max_strength_bits))\n            max_strength_bits = curr->cipher->strength_bits;\n        curr = curr->next;\n    }\n\n    number_uses = OPENSSL_zalloc(sizeof(int) * (max_strength_bits + 1));\n    if (number_uses == NULL)\n        return 0;\n\n    /*\n     * Now find the strength_bits values actually used\n     */\n    curr = *head_p;\n    while (curr != NULL) {\n        if (curr->active)\n            number_uses[curr->cipher->strength_bits]++;\n        curr = curr->next;\n    }\n    /*\n     * Go through the list of used strength_bits values in descending\n     * order.\n     */\n    for (i = max_strength_bits; i >= 0; i--)\n        if (number_uses[i] > 0)\n            ssl_cipher_apply_rule(0, 0, 0, 0, 0, 0, 0, CIPHER_ORD, i, head_p,\n                                  tail_p);\n\n    OPENSSL_free(number_uses);\n    return 1;\n}\n\nstatic int ssl_cipher_process_rulestr(const char *rule_str,\n                                      CIPHER_ORDER **head_p,\n                                      CIPHER_ORDER **tail_p,\n                                      const SSL_CIPHER **ca_list, CERT *c)\n{\n    uint32_t alg_mkey, alg_auth, alg_enc, alg_mac, algo_strength;\n    int min_tls;\n    const char *l, *buf;\n    int j, multi, found, rule, retval, ok, buflen;\n    uint32_t cipher_id = 0;\n    char ch;\n\n    retval = 1;\n    l = rule_str;\n    for (;;) {\n        ch = *l;\n\n        if (ch == '\\0')\n            break;              /* done */\n        if (ch == '-') {\n            rule = CIPHER_DEL;\n            l++;\n        } else if (ch == '+') {\n            rule = CIPHER_ORD;\n            l++;\n        } else if (ch == '!') {\n            rule = CIPHER_KILL;\n            l++;\n        } else if (ch == '@') {\n            rule = CIPHER_SPECIAL;\n            l++;\n        } else {\n            rule = CIPHER_ADD;\n        }\n\n        if (ITEM_SEP(ch)) {\n            l++;\n            continue;\n        }\n\n        alg_mkey = 0;\n        alg_auth = 0;\n        alg_enc = 0;\n        alg_mac = 0;\n        min_tls = 0;\n        algo_strength = 0;\n\n        for (;;) {\n            ch = *l;\n            buf = l;\n            buflen = 0;\n            while (isalnum((unsigned char)ch) || (ch == '-') || (ch == '_') || (ch == '.')\n                   || (ch == '='))\n            {\n                ch = *(++l);\n                buflen++;\n            }\n\n            if (buflen == 0) {\n                /*\n                 * We hit something we cannot deal with,\n                 * it is no command or separator nor\n                 * alphanumeric, so we call this an error.\n                 */\n                ERR_raise(ERR_LIB_SSL, SSL_R_INVALID_COMMAND);\n                return 0;\n            }\n\n            if (rule == CIPHER_SPECIAL) {\n                found = 0;      /* unused -- avoid compiler warning */\n                break;          /* special treatment */\n            }\n\n            /* check for multi-part specification */\n            if (ch == '+') {\n                multi = 1;\n                l++;\n            } else {\n                multi = 0;\n            }\n\n            /*\n             * Now search for the cipher alias in the ca_list. Be careful\n             * with the strncmp, because the \"buflen\" limitation\n             * will make the rule \"ADH:SOME\" and the cipher\n             * \"ADH-MY-CIPHER\" look like a match for buflen=3.\n             * So additionally check whether the cipher name found\n             * has the correct length. We can save a strlen() call:\n             * just checking for the '\\0' at the right place is\n             * sufficient, we have to strncmp() anyway. (We cannot\n             * use strcmp(), because buf is not '\\0' terminated.)\n             */\n            j = found = 0;\n            cipher_id = 0;\n            while (ca_list[j]) {\n                if (strncmp(buf, ca_list[j]->name, buflen) == 0\n                    && (ca_list[j]->name[buflen] == '\\0')) {\n                    found = 1;\n                    break;\n                } else if (ca_list[j]->stdname != NULL\n                           && strncmp(buf, ca_list[j]->stdname, buflen) == 0\n                           && ca_list[j]->stdname[buflen] == '\\0') {\n                    found = 1;\n                    break;\n                } else\n                    j++;\n            }\n\n            if (!found)\n                break;          /* ignore this entry */\n\n            if (ca_list[j]->algorithm_mkey) {\n                if (alg_mkey) {\n                    alg_mkey &= ca_list[j]->algorithm_mkey;\n                    if (!alg_mkey) {\n                        found = 0;\n                        break;\n                    }\n                } else {\n                    alg_mkey = ca_list[j]->algorithm_mkey;\n                }\n            }\n\n            if (ca_list[j]->algorithm_auth) {\n                if (alg_auth) {\n                    alg_auth &= ca_list[j]->algorithm_auth;\n                    if (!alg_auth) {\n                        found = 0;\n                        break;\n                    }\n                } else {\n                    alg_auth = ca_list[j]->algorithm_auth;\n                }\n            }\n\n            if (ca_list[j]->algorithm_enc) {\n                if (alg_enc) {\n                    alg_enc &= ca_list[j]->algorithm_enc;\n                    if (!alg_enc) {\n                        found = 0;\n                        break;\n                    }\n                } else {\n                    alg_enc = ca_list[j]->algorithm_enc;\n                }\n            }\n\n            if (ca_list[j]->algorithm_mac) {\n                if (alg_mac) {\n                    alg_mac &= ca_list[j]->algorithm_mac;\n                    if (!alg_mac) {\n                        found = 0;\n                        break;\n                    }\n                } else {\n                    alg_mac = ca_list[j]->algorithm_mac;\n                }\n            }\n\n            if (ca_list[j]->algo_strength & SSL_STRONG_MASK) {\n                if (algo_strength & SSL_STRONG_MASK) {\n                    algo_strength &=\n                        (ca_list[j]->algo_strength & SSL_STRONG_MASK) |\n                        ~SSL_STRONG_MASK;\n                    if (!(algo_strength & SSL_STRONG_MASK)) {\n                        found = 0;\n                        break;\n                    }\n                } else {\n                    algo_strength = ca_list[j]->algo_strength & SSL_STRONG_MASK;\n                }\n            }\n\n            if (ca_list[j]->algo_strength & SSL_DEFAULT_MASK) {\n                if (algo_strength & SSL_DEFAULT_MASK) {\n                    algo_strength &=\n                        (ca_list[j]->algo_strength & SSL_DEFAULT_MASK) |\n                        ~SSL_DEFAULT_MASK;\n                    if (!(algo_strength & SSL_DEFAULT_MASK)) {\n                        found = 0;\n                        break;\n                    }\n                } else {\n                    algo_strength |=\n                        ca_list[j]->algo_strength & SSL_DEFAULT_MASK;\n                }\n            }\n\n            if (ca_list[j]->valid) {\n                /*\n                 * explicit ciphersuite found; its protocol version does not\n                 * become part of the search pattern!\n                 */\n\n                cipher_id = ca_list[j]->id;\n            } else {\n                /*\n                 * not an explicit ciphersuite; only in this case, the\n                 * protocol version is considered part of the search pattern\n                 */\n\n                if (ca_list[j]->min_tls) {\n                    if (min_tls != 0 && min_tls != ca_list[j]->min_tls) {\n                        found = 0;\n                        break;\n                    } else {\n                        min_tls = ca_list[j]->min_tls;\n                    }\n                }\n            }\n\n            if (!multi)\n                break;\n        }\n\n        /*\n         * Ok, we have the rule, now apply it\n         */\n        if (rule == CIPHER_SPECIAL) { /* special command */\n            ok = 0;\n            if ((buflen == 8) && HAS_PREFIX(buf, \"STRENGTH\")) {\n                ok = ssl_cipher_strength_sort(head_p, tail_p);\n            } else if (buflen == 10 && CHECK_AND_SKIP_PREFIX(buf, \"SECLEVEL=\")) {\n                int level = *buf - '0';\n                if (level < 0 || level > 5) {\n                    ERR_raise(ERR_LIB_SSL, SSL_R_INVALID_COMMAND);\n                } else {\n                    c->sec_level = level;\n                    ok = 1;\n                }\n            } else {\n                ERR_raise(ERR_LIB_SSL, SSL_R_INVALID_COMMAND);\n            }\n            if (ok == 0)\n                retval = 0;\n            /*\n             * We do not support any \"multi\" options\n             * together with \"@\", so throw away the\n             * rest of the command, if any left, until\n             * end or ':' is found.\n             */\n            while ((*l != '\\0') && !ITEM_SEP(*l))\n                l++;\n        } else if (found) {\n            ssl_cipher_apply_rule(cipher_id,\n                                  alg_mkey, alg_auth, alg_enc, alg_mac,\n                                  min_tls, algo_strength, rule, -1, head_p,\n                                  tail_p);\n        } else {\n            while ((*l != '\\0') && !ITEM_SEP(*l))\n                l++;\n        }\n        if (*l == '\\0')\n            break;              /* done */\n    }\n\n    return retval;\n}\n\n"}], "code": "int tls13_generate_handshake_secret(SSL_CONNECTION *s,\n                                    const unsigned char *insecret,\n                                    size_t insecretlen)\n{\n    /* Calls SSLfatal() if required */\n    return tls13_generate_secret(s, ssl_handshake_md(s), s->early_secret,\n                                 insecret, insecretlen,\n                                 (unsigned char *)&s->handshake_secret);\n}\n"}, "F51460EBEA5EC73A": {"calls": [{"id": "3954C80B7B27B1C1", "name": "tls13_export_keying_material_early", "path": "openssl/ssl/tls13_enc.c", "start": {"line": 808, "col": 1}, "end": {"line": 868, "col": 1}, "code": "                                       unsigned char *out, size_t olen,\n                                       const char *label, size_t llen,\n                                       const unsigned char *context,\n                                       size_t contextlen)\n{\n    /* ASCII: \"exporter\", in hex for EBCDIC compatibility */\n    static const unsigned char exporterlabel[] = \"\\x65\\x78\\x70\\x6F\\x72\\x74\\x65\\x72\";\n    unsigned char exportsecret[EVP_MAX_MD_SIZE];\n    unsigned char hash[EVP_MAX_MD_SIZE], data[EVP_MAX_MD_SIZE];\n    const EVP_MD *md;\n    EVP_MD_CTX *ctx = EVP_MD_CTX_new();\n    unsigned int hashsize, datalen;\n    int ret = 0;\n    const SSL_CIPHER *sslcipher;\n\n    if (ctx == NULL || !ossl_statem_export_early_allowed(s))\n        goto err;\n\n    if (!s->server && s->max_early_data > 0\n            && s->session->ext.max_early_data == 0)\n        sslcipher = SSL_SESSION_get0_cipher(s->psksession);\n    else\n        sslcipher = SSL_SESSION_get0_cipher(s->session);\n\n    md = ssl_md(SSL_CONNECTION_GET_CTX(s), sslcipher->algorithm2);\n\n    /*\n     * Calculate the hash value and store it in |data|. The reason why\n     * the empty string is used is that the definition of TLS-Exporter\n     * is like so:\n     *\n     * TLS-Exporter(label, context_value, key_length) =\n     *     HKDF-Expand-Label(Derive-Secret(Secret, label, \"\"),\n     *                       \"exporter\", Hash(context_value), key_length)\n     *\n     * Derive-Secret(Secret, Label, Messages) =\n     *       HKDF-Expand-Label(Secret, Label,\n     *                         Transcript-Hash(Messages), Hash.length)\n     *\n     * Here Transcript-Hash is the cipher suite hash algorithm.\n     */\n    if (md == NULL\n            || EVP_DigestInit_ex(ctx, md, NULL) <= 0\n            || EVP_DigestUpdate(ctx, context, contextlen) <= 0\n            || EVP_DigestFinal_ex(ctx, hash, &hashsize) <= 0\n            || EVP_DigestInit_ex(ctx, md, NULL) <= 0\n            || EVP_DigestFinal_ex(ctx, data, &datalen) <= 0\n            || !tls13_hkdf_expand(s, md, s->early_exporter_master_secret,\n                                  (const unsigned char *)label, llen,\n                                  data, datalen, exportsecret, hashsize, 0)\n            || !tls13_hkdf_expand(s, md, exportsecret, exporterlabel,\n                                  sizeof(exporterlabel) - 1, hash, hashsize,\n                                  out, olen, 0))\n        goto err;\n\n    ret = 1;\n err:\n    EVP_MD_CTX_free(ctx);\n    return ret;\n}\n"}], "code": "int SSL_export_keying_material_early(SSL *s, unsigned char *out, size_t olen,\n                                     const char *label, size_t llen,\n                                     const unsigned char *context,\n                                     size_t contextlen)\n{\n    SSL_CONNECTION *sc = SSL_CONNECTION_FROM_SSL(s);\n\n    if (sc == NULL)\n        return -1;\n\n    if (sc->version != TLS1_3_VERSION)\n        return 0;\n\n    return tls13_export_keying_material_early(sc, out, olen, label, llen,\n                                              context, contextlen);\n}\n"}, "95D36DAC386C30F9": {"calls": [{"id": "A4054E2DC1F6C9B1", "name": "ossl_lib_ctx_get_data", "path": "openssl/crypto/context.c", "start": {"line": 544, "col": 1}, "end": {"line": 633, "col": 1}, "code": "{\n    void *p;\n\n    ctx = ossl_lib_ctx_get_concrete(ctx);\n    if (ctx == NULL)\n        return NULL;\n\n    switch (index) {\n    case OSSL_LIB_CTX_PROPERTY_STRING_INDEX:\n        return ctx->property_string_data;\n    case OSSL_LIB_CTX_EVP_METHOD_STORE_INDEX:\n        return ctx->evp_method_store;\n    case OSSL_LIB_CTX_PROVIDER_STORE_INDEX:\n        return ctx->provider_store;\n    case OSSL_LIB_CTX_NAMEMAP_INDEX:\n        return ctx->namemap;\n    case OSSL_LIB_CTX_PROPERTY_DEFN_INDEX:\n        return ctx->property_defns;\n    case OSSL_LIB_CTX_GLOBAL_PROPERTIES:\n        return ctx->global_properties;\n    case OSSL_LIB_CTX_DRBG_INDEX:\n        return ctx->drbg;\n    case OSSL_LIB_CTX_DRBG_NONCE_INDEX:\n        return ctx->drbg_nonce;\n"}, {"id": "5BCCB55077A06C16", "name": "ossl_provider_libctx", "path": "openssl/crypto/provider_core.c", "start": {"line": 1606, "col": 1}, "end": {"line": 1609, "col": 1}, "code": "{\n    return prov != NULL ? prov->libctx : NULL;\n}\n\n/* Wrappers around calls to the provider */\nvoid ossl_provider_teardown(const OSSL_PROVIDER *prov)\n{\n    if (prov->teardown != NULL\n#ifndef FIPS_MODULE\n            && !prov->ischild\n#endif\n       )\n        prov->teardown(prov->provctx);\n}\n\nconst OSSL_PARAM *ossl_provider_gettable_params(const OSSL_PROVIDER *prov)\n{\n    return prov->gettable_params == NULL\n        ? NULL : prov->gettable_params(prov->provctx);\n}\n\nint ossl_provider_get_params(const OSSL_PROVIDER *prov, OSSL_PARAM params[])\n{\n    return prov->get_params == NULL\n        ? 0 : prov->get_params(prov->provctx, params);\n}\n\nint ossl_provider_self_test(const OSSL_PROVIDER *prov)\n{\n    int ret;\n\n    if (prov->self_test == NULL)\n        return 1;\n    ret = prov->self_test(prov->provctx);\n    if (ret == 0)\n        (void)provider_remove_store_methods((OSSL_PROVIDER *)prov);\n    return ret;\n}\n\nint ossl_provider_get_capabilities(const OSSL_PROVIDER *prov,\n                                   const char *capability,\n                                   OSSL_CALLBACK *cb,\n                                   void *arg)\n{\n    return prov->get_capabilities == NULL\n        ? 1 : prov->get_capabilities(prov->provctx, capability, cb, arg);\n}\n\nconst OSSL_ALGORITHM *ossl_provider_query_operation(const OSSL_PROVIDER *prov,\n                                                    int operation_id,\n                                                    int *no_cache)\n{\n    const OSSL_ALGORITHM *res;\n\n    if (prov->query_operation == NULL)\n        return NULL;\n    res = prov->query_operation(prov->provctx, operation_id, no_cache);\n#if defined(OPENSSL_NO_CACHED_FETCH)\n    /* Forcing the non-caching of queries */\n    if (no_cache != NULL)\n        *no_cache = 1;\n#endif\n    return res;\n}\n\nvoid ossl_provider_unquery_operation(const OSSL_PROVIDER *prov,\n                                     int operation_id,\n                                     const OSSL_ALGORITHM *algs)\n{\n    if (prov->unquery_operation != NULL)\n        prov->unquery_operation(prov->provctx, operation_id, algs);\n}\n\nint ossl_provider_set_operation_bit(OSSL_PROVIDER *provider, size_t bitnum)\n{\n    size_t byte = bitnum / 8;\n    unsigned char bit = (1 << (bitnum % 8)) & 0xFF;\n\n    if (!CRYPTO_THREAD_write_lock(provider->opbits_lock))\n        return 0;\n    if (provider->operation_bits_sz <= byte) {\n        unsigned char *tmp = OPENSSL_realloc(provider->operation_bits,\n                                             byte + 1);\n\n        if (tmp == NULL) {\n            CRYPTO_THREAD_unlock(provider->opbits_lock);\n            return 0;\n        }\n        provider->operation_bits = tmp;\n        memset(provider->operation_bits + provider->operation_bits_sz,\n               '\\0', byte + 1 - provider->operation_bits_sz);\n        provider->operation_bits_sz = byte + 1;\n    }\n    provider->operation_bits[byte] |= bit;\n    CRYPTO_THREAD_unlock(provider->opbits_lock);\n    return 1;\n}\n\nint ossl_provider_test_operation_bit(OSSL_PROVIDER *provider, size_t bitnum,\n                                     int *result)\n{\n    size_t byte = bitnum / 8;\n    unsigned char bit = (1 << (bitnum % 8)) & 0xFF;\n\n    if (!ossl_assert(result != NULL)) {\n        ERR_raise(ERR_LIB_CRYPTO, ERR_R_PASSED_NULL_PARAMETER);\n        return 0;\n    }\n\n    *result = 0;\n    if (!CRYPTO_THREAD_read_lock(provider->opbits_lock))\n        return 0;\n    if (provider->operation_bits_sz > byte)\n        *result = ((provider->operation_bits[byte] & bit) != 0);\n    CRYPTO_THREAD_unlock(provider->opbits_lock);\n    return 1;\n}\n\n#ifndef FIPS_MODULE\nconst OSSL_CORE_HANDLE *ossl_provider_get_parent(OSSL_PROVIDER *prov)\n{\n    return prov->handle;\n}\n\nint ossl_provider_is_child(const OSSL_PROVIDER *prov)\n{\n    return prov->ischild;\n}\n\nint ossl_provider_set_child(OSSL_PROVIDER *prov, const OSSL_CORE_HANDLE *handle)\n{\n    prov->handle = handle;\n    prov->ischild = 1;\n\n    return 1;\n}\n\nint ossl_provider_default_props_update(OSSL_LIB_CTX *libctx, const char *props)\n{\n#ifndef FIPS_MODULE\n    struct provider_store_st *store = NULL;\n    int i, max;\n    OSSL_PROVIDER_CHILD_CB *child_cb;\n\n    if ((store = get_provider_store(libctx)) == NULL)\n        return 0;\n\n    if (!CRYPTO_THREAD_read_lock(store->lock))\n        return 0;\n\n    max = sk_OSSL_PROVIDER_CHILD_CB_num(store->child_cbs);\n    for (i = 0; i < max; i++) {\n        child_cb = sk_OSSL_PROVIDER_CHILD_CB_value(store->child_cbs, i);\n        child_cb->global_props_cb(props, child_cb->cbdata);\n    }\n\n    CRYPTO_THREAD_unlock(store->lock);\n#endif\n    return 1;\n}\n\nstatic int ossl_provider_register_child_cb(const OSSL_CORE_HANDLE *handle,\n                                           int (*create_cb)(\n                                               const OSSL_CORE_HANDLE *provider,\n                                               void *cbdata),\n                                           int (*remove_cb)(\n                                               const OSSL_CORE_HANDLE *provider,\n                                               void *cbdata),\n                                           int (*global_props_cb)(\n                                               const char *props,\n                                               void *cbdata),\n                                           void *cbdata)\n{\n    /*\n     * This is really an OSSL_PROVIDER that we created and cast to\n     * OSSL_CORE_HANDLE originally. Therefore it is safe to cast it back.\n     */\n    OSSL_PROVIDER *thisprov = (OSSL_PROVIDER *)handle;\n    OSSL_PROVIDER *prov;\n    OSSL_LIB_CTX *libctx = thisprov->libctx;\n    struct provider_store_st *store = NULL;\n    int ret = 0, i, max;\n    OSSL_PROVIDER_CHILD_CB *child_cb;\n    char *propsstr = NULL;\n\n    if ((store = get_provider_store(libctx)) == NULL)\n        return 0;\n\n    child_cb = OPENSSL_malloc(sizeof(*child_cb));\n    if (child_cb == NULL)\n        return 0;\n    child_cb->prov = thisprov;\n    child_cb->create_cb = create_cb;\n    child_cb->remove_cb = remove_cb;\n    child_cb->global_props_cb = global_props_cb;\n    child_cb->cbdata = cbdata;\n\n    if (!CRYPTO_THREAD_write_lock(store->lock)) {\n        OPENSSL_free(child_cb);\n        return 0;\n    }\n    propsstr = evp_get_global_properties_str(libctx, 0);\n\n    if (propsstr != NULL) {\n        global_props_cb(propsstr, cbdata);\n        OPENSSL_free(propsstr);\n    }\n    max = sk_OSSL_PROVIDER_num(store->providers);\n    for (i = 0; i < max; i++) {\n        int activated;\n\n        prov = sk_OSSL_PROVIDER_value(store->providers, i);\n\n        if (!CRYPTO_THREAD_read_lock(prov->flag_lock))\n            break;\n        activated = prov->flag_activated;\n        CRYPTO_THREAD_unlock(prov->flag_lock);\n        /*\n         * We hold the store lock while calling the user callback. This means\n         * that the user callback must be short and simple and not do anything\n         * likely to cause a deadlock. We don't hold the flag_lock during this\n         * call. In theory this means that another thread could deactivate it\n         * while we are calling create. This is ok because the other thread\n         * will also call remove_cb, but won't be able to do so until we release\n         * the store lock.\n         */\n        if (activated && !create_cb((OSSL_CORE_HANDLE *)prov, cbdata))\n            break;\n    }\n    if (i == max) {\n        /* Success */\n        ret = sk_OSSL_PROVIDER_CHILD_CB_push(store->child_cbs, child_cb);\n    }\n    if (i != max || ret <= 0) {\n        /* Failed during creation. Remove everything we just added */\n        for (; i >= 0; i--) {\n            prov = sk_OSSL_PROVIDER_value(store->providers, i);\n            remove_cb((OSSL_CORE_HANDLE *)prov, cbdata);\n        }\n        OPENSSL_free(child_cb);\n        ret = 0;\n    }\n    CRYPTO_THREAD_unlock(store->lock);\n\n    return ret;\n}\n\nstatic void ossl_provider_deregister_child_cb(const OSSL_CORE_HANDLE *handle)\n{\n    /*\n     * This is really an OSSL_PROVIDER that we created and cast to\n     * OSSL_CORE_HANDLE originally. Therefore it is safe to cast it back.\n     */\n    OSSL_PROVIDER *thisprov = (OSSL_PROVIDER *)handle;\n    OSSL_LIB_CTX *libctx = thisprov->libctx;\n    struct provider_store_st *store = NULL;\n    int i, max;\n    OSSL_PROVIDER_CHILD_CB *child_cb;\n\n    if ((store = get_provider_store(libctx)) == NULL)\n        return;\n\n    if (!CRYPTO_THREAD_write_lock(store->lock))\n        return;\n    max = sk_OSSL_PROVIDER_CHILD_CB_num(store->child_cbs);\n    for (i = 0; i < max; i++) {\n        child_cb = sk_OSSL_PROVIDER_CHILD_CB_value(store->child_cbs, i);\n        if (child_cb->prov == thisprov) {\n            /* Found an entry */\n            sk_OSSL_PROVIDER_CHILD_CB_delete(store->child_cbs, i);\n            OPENSSL_free(child_cb);\n            break;\n        }\n    }\n    CRYPTO_THREAD_unlock(store->lock);\n}\n#endif\n\n/*-\n * Core functions for the provider\n * ===============================\n *\n * This is the set of functions that the core makes available to the provider\n */\n\n/*\n * This returns a list of Provider Object parameters with their types, for\n * discovery.  We do not expect that many providers will use this, but one\n * never knows.\n */\nstatic const OSSL_PARAM param_types[] = {\n    OSSL_PARAM_DEFN(OSSL_PROV_PARAM_CORE_VERSION, OSSL_PARAM_UTF8_PTR, NULL, 0),\n    OSSL_PARAM_DEFN(OSSL_PROV_PARAM_CORE_PROV_NAME, OSSL_PARAM_UTF8_PTR,\n                    NULL, 0),\n#ifndef FIPS_MODULE\n    OSSL_PARAM_DEFN(OSSL_PROV_PARAM_CORE_MODULE_FILENAME, OSSL_PARAM_UTF8_PTR,\n                    NULL, 0),\n#endif\n    OSSL_PARAM_END\n};\n\n/*\n * Forward declare all the functions that are provided aa dispatch.\n * This ensures that the compiler will complain if they aren't defined\n * with the correct signature.\n */\nstatic OSSL_FUNC_core_gettable_params_fn core_gettable_params;\nstatic OSSL_FUNC_core_get_params_fn core_get_params;\nstatic OSSL_FUNC_core_get_libctx_fn core_get_libctx;\nstatic OSSL_FUNC_core_thread_start_fn core_thread_start;\n#ifndef FIPS_MODULE\nstatic OSSL_FUNC_core_new_error_fn core_new_error;\nstatic OSSL_FUNC_core_set_error_debug_fn core_set_error_debug;\nstatic OSSL_FUNC_core_vset_error_fn core_vset_error;\nstatic OSSL_FUNC_core_set_error_mark_fn core_set_error_mark;\nstatic OSSL_FUNC_core_clear_last_error_mark_fn core_clear_last_error_mark;\nstatic OSSL_FUNC_core_pop_error_to_mark_fn core_pop_error_to_mark;\nOSSL_FUNC_BIO_new_file_fn ossl_core_bio_new_file;\nOSSL_FUNC_BIO_new_membuf_fn ossl_core_bio_new_mem_buf;\nOSSL_FUNC_BIO_read_ex_fn ossl_core_bio_read_ex;\nOSSL_FUNC_BIO_write_ex_fn ossl_core_bio_write_ex;\nOSSL_FUNC_BIO_gets_fn ossl_core_bio_gets;\nOSSL_FUNC_BIO_puts_fn ossl_core_bio_puts;\nOSSL_FUNC_BIO_up_ref_fn ossl_core_bio_up_ref;\nOSSL_FUNC_BIO_free_fn ossl_core_bio_free;\nOSSL_FUNC_BIO_vprintf_fn ossl_core_bio_vprintf;\nOSSL_FUNC_BIO_vsnprintf_fn BIO_vsnprintf;\nstatic OSSL_FUNC_self_test_cb_fn core_self_test_get_callback;\nstatic OSSL_FUNC_get_entropy_fn rand_get_entropy;\nstatic OSSL_FUNC_get_user_entropy_fn rand_get_user_entropy;\nstatic OSSL_FUNC_cleanup_entropy_fn rand_cleanup_entropy;\nstatic OSSL_FUNC_cleanup_user_entropy_fn rand_cleanup_user_entropy;\nstatic OSSL_FUNC_get_nonce_fn rand_get_nonce;\nstatic OSSL_FUNC_get_user_nonce_fn rand_get_user_nonce;\nstatic OSSL_FUNC_cleanup_nonce_fn rand_cleanup_nonce;\nstatic OSSL_FUNC_cleanup_user_nonce_fn rand_cleanup_user_nonce;\n#endif\nOSSL_FUNC_CRYPTO_malloc_fn CRYPTO_malloc;\nOSSL_FUNC_CRYPTO_zalloc_fn CRYPTO_zalloc;\nOSSL_FUNC_CRYPTO_free_fn CRYPTO_free;\nOSSL_FUNC_CRYPTO_clear_free_fn CRYPTO_clear_free;\nOSSL_FUNC_CRYPTO_realloc_fn CRYPTO_realloc;\nOSSL_FUNC_CRYPTO_clear_realloc_fn CRYPTO_clear_realloc;\nOSSL_FUNC_CRYPTO_secure_malloc_fn CRYPTO_secure_malloc;\nOSSL_FUNC_CRYPTO_secure_zalloc_fn CRYPTO_secure_zalloc;\nOSSL_FUNC_CRYPTO_secure_free_fn CRYPTO_secure_free;\nOSSL_FUNC_CRYPTO_secure_clear_free_fn CRYPTO_secure_clear_free;\nOSSL_FUNC_CRYPTO_secure_allocated_fn CRYPTO_secure_allocated;\nOSSL_FUNC_OPENSSL_cleanse_fn OPENSSL_cleanse;\n#ifndef FIPS_MODULE\nOSSL_FUNC_provider_register_child_cb_fn ossl_provider_register_child_cb;\nOSSL_FUNC_provider_deregister_child_cb_fn ossl_provider_deregister_child_cb;\nstatic OSSL_FUNC_provider_name_fn core_provider_get0_name;\nstatic OSSL_FUNC_provider_get0_provider_ctx_fn core_provider_get0_provider_ctx;\nstatic OSSL_FUNC_provider_get0_dispatch_fn core_provider_get0_dispatch;\nstatic OSSL_FUNC_provider_up_ref_fn core_provider_up_ref_intern;\nstatic OSSL_FUNC_provider_free_fn core_provider_free_intern;\nstatic OSSL_FUNC_core_obj_add_sigid_fn core_obj_add_sigid;\nstatic OSSL_FUNC_core_obj_create_fn core_obj_create;\n#endif\n\nstatic const OSSL_PARAM *core_gettable_params(const OSSL_CORE_HANDLE *handle)\n{\n    return param_types;\n}\n\nstatic int core_get_params(const OSSL_CORE_HANDLE *handle, OSSL_PARAM params[])\n{\n    int i;\n    OSSL_PARAM *p;\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    if ((p = OSSL_PARAM_locate(params, OSSL_PROV_PARAM_CORE_VERSION)) != NULL)\n        OSSL_PARAM_set_utf8_ptr(p, OPENSSL_VERSION_STR);\n    if ((p = OSSL_PARAM_locate(params, OSSL_PROV_PARAM_CORE_PROV_NAME)) != NULL)\n        OSSL_PARAM_set_utf8_ptr(p, prov->name);\n\n#ifndef FIPS_MODULE\n    if ((p = OSSL_PARAM_locate(params,\n                               OSSL_PROV_PARAM_CORE_MODULE_FILENAME)) != NULL)\n        OSSL_PARAM_set_utf8_ptr(p, ossl_provider_module_path(prov));\n#endif\n\n    if (prov->parameters == NULL)\n        return 1;\n\n    for (i = 0; i < sk_INFOPAIR_num(prov->parameters); i++) {\n        INFOPAIR *pair = sk_INFOPAIR_value(prov->parameters, i);\n\n        if ((p = OSSL_PARAM_locate(params, pair->name)) != NULL)\n            OSSL_PARAM_set_utf8_ptr(p, pair->value);\n    }\n    return 1;\n}\n\nstatic OPENSSL_CORE_CTX *core_get_libctx(const OSSL_CORE_HANDLE *handle)\n{\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    /*\n     * Using ossl_provider_libctx would be wrong as that returns\n     * NULL for |prov| == NULL and NULL libctx has a special meaning\n     * that does not apply here. Here |prov| == NULL can happen only in\n     * case of a coding error.\n     */\n    assert(prov != NULL);\n    return (OPENSSL_CORE_CTX *)prov->libctx;\n}\n\nstatic int core_thread_start(const OSSL_CORE_HANDLE *handle,\n                             OSSL_thread_stop_handler_fn handfn,\n                             void *arg)\n{\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    return ossl_init_thread_start(prov, arg, handfn);\n}\n\n/*\n * The FIPS module inner provider doesn't implement these.  They aren't\n * needed there, since the FIPS module upcalls are always the outer provider\n * ones.\n */\n#ifndef FIPS_MODULE\n/*\n * These error functions should use |handle| to select the proper\n * library context to report in the correct error stack if error\n * stacks become tied to the library context.\n * We cannot currently do that since there's no support for it in the\n * ERR subsystem.\n */\nstatic void core_new_error(const OSSL_CORE_HANDLE *handle)\n{\n    ERR_new();\n}\n\nstatic void core_set_error_debug(const OSSL_CORE_HANDLE *handle,\n                                 const char *file, int line, const char *func)\n{\n    ERR_set_debug(file, line, func);\n}\n\nstatic void core_vset_error(const OSSL_CORE_HANDLE *handle,\n                            uint32_t reason, const char *fmt, va_list args)\n{\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    /*\n     * If the uppermost 8 bits are non-zero, it's an OpenSSL library\n     * error and will be treated as such.  Otherwise, it's a new style\n     * provider error and will be treated as such.\n     */\n    if (ERR_GET_LIB(reason) != 0) {\n        ERR_vset_error(ERR_GET_LIB(reason), ERR_GET_REASON(reason), fmt, args);\n    } else {\n        ERR_vset_error(prov->error_lib, (int)reason, fmt, args);\n    }\n}\n\nstatic int core_set_error_mark(const OSSL_CORE_HANDLE *handle)\n{\n    return ERR_set_mark();\n}\n\nstatic int core_clear_last_error_mark(const OSSL_CORE_HANDLE *handle)\n{\n    return ERR_clear_last_mark();\n}\n\nstatic int core_pop_error_to_mark(const OSSL_CORE_HANDLE *handle)\n{\n    return ERR_pop_to_mark();\n}\n\nstatic void core_self_test_get_callback(OPENSSL_CORE_CTX *libctx,\n                                        OSSL_CALLBACK **cb, void **cbarg)\n{\n    OSSL_SELF_TEST_get_callback((OSSL_LIB_CTX *)libctx, cb, cbarg);\n}\n\nstatic size_t rand_get_entropy(const OSSL_CORE_HANDLE *handle,\n                               unsigned char **pout, int entropy,\n                               size_t min_len, size_t max_len)\n{\n    return ossl_rand_get_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                 pout, entropy, min_len, max_len);\n}\n\nstatic size_t rand_get_user_entropy(const OSSL_CORE_HANDLE *handle,\n                                    unsigned char **pout, int entropy,\n                                    size_t min_len, size_t max_len)\n{\n    return ossl_rand_get_user_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                      pout, entropy, min_len, max_len);\n}\n\nstatic void rand_cleanup_entropy(const OSSL_CORE_HANDLE *handle,\n                                 unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                              buf, len);\n}\n\nstatic void rand_cleanup_user_entropy(const OSSL_CORE_HANDLE *handle,\n                                      unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_user_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                   buf, len);\n}\n\nstatic size_t rand_get_nonce(const OSSL_CORE_HANDLE *handle,\n                             unsigned char **pout,\n                             size_t min_len, size_t max_len,\n                             const void *salt, size_t salt_len)\n{\n    return ossl_rand_get_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                               pout, min_len, max_len, salt, salt_len);\n}\n\nstatic size_t rand_get_user_nonce(const OSSL_CORE_HANDLE *handle,\n                                  unsigned char **pout,\n                                  size_t min_len, size_t max_len,\n                                  const void *salt, size_t salt_len)\n{\n    return ossl_rand_get_user_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                    pout, min_len, max_len, salt, salt_len);\n}\n\nstatic void rand_cleanup_nonce(const OSSL_CORE_HANDLE *handle,\n                               unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                            buf, len);\n}\n\nstatic void rand_cleanup_user_nonce(const OSSL_CORE_HANDLE *handle,\n                               unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_user_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                 buf, len);\n}\n\nstatic const char *core_provider_get0_name(const OSSL_CORE_HANDLE *prov)\n{\n    return OSSL_PROVIDER_get0_name((const OSSL_PROVIDER *)prov);\n}\n\nstatic void *core_provider_get0_provider_ctx(const OSSL_CORE_HANDLE *prov)\n{\n    return OSSL_PROVIDER_get0_provider_ctx((const OSSL_PROVIDER *)prov);\n}\n\nstatic const OSSL_DISPATCH *\ncore_provider_get0_dispatch(const OSSL_CORE_HANDLE *prov)\n{\n    return OSSL_PROVIDER_get0_dispatch((const OSSL_PROVIDER *)prov);\n}\n\nstatic int core_provider_up_ref_intern(const OSSL_CORE_HANDLE *prov,\n                                       int activate)\n{\n    return provider_up_ref_intern((OSSL_PROVIDER *)prov, activate);\n}\n\nstatic int core_provider_free_intern(const OSSL_CORE_HANDLE *prov,\n                                     int deactivate)\n{\n    return provider_free_intern((OSSL_PROVIDER *)prov, deactivate);\n}\n\nstatic int core_obj_add_sigid(const OSSL_CORE_HANDLE *prov,\n                              const char *sign_name, const char *digest_name,\n                              const char *pkey_name)\n{\n    int sign_nid = OBJ_txt2nid(sign_name);\n    int digest_nid = NID_undef;\n    int pkey_nid = OBJ_txt2nid(pkey_name);\n\n    if (digest_name != NULL && digest_name[0] != '\\0'\n        && (digest_nid = OBJ_txt2nid(digest_name)) == NID_undef)\n            return 0;\n\n    if (sign_nid == NID_undef)\n        return 0;\n\n    /*\n     * Check if it already exists. This is a success if so (even if we don't\n     * have nids for the digest/pkey)\n     */\n    if (OBJ_find_sigid_algs(sign_nid, NULL, NULL))\n        return 1;\n\n    if (pkey_nid == NID_undef)\n        return 0;\n\n    return OBJ_add_sigid(sign_nid, digest_nid, pkey_nid);\n}\n\nstatic int core_obj_create(const OSSL_CORE_HANDLE *prov, const char *oid,\n                           const char *sn, const char *ln)\n{\n    /* Check if it already exists and create it if not */\n    return OBJ_txt2nid(oid) != NID_undef\n           || OBJ_create(oid, sn, ln) != NID_undef;\n}\n#endif /* FIPS_MODULE */\n\n/*\n * Functions provided by the core.\n */\nstatic const OSSL_DISPATCH core_dispatch_[] = {\n    { OSSL_FUNC_CORE_GETTABLE_PARAMS, (void (*)(void))core_gettable_params },\n    { OSSL_FUNC_CORE_GET_PARAMS, (void (*)(void))core_get_params },\n    { OSSL_FUNC_CORE_GET_LIBCTX, (void (*)(void))core_get_libctx },\n    { OSSL_FUNC_CORE_THREAD_START, (void (*)(void))core_thread_start },\n#ifndef FIPS_MODULE\n    { OSSL_FUNC_CORE_NEW_ERROR, (void (*)(void))core_new_error },\n    { OSSL_FUNC_CORE_SET_ERROR_DEBUG, (void (*)(void))core_set_error_debug },\n    { OSSL_FUNC_CORE_VSET_ERROR, (void (*)(void))core_vset_error },\n    { OSSL_FUNC_CORE_SET_ERROR_MARK, (void (*)(void))core_set_error_mark },\n    { OSSL_FUNC_CORE_CLEAR_LAST_ERROR_MARK,\n      (void (*)(void))core_clear_last_error_mark },\n    { OSSL_FUNC_CORE_POP_ERROR_TO_MARK, (void (*)(void))core_pop_error_to_mark },\n    { OSSL_FUNC_BIO_NEW_FILE, (void (*)(void))ossl_core_bio_new_file },\n    { OSSL_FUNC_BIO_NEW_MEMBUF, (void (*)(void))ossl_core_bio_new_mem_buf },\n    { OSSL_FUNC_BIO_READ_EX, (void (*)(void))ossl_core_bio_read_ex },\n    { OSSL_FUNC_BIO_WRITE_EX, (void (*)(void))ossl_core_bio_write_ex },\n    { OSSL_FUNC_BIO_GETS, (void (*)(void))ossl_core_bio_gets },\n    { OSSL_FUNC_BIO_PUTS, (void (*)(void))ossl_core_bio_puts },\n    { OSSL_FUNC_BIO_CTRL, (void (*)(void))ossl_core_bio_ctrl },\n    { OSSL_FUNC_BIO_UP_REF, (void (*)(void))ossl_core_bio_up_ref },\n    { OSSL_FUNC_BIO_FREE, (void (*)(void))ossl_core_bio_free },\n    { OSSL_FUNC_BIO_VPRINTF, (void (*)(void))ossl_core_bio_vprintf },\n    { OSSL_FUNC_BIO_VSNPRINTF, (void (*)(void))BIO_vsnprintf },\n    { OSSL_FUNC_SELF_TEST_CB, (void (*)(void))core_self_test_get_callback },\n    { OSSL_FUNC_GET_ENTROPY, (void (*)(void))rand_get_entropy },\n    { OSSL_FUNC_GET_USER_ENTROPY, (void (*)(void))rand_get_user_entropy },\n    { OSSL_FUNC_CLEANUP_ENTROPY, (void (*)(void))rand_cleanup_entropy },\n    { OSSL_FUNC_CLEANUP_USER_ENTROPY, (void (*)(void))rand_cleanup_user_entropy },\n    { OSSL_FUNC_GET_NONCE, (void (*)(void))rand_get_nonce },\n    { OSSL_FUNC_GET_USER_NONCE, (void (*)(void))rand_get_user_nonce },\n    { OSSL_FUNC_CLEANUP_NONCE, (void (*)(void))rand_cleanup_nonce },\n    { OSSL_FUNC_CLEANUP_USER_NONCE, (void (*)(void))rand_cleanup_user_nonce },\n#endif\n    { OSSL_FUNC_CRYPTO_MALLOC, (void (*)(void))CRYPTO_malloc },\n    { OSSL_FUNC_CRYPTO_ZALLOC, (void (*)(void))CRYPTO_zalloc },\n    { OSSL_FUNC_CRYPTO_FREE, (void (*)(void))CRYPTO_free },\n    { OSSL_FUNC_CRYPTO_CLEAR_FREE, (void (*)(void))CRYPTO_clear_free },\n    { OSSL_FUNC_CRYPTO_REALLOC, (void (*)(void))CRYPTO_realloc },\n    { OSSL_FUNC_CRYPTO_CLEAR_REALLOC, (void (*)(void))CRYPTO_clear_realloc },\n    { OSSL_FUNC_CRYPTO_SECURE_MALLOC, (void (*)(void))CRYPTO_secure_malloc },\n    { OSSL_FUNC_CRYPTO_SECURE_ZALLOC, (void (*)(void))CRYPTO_secure_zalloc },\n    { OSSL_FUNC_CRYPTO_SECURE_FREE, (void (*)(void))CRYPTO_secure_free },\n    { OSSL_FUNC_CRYPTO_SECURE_CLEAR_FREE,\n        (void (*)(void))CRYPTO_secure_clear_free },\n    { OSSL_FUNC_CRYPTO_SECURE_ALLOCATED,\n        (void (*)(void))CRYPTO_secure_allocated },\n    { OSSL_FUNC_OPENSSL_CLEANSE, (void (*)(void))OPENSSL_cleanse },\n#ifndef FIPS_MODULE\n    { OSSL_FUNC_PROVIDER_REGISTER_CHILD_CB,\n        (void (*)(void))ossl_provider_register_child_cb },\n    { OSSL_FUNC_PROVIDER_DEREGISTER_CHILD_CB,\n        (void (*)(void))ossl_provider_deregister_child_cb },\n    { OSSL_FUNC_PROVIDER_NAME,\n        (void (*)(void))core_provider_get0_name },\n    { OSSL_FUNC_PROVIDER_GET0_PROVIDER_CTX,\n        (void (*)(void))core_provider_get0_provider_ctx },\n    { OSSL_FUNC_PROVIDER_GET0_DISPATCH,\n        (void (*)(void))core_provider_get0_dispatch },\n    { OSSL_FUNC_PROVIDER_UP_REF,\n        (void (*)(void))core_provider_up_ref_intern },\n    { OSSL_FUNC_PROVIDER_FREE,\n        (void (*)(void))core_provider_free_intern },\n    { OSSL_FUNC_CORE_OBJ_ADD_SIGID, (void (*)(void))core_obj_add_sigid },\n    { OSSL_FUNC_CORE_OBJ_CREATE, (void (*)(void))core_obj_create },\n#endif\n    OSSL_DISPATCH_END\n};\nstatic const OSSL_DISPATCH *core_dispatch = core_dispatch_;\n"}, {"id": "00BADC77F97FF4F4", "name": "ossl_provider_get_parent", "path": "openssl/crypto/provider_core.c", "start": {"line": 1726, "col": 1}, "end": {"line": 1729, "col": 1}, "code": "{\n    return prov->handle;\n}\n\nint ossl_provider_is_child(const OSSL_PROVIDER *prov)\n{\n    return prov->ischild;\n}\n\nint ossl_provider_set_child(OSSL_PROVIDER *prov, const OSSL_CORE_HANDLE *handle)\n{\n    prov->handle = handle;\n    prov->ischild = 1;\n\n    return 1;\n}\n\nint ossl_provider_default_props_update(OSSL_LIB_CTX *libctx, const char *props)\n{\n#ifndef FIPS_MODULE\n    struct provider_store_st *store = NULL;\n    int i, max;\n    OSSL_PROVIDER_CHILD_CB *child_cb;\n\n    if ((store = get_provider_store(libctx)) == NULL)\n        return 0;\n\n    if (!CRYPTO_THREAD_read_lock(store->lock))\n        return 0;\n\n    max = sk_OSSL_PROVIDER_CHILD_CB_num(store->child_cbs);\n    for (i = 0; i < max; i++) {\n        child_cb = sk_OSSL_PROVIDER_CHILD_CB_value(store->child_cbs, i);\n        child_cb->global_props_cb(props, child_cb->cbdata);\n    }\n\n    CRYPTO_THREAD_unlock(store->lock);\n#endif\n    return 1;\n}\n\nstatic int ossl_provider_register_child_cb(const OSSL_CORE_HANDLE *handle,\n                                           int (*create_cb)(\n                                               const OSSL_CORE_HANDLE *provider,\n                                               void *cbdata),\n                                           int (*remove_cb)(\n                                               const OSSL_CORE_HANDLE *provider,\n                                               void *cbdata),\n                                           int (*global_props_cb)(\n                                               const char *props,\n                                               void *cbdata),\n                                           void *cbdata)\n{\n    /*\n     * This is really an OSSL_PROVIDER that we created and cast to\n     * OSSL_CORE_HANDLE originally. Therefore it is safe to cast it back.\n     */\n    OSSL_PROVIDER *thisprov = (OSSL_PROVIDER *)handle;\n    OSSL_PROVIDER *prov;\n    OSSL_LIB_CTX *libctx = thisprov->libctx;\n    struct provider_store_st *store = NULL;\n    int ret = 0, i, max;\n    OSSL_PROVIDER_CHILD_CB *child_cb;\n    char *propsstr = NULL;\n\n    if ((store = get_provider_store(libctx)) == NULL)\n        return 0;\n\n    child_cb = OPENSSL_malloc(sizeof(*child_cb));\n    if (child_cb == NULL)\n        return 0;\n    child_cb->prov = thisprov;\n    child_cb->create_cb = create_cb;\n    child_cb->remove_cb = remove_cb;\n    child_cb->global_props_cb = global_props_cb;\n    child_cb->cbdata = cbdata;\n\n    if (!CRYPTO_THREAD_write_lock(store->lock)) {\n        OPENSSL_free(child_cb);\n        return 0;\n    }\n    propsstr = evp_get_global_properties_str(libctx, 0);\n\n    if (propsstr != NULL) {\n        global_props_cb(propsstr, cbdata);\n        OPENSSL_free(propsstr);\n    }\n    max = sk_OSSL_PROVIDER_num(store->providers);\n    for (i = 0; i < max; i++) {\n        int activated;\n\n        prov = sk_OSSL_PROVIDER_value(store->providers, i);\n\n        if (!CRYPTO_THREAD_read_lock(prov->flag_lock))\n            break;\n        activated = prov->flag_activated;\n        CRYPTO_THREAD_unlock(prov->flag_lock);\n        /*\n         * We hold the store lock while calling the user callback. This means\n         * that the user callback must be short and simple and not do anything\n         * likely to cause a deadlock. We don't hold the flag_lock during this\n         * call. In theory this means that another thread could deactivate it\n         * while we are calling create. This is ok because the other thread\n         * will also call remove_cb, but won't be able to do so until we release\n         * the store lock.\n         */\n        if (activated && !create_cb((OSSL_CORE_HANDLE *)prov, cbdata))\n            break;\n    }\n    if (i == max) {\n        /* Success */\n        ret = sk_OSSL_PROVIDER_CHILD_CB_push(store->child_cbs, child_cb);\n    }\n    if (i != max || ret <= 0) {\n        /* Failed during creation. Remove everything we just added */\n        for (; i >= 0; i--) {\n            prov = sk_OSSL_PROVIDER_value(store->providers, i);\n            remove_cb((OSSL_CORE_HANDLE *)prov, cbdata);\n        }\n        OPENSSL_free(child_cb);\n        ret = 0;\n    }\n    CRYPTO_THREAD_unlock(store->lock);\n\n    return ret;\n}\n\nstatic void ossl_provider_deregister_child_cb(const OSSL_CORE_HANDLE *handle)\n{\n    /*\n     * This is really an OSSL_PROVIDER that we created and cast to\n     * OSSL_CORE_HANDLE originally. Therefore it is safe to cast it back.\n     */\n    OSSL_PROVIDER *thisprov = (OSSL_PROVIDER *)handle;\n    OSSL_LIB_CTX *libctx = thisprov->libctx;\n    struct provider_store_st *store = NULL;\n    int i, max;\n    OSSL_PROVIDER_CHILD_CB *child_cb;\n\n    if ((store = get_provider_store(libctx)) == NULL)\n        return;\n\n    if (!CRYPTO_THREAD_write_lock(store->lock))\n        return;\n    max = sk_OSSL_PROVIDER_CHILD_CB_num(store->child_cbs);\n    for (i = 0; i < max; i++) {\n        child_cb = sk_OSSL_PROVIDER_CHILD_CB_value(store->child_cbs, i);\n        if (child_cb->prov == thisprov) {\n            /* Found an entry */\n            sk_OSSL_PROVIDER_CHILD_CB_delete(store->child_cbs, i);\n            OPENSSL_free(child_cb);\n            break;\n        }\n    }\n    CRYPTO_THREAD_unlock(store->lock);\n}\n#endif\n\n/*-\n * Core functions for the provider\n * ===============================\n *\n * This is the set of functions that the core makes available to the provider\n */\n\n/*\n * This returns a list of Provider Object parameters with their types, for\n * discovery.  We do not expect that many providers will use this, but one\n * never knows.\n */\nstatic const OSSL_PARAM param_types[] = {\n    OSSL_PARAM_DEFN(OSSL_PROV_PARAM_CORE_VERSION, OSSL_PARAM_UTF8_PTR, NULL, 0),\n    OSSL_PARAM_DEFN(OSSL_PROV_PARAM_CORE_PROV_NAME, OSSL_PARAM_UTF8_PTR,\n                    NULL, 0),\n#ifndef FIPS_MODULE\n    OSSL_PARAM_DEFN(OSSL_PROV_PARAM_CORE_MODULE_FILENAME, OSSL_PARAM_UTF8_PTR,\n                    NULL, 0),\n#endif\n    OSSL_PARAM_END\n};\n\n/*\n * Forward declare all the functions that are provided aa dispatch.\n * This ensures that the compiler will complain if they aren't defined\n * with the correct signature.\n */\nstatic OSSL_FUNC_core_gettable_params_fn core_gettable_params;\nstatic OSSL_FUNC_core_get_params_fn core_get_params;\nstatic OSSL_FUNC_core_get_libctx_fn core_get_libctx;\nstatic OSSL_FUNC_core_thread_start_fn core_thread_start;\n#ifndef FIPS_MODULE\nstatic OSSL_FUNC_core_new_error_fn core_new_error;\nstatic OSSL_FUNC_core_set_error_debug_fn core_set_error_debug;\nstatic OSSL_FUNC_core_vset_error_fn core_vset_error;\nstatic OSSL_FUNC_core_set_error_mark_fn core_set_error_mark;\nstatic OSSL_FUNC_core_clear_last_error_mark_fn core_clear_last_error_mark;\nstatic OSSL_FUNC_core_pop_error_to_mark_fn core_pop_error_to_mark;\nOSSL_FUNC_BIO_new_file_fn ossl_core_bio_new_file;\nOSSL_FUNC_BIO_new_membuf_fn ossl_core_bio_new_mem_buf;\nOSSL_FUNC_BIO_read_ex_fn ossl_core_bio_read_ex;\nOSSL_FUNC_BIO_write_ex_fn ossl_core_bio_write_ex;\nOSSL_FUNC_BIO_gets_fn ossl_core_bio_gets;\nOSSL_FUNC_BIO_puts_fn ossl_core_bio_puts;\nOSSL_FUNC_BIO_up_ref_fn ossl_core_bio_up_ref;\nOSSL_FUNC_BIO_free_fn ossl_core_bio_free;\nOSSL_FUNC_BIO_vprintf_fn ossl_core_bio_vprintf;\nOSSL_FUNC_BIO_vsnprintf_fn BIO_vsnprintf;\nstatic OSSL_FUNC_self_test_cb_fn core_self_test_get_callback;\nstatic OSSL_FUNC_get_entropy_fn rand_get_entropy;\nstatic OSSL_FUNC_get_user_entropy_fn rand_get_user_entropy;\nstatic OSSL_FUNC_cleanup_entropy_fn rand_cleanup_entropy;\nstatic OSSL_FUNC_cleanup_user_entropy_fn rand_cleanup_user_entropy;\nstatic OSSL_FUNC_get_nonce_fn rand_get_nonce;\nstatic OSSL_FUNC_get_user_nonce_fn rand_get_user_nonce;\nstatic OSSL_FUNC_cleanup_nonce_fn rand_cleanup_nonce;\nstatic OSSL_FUNC_cleanup_user_nonce_fn rand_cleanup_user_nonce;\n#endif\nOSSL_FUNC_CRYPTO_malloc_fn CRYPTO_malloc;\nOSSL_FUNC_CRYPTO_zalloc_fn CRYPTO_zalloc;\nOSSL_FUNC_CRYPTO_free_fn CRYPTO_free;\nOSSL_FUNC_CRYPTO_clear_free_fn CRYPTO_clear_free;\nOSSL_FUNC_CRYPTO_realloc_fn CRYPTO_realloc;\nOSSL_FUNC_CRYPTO_clear_realloc_fn CRYPTO_clear_realloc;\nOSSL_FUNC_CRYPTO_secure_malloc_fn CRYPTO_secure_malloc;\nOSSL_FUNC_CRYPTO_secure_zalloc_fn CRYPTO_secure_zalloc;\nOSSL_FUNC_CRYPTO_secure_free_fn CRYPTO_secure_free;\nOSSL_FUNC_CRYPTO_secure_clear_free_fn CRYPTO_secure_clear_free;\nOSSL_FUNC_CRYPTO_secure_allocated_fn CRYPTO_secure_allocated;\nOSSL_FUNC_OPENSSL_cleanse_fn OPENSSL_cleanse;\n#ifndef FIPS_MODULE\nOSSL_FUNC_provider_register_child_cb_fn ossl_provider_register_child_cb;\nOSSL_FUNC_provider_deregister_child_cb_fn ossl_provider_deregister_child_cb;\nstatic OSSL_FUNC_provider_name_fn core_provider_get0_name;\nstatic OSSL_FUNC_provider_get0_provider_ctx_fn core_provider_get0_provider_ctx;\nstatic OSSL_FUNC_provider_get0_dispatch_fn core_provider_get0_dispatch;\nstatic OSSL_FUNC_provider_up_ref_fn core_provider_up_ref_intern;\nstatic OSSL_FUNC_provider_free_fn core_provider_free_intern;\nstatic OSSL_FUNC_core_obj_add_sigid_fn core_obj_add_sigid;\nstatic OSSL_FUNC_core_obj_create_fn core_obj_create;\n#endif\n\nstatic const OSSL_PARAM *core_gettable_params(const OSSL_CORE_HANDLE *handle)\n{\n    return param_types;\n}\n\nstatic int core_get_params(const OSSL_CORE_HANDLE *handle, OSSL_PARAM params[])\n{\n    int i;\n    OSSL_PARAM *p;\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    if ((p = OSSL_PARAM_locate(params, OSSL_PROV_PARAM_CORE_VERSION)) != NULL)\n        OSSL_PARAM_set_utf8_ptr(p, OPENSSL_VERSION_STR);\n    if ((p = OSSL_PARAM_locate(params, OSSL_PROV_PARAM_CORE_PROV_NAME)) != NULL)\n        OSSL_PARAM_set_utf8_ptr(p, prov->name);\n\n#ifndef FIPS_MODULE\n    if ((p = OSSL_PARAM_locate(params,\n                               OSSL_PROV_PARAM_CORE_MODULE_FILENAME)) != NULL)\n        OSSL_PARAM_set_utf8_ptr(p, ossl_provider_module_path(prov));\n#endif\n\n    if (prov->parameters == NULL)\n        return 1;\n\n    for (i = 0; i < sk_INFOPAIR_num(prov->parameters); i++) {\n        INFOPAIR *pair = sk_INFOPAIR_value(prov->parameters, i);\n\n        if ((p = OSSL_PARAM_locate(params, pair->name)) != NULL)\n            OSSL_PARAM_set_utf8_ptr(p, pair->value);\n    }\n    return 1;\n}\n\nstatic OPENSSL_CORE_CTX *core_get_libctx(const OSSL_CORE_HANDLE *handle)\n{\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    /*\n     * Using ossl_provider_libctx would be wrong as that returns\n     * NULL for |prov| == NULL and NULL libctx has a special meaning\n     * that does not apply here. Here |prov| == NULL can happen only in\n     * case of a coding error.\n     */\n    assert(prov != NULL);\n    return (OPENSSL_CORE_CTX *)prov->libctx;\n}\n\nstatic int core_thread_start(const OSSL_CORE_HANDLE *handle,\n                             OSSL_thread_stop_handler_fn handfn,\n                             void *arg)\n{\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    return ossl_init_thread_start(prov, arg, handfn);\n}\n\n/*\n * The FIPS module inner provider doesn't implement these.  They aren't\n * needed there, since the FIPS module upcalls are always the outer provider\n * ones.\n */\n#ifndef FIPS_MODULE\n/*\n * These error functions should use |handle| to select the proper\n * library context to report in the correct error stack if error\n * stacks become tied to the library context.\n * We cannot currently do that since there's no support for it in the\n * ERR subsystem.\n */\nstatic void core_new_error(const OSSL_CORE_HANDLE *handle)\n{\n    ERR_new();\n}\n\nstatic void core_set_error_debug(const OSSL_CORE_HANDLE *handle,\n                                 const char *file, int line, const char *func)\n{\n    ERR_set_debug(file, line, func);\n}\n\nstatic void core_vset_error(const OSSL_CORE_HANDLE *handle,\n                            uint32_t reason, const char *fmt, va_list args)\n{\n    /*\n     * We created this object originally and we know it is actually an\n     * OSSL_PROVIDER *, so the cast is safe\n     */\n    OSSL_PROVIDER *prov = (OSSL_PROVIDER *)handle;\n\n    /*\n     * If the uppermost 8 bits are non-zero, it's an OpenSSL library\n     * error and will be treated as such.  Otherwise, it's a new style\n     * provider error and will be treated as such.\n     */\n    if (ERR_GET_LIB(reason) != 0) {\n        ERR_vset_error(ERR_GET_LIB(reason), ERR_GET_REASON(reason), fmt, args);\n    } else {\n        ERR_vset_error(prov->error_lib, (int)reason, fmt, args);\n    }\n}\n\nstatic int core_set_error_mark(const OSSL_CORE_HANDLE *handle)\n{\n    return ERR_set_mark();\n}\n\nstatic int core_clear_last_error_mark(const OSSL_CORE_HANDLE *handle)\n{\n    return ERR_clear_last_mark();\n}\n\nstatic int core_pop_error_to_mark(const OSSL_CORE_HANDLE *handle)\n{\n    return ERR_pop_to_mark();\n}\n\nstatic void core_self_test_get_callback(OPENSSL_CORE_CTX *libctx,\n                                        OSSL_CALLBACK **cb, void **cbarg)\n{\n    OSSL_SELF_TEST_get_callback((OSSL_LIB_CTX *)libctx, cb, cbarg);\n}\n\nstatic size_t rand_get_entropy(const OSSL_CORE_HANDLE *handle,\n                               unsigned char **pout, int entropy,\n                               size_t min_len, size_t max_len)\n{\n    return ossl_rand_get_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                 pout, entropy, min_len, max_len);\n}\n\nstatic size_t rand_get_user_entropy(const OSSL_CORE_HANDLE *handle,\n                                    unsigned char **pout, int entropy,\n                                    size_t min_len, size_t max_len)\n{\n    return ossl_rand_get_user_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                      pout, entropy, min_len, max_len);\n}\n\nstatic void rand_cleanup_entropy(const OSSL_CORE_HANDLE *handle,\n                                 unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                              buf, len);\n}\n\nstatic void rand_cleanup_user_entropy(const OSSL_CORE_HANDLE *handle,\n                                      unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_user_entropy((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                   buf, len);\n}\n\nstatic size_t rand_get_nonce(const OSSL_CORE_HANDLE *handle,\n                             unsigned char **pout,\n                             size_t min_len, size_t max_len,\n                             const void *salt, size_t salt_len)\n{\n    return ossl_rand_get_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                               pout, min_len, max_len, salt, salt_len);\n}\n\nstatic size_t rand_get_user_nonce(const OSSL_CORE_HANDLE *handle,\n                                  unsigned char **pout,\n                                  size_t min_len, size_t max_len,\n                                  const void *salt, size_t salt_len)\n{\n    return ossl_rand_get_user_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                    pout, min_len, max_len, salt, salt_len);\n}\n\nstatic void rand_cleanup_nonce(const OSSL_CORE_HANDLE *handle,\n                               unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                            buf, len);\n}\n\nstatic void rand_cleanup_user_nonce(const OSSL_CORE_HANDLE *handle,\n                               unsigned char *buf, size_t len)\n{\n    ossl_rand_cleanup_user_nonce((OSSL_LIB_CTX *)core_get_libctx(handle),\n                                 buf, len);\n}\n\nstatic const char *core_provider_get0_name(const OSSL_CORE_HANDLE *prov)\n{\n    return OSSL_PROVIDER_get0_name((const OSSL_PROVIDER *)prov);\n}\n\nstatic void *core_provider_get0_provider_ctx(const OSSL_CORE_HANDLE *prov)\n{\n    return OSSL_PROVIDER_get0_provider_ctx((const OSSL_PROVIDER *)prov);\n}\n\nstatic const OSSL_DISPATCH *\ncore_provider_get0_dispatch(const OSSL_CORE_HANDLE *prov)\n{\n    return OSSL_PROVIDER_get0_dispatch((const OSSL_PROVIDER *)prov);\n}\n\nstatic int core_provider_up_ref_intern(const OSSL_CORE_HANDLE *prov,\n                                       int activate)\n{\n    return provider_up_ref_intern((OSSL_PROVIDER *)prov, activate);\n}\n\nstatic int core_provider_free_intern(const OSSL_CORE_HANDLE *prov,\n                                     int deactivate)\n{\n    return provider_free_intern((OSSL_PROVIDER *)prov, deactivate);\n}\n\nstatic int core_obj_add_sigid(const OSSL_CORE_HANDLE *prov,\n                              const char *sign_name, const char *digest_name,\n                              const char *pkey_name)\n{\n    int sign_nid = OBJ_txt2nid(sign_name);\n    int digest_nid = NID_undef;\n    int pkey_nid = OBJ_txt2nid(pkey_name);\n\n    if (digest_name != NULL && digest_name[0] != '\\0'\n        && (digest_nid = OBJ_txt2nid(digest_name)) == NID_undef)\n            return 0;\n\n    if (sign_nid == NID_undef)\n        return 0;\n\n    /*\n     * Check if it already exists. This is a success if so (even if we don't\n     * have nids for the digest/pkey)\n     */\n    if (OBJ_find_sigid_algs(sign_nid, NULL, NULL))\n        return 1;\n\n    if (pkey_nid == NID_undef)\n        return 0;\n\n    return OBJ_add_sigid(sign_nid, digest_nid, pkey_nid);\n}\n\nstatic int core_obj_create(const OSSL_CORE_HANDLE *prov, const char *oid,\n                           const char *sn, const char *ln)\n{\n    /* Check if it already exists and create it if not */\n    return OBJ_txt2nid(oid) != NID_undef\n           || OBJ_create(oid, sn, ln) != NID_undef;\n}\n#endif /* FIPS_MODULE */\n\n/*\n * Functions provided by the core.\n */\nstatic const OSSL_DISPATCH core_dispatch_[] = {\n    { OSSL_FUNC_CORE_GETTABLE_PARAMS, (void (*)(void))core_gettable_params },\n    { OSSL_FUNC_CORE_GET_PARAMS, (void (*)(void))core_get_params },\n    { OSSL_FUNC_CORE_GET_LIBCTX, (void (*)(void))core_get_libctx },\n    { OSSL_FUNC_CORE_THREAD_START, (void (*)(void))core_thread_start },\n#ifndef FIPS_MODULE\n    { OSSL_FUNC_CORE_NEW_ERROR, (void (*)(void))core_new_error },\n    { OSSL_FUNC_CORE_SET_ERROR_DEBUG, (void (*)(void))core_set_error_debug },\n    { OSSL_FUNC_CORE_VSET_ERROR, (void (*)(void))core_vset_error },\n    { OSSL_FUNC_CORE_SET_ERROR_MARK, (void (*)(void))core_set_error_mark },\n    { OSSL_FUNC_CORE_CLEAR_LAST_ERROR_MARK,\n      (void (*)(void))core_clear_last_error_mark },\n    { OSSL_FUNC_CORE_POP_ERROR_TO_MARK, (void (*)(void))core_pop_error_to_mark },\n    { OSSL_FUNC_BIO_NEW_FILE, (void (*)(void))ossl_core_bio_new_file },\n    { OSSL_FUNC_BIO_NEW_MEMBUF, (void (*)(void))ossl_core_bio_new_mem_buf },\n    { OSSL_FUNC_BIO_READ_EX, (void (*)(void))ossl_core_bio_read_ex },\n    { OSSL_FUNC_BIO_WRITE_EX, (void (*)(void))ossl_core_bio_write_ex },\n    { OSSL_FUNC_BIO_GETS, (void (*)(void))ossl_core_bio_gets },\n    { OSSL_FUNC_BIO_PUTS, (void (*)(void))ossl_core_bio_puts },\n    { OSSL_FUNC_BIO_CTRL, (void (*)(void))ossl_core_bio_ctrl },\n    { OSSL_FUNC_BIO_UP_REF, (void (*)(void))ossl_core_bio_up_ref },\n    { OSSL_FUNC_BIO_FREE, (void (*)(void))ossl_core_bio_free },\n    { OSSL_FUNC_BIO_VPRINTF, (void (*)(void))ossl_core_bio_vprintf },\n    { OSSL_FUNC_BIO_VSNPRINTF, (void (*)(void))BIO_vsnprintf },\n    { OSSL_FUNC_SELF_TEST_CB, (void (*)(void))core_self_test_get_callback },\n    { OSSL_FUNC_GET_ENTROPY, (void (*)(void))rand_get_entropy },\n    { OSSL_FUNC_GET_USER_ENTROPY, (void (*)(void))rand_get_user_entropy },\n    { OSSL_FUNC_CLEANUP_ENTROPY, (void (*)(void))rand_cleanup_entropy },\n    { OSSL_FUNC_CLEANUP_USER_ENTROPY, (void (*)(void))rand_cleanup_user_entropy },\n    { OSSL_FUNC_GET_NONCE, (void (*)(void))rand_get_nonce },\n    { OSSL_FUNC_GET_USER_NONCE, (void (*)(void))rand_get_user_nonce },\n    { OSSL_FUNC_CLEANUP_NONCE, (void (*)(void))rand_cleanup_nonce },\n    { OSSL_FUNC_CLEANUP_USER_NONCE, (void (*)(void))rand_cleanup_user_nonce },\n#endif\n    { OSSL_FUNC_CRYPTO_MALLOC, (void (*)(void))CRYPTO_malloc },\n    { OSSL_FUNC_CRYPTO_ZALLOC, (void (*)(void))CRYPTO_zalloc },\n    { OSSL_FUNC_CRYPTO_FREE, (void (*)(void))CRYPTO_free },\n    { OSSL_FUNC_CRYPTO_CLEAR_FREE, (void (*)(void))CRYPTO_clear_free },\n    { OSSL_FUNC_CRYPTO_REALLOC, (void (*)(void))CRYPTO_realloc },\n    { OSSL_FUNC_CRYPTO_CLEAR_REALLOC, (void (*)(void))CRYPTO_clear_realloc },\n    { OSSL_FUNC_CRYPTO_SECURE_MALLOC, (void (*)(void))CRYPTO_secure_malloc },\n    { OSSL_FUNC_CRYPTO_SECURE_ZALLOC, (void (*)(void))CRYPTO_secure_zalloc },\n    { OSSL_FUNC_CRYPTO_SECURE_FREE, (void (*)(void))CRYPTO_secure_free },\n    { OSSL_FUNC_CRYPTO_SECURE_CLEAR_FREE,\n        (void (*)(void))CRYPTO_secure_clear_free },\n    { OSSL_FUNC_CRYPTO_SECURE_ALLOCATED,\n        (void (*)(void))CRYPTO_secure_allocated },\n    { OSSL_FUNC_OPENSSL_CLEANSE, (void (*)(void))OPENSSL_cleanse },\n#ifndef FIPS_MODULE\n    { OSSL_FUNC_PROVIDER_REGISTER_CHILD_CB,\n        (void (*)(void))ossl_provider_register_child_cb },\n    { OSSL_FUNC_PROVIDER_DEREGISTER_CHILD_CB,\n        (void (*)(void))ossl_provider_deregister_child_cb },\n    { OSSL_FUNC_PROVIDER_NAME,\n        (void (*)(void))core_provider_get0_name },\n    { OSSL_FUNC_PROVIDER_GET0_PROVIDER_CTX,\n        (void (*)(void))core_provider_get0_provider_ctx },\n    { OSSL_FUNC_PROVIDER_GET0_DISPATCH,\n        (void (*)(void))core_provider_get0_dispatch },\n    { OSSL_FUNC_PROVIDER_UP_REF,\n        (void (*)(void))core_provider_up_ref_intern },\n    { OSSL_FUNC_PROVIDER_FREE,\n        (void (*)(void))core_provider_free_intern },\n    { OSSL_FUNC_CORE_OBJ_ADD_SIGID, (void (*)(void))core_obj_add_sigid },\n    { OSSL_FUNC_CORE_OBJ_CREATE, (void (*)(void))core_obj_create },\n#endif\n    OSSL_DISPATCH_END\n};\nstatic const OSSL_DISPATCH *core_dispatch = core_dispatch_;\n"}, {"id": "AC89B15B00B8F168", "name": "gbl", "path": "openssl/crypto/provider_child.c", "start": {"line": 288, "col": 32}, "end": {"line": 288, "col": 32}, "code": "    const OSSL_CORE_HANDLE *parent_handle;\n\n    gbl = ossl_lib_ctx_get_data(ossl_provider_libctx(prov),\n                                OSSL_LIB_CTX_CHILD_PROVIDER_INDEX);\n    if (gbl == NULL)\n        return 0;\n\n    parent_handle = ossl_provider_get_parent(prov);\n    if (parent_handle == gbl->handle)\n        return 1;\n    return gbl->c_prov_up_ref(parent_handle, activate);\n}\n\nint ossl_provider_free_parent(OSSL_PROVIDER *prov, int deactivate)\n{\n    struct child_prov_globals *gbl;\n    const OSSL_CORE_HANDLE *parent_handle;\n\n    gbl = ossl_lib_ctx_get_data(ossl_provider_libctx(prov),\n                                OSSL_LIB_CTX_CHILD_PROVIDER_INDEX);\n    if (gbl == NULL)\n        return 0;\n\n    parent_handle = ossl_provider_get_parent(prov);\n    if (parent_handle == gbl->handle)\n        return 1;\n    return gbl->c_prov_free(ossl_provider_get_parent(prov), deactivate);\n}\n"}, {"id": "4AA8CD6B8023A825", "name": "child_prov_globals::c_prov_up_ref", "path": "openssl/crypto/provider_child.c", "start": {"line": 33, "col": 35}, "end": {"line": 33, "col": 35}, "code": "    OSSL_FUNC_provider_free_fn *c_prov_free;\n};\n\nvoid *ossl_child_prov_ctx_new(OSSL_LIB_CTX *libctx)\n{\n    return OPENSSL_zalloc(sizeof(struct child_prov_globals));\n}\n\nvoid ossl_child_prov_ctx_free(void *vgbl)\n{\n    struct child_prov_globals *gbl = vgbl;\n\n    CRYPTO_THREAD_lock_free(gbl->lock);\n    OPENSSL_free(gbl);\n}\n\nstatic OSSL_provider_init_fn ossl_child_provider_init;\n\nstatic int ossl_child_provider_init(const OSSL_CORE_HANDLE *handle,\n                                    const OSSL_DISPATCH *in,\n                                    const OSSL_DISPATCH **out,\n                                    void **provctx)\n{\n    OSSL_FUNC_core_get_libctx_fn *c_get_libctx = NULL;\n    OSSL_LIB_CTX *ctx;\n    struct child_prov_globals *gbl;\n\n    for (; in->function_id != 0; in++) {\n        switch (in->function_id) {\n        case OSSL_FUNC_CORE_GET_LIBCTX:\n            c_get_libctx = OSSL_FUNC_core_get_libctx(in);\n            break;\n        default:\n            /* Just ignore anything we don't understand */\n"}], "code": "int ossl_provider_up_ref_parent(OSSL_PROVIDER *prov, int activate)\n{\n    struct child_prov_globals *gbl;\n    const OSSL_CORE_HANDLE *parent_handle;\n\n    gbl = ossl_lib_ctx_get_data(ossl_provider_libctx(prov),\n                                OSSL_LIB_CTX_CHILD_PROVIDER_INDEX);\n    if (gbl == NULL)\n        return 0;\n\n    parent_handle = ossl_provider_get_parent(prov);\n    if (parent_handle == gbl->handle)\n        return 1;\n    return gbl->c_prov_up_ref(parent_handle, activate);\n}\n"}, "77A8F931A0C1CD5C": {"calls": [{"id": "58582DC77D7797DC", "name": "ossl_property_free", "path": "openssl/crypto/property/property_parse.c", "start": {"line": 528, "col": 1}, "end": {"line": 531, "col": 1}, "code": "{\n    OPENSSL_free(p);\n}\n\n/*\n * Merge two property lists.\n * If there is a common name, the one from the first list is used.\n */\nOSSL_PROPERTY_LIST *ossl_property_merge(const OSSL_PROPERTY_LIST *a,\n                                        const OSSL_PROPERTY_LIST *b)\n{\n    const OSSL_PROPERTY_DEFINITION *const ap = a->properties;\n    const OSSL_PROPERTY_DEFINITION *const bp = b->properties;\n    const OSSL_PROPERTY_DEFINITION *copy;\n    OSSL_PROPERTY_LIST *r;\n    int i, j, n;\n    const int t = a->num_properties + b->num_properties;\n\n    r = OPENSSL_malloc(sizeof(*r)\n                       + (t == 0 ? 0 : t - 1) * sizeof(r->properties[0]));\n    if (r == NULL)\n        return NULL;\n\n    r->has_optional = 0;\n    for (i = j = n = 0; i < a->num_properties || j < b->num_properties; n++) {\n        if (i >= a->num_properties) {\n            copy = &bp[j++];\n        } else if (j >= b->num_properties) {\n            copy = &ap[i++];\n        } else if (ap[i].name_idx <= bp[j].name_idx) {\n            if (ap[i].name_idx == bp[j].name_idx)\n                j++;\n            copy = &ap[i++];\n        } else {\n            copy = &bp[j++];\n        }\n        memcpy(r->properties + n, copy, sizeof(r->properties[0]));\n        r->has_optional |= copy->optional;\n    }\n    r->num_properties = n;\n    if (n != t)\n        r = OPENSSL_realloc(r, sizeof(*r) + (n - 1) * sizeof(r->properties[0]));\n    return r;\n}\n\nint ossl_property_parse_init(OSSL_LIB_CTX *ctx)\n{\n    static const char *const predefined_names[] = {\n        \"provider\",     /* Name of provider (default, legacy, fips) */\n        \"version\",      /* Version number of this provider */\n        \"fips\",         /* FIPS validated or FIPS supporting algorithm */\n        \"output\",       /* Output type for encoders */\n        \"input\",        /* Input type for decoders */\n        \"structure\",    /* Structure name for encoders and decoders */\n    };\n    size_t i;\n\n    for (i = 0; i < OSSL_NELEM(predefined_names); i++)\n        if (ossl_property_name(ctx, predefined_names[i], 1) == 0)\n            goto err;\n\n    /*\n     * Pre-populate the two Boolean values. We must do them before any other\n     * values and in this order so that we get the same index as the global\n     * OSSL_PROPERTY_TRUE and OSSL_PROPERTY_FALSE values\n     */\n    if ((ossl_property_value(ctx, \"yes\", 1) != OSSL_PROPERTY_TRUE)\n        || (ossl_property_value(ctx, \"no\", 1) != OSSL_PROPERTY_FALSE))\n        goto err;\n\n    return 1;\nerr:\n    return 0;\n}\n\nstatic void put_char(char ch, char **buf, size_t *remain, size_t *needed)\n{\n    if (*remain == 0) {\n        ++*needed;\n        return;\n    }\n    if (*remain == 1)\n        **buf = '\\0';\n    else\n        **buf = ch;\n    ++*buf;\n    ++*needed;\n    --*remain;\n}\n\nstatic void put_str(const char *str, char **buf, size_t *remain, size_t *needed)\n{\n    size_t olen, len, i;\n    char quote = '\\0';\n    int quotes;\n\n    len = olen = strlen(str);\n    *needed += len;\n\n    /*\n     * Check to see if we need quotes or not.\n     * Characters that are legal in a PropertyName don't need quoting.\n     * We simply assume all others require quotes.\n     */\n    for (i = 0; i < len; i++)\n        if (!ossl_isalnum(str[i]) && str[i] != '.' && str[i] != '_') {\n            /* Default to single quotes ... */\n            if (quote == '\\0')\n                quote = '\\'';\n            /* ... but use double quotes if a single is present */\n            if (str[i] == '\\'')\n                quote = '\"';\n        }\n\n    quotes = quote != '\\0';\n    if (*remain == 0) {\n        *needed += 2 * quotes;\n        return;\n    }\n\n    if (quotes)\n        put_char(quote, buf, remain, needed);\n\n    if (*remain < len + 1 + quotes)\n        len = *remain - 1;\n\n    if (len > 0) {\n        memcpy(*buf, str, len);\n        *buf += len;\n        *remain -= len;\n    }\n\n    if (quotes)\n        put_char(quote, buf, remain, needed);\n\n    if (len < olen && *remain == 1) {\n        **buf = '\\0';\n        ++*buf;\n        --*remain;\n    }\n}\n\nstatic void put_num(int64_t val, char **buf, size_t *remain, size_t *needed)\n{\n    int64_t tmpval = val;\n    size_t len = 1;\n\n    if (tmpval < 0) {\n        len++;\n        tmpval = -tmpval;\n    }\n    for (; tmpval > 9; len++, tmpval /= 10);\n\n    *needed += len;\n\n    if (*remain == 0)\n        return;\n\n    BIO_snprintf(*buf, *remain, \"%lld\", (long long int)val);\n    if (*remain < len) {\n        *buf += *remain;\n        *remain = 0;\n    } else {\n        *buf += len;\n        *remain -= len;\n    }\n}\n\nsize_t ossl_property_list_to_string(OSSL_LIB_CTX *ctx,\n                                    const OSSL_PROPERTY_LIST *list, char *buf,\n                                    size_t bufsize)\n{\n    int i;\n    const OSSL_PROPERTY_DEFINITION *prop = NULL;\n    size_t needed = 0;\n    const char *val;\n\n    if (list == NULL) {\n        if (bufsize > 0)\n            *buf = '\\0';\n        return 1;\n    }\n    if (list->num_properties != 0)\n        prop = &list->properties[list->num_properties - 1];\n    for (i = 0; i < list->num_properties; i++, prop--) {\n        /* Skip invalid names */\n        if (prop->name_idx == 0)\n            continue;\n\n        if (needed > 0)\n            put_char(',', &buf, &bufsize, &needed);\n\n        if (prop->optional)\n            put_char('?', &buf, &bufsize, &needed);\n        else if (prop->oper == OSSL_PROPERTY_OVERRIDE)\n            put_char('-', &buf, &bufsize, &needed);\n\n        val = ossl_property_name_str(ctx, prop->name_idx);\n        if (val == NULL)\n            return 0;\n        put_str(val, &buf, &bufsize, &needed);\n\n        switch (prop->oper) {\n            case OSSL_PROPERTY_OPER_NE:\n                put_char('!', &buf, &bufsize, &needed);\n                /* fall through */\n            case OSSL_PROPERTY_OPER_EQ:\n                put_char('=', &buf, &bufsize, &needed);\n                /* put value */\n                switch (prop->type) {\n                case OSSL_PROPERTY_TYPE_STRING:\n                    val = ossl_property_value_str(ctx, prop->v.str_val);\n                    if (val == NULL)\n                        return 0;\n                    put_str(val, &buf, &bufsize, &needed);\n                    break;\n\n                case OSSL_PROPERTY_TYPE_NUMBER:\n                    put_num(prop->v.int_val, &buf, &bufsize, &needed);\n                    break;\n\n                default:\n                    return 0;\n                }\n                break;\n            default:\n                /* do nothing */\n                break;\n        }\n    }\n\n    put_char('\\0', &buf, &bufsize, &needed);\n    return needed;\n}\n"}], "code": "void ossl_ctx_global_properties_free(void *vglobp)\n{\n    OSSL_GLOBAL_PROPERTIES *globp = vglobp;\n\n    if (globp != NULL) {\n        ossl_property_free(globp->list);\n        OPENSSL_free(globp);\n    }\n}\n"}, "3428FE5AC8D7F9FA": {"calls": [{"id": "3B0388CAD25113F9", "name": "keymgmt", "path": "openssl/crypto/evp/keymgmt_lib.c", "start": {"line": 573, "col": 64}, "end": {"line": 573, "col": 64}, "code": "                                                  int op_id)\n{\n    const char *name = NULL;\n\n    if (keymgmt != NULL) {\n        if (keymgmt->query_operation_name != NULL)\n            name = keymgmt->query_operation_name(op_id);\n        if (name == NULL)\n            name = EVP_KEYMGMT_get0_name(keymgmt);\n    }\n    return name;\n}\n"}, {"id": "9BD88CA5E4FF9BE4", "name": "evp_keymgmt_st::query_operation_name", "path": "openssl/crypto/evp/evp_local.h", "start": {"line": 124, "col": 48}, "end": {"line": 124, "col": 48}, "code": "    OSSL_FUNC_keymgmt_has_fn *has;\n    OSSL_FUNC_keymgmt_validate_fn *validate;\n    OSSL_FUNC_keymgmt_match_fn *match;\n\n    /* Import and export routines */\n    OSSL_FUNC_keymgmt_import_fn *import;\n    OSSL_FUNC_keymgmt_import_types_fn *import_types;\n    OSSL_FUNC_keymgmt_import_types_ex_fn *import_types_ex;\n    OSSL_FUNC_keymgmt_export_fn *export;\n    OSSL_FUNC_keymgmt_export_types_fn *export_types;\n    OSSL_FUNC_keymgmt_export_types_ex_fn *export_types_ex;\n    OSSL_FUNC_keymgmt_dup_fn *dup;\n} /* EVP_KEYMGMT */ ;\n\nstruct evp_keyexch_st {\n    int name_id;\n    char *type_name;\n    const char *description;\n    OSSL_PROVIDER *prov;\n    CRYPTO_REF_COUNT refcnt;\n\n    OSSL_FUNC_keyexch_newctx_fn *newctx;\n    OSSL_FUNC_keyexch_init_fn *init;\n    OSSL_FUNC_keyexch_set_peer_fn *set_peer;\n    OSSL_FUNC_keyexch_derive_fn *derive;\n    OSSL_FUNC_keyexch_freectx_fn *freectx;\n    OSSL_FUNC_keyexch_dupctx_fn *dupctx;\n    OSSL_FUNC_keyexch_set_ctx_params_fn *set_ctx_params;\n    OSSL_FUNC_keyexch_settable_ctx_params_fn *settable_ctx_params;\n    OSSL_FUNC_keyexch_get_ctx_params_fn *get_ctx_params;\n    OSSL_FUNC_keyexch_gettable_ctx_params_fn *gettable_ctx_params;\n} /* EVP_KEYEXCH */;\n\nstruct evp_signature_st {\n    int name_id;\n    char *type_name;\n    const char *description;\n    OSSL_PROVIDER *prov;\n    CRYPTO_REF_COUNT refcnt;\n\n    OSSL_FUNC_signature_newctx_fn *newctx;\n    OSSL_FUNC_signature_sign_init_fn *sign_init;\n    OSSL_FUNC_signature_sign_fn *sign;\n    OSSL_FUNC_signature_verify_init_fn *verify_init;\n    OSSL_FUNC_signature_verify_fn *verify;\n    OSSL_FUNC_signature_verify_recover_init_fn *verify_recover_init;\n    OSSL_FUNC_signature_verify_recover_fn *verify_recover;\n    OSSL_FUNC_signature_digest_sign_init_fn *digest_sign_init;\n    OSSL_FUNC_signature_digest_sign_update_fn *digest_sign_update;\n    OSSL_FUNC_signature_digest_sign_final_fn *digest_sign_final;\n    OSSL_FUNC_signature_digest_sign_fn *digest_sign;\n    OSSL_FUNC_signature_digest_verify_init_fn *digest_verify_init;\n    OSSL_FUNC_signature_digest_verify_update_fn *digest_verify_update;\n    OSSL_FUNC_signature_digest_verify_final_fn *digest_verify_final;\n    OSSL_FUNC_signature_digest_verify_fn *digest_verify;\n    OSSL_FUNC_signature_freectx_fn *freectx;\n    OSSL_FUNC_signature_dupctx_fn *dupctx;\n    OSSL_FUNC_signature_get_ctx_params_fn *get_ctx_params;\n    OSSL_FUNC_signature_gettable_ctx_params_fn *gettable_ctx_params;\n    OSSL_FUNC_signature_set_ctx_params_fn *set_ctx_params;\n    OSSL_FUNC_signature_settable_ctx_params_fn *settable_ctx_params;\n    OSSL_FUNC_signature_get_ctx_md_params_fn *get_ctx_md_params;\n    OSSL_FUNC_signature_gettable_ctx_md_params_fn *gettable_ctx_md_params;\n    OSSL_FUNC_signature_set_ctx_md_params_fn *set_ctx_md_params;\n    OSSL_FUNC_signature_settable_ctx_md_params_fn *settable_ctx_md_params;\n} /* EVP_SIGNATURE */;\n\nstruct evp_asym_cipher_st {\n    int name_id;\n    char *type_name;\n    const char *description;\n    OSSL_PROVIDER *prov;\n    CRYPTO_REF_COUNT refcnt;\n\n    OSSL_FUNC_asym_cipher_newctx_fn *newctx;\n    OSSL_FUNC_asym_cipher_encrypt_init_fn *encrypt_init;\n    OSSL_FUNC_asym_cipher_encrypt_fn *encrypt;\n    OSSL_FUNC_asym_cipher_decrypt_init_fn *decrypt_init;\n    OSSL_FUNC_asym_cipher_decrypt_fn *decrypt;\n    OSSL_FUNC_asym_cipher_freectx_fn *freectx;\n    OSSL_FUNC_asym_cipher_dupctx_fn *dupctx;\n    OSSL_FUNC_asym_cipher_get_ctx_params_fn *get_ctx_params;\n    OSSL_FUNC_asym_cipher_gettable_ctx_params_fn *gettable_ctx_params;\n    OSSL_FUNC_asym_cipher_set_ctx_params_fn *set_ctx_params;\n    OSSL_FUNC_asym_cipher_settable_ctx_params_fn *settable_ctx_params;\n} /* EVP_ASYM_CIPHER */;\n\nstruct evp_kem_st {\n    int name_id;\n    char *type_name;\n    const char *description;\n    OSSL_PROVIDER *prov;\n    CRYPTO_REF_COUNT refcnt;\n\n    OSSL_FUNC_kem_newctx_fn *newctx;\n    OSSL_FUNC_kem_encapsulate_init_fn *encapsulate_init;\n    OSSL_FUNC_kem_encapsulate_fn *encapsulate;\n    OSSL_FUNC_kem_decapsulate_init_fn *decapsulate_init;\n    OSSL_FUNC_kem_decapsulate_fn *decapsulate;\n    OSSL_FUNC_kem_freectx_fn *freectx;\n    OSSL_FUNC_kem_dupctx_fn *dupctx;\n    OSSL_FUNC_kem_get_ctx_params_fn *get_ctx_params;\n    OSSL_FUNC_kem_gettable_ctx_params_fn *gettable_ctx_params;\n    OSSL_FUNC_kem_set_ctx_params_fn *set_ctx_params;\n    OSSL_FUNC_kem_settable_ctx_params_fn *settable_ctx_params;\n    OSSL_FUNC_kem_auth_encapsulate_init_fn *auth_encapsulate_init;\n    OSSL_FUNC_kem_auth_decapsulate_init_fn *auth_decapsulate_init;\n} /* EVP_KEM */;\n\nint PKCS5_v2_PBKDF2_keyivgen(EVP_CIPHER_CTX *ctx, const char *pass,\n                             int passlen, ASN1_TYPE *param,\n                             const EVP_CIPHER *c, const EVP_MD *md,\n                             int en_de);\nint PKCS5_v2_PBKDF2_keyivgen_ex(EVP_CIPHER_CTX *ctx, const char *pass,\n                                int passlen, ASN1_TYPE *param,\n                                const EVP_CIPHER *c, const EVP_MD *md,\n                                int en_de, OSSL_LIB_CTX *libctx, const char *propq);\n\nstruct evp_Encode_Ctx_st {\n    /* number saved in a partial encode/decode */\n    int num;\n    /*\n     * The length is either the output line length (in input bytes) or the\n     * shortest input line length that is ok.  Once decoding begins, the\n     * length is adjusted up each time a longer line is decoded\n"}, {"id": "33A0701F36D84616", "name": "EVP_KEYMGMT_get0_name", "path": "openssl/crypto/evp/keymgmt_meth.c", "start": {"line": 312, "col": 1}, "end": {"line": 315, "col": 1}, "code": "{\n    return keymgmt->type_name;\n}\n\nint EVP_KEYMGMT_is_a(const EVP_KEYMGMT *keymgmt, const char *name)\n{\n    return keymgmt != NULL\n           && evp_is_a(keymgmt->prov, keymgmt->name_id, NULL, name);\n}\n\nvoid EVP_KEYMGMT_do_all_provided(OSSL_LIB_CTX *libctx,\n                                 void (*fn)(EVP_KEYMGMT *keymgmt, void *arg),\n                                 void *arg)\n{\n    evp_generic_do_all(libctx, OSSL_OP_KEYMGMT,\n                       (void (*)(void *, void *))fn, arg,\n                       keymgmt_from_algorithm,\n                       (int (*)(void *))EVP_KEYMGMT_up_ref,\n                       (void (*)(void *))EVP_KEYMGMT_free);\n}\n\nint EVP_KEYMGMT_names_do_all(const EVP_KEYMGMT *keymgmt,\n                             void (*fn)(const char *name, void *data),\n                             void *data)\n{\n    if (keymgmt->prov != NULL)\n        return evp_names_do_all(keymgmt->prov, keymgmt->name_id, fn, data);\n\n    return 1;\n}\n\n/*\n * Internal API that interfaces with the method function pointers\n */\nvoid *evp_keymgmt_newdata(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    /*\n     * 'new' is currently mandatory on its own, but when new\n     * constructors appear, it won't be quite as mandatory,\n     * so we have a check for future cases.\n     */\n    if (keymgmt->new == NULL)\n        return NULL;\n    return keymgmt->new(provctx);\n}\n\nvoid evp_keymgmt_freedata(const EVP_KEYMGMT *keymgmt, void *keydata)\n{\n    /* This is mandatory, no need to check for its presence */\n    keymgmt->free(keydata);\n}\n\nvoid *evp_keymgmt_gen_init(const EVP_KEYMGMT *keymgmt, int selection,\n                           const OSSL_PARAM params[])\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gen_init == NULL)\n        return NULL;\n    return keymgmt->gen_init(provctx, selection, params);\n}\n\nint evp_keymgmt_gen_set_template(const EVP_KEYMGMT *keymgmt, void *genctx,\n                                 void *templ)\n{\n    /*\n     * It's arguable if we actually should return success in this case, as\n     * it allows the caller to set a template key, which is then ignored.\n     * However, this is how the legacy methods (EVP_PKEY_METHOD) operate,\n     * so we do this in the interest of backward compatibility.\n     */\n    if (keymgmt->gen_set_template == NULL)\n        return 1;\n    return keymgmt->gen_set_template(genctx, templ);\n}\n\nint evp_keymgmt_gen_set_params(const EVP_KEYMGMT *keymgmt, void *genctx,\n                               const OSSL_PARAM params[])\n{\n    if (keymgmt->gen_set_params == NULL)\n        return 0;\n    return keymgmt->gen_set_params(genctx, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_gen_settable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gen_settable_params == NULL)\n        return NULL;\n    return keymgmt->gen_settable_params(NULL, provctx);\n}\n\nvoid *evp_keymgmt_gen(const EVP_KEYMGMT *keymgmt, void *genctx,\n                      OSSL_CALLBACK *cb, void *cbarg)\n{\n    if (keymgmt->gen == NULL)\n        return NULL;\n    return keymgmt->gen(genctx, cb, cbarg);\n}\n\nvoid evp_keymgmt_gen_cleanup(const EVP_KEYMGMT *keymgmt, void *genctx)\n{\n    if (keymgmt->gen_cleanup != NULL)\n        keymgmt->gen_cleanup(genctx);\n}\n\nint evp_keymgmt_has_load(const EVP_KEYMGMT *keymgmt)\n{\n    return keymgmt != NULL && keymgmt->load != NULL;\n}\n\nvoid *evp_keymgmt_load(const EVP_KEYMGMT *keymgmt,\n                       const void *objref, size_t objref_sz)\n{\n    if (evp_keymgmt_has_load(keymgmt))\n        return keymgmt->load(objref, objref_sz);\n    return NULL;\n}\n\nint evp_keymgmt_get_params(const EVP_KEYMGMT *keymgmt, void *keydata,\n                           OSSL_PARAM params[])\n{\n    if (keymgmt->get_params == NULL)\n        return 1;\n    return keymgmt->get_params(keydata, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_gettable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gettable_params == NULL)\n        return NULL;\n    return keymgmt->gettable_params(provctx);\n}\n\nint evp_keymgmt_set_params(const EVP_KEYMGMT *keymgmt, void *keydata,\n                           const OSSL_PARAM params[])\n{\n    if (keymgmt->set_params == NULL)\n        return 1;\n    return keymgmt->set_params(keydata, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_settable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->settable_params == NULL)\n        return NULL;\n    return keymgmt->settable_params(provctx);\n}\n\nint evp_keymgmt_has(const EVP_KEYMGMT *keymgmt, void *keydata, int selection)\n{\n    /* This is mandatory, no need to check for its presence */\n    return keymgmt->has(keydata, selection);\n}\n\nint evp_keymgmt_validate(const EVP_KEYMGMT *keymgmt, void *keydata,\n                         int selection, int checktype)\n{\n    /* We assume valid if the implementation doesn't have a function */\n    if (keymgmt->validate == NULL)\n        return 1;\n    return keymgmt->validate(keydata, selection, checktype);\n}\n\nint evp_keymgmt_match(const EVP_KEYMGMT *keymgmt,\n                      const void *keydata1, const void *keydata2,\n                      int selection)\n{\n    /* We assume no match if the implementation doesn't have a function */\n    if (keymgmt->match == NULL)\n        return 0;\n    return keymgmt->match(keydata1, keydata2, selection);\n}\n\nint evp_keymgmt_import(const EVP_KEYMGMT *keymgmt, void *keydata,\n                       int selection, const OSSL_PARAM params[])\n{\n    if (keymgmt->import == NULL)\n        return 0;\n    return keymgmt->import(keydata, selection, params);\n}\n\nconst OSSL_PARAM *evp_keymgmt_import_types(const EVP_KEYMGMT *keymgmt,\n                                           int selection)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->import_types_ex != NULL)\n        return keymgmt->import_types_ex(provctx, selection);\n    if (keymgmt->import_types == NULL)\n        return NULL;\n    return keymgmt->import_types(selection);\n}\n\nint evp_keymgmt_export(const EVP_KEYMGMT *keymgmt, void *keydata,\n                       int selection, OSSL_CALLBACK *param_cb, void *cbarg)\n{\n    if (keymgmt->export == NULL)\n        return 0;\n    return keymgmt->export(keydata, selection, param_cb, cbarg);\n}\n\nconst OSSL_PARAM *evp_keymgmt_export_types(const EVP_KEYMGMT *keymgmt,\n                                           int selection)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->export_types_ex != NULL)\n        return keymgmt->export_types_ex(provctx, selection);\n    if (keymgmt->export_types == NULL)\n        return NULL;\n    return keymgmt->export_types(selection);\n}\n\nvoid *evp_keymgmt_dup(const EVP_KEYMGMT *keymgmt, const void *keydata_from,\n                      int selection)\n{\n    /* We assume no dup if the implementation doesn't have a function */\n    if (keymgmt->dup == NULL)\n        return NULL;\n    return keymgmt->dup(keydata_from, selection);\n}\n"}], "code": "const char *evp_keymgmt_util_query_operation_name(EVP_KEYMGMT *keymgmt,\n                                                  int op_id)\n{\n    const char *name = NULL;\n\n    if (keymgmt != NULL) {\n        if (keymgmt->query_operation_name != NULL)\n            name = keymgmt->query_operation_name(op_id);\n        if (name == NULL)\n            name = EVP_KEYMGMT_get0_name(keymgmt);\n    }\n    return name;\n}\n"}, "D6EC6B1ACE221810": {"calls": [{"id": "33A0701F36D84616", "name": "EVP_KEYMGMT_get0_name", "path": "openssl/crypto/evp/keymgmt_meth.c", "start": {"line": 312, "col": 1}, "end": {"line": 315, "col": 1}, "code": "{\n    return keymgmt->type_name;\n}\n\nint EVP_KEYMGMT_is_a(const EVP_KEYMGMT *keymgmt, const char *name)\n{\n    return keymgmt != NULL\n           && evp_is_a(keymgmt->prov, keymgmt->name_id, NULL, name);\n}\n\nvoid EVP_KEYMGMT_do_all_provided(OSSL_LIB_CTX *libctx,\n                                 void (*fn)(EVP_KEYMGMT *keymgmt, void *arg),\n                                 void *arg)\n{\n    evp_generic_do_all(libctx, OSSL_OP_KEYMGMT,\n                       (void (*)(void *, void *))fn, arg,\n                       keymgmt_from_algorithm,\n                       (int (*)(void *))EVP_KEYMGMT_up_ref,\n                       (void (*)(void *))EVP_KEYMGMT_free);\n}\n\nint EVP_KEYMGMT_names_do_all(const EVP_KEYMGMT *keymgmt,\n                             void (*fn)(const char *name, void *data),\n                             void *data)\n{\n    if (keymgmt->prov != NULL)\n        return evp_names_do_all(keymgmt->prov, keymgmt->name_id, fn, data);\n\n    return 1;\n}\n\n/*\n * Internal API that interfaces with the method function pointers\n */\nvoid *evp_keymgmt_newdata(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    /*\n     * 'new' is currently mandatory on its own, but when new\n     * constructors appear, it won't be quite as mandatory,\n     * so we have a check for future cases.\n     */\n    if (keymgmt->new == NULL)\n        return NULL;\n    return keymgmt->new(provctx);\n}\n\nvoid evp_keymgmt_freedata(const EVP_KEYMGMT *keymgmt, void *keydata)\n{\n    /* This is mandatory, no need to check for its presence */\n    keymgmt->free(keydata);\n}\n\nvoid *evp_keymgmt_gen_init(const EVP_KEYMGMT *keymgmt, int selection,\n                           const OSSL_PARAM params[])\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gen_init == NULL)\n        return NULL;\n    return keymgmt->gen_init(provctx, selection, params);\n}\n\nint evp_keymgmt_gen_set_template(const EVP_KEYMGMT *keymgmt, void *genctx,\n                                 void *templ)\n{\n    /*\n     * It's arguable if we actually should return success in this case, as\n     * it allows the caller to set a template key, which is then ignored.\n     * However, this is how the legacy methods (EVP_PKEY_METHOD) operate,\n     * so we do this in the interest of backward compatibility.\n     */\n    if (keymgmt->gen_set_template == NULL)\n        return 1;\n    return keymgmt->gen_set_template(genctx, templ);\n}\n\nint evp_keymgmt_gen_set_params(const EVP_KEYMGMT *keymgmt, void *genctx,\n                               const OSSL_PARAM params[])\n{\n    if (keymgmt->gen_set_params == NULL)\n        return 0;\n    return keymgmt->gen_set_params(genctx, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_gen_settable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gen_settable_params == NULL)\n        return NULL;\n    return keymgmt->gen_settable_params(NULL, provctx);\n}\n\nvoid *evp_keymgmt_gen(const EVP_KEYMGMT *keymgmt, void *genctx,\n                      OSSL_CALLBACK *cb, void *cbarg)\n{\n    if (keymgmt->gen == NULL)\n        return NULL;\n    return keymgmt->gen(genctx, cb, cbarg);\n}\n\nvoid evp_keymgmt_gen_cleanup(const EVP_KEYMGMT *keymgmt, void *genctx)\n{\n    if (keymgmt->gen_cleanup != NULL)\n        keymgmt->gen_cleanup(genctx);\n}\n\nint evp_keymgmt_has_load(const EVP_KEYMGMT *keymgmt)\n{\n    return keymgmt != NULL && keymgmt->load != NULL;\n}\n\nvoid *evp_keymgmt_load(const EVP_KEYMGMT *keymgmt,\n                       const void *objref, size_t objref_sz)\n{\n    if (evp_keymgmt_has_load(keymgmt))\n        return keymgmt->load(objref, objref_sz);\n    return NULL;\n}\n\nint evp_keymgmt_get_params(const EVP_KEYMGMT *keymgmt, void *keydata,\n                           OSSL_PARAM params[])\n{\n    if (keymgmt->get_params == NULL)\n        return 1;\n    return keymgmt->get_params(keydata, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_gettable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gettable_params == NULL)\n        return NULL;\n    return keymgmt->gettable_params(provctx);\n}\n\nint evp_keymgmt_set_params(const EVP_KEYMGMT *keymgmt, void *keydata,\n                           const OSSL_PARAM params[])\n{\n    if (keymgmt->set_params == NULL)\n        return 1;\n    return keymgmt->set_params(keydata, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_settable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->settable_params == NULL)\n        return NULL;\n    return keymgmt->settable_params(provctx);\n}\n\nint evp_keymgmt_has(const EVP_KEYMGMT *keymgmt, void *keydata, int selection)\n{\n    /* This is mandatory, no need to check for its presence */\n    return keymgmt->has(keydata, selection);\n}\n\nint evp_keymgmt_validate(const EVP_KEYMGMT *keymgmt, void *keydata,\n                         int selection, int checktype)\n{\n    /* We assume valid if the implementation doesn't have a function */\n    if (keymgmt->validate == NULL)\n        return 1;\n    return keymgmt->validate(keydata, selection, checktype);\n}\n\nint evp_keymgmt_match(const EVP_KEYMGMT *keymgmt,\n                      const void *keydata1, const void *keydata2,\n                      int selection)\n{\n    /* We assume no match if the implementation doesn't have a function */\n    if (keymgmt->match == NULL)\n        return 0;\n    return keymgmt->match(keydata1, keydata2, selection);\n}\n\nint evp_keymgmt_import(const EVP_KEYMGMT *keymgmt, void *keydata,\n                       int selection, const OSSL_PARAM params[])\n{\n    if (keymgmt->import == NULL)\n        return 0;\n    return keymgmt->import(keydata, selection, params);\n}\n\nconst OSSL_PARAM *evp_keymgmt_import_types(const EVP_KEYMGMT *keymgmt,\n                                           int selection)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->import_types_ex != NULL)\n        return keymgmt->import_types_ex(provctx, selection);\n    if (keymgmt->import_types == NULL)\n        return NULL;\n    return keymgmt->import_types(selection);\n}\n\nint evp_keymgmt_export(const EVP_KEYMGMT *keymgmt, void *keydata,\n                       int selection, OSSL_CALLBACK *param_cb, void *cbarg)\n{\n    if (keymgmt->export == NULL)\n        return 0;\n    return keymgmt->export(keydata, selection, param_cb, cbarg);\n}\n\nconst OSSL_PARAM *evp_keymgmt_export_types(const EVP_KEYMGMT *keymgmt,\n                                           int selection)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->export_types_ex != NULL)\n        return keymgmt->export_types_ex(provctx, selection);\n    if (keymgmt->export_types == NULL)\n        return NULL;\n    return keymgmt->export_types(selection);\n}\n\nvoid *evp_keymgmt_dup(const EVP_KEYMGMT *keymgmt, const void *keydata_from,\n                      int selection)\n{\n    /* We assume no dup if the implementation doesn't have a function */\n    if (keymgmt->dup == NULL)\n        return NULL;\n    return keymgmt->dup(keydata_from, selection);\n}\n"}, {"id": "9D8223F9872C49F0", "name": "EVP_KEYMGMT_is_a", "path": "openssl/crypto/evp/keymgmt_meth.c", "start": {"line": 317, "col": 1}, "end": {"line": 321, "col": 1}, "code": "{\n    return keymgmt != NULL\n           && evp_is_a(keymgmt->prov, keymgmt->name_id, NULL, name);\n}\n\nvoid EVP_KEYMGMT_do_all_provided(OSSL_LIB_CTX *libctx,\n                                 void (*fn)(EVP_KEYMGMT *keymgmt, void *arg),\n                                 void *arg)\n{\n    evp_generic_do_all(libctx, OSSL_OP_KEYMGMT,\n                       (void (*)(void *, void *))fn, arg,\n                       keymgmt_from_algorithm,\n                       (int (*)(void *))EVP_KEYMGMT_up_ref,\n                       (void (*)(void *))EVP_KEYMGMT_free);\n}\n\nint EVP_KEYMGMT_names_do_all(const EVP_KEYMGMT *keymgmt,\n                             void (*fn)(const char *name, void *data),\n                             void *data)\n{\n    if (keymgmt->prov != NULL)\n        return evp_names_do_all(keymgmt->prov, keymgmt->name_id, fn, data);\n\n    return 1;\n}\n\n/*\n * Internal API that interfaces with the method function pointers\n */\nvoid *evp_keymgmt_newdata(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    /*\n     * 'new' is currently mandatory on its own, but when new\n     * constructors appear, it won't be quite as mandatory,\n     * so we have a check for future cases.\n     */\n    if (keymgmt->new == NULL)\n        return NULL;\n    return keymgmt->new(provctx);\n}\n\nvoid evp_keymgmt_freedata(const EVP_KEYMGMT *keymgmt, void *keydata)\n{\n    /* This is mandatory, no need to check for its presence */\n    keymgmt->free(keydata);\n}\n\nvoid *evp_keymgmt_gen_init(const EVP_KEYMGMT *keymgmt, int selection,\n                           const OSSL_PARAM params[])\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gen_init == NULL)\n        return NULL;\n    return keymgmt->gen_init(provctx, selection, params);\n}\n\nint evp_keymgmt_gen_set_template(const EVP_KEYMGMT *keymgmt, void *genctx,\n                                 void *templ)\n{\n    /*\n     * It's arguable if we actually should return success in this case, as\n     * it allows the caller to set a template key, which is then ignored.\n     * However, this is how the legacy methods (EVP_PKEY_METHOD) operate,\n     * so we do this in the interest of backward compatibility.\n     */\n    if (keymgmt->gen_set_template == NULL)\n        return 1;\n    return keymgmt->gen_set_template(genctx, templ);\n}\n\nint evp_keymgmt_gen_set_params(const EVP_KEYMGMT *keymgmt, void *genctx,\n                               const OSSL_PARAM params[])\n{\n    if (keymgmt->gen_set_params == NULL)\n        return 0;\n    return keymgmt->gen_set_params(genctx, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_gen_settable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gen_settable_params == NULL)\n        return NULL;\n    return keymgmt->gen_settable_params(NULL, provctx);\n}\n\nvoid *evp_keymgmt_gen(const EVP_KEYMGMT *keymgmt, void *genctx,\n                      OSSL_CALLBACK *cb, void *cbarg)\n{\n    if (keymgmt->gen == NULL)\n        return NULL;\n    return keymgmt->gen(genctx, cb, cbarg);\n}\n\nvoid evp_keymgmt_gen_cleanup(const EVP_KEYMGMT *keymgmt, void *genctx)\n{\n    if (keymgmt->gen_cleanup != NULL)\n        keymgmt->gen_cleanup(genctx);\n}\n\nint evp_keymgmt_has_load(const EVP_KEYMGMT *keymgmt)\n{\n    return keymgmt != NULL && keymgmt->load != NULL;\n}\n\nvoid *evp_keymgmt_load(const EVP_KEYMGMT *keymgmt,\n                       const void *objref, size_t objref_sz)\n{\n    if (evp_keymgmt_has_load(keymgmt))\n        return keymgmt->load(objref, objref_sz);\n    return NULL;\n}\n\nint evp_keymgmt_get_params(const EVP_KEYMGMT *keymgmt, void *keydata,\n                           OSSL_PARAM params[])\n{\n    if (keymgmt->get_params == NULL)\n        return 1;\n    return keymgmt->get_params(keydata, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_gettable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->gettable_params == NULL)\n        return NULL;\n    return keymgmt->gettable_params(provctx);\n}\n\nint evp_keymgmt_set_params(const EVP_KEYMGMT *keymgmt, void *keydata,\n                           const OSSL_PARAM params[])\n{\n    if (keymgmt->set_params == NULL)\n        return 1;\n    return keymgmt->set_params(keydata, params);\n}\n\nconst OSSL_PARAM *EVP_KEYMGMT_settable_params(const EVP_KEYMGMT *keymgmt)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->settable_params == NULL)\n        return NULL;\n    return keymgmt->settable_params(provctx);\n}\n\nint evp_keymgmt_has(const EVP_KEYMGMT *keymgmt, void *keydata, int selection)\n{\n    /* This is mandatory, no need to check for its presence */\n    return keymgmt->has(keydata, selection);\n}\n\nint evp_keymgmt_validate(const EVP_KEYMGMT *keymgmt, void *keydata,\n                         int selection, int checktype)\n{\n    /* We assume valid if the implementation doesn't have a function */\n    if (keymgmt->validate == NULL)\n        return 1;\n    return keymgmt->validate(keydata, selection, checktype);\n}\n\nint evp_keymgmt_match(const EVP_KEYMGMT *keymgmt,\n                      const void *keydata1, const void *keydata2,\n                      int selection)\n{\n    /* We assume no match if the implementation doesn't have a function */\n    if (keymgmt->match == NULL)\n        return 0;\n    return keymgmt->match(keydata1, keydata2, selection);\n}\n\nint evp_keymgmt_import(const EVP_KEYMGMT *keymgmt, void *keydata,\n                       int selection, const OSSL_PARAM params[])\n{\n    if (keymgmt->import == NULL)\n        return 0;\n    return keymgmt->import(keydata, selection, params);\n}\n\nconst OSSL_PARAM *evp_keymgmt_import_types(const EVP_KEYMGMT *keymgmt,\n                                           int selection)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->import_types_ex != NULL)\n        return keymgmt->import_types_ex(provctx, selection);\n    if (keymgmt->import_types == NULL)\n        return NULL;\n    return keymgmt->import_types(selection);\n}\n\nint evp_keymgmt_export(const EVP_KEYMGMT *keymgmt, void *keydata,\n                       int selection, OSSL_CALLBACK *param_cb, void *cbarg)\n{\n    if (keymgmt->export == NULL)\n        return 0;\n    return keymgmt->export(keydata, selection, param_cb, cbarg);\n}\n\nconst OSSL_PARAM *evp_keymgmt_export_types(const EVP_KEYMGMT *keymgmt,\n                                           int selection)\n{\n    void *provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(keymgmt));\n\n    if (keymgmt->export_types_ex != NULL)\n        return keymgmt->export_types_ex(provctx, selection);\n    if (keymgmt->export_types == NULL)\n        return NULL;\n    return keymgmt->export_types(selection);\n}\n\nvoid *evp_keymgmt_dup(const EVP_KEYMGMT *keymgmt, const void *keydata_from,\n                      int selection)\n{\n    /* We assume no dup if the implementation doesn't have a function */\n    if (keymgmt->dup == NULL)\n        return NULL;\n    return keymgmt->dup(keydata_from, selection);\n}\n"}], "code": "static int match_type(const EVP_KEYMGMT *keymgmt1, const EVP_KEYMGMT *keymgmt2)\n{\n    const char *name2 = EVP_KEYMGMT_get0_name(keymgmt2);\n\n    return EVP_KEYMGMT_is_a(keymgmt1, name2);\n}\n"}, "A15E1111AA115EBE": {"calls": [{"id": "9734C3811065FAB9", "name": "ossl_ifc_ffc_compute_security_bits", "path": "openssl/crypto/rsa/rsa_lib.c", "start": {"line": 317, "col": 1}, "end": {"line": 376, "col": 1}, "code": "{\n    uint64_t x;\n    uint32_t lx;\n    uint16_t y, cap;\n\n    /*\n     * Look for common values as listed in standards.\n     * These values are not exactly equal to the results from the formulae in\n     * the standards but are defined to be canonical.\n     */\n    switch (n) {\n    case 2048:      /* SP 800-56B rev 2 Appendix D and FIPS 140-2 IG 7.5 */\n        return 112;\n    case 3072:      /* SP 800-56B rev 2 Appendix D and FIPS 140-2 IG 7.5 */\n        return 128;\n    case 4096:      /* SP 800-56B rev 2 Appendix D */\n        return 152;\n    case 6144:      /* SP 800-56B rev 2 Appendix D */\n        return 176;\n    case 7680:      /* FIPS 140-2 IG 7.5 */\n        return 192;\n    case 8192:      /* SP 800-56B rev 2 Appendix D */\n        return 200;\n    case 15360:     /* FIPS 140-2 IG 7.5 */\n        return 256;\n    }\n\n    /*\n     * The first incorrect result (i.e. not accurate or off by one low) occurs\n     * for n = 699668.  The true value here is 1200.  Instead of using this n\n     * as the check threshold, the smallest n such that the correct result is\n     * 1200 is used instead.\n     */\n    if (n >= 687737)\n        return 1200;\n    if (n < 8)\n        return 0;\n\n    /*\n     * To ensure that the output is non-decreasing with respect to n,\n     * a cap needs to be applied to the two values where the function over\n     * estimates the strength (according to the above fast path).\n     */\n    if (n <= 7680)\n        cap = 192;\n    else if (n <= 15360)\n        cap = 256;\n    else\n        cap = 1200;\n\n    x = n * (uint64_t)log_2;\n    lx = ilog_e(x);\n    y = (uint16_t)((mul2(c1_923, icbrt64(mul2(mul2(x, lx), lx))) - c4_690)\n                   / log_2);\n    y = (y + 4) & ~7;\n    if (y > cap)\n        y = cap;\n    return y;\n}\n\n\n\nint RSA_security_bits(const RSA *rsa)\n{\n    int bits = BN_num_bits(rsa->n);\n\n"}], "code": "int ossl_rsa_sp800_56b_validate_strength(int nbits, int strength)\n{\n    int s = (int)ossl_ifc_ffc_compute_security_bits(nbits);\n\n#ifdef FIPS_MODULE\n    if (s < RSA_FIPS1864_MIN_KEYGEN_STRENGTH) {\n        ERR_raise(ERR_LIB_RSA, RSA_R_INVALID_MODULUS);\n        return 0;\n    }\n#endif\n    if (strength != -1 && s != strength) {\n        ERR_raise(ERR_LIB_RSA, RSA_R_INVALID_STRENGTH);\n        return 0;\n    }\n    return 1;\n}\n"}, "2EC2B72D1CCAE2A5": {"calls": [{"id": "C80C3A08045EC7A1", "name": "EVP_PKEY_CTX_new_from_name", "path": "openssl/crypto/evp/pmeth_lib.c", "start": {"line": 341, "col": 1}, "end": {"line": 346, "col": 1}, "code": "                                         const char *name,\n                                         const char *propquery)\n{\n    return int_ctx_new(libctx, NULL, NULL, name, propquery, -1);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_new_from_pkey(OSSL_LIB_CTX *libctx, EVP_PKEY *pkey,\n                                         const char *propquery)\n{\n    return int_ctx_new(libctx, pkey, NULL, NULL, propquery, -1);\n}\n\nvoid evp_pkey_ctx_free_old_ops(EVP_PKEY_CTX *ctx)\n{\n    if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)) {\n        if (ctx->op.sig.algctx != NULL && ctx->op.sig.signature != NULL)\n            ctx->op.sig.signature->freectx(ctx->op.sig.algctx);\n        EVP_SIGNATURE_free(ctx->op.sig.signature);\n        ctx->op.sig.algctx = NULL;\n        ctx->op.sig.signature = NULL;\n    } else if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)) {\n        if (ctx->op.kex.algctx != NULL && ctx->op.kex.exchange != NULL)\n            ctx->op.kex.exchange->freectx(ctx->op.kex.algctx);\n        EVP_KEYEXCH_free(ctx->op.kex.exchange);\n        ctx->op.kex.algctx = NULL;\n        ctx->op.kex.exchange = NULL;\n    } else if (EVP_PKEY_CTX_IS_KEM_OP(ctx)) {\n        if (ctx->op.encap.algctx != NULL && ctx->op.encap.kem != NULL)\n            ctx->op.encap.kem->freectx(ctx->op.encap.algctx);\n        EVP_KEM_free(ctx->op.encap.kem);\n        ctx->op.encap.algctx = NULL;\n        ctx->op.encap.kem = NULL;\n    }\n    else if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)) {\n        if (ctx->op.ciph.algctx != NULL && ctx->op.ciph.cipher != NULL)\n            ctx->op.ciph.cipher->freectx(ctx->op.ciph.algctx);\n        EVP_ASYM_CIPHER_free(ctx->op.ciph.cipher);\n        ctx->op.ciph.algctx = NULL;\n        ctx->op.ciph.cipher = NULL;\n    } else if (EVP_PKEY_CTX_IS_GEN_OP(ctx)) {\n        if (ctx->op.keymgmt.genctx != NULL && ctx->keymgmt != NULL)\n            evp_keymgmt_gen_cleanup(ctx->keymgmt, ctx->op.keymgmt.genctx);\n    }\n}\n\nvoid EVP_PKEY_CTX_free(EVP_PKEY_CTX *ctx)\n{\n    if (ctx == NULL)\n        return;\n    if (ctx->pmeth && ctx->pmeth->cleanup)\n        ctx->pmeth->cleanup(ctx);\n\n    evp_pkey_ctx_free_old_ops(ctx);\n#ifndef FIPS_MODULE\n    evp_pkey_ctx_free_all_cached_data(ctx);\n#endif\n    EVP_KEYMGMT_free(ctx->keymgmt);\n\n    OPENSSL_free(ctx->propquery);\n    EVP_PKEY_free(ctx->pkey);\n    EVP_PKEY_free(ctx->peerkey);\n#if !defined(OPENSSL_NO_ENGINE) && !defined(FIPS_MODULE)\n    ENGINE_finish(ctx->engine);\n#endif\n    BN_free(ctx->rsa_pubexp);\n    OPENSSL_free(ctx);\n}\n\n#ifndef FIPS_MODULE\n\nvoid EVP_PKEY_meth_get0_info(int *ppkey_id, int *pflags,\n                             const EVP_PKEY_METHOD *meth)\n{\n    if (ppkey_id)\n        *ppkey_id = meth->pkey_id;\n    if (pflags)\n        *pflags = meth->flags;\n}\n\nvoid EVP_PKEY_meth_copy(EVP_PKEY_METHOD *dst, const EVP_PKEY_METHOD *src)\n{\n    int pkey_id = dst->pkey_id;\n    int flags = dst->flags;\n\n    *dst = *src;\n\n    /* We only copy the function pointers so restore the other values */\n    dst->pkey_id = pkey_id;\n    dst->flags = flags;\n}\n\nvoid EVP_PKEY_meth_free(EVP_PKEY_METHOD *pmeth)\n{\n    if (pmeth && (pmeth->flags & EVP_PKEY_FLAG_DYNAMIC))\n        OPENSSL_free(pmeth);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_new(EVP_PKEY *pkey, ENGINE *e)\n{\n    return int_ctx_new(NULL, pkey, e, NULL, NULL, -1);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_new_id(int id, ENGINE *e)\n{\n    return int_ctx_new(NULL, NULL, e, NULL, NULL, id);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_dup(const EVP_PKEY_CTX *pctx)\n{\n    EVP_PKEY_CTX *rctx;\n\n# ifndef OPENSSL_NO_ENGINE\n    /* Make sure it's safe to copy a pkey context using an ENGINE */\n    if (pctx->engine && !ENGINE_init(pctx->engine)) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_ENGINE_LIB);\n        return 0;\n    }\n# endif\n    rctx = OPENSSL_zalloc(sizeof(*rctx));\n    if (rctx == NULL)\n        return NULL;\n\n    if (pctx->pkey != NULL)\n        EVP_PKEY_up_ref(pctx->pkey);\n    rctx->pkey = pctx->pkey;\n    rctx->operation = pctx->operation;\n    rctx->libctx = pctx->libctx;\n    rctx->keytype = pctx->keytype;\n    rctx->propquery = NULL;\n    if (pctx->propquery != NULL) {\n        rctx->propquery = OPENSSL_strdup(pctx->propquery);\n        if (rctx->propquery == NULL)\n            goto err;\n    }\n    rctx->legacy_keytype = pctx->legacy_keytype;\n\n    if (EVP_PKEY_CTX_IS_DERIVE_OP(pctx)) {\n        if (pctx->op.kex.exchange != NULL) {\n            rctx->op.kex.exchange = pctx->op.kex.exchange;\n            if (!EVP_KEYEXCH_up_ref(rctx->op.kex.exchange))\n                goto err;\n        }\n        if (pctx->op.kex.algctx != NULL) {\n            if (!ossl_assert(pctx->op.kex.exchange != NULL))\n                goto err;\n\n            if (pctx->op.kex.exchange->dupctx != NULL)\n                rctx->op.kex.algctx\n                    = pctx->op.kex.exchange->dupctx(pctx->op.kex.algctx);\n\n            if (rctx->op.kex.algctx == NULL) {\n                EVP_KEYEXCH_free(rctx->op.kex.exchange);\n                rctx->op.kex.exchange = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_SIGNATURE_OP(pctx)) {\n        if (pctx->op.sig.signature != NULL) {\n            rctx->op.sig.signature = pctx->op.sig.signature;\n            if (!EVP_SIGNATURE_up_ref(rctx->op.sig.signature))\n                goto err;\n        }\n        if (pctx->op.sig.algctx != NULL) {\n            if (!ossl_assert(pctx->op.sig.signature != NULL))\n                goto err;\n\n            if (pctx->op.sig.signature->dupctx != NULL)\n                rctx->op.sig.algctx\n                    = pctx->op.sig.signature->dupctx(pctx->op.sig.algctx);\n\n            if (rctx->op.sig.algctx == NULL) {\n                EVP_SIGNATURE_free(rctx->op.sig.signature);\n                rctx->op.sig.signature = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(pctx)) {\n        if (pctx->op.ciph.cipher != NULL) {\n            rctx->op.ciph.cipher = pctx->op.ciph.cipher;\n            if (!EVP_ASYM_CIPHER_up_ref(rctx->op.ciph.cipher))\n                goto err;\n        }\n        if (pctx->op.ciph.algctx != NULL) {\n            if (!ossl_assert(pctx->op.ciph.cipher != NULL))\n                goto err;\n\n            if (pctx->op.ciph.cipher->dupctx != NULL)\n                rctx->op.ciph.algctx\n                    = pctx->op.ciph.cipher->dupctx(pctx->op.ciph.algctx);\n\n            if (rctx->op.ciph.algctx == NULL) {\n                EVP_ASYM_CIPHER_free(rctx->op.ciph.cipher);\n                rctx->op.ciph.cipher = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_KEM_OP(pctx)) {\n        if (pctx->op.encap.kem != NULL) {\n            rctx->op.encap.kem = pctx->op.encap.kem;\n            if (!EVP_KEM_up_ref(rctx->op.encap.kem))\n                goto err;\n        }\n        if (pctx->op.encap.algctx != NULL) {\n            if (!ossl_assert(pctx->op.encap.kem != NULL))\n                goto err;\n\n            if (pctx->op.encap.kem->dupctx != NULL)\n                rctx->op.encap.algctx\n                    = pctx->op.encap.kem->dupctx(pctx->op.encap.algctx);\n\n            if (rctx->op.encap.algctx == NULL) {\n                EVP_KEM_free(rctx->op.encap.kem);\n                rctx->op.encap.kem = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_GEN_OP(pctx)) {\n        /* Not supported - This would need a gen_dupctx() to work */\n        goto err;\n    }\n\n    rctx->pmeth = pctx->pmeth;\n# ifndef OPENSSL_NO_ENGINE\n    rctx->engine = pctx->engine;\n# endif\n\n    if (pctx->peerkey != NULL)\n        EVP_PKEY_up_ref(pctx->peerkey);\n    rctx->peerkey = pctx->peerkey;\n\n    if (pctx->pmeth == NULL) {\n        if (rctx->operation == EVP_PKEY_OP_UNDEFINED) {\n            EVP_KEYMGMT *tmp_keymgmt = pctx->keymgmt;\n            void *provkey;\n\n            provkey = evp_pkey_export_to_provider(pctx->pkey, pctx->libctx,\n                                                  &tmp_keymgmt, pctx->propquery);\n            if (provkey == NULL)\n                goto err;\n            if (!EVP_KEYMGMT_up_ref(tmp_keymgmt))\n                goto err;\n            EVP_KEYMGMT_free(rctx->keymgmt);\n            rctx->keymgmt = tmp_keymgmt;\n            return rctx;\n        }\n    } else if (pctx->pmeth->copy(rctx, pctx) > 0) {\n        return rctx;\n    }\nerr:\n    rctx->pmeth = NULL;\n    EVP_PKEY_CTX_free(rctx);\n    return NULL;\n}\n\nint EVP_PKEY_meth_add0(const EVP_PKEY_METHOD *pmeth)\n{\n    if (app_pkey_methods == NULL) {\n        app_pkey_methods = sk_EVP_PKEY_METHOD_new(pmeth_cmp);\n        if (app_pkey_methods == NULL) {\n            ERR_raise(ERR_LIB_EVP, ERR_R_CRYPTO_LIB);\n            return 0;\n        }\n    }\n    if (!sk_EVP_PKEY_METHOD_push(app_pkey_methods, pmeth)) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_CRYPTO_LIB);\n        return 0;\n    }\n    sk_EVP_PKEY_METHOD_sort(app_pkey_methods);\n    return 1;\n}\n\nvoid evp_app_cleanup_int(void)\n{\n    if (app_pkey_methods != NULL)\n        sk_EVP_PKEY_METHOD_pop_free(app_pkey_methods, EVP_PKEY_meth_free);\n}\n\nint EVP_PKEY_meth_remove(const EVP_PKEY_METHOD *pmeth)\n{\n    const EVP_PKEY_METHOD *ret;\n\n    ret = sk_EVP_PKEY_METHOD_delete_ptr(app_pkey_methods, pmeth);\n\n    return ret == NULL ? 0 : 1;\n}\n\nsize_t EVP_PKEY_meth_get_count(void)\n{\n    size_t rv = OSSL_NELEM(standard_methods);\n\n    if (app_pkey_methods)\n        rv += sk_EVP_PKEY_METHOD_num(app_pkey_methods);\n    return rv;\n}\n\nconst EVP_PKEY_METHOD *EVP_PKEY_meth_get0(size_t idx)\n{\n    if (idx < OSSL_NELEM(standard_methods))\n        return (standard_methods[idx])();\n    if (app_pkey_methods == NULL)\n        return NULL;\n    idx -= OSSL_NELEM(standard_methods);\n    if (idx >= (size_t)sk_EVP_PKEY_METHOD_num(app_pkey_methods))\n        return NULL;\n    return sk_EVP_PKEY_METHOD_value(app_pkey_methods, idx);\n}\n#endif\n\nint EVP_PKEY_CTX_is_a(EVP_PKEY_CTX *ctx, const char *keytype)\n{\n#ifndef FIPS_MODULE\n    if (evp_pkey_ctx_is_legacy(ctx))\n        return (ctx->pmeth->pkey_id == evp_pkey_name2type(keytype));\n#endif\n    return EVP_KEYMGMT_is_a(ctx->keymgmt, keytype);\n}\n\nint EVP_PKEY_CTX_set_params(EVP_PKEY_CTX *ctx, const OSSL_PARAM *params)\n{\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->set_ctx_params != NULL)\n            return\n                ctx->op.kex.exchange->set_ctx_params(ctx->op.kex.algctx,\n                                                     params);\n        if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->set_ctx_params != NULL)\n            return\n                ctx->op.sig.signature->set_ctx_params(ctx->op.sig.algctx,\n                                                      params);\n        if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->set_ctx_params != NULL)\n            return\n                ctx->op.ciph.cipher->set_ctx_params(ctx->op.ciph.algctx,\n                                                    params);\n        if (EVP_PKEY_CTX_IS_GEN_OP(ctx)\n            && ctx->keymgmt != NULL\n            && ctx->keymgmt->gen_set_params != NULL)\n            return\n"}, {"id": "50D351968D14F514", "name": "EVP_PKEY_generate", "path": "openssl/crypto/evp/pmeth_gn.c", "start": {"line": 128, "col": 1}, "end": {"line": 257, "col": 1}, "code": "{\n    int ret = 0;\n    EVP_PKEY *allocated_pkey = NULL;\n    /* Legacy compatible keygen callback info, only used with provider impls */\n    int gentmp[2];\n\n    if (ppkey == NULL)\n        return -1;\n\n    if (ctx == NULL)\n        goto not_supported;\n\n    if ((ctx->operation & EVP_PKEY_OP_TYPE_GEN) == 0)\n        goto not_initialized;\n\n    if (*ppkey == NULL)\n        *ppkey = allocated_pkey = EVP_PKEY_new();\n\n    if (*ppkey == NULL) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_EVP_LIB);\n        return -1;\n    }\n\n    if (ctx->op.keymgmt.genctx == NULL)\n        goto legacy;\n\n    /*\n     * Assigning gentmp to ctx->keygen_info is something our legacy\n     * implementations do.  Because the provider implementations aren't\n     * allowed to reach into our EVP_PKEY_CTX, we need to provide similar\n     * space for backward compatibility.  It's ok that we attach a local\n     * variable, as it should only be useful in the calls down from here.\n     * This is cleared as soon as it isn't useful any more, i.e. directly\n     * after the evp_keymgmt_util_gen() call.\n     */\n    ctx->keygen_info = gentmp;\n    ctx->keygen_info_count = 2;\n\n    ret = 1;\n    if (ctx->pkey != NULL) {\n        EVP_KEYMGMT *tmp_keymgmt = ctx->keymgmt;\n        void *keydata =\n            evp_pkey_export_to_provider(ctx->pkey, ctx->libctx,\n                                        &tmp_keymgmt, ctx->propquery);\n\n        if (tmp_keymgmt == NULL)\n            goto not_supported;\n        /*\n         * It's ok if keydata is NULL here.  The backend is expected to deal\n         * with that as it sees fit.\n         */\n        ret = evp_keymgmt_gen_set_template(ctx->keymgmt,\n                                           ctx->op.keymgmt.genctx, keydata);\n    }\n\n    /*\n     * the returned value from evp_keymgmt_util_gen() is cached in *ppkey,\n     * so we do not need to save it, just check it.\n     */\n    ret = ret\n        && (evp_keymgmt_util_gen(*ppkey, ctx->keymgmt, ctx->op.keymgmt.genctx,\n                                 ossl_callback_to_pkey_gencb, ctx)\n            != NULL);\n\n    ctx->keygen_info = NULL;\n\n"}, {"id": "F3AEE16FC3233300", "name": "EVP_PKEY_CTX_free", "path": "openssl/crypto/evp/pmeth_lib.c", "start": {"line": 387, "col": 1}, "end": {"line": 408, "col": 1}, "code": "{\n    if (ctx == NULL)\n        return;\n    if (ctx->pmeth && ctx->pmeth->cleanup)\n        ctx->pmeth->cleanup(ctx);\n\n    evp_pkey_ctx_free_old_ops(ctx);\n#ifndef FIPS_MODULE\n    evp_pkey_ctx_free_all_cached_data(ctx);\n#endif\n    EVP_KEYMGMT_free(ctx->keymgmt);\n\n    OPENSSL_free(ctx->propquery);\n    EVP_PKEY_free(ctx->pkey);\n    EVP_PKEY_free(ctx->peerkey);\n#if !defined(OPENSSL_NO_ENGINE) && !defined(FIPS_MODULE)\n    ENGINE_finish(ctx->engine);\n#endif\n    BN_free(ctx->rsa_pubexp);\n    OPENSSL_free(ctx);\n}\n\n#ifndef FIPS_MODULE\n\nvoid EVP_PKEY_meth_get0_info(int *ppkey_id, int *pflags,\n                             const EVP_PKEY_METHOD *meth)\n{\n    if (ppkey_id)\n        *ppkey_id = meth->pkey_id;\n    if (pflags)\n        *pflags = meth->flags;\n}\n\nvoid EVP_PKEY_meth_copy(EVP_PKEY_METHOD *dst, const EVP_PKEY_METHOD *src)\n{\n    int pkey_id = dst->pkey_id;\n    int flags = dst->flags;\n\n    *dst = *src;\n\n    /* We only copy the function pointers so restore the other values */\n    dst->pkey_id = pkey_id;\n    dst->flags = flags;\n}\n\nvoid EVP_PKEY_meth_free(EVP_PKEY_METHOD *pmeth)\n{\n    if (pmeth && (pmeth->flags & EVP_PKEY_FLAG_DYNAMIC))\n        OPENSSL_free(pmeth);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_new(EVP_PKEY *pkey, ENGINE *e)\n{\n    return int_ctx_new(NULL, pkey, e, NULL, NULL, -1);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_new_id(int id, ENGINE *e)\n{\n    return int_ctx_new(NULL, NULL, e, NULL, NULL, id);\n}\n\nEVP_PKEY_CTX *EVP_PKEY_CTX_dup(const EVP_PKEY_CTX *pctx)\n{\n    EVP_PKEY_CTX *rctx;\n\n# ifndef OPENSSL_NO_ENGINE\n    /* Make sure it's safe to copy a pkey context using an ENGINE */\n    if (pctx->engine && !ENGINE_init(pctx->engine)) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_ENGINE_LIB);\n        return 0;\n    }\n# endif\n    rctx = OPENSSL_zalloc(sizeof(*rctx));\n    if (rctx == NULL)\n        return NULL;\n\n    if (pctx->pkey != NULL)\n        EVP_PKEY_up_ref(pctx->pkey);\n    rctx->pkey = pctx->pkey;\n    rctx->operation = pctx->operation;\n    rctx->libctx = pctx->libctx;\n    rctx->keytype = pctx->keytype;\n    rctx->propquery = NULL;\n    if (pctx->propquery != NULL) {\n        rctx->propquery = OPENSSL_strdup(pctx->propquery);\n        if (rctx->propquery == NULL)\n            goto err;\n    }\n    rctx->legacy_keytype = pctx->legacy_keytype;\n\n    if (EVP_PKEY_CTX_IS_DERIVE_OP(pctx)) {\n        if (pctx->op.kex.exchange != NULL) {\n            rctx->op.kex.exchange = pctx->op.kex.exchange;\n            if (!EVP_KEYEXCH_up_ref(rctx->op.kex.exchange))\n                goto err;\n        }\n        if (pctx->op.kex.algctx != NULL) {\n            if (!ossl_assert(pctx->op.kex.exchange != NULL))\n                goto err;\n\n            if (pctx->op.kex.exchange->dupctx != NULL)\n                rctx->op.kex.algctx\n                    = pctx->op.kex.exchange->dupctx(pctx->op.kex.algctx);\n\n            if (rctx->op.kex.algctx == NULL) {\n                EVP_KEYEXCH_free(rctx->op.kex.exchange);\n                rctx->op.kex.exchange = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_SIGNATURE_OP(pctx)) {\n        if (pctx->op.sig.signature != NULL) {\n            rctx->op.sig.signature = pctx->op.sig.signature;\n            if (!EVP_SIGNATURE_up_ref(rctx->op.sig.signature))\n                goto err;\n        }\n        if (pctx->op.sig.algctx != NULL) {\n            if (!ossl_assert(pctx->op.sig.signature != NULL))\n                goto err;\n\n            if (pctx->op.sig.signature->dupctx != NULL)\n                rctx->op.sig.algctx\n                    = pctx->op.sig.signature->dupctx(pctx->op.sig.algctx);\n\n            if (rctx->op.sig.algctx == NULL) {\n                EVP_SIGNATURE_free(rctx->op.sig.signature);\n                rctx->op.sig.signature = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(pctx)) {\n        if (pctx->op.ciph.cipher != NULL) {\n            rctx->op.ciph.cipher = pctx->op.ciph.cipher;\n            if (!EVP_ASYM_CIPHER_up_ref(rctx->op.ciph.cipher))\n                goto err;\n        }\n        if (pctx->op.ciph.algctx != NULL) {\n            if (!ossl_assert(pctx->op.ciph.cipher != NULL))\n                goto err;\n\n            if (pctx->op.ciph.cipher->dupctx != NULL)\n                rctx->op.ciph.algctx\n                    = pctx->op.ciph.cipher->dupctx(pctx->op.ciph.algctx);\n\n            if (rctx->op.ciph.algctx == NULL) {\n                EVP_ASYM_CIPHER_free(rctx->op.ciph.cipher);\n                rctx->op.ciph.cipher = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_KEM_OP(pctx)) {\n        if (pctx->op.encap.kem != NULL) {\n            rctx->op.encap.kem = pctx->op.encap.kem;\n            if (!EVP_KEM_up_ref(rctx->op.encap.kem))\n                goto err;\n        }\n        if (pctx->op.encap.algctx != NULL) {\n            if (!ossl_assert(pctx->op.encap.kem != NULL))\n                goto err;\n\n            if (pctx->op.encap.kem->dupctx != NULL)\n                rctx->op.encap.algctx\n                    = pctx->op.encap.kem->dupctx(pctx->op.encap.algctx);\n\n            if (rctx->op.encap.algctx == NULL) {\n                EVP_KEM_free(rctx->op.encap.kem);\n                rctx->op.encap.kem = NULL;\n                goto err;\n            }\n            return rctx;\n        }\n    } else if (EVP_PKEY_CTX_IS_GEN_OP(pctx)) {\n        /* Not supported - This would need a gen_dupctx() to work */\n        goto err;\n    }\n\n    rctx->pmeth = pctx->pmeth;\n# ifndef OPENSSL_NO_ENGINE\n    rctx->engine = pctx->engine;\n# endif\n\n    if (pctx->peerkey != NULL)\n        EVP_PKEY_up_ref(pctx->peerkey);\n    rctx->peerkey = pctx->peerkey;\n\n    if (pctx->pmeth == NULL) {\n        if (rctx->operation == EVP_PKEY_OP_UNDEFINED) {\n            EVP_KEYMGMT *tmp_keymgmt = pctx->keymgmt;\n            void *provkey;\n\n            provkey = evp_pkey_export_to_provider(pctx->pkey, pctx->libctx,\n                                                  &tmp_keymgmt, pctx->propquery);\n            if (provkey == NULL)\n                goto err;\n            if (!EVP_KEYMGMT_up_ref(tmp_keymgmt))\n                goto err;\n            EVP_KEYMGMT_free(rctx->keymgmt);\n            rctx->keymgmt = tmp_keymgmt;\n            return rctx;\n        }\n    } else if (pctx->pmeth->copy(rctx, pctx) > 0) {\n        return rctx;\n    }\nerr:\n    rctx->pmeth = NULL;\n    EVP_PKEY_CTX_free(rctx);\n    return NULL;\n}\n\nint EVP_PKEY_meth_add0(const EVP_PKEY_METHOD *pmeth)\n{\n    if (app_pkey_methods == NULL) {\n        app_pkey_methods = sk_EVP_PKEY_METHOD_new(pmeth_cmp);\n        if (app_pkey_methods == NULL) {\n            ERR_raise(ERR_LIB_EVP, ERR_R_CRYPTO_LIB);\n            return 0;\n        }\n    }\n    if (!sk_EVP_PKEY_METHOD_push(app_pkey_methods, pmeth)) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_CRYPTO_LIB);\n        return 0;\n    }\n    sk_EVP_PKEY_METHOD_sort(app_pkey_methods);\n    return 1;\n}\n\nvoid evp_app_cleanup_int(void)\n{\n    if (app_pkey_methods != NULL)\n        sk_EVP_PKEY_METHOD_pop_free(app_pkey_methods, EVP_PKEY_meth_free);\n}\n\nint EVP_PKEY_meth_remove(const EVP_PKEY_METHOD *pmeth)\n{\n    const EVP_PKEY_METHOD *ret;\n\n    ret = sk_EVP_PKEY_METHOD_delete_ptr(app_pkey_methods, pmeth);\n\n    return ret == NULL ? 0 : 1;\n}\n\nsize_t EVP_PKEY_meth_get_count(void)\n{\n    size_t rv = OSSL_NELEM(standard_methods);\n\n    if (app_pkey_methods)\n        rv += sk_EVP_PKEY_METHOD_num(app_pkey_methods);\n    return rv;\n}\n\nconst EVP_PKEY_METHOD *EVP_PKEY_meth_get0(size_t idx)\n{\n    if (idx < OSSL_NELEM(standard_methods))\n        return (standard_methods[idx])();\n    if (app_pkey_methods == NULL)\n        return NULL;\n    idx -= OSSL_NELEM(standard_methods);\n    if (idx >= (size_t)sk_EVP_PKEY_METHOD_num(app_pkey_methods))\n        return NULL;\n    return sk_EVP_PKEY_METHOD_value(app_pkey_methods, idx);\n}\n#endif\n\nint EVP_PKEY_CTX_is_a(EVP_PKEY_CTX *ctx, const char *keytype)\n{\n#ifndef FIPS_MODULE\n    if (evp_pkey_ctx_is_legacy(ctx))\n        return (ctx->pmeth->pkey_id == evp_pkey_name2type(keytype));\n#endif\n    return EVP_KEYMGMT_is_a(ctx->keymgmt, keytype);\n}\n\nint EVP_PKEY_CTX_set_params(EVP_PKEY_CTX *ctx, const OSSL_PARAM *params)\n{\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->set_ctx_params != NULL)\n            return\n                ctx->op.kex.exchange->set_ctx_params(ctx->op.kex.algctx,\n                                                     params);\n        if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->set_ctx_params != NULL)\n            return\n                ctx->op.sig.signature->set_ctx_params(ctx->op.sig.algctx,\n                                                      params);\n        if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->set_ctx_params != NULL)\n            return\n                ctx->op.ciph.cipher->set_ctx_params(ctx->op.ciph.algctx,\n                                                    params);\n        if (EVP_PKEY_CTX_IS_GEN_OP(ctx)\n            && ctx->keymgmt != NULL\n            && ctx->keymgmt->gen_set_params != NULL)\n            return\n                evp_keymgmt_gen_set_params(ctx->keymgmt, ctx->op.keymgmt.genctx,\n                                           params);\n        if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n            && ctx->op.encap.kem != NULL\n            && ctx->op.encap.kem->set_ctx_params != NULL)\n            return\n                ctx->op.encap.kem->set_ctx_params(ctx->op.encap.algctx,\n                                                  params);\n        break;\n#ifndef FIPS_MODULE\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        return evp_pkey_ctx_set_params_to_ctrl(ctx, params);\n#endif\n    }\n    return 0;\n}\n\nint EVP_PKEY_CTX_get_params(EVP_PKEY_CTX *ctx, OSSL_PARAM *params)\n{\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->get_ctx_params != NULL)\n            return\n                ctx->op.kex.exchange->get_ctx_params(ctx->op.kex.algctx,\n                                                     params);\n        if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->get_ctx_params != NULL)\n            return\n                ctx->op.sig.signature->get_ctx_params(ctx->op.sig.algctx,\n                                                      params);\n        if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->get_ctx_params != NULL)\n            return\n                ctx->op.ciph.cipher->get_ctx_params(ctx->op.ciph.algctx,\n                                                    params);\n        if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n            && ctx->op.encap.kem != NULL\n            && ctx->op.encap.kem->get_ctx_params != NULL)\n            return\n                ctx->op.encap.kem->get_ctx_params(ctx->op.encap.algctx,\n                                                  params);\n        break;\n#ifndef FIPS_MODULE\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        return evp_pkey_ctx_get_params_to_ctrl(ctx, params);\n#endif\n    }\n    return 0;\n}\n\n#ifndef FIPS_MODULE\nconst OSSL_PARAM *EVP_PKEY_CTX_gettable_params(const EVP_PKEY_CTX *ctx)\n{\n    void *provctx;\n\n    if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEYEXCH_get0_provider(ctx->op.kex.exchange));\n        return ctx->op.kex.exchange->gettable_ctx_params(ctx->op.kex.algctx,\n                                                         provctx);\n    }\n    if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(\n                      EVP_SIGNATURE_get0_provider(ctx->op.sig.signature));\n        return ctx->op.sig.signature->gettable_ctx_params(ctx->op.sig.algctx,\n                                                          provctx);\n    }\n    if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(\n                      EVP_ASYM_CIPHER_get0_provider(ctx->op.ciph.cipher));\n        return ctx->op.ciph.cipher->gettable_ctx_params(ctx->op.ciph.algctx,\n                                                        provctx);\n    }\n    if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n        && ctx->op.encap.kem != NULL\n        && ctx->op.encap.kem->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEM_get0_provider(ctx->op.encap.kem));\n        return ctx->op.encap.kem->gettable_ctx_params(ctx->op.encap.algctx,\n                                                      provctx);\n    }\n    return NULL;\n}\n\nconst OSSL_PARAM *EVP_PKEY_CTX_settable_params(const EVP_PKEY_CTX *ctx)\n{\n    void *provctx;\n\n    if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->settable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEYEXCH_get0_provider(ctx->op.kex.exchange));\n        return ctx->op.kex.exchange->settable_ctx_params(ctx->op.kex.algctx,\n                                                         provctx);\n    }\n    if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->settable_ctx_params != NULL) {\n"}], "code": "static EVP_PKEY *evp_pkey_keygen(OSSL_LIB_CTX *libctx, const char *name,\n                                 const char *propq, const OSSL_PARAM *params)\n{\n    EVP_PKEY *pkey = NULL;\n    EVP_PKEY_CTX *ctx = EVP_PKEY_CTX_new_from_name(libctx, name, propq);\n\n    if (ctx != NULL\n            && EVP_PKEY_keygen_init(ctx) > 0\n            && EVP_PKEY_CTX_set_params(ctx, params))\n        (void)EVP_PKEY_generate(ctx, &pkey);\n\n    EVP_PKEY_CTX_free(ctx);\n    return pkey;\n}\n"}, "08A6FA08CFC72ED6": {"calls": [{"id": "2275C9E9CA6F81DF", "name": "ctx", "path": "openssl/crypto/store/store_lib.c", "start": {"line": 557, "col": 36}, "end": {"line": 557, "col": 36}, "code": "{\n    int ret = 1;\n\n    if (ctx->fetched_loader != NULL)\n        ret = ctx->loader->p_eof(ctx->loader_ctx);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->fetched_loader == NULL)\n        ret = ctx->loader->eof(ctx->loader_ctx);\n#endif\n    return ret != 0;\n}\n\nstatic int ossl_store_close_it(OSSL_STORE_CTX *ctx)\n{\n    int ret = 0;\n\n    if (ctx == NULL)\n        return 1;\n    OSSL_TRACE1(STORE, \"Closing %p\\n\", (void *)ctx->loader_ctx);\n\n    if (ctx->fetched_loader != NULL)\n        ret = ctx->loader->p_close(ctx->loader_ctx);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->fetched_loader == NULL)\n        ret = ctx->loader->closefn(ctx->loader_ctx);\n#endif\n\n    sk_OSSL_STORE_INFO_pop_free(ctx->cached_info, OSSL_STORE_INFO_free);\n    OSSL_STORE_LOADER_free(ctx->fetched_loader);\n    OPENSSL_free(ctx->properties);\n    ossl_pw_clear_passphrase_data(&ctx->pwdata);\n    return ret;\n}\n\nint OSSL_STORE_close(OSSL_STORE_CTX *ctx)\n{\n    int ret = ossl_store_close_it(ctx);\n\n    OPENSSL_free(ctx);\n    return ret;\n}\n\n/*\n * Functions to generate OSSL_STORE_INFOs, one function for each type we\n * support having in them as well as a generic constructor.\n *\n * In all cases, ownership of the object is transferred to the OSSL_STORE_INFO\n * and will therefore be freed when the OSSL_STORE_INFO is freed.\n */\nOSSL_STORE_INFO *OSSL_STORE_INFO_new(int type, void *data)\n{\n    OSSL_STORE_INFO *info = OPENSSL_zalloc(sizeof(*info));\n\n    if (info == NULL)\n        return NULL;\n\n    info->type = type;\n    info->_.data = data;\n    return info;\n}\n\nOSSL_STORE_INFO *OSSL_STORE_INFO_new_NAME(char *name)\n{\n    OSSL_STORE_INFO *info = OSSL_STORE_INFO_new(OSSL_STORE_INFO_NAME, NULL);\n\n    if (info == NULL) {\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_OSSL_STORE_LIB);\n        return NULL;\n    }\n\n    info->_.name.name = name;\n    info->_.name.desc = NULL;\n\n    return info;\n}\n\nint OSSL_STORE_INFO_set0_NAME_description(OSSL_STORE_INFO *info, char *desc)\n{\n    if (info->type != OSSL_STORE_INFO_NAME) {\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_PASSED_INVALID_ARGUMENT);\n        return 0;\n    }\n\n    info->_.name.desc = desc;\n\n    return 1;\n}\nOSSL_STORE_INFO *OSSL_STORE_INFO_new_PARAMS(EVP_PKEY *params)\n{\n    OSSL_STORE_INFO *info = OSSL_STORE_INFO_new(OSSL_STORE_INFO_PARAMS, params);\n\n    if (info == NULL)\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_OSSL_STORE_LIB);\n    return info;\n}\n\nOSSL_STORE_INFO *OSSL_STORE_INFO_new_PUBKEY(EVP_PKEY *pkey)\n{\n    OSSL_STORE_INFO *info = OSSL_STORE_INFO_new(OSSL_STORE_INFO_PUBKEY, pkey);\n\n    if (info == NULL)\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_OSSL_STORE_LIB);\n    return info;\n}\n\nOSSL_STORE_INFO *OSSL_STORE_INFO_new_PKEY(EVP_PKEY *pkey)\n{\n    OSSL_STORE_INFO *info = OSSL_STORE_INFO_new(OSSL_STORE_INFO_PKEY, pkey);\n\n    if (info == NULL)\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_OSSL_STORE_LIB);\n    return info;\n}\n\nOSSL_STORE_INFO *OSSL_STORE_INFO_new_CERT(X509 *x509)\n{\n    OSSL_STORE_INFO *info = OSSL_STORE_INFO_new(OSSL_STORE_INFO_CERT, x509);\n\n    if (info == NULL)\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_OSSL_STORE_LIB);\n    return info;\n}\n\nOSSL_STORE_INFO *OSSL_STORE_INFO_new_CRL(X509_CRL *crl)\n{\n    OSSL_STORE_INFO *info = OSSL_STORE_INFO_new(OSSL_STORE_INFO_CRL, crl);\n\n    if (info == NULL)\n        ERR_raise(ERR_LIB_OSSL_STORE, ERR_R_OSSL_STORE_LIB);\n    return info;\n}\n\n/*\n * Functions to try to extract data from an OSSL_STORE_INFO.\n */\nint OSSL_STORE_INFO_get_type(const OSSL_STORE_INFO *info)\n{\n    return info->type;\n}\n\nvoid *OSSL_STORE_INFO_get0_data(int type, const OSSL_STORE_INFO *info)\n{\n    if (info->type == type)\n        return info->_.data;\n    return NULL;\n}\n\nconst char *OSSL_STORE_INFO_get0_NAME(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_NAME)\n        return info->_.name.name;\n    return NULL;\n}\n\nchar *OSSL_STORE_INFO_get1_NAME(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_NAME)\n        return OPENSSL_strdup(info->_.name.name);\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_A_NAME);\n    return NULL;\n}\n\nconst char *OSSL_STORE_INFO_get0_NAME_description(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_NAME)\n        return info->_.name.desc;\n    return NULL;\n}\n\nchar *OSSL_STORE_INFO_get1_NAME_description(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_NAME)\n        return OPENSSL_strdup(info->_.name.desc ? info->_.name.desc : \"\");\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_A_NAME);\n    return NULL;\n}\n\nEVP_PKEY *OSSL_STORE_INFO_get0_PARAMS(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_PARAMS)\n        return info->_.params;\n    return NULL;\n}\n\nEVP_PKEY *OSSL_STORE_INFO_get1_PARAMS(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_PARAMS) {\n        EVP_PKEY_up_ref(info->_.params);\n        return info->_.params;\n    }\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_PARAMETERS);\n    return NULL;\n}\n\nEVP_PKEY *OSSL_STORE_INFO_get0_PUBKEY(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_PUBKEY)\n        return info->_.pubkey;\n    return NULL;\n}\n\nEVP_PKEY *OSSL_STORE_INFO_get1_PUBKEY(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_PUBKEY) {\n        EVP_PKEY_up_ref(info->_.pubkey);\n        return info->_.pubkey;\n    }\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_A_PUBLIC_KEY);\n    return NULL;\n}\n\nEVP_PKEY *OSSL_STORE_INFO_get0_PKEY(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_PKEY)\n        return info->_.pkey;\n    return NULL;\n}\n\nEVP_PKEY *OSSL_STORE_INFO_get1_PKEY(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_PKEY) {\n        EVP_PKEY_up_ref(info->_.pkey);\n        return info->_.pkey;\n    }\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_A_PRIVATE_KEY);\n    return NULL;\n}\n\nX509 *OSSL_STORE_INFO_get0_CERT(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_CERT)\n        return info->_.x509;\n    return NULL;\n}\n\nX509 *OSSL_STORE_INFO_get1_CERT(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_CERT) {\n        X509_up_ref(info->_.x509);\n        return info->_.x509;\n    }\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_A_CERTIFICATE);\n    return NULL;\n}\n\nX509_CRL *OSSL_STORE_INFO_get0_CRL(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_CRL)\n        return info->_.crl;\n    return NULL;\n}\n\nX509_CRL *OSSL_STORE_INFO_get1_CRL(const OSSL_STORE_INFO *info)\n{\n    if (info->type == OSSL_STORE_INFO_CRL) {\n        X509_CRL_up_ref(info->_.crl);\n        return info->_.crl;\n    }\n    ERR_raise(ERR_LIB_OSSL_STORE, OSSL_STORE_R_NOT_A_CRL);\n    return NULL;\n}\n\n/*\n * Free the OSSL_STORE_INFO\n */\nvoid OSSL_STORE_INFO_free(OSSL_STORE_INFO *info)\n{\n    if (info != NULL) {\n        switch (info->type) {\n        case OSSL_STORE_INFO_NAME:\n            OPENSSL_free(info->_.name.name);\n            OPENSSL_free(info->_.name.desc);\n            break;\n        case OSSL_STORE_INFO_PARAMS:\n            EVP_PKEY_free(info->_.params);\n            break;\n        case OSSL_STORE_INFO_PUBKEY:\n            EVP_PKEY_free(info->_.pubkey);\n            break;\n        case OSSL_STORE_INFO_PKEY:\n            EVP_PKEY_free(info->_.pkey);\n            break;\n        case OSSL_STORE_INFO_CERT:\n            X509_free(info->_.x509);\n            break;\n        case OSSL_STORE_INFO_CRL:\n            X509_CRL_free(info->_.crl);\n            break;\n        }\n        OPENSSL_free(info);\n    }\n}\n\nint OSSL_STORE_supports_search(OSSL_STORE_CTX *ctx, int search_type)\n{\n    int ret = 0;\n\n    if (ctx->fetched_loader != NULL) {\n        void *provctx =\n            ossl_provider_ctx(OSSL_STORE_LOADER_get0_provider(ctx->fetched_loader));\n        const OSSL_PARAM *params;\n        const OSSL_PARAM *p_subject = NULL;\n        const OSSL_PARAM *p_issuer = NULL;\n        const OSSL_PARAM *p_serial = NULL;\n        const OSSL_PARAM *p_fingerprint = NULL;\n        const OSSL_PARAM *p_alias = NULL;\n\n        if (ctx->fetched_loader->p_settable_ctx_params == NULL)\n            return 0;\n\n        params = ctx->fetched_loader->p_settable_ctx_params(provctx);\n        p_subject = OSSL_PARAM_locate_const(params, OSSL_STORE_PARAM_SUBJECT);\n        p_issuer = OSSL_PARAM_locate_const(params, OSSL_STORE_PARAM_ISSUER);\n        p_serial = OSSL_PARAM_locate_const(params, OSSL_STORE_PARAM_SERIAL);\n        p_fingerprint =\n            OSSL_PARAM_locate_const(params, OSSL_STORE_PARAM_FINGERPRINT);\n        p_alias = OSSL_PARAM_locate_const(params, OSSL_STORE_PARAM_ALIAS);\n\n        switch (search_type) {\n        case OSSL_STORE_SEARCH_BY_NAME:\n            ret = (p_subject != NULL);\n            break;\n        case OSSL_STORE_SEARCH_BY_ISSUER_SERIAL:\n            ret = (p_issuer != NULL && p_serial != NULL);\n            break;\n        case OSSL_STORE_SEARCH_BY_KEY_FINGERPRINT:\n            ret = (p_fingerprint != NULL);\n            break;\n        case OSSL_STORE_SEARCH_BY_ALIAS:\n            ret = (p_alias != NULL);\n            break;\n        }\n    }\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->fetched_loader == NULL) {\n        OSSL_STORE_SEARCH tmp_search;\n\n        if (ctx->loader->find == NULL)\n            return 0;\n        tmp_search.search_type = search_type;\n        ret = ctx->loader->find(NULL, &tmp_search);\n    }\n#endif\n    return ret;\n}\n\n/* Search term constructors */\nOSSL_STORE_SEARCH *OSSL_STORE_SEARCH_by_name(X509_NAME *name)\n{\n    OSSL_STORE_SEARCH *search = OPENSSL_zalloc(sizeof(*search));\n\n    if (search == NULL)\n        return NULL;\n\n    search->search_type = OSSL_STORE_SEARCH_BY_NAME;\n    search->name = name;\n    return search;\n}\n\nOSSL_STORE_SEARCH *OSSL_STORE_SEARCH_by_issuer_serial(X509_NAME *name,\n                                                      const ASN1_INTEGER *serial)\n{\n    OSSL_STORE_SEARCH *search = OPENSSL_zalloc(sizeof(*search));\n\n    if (search == NULL)\n        return NULL;\n\n    search->search_type = OSSL_STORE_SEARCH_BY_ISSUER_SERIAL;\n    search->name = name;\n    search->serial = serial;\n    return search;\n}\n\nOSSL_STORE_SEARCH *OSSL_STORE_SEARCH_by_key_fingerprint(const EVP_MD *digest,\n                                                        const unsigned char\n                                                        *bytes, size_t len)\n{\n    OSSL_STORE_SEARCH *search = OPENSSL_zalloc(sizeof(*search));\n\n    if (search == NULL)\n        return NULL;\n\n    if (digest != NULL && len != (size_t)EVP_MD_get_size(digest)) {\n        ERR_raise_data(ERR_LIB_OSSL_STORE,\n                       OSSL_STORE_R_FINGERPRINT_SIZE_DOES_NOT_MATCH_DIGEST,\n                       \"%s size is %d, fingerprint size is %zu\",\n                       EVP_MD_get0_name(digest), EVP_MD_get_size(digest), len);\n        OPENSSL_free(search);\n        return NULL;\n    }\n\n    search->search_type = OSSL_STORE_SEARCH_BY_KEY_FINGERPRINT;\n    search->digest = digest;\n    search->string = bytes;\n    search->stringlength = len;\n    return search;\n}\n\nOSSL_STORE_SEARCH *OSSL_STORE_SEARCH_by_alias(const char *alias)\n{\n    OSSL_STORE_SEARCH *search = OPENSSL_zalloc(sizeof(*search));\n\n    if (search == NULL)\n        return NULL;\n\n    search->search_type = OSSL_STORE_SEARCH_BY_ALIAS;\n    search->string = (const unsigned char *)alias;\n    search->stringlength = strlen(alias);\n    return search;\n}\n\n/* Search term destructor */\nvoid OSSL_STORE_SEARCH_free(OSSL_STORE_SEARCH *search)\n{\n    OPENSSL_free(search);\n}\n\n/* Search term accessors */\nint OSSL_STORE_SEARCH_get_type(const OSSL_STORE_SEARCH *criterion)\n{\n    return criterion->search_type;\n}\n\nX509_NAME *OSSL_STORE_SEARCH_get0_name(const OSSL_STORE_SEARCH *criterion)\n{\n    return criterion->name;\n}\n\nconst ASN1_INTEGER *OSSL_STORE_SEARCH_get0_serial(const OSSL_STORE_SEARCH\n                                                  *criterion)\n{\n    return criterion->serial;\n}\n\nconst unsigned char *OSSL_STORE_SEARCH_get0_bytes(const OSSL_STORE_SEARCH\n                                                  *criterion, size_t *length)\n{\n    *length = criterion->stringlength;\n    return criterion->string;\n}\n\nconst char *OSSL_STORE_SEARCH_get0_string(const OSSL_STORE_SEARCH *criterion)\n{\n    return (const char *)criterion->string;\n}\n\nconst EVP_MD *OSSL_STORE_SEARCH_get0_digest(const OSSL_STORE_SEARCH *criterion)\n{\n    return criterion->digest;\n}\n\nOSSL_STORE_CTX *OSSL_STORE_attach(BIO *bp, const char *scheme,\n                                  OSSL_LIB_CTX *libctx, const char *propq,\n                                  const UI_METHOD *ui_method, void *ui_data,\n                                  const OSSL_PARAM params[],\n                                  OSSL_STORE_post_process_info_fn post_process,\n                                  void *post_process_data)\n{\n    const OSSL_STORE_LOADER *loader = NULL;\n    OSSL_STORE_LOADER *fetched_loader = NULL;\n    OSSL_STORE_LOADER_CTX *loader_ctx = NULL;\n    OSSL_STORE_CTX *ctx = NULL;\n\n    if (scheme == NULL)\n        scheme = \"file\";\n\n    OSSL_TRACE1(STORE, \"Looking up scheme %s\\n\", scheme);\n    ERR_set_mark();\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if ((loader = ossl_store_get0_loader_int(scheme)) != NULL)\n        loader_ctx = loader->attach(loader, bp, libctx, propq,\n                                    ui_method, ui_data);\n#endif\n    if (loader == NULL\n        && (fetched_loader =\n            OSSL_STORE_LOADER_fetch(libctx, scheme, propq)) != NULL) {\n        const OSSL_PROVIDER *provider =\n            OSSL_STORE_LOADER_get0_provider(fetched_loader);\n        void *provctx = OSSL_PROVIDER_get0_provider_ctx(provider);\n        OSSL_CORE_BIO *cbio = ossl_core_bio_new_from_bio(bp);\n\n        if (cbio == NULL\n            || (loader_ctx = fetched_loader->p_attach(provctx, cbio)) == NULL) {\n            OSSL_STORE_LOADER_free(fetched_loader);\n            fetched_loader = NULL;\n        } else if (!loader_set_params(fetched_loader, loader_ctx,\n                                      params, propq)) {\n            (void)fetched_loader->p_close(loader_ctx);\n            OSSL_STORE_LOADER_free(fetched_loader);\n            fetched_loader = NULL;\n        }\n        loader = fetched_loader;\n        ossl_core_bio_free(cbio);\n    }\n\n    if (loader_ctx == NULL) {\n        ERR_clear_last_mark();\n        return NULL;\n    }\n\n    if ((ctx = OPENSSL_zalloc(sizeof(*ctx))) == NULL) {\n        ERR_clear_last_mark();\n        return NULL;\n    }\n\n    if (ui_method != NULL\n        && !ossl_pw_set_ui_method(&ctx->pwdata, ui_method, ui_data)) {\n        ERR_clear_last_mark();\n        OPENSSL_free(ctx);\n        return NULL;\n    }\n\n    ctx->fetched_loader = fetched_loader;\n    ctx->loader = loader;\n    ctx->loader_ctx = loader_ctx;\n    ctx->post_process = post_process;\n    ctx->post_process_data = post_process_data;\n\n    /*\n     * ossl_store_get0_loader_int will raise an error if the loader for\n     * the scheme cannot be retrieved. But if a loader was successfully\n     * fetched then we remove this error from the error stack.\n     */\n    ERR_pop_to_mark();\n\n    return ctx;\n}\n"}, {"id": "74EB0EF3BACC34F5", "name": "ossl_store_loader_st::p_eof", "path": "openssl/crypto/store/store_local.h", "start": {"line": 112, "col": 29}, "end": {"line": 112, "col": 29}, "code": "    OSSL_FUNC_store_close_fn *p_close;\n    OSSL_FUNC_store_export_object_fn *p_export_object;\n    OSSL_FUNC_store_delete_fn *p_delete;\n    OSSL_FUNC_store_open_ex_fn *p_open_ex;\n};\nDEFINE_LHASH_OF_EX(OSSL_STORE_LOADER);\n\nconst OSSL_STORE_LOADER *ossl_store_get0_loader_int(const char *scheme);\nvoid ossl_store_destroy_loaders_int(void);\n\n#ifdef OPENSSL_NO_DEPRECATED_3_0\n/* struct ossl_store_loader_ctx_st is defined differently by each loader */\ntypedef struct ossl_store_loader_ctx_st OSSL_STORE_LOADER_CTX;\n#endif\n\n/*-\n *  OSSL_STORE_CTX stuff\n *  ---------------------\n */\n\nstruct ossl_store_ctx_st {\n    const OSSL_STORE_LOADER *loader; /* legacy */\n    OSSL_STORE_LOADER *fetched_loader;\n    OSSL_STORE_LOADER_CTX *loader_ctx;\n    OSSL_STORE_post_process_info_fn post_process;\n    void *post_process_data;\n    int expected_type;\n\n    char *properties;\n\n    /* 0 before the first STORE_load(), 1 otherwise */\n    int loading;\n    /* 1 on load error, only valid for fetched loaders */\n    int error_flag;\n\n    /*\n     * Cache of stuff, to be able to return the contents of a PKCS#12\n     * blob, one object at a time.\n     */\n    STACK_OF(OSSL_STORE_INFO) *cached_info;\n\n    struct ossl_passphrase_data_st pwdata;\n};\n\n/*-\n *  'file' scheme stuff\n *  -------------------\n */\n\nOSSL_STORE_LOADER_CTX *ossl_store_file_attach_pem_bio_int(BIO *bp);\nint ossl_store_file_detach_pem_bio_int(OSSL_STORE_LOADER_CTX *ctx);\n\n/*-\n * Provider stuff\n * -------------------\n */\nOSSL_STORE_LOADER *ossl_store_loader_fetch(OSSL_LIB_CTX *libctx,\n                                           const char *scheme,\n                                           const char *properties);\n\n/* Standard function to handle the result from OSSL_FUNC_store_load() */\nstruct ossl_load_result_data_st {\n    OSSL_STORE_INFO *v;          /* To be filled in */\n    OSSL_STORE_CTX *ctx;\n};\nOSSL_CALLBACK ossl_store_handle_load_result;\n"}, {"id": "7E752F75019F5DE1", "name": "ossl_store_loader_st::eof", "path": "openssl/crypto/store/store_local.h", "start": {"line": 93, "col": 23}, "end": {"line": 93, "col": 23}, "code": "    OSSL_STORE_error_fn error;\n    OSSL_STORE_close_fn closefn;\n    OSSL_STORE_open_ex_fn open_ex;\n#endif\n\n    /* Provider stuff */\n    OSSL_PROVIDER *prov;\n    int scheme_id;\n    const char *propdef;\n    const char *description;\n\n    CRYPTO_REF_COUNT refcnt;\n\n    OSSL_FUNC_store_open_fn *p_open;\n    OSSL_FUNC_store_attach_fn *p_attach;\n    OSSL_FUNC_store_settable_ctx_params_fn *p_settable_ctx_params;\n    OSSL_FUNC_store_set_ctx_params_fn *p_set_ctx_params;\n    OSSL_FUNC_store_load_fn *p_load;\n    OSSL_FUNC_store_eof_fn *p_eof;\n    OSSL_FUNC_store_close_fn *p_close;\n    OSSL_FUNC_store_export_object_fn *p_export_object;\n    OSSL_FUNC_store_delete_fn *p_delete;\n    OSSL_FUNC_store_open_ex_fn *p_open_ex;\n};\nDEFINE_LHASH_OF_EX(OSSL_STORE_LOADER);\n\nconst OSSL_STORE_LOADER *ossl_store_get0_loader_int(const char *scheme);\nvoid ossl_store_destroy_loaders_int(void);\n\n#ifdef OPENSSL_NO_DEPRECATED_3_0\n/* struct ossl_store_loader_ctx_st is defined differently by each loader */\ntypedef struct ossl_store_loader_ctx_st OSSL_STORE_LOADER_CTX;\n#endif\n\n/*-\n *  OSSL_STORE_CTX stuff\n *  ---------------------\n */\n\nstruct ossl_store_ctx_st {\n    const OSSL_STORE_LOADER *loader; /* legacy */\n    OSSL_STORE_LOADER *fetched_loader;\n    OSSL_STORE_LOADER_CTX *loader_ctx;\n    OSSL_STORE_post_process_info_fn post_process;\n    void *post_process_data;\n    int expected_type;\n\n    char *properties;\n\n    /* 0 before the first STORE_load(), 1 otherwise */\n    int loading;\n    /* 1 on load error, only valid for fetched loaders */\n    int error_flag;\n\n    /*\n     * Cache of stuff, to be able to return the contents of a PKCS#12\n     * blob, one object at a time.\n     */\n    STACK_OF(OSSL_STORE_INFO) *cached_info;\n\n    struct ossl_passphrase_data_st pwdata;\n};\n\n/*-\n *  'file' scheme stuff\n *  -------------------\n */\n\nOSSL_STORE_LOADER_CTX *ossl_store_file_attach_pem_bio_int(BIO *bp);\nint ossl_store_file_detach_pem_bio_int(OSSL_STORE_LOADER_CTX *ctx);\n\n/*-\n * Provider stuff\n * -------------------\n */\nOSSL_STORE_LOADER *ossl_store_loader_fetch(OSSL_LIB_CTX *libctx,\n                                           const char *scheme,\n                                           const char *properties);\n\n/* Standard function to handle the result from OSSL_FUNC_store_load() */\nstruct ossl_load_result_data_st {\n    OSSL_STORE_INFO *v;          /* To be filled in */\n    OSSL_STORE_CTX *ctx;\n};\nOSSL_CALLBACK ossl_store_handle_load_result;\n"}], "code": "int OSSL_STORE_eof(OSSL_STORE_CTX *ctx)\n{\n    int ret = 1;\n\n    if (ctx->fetched_loader != NULL)\n        ret = ctx->loader->p_eof(ctx->loader_ctx);\n#ifndef OPENSSL_NO_DEPRECATED_3_0\n    if (ctx->fetched_loader == NULL)\n        ret = ctx->loader->eof(ctx->loader_ctx);\n#endif\n    return ret != 0;\n}\n"}, "6563624997F5DB4A": {"calls": [{"id": "C2B6C1C5FCF682E3", "name": "ossl_x509v3_cache_extensions", "path": "openssl/crypto/x509/v3_purp.c", "start": {"line": 400, "col": 1}, "end": {"line": 639, "col": 1}, "code": "{\n    BASIC_CONSTRAINTS *bs;\n    PROXY_CERT_INFO_EXTENSION *pci;\n    ASN1_BIT_STRING *usage;\n    ASN1_BIT_STRING *ns;\n    EXTENDED_KEY_USAGE *extusage;\n    int i;\n    int res;\n\n#ifdef tsan_ld_acq\n    /* Fast lock-free check, see end of the function for details. */\n    if (tsan_ld_acq((TSAN_QUALIFIER int *)&x->ex_cached))\n        return (x->ex_flags & EXFLAG_INVALID) == 0;\n#endif\n\n    if (!CRYPTO_THREAD_write_lock(x->lock))\n        return 0;\n    if ((x->ex_flags & EXFLAG_SET) != 0) { /* Cert has already been processed */\n        CRYPTO_THREAD_unlock(x->lock);\n        return (x->ex_flags & EXFLAG_INVALID) == 0;\n    }\n\n    ERR_set_mark();\n\n    /* Cache the SHA1 digest of the cert */\n    if (!X509_digest(x, EVP_sha1(), x->sha1_hash, NULL))\n        x->ex_flags |= EXFLAG_NO_FINGERPRINT;\n\n    /* V1 should mean no extensions ... */\n    if (X509_get_version(x) == X509_VERSION_1)\n        x->ex_flags |= EXFLAG_V1;\n\n    /* Handle basic constraints */\n    x->ex_pathlen = -1;\n    if ((bs = X509_get_ext_d2i(x, NID_basic_constraints, &i, NULL)) != NULL) {\n        if (bs->ca)\n            x->ex_flags |= EXFLAG_CA;\n        if (bs->pathlen != NULL) {\n            /*\n             * The error case !bs->ca is checked by check_chain()\n             * in case ctx->param->flags & X509_V_FLAG_X509_STRICT\n             */\n            if (bs->pathlen->type == V_ASN1_NEG_INTEGER) {\n                ERR_raise(ERR_LIB_X509V3, X509V3_R_NEGATIVE_PATHLEN);\n                x->ex_flags |= EXFLAG_INVALID;\n            } else {\n                x->ex_pathlen = ASN1_INTEGER_get(bs->pathlen);\n            }\n        }\n        BASIC_CONSTRAINTS_free(bs);\n        x->ex_flags |= EXFLAG_BCONS;\n    } else if (i != -1) {\n        x->ex_flags |= EXFLAG_INVALID;\n    }\n\n    /* Handle proxy certificates */\n    if ((pci = X509_get_ext_d2i(x, NID_proxyCertInfo, &i, NULL)) != NULL) {\n        if ((x->ex_flags & EXFLAG_CA) != 0\n            || X509_get_ext_by_NID(x, NID_subject_alt_name, -1) >= 0\n            || X509_get_ext_by_NID(x, NID_issuer_alt_name, -1) >= 0) {\n            x->ex_flags |= EXFLAG_INVALID;\n        }\n        if (pci->pcPathLengthConstraint != NULL)\n            x->ex_pcpathlen = ASN1_INTEGER_get(pci->pcPathLengthConstraint);\n        else\n            x->ex_pcpathlen = -1;\n        PROXY_CERT_INFO_EXTENSION_free(pci);\n        x->ex_flags |= EXFLAG_PROXY;\n    } else if (i != -1) {\n        x->ex_flags |= EXFLAG_INVALID;\n    }\n\n    /* Handle (basic) key usage */\n    if ((usage = X509_get_ext_d2i(x, NID_key_usage, &i, NULL)) != NULL) {\n        x->ex_kusage = 0;\n        if (usage->length > 0) {\n            x->ex_kusage = usage->data[0];\n            if (usage->length > 1)\n                x->ex_kusage |= usage->data[1] << 8;\n        }\n        x->ex_flags |= EXFLAG_KUSAGE;\n        ASN1_BIT_STRING_free(usage);\n        /* Check for empty key usage according to RFC 5280 section 4.2.1.3 */\n        if (x->ex_kusage == 0) {\n            ERR_raise(ERR_LIB_X509V3, X509V3_R_EMPTY_KEY_USAGE);\n            x->ex_flags |= EXFLAG_INVALID;\n        }\n    } else if (i != -1) {\n        x->ex_flags |= EXFLAG_INVALID;\n    }\n\n    /* Handle extended key usage */\n    x->ex_xkusage = 0;\n    if ((extusage = X509_get_ext_d2i(x, NID_ext_key_usage, &i, NULL)) != NULL) {\n        x->ex_flags |= EXFLAG_XKUSAGE;\n        for (i = 0; i < sk_ASN1_OBJECT_num(extusage); i++) {\n            switch (OBJ_obj2nid(sk_ASN1_OBJECT_value(extusage, i))) {\n            case NID_server_auth:\n                x->ex_xkusage |= XKU_SSL_SERVER;\n                break;\n            case NID_client_auth:\n                x->ex_xkusage |= XKU_SSL_CLIENT;\n                break;\n            case NID_email_protect:\n                x->ex_xkusage |= XKU_SMIME;\n                break;\n            case NID_code_sign:\n                x->ex_xkusage |= XKU_CODE_SIGN;\n                break;\n            case NID_ms_sgc:\n            case NID_ns_sgc:\n                x->ex_xkusage |= XKU_SGC;\n                break;\n            case NID_OCSP_sign:\n                x->ex_xkusage |= XKU_OCSP_SIGN;\n                break;\n            case NID_time_stamp:\n                x->ex_xkusage |= XKU_TIMESTAMP;\n                break;\n            case NID_dvcs:\n                x->ex_xkusage |= XKU_DVCS;\n                break;\n            case NID_anyExtendedKeyUsage:\n                x->ex_xkusage |= XKU_ANYEKU;\n                break;\n            default:\n                /* Ignore unknown extended key usage */\n                break;\n            }\n        }\n        sk_ASN1_OBJECT_pop_free(extusage, ASN1_OBJECT_free);\n    } else if (i != -1) {\n        x->ex_flags |= EXFLAG_INVALID;\n    }\n\n    /* Handle legacy Netscape extension */\n    if ((ns = X509_get_ext_d2i(x, NID_netscape_cert_type, &i, NULL)) != NULL) {\n        if (ns->length > 0)\n            x->ex_nscert = ns->data[0];\n        else\n            x->ex_nscert = 0;\n        x->ex_flags |= EXFLAG_NSCERT;\n        ASN1_BIT_STRING_free(ns);\n    } else if (i != -1) {\n        x->ex_flags |= EXFLAG_INVALID;\n    }\n\n    /* Handle subject key identifier and issuer/authority key identifier */\n    x->skid = X509_get_ext_d2i(x, NID_subject_key_identifier, &i, NULL);\n    if (x->skid == NULL && i != -1)\n        x->ex_flags |= EXFLAG_INVALID;\n\n    x->akid = X509_get_ext_d2i(x, NID_authority_key_identifier, &i, NULL);\n    if (x->akid == NULL && i != -1)\n        x->ex_flags |= EXFLAG_INVALID;\n\n    /* Check if subject name matches issuer */\n    if (X509_NAME_cmp(X509_get_subject_name(x), X509_get_issuer_name(x)) == 0) {\n        x->ex_flags |= EXFLAG_SI; /* Cert is self-issued */\n        if (X509_check_akid(x, x->akid) == X509_V_OK /* SKID matches AKID */\n                /* .. and the signature alg matches the PUBKEY alg: */\n                && check_sig_alg_match(X509_get0_pubkey(x), x) == X509_V_OK)\n            x->ex_flags |= EXFLAG_SS; /* indicate self-signed */\n        /* This is very related to ossl_x509_likely_issued(x, x) == X509_V_OK */\n    }\n\n    /* Handle subject alternative names and various other extensions */\n    x->altname = X509_get_ext_d2i(x, NID_subject_alt_name, &i, NULL);\n    if (x->altname == NULL && i != -1)\n        x->ex_flags |= EXFLAG_INVALID;\n    x->nc = X509_get_ext_d2i(x, NID_name_constraints, &i, NULL);\n    if (x->nc == NULL && i != -1)\n        x->ex_flags |= EXFLAG_INVALID;\n\n    /* Handle CRL distribution point entries */\n    res = setup_crldp(x);\n    if (res == 0)\n        x->ex_flags |= EXFLAG_INVALID;\n\n#ifndef OPENSSL_NO_RFC3779\n    x->rfc3779_addr = X509_get_ext_d2i(x, NID_sbgp_ipAddrBlock, &i, NULL);\n    if (x->rfc3779_addr == NULL && i != -1)\n        x->ex_flags |= EXFLAG_INVALID;\n    x->rfc3779_asid = X509_get_ext_d2i(x, NID_sbgp_autonomousSysNum, &i, NULL);\n    if (x->rfc3779_asid == NULL && i != -1)\n        x->ex_flags |= EXFLAG_INVALID;\n#endif\n    for (i = 0; i < X509_get_ext_count(x); i++) {\n        X509_EXTENSION *ex = X509_get_ext(x, i);\n        int nid = OBJ_obj2nid(X509_EXTENSION_get_object(ex));\n\n        if (nid == NID_freshest_crl)\n            x->ex_flags |= EXFLAG_FRESHEST;\n        if (!X509_EXTENSION_get_critical(ex))\n            continue;\n        if (!X509_supported_extension(ex)) {\n            x->ex_flags |= EXFLAG_CRITICAL;\n            break;\n        }\n        switch (nid) {\n        case NID_basic_constraints:\n            x->ex_flags |= EXFLAG_BCONS_CRITICAL;\n            break;\n        case NID_authority_key_identifier:\n            x->ex_flags |= EXFLAG_AKID_CRITICAL;\n            break;\n        case NID_subject_key_identifier:\n            x->ex_flags |= EXFLAG_SKID_CRITICAL;\n            break;\n        case NID_subject_alt_name:\n            x->ex_flags |= EXFLAG_SAN_CRITICAL;\n            break;\n        default:\n            break;\n        }\n    }\n\n    /* Set x->siginf, ignoring errors due to unsupported algos */\n    (void)ossl_x509_init_sig_info(x);\n\n    x->ex_flags |= EXFLAG_SET; /* Indicate that cert has been processed */\n#ifdef tsan_st_rel\n    tsan_st_rel((TSAN_QUALIFIER int *)&x->ex_cached, 1);\n    /*\n     * Above store triggers fast lock-free check in the beginning of the\n     * function. But one has to ensure that the structure is \"stable\", i.e.\n     * all stores are visible on all processors. Hence the release fence.\n     */\n#endif\n    ERR_pop_to_mark();\n\n    if ((x->ex_flags & EXFLAG_INVALID) == 0) {\n        CRYPTO_THREAD_unlock(x->lock);\n        return 1;\n    }\n    CRYPTO_THREAD_unlock(x->lock);\n    ERR_raise(ERR_LIB_X509V3, X509V3_R_INVALID_CERTIFICATE);\n    return 0;\n}\n\n/*-\n * CA checks common to all purposes\n * return codes:\n * 0 not a CA\n * 1 is a CA\n * 2 Only possible in older versions of openSSL when basicConstraints are absent\n *   new versions will not return this value. May be a CA\n * 3 basicConstraints absent but self-signed V1.\n * 4 basicConstraints absent but keyUsage present and keyCertSign asserted.\n * 5 Netscape specific CA Flags present\n */\n\nstatic int check_ca(const X509 *x)\n{\n    /* keyUsage if present should allow cert signing */\n    if (ku_reject(x, KU_KEY_CERT_SIGN))\n        return 0;\n    if ((x->ex_flags & EXFLAG_BCONS) != 0) {\n        /* If basicConstraints says not a CA then say so */\n        return (x->ex_flags & EXFLAG_CA) != 0;\n    } else {\n        /* We support V1 roots for...  uh, I don't really know why. */\n        if ((x->ex_flags & V1_ROOT) == V1_ROOT)\n            return 3;\n        /*\n         * If key usage present it must have certSign so tolerate it\n         */\n        else if ((x->ex_flags & EXFLAG_KUSAGE) != 0)\n            return 4;\n        /* Older certificates could have Netscape-specific CA types */\n        else if ((x->ex_flags & EXFLAG_NSCERT) != 0\n                 && (x->ex_nscert & NS_ANY_CA) != 0)\n            return 5;\n        /* Can this still be regarded a CA certificate?  I doubt it. */\n        return 0;\n    }\n}\n\nvoid X509_set_proxy_flag(X509 *x)\n{\n    if (CRYPTO_THREAD_write_lock(x->lock)) {\n        x->ex_flags |= EXFLAG_PROXY;\n        CRYPTO_THREAD_unlock(x->lock);\n    }\n}\n\nvoid X509_set_proxy_pathlen(X509 *x, long l)\n{\n    x->ex_pcpathlen = l;\n}\n\nint X509_check_ca(X509 *x)\n{\n    /* Note 0 normally means \"not a CA\" - but in this case means error. */\n    if (!ossl_x509v3_cache_extensions(x))\n        return 0;\n\n    return check_ca(x);\n}\n\n/* Check SSL CA: common checks for SSL client and server. */\nstatic int check_ssl_ca(const X509 *x)\n{\n    int ca_ret = check_ca(x);\n\n    if (ca_ret == 0)\n        return 0;\n    /* Check nsCertType if present */\n    return ca_ret != 5 || (x->ex_nscert & NS_SSL_CA) != 0;\n}\n\nstatic int check_purpose_ssl_client(const X509_PURPOSE *xp, const X509 *x,\n                                    int non_leaf)\n{\n    if (xku_reject(x, XKU_SSL_CLIENT))\n        return 0;\n    if (non_leaf)\n        return check_ssl_ca(x);\n    /* We need to do digital signatures or key agreement */\n    if (ku_reject(x, KU_DIGITAL_SIGNATURE | KU_KEY_AGREEMENT))\n        return 0;\n    /* nsCertType if present should allow SSL client use */\n    if (ns_reject(x, NS_SSL_CLIENT))\n        return 0;\n    return 1;\n}\n\n/*\n * Key usage needed for TLS/SSL server: digital signature, encipherment or\n * key agreement. The ssl code can check this more thoroughly for individual\n * key types.\n */\n#define KU_TLS \\\n    KU_DIGITAL_SIGNATURE | KU_KEY_ENCIPHERMENT | KU_KEY_AGREEMENT\n\nstatic int check_purpose_ssl_server(const X509_PURPOSE *xp, const X509 *x,\n                                    int non_leaf)\n{\n    if (xku_reject(x, XKU_SSL_SERVER | XKU_SGC))\n        return 0;\n    if (non_leaf)\n        return check_ssl_ca(x);\n\n    if (ns_reject(x, NS_SSL_SERVER))\n        return 0;\n    if (ku_reject(x, KU_TLS))\n        return 0;\n\n    return 1;\n\n}\n\nstatic int check_purpose_ns_ssl_server(const X509_PURPOSE *xp, const X509 *x,\n                                       int non_leaf)\n{\n    int ret = check_purpose_ssl_server(xp, x, non_leaf);\n\n    if (!ret || non_leaf)\n        return ret;\n    /* We need to encipher or Netscape complains */\n    return ku_reject(x, KU_KEY_ENCIPHERMENT) ? 0 : ret;\n}\n\n/* common S/MIME checks */\nstatic int purpose_smime(const X509 *x, int non_leaf)\n{\n    if (xku_reject(x, XKU_SMIME))\n        return 0;\n    if (non_leaf) {\n        int ca_ret = check_ca(x);\n\n        if (ca_ret == 0)\n            return 0;\n        /* Check nsCertType if present */\n        if (ca_ret != 5 || (x->ex_nscert & NS_SMIME_CA) != 0)\n            return ca_ret;\n        else\n            return 0;\n    }\n    if ((x->ex_flags & EXFLAG_NSCERT) != 0) {\n        if ((x->ex_nscert & NS_SMIME) != 0)\n            return 1;\n        /* Workaround for some buggy certificates */\n        return (x->ex_nscert & NS_SSL_CLIENT) != 0 ? 2 : 0;\n    }\n    return 1;\n}\n\nstatic int check_purpose_smime_sign(const X509_PURPOSE *xp, const X509 *x,\n                                    int non_leaf)\n{\n    int ret = purpose_smime(x, non_leaf);\n\n    if (!ret || non_leaf)\n        return ret;\n    return ku_reject(x, KU_DIGITAL_SIGNATURE | KU_NON_REPUDIATION) ? 0 : ret;\n}\n\nstatic int check_purpose_smime_encrypt(const X509_PURPOSE *xp, const X509 *x,\n                                       int non_leaf)\n{\n    int ret = purpose_smime(x, non_leaf);\n\n    if (!ret || non_leaf)\n        return ret;\n    return ku_reject(x, KU_KEY_ENCIPHERMENT) ? 0 : ret;\n}\n\nstatic int check_purpose_crl_sign(const X509_PURPOSE *xp, const X509 *x,\n                                  int non_leaf)\n{\n    if (non_leaf) {\n        int ca_ret = check_ca(x);\n\n        return ca_ret == 2 ? 0 : ca_ret;\n    }\n    return !ku_reject(x, KU_CRL_SIGN);\n}\n\n/*\n * OCSP helper: this is *not* a full OCSP check. It just checks that each CA\n * is valid. Additional checks must be made on the chain.\n */\nstatic int check_purpose_ocsp_helper(const X509_PURPOSE *xp, const X509 *x,\n                                     int non_leaf)\n{\n    /*\n     * Must be a valid CA.  Should we really support the \"I don't know\" value\n     * (2)?\n     */\n    if (non_leaf)\n        return check_ca(x);\n    /* Leaf certificate is checked in OCSP_verify() */\n    return 1;\n}\n\nstatic int check_purpose_timestamp_sign(const X509_PURPOSE *xp, const X509 *x,\n                                        int non_leaf)\n{\n    int i_ext;\n\n    /*\n     * If non_leaf is true we must check if this is a valid CA certificate.\n     * The extra requirements by the CA/Browser Forum are not checked.\n     */\n    if (non_leaf)\n        return check_ca(x);\n\n    /*\n     * Key Usage is checked according to RFC 5280 and\n     * Extended Key Usage attributes is checked according to RFC 3161.\n     * The extra (and somewhat conflicting) CA/Browser Forum\n     * Baseline Requirements for the Issuance and Management of\n     * Publicly\u2010Trusted Code Signing Certificates, Version 3.0.0,\n     * Section 7.1.2.3: Code signing and Timestamp Certificate are not checked.\n     */\n    /*\n     * Check the optional key usage field:\n     * if Key Usage is present, it must be one of digitalSignature\n     * and/or nonRepudiation (other values are not consistent and shall\n     * be rejected).\n     */\n    if ((x->ex_flags & EXFLAG_KUSAGE) != 0\n        && ((x->ex_kusage & ~(KU_NON_REPUDIATION | KU_DIGITAL_SIGNATURE)) ||\n            !(x->ex_kusage & (KU_NON_REPUDIATION | KU_DIGITAL_SIGNATURE))))\n        return 0;\n\n    /* Only timestamp key usage is permitted and it's required. */\n    if ((x->ex_flags & EXFLAG_XKUSAGE) == 0 || x->ex_xkusage != XKU_TIMESTAMP)\n        return 0;\n\n    /* Extended Key Usage MUST be critical */\n    i_ext = X509_get_ext_by_NID(x, NID_ext_key_usage, -1);\n    if (i_ext >= 0\n            && !X509_EXTENSION_get_critical(X509_get_ext((X509 *)x, i_ext)))\n        return 0;\n    return 1;\n}\n\nstatic int check_purpose_code_sign(const X509_PURPOSE *xp, const X509 *x,\n                                   int non_leaf)\n{\n    int i_ext;\n\n    /*\n     * If non_leaf is true we must check if this is a valid CA certificate.\n     * The extra requirements by the CA/Browser Forum are not checked.\n     */\n    if (non_leaf)\n        return check_ca(x);\n\n    /*\n     * Check the key usage and extended key usage fields:\n     *\n     * Reference: CA/Browser Forum,\n     * Baseline Requirements for the Issuance and Management of\n     * Publicly\u2010Trusted Code Signing Certificates, Version 3.0.0,\n     * Section 7.1.2.3: Code signing and Timestamp Certificate\n     *\n     * Checking covers Key Usage and Extended Key Usage attributes.\n     * The certificatePolicies, cRLDistributionPoints (CDP), and\n     * authorityInformationAccess (AIA) extensions are so far not checked.\n     */\n    /* Key Usage */\n    if ((x->ex_flags & EXFLAG_KUSAGE) == 0)\n        return 0;\n    if ((x->ex_kusage & KU_DIGITAL_SIGNATURE) == 0)\n        return 0;\n    if ((x->ex_kusage & (KU_KEY_CERT_SIGN | KU_CRL_SIGN)) != 0)\n        return 0;\n\n    /* Key Usage MUST be critical */\n    i_ext = X509_get_ext_by_NID(x, NID_key_usage, -1);\n    if (i_ext < 0)\n        return 0;\n    if (i_ext >= 0) {\n        X509_EXTENSION *ext = X509_get_ext((X509 *)x, i_ext);\n        if (!X509_EXTENSION_get_critical(ext))\n            return 0;\n    }\n\n    /* Extended Key Usage */\n    if ((x->ex_flags & EXFLAG_XKUSAGE) == 0)\n        return 0;\n    if ((x->ex_xkusage & XKU_CODE_SIGN) == 0)\n        return 0;\n    if ((x->ex_xkusage & (XKU_ANYEKU | XKU_SSL_SERVER)) != 0)\n        return 0;\n\n    return 1;\n\n}\n\nstatic int no_check_purpose(const X509_PURPOSE *xp, const X509 *x,\n                            int non_leaf)\n{\n    return 1;\n}\n\n/*-\n * Various checks to see if one certificate potentially issued the second.\n * This can be used to prune a set of possible issuer certificates which\n * have been looked up using some simple method such as by subject name.\n * These are:\n * 1. issuer_name(subject) == subject_name(issuer)\n * 2. If akid(subject) exists, it matches the respective issuer fields.\n * 3. subject signature algorithm == issuer public key algorithm\n * 4. If key_usage(issuer) exists, it allows for signing subject.\n * Note that this does not include actually checking the signature.\n * Returns 0 for OK, or positive for reason for mismatch\n * where reason codes match those for X509_verify_cert().\n */\nint X509_check_issued(X509 *issuer, X509 *subject)\n{\n    int ret;\n\n    if ((ret = ossl_x509_likely_issued(issuer, subject)) != X509_V_OK)\n        return ret;\n    return ossl_x509_signing_allowed(issuer, subject);\n}\n\n/* do the checks 1., 2., and 3. as described above for X509_check_issued() */\nint ossl_x509_likely_issued(X509 *issuer, X509 *subject)\n{\n    int ret;\n\n    if (X509_NAME_cmp(X509_get_subject_name(issuer),\n                      X509_get_issuer_name(subject)) != 0)\n        return X509_V_ERR_SUBJECT_ISSUER_MISMATCH;\n\n    /* set issuer->skid and subject->akid */\n    if (!ossl_x509v3_cache_extensions(issuer)\n            || !ossl_x509v3_cache_extensions(subject))\n        return X509_V_ERR_UNSPECIFIED;\n\n    ret = X509_check_akid(issuer, subject->akid);\n    if (ret != X509_V_OK)\n        return ret;\n\n    /* Check if the subject signature alg matches the issuer's PUBKEY alg */\n    return check_sig_alg_match(X509_get0_pubkey(issuer), subject);\n}\n\n/*-\n * Check if certificate I<issuer> is allowed to issue certificate I<subject>\n * according to the B<keyUsage> field of I<issuer> if present\n * depending on any proxyCertInfo extension of I<subject>.\n * Returns 0 for OK, or positive for reason for rejection\n * where reason codes match those for X509_verify_cert().\n */\nint ossl_x509_signing_allowed(const X509 *issuer, const X509 *subject)\n{\n    if ((subject->ex_flags & EXFLAG_PROXY) != 0) {\n        if (ku_reject(issuer, KU_DIGITAL_SIGNATURE))\n            return X509_V_ERR_KEYUSAGE_NO_DIGITAL_SIGNATURE;\n    } else if (ku_reject(issuer, KU_KEY_CERT_SIGN)) {\n        return X509_V_ERR_KEYUSAGE_NO_CERTSIGN;\n    }\n    return X509_V_OK;\n}\n\nint X509_check_akid(const X509 *issuer, const AUTHORITY_KEYID *akid)\n{\n    if (akid == NULL)\n        return X509_V_OK;\n\n    /* Check key ids (if present) */\n    if (akid->keyid && issuer->skid &&\n        ASN1_OCTET_STRING_cmp(akid->keyid, issuer->skid))\n        return X509_V_ERR_AKID_SKID_MISMATCH;\n    /* Check serial number */\n    if (akid->serial &&\n        ASN1_INTEGER_cmp(X509_get0_serialNumber(issuer), akid->serial))\n        return X509_V_ERR_AKID_ISSUER_SERIAL_MISMATCH;\n    /* Check issuer name */\n    if (akid->issuer) {\n        /*\n         * Ugh, for some peculiar reason AKID includes SEQUENCE OF\n         * GeneralName. So look for a DirName. There may be more than one but\n         * we only take any notice of the first.\n         */\n        GENERAL_NAMES *gens = akid->issuer;\n        GENERAL_NAME *gen;\n        X509_NAME *nm = NULL;\n        int i;\n\n        for (i = 0; i < sk_GENERAL_NAME_num(gens); i++) {\n            gen = sk_GENERAL_NAME_value(gens, i);\n            if (gen->type == GEN_DIRNAME) {\n                nm = gen->d.dirn;\n                break;\n            }\n        }\n        if (nm != NULL && X509_NAME_cmp(nm, X509_get_issuer_name(issuer)) != 0)\n            return X509_V_ERR_AKID_ISSUER_SERIAL_MISMATCH;\n    }\n    return X509_V_OK;\n}\n\nuint32_t X509_get_extension_flags(X509 *x)\n"}, {"id": "4F7B3E690DABCACB", "name": "X509_verify", "path": "openssl/crypto/x509/x_all.c", "start": {"line": 31, "col": 1}, "end": {"line": 39, "col": 1}, "code": "{\n    if (X509_ALGOR_cmp(&a->sig_alg, &a->cert_info.signature) != 0)\n        return 0;\n\n    return ASN1_item_verify_ex(ASN1_ITEM_rptr(X509_CINF), &a->sig_alg,\n                               &a->signature, &a->cert_info,\n                               a->distinguishing_id, r, a->libctx, a->propq);\n}\n\nint X509_REQ_verify_ex(X509_REQ *a, EVP_PKEY *r, OSSL_LIB_CTX *libctx,\n                       const char *propq)\n{\n    return ASN1_item_verify_ex(ASN1_ITEM_rptr(X509_REQ_INFO), &a->sig_alg,\n                               a->signature, &a->req_info, a->distinguishing_id,\n                               r, libctx, propq);\n}\n\nint X509_REQ_verify(X509_REQ *a, EVP_PKEY *r)\n{\n    return X509_REQ_verify_ex(a, r, NULL, NULL);\n}\n\nint NETSCAPE_SPKI_verify(NETSCAPE_SPKI *a, EVP_PKEY *r)\n{\n    return ASN1_item_verify(ASN1_ITEM_rptr(NETSCAPE_SPKAC),\n                            &a->sig_algor, a->signature, a->spkac, r);\n}\n\nint X509_sign(X509 *x, EVP_PKEY *pkey, const EVP_MD *md)\n{\n    if (x == NULL) {\n        ERR_raise(ERR_LIB_X509, ERR_R_PASSED_NULL_PARAMETER);\n        return 0;\n    }\n    if (sk_X509_EXTENSION_num(X509_get0_extensions(x)) > 0\n            && !X509_set_version(x, X509_VERSION_3))\n        return 0;\n\n    /*\n     * Setting the modified flag before signing it. This makes the cached\n"}], "code": "int X509_self_signed(X509 *cert, int verify_signature)\n{\n    EVP_PKEY *pkey;\n\n    if ((pkey = X509_get0_pubkey(cert)) == NULL) { /* handles cert == NULL */\n        ERR_raise(ERR_LIB_X509, X509_R_UNABLE_TO_GET_CERTS_PUBLIC_KEY);\n        return -1;\n    }\n    if (!ossl_x509v3_cache_extensions(cert))\n        return -1;\n    if ((cert->ex_flags & EXFLAG_SS) == 0)\n        return 0;\n    if (!verify_signature)\n        return 1;\n    return X509_verify(cert, pkey);\n}\n"}, "AC4F3EF59CA94B57": {"calls": [{"id": "DD0D9BB28CB79FA2", "name": "ossl_x509_likely_issued", "path": "openssl/crypto/x509/v3_purp.c", "start": {"line": 963, "col": 1}, "end": {"line": 982, "col": 1}, "code": "{\n    int ret;\n\n    if (X509_NAME_cmp(X509_get_subject_name(issuer),\n                      X509_get_issuer_name(subject)) != 0)\n        return X509_V_ERR_SUBJECT_ISSUER_MISMATCH;\n\n    /* set issuer->skid and subject->akid */\n    if (!ossl_x509v3_cache_extensions(issuer)\n            || !ossl_x509v3_cache_extensions(subject))\n        return X509_V_ERR_UNSPECIFIED;\n\n    ret = X509_check_akid(issuer, subject->akid);\n    if (ret != X509_V_OK)\n        return ret;\n\n    /* Check if the subject signature alg matches the issuer's PUBKEY alg */\n    return check_sig_alg_match(X509_get0_pubkey(issuer), subject);\n}\n\n/*-\n * Check if certificate I<issuer> is allowed to issue certificate I<subject>\n * according to the B<keyUsage> field of I<issuer> if present\n * depending on any proxyCertInfo extension of I<subject>.\n * Returns 0 for OK, or positive for reason for rejection\n * where reason codes match those for X509_verify_cert().\n */\nint ossl_x509_signing_allowed(const X509 *issuer, const X509 *subject)\n{\n    if ((subject->ex_flags & EXFLAG_PROXY) != 0) {\n        if (ku_reject(issuer, KU_DIGITAL_SIGNATURE))\n            return X509_V_ERR_KEYUSAGE_NO_DIGITAL_SIGNATURE;\n    } else if (ku_reject(issuer, KU_KEY_CERT_SIGN)) {\n        return X509_V_ERR_KEYUSAGE_NO_CERTSIGN;\n    }\n    return X509_V_OK;\n}\n\nint X509_check_akid(const X509 *issuer, const AUTHORITY_KEYID *akid)\n{\n    if (akid == NULL)\n        return X509_V_OK;\n\n    /* Check key ids (if present) */\n    if (akid->keyid && issuer->skid &&\n        ASN1_OCTET_STRING_cmp(akid->keyid, issuer->skid))\n        return X509_V_ERR_AKID_SKID_MISMATCH;\n    /* Check serial number */\n    if (akid->serial &&\n        ASN1_INTEGER_cmp(X509_get0_serialNumber(issuer), akid->serial))\n        return X509_V_ERR_AKID_ISSUER_SERIAL_MISMATCH;\n    /* Check issuer name */\n    if (akid->issuer) {\n        /*\n         * Ugh, for some peculiar reason AKID includes SEQUENCE OF\n         * GeneralName. So look for a DirName. There may be more than one but\n         * we only take any notice of the first.\n         */\n        GENERAL_NAMES *gens = akid->issuer;\n        GENERAL_NAME *gen;\n        X509_NAME *nm = NULL;\n        int i;\n\n        for (i = 0; i < sk_GENERAL_NAME_num(gens); i++) {\n            gen = sk_GENERAL_NAME_value(gens, i);\n            if (gen->type == GEN_DIRNAME) {\n                nm = gen->d.dirn;\n                break;\n            }\n        }\n        if (nm != NULL && X509_NAME_cmp(nm, X509_get_issuer_name(issuer)) != 0)\n            return X509_V_ERR_AKID_ISSUER_SERIAL_MISMATCH;\n    }\n    return X509_V_OK;\n}\n\nuint32_t X509_get_extension_flags(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    X509_check_purpose(x, -1, 0);\n    return x->ex_flags;\n}\n\nuint32_t X509_get_key_usage(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return 0;\n    return (x->ex_flags & EXFLAG_KUSAGE) != 0 ? x->ex_kusage : UINT32_MAX;\n}\n\nuint32_t X509_get_extended_key_usage(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return 0;\n    return (x->ex_flags & EXFLAG_XKUSAGE) != 0 ? x->ex_xkusage : UINT32_MAX;\n}\n\nconst ASN1_OCTET_STRING *X509_get0_subject_key_id(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return x->skid;\n}\n\nconst ASN1_OCTET_STRING *X509_get0_authority_key_id(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return (x->akid != NULL ? x->akid->keyid : NULL);\n}\n\nconst GENERAL_NAMES *X509_get0_authority_issuer(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return (x->akid != NULL ? x->akid->issuer : NULL);\n}\n\nconst ASN1_INTEGER *X509_get0_authority_serial(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return (x->akid != NULL ? x->akid->serial : NULL);\n}\n\nlong X509_get_pathlen(X509 *x)\n{\n    /* Called for side effect of caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1\n            || (x->ex_flags & EXFLAG_BCONS) == 0)\n        return -1;\n    return x->ex_pathlen;\n}\n\nlong X509_get_proxy_pathlen(X509 *x)\n{\n    /* Called for side effect of caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1\n            || (x->ex_flags & EXFLAG_PROXY) == 0)\n        return -1;\n    return x->ex_pcpathlen;\n}\n"}], "code": "static int check_issued(ossl_unused X509_STORE_CTX *ctx, X509 *x, X509 *issuer)\n{\n    int err = ossl_x509_likely_issued(issuer, x);\n\n    if (err == X509_V_OK)\n        return 1;\n    /*\n     * SUBJECT_ISSUER_MISMATCH just means 'x' is clearly not issued by 'issuer'.\n     * Every other error code likely indicates a real error.\n     */\n    return 0;\n}\n"}, "9566C87BE346F08A": {"calls": [{"id": "A837CCBCD585E924", "name": "ch_cleanup", "path": "openssl/ssl/quic/quic_channel.c", "start": {"line": 355, "col": 1}, "end": {"line": 407, "col": 1}, "code": "{\n    uint32_t pn_space;\n\n    if (ch->ackm != NULL)\n        for (pn_space = QUIC_PN_SPACE_INITIAL;\n             pn_space < QUIC_PN_SPACE_NUM;\n             ++pn_space)\n            ossl_ackm_on_pkt_space_discarded(ch->ackm, pn_space);\n\n    ossl_quic_lcidm_cull(ch->lcidm, ch);\n    ossl_quic_srtm_cull(ch->srtm, ch);\n    ossl_quic_tx_packetiser_free(ch->txp);\n    ossl_quic_txpim_free(ch->txpim);\n    ossl_quic_cfq_free(ch->cfq);\n    ossl_qtx_free(ch->qtx);\n    if (ch->cc_data != NULL)\n        ch->cc_method->free(ch->cc_data);\n    if (ch->have_statm)\n        ossl_statm_destroy(&ch->statm);\n    ossl_ackm_free(ch->ackm);\n\n    if (ch->have_qsm)\n        ossl_quic_stream_map_cleanup(&ch->qsm);\n\n    for (pn_space = QUIC_PN_SPACE_INITIAL; pn_space < QUIC_PN_SPACE_NUM; ++pn_space) {\n        ossl_quic_sstream_free(ch->crypto_send[pn_space]);\n        ossl_quic_rstream_free(ch->crypto_recv[pn_space]);\n    }\n\n    ossl_qrx_pkt_release(ch->qrx_pkt);\n    ch->qrx_pkt = NULL;\n\n    ossl_quic_tls_free(ch->qtls);\n    ossl_qrx_free(ch->qrx);\n    OPENSSL_free(ch->local_transport_params);\n    OPENSSL_free((char *)ch->terminate_cause.reason);\n    OSSL_ERR_STATE_free(ch->err_state);\n    OPENSSL_free(ch->ack_range_scratch);\n\n    if (ch->on_port_list) {\n        ossl_list_ch_remove(&ch->port->channel_list, ch);\n        ch->on_port_list = 0;\n    }\n\n#ifndef OPENSSL_NO_QLOG\n    if (ch->qlog != NULL)\n        ossl_qlog_flush(ch->qlog); /* best effort */\n\n    OPENSSL_free(ch->qlog_title);\n    ossl_qlog_free(ch->qlog);\n#endif\n}\n\nQUIC_CHANNEL *ossl_quic_channel_new(const QUIC_CHANNEL_ARGS *args)\n{\n    QUIC_CHANNEL *ch = NULL;\n\n    if ((ch = OPENSSL_zalloc(sizeof(*ch))) == NULL)\n        return NULL;\n\n    ch->port        = args->port;\n    ch->is_server   = args->is_server;\n    ch->tls         = args->tls;\n    ch->lcidm       = args->lcidm;\n    ch->srtm        = args->srtm;\n#ifndef OPENSSL_NO_QLOG\n    ch->use_qlog    = args->use_qlog;\n\n    if (ch->use_qlog && args->qlog_title != NULL) {\n        if ((ch->qlog_title = OPENSSL_strdup(args->qlog_title)) == NULL) {\n            OPENSSL_free(ch);\n            return NULL;\n        }\n    }\n#endif\n\n    if (!ch_init(ch)) {\n        OPENSSL_free(ch);\n        return NULL;\n    }\n\n    return ch;\n}\n\nvoid ossl_quic_channel_free(QUIC_CHANNEL *ch)\n{\n    if (ch == NULL)\n        return;\n\n    ch_cleanup(ch);\n    OPENSSL_free(ch);\n}\n\n/* Set mutator callbacks for test framework support */\nint ossl_quic_channel_set_mutator(QUIC_CHANNEL *ch,\n                                  ossl_mutate_packet_cb mutatecb,\n                                  ossl_finish_mutate_cb finishmutatecb,\n                                  void *mutatearg)\n{\n    if (ch->qtx == NULL)\n        return 0;\n\n    ossl_qtx_set_mutator(ch->qtx, mutatecb, finishmutatecb, mutatearg);\n    return 1;\n}\n\nint ossl_quic_channel_get_peer_addr(QUIC_CHANNEL *ch, BIO_ADDR *peer_addr)\n{\n    if (!ch->addressed_mode)\n        return 0;\n\n    *peer_addr = ch->cur_peer_addr;\n    return 1;\n}\n\nint ossl_quic_channel_set_peer_addr(QUIC_CHANNEL *ch, const BIO_ADDR *peer_addr)\n{\n    if (ch->state != QUIC_CHANNEL_STATE_IDLE)\n        return 0;\n\n    if (peer_addr == NULL || BIO_ADDR_family(peer_addr) == AF_UNSPEC) {\n        BIO_ADDR_clear(&ch->cur_peer_addr);\n        ch->addressed_mode = 0;\n        return 1;\n    }\n\n    ch->cur_peer_addr   = *peer_addr;\n    ch->addressed_mode  = 1;\n    return 1;\n}\n\nQUIC_REACTOR *ossl_quic_channel_get_reactor(QUIC_CHANNEL *ch)\n{\n    return ossl_quic_port_get0_reactor(ch->port);\n}\n\nQUIC_STREAM_MAP *ossl_quic_channel_get_qsm(QUIC_CHANNEL *ch)\n{\n    return &ch->qsm;\n}\n\nOSSL_STATM *ossl_quic_channel_get_statm(QUIC_CHANNEL *ch)\n{\n    return &ch->statm;\n}\n\nQUIC_STREAM *ossl_quic_channel_get_stream_by_id(QUIC_CHANNEL *ch,\n                                                uint64_t stream_id)\n{\n    return ossl_quic_stream_map_get_by_id(&ch->qsm, stream_id);\n}\n\nint ossl_quic_channel_is_active(const QUIC_CHANNEL *ch)\n{\n    return ch != NULL && ch->state == QUIC_CHANNEL_STATE_ACTIVE;\n}\n\nint ossl_quic_channel_is_closing(const QUIC_CHANNEL *ch)\n{\n    return ch->state == QUIC_CHANNEL_STATE_TERMINATING_CLOSING;\n}\n\nstatic int ossl_quic_channel_is_draining(const QUIC_CHANNEL *ch)\n{\n    return ch->state == QUIC_CHANNEL_STATE_TERMINATING_DRAINING;\n}\n\nstatic int ossl_quic_channel_is_terminating(const QUIC_CHANNEL *ch)\n{\n    return ossl_quic_channel_is_closing(ch)\n        || ossl_quic_channel_is_draining(ch);\n}\n\nint ossl_quic_channel_is_terminated(const QUIC_CHANNEL *ch)\n{\n    return ch->state == QUIC_CHANNEL_STATE_TERMINATED;\n}\n\nint ossl_quic_channel_is_term_any(const QUIC_CHANNEL *ch)\n{\n    return ossl_quic_channel_is_terminating(ch)\n        || ossl_quic_channel_is_terminated(ch);\n}\n\nconst QUIC_TERMINATE_CAUSE *\nossl_quic_channel_get_terminate_cause(const QUIC_CHANNEL *ch)\n{\n    return ossl_quic_channel_is_term_any(ch) ? &ch->terminate_cause : NULL;\n}\n\nint ossl_quic_channel_is_handshake_complete(const QUIC_CHANNEL *ch)\n{\n    return ch->handshake_complete;\n}\n\nint ossl_quic_channel_is_handshake_confirmed(const QUIC_CHANNEL *ch)\n{\n    return ch->handshake_confirmed;\n}\n\nQUIC_DEMUX *ossl_quic_channel_get0_demux(QUIC_CHANNEL *ch)\n{\n    return ch->port->demux;\n}\n\nQUIC_PORT *ossl_quic_channel_get0_port(QUIC_CHANNEL *ch)\n{\n    return ch->port;\n}\n\nQUIC_ENGINE *ossl_quic_channel_get0_engine(QUIC_CHANNEL *ch)\n{\n    return ossl_quic_port_get0_engine(ch->port);\n}\n\nCRYPTO_MUTEX *ossl_quic_channel_get_mutex(QUIC_CHANNEL *ch)\n{\n    return ossl_quic_port_get0_mutex(ch->port);\n}\n\nint ossl_quic_channel_has_pending(const QUIC_CHANNEL *ch)\n{\n    return ossl_quic_demux_has_pending(ch->port->demux)\n        || ossl_qrx_processed_read_pending(ch->qrx);\n}\n\n/*\n * QUIC Channel: Callbacks from Miscellaneous Subsidiary Components\n * ================================================================\n */\n\n/* Used by various components. */\nstatic OSSL_TIME get_time(void *arg)\n{\n    QUIC_CHANNEL *ch = arg;\n\n    return ossl_quic_port_get_time(ch->port);\n}\n\n/* Used by QSM. */\nstatic uint64_t get_stream_limit(int uni, void *arg)\n{\n    QUIC_CHANNEL *ch = arg;\n\n    return uni ? ch->max_local_streams_uni : ch->max_local_streams_bidi;\n}\n\n/*\n * Called by QRX to determine if a packet is potentially invalid before trying\n * to decrypt it.\n */\nstatic int rx_late_validate(QUIC_PN pn, int pn_space, void *arg)\n{\n    QUIC_CHANNEL *ch = arg;\n\n    /* Potential duplicates should not be processed. */\n    if (!ossl_ackm_is_rx_pn_processable(ch->ackm, pn, pn_space))\n        return 0;\n\n    return 1;\n}\n\n/*\n * Triggers a TXKU (whether spontaneous or solicited). Does not check whether\n * spontaneous TXKU is currently allowed.\n */\nQUIC_NEEDS_LOCK\nstatic void ch_trigger_txku(QUIC_CHANNEL *ch)\n{\n    uint64_t next_pn\n        = ossl_quic_tx_packetiser_get_next_pn(ch->txp, QUIC_PN_SPACE_APP);\n\n    if (!ossl_quic_pn_valid(next_pn)\n        || !ossl_qtx_trigger_key_update(ch->qtx)) {\n        ossl_quic_channel_raise_protocol_error(ch, QUIC_ERR_INTERNAL_ERROR, 0,\n                                               \"key update\");\n        return;\n    }\n\n    ch->txku_in_progress    = 1;\n    ch->txku_pn             = next_pn;\n    ch->rxku_expected       = ch->ku_locally_initiated;\n}\n\nQUIC_NEEDS_LOCK\nstatic int txku_in_progress(QUIC_CHANNEL *ch)\n{\n    if (ch->txku_in_progress\n        && ossl_ackm_get_largest_acked(ch->ackm, QUIC_PN_SPACE_APP) >= ch->txku_pn) {\n        OSSL_TIME pto = ossl_ackm_get_pto_duration(ch->ackm);\n\n        /*\n         * RFC 9001 s. 6.5: Endpoints SHOULD wait three times the PTO before\n         * initiating a key update after receiving an acknowledgment that\n         * confirms that the previous key update was received.\n         *\n         * Note that by the above wording, this period starts from when we get\n         * the ack for a TXKU-triggering packet, not when the TXKU is initiated.\n         * So we defer TXKU cooldown deadline calculation to this point.\n         */\n        ch->txku_in_progress        = 0;\n        ch->txku_cooldown_deadline  = ossl_time_add(get_time(ch),\n                                                    ossl_time_multiply(pto, 3));\n    }\n\n    return ch->txku_in_progress;\n}\n\nQUIC_NEEDS_LOCK\nstatic int txku_allowed(QUIC_CHANNEL *ch)\n{\n    return ch->tx_enc_level == QUIC_ENC_LEVEL_1RTT /* Sanity check. */\n        /* Strict RFC 9001 criterion for TXKU. */\n        && ch->handshake_confirmed\n        && !txku_in_progress(ch);\n}\n\nQUIC_NEEDS_LOCK\nstatic int txku_recommendable(QUIC_CHANNEL *ch)\n{\n    if (!txku_allowed(ch))\n        return 0;\n\n    return\n        /* Recommended RFC 9001 criterion for TXKU. */\n        ossl_time_compare(get_time(ch), ch->txku_cooldown_deadline) >= 0\n        /* Some additional sensible criteria. */\n        && !ch->rxku_in_progress\n        && !ch->rxku_pending_confirm;\n}\n\nQUIC_NEEDS_LOCK\nstatic int txku_desirable(QUIC_CHANNEL *ch)\n{\n    uint64_t cur_pkt_count, max_pkt_count, thresh_pkt_count;\n    const uint32_t enc_level = QUIC_ENC_LEVEL_1RTT;\n\n    /* Check AEAD limit to determine if we should perform a spontaneous TXKU. */\n    cur_pkt_count = ossl_qtx_get_cur_epoch_pkt_count(ch->qtx, enc_level);\n    max_pkt_count = ossl_qtx_get_max_epoch_pkt_count(ch->qtx, enc_level);\n\n    thresh_pkt_count = max_pkt_count / 2;\n    if (ch->txku_threshold_override != UINT64_MAX)\n        thresh_pkt_count = ch->txku_threshold_override;\n\n    return cur_pkt_count >= thresh_pkt_count;\n}\n\nQUIC_NEEDS_LOCK\nstatic void ch_maybe_trigger_spontaneous_txku(QUIC_CHANNEL *ch)\n{\n    if (!txku_recommendable(ch) || !txku_desirable(ch))\n        return;\n\n    ch->ku_locally_initiated = 1;\n    ch_trigger_txku(ch);\n}\n\nQUIC_NEEDS_LOCK\nstatic int rxku_allowed(QUIC_CHANNEL *ch)\n{\n    /*\n     * RFC 9001 s. 6.1: An endpoint MUST NOT initiate a key update prior to\n     * having confirmed the handshake (Section 4.1.2).\n     *\n     * RFC 9001 s. 6.1: An endpoint MUST NOT initiate a subsequent key update\n     * unless it has received an acknowledgment for a packet that was sent\n     * protected with keys from the current key phase.\n     *\n     * RFC 9001 s. 6.2: If an endpoint detects a second update before it has\n     * sent any packets with updated keys containing an acknowledgment for the\n     * packet that initiated the key update, it indicates that its peer has\n     * updated keys twice without awaiting confirmation. An endpoint MAY treat\n     * such consecutive key updates as a connection error of type\n     * KEY_UPDATE_ERROR.\n     */\n    return ch->handshake_confirmed && !ch->rxku_pending_confirm;\n}\n\n/*\n * Called when the QRX detects a new RX key update event.\n */\nenum rxku_decision {\n    DECISION_RXKU_ONLY,\n    DECISION_PROTOCOL_VIOLATION,\n    DECISION_SOLICITED_TXKU\n};\n\n/* Called when the QRX detects a key update has occurred. */\nQUIC_NEEDS_LOCK\nstatic void rxku_detected(QUIC_PN pn, void *arg)\n{\n    QUIC_CHANNEL *ch = arg;\n    enum rxku_decision decision;\n    OSSL_TIME pto;\n\n    /*\n     * Note: rxku_in_progress is always 0 here as an RXKU cannot be detected\n     * when we are still in UPDATING or COOLDOWN (see quic_record_rx.h).\n     */\n    assert(!ch->rxku_in_progress);\n\n    if (!rxku_allowed(ch))\n        /* Is RXKU even allowed at this time? */\n        decision = DECISION_PROTOCOL_VIOLATION;\n\n    else if (ch->ku_locally_initiated)\n        /*\n"}], "code": "void ossl_quic_channel_free(QUIC_CHANNEL *ch)\n{\n    if (ch == NULL)\n        return;\n\n    ch_cleanup(ch);\n    OPENSSL_free(ch);\n}\n"}, "F0718158305A9415": {"calls": [{"id": "1DCAB6E9B9F16B52", "name": "CRYPTO_THREAD_get_local", "path": "openssl/crypto/threads_pthread.c", "start": {"line": 734, "col": 1}, "end": {"line": 737, "col": 1}, "code": "{\n    return pthread_getspecific(*key);\n}\n\nint CRYPTO_THREAD_set_local(CRYPTO_THREAD_LOCAL *key, void *val)\n{\n    if (pthread_setspecific(*key, val) != 0)\n        return 0;\n\n    return 1;\n}\n\nint CRYPTO_THREAD_cleanup_local(CRYPTO_THREAD_LOCAL *key)\n{\n    if (pthread_key_delete(*key) != 0)\n        return 0;\n\n    return 1;\n}\n\nCRYPTO_THREAD_ID CRYPTO_THREAD_get_current_id(void)\n{\n    return pthread_self();\n}\n\nint CRYPTO_THREAD_compare_id(CRYPTO_THREAD_ID a, CRYPTO_THREAD_ID b)\n{\n    return pthread_equal(a, b);\n}\n\nint CRYPTO_atomic_add(int *val, int amount, int *ret, CRYPTO_RWLOCK *lock)\n{\n# if defined(__GNUC__) && defined(__ATOMIC_ACQ_REL) && !defined(BROKEN_CLANG_ATOMICS)\n    if (__atomic_is_lock_free(sizeof(*val), val)) {\n        *ret = __atomic_add_fetch(val, amount, __ATOMIC_ACQ_REL);\n        return 1;\n    }\n# elif defined(__sun) && (defined(__SunOS_5_10) || defined(__SunOS_5_11))\n    /* This will work for all future Solaris versions. */\n    if (ret != NULL) {\n        *ret = atomic_add_int_nv((volatile unsigned int *)val, amount);\n        return 1;\n    }\n# endif\n    if (lock == NULL || !CRYPTO_THREAD_write_lock(lock))\n        return 0;\n\n    *val += amount;\n    *ret  = *val;\n\n    if (!CRYPTO_THREAD_unlock(lock))\n        return 0;\n\n    return 1;\n}\n\nint CRYPTO_atomic_or(uint64_t *val, uint64_t op, uint64_t *ret,\n                     CRYPTO_RWLOCK *lock)\n{\n# if defined(__GNUC__) && defined(__ATOMIC_ACQ_REL) && !defined(BROKEN_CLANG_ATOMICS)\n    if (__atomic_is_lock_free(sizeof(*val), val)) {\n        *ret = __atomic_or_fetch(val, op, __ATOMIC_ACQ_REL);\n        return 1;\n    }\n# elif defined(__sun) && (defined(__SunOS_5_10) || defined(__SunOS_5_11))\n    /* This will work for all future Solaris versions. */\n    if (ret != NULL) {\n        *ret = atomic_or_64_nv(val, op);\n        return 1;\n    }\n# endif\n    if (lock == NULL || !CRYPTO_THREAD_write_lock(lock))\n        return 0;\n    *val |= op;\n    *ret  = *val;\n\n    if (!CRYPTO_THREAD_unlock(lock))\n        return 0;\n\n    return 1;\n}\n\nint CRYPTO_atomic_load(uint64_t *val, uint64_t *ret, CRYPTO_RWLOCK *lock)\n{\n# if defined(__GNUC__) && defined(__ATOMIC_ACQUIRE) && !defined(BROKEN_CLANG_ATOMICS)\n    if (__atomic_is_lock_free(sizeof(*val), val)) {\n        __atomic_load(val, ret, __ATOMIC_ACQUIRE);\n        return 1;\n    }\n# elif defined(__sun) && (defined(__SunOS_5_10) || defined(__SunOS_5_11))\n    /* This will work for all future Solaris versions. */\n    if (ret != NULL) {\n        *ret = atomic_or_64_nv(val, 0);\n        return 1;\n    }\n# endif\n    if (lock == NULL || !CRYPTO_THREAD_read_lock(lock))\n        return 0;\n    *ret  = *val;\n    if (!CRYPTO_THREAD_unlock(lock))\n        return 0;\n\n    return 1;\n}\n\nint CRYPTO_atomic_load_int(int *val, int *ret, CRYPTO_RWLOCK *lock)\n{\n# if defined(__GNUC__) && defined(__ATOMIC_ACQUIRE) && !defined(BROKEN_CLANG_ATOMICS)\n    if (__atomic_is_lock_free(sizeof(*val), val)) {\n        __atomic_load(val, ret, __ATOMIC_ACQUIRE);\n        return 1;\n    }\n# elif defined(__sun) && (defined(__SunOS_5_10) || defined(__SunOS_5_11))\n    /* This will work for all future Solaris versions. */\n    if (ret != NULL) {\n        *ret = (int *)atomic_or_uint_nv((unsigned int *)val, 0);\n        return 1;\n    }\n# endif\n    if (lock == NULL || !CRYPTO_THREAD_read_lock(lock))\n        return 0;\n    *ret  = *val;\n    if (!CRYPTO_THREAD_unlock(lock))\n        return 0;\n\n    return 1;\n}\n\n# ifndef FIPS_MODULE\nint openssl_init_fork_handlers(void)\n{\n    return 1;\n}\n# endif /* FIPS_MODULE */\n\nint openssl_get_fork_id(void)\n{\n    return getpid();\n}\n#endif\n"}], "code": "static void free_rcu_thr_data(void *ptr)\n{\n    struct rcu_thr_data *data =\n                        (struct rcu_thr_data *)CRYPTO_THREAD_get_local(&rcu_thr_key);\n\n    OPENSSL_free(data);\n    CRYPTO_THREAD_set_local(&rcu_thr_key, NULL);\n}\n"}, "FBE031EE3DC1FDB6": {"calls": [{"id": "010BDE680D3C1DB9", "name": "provider_conf_params_internal", "path": "openssl/crypto/provider_conf.c", "start": {"line": 74, "col": 1}, "end": {"line": 145, "col": 1}, "code": "                                         OSSL_PROVIDER_INFO *provinfo,\n                                         const char *name, const char *value,\n                                         const CONF *cnf,\n                                         STACK_OF(OPENSSL_CSTRING) *visited)\n{\n    STACK_OF(CONF_VALUE) *sect;\n    int ok = 1;\n    int rc = 0;\n\n    sect = NCONF_get_section(cnf, value);\n    if (sect != NULL) {\n        int i;\n        char buffer[512];\n        size_t buffer_len = 0;\n\n        OSSL_TRACE1(CONF, \"Provider params: start section %s\\n\", value);\n\n        /*\n         * Check to see if the provided section value has already\n         * been visited.  If it has, then we have a recursive lookup\n         * in the configuration which isn't valid.  As such we should error\n         * out\n         */\n        for (i = 0; i < sk_OPENSSL_CSTRING_num(visited); i++) {\n            if (sk_OPENSSL_CSTRING_value(visited, i) == value) {\n                ERR_raise(ERR_LIB_CONF, CONF_R_RECURSIVE_SECTION_REFERENCE);\n                return -1;\n            }\n        }\n\n        /*\n         * We've not visited this node yet, so record it on the stack\n         */\n        if (!sk_OPENSSL_CSTRING_push(visited, value))\n            return -1;\n\n        if (name != NULL) {\n            OPENSSL_strlcpy(buffer, name, sizeof(buffer));\n            OPENSSL_strlcat(buffer, \".\", sizeof(buffer));\n            buffer_len = strlen(buffer);\n        }\n\n        for (i = 0; i < sk_CONF_VALUE_num(sect); i++) {\n            CONF_VALUE *sectconf = sk_CONF_VALUE_value(sect, i);\n\n            if (buffer_len + strlen(sectconf->name) >= sizeof(buffer)) {\n                sk_OPENSSL_CSTRING_pop(visited);\n                return -1;\n            }\n            buffer[buffer_len] = '\\0';\n            OPENSSL_strlcat(buffer, sectconf->name, sizeof(buffer));\n            rc = provider_conf_params_internal(prov, provinfo, buffer,\n                                               sectconf->value, cnf, visited);\n            if (rc < 0) {\n                sk_OPENSSL_CSTRING_pop(visited);\n                return rc;\n            }\n        }\n        sk_OPENSSL_CSTRING_pop(visited);\n\n        OSSL_TRACE1(CONF, \"Provider params: finish section %s\\n\", value);\n    } else {\n        OSSL_TRACE2(CONF, \"Provider params: %s = %s\\n\", name, value);\n        if (prov != NULL)\n            ok = ossl_provider_add_parameter(prov, name, value);\n        else\n            ok = ossl_provider_info_add_parameter(provinfo, name, value);\n    }\n\n    return ok;\n}\n\n/*\n * recursively parse the provider configuration section\n * of the config file. \n * Returns\n * 1 on success\n * 0 on non-fatal error\n * < 0 on fatal errors\n */\nstatic int provider_conf_params(OSSL_PROVIDER *prov,\n                                OSSL_PROVIDER_INFO *provinfo,\n                                const char *name, const char *value,\n                                const CONF *cnf)\n{\n    int rc;\n    STACK_OF(OPENSSL_CSTRING) *visited = sk_OPENSSL_CSTRING_new_null();\n\n    if (visited == NULL)\n        return -1;\n\n    rc = provider_conf_params_internal(prov, provinfo, name,\n                                       value, cnf, visited);\n\n    sk_OPENSSL_CSTRING_free(visited);\n\n    return rc;\n}\n\nstatic int prov_already_activated(const char *name,\n                                  STACK_OF(OSSL_PROVIDER) *activated)\n{\n    int i, max;\n\n    if (activated == NULL)\n        return 0;\n\n    max = sk_OSSL_PROVIDER_num(activated);\n    for (i = 0; i < max; i++) {\n        OSSL_PROVIDER *tstprov = sk_OSSL_PROVIDER_value(activated, i);\n\n        if (strcmp(OSSL_PROVIDER_get0_name(tstprov), name) == 0) {\n            return 1;\n        }\n    }\n\n    return 0;\n}\n\n/*\n * Attempt to activate a provider\n * Returns:\n * 1 on successful activation\n * 0 on failed activation for non-fatal error\n * < 0 on failed activation for fatal errors\n */\nstatic int provider_conf_activate(OSSL_LIB_CTX *libctx, const char *name,\n                                  const char *value, const char *path,\n                                  int soft, const CONF *cnf)\n{\n    PROVIDER_CONF_GLOBAL *pcgbl\n        = ossl_lib_ctx_get_data(libctx, OSSL_LIB_CTX_PROVIDER_CONF_INDEX);\n    OSSL_PROVIDER *prov = NULL, *actual = NULL;\n    int ok = 0;\n\n    if (pcgbl == NULL || !CRYPTO_THREAD_write_lock(pcgbl->lock)) {\n        ERR_raise(ERR_LIB_CRYPTO, ERR_R_INTERNAL_ERROR);\n        return -1;\n    }\n    if (!prov_already_activated(name, pcgbl->activated_providers)) {\n        /*\n        * There is an attempt to activate a provider, so we should disable\n        * loading of fallbacks. Otherwise a misconfiguration could mean the\n        * intended provider does not get loaded. Subsequent fetches could\n        * then fallback to the default provider - which may be the wrong\n        * thing.\n"}], "code": "static int provider_conf_params(OSSL_PROVIDER *prov,\n                                OSSL_PROVIDER_INFO *provinfo,\n                                const char *name, const char *value,\n                                const CONF *cnf)\n{\n    int rc;\n    STACK_OF(OPENSSL_CSTRING) *visited = sk_OPENSSL_CSTRING_new_null();\n\n    if (visited == NULL)\n        return -1;\n\n    rc = provider_conf_params_internal(prov, provinfo, name,\n                                       value, cnf, visited);\n\n    sk_OPENSSL_CSTRING_free(visited);\n\n    return rc;\n}\n"}, "C8EF3908D2059468": {"calls": [{"id": "2545AE8663083A00", "name": "txp_check_token_len", "path": "openssl/ssl/quic/quic_txp.c", "start": {"line": 544, "col": 1}, "end": {"line": 560, "col": 1}, "code": "{\n    if (token_len == 0)\n        return 1;\n\n    if (token_len >= mdpl)\n        return 0;\n\n    if (TXP_REQUIRED_TOKEN_MARGIN >= mdpl)\n        /* (should not be possible because MDPL must be at least 1200) */\n        return 0;\n\n    if (token_len > mdpl - TXP_REQUIRED_TOKEN_MARGIN)\n        return 0;\n\n    return 1;\n}\n\nint ossl_quic_tx_packetiser_set_initial_token(OSSL_QUIC_TX_PACKETISER *txp,\n                                              const unsigned char *token,\n                                              size_t token_len,\n                                              ossl_quic_initial_token_free_fn *free_cb,\n                                              void *free_cb_arg)\n{\n    if (!txp_check_token_len(token_len, txp_get_mdpl(txp)))\n        return 0;\n\n    if (txp->initial_token != NULL && txp->initial_token_free_cb != NULL)\n        txp->initial_token_free_cb(txp->initial_token, txp->initial_token_len,\n                                   txp->initial_token_free_cb_arg);\n\n    txp->initial_token              = token;\n    txp->initial_token_len          = token_len;\n    txp->initial_token_free_cb      = free_cb;\n    txp->initial_token_free_cb_arg  = free_cb_arg;\n    return 1;\n}\n\nint ossl_quic_tx_packetiser_set_cur_dcid(OSSL_QUIC_TX_PACKETISER *txp,\n                                         const QUIC_CONN_ID *dcid)\n{\n    if (dcid == NULL) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_PASSED_NULL_PARAMETER);\n        return 0;\n    }\n\n    txp->args.cur_dcid = *dcid;\n    return 1;\n}\n\nint ossl_quic_tx_packetiser_set_cur_scid(OSSL_QUIC_TX_PACKETISER *txp,\n                                         const QUIC_CONN_ID *scid)\n{\n    if (scid == NULL) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_PASSED_NULL_PARAMETER);\n        return 0;\n    }\n\n    txp->args.cur_scid = *scid;\n    return 1;\n}\n\n/* Change the destination L4 address the TXP uses to send datagrams. */\nint ossl_quic_tx_packetiser_set_peer(OSSL_QUIC_TX_PACKETISER *txp,\n                                     const BIO_ADDR *peer)\n{\n    if (peer == NULL) {\n        BIO_ADDR_clear(&txp->args.peer);\n        return 1;\n    }\n\n    txp->args.peer = *peer;\n    return 1;\n}\n\nvoid ossl_quic_tx_packetiser_set_ack_tx_cb(OSSL_QUIC_TX_PACKETISER *txp,\n                                           void (*cb)(const OSSL_QUIC_FRAME_ACK *ack,\n                                                      uint32_t pn_space,\n                                                      void *arg),\n                                           void *cb_arg)\n{\n    txp->ack_tx_cb      = cb;\n    txp->ack_tx_cb_arg  = cb_arg;\n}\n\nvoid ossl_quic_tx_packetiser_set0_qlog(OSSL_QUIC_TX_PACKETISER *txp,\n                                       QLOG *qlog)\n{\n    ossl_quic_fifd_set0_qlog(&txp->fifd, qlog);\n}\n\nint ossl_quic_tx_packetiser_discard_enc_level(OSSL_QUIC_TX_PACKETISER *txp,\n                                              uint32_t enc_level)\n{\n    if (enc_level >= QUIC_ENC_LEVEL_NUM) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_PASSED_INVALID_ARGUMENT);\n        return 0;\n    }\n\n    if (enc_level != QUIC_ENC_LEVEL_0RTT)\n        txp->args.crypto[ossl_quic_enc_level_to_pn_space(enc_level)] = NULL;\n\n    return 1;\n}\n\nvoid ossl_quic_tx_packetiser_notify_handshake_complete(OSSL_QUIC_TX_PACKETISER *txp)\n{\n    txp->handshake_complete = 1;\n}\n\nvoid ossl_quic_tx_packetiser_schedule_handshake_done(OSSL_QUIC_TX_PACKETISER *txp)\n{\n    txp->want_handshake_done = 1;\n}\n\nvoid ossl_quic_tx_packetiser_schedule_ack_eliciting(OSSL_QUIC_TX_PACKETISER *txp,\n                                                    uint32_t pn_space)\n{\n    txp->force_ack_eliciting |= (1UL << pn_space);\n}\n\nvoid ossl_quic_tx_packetiser_schedule_ack(OSSL_QUIC_TX_PACKETISER *txp,\n                                          uint32_t pn_space)\n{\n    txp->want_ack |= (1UL << pn_space);\n}\n\n#define TXP_ERR_INTERNAL     0  /* Internal (e.g. alloc) error */\n#define TXP_ERR_SUCCESS      1  /* Success */\n#define TXP_ERR_SPACE        2  /* Not enough room for another packet */\n#define TXP_ERR_INPUT        3  /* Invalid/malformed input */\n\n/*\n * Generates a datagram by polling the various ELs to determine if they want to\n * generate any frames, and generating a datagram which coalesces packets for\n * any ELs which do.\n */\nint ossl_quic_tx_packetiser_generate(OSSL_QUIC_TX_PACKETISER *txp,\n                                     QUIC_TXP_STATUS *status)\n{\n    /*\n     * Called to generate one or more datagrams, each containing one or more\n     * packets.\n     *\n     * There are some tricky things to note here:\n     *\n     *   - The TXP is only concerned with generating encrypted packets;\n     *     other packets use a different path.\n     *\n     *   - Any datagram containing an Initial packet must have a payload length\n     *     (DPL) of at least 1200 bytes. This padding need not necessarily be\n     *     found in the Initial packet.\n     *\n     *     - It is desirable to be able to coalesce an Initial packet\n     *       with a Handshake packet. Since, before generating the Handshake\n     *       packet, we do not know how long it will be, we cannot know the\n     *       correct amount of padding to ensure a DPL of at least 1200 bytes.\n     *       Thus this padding must added to the Handshake packet (or whatever\n     *       packet is the last in the datagram).\n     *\n     *     - However, at the time that we generate the Initial packet,\n     *       we do not actually know for sure that we will be followed\n     *       in the datagram by another packet. For example, suppose we have\n     *       some queued data (e.g. crypto stream data for the HANDSHAKE EL)\n     *       it looks like we will want to send on the HANDSHAKE EL.\n     *       We could assume padding will be placed in the Handshake packet\n     *       subsequently and avoid adding any padding to the Initial packet\n     *       (which would leave no room for the Handshake packet in the\n     *       datagram).\n     *\n     *       However, this is not actually a safe assumption. Suppose that we\n     *       are using a link with a MDPL of 1200 bytes, the minimum allowed by\n     *       QUIC. Suppose that the Initial packet consumes 1195 bytes in total.\n     *       Since it is not possible to fit a Handshake packet in just 5 bytes,\n     *       upon trying to add a Handshake packet after generating the Initial\n     *       packet, we will discover we have no room to fit it! This is not a\n     *       problem in itself as another datagram can be sent subsequently, but\n     *       it is a problem because we were counting to use that packet to hold\n     *       the essential padding. But if we have already finished encrypting\n     *       the Initial packet, we cannot go and add padding to it anymore.\n     *       This leaves us stuck.\n     *\n     * Because of this, we have to plan multiple packets simultaneously, such\n     * that we can start generating a Handshake (or 0-RTT or 1-RTT, or so on)\n     * packet while still having the option to go back and add padding to the\n     * Initial packet if it turns out to be needed.\n     *\n     * Trying to predict ahead of time (e.g. during Initial packet generation)\n     * whether we will successfully generate a subsequent packet is fraught with\n     * error as it relies on a large number of variables:\n     *\n     *   - Do we have room to fit a packet header? (Consider that due to\n     *     variable-length integer encoding this is highly variable and can even\n     *     depend on payload length due to a variable-length Length field.)\n     *\n     *   - Can we fit even a single one of the frames we want to put in this\n     *     packet in the packet? (Each frame type has a bespoke encoding. While\n     *     our encodings of some frame types are adaptive based on the available\n     *     room - e.g. STREAM frames - ultimately all frame types have some\n     *     absolute minimum number of bytes to be successfully encoded. For\n     *     example, if after an Initial packet there is enough room to encode\n     *     only one byte of frame data, it is quite likely we can't send any of\n     *     the frames we wanted to send.) While this is not strictly a problem\n     *     because we could just fill the packet with padding frames, this is a\n     *     pointless packet and is wasteful.\n     *\n     * Thus we adopt a multi-phase architecture:\n     *\n     *   1. Archetype Selection: Determine desired packet archetype.\n     *\n     *   2. Packet Staging: Generation of packet information and packet payload\n     *      data (frame data) into staging areas.\n     *\n     *   3. Packet Adjustment: Adjustment of staged packets, adding padding to\n     *      the staged packets if needed.\n     *\n     *   4. Commit: The packets are sent to the QTX and recorded as having been\n     *      sent to the FIFM.\n     *\n     */\n    int res = 0, rc;\n    uint32_t archetype, enc_level;\n    uint32_t conn_close_enc_level = QUIC_ENC_LEVEL_NUM;\n    struct txp_pkt pkt[QUIC_ENC_LEVEL_NUM];\n    size_t pkts_done = 0;\n    uint64_t cc_limit = txp->args.cc_method->get_tx_allowance(txp->args.cc_data);\n    int need_padding = 0, txpim_pkt_reffed;\n\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level)\n        pkt[enc_level].h_valid = 0;\n\n    memset(status, 0, sizeof(*status));\n\n    /*\n     * Should not be needed, but a sanity check in case anyone else has been\n     * using the QTX.\n     */\n    ossl_qtx_finish_dgram(txp->args.qtx);\n\n    /* 1. Archetype Selection */\n    archetype = txp_determine_archetype(txp, cc_limit);\n\n    /* 2. Packet Staging */\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level) {\n        size_t running_total = (enc_level > QUIC_ENC_LEVEL_INITIAL)\n            ? pkt[enc_level - 1].geom.hwm : 0;\n\n        pkt[enc_level].geom.hwm = running_total;\n\n        if (!txp_should_try_staging(txp, enc_level, archetype, cc_limit,\n                                    &conn_close_enc_level))\n            continue;\n\n        if (!txp_pkt_init(&pkt[enc_level], txp, enc_level, archetype,\n                          running_total))\n            /*\n             * If this fails this is not a fatal error - it means the geometry\n             * planning determined there was not enough space for another\n             * packet. So just proceed with what we've already planned for.\n             */\n            break;\n\n        rc = txp_generate_for_el(txp, &pkt[enc_level],\n                                 conn_close_enc_level == enc_level);\n        if (rc != TXP_ERR_SUCCESS)\n            goto out;\n\n        if (pkt[enc_level].force_pad)\n            /*\n             * txp_generate_for_el emitted a frame which forces packet padding.\n             */\n            need_padding = 1;\n\n        pkt[enc_level].geom.hwm = running_total\n            + pkt[enc_level].h.bytes_appended\n            + pkt[enc_level].geom.pkt_overhead;\n    }\n\n    /* 3. Packet Adjustment */\n    if (pkt[QUIC_ENC_LEVEL_INITIAL].h_valid\n        && pkt[QUIC_ENC_LEVEL_INITIAL].h.bytes_appended > 0)\n        /*\n         * We have an Initial packet in this datagram, so we need to make sure\n         * the total size of the datagram is adequate.\n         */\n        need_padding = 1;\n\n    if (need_padding) {\n        size_t total_dgram_size = 0;\n        const size_t min_dpl = QUIC_MIN_INITIAL_DGRAM_LEN;\n        uint32_t pad_el = QUIC_ENC_LEVEL_NUM;\n\n        for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n             enc_level < QUIC_ENC_LEVEL_NUM;\n             ++enc_level)\n            if (pkt[enc_level].h_valid && pkt[enc_level].h.bytes_appended > 0) {\n                if (pad_el == QUIC_ENC_LEVEL_NUM\n                    /*\n                     * We might not be able to add padding, for example if we\n                     * are using the ACK_ONLY archetype.\n                     */\n                    && pkt[enc_level].geom.adata.allow_padding\n                    && !pkt[enc_level].h.done_implicit)\n                    pad_el = enc_level;\n\n                txp_pkt_postgen_update_pkt_overhead(&pkt[enc_level], txp);\n                total_dgram_size += pkt[enc_level].geom.pkt_overhead\n                    + pkt[enc_level].h.bytes_appended;\n            }\n\n        if (pad_el != QUIC_ENC_LEVEL_NUM && total_dgram_size < min_dpl) {\n            size_t deficit = min_dpl - total_dgram_size;\n\n            if (!txp_pkt_append_padding(&pkt[pad_el], txp, deficit))\n                goto out;\n\n            total_dgram_size += deficit;\n\n            /*\n             * Padding frames make a packet ineligible for being a non-inflight\n             * packet.\n             */\n            pkt[pad_el].tpkt->ackm_pkt.is_inflight = 1;\n        }\n\n        /*\n         * If we have failed to make a datagram of adequate size, for example\n         * because we have a padding requirement but are using the ACK_ONLY\n         * archetype (because we are CC limited), which precludes us from\n         * sending padding, give up on generating the datagram - there is\n         * nothing we can do.\n         */\n        if (total_dgram_size < min_dpl) {\n            res = 1;\n            goto out;\n        }\n    }\n\n    /* 4. Commit */\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level) {\n\n        if (!pkt[enc_level].h_valid)\n            /* Did not attempt to generate a packet for this EL. */\n            continue;\n\n        if (pkt[enc_level].h.bytes_appended == 0)\n            /* Nothing was generated for this EL, so skip. */\n            continue;\n\n        rc = txp_pkt_commit(txp, &pkt[enc_level], archetype,\n                            &txpim_pkt_reffed);\n        if (rc) {\n            status->sent_ack_eliciting\n                = status->sent_ack_eliciting\n                || pkt[enc_level].tpkt->ackm_pkt.is_ack_eliciting;\n\n            if (enc_level == QUIC_ENC_LEVEL_HANDSHAKE)\n                status->sent_handshake\n                    = (pkt[enc_level].h_valid\n                       && pkt[enc_level].h.bytes_appended > 0);\n        }\n\n        if (txpim_pkt_reffed)\n            pkt[enc_level].tpkt = NULL; /* don't free */\n\n        if (!rc)\n            goto out;\n\n        ++pkts_done;\n    }\n\n    /* Flush & Cleanup */\n    res = 1;\nout:\n    ossl_qtx_finish_dgram(txp->args.qtx);\n\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level)\n        txp_pkt_cleanup(&pkt[enc_level], txp);\n\n    status->sent_pkt = pkts_done;\n\n    return res;\n}\n\nstatic const struct archetype_data archetypes[QUIC_ENC_LEVEL_NUM][TX_PACKETISER_ARCHETYPE_NUM] = {\n    /* EL 0(INITIAL) */\n    {\n        /* EL 0(INITIAL) - Archetype 0(NORMAL) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 0,\n        },\n        /* EL 0(INITIAL) - Archetype 1(PROBE) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 1,\n            /*bypass_cc                       =*/ 1,\n        },\n        /* EL 0(INITIAL) - Archetype 2(ACK_ONLY) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 0,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 0,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 0,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 1,\n        },\n    },\n    /* EL 1(HANDSHAKE) */\n    {\n        /* EL 1(HANDSHAKE) - Archetype 0(NORMAL) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 0,\n        },\n        /* EL 1(HANDSHAKE) - Archetype 1(PROBE) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 1,\n            /*bypass_cc                       =*/ 1,\n        },\n        /* EL 1(HANDSHAKE) - Archetype 2(ACK_ONLY) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 0,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 0,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 0,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 1,\n        },\n    },\n    /* EL 2(0RTT) */\n    {\n        /* EL 2(0RTT) - Archetype 0(NORMAL) */\n        {\n            /*allow_ack                       =*/ 0,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 1,\n            /*allow_retire_conn_id            =*/ 1,\n            /*allow_stream_rel                =*/ 1,\n            /*allow_conn_fc                   =*/ 1,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 0,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 0,\n        },\n        /* EL 2(0RTT) - Archetype 1(PROBE) */\n        {\n            /*allow_ack                       =*/ 0,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 1,\n            /*allow_retire_conn_id            =*/ 1,\n            /*allow_stream_rel                =*/ 1,\n            /*allow_conn_fc                   =*/ 1,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 0,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 1,\n            /*bypass_cc                       =*/ 1,\n        },\n        /* EL 2(0RTT) - Archetype 2(ACK_ONLY) */\n"}, {"id": "BDB1E8DE84B5E236", "name": "txp", "path": "openssl/ssl/quic/quic_txp.c", "start": {"line": 562, "col": 72}, "end": {"line": 562, "col": 72}, "code": "                                              const unsigned char *token,\n                                              size_t token_len,\n                                              ossl_quic_initial_token_free_fn *free_cb,\n                                              void *free_cb_arg)\n{\n    if (!txp_check_token_len(token_len, txp_get_mdpl(txp)))\n        return 0;\n\n    if (txp->initial_token != NULL && txp->initial_token_free_cb != NULL)\n        txp->initial_token_free_cb(txp->initial_token, txp->initial_token_len,\n                                   txp->initial_token_free_cb_arg);\n\n    txp->initial_token              = token;\n    txp->initial_token_len          = token_len;\n    txp->initial_token_free_cb      = free_cb;\n    txp->initial_token_free_cb_arg  = free_cb_arg;\n    return 1;\n}\n\nint ossl_quic_tx_packetiser_set_cur_dcid(OSSL_QUIC_TX_PACKETISER *txp,\n                                         const QUIC_CONN_ID *dcid)\n{\n    if (dcid == NULL) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_PASSED_NULL_PARAMETER);\n        return 0;\n    }\n\n    txp->args.cur_dcid = *dcid;\n    return 1;\n}\n\nint ossl_quic_tx_packetiser_set_cur_scid(OSSL_QUIC_TX_PACKETISER *txp,\n                                         const QUIC_CONN_ID *scid)\n{\n    if (scid == NULL) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_PASSED_NULL_PARAMETER);\n        return 0;\n    }\n\n    txp->args.cur_scid = *scid;\n    return 1;\n}\n\n/* Change the destination L4 address the TXP uses to send datagrams. */\nint ossl_quic_tx_packetiser_set_peer(OSSL_QUIC_TX_PACKETISER *txp,\n                                     const BIO_ADDR *peer)\n{\n    if (peer == NULL) {\n        BIO_ADDR_clear(&txp->args.peer);\n        return 1;\n    }\n\n    txp->args.peer = *peer;\n    return 1;\n}\n\nvoid ossl_quic_tx_packetiser_set_ack_tx_cb(OSSL_QUIC_TX_PACKETISER *txp,\n                                           void (*cb)(const OSSL_QUIC_FRAME_ACK *ack,\n                                                      uint32_t pn_space,\n                                                      void *arg),\n                                           void *cb_arg)\n{\n    txp->ack_tx_cb      = cb;\n    txp->ack_tx_cb_arg  = cb_arg;\n}\n\nvoid ossl_quic_tx_packetiser_set0_qlog(OSSL_QUIC_TX_PACKETISER *txp,\n                                       QLOG *qlog)\n{\n    ossl_quic_fifd_set0_qlog(&txp->fifd, qlog);\n}\n\nint ossl_quic_tx_packetiser_discard_enc_level(OSSL_QUIC_TX_PACKETISER *txp,\n                                              uint32_t enc_level)\n{\n    if (enc_level >= QUIC_ENC_LEVEL_NUM) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_PASSED_INVALID_ARGUMENT);\n        return 0;\n    }\n\n    if (enc_level != QUIC_ENC_LEVEL_0RTT)\n        txp->args.crypto[ossl_quic_enc_level_to_pn_space(enc_level)] = NULL;\n\n    return 1;\n}\n\nvoid ossl_quic_tx_packetiser_notify_handshake_complete(OSSL_QUIC_TX_PACKETISER *txp)\n{\n    txp->handshake_complete = 1;\n}\n\nvoid ossl_quic_tx_packetiser_schedule_handshake_done(OSSL_QUIC_TX_PACKETISER *txp)\n{\n    txp->want_handshake_done = 1;\n}\n\nvoid ossl_quic_tx_packetiser_schedule_ack_eliciting(OSSL_QUIC_TX_PACKETISER *txp,\n                                                    uint32_t pn_space)\n{\n    txp->force_ack_eliciting |= (1UL << pn_space);\n}\n\nvoid ossl_quic_tx_packetiser_schedule_ack(OSSL_QUIC_TX_PACKETISER *txp,\n                                          uint32_t pn_space)\n{\n    txp->want_ack |= (1UL << pn_space);\n}\n\n#define TXP_ERR_INTERNAL     0  /* Internal (e.g. alloc) error */\n#define TXP_ERR_SUCCESS      1  /* Success */\n#define TXP_ERR_SPACE        2  /* Not enough room for another packet */\n#define TXP_ERR_INPUT        3  /* Invalid/malformed input */\n\n/*\n * Generates a datagram by polling the various ELs to determine if they want to\n * generate any frames, and generating a datagram which coalesces packets for\n * any ELs which do.\n */\nint ossl_quic_tx_packetiser_generate(OSSL_QUIC_TX_PACKETISER *txp,\n                                     QUIC_TXP_STATUS *status)\n{\n    /*\n     * Called to generate one or more datagrams, each containing one or more\n     * packets.\n     *\n     * There are some tricky things to note here:\n     *\n     *   - The TXP is only concerned with generating encrypted packets;\n     *     other packets use a different path.\n     *\n     *   - Any datagram containing an Initial packet must have a payload length\n     *     (DPL) of at least 1200 bytes. This padding need not necessarily be\n     *     found in the Initial packet.\n     *\n     *     - It is desirable to be able to coalesce an Initial packet\n     *       with a Handshake packet. Since, before generating the Handshake\n     *       packet, we do not know how long it will be, we cannot know the\n     *       correct amount of padding to ensure a DPL of at least 1200 bytes.\n     *       Thus this padding must added to the Handshake packet (or whatever\n     *       packet is the last in the datagram).\n     *\n     *     - However, at the time that we generate the Initial packet,\n     *       we do not actually know for sure that we will be followed\n     *       in the datagram by another packet. For example, suppose we have\n     *       some queued data (e.g. crypto stream data for the HANDSHAKE EL)\n     *       it looks like we will want to send on the HANDSHAKE EL.\n     *       We could assume padding will be placed in the Handshake packet\n     *       subsequently and avoid adding any padding to the Initial packet\n     *       (which would leave no room for the Handshake packet in the\n     *       datagram).\n     *\n     *       However, this is not actually a safe assumption. Suppose that we\n     *       are using a link with a MDPL of 1200 bytes, the minimum allowed by\n     *       QUIC. Suppose that the Initial packet consumes 1195 bytes in total.\n     *       Since it is not possible to fit a Handshake packet in just 5 bytes,\n     *       upon trying to add a Handshake packet after generating the Initial\n     *       packet, we will discover we have no room to fit it! This is not a\n     *       problem in itself as another datagram can be sent subsequently, but\n     *       it is a problem because we were counting to use that packet to hold\n     *       the essential padding. But if we have already finished encrypting\n     *       the Initial packet, we cannot go and add padding to it anymore.\n     *       This leaves us stuck.\n     *\n     * Because of this, we have to plan multiple packets simultaneously, such\n     * that we can start generating a Handshake (or 0-RTT or 1-RTT, or so on)\n     * packet while still having the option to go back and add padding to the\n     * Initial packet if it turns out to be needed.\n     *\n     * Trying to predict ahead of time (e.g. during Initial packet generation)\n     * whether we will successfully generate a subsequent packet is fraught with\n     * error as it relies on a large number of variables:\n     *\n     *   - Do we have room to fit a packet header? (Consider that due to\n     *     variable-length integer encoding this is highly variable and can even\n     *     depend on payload length due to a variable-length Length field.)\n     *\n     *   - Can we fit even a single one of the frames we want to put in this\n     *     packet in the packet? (Each frame type has a bespoke encoding. While\n     *     our encodings of some frame types are adaptive based on the available\n     *     room - e.g. STREAM frames - ultimately all frame types have some\n     *     absolute minimum number of bytes to be successfully encoded. For\n     *     example, if after an Initial packet there is enough room to encode\n     *     only one byte of frame data, it is quite likely we can't send any of\n     *     the frames we wanted to send.) While this is not strictly a problem\n     *     because we could just fill the packet with padding frames, this is a\n     *     pointless packet and is wasteful.\n     *\n     * Thus we adopt a multi-phase architecture:\n     *\n     *   1. Archetype Selection: Determine desired packet archetype.\n     *\n     *   2. Packet Staging: Generation of packet information and packet payload\n     *      data (frame data) into staging areas.\n     *\n     *   3. Packet Adjustment: Adjustment of staged packets, adding padding to\n     *      the staged packets if needed.\n     *\n     *   4. Commit: The packets are sent to the QTX and recorded as having been\n     *      sent to the FIFM.\n     *\n     */\n    int res = 0, rc;\n    uint32_t archetype, enc_level;\n    uint32_t conn_close_enc_level = QUIC_ENC_LEVEL_NUM;\n    struct txp_pkt pkt[QUIC_ENC_LEVEL_NUM];\n    size_t pkts_done = 0;\n    uint64_t cc_limit = txp->args.cc_method->get_tx_allowance(txp->args.cc_data);\n    int need_padding = 0, txpim_pkt_reffed;\n\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level)\n        pkt[enc_level].h_valid = 0;\n\n    memset(status, 0, sizeof(*status));\n\n    /*\n     * Should not be needed, but a sanity check in case anyone else has been\n     * using the QTX.\n     */\n    ossl_qtx_finish_dgram(txp->args.qtx);\n\n    /* 1. Archetype Selection */\n    archetype = txp_determine_archetype(txp, cc_limit);\n\n    /* 2. Packet Staging */\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level) {\n        size_t running_total = (enc_level > QUIC_ENC_LEVEL_INITIAL)\n            ? pkt[enc_level - 1].geom.hwm : 0;\n\n        pkt[enc_level].geom.hwm = running_total;\n\n        if (!txp_should_try_staging(txp, enc_level, archetype, cc_limit,\n                                    &conn_close_enc_level))\n            continue;\n\n        if (!txp_pkt_init(&pkt[enc_level], txp, enc_level, archetype,\n                          running_total))\n            /*\n             * If this fails this is not a fatal error - it means the geometry\n             * planning determined there was not enough space for another\n             * packet. So just proceed with what we've already planned for.\n             */\n            break;\n\n        rc = txp_generate_for_el(txp, &pkt[enc_level],\n                                 conn_close_enc_level == enc_level);\n        if (rc != TXP_ERR_SUCCESS)\n            goto out;\n\n        if (pkt[enc_level].force_pad)\n            /*\n             * txp_generate_for_el emitted a frame which forces packet padding.\n             */\n            need_padding = 1;\n\n        pkt[enc_level].geom.hwm = running_total\n            + pkt[enc_level].h.bytes_appended\n            + pkt[enc_level].geom.pkt_overhead;\n    }\n\n    /* 3. Packet Adjustment */\n    if (pkt[QUIC_ENC_LEVEL_INITIAL].h_valid\n        && pkt[QUIC_ENC_LEVEL_INITIAL].h.bytes_appended > 0)\n        /*\n         * We have an Initial packet in this datagram, so we need to make sure\n         * the total size of the datagram is adequate.\n         */\n        need_padding = 1;\n\n    if (need_padding) {\n        size_t total_dgram_size = 0;\n        const size_t min_dpl = QUIC_MIN_INITIAL_DGRAM_LEN;\n        uint32_t pad_el = QUIC_ENC_LEVEL_NUM;\n\n        for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n             enc_level < QUIC_ENC_LEVEL_NUM;\n             ++enc_level)\n            if (pkt[enc_level].h_valid && pkt[enc_level].h.bytes_appended > 0) {\n                if (pad_el == QUIC_ENC_LEVEL_NUM\n                    /*\n                     * We might not be able to add padding, for example if we\n                     * are using the ACK_ONLY archetype.\n                     */\n                    && pkt[enc_level].geom.adata.allow_padding\n                    && !pkt[enc_level].h.done_implicit)\n                    pad_el = enc_level;\n\n                txp_pkt_postgen_update_pkt_overhead(&pkt[enc_level], txp);\n                total_dgram_size += pkt[enc_level].geom.pkt_overhead\n                    + pkt[enc_level].h.bytes_appended;\n            }\n\n        if (pad_el != QUIC_ENC_LEVEL_NUM && total_dgram_size < min_dpl) {\n            size_t deficit = min_dpl - total_dgram_size;\n\n            if (!txp_pkt_append_padding(&pkt[pad_el], txp, deficit))\n                goto out;\n\n            total_dgram_size += deficit;\n\n            /*\n             * Padding frames make a packet ineligible for being a non-inflight\n             * packet.\n             */\n            pkt[pad_el].tpkt->ackm_pkt.is_inflight = 1;\n        }\n\n        /*\n         * If we have failed to make a datagram of adequate size, for example\n         * because we have a padding requirement but are using the ACK_ONLY\n         * archetype (because we are CC limited), which precludes us from\n         * sending padding, give up on generating the datagram - there is\n         * nothing we can do.\n         */\n        if (total_dgram_size < min_dpl) {\n            res = 1;\n            goto out;\n        }\n    }\n\n    /* 4. Commit */\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level) {\n\n        if (!pkt[enc_level].h_valid)\n            /* Did not attempt to generate a packet for this EL. */\n            continue;\n\n        if (pkt[enc_level].h.bytes_appended == 0)\n            /* Nothing was generated for this EL, so skip. */\n            continue;\n\n        rc = txp_pkt_commit(txp, &pkt[enc_level], archetype,\n                            &txpim_pkt_reffed);\n        if (rc) {\n            status->sent_ack_eliciting\n                = status->sent_ack_eliciting\n                || pkt[enc_level].tpkt->ackm_pkt.is_ack_eliciting;\n\n            if (enc_level == QUIC_ENC_LEVEL_HANDSHAKE)\n                status->sent_handshake\n                    = (pkt[enc_level].h_valid\n                       && pkt[enc_level].h.bytes_appended > 0);\n        }\n\n        if (txpim_pkt_reffed)\n            pkt[enc_level].tpkt = NULL; /* don't free */\n\n        if (!rc)\n            goto out;\n\n        ++pkts_done;\n    }\n\n    /* Flush & Cleanup */\n    res = 1;\nout:\n    ossl_qtx_finish_dgram(txp->args.qtx);\n\n    for (enc_level = QUIC_ENC_LEVEL_INITIAL;\n         enc_level < QUIC_ENC_LEVEL_NUM;\n         ++enc_level)\n        txp_pkt_cleanup(&pkt[enc_level], txp);\n\n    status->sent_pkt = pkts_done;\n\n    return res;\n}\n\nstatic const struct archetype_data archetypes[QUIC_ENC_LEVEL_NUM][TX_PACKETISER_ARCHETYPE_NUM] = {\n    /* EL 0(INITIAL) */\n    {\n        /* EL 0(INITIAL) - Archetype 0(NORMAL) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 0,\n        },\n        /* EL 0(INITIAL) - Archetype 1(PROBE) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 1,\n            /*bypass_cc                       =*/ 1,\n        },\n        /* EL 0(INITIAL) - Archetype 2(ACK_ONLY) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 0,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 0,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 0,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 1,\n        },\n    },\n    /* EL 1(HANDSHAKE) */\n    {\n        /* EL 1(HANDSHAKE) - Archetype 0(NORMAL) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 0,\n        },\n        /* EL 1(HANDSHAKE) - Archetype 1(PROBE) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 1,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 1,\n            /*bypass_cc                       =*/ 1,\n        },\n        /* EL 1(HANDSHAKE) - Archetype 2(ACK_ONLY) */\n        {\n            /*allow_ack                       =*/ 1,\n            /*allow_ping                      =*/ 0,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 0,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 1,\n            /*allow_padding                   =*/ 0,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 1,\n        },\n    },\n    /* EL 2(0RTT) */\n    {\n        /* EL 2(0RTT) - Archetype 0(NORMAL) */\n        {\n            /*allow_ack                       =*/ 0,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 1,\n            /*allow_retire_conn_id            =*/ 1,\n            /*allow_stream_rel                =*/ 1,\n            /*allow_conn_fc                   =*/ 1,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 0,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 0,\n        },\n        /* EL 2(0RTT) - Archetype 1(PROBE) */\n        {\n            /*allow_ack                       =*/ 0,\n            /*allow_ping                      =*/ 1,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 1,\n            /*allow_retire_conn_id            =*/ 1,\n            /*allow_stream_rel                =*/ 1,\n            /*allow_conn_fc                   =*/ 1,\n            /*allow_conn_close                =*/ 1,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 0,\n            /*allow_padding                   =*/ 1,\n            /*require_ack_eliciting           =*/ 1,\n            /*bypass_cc                       =*/ 1,\n        },\n        /* EL 2(0RTT) - Archetype 2(ACK_ONLY) */\n        {\n            /*allow_ack                       =*/ 0,\n            /*allow_ping                      =*/ 0,\n            /*allow_crypto                    =*/ 0,\n            /*allow_handshake_done            =*/ 0,\n            /*allow_path_challenge            =*/ 0,\n            /*allow_path_response             =*/ 0,\n            /*allow_new_conn_id               =*/ 0,\n            /*allow_retire_conn_id            =*/ 0,\n            /*allow_stream_rel                =*/ 0,\n            /*allow_conn_fc                   =*/ 0,\n            /*allow_conn_close                =*/ 0,\n            /*allow_cfq_other                 =*/ 0,\n            /*allow_new_token                 =*/ 0,\n            /*allow_force_ack_eliciting       =*/ 0,\n            /*allow_padding                   =*/ 0,\n            /*require_ack_eliciting           =*/ 0,\n            /*bypass_cc                       =*/ 1,\n        },\n    },\n"}, {"id": "5DC12F010828A601", "name": "ossl_quic_tx_packetiser_st::initial_token_free_cb", "path": "openssl/ssl/quic/quic_txp.c", "start": {"line": 60, "col": 38}, "end": {"line": 60, "col": 38}, "code": "    void                            *initial_token_free_cb_arg;\n\n    /* Subcomponents of the TXP that we own. */\n    QUIC_FIFD       fifd;       /* QUIC Frame-in-Flight Dispatcher */\n\n    /* Internal state. */\n    uint64_t        next_pn[QUIC_PN_SPACE_NUM]; /* Next PN to use in given PN space. */\n    OSSL_TIME       last_tx_time;               /* Last time a packet was generated, or 0. */\n\n    /* Internal state - frame (re)generation flags. */\n    unsigned int    want_handshake_done     : 1;\n    unsigned int    want_max_data           : 1;\n    unsigned int    want_max_streams_bidi   : 1;\n    unsigned int    want_max_streams_uni    : 1;\n\n    /* Internal state - frame (re)generation flags - per PN space. */\n    unsigned int    want_ack                : QUIC_PN_SPACE_NUM;\n    unsigned int    force_ack_eliciting     : QUIC_PN_SPACE_NUM;\n\n    /*\n     * Internal state - connection close terminal state.\n     * Once this is set, it is not unset unlike other want_ flags - we keep\n     * sending it in every packet.\n     */\n    unsigned int    want_conn_close         : 1;\n\n    /* Has the handshake been completed? */\n    unsigned int    handshake_complete      : 1;\n\n    OSSL_QUIC_FRAME_CONN_CLOSE  conn_close_frame;\n\n    /*\n     * Counts of the number of bytes received and sent while in the closing\n     * state.\n     */\n    uint64_t                        closing_bytes_recv;\n    uint64_t                        closing_bytes_xmit;\n\n    /* Internal state - packet assembly. */\n    struct txp_el {\n        unsigned char   *scratch;       /* scratch buffer for packet assembly */\n        size_t          scratch_len;    /* number of bytes allocated for scratch */\n        OSSL_QTX_IOVEC  *iovec;         /* scratch iovec array for use with QTX */\n        size_t          alloc_iovec;    /* size of iovec array */\n    } el[QUIC_ENC_LEVEL_NUM];\n\n    /* Message callback related arguments */\n    ossl_msg_cb msg_callback;\n    void *msg_callback_arg;\n    SSL *msg_callback_ssl;\n\n    /* Callbacks. */\n    void            (*ack_tx_cb)(const OSSL_QUIC_FRAME_ACK *ack,\n                                 uint32_t pn_space,\n                                 void *arg);\n    void            *ack_tx_cb_arg;\n};\n\n/*\n * The TX helper records state used while generating frames into packets. It\n * enables serialization into the packet to be done \"transactionally\" where\n"}], "code": "int ossl_quic_tx_packetiser_set_initial_token(OSSL_QUIC_TX_PACKETISER *txp,\n                                              const unsigned char *token,\n                                              size_t token_len,\n                                              ossl_quic_initial_token_free_fn *free_cb,\n                                              void *free_cb_arg)\n{\n    if (!txp_check_token_len(token_len, txp_get_mdpl(txp)))\n        return 0;\n\n    if (txp->initial_token != NULL && txp->initial_token_free_cb != NULL)\n        txp->initial_token_free_cb(txp->initial_token, txp->initial_token_len,\n                                   txp->initial_token_free_cb_arg);\n\n    txp->initial_token              = token;\n    txp->initial_token_len          = token_len;\n    txp->initial_token_free_cb      = free_cb;\n    txp->initial_token_free_cb_arg  = free_cb_arg;\n    return 1;\n}\n"}, "5659C3E7C6372047": {"calls": [{"id": "C71092D852A17B67", "name": "EVP_PKEY_decrypt", "path": "openssl/crypto/evp/asymcipher.c", "start": {"line": 269, "col": 1}, "end": {"line": 299, "col": 1}, "code": "                     unsigned char *out, size_t *outlen,\n                     const unsigned char *in, size_t inlen)\n{\n    int ret;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_OPERATION_NOT_SUPPORTED_FOR_THIS_KEYTYPE);\n        return -2;\n    }\n\n    if (ctx->operation != EVP_PKEY_OP_DECRYPT) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_OPERATION_NOT_INITIALIZED);\n        return -1;\n    }\n\n    if (ctx->op.ciph.algctx == NULL)\n        goto legacy;\n\n    ret = ctx->op.ciph.cipher->decrypt(ctx->op.ciph.algctx, out, outlen,\n                                       (out == NULL ? 0 : *outlen), in, inlen);\n    return ret;\n\n legacy:\n    if (ctx->pmeth == NULL || ctx->pmeth->decrypt == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_OPERATION_NOT_SUPPORTED_FOR_THIS_KEYTYPE);\n        return -2;\n    }\n    M_check_autoarg(ctx, out, outlen, EVP_F_EVP_PKEY_DECRYPT)\n        return ctx->pmeth->decrypt(ctx, out, outlen, in, inlen);\n}\n\n/* decrypt to new buffer of dynamic size, checking any pre-determined size */\nint evp_pkey_decrypt_alloc(EVP_PKEY_CTX *ctx, unsigned char **outp,\n                           size_t *outlenp, size_t expected_outlen,\n                           const unsigned char *in, size_t inlen)\n{\n    if (EVP_PKEY_decrypt(ctx, NULL, outlenp, in, inlen) <= 0\n            || (*outp = OPENSSL_malloc(*outlenp)) == NULL)\n        return -1;\n    if (EVP_PKEY_decrypt(ctx, *outp, outlenp, in, inlen) <= 0\n            || *outlenp == 0\n            || (expected_outlen != 0 && *outlenp != expected_outlen)) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_EVP_LIB);\n        OPENSSL_clear_free(*outp, *outlenp);\n        *outp = NULL;\n        return 0;\n    }\n    return 1;\n}\n\nstatic EVP_ASYM_CIPHER *evp_asym_cipher_new(OSSL_PROVIDER *prov)\n{\n    EVP_ASYM_CIPHER *cipher = OPENSSL_zalloc(sizeof(EVP_ASYM_CIPHER));\n\n    if (cipher == NULL)\n        return NULL;\n\n    if (!CRYPTO_NEW_REF(&cipher->refcnt, 1)) {\n        OPENSSL_free(cipher);\n        return NULL;\n    }\n    cipher->prov = prov;\n    ossl_provider_up_ref(prov);\n\n    return cipher;\n}\n\nstatic void *evp_asym_cipher_from_algorithm(int name_id,\n                                            const OSSL_ALGORITHM *algodef,\n                                            OSSL_PROVIDER *prov)\n{\n    const OSSL_DISPATCH *fns = algodef->implementation;\n    EVP_ASYM_CIPHER *cipher = NULL;\n    int ctxfncnt = 0, encfncnt = 0, decfncnt = 0;\n    int gparamfncnt = 0, sparamfncnt = 0;\n\n    if ((cipher = evp_asym_cipher_new(prov)) == NULL) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_EVP_LIB);\n        goto err;\n    }\n\n    cipher->name_id = name_id;\n    if ((cipher->type_name = ossl_algorithm_get1_first_name(algodef)) == NULL)\n        goto err;\n    cipher->description = algodef->algorithm_description;\n\n    for (; fns->function_id != 0; fns++) {\n        switch (fns->function_id) {\n        case OSSL_FUNC_ASYM_CIPHER_NEWCTX:\n            if (cipher->newctx != NULL)\n                break;\n            cipher->newctx = OSSL_FUNC_asym_cipher_newctx(fns);\n            ctxfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_ENCRYPT_INIT:\n            if (cipher->encrypt_init != NULL)\n                break;\n            cipher->encrypt_init = OSSL_FUNC_asym_cipher_encrypt_init(fns);\n            encfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_ENCRYPT:\n            if (cipher->encrypt != NULL)\n                break;\n            cipher->encrypt = OSSL_FUNC_asym_cipher_encrypt(fns);\n            encfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_DECRYPT_INIT:\n            if (cipher->decrypt_init != NULL)\n                break;\n            cipher->decrypt_init = OSSL_FUNC_asym_cipher_decrypt_init(fns);\n            decfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_DECRYPT:\n            if (cipher->decrypt != NULL)\n                break;\n            cipher->decrypt = OSSL_FUNC_asym_cipher_decrypt(fns);\n            decfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_FREECTX:\n            if (cipher->freectx != NULL)\n                break;\n            cipher->freectx = OSSL_FUNC_asym_cipher_freectx(fns);\n            ctxfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_DUPCTX:\n            if (cipher->dupctx != NULL)\n                break;\n            cipher->dupctx = OSSL_FUNC_asym_cipher_dupctx(fns);\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_GET_CTX_PARAMS:\n            if (cipher->get_ctx_params != NULL)\n                break;\n            cipher->get_ctx_params\n                = OSSL_FUNC_asym_cipher_get_ctx_params(fns);\n            gparamfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_GETTABLE_CTX_PARAMS:\n            if (cipher->gettable_ctx_params != NULL)\n                break;\n            cipher->gettable_ctx_params\n                = OSSL_FUNC_asym_cipher_gettable_ctx_params(fns);\n            gparamfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_SET_CTX_PARAMS:\n            if (cipher->set_ctx_params != NULL)\n                break;\n            cipher->set_ctx_params\n                = OSSL_FUNC_asym_cipher_set_ctx_params(fns);\n            sparamfncnt++;\n            break;\n        case OSSL_FUNC_ASYM_CIPHER_SETTABLE_CTX_PARAMS:\n            if (cipher->settable_ctx_params != NULL)\n                break;\n            cipher->settable_ctx_params\n                = OSSL_FUNC_asym_cipher_settable_ctx_params(fns);\n            sparamfncnt++;\n            break;\n        }\n    }\n    if (ctxfncnt != 2\n        || (encfncnt != 0 && encfncnt != 2)\n        || (decfncnt != 0 && decfncnt != 2)\n        || (encfncnt != 2 && decfncnt != 2)\n        || (gparamfncnt != 0 && gparamfncnt != 2)\n        || (sparamfncnt != 0 && sparamfncnt != 2)) {\n        /*\n         * In order to be a consistent set of functions we must have at least\n         * a set of context functions (newctx and freectx) as well as a pair of\n         * \"cipher\" functions: (encrypt_init, encrypt) or\n         * (decrypt_init decrypt). set_ctx_params and settable_ctx_params are\n         * optional, but if one of them is present then the other one must also\n         * be present. The same applies to get_ctx_params and\n         * gettable_ctx_params. The dupctx function is optional.\n         */\n        ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_PROVIDER_FUNCTIONS);\n        goto err;\n    }\n\n    return cipher;\n err:\n    EVP_ASYM_CIPHER_free(cipher);\n    return NULL;\n}\n\nvoid EVP_ASYM_CIPHER_free(EVP_ASYM_CIPHER *cipher)\n{\n    int i;\n\n    if (cipher == NULL)\n        return;\n    CRYPTO_DOWN_REF(&cipher->refcnt, &i);\n    if (i > 0)\n        return;\n    OPENSSL_free(cipher->type_name);\n    ossl_provider_free(cipher->prov);\n    CRYPTO_FREE_REF(&cipher->refcnt);\n    OPENSSL_free(cipher);\n}\n\nint EVP_ASYM_CIPHER_up_ref(EVP_ASYM_CIPHER *cipher)\n{\n    int ref = 0;\n\n    CRYPTO_UP_REF(&cipher->refcnt, &ref);\n    return 1;\n}\n\nOSSL_PROVIDER *EVP_ASYM_CIPHER_get0_provider(const EVP_ASYM_CIPHER *cipher)\n{\n    return cipher->prov;\n}\n\nEVP_ASYM_CIPHER *EVP_ASYM_CIPHER_fetch(OSSL_LIB_CTX *ctx, const char *algorithm,\n                                       const char *properties)\n{\n    return evp_generic_fetch(ctx, OSSL_OP_ASYM_CIPHER, algorithm, properties,\n                             evp_asym_cipher_from_algorithm,\n                             (int (*)(void *))EVP_ASYM_CIPHER_up_ref,\n                             (void (*)(void *))EVP_ASYM_CIPHER_free);\n}\n\nEVP_ASYM_CIPHER *evp_asym_cipher_fetch_from_prov(OSSL_PROVIDER *prov,\n                                                 const char *algorithm,\n                                                 const char *properties)\n{\n    return evp_generic_fetch_from_prov(prov, OSSL_OP_ASYM_CIPHER,\n                                       algorithm, properties,\n                                       evp_asym_cipher_from_algorithm,\n                                       (int (*)(void *))EVP_ASYM_CIPHER_up_ref,\n                                       (void (*)(void *))EVP_ASYM_CIPHER_free);\n}\n\nint EVP_ASYM_CIPHER_is_a(const EVP_ASYM_CIPHER *cipher, const char *name)\n{\n    return evp_is_a(cipher->prov, cipher->name_id, NULL, name);\n}\n\nint evp_asym_cipher_get_number(const EVP_ASYM_CIPHER *cipher)\n{\n    return cipher->name_id;\n}\n\nconst char *EVP_ASYM_CIPHER_get0_name(const EVP_ASYM_CIPHER *cipher)\n{\n    return cipher->type_name;\n}\n\nconst char *EVP_ASYM_CIPHER_get0_description(const EVP_ASYM_CIPHER *cipher)\n{\n    return cipher->description;\n}\n\nvoid EVP_ASYM_CIPHER_do_all_provided(OSSL_LIB_CTX *libctx,\n                                     void (*fn)(EVP_ASYM_CIPHER *cipher,\n                                                void *arg),\n                                     void *arg)\n{\n    evp_generic_do_all(libctx, OSSL_OP_ASYM_CIPHER,\n                       (void (*)(void *, void *))fn, arg,\n                       evp_asym_cipher_from_algorithm,\n                       (int (*)(void *))EVP_ASYM_CIPHER_up_ref,\n                       (void (*)(void *))EVP_ASYM_CIPHER_free);\n}\n\n\nint EVP_ASYM_CIPHER_names_do_all(const EVP_ASYM_CIPHER *cipher,\n                                 void (*fn)(const char *name, void *data),\n                                 void *data)\n{\n    if (cipher->prov != NULL)\n        return evp_names_do_all(cipher->prov, cipher->name_id, fn, data);\n\n    return 1;\n}\n\nconst OSSL_PARAM *EVP_ASYM_CIPHER_gettable_ctx_params(const EVP_ASYM_CIPHER *cip)\n{\n    void *provctx;\n\n    if (cip == NULL || cip->gettable_ctx_params == NULL)\n        return NULL;\n\n    provctx = ossl_provider_ctx(EVP_ASYM_CIPHER_get0_provider(cip));\n    return cip->gettable_ctx_params(NULL, provctx);\n}\n\nconst OSSL_PARAM *EVP_ASYM_CIPHER_settable_ctx_params(const EVP_ASYM_CIPHER *cip)\n{\n    void *provctx;\n\n    if (cip == NULL || cip->settable_ctx_params == NULL)\n        return NULL;\n\n    provctx = ossl_provider_ctx(EVP_ASYM_CIPHER_get0_provider(cip));\n    return cip->settable_ctx_params(NULL, provctx);\n}\n"}], "code": "int evp_pkey_decrypt_alloc(EVP_PKEY_CTX *ctx, unsigned char **outp,\n                           size_t *outlenp, size_t expected_outlen,\n                           const unsigned char *in, size_t inlen)\n{\n    if (EVP_PKEY_decrypt(ctx, NULL, outlenp, in, inlen) <= 0\n            || (*outp = OPENSSL_malloc(*outlenp)) == NULL)\n        return -1;\n    if (EVP_PKEY_decrypt(ctx, *outp, outlenp, in, inlen) <= 0\n            || *outlenp == 0\n            || (expected_outlen != 0 && *outlenp != expected_outlen)) {\n        ERR_raise(ERR_LIB_EVP, ERR_R_EVP_LIB);\n        OPENSSL_clear_free(*outp, *outlenp);\n        *outp = NULL;\n        return 0;\n    }\n    return 1;\n}\n"}, "148903C6EE544163": {"calls": [{"id": "BE6A9302D4A3BBD8", "name": "tls1_get_legacy_sigalg", "path": "openssl/ssl/t1_lib.c", "start": {"line": 1650, "col": 1}, "end": {"line": 1720, "col": 1}, "code": "                                                   int idx)\n{\n    if (idx == -1) {\n        if (s->server) {\n            size_t i;\n\n            /* Work out index corresponding to ciphersuite */\n            for (i = 0; i < s->ssl_pkey_num; i++) {\n                const SSL_CERT_LOOKUP *clu\n                    = ssl_cert_lookup_by_idx(i, SSL_CONNECTION_GET_CTX(s));\n\n                if (clu == NULL)\n                    continue;\n                if (clu->amask & s->s3.tmp.new_cipher->algorithm_auth) {\n                    idx = i;\n                    break;\n                }\n            }\n\n            /*\n             * Some GOST ciphersuites allow more than one signature algorithms\n             * */\n            if (idx == SSL_PKEY_GOST01 && s->s3.tmp.new_cipher->algorithm_auth != SSL_aGOST01) {\n                int real_idx;\n\n                for (real_idx = SSL_PKEY_GOST12_512; real_idx >= SSL_PKEY_GOST01;\n                     real_idx--) {\n                    if (s->cert->pkeys[real_idx].privatekey != NULL) {\n                        idx = real_idx;\n                        break;\n                    }\n                }\n            }\n            /*\n             * As both SSL_PKEY_GOST12_512 and SSL_PKEY_GOST12_256 indices can be used\n             * with new (aGOST12-only) ciphersuites, we should find out which one is available really.\n             */\n            else if (idx == SSL_PKEY_GOST12_256) {\n                int real_idx;\n\n                for (real_idx = SSL_PKEY_GOST12_512; real_idx >= SSL_PKEY_GOST12_256;\n                     real_idx--) {\n                     if (s->cert->pkeys[real_idx].privatekey != NULL) {\n                         idx = real_idx;\n                         break;\n                     }\n                }\n            }\n        } else {\n            idx = s->cert->key - s->cert->pkeys;\n        }\n    }\n    if (idx < 0 || idx >= (int)OSSL_NELEM(tls_default_sigalg))\n        return NULL;\n\n    if (SSL_USE_SIGALGS(s) || idx != SSL_PKEY_RSA) {\n        const SIGALG_LOOKUP *lu = tls1_lookup_sigalg(s, tls_default_sigalg[idx]);\n\n        if (lu == NULL)\n            return NULL;\n        if (!tls1_lookup_md(SSL_CONNECTION_GET_CTX(s), lu, NULL))\n            return NULL;\n        if (!tls12_sigalg_allowed(s, SSL_SECOP_SIGALG_SUPPORTED, lu))\n            return NULL;\n        return lu;\n    }\n    if (!tls12_sigalg_allowed(s, SSL_SECOP_SIGALG_SUPPORTED, &legacy_rsa_sigalg))\n        return NULL;\n    return &legacy_rsa_sigalg;\n}\n/* Set peer sigalg based key type */\nint tls1_set_peer_legacy_sigalg(SSL_CONNECTION *s, const EVP_PKEY *pkey)\n{\n    size_t idx;\n    const SIGALG_LOOKUP *lu;\n\n    if (ssl_cert_lookup_by_pkey(pkey, &idx, SSL_CONNECTION_GET_CTX(s)) == NULL)\n        return 0;\n    lu = tls1_get_legacy_sigalg(s, idx);\n    if (lu == NULL)\n        return 0;\n    s->s3.tmp.peer_sigalg = lu;\n    return 1;\n}\n\nsize_t tls12_get_psigalgs(SSL_CONNECTION *s, int sent, const uint16_t **psigs)\n{\n    /*\n     * If Suite B mode use Suite B sigalgs only, ignore any other\n     * preferences.\n     */\n    switch (tls1_suiteb(s)) {\n    case SSL_CERT_FLAG_SUITEB_128_LOS:\n        *psigs = suiteb_sigalgs;\n        return OSSL_NELEM(suiteb_sigalgs);\n\n    case SSL_CERT_FLAG_SUITEB_128_LOS_ONLY:\n        *psigs = suiteb_sigalgs;\n        return 1;\n\n    case SSL_CERT_FLAG_SUITEB_192_LOS:\n        *psigs = suiteb_sigalgs + 1;\n        return 1;\n    }\n    /*\n     *  We use client_sigalgs (if not NULL) if we're a server\n     *  and sending a certificate request or if we're a client and\n     *  determining which shared algorithm to use.\n     */\n    if ((s->server == sent) && s->cert->client_sigalgs != NULL) {\n        *psigs = s->cert->client_sigalgs;\n        return s->cert->client_sigalgslen;\n    } else if (s->cert->conf_sigalgs) {\n        *psigs = s->cert->conf_sigalgs;\n        return s->cert->conf_sigalgslen;\n    } else {\n        *psigs = SSL_CONNECTION_GET_CTX(s)->tls12_sigalgs;\n        return SSL_CONNECTION_GET_CTX(s)->tls12_sigalgs_len;\n    }\n}\n\n/*\n * Called by servers only. Checks that we have a sig alg that supports the\n * specified EC curve.\n */\nint tls_check_sigalg_curve(const SSL_CONNECTION *s, int curve)\n{\n   const uint16_t *sigs;\n   size_t siglen, i;\n\n    if (s->cert->conf_sigalgs) {\n        sigs = s->cert->conf_sigalgs;\n        siglen = s->cert->conf_sigalgslen;\n    } else {\n        sigs = SSL_CONNECTION_GET_CTX(s)->tls12_sigalgs;\n        siglen = SSL_CONNECTION_GET_CTX(s)->tls12_sigalgs_len;\n    }\n\n    for (i = 0; i < siglen; i++) {\n        const SIGALG_LOOKUP *lu = tls1_lookup_sigalg(s, sigs[i]);\n\n        if (lu == NULL)\n            continue;\n        if (lu->sig == EVP_PKEY_EC\n                && lu->curve != NID_undef\n                && curve == lu->curve)\n            return 1;\n    }\n\n    return 0;\n}\n\n/*\n * Return the number of security bits for the signature algorithm, or 0 on\n * error.\n */\nstatic int sigalg_security_bits(SSL_CTX *ctx, const SIGALG_LOOKUP *lu)\n{\n    const EVP_MD *md = NULL;\n    int secbits = 0;\n\n    if (!tls1_lookup_md(ctx, lu, &md))\n        return 0;\n    if (md != NULL)\n    {\n        int md_type = EVP_MD_get_type(md);\n\n        /* Security bits: half digest bits */\n        secbits = EVP_MD_get_size(md) * 4;\n        /*\n         * SHA1 and MD5 are known to be broken. Reduce security bits so that\n         * they're no longer accepted at security level 1. The real values don't\n         * really matter as long as they're lower than 80, which is our\n         * security level 1.\n         * https://eprint.iacr.org/2020/014 puts a chosen-prefix attack for\n         * SHA1 at 2^63.4 and MD5+SHA1 at 2^67.2\n         * https://documents.epfl.ch/users/l/le/lenstra/public/papers/lat.pdf\n         * puts a chosen-prefix attack for MD5 at 2^39.\n         */\n        if (md_type == NID_sha1)\n            secbits = 64;\n        else if (md_type == NID_md5_sha1)\n            secbits = 67;\n        else if (md_type == NID_md5)\n            secbits = 39;\n    } else {\n        /* Values from https://tools.ietf.org/html/rfc8032#section-8.5 */\n        if (lu->sigalg == TLSEXT_SIGALG_ed25519)\n            secbits = 128;\n        else if (lu->sigalg == TLSEXT_SIGALG_ed448)\n            secbits = 224;\n    }\n    /*\n     * For provider-based sigalgs we have secbits information available\n     * in the (provider-loaded) sigalg_list structure\n     */\n    if ((secbits == 0) && (lu->sig_idx >= SSL_PKEY_NUM)\n               && ((lu->sig_idx - SSL_PKEY_NUM) < (int)ctx->sigalg_list_len)) {\n        secbits = ctx->sigalg_list[lu->sig_idx - SSL_PKEY_NUM].secbits;\n    }\n    return secbits;\n}\n\n/*\n * Check signature algorithm is consistent with sent supported signature\n * algorithms and if so set relevant digest and signature scheme in\n * s.\n */\nint tls12_check_peer_sigalg(SSL_CONNECTION *s, uint16_t sig, EVP_PKEY *pkey)\n{\n    const uint16_t *sent_sigs;\n    const EVP_MD *md = NULL;\n    char sigalgstr[2];\n    size_t sent_sigslen, i, cidx;\n    int pkeyid = -1;\n    const SIGALG_LOOKUP *lu;\n    int secbits = 0;\n\n    pkeyid = EVP_PKEY_get_id(pkey);\n\n    if (SSL_CONNECTION_IS_TLS13(s)) {\n        /* Disallow DSA for TLS 1.3 */\n        if (pkeyid == EVP_PKEY_DSA) {\n            SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER, SSL_R_WRONG_SIGNATURE_TYPE);\n            return 0;\n        }\n        /* Only allow PSS for TLS 1.3 */\n        if (pkeyid == EVP_PKEY_RSA)\n            pkeyid = EVP_PKEY_RSA_PSS;\n    }\n    lu = tls1_lookup_sigalg(s, sig);\n    /* if this sigalg is loaded, set so far unknown pkeyid to its sig NID */\n    if ((pkeyid == EVP_PKEY_KEYMGMT) && (lu != NULL))\n        pkeyid = lu->sig;\n\n    /* Should never happen */\n    if (pkeyid == -1)\n        return -1;\n\n    /*\n     * Check sigalgs is known. Disallow SHA1/SHA224 with TLS 1.3. Check key type\n     * is consistent with signature: RSA keys can be used for RSA-PSS\n     */\n    if (lu == NULL\n        || (SSL_CONNECTION_IS_TLS13(s)\n            && (lu->hash == NID_sha1 || lu->hash == NID_sha224))\n        || (pkeyid != lu->sig\n        && (lu->sig != EVP_PKEY_RSA_PSS || pkeyid != EVP_PKEY_RSA))) {\n        SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER, SSL_R_WRONG_SIGNATURE_TYPE);\n        return 0;\n    }\n    /* Check the sigalg is consistent with the key OID */\n    if (!ssl_cert_lookup_by_nid(\n                 (pkeyid == EVP_PKEY_RSA_PSS) ? EVP_PKEY_get_id(pkey) : pkeyid,\n                 &cidx, SSL_CONNECTION_GET_CTX(s))\n            || lu->sig_idx != (int)cidx) {\n        SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER, SSL_R_WRONG_SIGNATURE_TYPE);\n        return 0;\n    }\n\n    if (pkeyid == EVP_PKEY_EC) {\n\n        /* Check point compression is permitted */\n        if (!tls1_check_pkey_comp(s, pkey)) {\n            SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER,\n                     SSL_R_ILLEGAL_POINT_COMPRESSION);\n            return 0;\n        }\n\n        /* For TLS 1.3 or Suite B check curve matches signature algorithm */\n        if (SSL_CONNECTION_IS_TLS13(s) || tls1_suiteb(s)) {\n            int curve = ssl_get_EC_curve_nid(pkey);\n\n            if (lu->curve != NID_undef && curve != lu->curve) {\n                SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER, SSL_R_WRONG_CURVE);\n                return 0;\n            }\n        }\n        if (!SSL_CONNECTION_IS_TLS13(s)) {\n            /* Check curve matches extensions */\n            if (!tls1_check_group_id(s, tls1_get_group_id(pkey), 1)) {\n                SSLfatal(s, SSL_AD_ILLEGAL_PARAMETER, SSL_R_WRONG_CURVE);\n                return 0;\n            }\n            if (tls1_suiteb(s)) {\n                /* Check sigalg matches a permissible Suite B value */\n                if (sig != TLSEXT_SIGALG_ecdsa_secp256r1_sha256\n                    && sig != TLSEXT_SIGALG_ecdsa_secp384r1_sha384) {\n                    SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE,\n                             SSL_R_WRONG_SIGNATURE_TYPE);\n                    return 0;\n                }\n            }\n        }\n    } else if (tls1_suiteb(s)) {\n        SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE, SSL_R_WRONG_SIGNATURE_TYPE);\n        return 0;\n    }\n\n    /* Check signature matches a type we sent */\n    sent_sigslen = tls12_get_psigalgs(s, 1, &sent_sigs);\n    for (i = 0; i < sent_sigslen; i++, sent_sigs++) {\n        if (sig == *sent_sigs)\n            break;\n    }\n    /* Allow fallback to SHA1 if not strict mode */\n    if (i == sent_sigslen && (lu->hash != NID_sha1\n        || s->cert->cert_flags & SSL_CERT_FLAGS_CHECK_TLS_STRICT)) {\n        SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE, SSL_R_WRONG_SIGNATURE_TYPE);\n        return 0;\n    }\n    if (!tls1_lookup_md(SSL_CONNECTION_GET_CTX(s), lu, &md)) {\n        SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE, SSL_R_UNKNOWN_DIGEST);\n        return 0;\n    }\n    /*\n     * Make sure security callback allows algorithm. For historical\n     * reasons we have to pass the sigalg as a two byte char array.\n     */\n    sigalgstr[0] = (sig >> 8) & 0xff;\n    sigalgstr[1] = sig & 0xff;\n    secbits = sigalg_security_bits(SSL_CONNECTION_GET_CTX(s), lu);\n    if (secbits == 0 ||\n        !ssl_security(s, SSL_SECOP_SIGALG_CHECK, secbits,\n                      md != NULL ? EVP_MD_get_type(md) : NID_undef,\n                      (void *)sigalgstr)) {\n        SSLfatal(s, SSL_AD_HANDSHAKE_FAILURE, SSL_R_WRONG_SIGNATURE_TYPE);\n        return 0;\n    }\n    /* Store the sigalg the peer uses */\n    s->s3.tmp.peer_sigalg = lu;\n    return 1;\n}\n\nint SSL_get_peer_signature_type_nid(const SSL *s, int *pnid)\n{\n    const SSL_CONNECTION *sc = SSL_CONNECTION_FROM_CONST_SSL(s);\n\n    if (sc == NULL)\n        return 0;\n\n    if (sc->s3.tmp.peer_sigalg == NULL)\n        return 0;\n    *pnid = sc->s3.tmp.peer_sigalg->sig;\n    return 1;\n}\n\nint SSL_get_signature_type_nid(const SSL *s, int *pnid)\n{\n    const SSL_CONNECTION *sc = SSL_CONNECTION_FROM_CONST_SSL(s);\n\n    if (sc == NULL)\n        return 0;\n\n    if (sc->s3.tmp.sigalg == NULL)\n        return 0;\n    *pnid = sc->s3.tmp.sigalg->sig;\n    return 1;\n}\n\n/*\n * Set a mask of disabled algorithms: an algorithm is disabled if it isn't\n * supported, doesn't appear in supported signature algorithms, isn't supported\n * by the enabled protocol versions or by the security level.\n *\n * This function should only be used for checking which ciphers are supported\n * by the client.\n *\n * Call ssl_cipher_disabled() to check that it's enabled or not.\n */\nint ssl_set_client_disabled(SSL_CONNECTION *s)\n{\n    s->s3.tmp.mask_a = 0;\n    s->s3.tmp.mask_k = 0;\n    ssl_set_sig_mask(&s->s3.tmp.mask_a, s, SSL_SECOP_SIGALG_MASK);\n    if (ssl_get_min_max_version(s, &s->s3.tmp.min_ver,\n                                &s->s3.tmp.max_ver, NULL) != 0)\n        return 0;\n"}], "code": "int tls1_set_peer_legacy_sigalg(SSL_CONNECTION *s, const EVP_PKEY *pkey)\n{\n    size_t idx;\n    const SIGALG_LOOKUP *lu;\n\n    if (ssl_cert_lookup_by_pkey(pkey, &idx, SSL_CONNECTION_GET_CTX(s)) == NULL)\n        return 0;\n    lu = tls1_get_legacy_sigalg(s, idx);\n    if (lu == NULL)\n        return 0;\n    s->s3.tmp.peer_sigalg = lu;\n    return 1;\n}\n"}, "1544A5B6387D628A": {"calls": [{"id": "71D3BB146E60DF8C", "name": "qrx_recycle_rxe", "path": "openssl/ssl/quic/quic_record_rx.c", "start": {"line": 430, "col": 1}, "end": {"line": 438, "col": 1}, "code": "{\n    /* RXE should not be in any list */\n    assert(ossl_list_rxe_prev(rxe) == NULL && ossl_list_rxe_next(rxe) == NULL);\n    rxe->pkt.hdr    = NULL;\n    rxe->pkt.peer   = NULL;\n    rxe->pkt.local  = NULL;\n    ossl_list_rxe_insert_tail(&qrx->rx_free, rxe);\n}\n\n/*\n * Given a pointer to a pointer pointing to a buffer and the size of that\n * buffer, copy the buffer into *prxe, expanding the RXE if necessary (its\n * pointer may change due to realloc). *pi is the offset in bytes to copy the\n * buffer to, and on success is updated to be the offset pointing after the\n * copied buffer. *pptr is updated to point to the new location of the buffer.\n */\nstatic int qrx_relocate_buffer(OSSL_QRX *qrx, RXE **prxe, size_t *pi,\n                               const unsigned char **pptr, size_t buf_len)\n{\n    RXE *rxe;\n    unsigned char *dst;\n\n    if (!buf_len)\n        return 1;\n\n    if ((rxe = qrx_reserve_rxe(&qrx->rx_free, *prxe, *pi + buf_len)) == NULL)\n        return 0;\n\n    *prxe = rxe;\n    dst = (unsigned char *)rxe_data(rxe) + *pi;\n\n    memcpy(dst, *pptr, buf_len);\n    *pi += buf_len;\n    *pptr = dst;\n    return 1;\n}\n\nstatic uint32_t qrx_determine_enc_level(const QUIC_PKT_HDR *hdr)\n{\n    switch (hdr->type) {\n        case QUIC_PKT_TYPE_INITIAL:\n            return QUIC_ENC_LEVEL_INITIAL;\n        case QUIC_PKT_TYPE_HANDSHAKE:\n            return QUIC_ENC_LEVEL_HANDSHAKE;\n        case QUIC_PKT_TYPE_0RTT:\n            return QUIC_ENC_LEVEL_0RTT;\n        case QUIC_PKT_TYPE_1RTT:\n            return QUIC_ENC_LEVEL_1RTT;\n\n        default:\n            assert(0);\n        case QUIC_PKT_TYPE_RETRY:\n        case QUIC_PKT_TYPE_VERSION_NEG:\n            return QUIC_ENC_LEVEL_INITIAL; /* not used */\n    }\n}\n\nstatic uint32_t rxe_determine_pn_space(RXE *rxe)\n{\n    uint32_t enc_level;\n\n    enc_level = qrx_determine_enc_level(&rxe->hdr);\n    return ossl_quic_enc_level_to_pn_space(enc_level);\n}\n\nstatic int qrx_validate_hdr_early(OSSL_QRX *qrx, RXE *rxe,\n                                  const QUIC_CONN_ID *first_dcid)\n{\n    /* Ensure version is what we want. */\n    if (rxe->hdr.version != QUIC_VERSION_1\n        && rxe->hdr.version != QUIC_VERSION_NONE)\n        return 0;\n\n    /* Clients should never receive 0-RTT packets. */\n    if (rxe->hdr.type == QUIC_PKT_TYPE_0RTT)\n        return 0;\n\n    /* Version negotiation and retry packets must be the first packet. */\n    if (first_dcid != NULL && !ossl_quic_pkt_type_can_share_dgram(rxe->hdr.type))\n        return 0;\n\n    /*\n     * If this is not the first packet in a datagram, the destination connection\n     * ID must match the one in that packet.\n     */\n    if (first_dcid != NULL) {\n        if (!ossl_assert(first_dcid->id_len < QUIC_MAX_CONN_ID_LEN)\n            || !ossl_quic_conn_id_eq(first_dcid,\n                                     &rxe->hdr.dst_conn_id))\n        return 0;\n    }\n\n    return 1;\n}\n\n/* Validate header and decode PN. */\nstatic int qrx_validate_hdr(OSSL_QRX *qrx, RXE *rxe)\n{\n    int pn_space = rxe_determine_pn_space(rxe);\n\n    if (!ossl_quic_wire_decode_pkt_hdr_pn(rxe->hdr.pn, rxe->hdr.pn_len,\n                                          qrx->largest_pn[pn_space],\n                                          &rxe->pn))\n        return 0;\n\n    return 1;\n}\n\n/* Late packet header validation. */\nstatic int qrx_validate_hdr_late(OSSL_QRX *qrx, RXE *rxe)\n{\n    int pn_space = rxe_determine_pn_space(rxe);\n\n    /*\n     * Allow our user to decide whether to discard the packet before we try and\n     * decrypt it.\n     */\n    if (qrx->validation_cb != NULL\n        && !qrx->validation_cb(rxe->pn, pn_space, qrx->validation_cb_arg))\n        return 0;\n\n    return 1;\n}\n\n/*\n * Retrieves the correct cipher context for an EL and key phase. Writes the key\n * epoch number actually used for packet decryption to *rx_key_epoch.\n */\nstatic size_t qrx_get_cipher_ctx_idx(OSSL_QRX *qrx, OSSL_QRL_ENC_LEVEL *el,\n                                     uint32_t enc_level,\n                                     unsigned char key_phase_bit,\n                                     uint64_t *rx_key_epoch,\n                                     int *is_old_key)\n{\n    size_t idx;\n\n    *is_old_key = 0;\n\n    if (enc_level != QUIC_ENC_LEVEL_1RTT) {\n        *rx_key_epoch = 0;\n        return 0;\n    }\n\n    if (!ossl_assert(key_phase_bit <= 1))\n        return SIZE_MAX;\n\n    /*\n     * RFC 9001 requires that we not create timing channels which could reveal\n     * the decrypted value of the Key Phase bit. We usually handle this by\n     * keeping the cipher contexts for both the current and next key epochs\n     * around, so that we just select a cipher context blindly using the key\n     * phase bit, which is time-invariant.\n     *\n     * In the COOLDOWN state, we only have one keyslot/cipher context. RFC 9001\n     * suggests an implementation strategy to avoid creating a timing channel in\n     * this case:\n     *\n     *   Endpoints can use randomized packet protection keys in place of\n     *   discarded keys when key updates are not yet permitted.\n     *\n     * Rather than use a randomised key, we simply use our existing key as it\n     * will fail AEAD verification anyway. This avoids the need to keep around a\n     * dedicated garbage key.\n     *\n     * Note: Accessing different cipher contexts is technically not\n     * timing-channel safe due to microarchitectural side channels, but this is\n     * the best we can reasonably do and appears to be directly suggested by the\n     * RFC.\n     */\n    idx = (el->state == QRL_EL_STATE_PROV_COOLDOWN ? el->key_epoch & 1\n                                                   : key_phase_bit);\n\n    /*\n     * We also need to determine the key epoch number which this index\n     * corresponds to. This is so we can report the key epoch number in the\n     * OSSL_QRX_PKT structure, which callers need to validate whether it was OK\n     * for a packet to be sent using a given key epoch's keys.\n     */\n    switch (el->state) {\n    case QRL_EL_STATE_PROV_NORMAL:\n        /*\n         * If we are in the NORMAL state, usually the KP bit will match the LSB\n         * of our key epoch, meaning no new key update is being signalled. If it\n         * does not match, this means the packet (purports to) belong to\n         * the next key epoch.\n         *\n         * IMPORTANT: The AEAD tag has not been verified yet when this function\n         * is called, so this code must be timing-channel safe, hence use of\n         * XOR. Moreover, the value output below is not yet authenticated.\n         */\n        *rx_key_epoch\n            = el->key_epoch + ((el->key_epoch & 1) ^ (uint64_t)key_phase_bit);\n        break;\n\n    case QRL_EL_STATE_PROV_UPDATING:\n        /*\n         * If we are in the UPDATING state, usually the KP bit will match the\n         * LSB of our key epoch. If it does not match, this means that the\n         * packet (purports to) belong to the previous key epoch.\n         *\n         * As above, must be timing-channel safe.\n         */\n        *is_old_key = (el->key_epoch & 1) ^ (uint64_t)key_phase_bit;\n        *rx_key_epoch = el->key_epoch - (uint64_t)*is_old_key;\n        break;\n\n    case QRL_EL_STATE_PROV_COOLDOWN:\n        /*\n         * If we are in COOLDOWN, there is only one key epoch we can possibly\n         * decrypt with, so just try that. If AEAD decryption fails, the\n         * value we output here isn't used anyway.\n         */\n        *rx_key_epoch = el->key_epoch;\n        break;\n    }\n\n    return idx;\n}\n\n/*\n * Tries to decrypt a packet payload.\n *\n * Returns 1 on success or 0 on failure (which is permanent). The payload is\n * decrypted from src and written to dst. The buffer dst must be of at least\n * src_len bytes in length. The actual length of the output in bytes is written\n * to *dec_len on success, which will always be equal to or less than (usually\n * less than) src_len.\n */\nstatic int qrx_decrypt_pkt_body(OSSL_QRX *qrx, unsigned char *dst,\n                                const unsigned char *src,\n                                size_t src_len, size_t *dec_len,\n                                const unsigned char *aad, size_t aad_len,\n                                QUIC_PN pn, uint32_t enc_level,\n                                unsigned char key_phase_bit,\n                                uint64_t *rx_key_epoch)\n{\n    int l = 0, l2 = 0, is_old_key, nonce_len;\n    unsigned char nonce[EVP_MAX_IV_LENGTH];\n    size_t i, cctx_idx;\n    OSSL_QRL_ENC_LEVEL *el = ossl_qrl_enc_level_set_get(&qrx->el_set,\n                                                        enc_level, 1);\n    EVP_CIPHER_CTX *cctx;\n\n    if (src_len > INT_MAX || aad_len > INT_MAX)\n        return 0;\n\n    /* We should not have been called if we do not have key material. */\n    if (!ossl_assert(el != NULL))\n        return 0;\n\n    if (el->tag_len >= src_len)\n        return 0;\n\n    /*\n     * If we have failed to authenticate a certain number of ciphertexts, refuse\n     * to decrypt any more ciphertexts.\n     */\n    if (qrx->forged_pkt_count >= ossl_qrl_get_suite_max_forged_pkt(el->suite_id))\n        return 0;\n\n    cctx_idx = qrx_get_cipher_ctx_idx(qrx, el, enc_level, key_phase_bit,\n                                      rx_key_epoch, &is_old_key);\n    if (!ossl_assert(cctx_idx < OSSL_NELEM(el->cctx)))\n        return 0;\n\n    if (is_old_key && pn >= qrx->cur_epoch_start_pn)\n        /*\n         * RFC 9001 s. 5.5: Once an endpoint successfully receives a packet with\n         * a given PN, it MUST discard all packets in the same PN space with\n         * higher PNs if they cannot be successfully unprotected with the same\n         * key, or -- if there is a key update -- a subsequent packet protection\n         * key.\n         *\n         * In other words, once a PN x triggers a KU, it is invalid for us to\n         * receive a packet with a newer PN y (y > x) using the old keys.\n         */\n        return 0;\n\n    cctx = el->cctx[cctx_idx];\n\n    /* Construct nonce (nonce=IV ^ PN). */\n    nonce_len = EVP_CIPHER_CTX_get_iv_length(cctx);\n    if (!ossl_assert(nonce_len >= (int)sizeof(QUIC_PN)))\n        return 0;\n\n    memcpy(nonce, el->iv[cctx_idx], nonce_len);\n    for (i = 0; i < sizeof(QUIC_PN); ++i)\n        nonce[nonce_len - i - 1] ^= (unsigned char)(pn >> (i * 8));\n\n    /* type and key will already have been setup; feed the IV. */\n    if (EVP_CipherInit_ex(cctx, NULL,\n                          NULL, NULL, nonce, /*enc=*/0) != 1)\n        return 0;\n\n    /* Feed the AEAD tag we got so the cipher can validate it. */\n    if (EVP_CIPHER_CTX_ctrl(cctx, EVP_CTRL_AEAD_SET_TAG,\n                            el->tag_len,\n                            (unsigned char *)src + src_len - el->tag_len) != 1)\n        return 0;\n\n    /* Feed AAD data. */\n    if (EVP_CipherUpdate(cctx, NULL, &l, aad, aad_len) != 1)\n        return 0;\n\n    /* Feed encrypted packet body. */\n    if (EVP_CipherUpdate(cctx, dst, &l, src, src_len - el->tag_len) != 1)\n        return 0;\n\n    /* Ensure authentication succeeded. */\n    if (EVP_CipherFinal_ex(cctx, NULL, &l2) != 1) {\n        /* Authentication failed, increment failed auth counter. */\n        ++qrx->forged_pkt_count;\n        return 0;\n    }\n\n    *dec_len = l;\n    return 1;\n}\n\nstatic ossl_inline void ignore_res(int x)\n{\n    /* No-op. */\n}\n\nstatic void qrx_key_update_initiated(OSSL_QRX *qrx, QUIC_PN pn)\n{\n    if (!ossl_qrl_enc_level_set_key_update(&qrx->el_set, QUIC_ENC_LEVEL_1RTT))\n        /* We are already in RXKU, so we don't call the callback again. */\n        return;\n\n    qrx->cur_epoch_start_pn = pn;\n\n    if (qrx->key_update_cb != NULL)\n        qrx->key_update_cb(pn, qrx->key_update_cb_arg);\n}\n\n/* Process a single packet in a datagram. */\nstatic int qrx_process_pkt(OSSL_QRX *qrx, QUIC_URXE *urxe,\n                           PACKET *pkt, size_t pkt_idx,\n                           QUIC_CONN_ID *first_dcid,\n                           size_t datagram_len)\n{\n    RXE *rxe;\n    const unsigned char *eop = NULL;\n    size_t i, aad_len = 0, dec_len = 0;\n    PACKET orig_pkt = *pkt;\n    const unsigned char *sop = PACKET_data(pkt);\n    unsigned char *dst;\n    char need_second_decode = 0, already_processed = 0;\n    QUIC_PKT_HDR_PTRS ptrs;\n    uint32_t pn_space, enc_level;\n    OSSL_QRL_ENC_LEVEL *el = NULL;\n    uint64_t rx_key_epoch = UINT64_MAX;\n\n    /*\n     * Get a free RXE. If we need to allocate a new one, use the packet length\n     * as a good ballpark figure.\n     */\n    rxe = qrx_ensure_free_rxe(qrx, PACKET_remaining(pkt));\n    if (rxe == NULL)\n        return 0;\n\n    /* Have we already processed this packet? */\n    if (pkt_is_marked(&urxe->processed, pkt_idx))\n        already_processed = 1;\n\n    /*\n     * Decode the header into the RXE structure. We first decrypt and read the\n     * unprotected part of the packet header (unless we already removed header\n     * protection, in which case we decode all of it).\n     */\n    need_second_decode = !pkt_is_marked(&urxe->hpr_removed, pkt_idx);\n    if (!ossl_quic_wire_decode_pkt_hdr(pkt,\n                                       qrx->short_conn_id_len,\n                                       need_second_decode, 0, &rxe->hdr, &ptrs))\n        goto malformed;\n\n    /*\n     * Our successful decode above included an intelligible length and the\n     * PACKET is now pointing to the end of the QUIC packet.\n     */\n    eop = PACKET_data(pkt);\n\n    /*\n     * Make a note of the first packet's DCID so we can later ensure the\n     * destination connection IDs of all packets in a datagram match.\n     */\n    if (pkt_idx == 0)\n        *first_dcid = rxe->hdr.dst_conn_id;\n\n    /*\n     * Early header validation. Since we now know the packet length, we can also\n     * now skip over it if we already processed it.\n     */\n    if (already_processed\n        || !qrx_validate_hdr_early(qrx, rxe, pkt_idx == 0 ? NULL : first_dcid))\n        /*\n         * Already processed packets are handled identically to malformed\n         * packets; i.e., they are ignored.\n         */\n        goto malformed;\n\n    if (!ossl_quic_pkt_type_is_encrypted(rxe->hdr.type)) {\n        /*\n         * Version negotiation and retry packets are a special case. They do not\n         * contain a payload which needs decrypting and have no header\n         * protection.\n         */\n\n        /* Just copy the payload from the URXE to the RXE. */\n        if ((rxe = qrx_reserve_rxe(&qrx->rx_free, rxe, rxe->hdr.len)) == NULL)\n            /*\n             * Allocation failure. EOP will be pointing to the end of the\n             * datagram so processing of this datagram will end here.\n             */\n            goto malformed;\n\n        /* We are now committed to returning the packet. */\n        memcpy(rxe_data(rxe), rxe->hdr.data, rxe->hdr.len);\n        pkt_mark(&urxe->processed, pkt_idx);\n\n        rxe->hdr.data   = rxe_data(rxe);\n        rxe->pn         = QUIC_PN_INVALID;\n\n        rxe->data_len       = rxe->hdr.len;\n        rxe->datagram_len   = datagram_len;\n"}], "code": "void ossl_qrx_pkt_release(OSSL_QRX_PKT *pkt)\n{\n    RXE *rxe;\n\n    if (pkt == NULL)\n        return;\n\n    rxe = (RXE *)pkt;\n    assert(rxe->refcount > 0);\n    if (--rxe->refcount == 0)\n        qrx_recycle_rxe(pkt->qrx, rxe);\n}\n"}, "29F9962F61ED6A70": {"calls": [{"id": "FE5C4636C2249F23", "name": "ossl_quic_stream_map_visit", "path": "openssl/ssl/quic/quic_stream_map.c", "start": {"line": 133, "col": 1}, "end": {"line": 138, "col": 1}, "code": "                                void (*visit_cb)(QUIC_STREAM *stream, void *arg),\n                                void *visit_cb_arg)\n{\n    lh_QUIC_STREAM_doall_arg(qsm->map, visit_cb, visit_cb_arg);\n}\n\nQUIC_STREAM *ossl_quic_stream_map_alloc(QUIC_STREAM_MAP *qsm,\n                                        uint64_t stream_id,\n                                        int type)\n{\n    QUIC_STREAM *s;\n    QUIC_STREAM key;\n\n    key.id = stream_id;\n\n    s = lh_QUIC_STREAM_retrieve(qsm->map, &key);\n    if (s != NULL)\n        return NULL;\n\n    s = OPENSSL_zalloc(sizeof(*s));\n    if (s == NULL)\n        return NULL;\n\n    s->id           = stream_id;\n    s->type         = type;\n    s->as_server    = qsm->is_server;\n    s->send_state   = (ossl_quic_stream_is_local_init(s)\n                       || ossl_quic_stream_is_bidi(s))\n        ? QUIC_SSTREAM_STATE_READY\n        : QUIC_SSTREAM_STATE_NONE;\n    s->recv_state   = (!ossl_quic_stream_is_local_init(s)\n                       || ossl_quic_stream_is_bidi(s))\n        ? QUIC_RSTREAM_STATE_RECV\n        : QUIC_RSTREAM_STATE_NONE;\n\n    s->send_final_size  = UINT64_MAX;\n\n    lh_QUIC_STREAM_insert(qsm->map, s);\n    return s;\n}\n\nvoid ossl_quic_stream_map_release(QUIC_STREAM_MAP *qsm, QUIC_STREAM *stream)\n{\n    if (stream == NULL)\n        return;\n\n    if (stream->active_node.next != NULL)\n        list_remove(&qsm->active_list, &stream->active_node);\n    if (stream->accept_node.next != NULL)\n        list_remove(&qsm->accept_list, &stream->accept_node);\n    if (stream->ready_for_gc_node.next != NULL)\n        list_remove(&qsm->ready_for_gc_list, &stream->ready_for_gc_node);\n\n    ossl_quic_sstream_free(stream->sstream);\n    stream->sstream = NULL;\n\n    ossl_quic_rstream_free(stream->rstream);\n    stream->rstream = NULL;\n\n    lh_QUIC_STREAM_delete(qsm->map, stream);\n    OPENSSL_free(stream);\n}\n\nQUIC_STREAM *ossl_quic_stream_map_get_by_id(QUIC_STREAM_MAP *qsm,\n                                            uint64_t stream_id)\n{\n    QUIC_STREAM key;\n\n    key.id = stream_id;\n\n    return lh_QUIC_STREAM_retrieve(qsm->map, &key);\n}\n\nstatic void stream_map_mark_active(QUIC_STREAM_MAP *qsm, QUIC_STREAM *s)\n{\n    if (s->active)\n        return;\n\n    list_insert_tail(&qsm->active_list, &s->active_node);\n\n    if (qsm->rr_cur == NULL)\n        qsm->rr_cur = s;\n\n    s->active = 1;\n}\n\nstatic void stream_map_mark_inactive(QUIC_STREAM_MAP *qsm, QUIC_STREAM *s)\n{\n    if (!s->active)\n        return;\n\n    if (qsm->rr_cur == s)\n        qsm->rr_cur = active_next(&qsm->active_list, s);\n    if (qsm->rr_cur == s)\n        qsm->rr_cur = NULL;\n\n    list_remove(&qsm->active_list, &s->active_node);\n\n    s->active = 0;\n}\n\nvoid ossl_quic_stream_map_set_rr_stepping(QUIC_STREAM_MAP *qsm, size_t stepping)\n{\n    qsm->rr_stepping = stepping;\n    qsm->rr_counter  = 0;\n}\n\nstatic int stream_has_data_to_send(QUIC_STREAM *s)\n{\n    OSSL_QUIC_FRAME_STREAM shdr;\n    OSSL_QTX_IOVEC iov[2];\n    size_t num_iov;\n    uint64_t fc_credit, fc_swm, fc_limit;\n\n    switch (s->send_state) {\n    case QUIC_SSTREAM_STATE_READY:\n    case QUIC_SSTREAM_STATE_SEND:\n    case QUIC_SSTREAM_STATE_DATA_SENT:\n        /*\n         * We can still have data to send in DATA_SENT due to retransmissions,\n         * etc.\n         */\n        break;\n    default:\n        return 0; /* Nothing to send. */\n    }\n\n    /*\n     * We cannot determine if we have data to send simply by checking if\n     * ossl_quic_txfc_get_credit() is zero, because we may also have older\n     * stream data we need to retransmit. The SSTREAM returns older data first,\n     * so we do a simple comparison of the next chunk the SSTREAM wants to send\n     * against the TXFC CWM.\n     */\n    num_iov = OSSL_NELEM(iov);\n    if (!ossl_quic_sstream_get_stream_frame(s->sstream, 0, &shdr, iov,\n                                            &num_iov))\n        return 0;\n\n"}, {"id": "E8ECF3CDCE369B3C", "name": "lh_QUIC_STREAM_free", "path": "openssl/ssl/quic/quic_stream_map.c", "start": {"line": 17, "col": 1}, "end": {"line": 17, "col": 1}, "code": "\nstatic void shutdown_flush_done(QUIC_STREAM_MAP *qsm, QUIC_STREAM *qs);\n\n/* Circular list management. */\nstatic void list_insert_tail(QUIC_STREAM_LIST_NODE *l,\n                             QUIC_STREAM_LIST_NODE *n)\n{\n    /* Must not be in list. */\n    assert(n->prev == NULL && n->next == NULL\n           && l->prev != NULL && l->next != NULL);\n\n    n->prev = l->prev;\n    n->prev->next = n;\n    l->prev = n;\n    n->next = l;\n}\n\nstatic void list_remove(QUIC_STREAM_LIST_NODE *l,\n"}], "code": "void ossl_quic_stream_map_cleanup(QUIC_STREAM_MAP *qsm)\n{\n    ossl_quic_stream_map_visit(qsm, release_each, qsm);\n\n    lh_QUIC_STREAM_free(qsm->map);\n    qsm->map = NULL;\n}\n"}, "EE95207F8A1427E3": {"calls": [{"id": "F6024358DD1B45A6", "name": "check_ca", "path": "openssl/crypto/x509/v3_purp.c", "start": {"line": 653, "col": 1}, "end": {"line": 677, "col": 1}, "code": "{\n    /* keyUsage if present should allow cert signing */\n    if (ku_reject(x, KU_KEY_CERT_SIGN))\n        return 0;\n    if ((x->ex_flags & EXFLAG_BCONS) != 0) {\n        /* If basicConstraints says not a CA then say so */\n        return (x->ex_flags & EXFLAG_CA) != 0;\n    } else {\n        /* We support V1 roots for...  uh, I don't really know why. */\n        if ((x->ex_flags & V1_ROOT) == V1_ROOT)\n            return 3;\n        /*\n         * If key usage present it must have certSign so tolerate it\n         */\n        else if ((x->ex_flags & EXFLAG_KUSAGE) != 0)\n            return 4;\n        /* Older certificates could have Netscape-specific CA types */\n        else if ((x->ex_flags & EXFLAG_NSCERT) != 0\n                 && (x->ex_nscert & NS_ANY_CA) != 0)\n            return 5;\n        /* Can this still be regarded a CA certificate?  I doubt it. */\n        return 0;\n    }\n}\n\nvoid X509_set_proxy_flag(X509 *x)\n{\n    if (CRYPTO_THREAD_write_lock(x->lock)) {\n        x->ex_flags |= EXFLAG_PROXY;\n        CRYPTO_THREAD_unlock(x->lock);\n    }\n}\n\nvoid X509_set_proxy_pathlen(X509 *x, long l)\n{\n    x->ex_pcpathlen = l;\n}\n\nint X509_check_ca(X509 *x)\n{\n    /* Note 0 normally means \"not a CA\" - but in this case means error. */\n    if (!ossl_x509v3_cache_extensions(x))\n        return 0;\n\n    return check_ca(x);\n}\n\n/* Check SSL CA: common checks for SSL client and server. */\nstatic int check_ssl_ca(const X509 *x)\n{\n    int ca_ret = check_ca(x);\n\n    if (ca_ret == 0)\n        return 0;\n    /* Check nsCertType if present */\n    return ca_ret != 5 || (x->ex_nscert & NS_SSL_CA) != 0;\n}\n\nstatic int check_purpose_ssl_client(const X509_PURPOSE *xp, const X509 *x,\n                                    int non_leaf)\n{\n    if (xku_reject(x, XKU_SSL_CLIENT))\n        return 0;\n    if (non_leaf)\n        return check_ssl_ca(x);\n    /* We need to do digital signatures or key agreement */\n    if (ku_reject(x, KU_DIGITAL_SIGNATURE | KU_KEY_AGREEMENT))\n        return 0;\n    /* nsCertType if present should allow SSL client use */\n    if (ns_reject(x, NS_SSL_CLIENT))\n        return 0;\n    return 1;\n}\n\n/*\n * Key usage needed for TLS/SSL server: digital signature, encipherment or\n * key agreement. The ssl code can check this more thoroughly for individual\n * key types.\n */\n#define KU_TLS \\\n    KU_DIGITAL_SIGNATURE | KU_KEY_ENCIPHERMENT | KU_KEY_AGREEMENT\n\nstatic int check_purpose_ssl_server(const X509_PURPOSE *xp, const X509 *x,\n                                    int non_leaf)\n{\n    if (xku_reject(x, XKU_SSL_SERVER | XKU_SGC))\n        return 0;\n    if (non_leaf)\n        return check_ssl_ca(x);\n\n    if (ns_reject(x, NS_SSL_SERVER))\n        return 0;\n    if (ku_reject(x, KU_TLS))\n        return 0;\n\n    return 1;\n\n}\n\nstatic int check_purpose_ns_ssl_server(const X509_PURPOSE *xp, const X509 *x,\n                                       int non_leaf)\n{\n    int ret = check_purpose_ssl_server(xp, x, non_leaf);\n\n    if (!ret || non_leaf)\n        return ret;\n    /* We need to encipher or Netscape complains */\n    return ku_reject(x, KU_KEY_ENCIPHERMENT) ? 0 : ret;\n}\n\n/* common S/MIME checks */\nstatic int purpose_smime(const X509 *x, int non_leaf)\n{\n    if (xku_reject(x, XKU_SMIME))\n        return 0;\n    if (non_leaf) {\n        int ca_ret = check_ca(x);\n\n        if (ca_ret == 0)\n            return 0;\n        /* Check nsCertType if present */\n        if (ca_ret != 5 || (x->ex_nscert & NS_SMIME_CA) != 0)\n            return ca_ret;\n        else\n            return 0;\n    }\n    if ((x->ex_flags & EXFLAG_NSCERT) != 0) {\n        if ((x->ex_nscert & NS_SMIME) != 0)\n            return 1;\n        /* Workaround for some buggy certificates */\n        return (x->ex_nscert & NS_SSL_CLIENT) != 0 ? 2 : 0;\n    }\n    return 1;\n}\n\nstatic int check_purpose_smime_sign(const X509_PURPOSE *xp, const X509 *x,\n                                    int non_leaf)\n{\n    int ret = purpose_smime(x, non_leaf);\n\n    if (!ret || non_leaf)\n        return ret;\n    return ku_reject(x, KU_DIGITAL_SIGNATURE | KU_NON_REPUDIATION) ? 0 : ret;\n}\n\nstatic int check_purpose_smime_encrypt(const X509_PURPOSE *xp, const X509 *x,\n                                       int non_leaf)\n{\n    int ret = purpose_smime(x, non_leaf);\n\n    if (!ret || non_leaf)\n        return ret;\n    return ku_reject(x, KU_KEY_ENCIPHERMENT) ? 0 : ret;\n}\n\nstatic int check_purpose_crl_sign(const X509_PURPOSE *xp, const X509 *x,\n                                  int non_leaf)\n{\n    if (non_leaf) {\n        int ca_ret = check_ca(x);\n\n        return ca_ret == 2 ? 0 : ca_ret;\n    }\n    return !ku_reject(x, KU_CRL_SIGN);\n}\n\n/*\n * OCSP helper: this is *not* a full OCSP check. It just checks that each CA\n * is valid. Additional checks must be made on the chain.\n */\nstatic int check_purpose_ocsp_helper(const X509_PURPOSE *xp, const X509 *x,\n                                     int non_leaf)\n{\n    /*\n     * Must be a valid CA.  Should we really support the \"I don't know\" value\n     * (2)?\n     */\n    if (non_leaf)\n        return check_ca(x);\n    /* Leaf certificate is checked in OCSP_verify() */\n    return 1;\n}\n\nstatic int check_purpose_timestamp_sign(const X509_PURPOSE *xp, const X509 *x,\n                                        int non_leaf)\n{\n    int i_ext;\n\n    /*\n     * If non_leaf is true we must check if this is a valid CA certificate.\n     * The extra requirements by the CA/Browser Forum are not checked.\n     */\n    if (non_leaf)\n        return check_ca(x);\n\n    /*\n     * Key Usage is checked according to RFC 5280 and\n     * Extended Key Usage attributes is checked according to RFC 3161.\n     * The extra (and somewhat conflicting) CA/Browser Forum\n     * Baseline Requirements for the Issuance and Management of\n     * Publicly\u2010Trusted Code Signing Certificates, Version 3.0.0,\n     * Section 7.1.2.3: Code signing and Timestamp Certificate are not checked.\n     */\n    /*\n     * Check the optional key usage field:\n     * if Key Usage is present, it must be one of digitalSignature\n     * and/or nonRepudiation (other values are not consistent and shall\n     * be rejected).\n     */\n    if ((x->ex_flags & EXFLAG_KUSAGE) != 0\n        && ((x->ex_kusage & ~(KU_NON_REPUDIATION | KU_DIGITAL_SIGNATURE)) ||\n            !(x->ex_kusage & (KU_NON_REPUDIATION | KU_DIGITAL_SIGNATURE))))\n        return 0;\n\n    /* Only timestamp key usage is permitted and it's required. */\n    if ((x->ex_flags & EXFLAG_XKUSAGE) == 0 || x->ex_xkusage != XKU_TIMESTAMP)\n        return 0;\n\n    /* Extended Key Usage MUST be critical */\n    i_ext = X509_get_ext_by_NID(x, NID_ext_key_usage, -1);\n    if (i_ext >= 0\n            && !X509_EXTENSION_get_critical(X509_get_ext((X509 *)x, i_ext)))\n        return 0;\n    return 1;\n}\n\nstatic int check_purpose_code_sign(const X509_PURPOSE *xp, const X509 *x,\n                                   int non_leaf)\n{\n    int i_ext;\n\n    /*\n     * If non_leaf is true we must check if this is a valid CA certificate.\n     * The extra requirements by the CA/Browser Forum are not checked.\n     */\n    if (non_leaf)\n        return check_ca(x);\n\n    /*\n     * Check the key usage and extended key usage fields:\n     *\n     * Reference: CA/Browser Forum,\n     * Baseline Requirements for the Issuance and Management of\n     * Publicly\u2010Trusted Code Signing Certificates, Version 3.0.0,\n     * Section 7.1.2.3: Code signing and Timestamp Certificate\n     *\n     * Checking covers Key Usage and Extended Key Usage attributes.\n     * The certificatePolicies, cRLDistributionPoints (CDP), and\n     * authorityInformationAccess (AIA) extensions are so far not checked.\n     */\n    /* Key Usage */\n    if ((x->ex_flags & EXFLAG_KUSAGE) == 0)\n        return 0;\n    if ((x->ex_kusage & KU_DIGITAL_SIGNATURE) == 0)\n        return 0;\n    if ((x->ex_kusage & (KU_KEY_CERT_SIGN | KU_CRL_SIGN)) != 0)\n        return 0;\n\n    /* Key Usage MUST be critical */\n    i_ext = X509_get_ext_by_NID(x, NID_key_usage, -1);\n    if (i_ext < 0)\n        return 0;\n    if (i_ext >= 0) {\n        X509_EXTENSION *ext = X509_get_ext((X509 *)x, i_ext);\n        if (!X509_EXTENSION_get_critical(ext))\n            return 0;\n    }\n\n    /* Extended Key Usage */\n    if ((x->ex_flags & EXFLAG_XKUSAGE) == 0)\n        return 0;\n    if ((x->ex_xkusage & XKU_CODE_SIGN) == 0)\n        return 0;\n    if ((x->ex_xkusage & (XKU_ANYEKU | XKU_SSL_SERVER)) != 0)\n        return 0;\n\n    return 1;\n\n}\n\nstatic int no_check_purpose(const X509_PURPOSE *xp, const X509 *x,\n                            int non_leaf)\n{\n    return 1;\n}\n\n/*-\n * Various checks to see if one certificate potentially issued the second.\n * This can be used to prune a set of possible issuer certificates which\n * have been looked up using some simple method such as by subject name.\n * These are:\n * 1. issuer_name(subject) == subject_name(issuer)\n * 2. If akid(subject) exists, it matches the respective issuer fields.\n * 3. subject signature algorithm == issuer public key algorithm\n * 4. If key_usage(issuer) exists, it allows for signing subject.\n * Note that this does not include actually checking the signature.\n * Returns 0 for OK, or positive for reason for mismatch\n * where reason codes match those for X509_verify_cert().\n */\nint X509_check_issued(X509 *issuer, X509 *subject)\n{\n    int ret;\n\n    if ((ret = ossl_x509_likely_issued(issuer, subject)) != X509_V_OK)\n        return ret;\n    return ossl_x509_signing_allowed(issuer, subject);\n}\n\n/* do the checks 1., 2., and 3. as described above for X509_check_issued() */\nint ossl_x509_likely_issued(X509 *issuer, X509 *subject)\n{\n    int ret;\n\n    if (X509_NAME_cmp(X509_get_subject_name(issuer),\n                      X509_get_issuer_name(subject)) != 0)\n        return X509_V_ERR_SUBJECT_ISSUER_MISMATCH;\n\n    /* set issuer->skid and subject->akid */\n    if (!ossl_x509v3_cache_extensions(issuer)\n            || !ossl_x509v3_cache_extensions(subject))\n        return X509_V_ERR_UNSPECIFIED;\n\n    ret = X509_check_akid(issuer, subject->akid);\n    if (ret != X509_V_OK)\n        return ret;\n\n    /* Check if the subject signature alg matches the issuer's PUBKEY alg */\n    return check_sig_alg_match(X509_get0_pubkey(issuer), subject);\n}\n\n/*-\n * Check if certificate I<issuer> is allowed to issue certificate I<subject>\n * according to the B<keyUsage> field of I<issuer> if present\n * depending on any proxyCertInfo extension of I<subject>.\n * Returns 0 for OK, or positive for reason for rejection\n * where reason codes match those for X509_verify_cert().\n */\nint ossl_x509_signing_allowed(const X509 *issuer, const X509 *subject)\n{\n    if ((subject->ex_flags & EXFLAG_PROXY) != 0) {\n        if (ku_reject(issuer, KU_DIGITAL_SIGNATURE))\n            return X509_V_ERR_KEYUSAGE_NO_DIGITAL_SIGNATURE;\n    } else if (ku_reject(issuer, KU_KEY_CERT_SIGN)) {\n        return X509_V_ERR_KEYUSAGE_NO_CERTSIGN;\n    }\n    return X509_V_OK;\n}\n\nint X509_check_akid(const X509 *issuer, const AUTHORITY_KEYID *akid)\n{\n    if (akid == NULL)\n        return X509_V_OK;\n\n    /* Check key ids (if present) */\n    if (akid->keyid && issuer->skid &&\n        ASN1_OCTET_STRING_cmp(akid->keyid, issuer->skid))\n        return X509_V_ERR_AKID_SKID_MISMATCH;\n    /* Check serial number */\n    if (akid->serial &&\n        ASN1_INTEGER_cmp(X509_get0_serialNumber(issuer), akid->serial))\n        return X509_V_ERR_AKID_ISSUER_SERIAL_MISMATCH;\n    /* Check issuer name */\n    if (akid->issuer) {\n        /*\n         * Ugh, for some peculiar reason AKID includes SEQUENCE OF\n         * GeneralName. So look for a DirName. There may be more than one but\n         * we only take any notice of the first.\n         */\n        GENERAL_NAMES *gens = akid->issuer;\n        GENERAL_NAME *gen;\n        X509_NAME *nm = NULL;\n        int i;\n\n        for (i = 0; i < sk_GENERAL_NAME_num(gens); i++) {\n            gen = sk_GENERAL_NAME_value(gens, i);\n            if (gen->type == GEN_DIRNAME) {\n                nm = gen->d.dirn;\n                break;\n            }\n        }\n        if (nm != NULL && X509_NAME_cmp(nm, X509_get_issuer_name(issuer)) != 0)\n            return X509_V_ERR_AKID_ISSUER_SERIAL_MISMATCH;\n    }\n    return X509_V_OK;\n}\n\nuint32_t X509_get_extension_flags(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    X509_check_purpose(x, -1, 0);\n    return x->ex_flags;\n}\n\nuint32_t X509_get_key_usage(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return 0;\n    return (x->ex_flags & EXFLAG_KUSAGE) != 0 ? x->ex_kusage : UINT32_MAX;\n}\n\nuint32_t X509_get_extended_key_usage(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return 0;\n    return (x->ex_flags & EXFLAG_XKUSAGE) != 0 ? x->ex_xkusage : UINT32_MAX;\n}\n\nconst ASN1_OCTET_STRING *X509_get0_subject_key_id(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return x->skid;\n}\n\nconst ASN1_OCTET_STRING *X509_get0_authority_key_id(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return (x->akid != NULL ? x->akid->keyid : NULL);\n}\n\nconst GENERAL_NAMES *X509_get0_authority_issuer(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return (x->akid != NULL ? x->akid->issuer : NULL);\n}\n\nconst ASN1_INTEGER *X509_get0_authority_serial(X509 *x)\n{\n    /* Call for side-effect of computing hash and caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1)\n        return NULL;\n    return (x->akid != NULL ? x->akid->serial : NULL);\n}\n\nlong X509_get_pathlen(X509 *x)\n{\n    /* Called for side effect of caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1\n            || (x->ex_flags & EXFLAG_BCONS) == 0)\n        return -1;\n    return x->ex_pathlen;\n}\n\nlong X509_get_proxy_pathlen(X509 *x)\n{\n    /* Called for side effect of caching extensions */\n    if (X509_check_purpose(x, -1, 0) != 1\n            || (x->ex_flags & EXFLAG_PROXY) == 0)\n        return -1;\n    return x->ex_pcpathlen;\n}\n"}], "code": "static int check_purpose_ocsp_helper(const X509_PURPOSE *xp, const X509 *x,\n                                     int non_leaf)\n{\n    /*\n     * Must be a valid CA.  Should we really support the \"I don't know\" value\n     * (2)?\n     */\n    if (non_leaf)\n        return check_ca(x);\n    /* Leaf certificate is checked in OCSP_verify() */\n    return 1;\n}\n"}, "B3CA49AE50AA5553": {"calls": [{"id": "293AE9088D24B41A", "name": "free_list", "path": "openssl/ssl/quic/quic_txpim.c", "start": {"line": 44, "col": 1}, "end": {"line": 56, "col": 1}, "code": "{\n    QUIC_TXPIM_PKT_EX *n, *nnext;\n\n    for (n = l->head; n != NULL; n = nnext) {\n        nnext = n->next;\n\n        OPENSSL_free(n->chunks);\n        OPENSSL_free(n);\n    }\n\n    l->head = l->tail = NULL;\n}\n\nvoid ossl_quic_txpim_free(QUIC_TXPIM *txpim)\n{\n    if (txpim == NULL)\n        return;\n\n    assert(txpim->in_use == 0);\n    free_list(&txpim->free_list);\n    OPENSSL_free(txpim);\n}\n\nstatic void list_remove(QUIC_TXPIM_PKT_EX_LIST *l, QUIC_TXPIM_PKT_EX *n)\n{\n    if (l->head == n)\n        l->head = n->next;\n    if (l->tail == n)\n        l->tail = n->prev;\n    if (n->prev != NULL)\n        n->prev->next = n->next;\n    if (n->next != NULL)\n        n->next->prev = n->prev;\n    n->prev = n->next = NULL;\n}\n\nstatic void list_insert_tail(QUIC_TXPIM_PKT_EX_LIST *l, QUIC_TXPIM_PKT_EX *n)\n{\n    n->prev = l->tail;\n    n->next = NULL;\n    l->tail = n;\n    if (n->prev != NULL)\n        n->prev->next = n;\n    if (l->head == NULL)\n        l->head = n;\n}\n\nstatic QUIC_TXPIM_PKT_EX *txpim_get_free(QUIC_TXPIM *txpim)\n{\n    QUIC_TXPIM_PKT_EX *ex = txpim->free_list.head;\n\n    if (ex != NULL)\n        return ex;\n\n    ex = OPENSSL_zalloc(sizeof(*ex));\n    if (ex == NULL)\n        return NULL;\n"}], "code": "void ossl_quic_txpim_free(QUIC_TXPIM *txpim)\n{\n    if (txpim == NULL)\n        return;\n\n    assert(txpim->in_use == 0);\n    free_list(&txpim->free_list);\n    OPENSSL_free(txpim);\n}\n"}, "B14FF577E75F4333": {"calls": [{"id": "2D0DDE9449675B50", "name": "sk_EVP_MD_push", "path": "openssl/crypto/ts/ts_rsp_sign.c", "start": {"line": 22, "col": 1}, "end": {"line": 22, "col": 1}, "code": "\nstatic ASN1_INTEGER *def_serial_cb(struct TS_resp_ctx *, void *);\nstatic int def_time_cb(struct TS_resp_ctx *, void *, long *sec, long *usec);\nstatic int def_extension_cb(struct TS_resp_ctx *, X509_EXTENSION *, void *);\n\nstatic void ts_RESP_CTX_init(TS_RESP_CTX *ctx);\nstatic void ts_RESP_CTX_cleanup(TS_RESP_CTX *ctx);\nstatic int ts_RESP_check_request(TS_RESP_CTX *ctx);\nstatic ASN1_OBJECT *ts_RESP_get_policy(TS_RESP_CTX *ctx);\nstatic TS_TST_INFO *ts_RESP_create_tst_info(TS_RESP_CTX *ctx,\n                                            ASN1_OBJECT *policy);\nstatic int ts_RESP_process_extensions(TS_RESP_CTX *ctx);\nstatic int ts_RESP_sign(TS_RESP_CTX *ctx);\n\nstatic int ts_TST_INFO_content_new(PKCS7 *p7);\n\nstatic ASN1_GENERALIZEDTIME\n*TS_RESP_set_genTime_with_precision(ASN1_GENERALIZEDTIME *, long, long,\n                                    unsigned);\n\n/* Default callback for response generation. */\nstatic ASN1_INTEGER *def_serial_cb(struct TS_resp_ctx *ctx, void *data)\n{\n"}], "code": "int TS_RESP_CTX_add_md(TS_RESP_CTX *ctx, const EVP_MD *md)\n{\n    if (ctx->mds == NULL\n        && (ctx->mds = sk_EVP_MD_new_null()) == NULL)\n        goto err;\n    if (!sk_EVP_MD_push(ctx->mds, md))\n        goto err;\n\n    return 1;\n err:\n    ERR_raise(ERR_LIB_TS, ERR_R_CRYPTO_LIB);\n    return 0;\n}\n"}, "AE5A8AC3C44BCAB7": {"calls": [{"id": "5C5E04007B706BAD", "name": "safe_muldiv_int", "path": "openssl/crypto/stack/stack.c", "start": {"line": 18, "col": 1}, "end": {"line": 18, "col": 1}, "code": "\n/*\n * The initial number of nodes in the array.\n */\nstatic const int min_nodes = 4;\nstatic const int max_nodes = SIZE_MAX / sizeof(void *) < INT_MAX\n    ? (int)(SIZE_MAX / sizeof(void *)) : INT_MAX;\n\nstruct stack_st {\n    int num;\n    const void **data;\n    int sorted;\n    int num_alloc;\n    OPENSSL_sk_compfunc comp;\n};\n\nOPENSSL_sk_compfunc OPENSSL_sk_set_cmp_func(OPENSSL_STACK *sk,\n                                            OPENSSL_sk_compfunc c)\n{\n"}], "code": "static ossl_inline int compute_growth(int target, int current)\n{\n    int err = 0;\n\n    while (current < target) {\n        if (current >= max_nodes)\n            return 0;\n\n        current = safe_muldiv_int(current, 8, 5, &err);\n        if (err != 0)\n            return 0;\n        if (current >= max_nodes)\n            current = max_nodes;\n    }\n    return current;\n}\n"}, "EFA75CD487735403": {"calls": [{"id": "3F75826EF034DF73", "name": "ossl_qrl_enc_level_set_get", "path": "openssl/ssl/quic/quic_record_shared.c", "start": {"line": 20, "col": 1}, "end": {"line": 42, "col": 1}, "code": "                                               uint32_t enc_level,\n                                               int require_prov)\n{\n    OSSL_QRL_ENC_LEVEL *el;\n\n    if (!ossl_assert(enc_level < QUIC_ENC_LEVEL_NUM))\n        return NULL;\n\n    el = &els->el[enc_level];\n\n    if (require_prov)\n        switch (el->state) {\n            case QRL_EL_STATE_PROV_NORMAL:\n            case QRL_EL_STATE_PROV_UPDATING:\n            case QRL_EL_STATE_PROV_COOLDOWN:\n                break;\n            default:\n                return NULL;\n        }\n\n    return el;\n}\n\nint ossl_qrl_enc_level_set_have_el(OSSL_QRL_ENC_LEVEL_SET *els,\n                                  uint32_t enc_level)\n{\n    OSSL_QRL_ENC_LEVEL *el = ossl_qrl_enc_level_set_get(els, enc_level, 0);\n\n    switch (el->state) {\n        case QRL_EL_STATE_UNPROV:\n            return 0;\n        case QRL_EL_STATE_PROV_NORMAL:\n        case QRL_EL_STATE_PROV_UPDATING:\n        case QRL_EL_STATE_PROV_COOLDOWN:\n            return 1;\n        default:\n        case QRL_EL_STATE_DISCARDED:\n            return -1;\n    }\n}\n\nint ossl_qrl_enc_level_set_has_keyslot(OSSL_QRL_ENC_LEVEL_SET *els,\n                                       uint32_t enc_level,\n"}], "code": "int ossl_qrl_enc_level_set_have_el(OSSL_QRL_ENC_LEVEL_SET *els,\n                                  uint32_t enc_level)\n{\n    OSSL_QRL_ENC_LEVEL *el = ossl_qrl_enc_level_set_get(els, enc_level, 0);\n\n    switch (el->state) {\n        case QRL_EL_STATE_UNPROV:\n            return 0;\n        case QRL_EL_STATE_PROV_NORMAL:\n        case QRL_EL_STATE_PROV_UPDATING:\n        case QRL_EL_STATE_PROV_COOLDOWN:\n            return 1;\n        default:\n        case QRL_EL_STATE_DISCARDED:\n            return -1;\n    }\n}\n"}, "68294A4C6AA331E0": {"calls": [{"id": "1674D32858218867", "name": "ossl_statem_set_in_init", "path": "openssl/ssl/statem/statem.c", "start": {"line": 200, "col": 1}, "end": {"line": 205, "col": 1}, "code": "{\n    s->statem.in_init = init;\n    if (s->rlayer.rrlmethod != NULL && s->rlayer.rrlmethod->set_in_init != NULL)\n        s->rlayer.rrlmethod->set_in_init(s->rlayer.rrl, init);\n}\n\nint ossl_statem_get_in_handshake(SSL_CONNECTION *s)\n{\n    return s->statem.in_handshake;\n}\n\nvoid ossl_statem_set_in_handshake(SSL_CONNECTION *s, int inhand)\n{\n    if (inhand)\n        s->statem.in_handshake++;\n    else\n        s->statem.in_handshake--;\n}\n\n/* Are we in a sensible state to skip over unreadable early data? */\nint ossl_statem_skip_early_data(SSL_CONNECTION *s)\n{\n    if (s->ext.early_data != SSL_EARLY_DATA_REJECTED)\n        return 0;\n\n    if (!s->server\n            || s->statem.hand_state != TLS_ST_EARLY_DATA\n            || s->hello_retry_request == SSL_HRR_COMPLETE)\n        return 0;\n\n    return 1;\n}\n\n/*\n * Called when we are in SSL_read*(), SSL_write*(), or SSL_accept()\n * /SSL_connect()/SSL_do_handshake(). Used to test whether we are in an early\n * data state and whether we should attempt to move the handshake on if so.\n * |sending| is 1 if we are attempting to send data (SSL_write*()), 0 if we are\n * attempting to read data (SSL_read*()), or -1 if we are in SSL_do_handshake()\n * or similar.\n */\nvoid ossl_statem_check_finish_init(SSL_CONNECTION *s, int sending)\n{\n    if (sending == -1) {\n        if (s->statem.hand_state == TLS_ST_PENDING_EARLY_DATA_END\n                || s->statem.hand_state == TLS_ST_EARLY_DATA) {\n            ossl_statem_set_in_init(s, 1);\n            if (s->early_data_state == SSL_EARLY_DATA_WRITE_RETRY) {\n                /*\n                 * SSL_connect() or SSL_do_handshake() has been called directly.\n                 * We don't allow any more writing of early data.\n                 */\n                s->early_data_state = SSL_EARLY_DATA_FINISHED_WRITING;\n            }\n        }\n    } else if (!s->server) {\n        if ((sending && (s->statem.hand_state == TLS_ST_PENDING_EARLY_DATA_END\n                      || s->statem.hand_state == TLS_ST_EARLY_DATA)\n                  && s->early_data_state != SSL_EARLY_DATA_WRITING)\n                || (!sending && s->statem.hand_state == TLS_ST_EARLY_DATA)) {\n            ossl_statem_set_in_init(s, 1);\n            /*\n             * SSL_write() has been called directly. We don't allow any more\n             * writing of early data.\n             */\n            if (sending && s->early_data_state == SSL_EARLY_DATA_WRITE_RETRY)\n                s->early_data_state = SSL_EARLY_DATA_FINISHED_WRITING;\n        }\n    } else {\n        if (s->early_data_state == SSL_EARLY_DATA_FINISHED_READING\n                && s->statem.hand_state == TLS_ST_EARLY_DATA)\n            ossl_statem_set_in_init(s, 1);\n    }\n}\n\nvoid ossl_statem_set_hello_verify_done(SSL_CONNECTION *s)\n{\n    s->statem.state = MSG_FLOW_UNINITED;\n    ossl_statem_set_in_init(s, 1);\n    /*\n     * This will get reset (briefly) back to TLS_ST_BEFORE when we enter\n     * state_machine() because |state| is MSG_FLOW_UNINITED, but until then any\n     * calls to SSL_in_before() will return false. Also calls to\n     * SSL_state_string() and SSL_state_string_long() will return something\n     * sensible.\n     */\n    s->statem.hand_state = TLS_ST_SR_CLNT_HELLO;\n}\n\nint ossl_statem_connect(SSL *s)\n{\n    SSL_CONNECTION *sc = SSL_CONNECTION_FROM_SSL(s);\n\n    if (sc == NULL)\n        return -1;\n\n    return state_machine(sc, 0);\n}\n\nint ossl_statem_accept(SSL *s)\n{\n    SSL_CONNECTION *sc = SSL_CONNECTION_FROM_SSL(s);\n\n    if (sc == NULL)\n        return -1;\n\n    return state_machine(sc, 1);\n}\n\ntypedef void (*info_cb) (const SSL *, int, int);\n\nstatic info_cb get_callback(SSL_CONNECTION *s)\n{\n    SSL_CTX *sctx = SSL_CONNECTION_GET_CTX(s);\n\n    if (s->info_callback != NULL)\n        return s->info_callback;\n    else if (sctx->info_callback != NULL)\n        return sctx->info_callback;\n\n    return NULL;\n}\n\n/*\n * The main message flow state machine. We start in the MSG_FLOW_UNINITED or\n * MSG_FLOW_FINISHED state and finish in MSG_FLOW_FINISHED. Valid states and\n * transitions are as follows:\n *\n * MSG_FLOW_UNINITED     MSG_FLOW_FINISHED\n *        |                       |\n *        +-----------------------+\n *        v\n * MSG_FLOW_WRITING <---> MSG_FLOW_READING\n *        |\n *        V\n * MSG_FLOW_FINISHED\n *        |\n *        V\n *    [SUCCESS]\n *\n * We may exit at any point due to an error or NBIO event. If an NBIO event\n * occurs then we restart at the point we left off when we are recalled.\n * MSG_FLOW_WRITING and MSG_FLOW_READING have sub-state machines associated with them.\n *\n * In addition to the above there is also the MSG_FLOW_ERROR state. We can move\n * into that state at any point in the event that an irrecoverable error occurs.\n *\n * Valid return values are:\n *   1: Success\n * <=0: NBIO or error\n */\nstatic int state_machine(SSL_CONNECTION *s, int server)\n{\n    BUF_MEM *buf = NULL;\n    void (*cb) (const SSL *ssl, int type, int val) = NULL;\n    OSSL_STATEM *st = &s->statem;\n    int ret = -1;\n    int ssret;\n    SSL *ssl = SSL_CONNECTION_GET_SSL(s);\n\n    if (st->state == MSG_FLOW_ERROR) {\n        /* Shouldn't have been called if we're already in the error state */\n        return -1;\n    }\n\n    ERR_clear_error();\n    clear_sys_error();\n\n    cb = get_callback(s);\n\n    st->in_handshake++;\n    if (!SSL_in_init(ssl) || SSL_in_before(ssl)) {\n        /*\n         * If we are stateless then we already called SSL_clear() - don't do\n         * it again and clear the STATELESS flag itself.\n         */\n        if ((s->s3.flags & TLS1_FLAGS_STATELESS) == 0 && !SSL_clear(ssl))\n            return -1;\n    }\n#ifndef OPENSSL_NO_SCTP\n    if (SSL_CONNECTION_IS_DTLS(s) && BIO_dgram_is_sctp(SSL_get_wbio(ssl))) {\n        /*\n         * Notify SCTP BIO socket to enter handshake mode and prevent stream\n         * identifier other than 0.\n         */\n        BIO_ctrl(SSL_get_wbio(ssl), BIO_CTRL_DGRAM_SCTP_SET_IN_HANDSHAKE,\n                 st->in_handshake, NULL);\n    }\n#endif\n\n    /* Initialise state machine */\n    if (st->state == MSG_FLOW_UNINITED\n            || st->state == MSG_FLOW_FINISHED) {\n        if (st->state == MSG_FLOW_UNINITED) {\n            st->hand_state = TLS_ST_BEFORE;\n            st->request_state = TLS_ST_BEFORE;\n        }\n\n        s->server = server;\n        if (cb != NULL) {\n            if (SSL_IS_FIRST_HANDSHAKE(s) || !SSL_CONNECTION_IS_TLS13(s))\n                cb(ssl, SSL_CB_HANDSHAKE_START, 1);\n        }\n\n        /*\n         * Fatal errors in this block don't send an alert because we have\n"}], "code": "void ossl_statem_set_renegotiate(SSL_CONNECTION *s)\n{\n    ossl_statem_set_in_init(s, 1);\n    s->statem.request_state = TLS_ST_SW_HELLO_REQ;\n}\n"}, "7910A7A9D34B934F": {"calls": [{"id": "210FA53C9E7D253D", "name": "SXNET_add_id_INTEGER", "path": "openssl/crypto/x509/v3_sxnet.c", "start": {"line": 160, "col": 1}, "end": {"line": 217, "col": 1}, "code": "                         int userlen)\n{\n    SXNET *sx = NULL;\n    SXNETID *id = NULL;\n\n    if (psx == NULL || zone == NULL || user == NULL) {\n        ERR_raise(ERR_LIB_X509V3, X509V3_R_INVALID_NULL_ARGUMENT);\n        return 0;\n    }\n    if (userlen == -1)\n        userlen = strlen(user);\n    if (userlen > 64) {\n        ERR_raise(ERR_LIB_X509V3, X509V3_R_USER_TOO_LONG);\n        return 0;\n    }\n    if (*psx == NULL) {\n        if ((sx = SXNET_new()) == NULL) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_ASN1_LIB);\n            goto err;\n        }\n        if (!ASN1_INTEGER_set(sx->version, 0)) {\n            ERR_raise(ERR_LIB_X509V3, ERR_R_ASN1_LIB);\n            goto err;\n        }\n    } else\n        sx = *psx;\n    if (SXNET_get_id_INTEGER(sx, zone)) {\n        ERR_raise(ERR_LIB_X509V3, X509V3_R_DUPLICATE_ZONE_ID);\n        if (*psx == NULL)\n            SXNET_free(sx);\n        return 0;\n    }\n\n    if ((id = SXNETID_new()) == NULL) {\n        ERR_raise(ERR_LIB_X509V3, ERR_R_ASN1_LIB);\n        goto err;\n    }\n\n    if (!ASN1_OCTET_STRING_set(id->user, (const unsigned char *)user, userlen)){\n        ERR_raise(ERR_LIB_X509V3, ERR_R_ASN1_LIB);\n        goto err;\n    }\n    if (!sk_SXNETID_push(sx->ids, id)) {\n        ERR_raise(ERR_LIB_X509V3, ERR_R_CRYPTO_LIB);\n        goto err;\n    }\n    ASN1_INTEGER_free(id->zone);\n    id->zone = zone;\n    *psx = sx;\n    return 1;\n\n err:\n    SXNETID_free(id);\n    if (*psx == NULL)\n        SXNET_free(sx);\n    return 0;\n}\n\nASN1_OCTET_STRING *SXNET_get_id_asc(SXNET *sx, const char *zone)\n{\n    ASN1_INTEGER *izone;\n    ASN1_OCTET_STRING *oct;\n\n    if ((izone = s2i_ASN1_INTEGER(NULL, zone)) == NULL) {\n        ERR_raise(ERR_LIB_X509V3, X509V3_R_ERROR_CONVERTING_ZONE);\n        return NULL;\n    }\n    oct = SXNET_get_id_INTEGER(sx, izone);\n    ASN1_INTEGER_free(izone);\n    return oct;\n}\n\nASN1_OCTET_STRING *SXNET_get_id_ulong(SXNET *sx, unsigned long lzone)\n{\n    ASN1_INTEGER *izone;\n    ASN1_OCTET_STRING *oct;\n\n    if ((izone = ASN1_INTEGER_new()) == NULL\n        || !ASN1_INTEGER_set(izone, lzone)) {\n        ERR_raise(ERR_LIB_X509V3, ERR_R_ASN1_LIB);\n        ASN1_INTEGER_free(izone);\n        return NULL;\n    }\n    oct = SXNET_get_id_INTEGER(sx, izone);\n    ASN1_INTEGER_free(izone);\n    return oct;\n}\n\nASN1_OCTET_STRING *SXNET_get_id_INTEGER(SXNET *sx, ASN1_INTEGER *zone)\n{\n    SXNETID *id;\n    int i;\n    for (i = 0; i < sk_SXNETID_num(sx->ids); i++) {\n        id = sk_SXNETID_value(sx->ids, i);\n        if (!ASN1_INTEGER_cmp(id->zone, zone))\n            return id->user;\n    }\n    return NULL;\n}\n"}, {"id": "0838F394C7150CBB", "name": "ASN1_INTEGER_free", "path": "openssl/crypto/asn1/tasn_typ.c", "start": {"line": 29, "col": 1}, "end": {"line": 29, "col": 1}, "code": "IMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_ENUMERATED)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_BIT_STRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_UTF8STRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_PRINTABLESTRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_T61STRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_IA5STRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_GENERALSTRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_UTCTIME)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_GENERALIZEDTIME)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_VISIBLESTRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_UNIVERSALSTRING)\nIMPLEMENT_ASN1_STRING_FUNCTIONS(ASN1_BMPSTRING)\n\nIMPLEMENT_ASN1_TYPE(ASN1_NULL)\nIMPLEMENT_ASN1_FUNCTIONS(ASN1_NULL)\n\nIMPLEMENT_ASN1_TYPE(ASN1_OBJECT)\n\nIMPLEMENT_ASN1_TYPE(ASN1_ANY)\n\n/* Just swallow an ASN1_SEQUENCE in an ASN1_STRING */\nIMPLEMENT_ASN1_TYPE(ASN1_SEQUENCE)\n\nIMPLEMENT_ASN1_FUNCTIONS_fname(ASN1_TYPE, ASN1_ANY, ASN1_TYPE)\n\n/* Multistring types */\n\nIMPLEMENT_ASN1_MSTRING(ASN1_PRINTABLE, B_ASN1_PRINTABLE)\nIMPLEMENT_ASN1_FUNCTIONS_name(ASN1_STRING, ASN1_PRINTABLE)\n\n"}], "code": "int SXNET_add_id_asc(SXNET **psx, const char *zone, const char *user, int userlen)\n{\n    ASN1_INTEGER *izone;\n\n    if ((izone = s2i_ASN1_INTEGER(NULL, zone)) == NULL) {\n        ERR_raise(ERR_LIB_X509V3, X509V3_R_ERROR_CONVERTING_ZONE);\n        return 0;\n    }\n    if (!SXNET_add_id_INTEGER(psx, izone, user, userlen)) {\n        ASN1_INTEGER_free(izone);\n        return 0;\n    }\n    return 1;\n}\n"}, "DB2F4F1BBCD12988": {"calls": [{"id": "F112F02841CAF7E0", "name": "EVP_PKEY_CTX_is_a", "path": "openssl/crypto/evp/pmeth_lib.c", "start": {"line": 654, "col": 1}, "end": {"line": 661, "col": 1}, "code": "{\n#ifndef FIPS_MODULE\n    if (evp_pkey_ctx_is_legacy(ctx))\n        return (ctx->pmeth->pkey_id == evp_pkey_name2type(keytype));\n#endif\n    return EVP_KEYMGMT_is_a(ctx->keymgmt, keytype);\n}\n\nint EVP_PKEY_CTX_set_params(EVP_PKEY_CTX *ctx, const OSSL_PARAM *params)\n{\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->set_ctx_params != NULL)\n            return\n                ctx->op.kex.exchange->set_ctx_params(ctx->op.kex.algctx,\n                                                     params);\n        if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->set_ctx_params != NULL)\n            return\n                ctx->op.sig.signature->set_ctx_params(ctx->op.sig.algctx,\n                                                      params);\n        if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->set_ctx_params != NULL)\n            return\n                ctx->op.ciph.cipher->set_ctx_params(ctx->op.ciph.algctx,\n                                                    params);\n        if (EVP_PKEY_CTX_IS_GEN_OP(ctx)\n            && ctx->keymgmt != NULL\n            && ctx->keymgmt->gen_set_params != NULL)\n            return\n                evp_keymgmt_gen_set_params(ctx->keymgmt, ctx->op.keymgmt.genctx,\n                                           params);\n        if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n            && ctx->op.encap.kem != NULL\n            && ctx->op.encap.kem->set_ctx_params != NULL)\n            return\n                ctx->op.encap.kem->set_ctx_params(ctx->op.encap.algctx,\n                                                  params);\n        break;\n#ifndef FIPS_MODULE\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        return evp_pkey_ctx_set_params_to_ctrl(ctx, params);\n#endif\n    }\n    return 0;\n}\n\nint EVP_PKEY_CTX_get_params(EVP_PKEY_CTX *ctx, OSSL_PARAM *params)\n{\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->get_ctx_params != NULL)\n            return\n                ctx->op.kex.exchange->get_ctx_params(ctx->op.kex.algctx,\n                                                     params);\n        if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->get_ctx_params != NULL)\n            return\n                ctx->op.sig.signature->get_ctx_params(ctx->op.sig.algctx,\n                                                      params);\n        if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->get_ctx_params != NULL)\n            return\n                ctx->op.ciph.cipher->get_ctx_params(ctx->op.ciph.algctx,\n                                                    params);\n        if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n            && ctx->op.encap.kem != NULL\n            && ctx->op.encap.kem->get_ctx_params != NULL)\n            return\n                ctx->op.encap.kem->get_ctx_params(ctx->op.encap.algctx,\n                                                  params);\n        break;\n#ifndef FIPS_MODULE\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        return evp_pkey_ctx_get_params_to_ctrl(ctx, params);\n#endif\n    }\n    return 0;\n}\n\n#ifndef FIPS_MODULE\nconst OSSL_PARAM *EVP_PKEY_CTX_gettable_params(const EVP_PKEY_CTX *ctx)\n{\n    void *provctx;\n\n    if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEYEXCH_get0_provider(ctx->op.kex.exchange));\n        return ctx->op.kex.exchange->gettable_ctx_params(ctx->op.kex.algctx,\n                                                         provctx);\n    }\n    if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(\n                      EVP_SIGNATURE_get0_provider(ctx->op.sig.signature));\n        return ctx->op.sig.signature->gettable_ctx_params(ctx->op.sig.algctx,\n                                                          provctx);\n    }\n    if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(\n                      EVP_ASYM_CIPHER_get0_provider(ctx->op.ciph.cipher));\n        return ctx->op.ciph.cipher->gettable_ctx_params(ctx->op.ciph.algctx,\n                                                        provctx);\n    }\n    if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n        && ctx->op.encap.kem != NULL\n        && ctx->op.encap.kem->gettable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEM_get0_provider(ctx->op.encap.kem));\n        return ctx->op.encap.kem->gettable_ctx_params(ctx->op.encap.algctx,\n                                                      provctx);\n    }\n    return NULL;\n}\n\nconst OSSL_PARAM *EVP_PKEY_CTX_settable_params(const EVP_PKEY_CTX *ctx)\n{\n    void *provctx;\n\n    if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)\n            && ctx->op.kex.exchange != NULL\n            && ctx->op.kex.exchange->settable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEYEXCH_get0_provider(ctx->op.kex.exchange));\n        return ctx->op.kex.exchange->settable_ctx_params(ctx->op.kex.algctx,\n                                                         provctx);\n    }\n    if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)\n            && ctx->op.sig.signature != NULL\n            && ctx->op.sig.signature->settable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(\n                      EVP_SIGNATURE_get0_provider(ctx->op.sig.signature));\n        return ctx->op.sig.signature->settable_ctx_params(ctx->op.sig.algctx,\n                                                          provctx);\n    }\n    if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)\n            && ctx->op.ciph.cipher != NULL\n            && ctx->op.ciph.cipher->settable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(\n                      EVP_ASYM_CIPHER_get0_provider(ctx->op.ciph.cipher));\n        return ctx->op.ciph.cipher->settable_ctx_params(ctx->op.ciph.algctx,\n                                                        provctx);\n    }\n    if (EVP_PKEY_CTX_IS_GEN_OP(ctx)\n            && ctx->keymgmt != NULL\n            && ctx->keymgmt->gen_settable_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEYMGMT_get0_provider(ctx->keymgmt));\n        return ctx->keymgmt->gen_settable_params(ctx->op.keymgmt.genctx,\n                                                 provctx);\n    }\n    if (EVP_PKEY_CTX_IS_KEM_OP(ctx)\n        && ctx->op.encap.kem != NULL\n        && ctx->op.encap.kem->settable_ctx_params != NULL) {\n        provctx = ossl_provider_ctx(EVP_KEM_get0_provider(ctx->op.encap.kem));\n        return ctx->op.encap.kem->settable_ctx_params(ctx->op.encap.algctx,\n                                                      provctx);\n    }\n    return NULL;\n}\n\n/*\n * Internal helpers for stricter EVP_PKEY_CTX_{set,get}_params().\n *\n * Return 1 on success, 0 or negative for errors.\n *\n * In particular they return -2 if any of the params is not supported.\n *\n * They are not available in FIPS_MODULE as they depend on\n *      - EVP_PKEY_CTX_{get,set}_params()\n *      - EVP_PKEY_CTX_{gettable,settable}_params()\n *\n */\nint evp_pkey_ctx_set_params_strict(EVP_PKEY_CTX *ctx, OSSL_PARAM *params)\n{\n    if (ctx == NULL || params == NULL)\n        return 0;\n\n    /*\n     * We only check for provider side EVP_PKEY_CTX.  For #legacy, we\n     * depend on the translation that happens in EVP_PKEY_CTX_set_params()\n     * call, and that the resulting ctrl call will return -2 if it doesn't\n     * known the ctrl command number.\n     */\n    if (evp_pkey_ctx_is_provided(ctx)) {\n        const OSSL_PARAM *settable = EVP_PKEY_CTX_settable_params(ctx);\n        const OSSL_PARAM *p;\n\n        for (p = params; p->key != NULL; p++) {\n            /* Check the ctx actually understands this parameter */\n            if (OSSL_PARAM_locate_const(settable, p->key) == NULL)\n                return -2;\n        }\n    }\n\n    return EVP_PKEY_CTX_set_params(ctx, params);\n}\n\nint evp_pkey_ctx_get_params_strict(EVP_PKEY_CTX *ctx, OSSL_PARAM *params)\n{\n    if (ctx == NULL || params == NULL)\n        return 0;\n\n    /*\n     * We only check for provider side EVP_PKEY_CTX.  For #legacy, we\n     * depend on the translation that happens in EVP_PKEY_CTX_get_params()\n     * call, and that the resulting ctrl call will return -2 if it doesn't\n     * known the ctrl command number.\n     */\n    if (evp_pkey_ctx_is_provided(ctx)) {\n        const OSSL_PARAM *gettable = EVP_PKEY_CTX_gettable_params(ctx);\n        const OSSL_PARAM *p;\n\n        for (p = params; p->key != NULL; p++) {\n            /* Check the ctx actually understands this parameter */\n            if (OSSL_PARAM_locate_const(gettable, p->key) == NULL)\n                return -2;\n        }\n    }\n\n    return EVP_PKEY_CTX_get_params(ctx, params);\n}\n\nint EVP_PKEY_CTX_get_signature_md(EVP_PKEY_CTX *ctx, const EVP_MD **md)\n{\n    OSSL_PARAM sig_md_params[2], *p = sig_md_params;\n    /* 80 should be big enough */\n    char name[80] = \"\";\n    const EVP_MD *tmp;\n\n    if (ctx == NULL || !EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        /* Uses the same return values as EVP_PKEY_CTX_ctrl */\n        return -2;\n    }\n\n    if (ctx->op.sig.algctx == NULL)\n        return EVP_PKEY_CTX_ctrl(ctx, -1, EVP_PKEY_OP_TYPE_SIG,\n                                 EVP_PKEY_CTRL_GET_MD, 0, (void *)(md));\n\n    *p++ = OSSL_PARAM_construct_utf8_string(OSSL_SIGNATURE_PARAM_DIGEST,\n                                            name,\n                                            sizeof(name));\n    *p = OSSL_PARAM_construct_end();\n\n    if (!EVP_PKEY_CTX_get_params(ctx, sig_md_params))\n        return 0;\n\n    tmp = evp_get_digestbyname_ex(ctx->libctx, name);\n    if (tmp == NULL)\n        return 0;\n\n    *md = tmp;\n\n    return 1;\n}\n\nstatic int evp_pkey_ctx_set_md(EVP_PKEY_CTX *ctx, const EVP_MD *md,\n                               int fallback, const char *param, int op,\n                               int ctrl)\n{\n    OSSL_PARAM md_params[2], *p = md_params;\n    const char *name;\n\n    if (ctx == NULL || (ctx->operation & op) == 0) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        /* Uses the same return values as EVP_PKEY_CTX_ctrl */\n        return -2;\n    }\n\n    if (fallback)\n        return EVP_PKEY_CTX_ctrl(ctx, -1, op, ctrl, 0, (void *)(md));\n\n    if (md == NULL) {\n        name = \"\";\n    } else {\n        name = EVP_MD_get0_name(md);\n    }\n\n    *p++ = OSSL_PARAM_construct_utf8_string(param,\n                                            /*\n                                             * Cast away the const. This is read\n                                             * only so should be safe\n                                             */\n                                            (char *)name, 0);\n    *p = OSSL_PARAM_construct_end();\n\n    return EVP_PKEY_CTX_set_params(ctx, md_params);\n}\n\nint EVP_PKEY_CTX_set_signature_md(EVP_PKEY_CTX *ctx, const EVP_MD *md)\n{\n    return evp_pkey_ctx_set_md(ctx, md, ctx->op.sig.algctx == NULL,\n                               OSSL_SIGNATURE_PARAM_DIGEST,\n                               EVP_PKEY_OP_TYPE_SIG, EVP_PKEY_CTRL_MD);\n}\n\nint EVP_PKEY_CTX_set_tls1_prf_md(EVP_PKEY_CTX *ctx, const EVP_MD *md)\n{\n    return evp_pkey_ctx_set_md(ctx, md, ctx->op.kex.algctx == NULL,\n                               OSSL_KDF_PARAM_DIGEST,\n                               EVP_PKEY_OP_DERIVE, EVP_PKEY_CTRL_TLS_MD);\n}\n\nstatic int evp_pkey_ctx_set1_octet_string(EVP_PKEY_CTX *ctx, int fallback,\n                                          const char *param, int op, int ctrl,\n                                          const unsigned char *data,\n                                          int datalen)\n{\n    OSSL_PARAM octet_string_params[2], *p = octet_string_params;\n\n    if (ctx == NULL || (ctx->operation & op) == 0) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        /* Uses the same return values as EVP_PKEY_CTX_ctrl */\n        return -2;\n    }\n\n    /* Code below to be removed when legacy support is dropped. */\n    if (fallback)\n        return EVP_PKEY_CTX_ctrl(ctx, -1, op, ctrl, datalen, (void *)(data));\n    /* end of legacy support */\n\n    if (datalen < 0) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_LENGTH);\n        return 0;\n    }\n\n    *p++ = OSSL_PARAM_construct_octet_string(param,\n                                            /*\n                                             * Cast away the const. This is read\n                                             * only so should be safe\n                                             */\n                                            (unsigned char *)data,\n                                            (size_t)datalen);\n    *p = OSSL_PARAM_construct_end();\n\n    return EVP_PKEY_CTX_set_params(ctx, octet_string_params);\n}\n\nint EVP_PKEY_CTX_set1_tls1_prf_secret(EVP_PKEY_CTX *ctx,\n                                      const unsigned char *sec, int seclen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_SECRET,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_TLS_SECRET,\n                                          sec, seclen);\n}\n\nint EVP_PKEY_CTX_add1_tls1_prf_seed(EVP_PKEY_CTX *ctx,\n                                    const unsigned char *seed, int seedlen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_SEED,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_TLS_SEED,\n                                          seed, seedlen);\n}\n\nint EVP_PKEY_CTX_set_hkdf_md(EVP_PKEY_CTX *ctx, const EVP_MD *md)\n{\n    return evp_pkey_ctx_set_md(ctx, md, ctx->op.kex.algctx == NULL,\n                               OSSL_KDF_PARAM_DIGEST,\n                               EVP_PKEY_OP_DERIVE, EVP_PKEY_CTRL_HKDF_MD);\n}\n\nint EVP_PKEY_CTX_set1_hkdf_salt(EVP_PKEY_CTX *ctx,\n                                const unsigned char *salt, int saltlen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_SALT,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_HKDF_SALT,\n                                          salt, saltlen);\n}\n\nint EVP_PKEY_CTX_set1_hkdf_key(EVP_PKEY_CTX *ctx,\n                                      const unsigned char *key, int keylen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_KEY,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_HKDF_KEY,\n                                          key, keylen);\n}\n\nint EVP_PKEY_CTX_add1_hkdf_info(EVP_PKEY_CTX *ctx,\n                                      const unsigned char *info, int infolen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_INFO,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_HKDF_INFO,\n                                          info, infolen);\n}\n\nint EVP_PKEY_CTX_set_hkdf_mode(EVP_PKEY_CTX *ctx, int mode)\n{\n    OSSL_PARAM int_params[2], *p = int_params;\n\n    if (ctx == NULL || !EVP_PKEY_CTX_IS_DERIVE_OP(ctx)) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        /* Uses the same return values as EVP_PKEY_CTX_ctrl */\n        return -2;\n    }\n\n    /* Code below to be removed when legacy support is dropped. */\n    if (ctx->op.kex.algctx == NULL)\n        return EVP_PKEY_CTX_ctrl(ctx, -1, EVP_PKEY_OP_DERIVE,\n                                 EVP_PKEY_CTRL_HKDF_MODE, mode, NULL);\n    /* end of legacy support */\n\n    if (mode < 0) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_VALUE);\n        return 0;\n    }\n\n    *p++ = OSSL_PARAM_construct_int(OSSL_KDF_PARAM_MODE, &mode);\n    *p = OSSL_PARAM_construct_end();\n\n    return EVP_PKEY_CTX_set_params(ctx, int_params);\n}\n\nint EVP_PKEY_CTX_set1_pbe_pass(EVP_PKEY_CTX *ctx, const char *pass,\n                               int passlen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_PASSWORD,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_PASS,\n                                          (const unsigned char *)pass, passlen);\n}\n\nint EVP_PKEY_CTX_set1_scrypt_salt(EVP_PKEY_CTX *ctx,\n                                  const unsigned char *salt, int saltlen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.kex.algctx == NULL,\n                                          OSSL_KDF_PARAM_SALT,\n                                          EVP_PKEY_OP_DERIVE,\n                                          EVP_PKEY_CTRL_SCRYPT_SALT,\n                                          salt, saltlen);\n}\n\nstatic int evp_pkey_ctx_set_uint64(EVP_PKEY_CTX *ctx, const char *param,\n                                   int op, int ctrl, uint64_t val)\n{\n    OSSL_PARAM uint64_params[2], *p = uint64_params;\n\n    if (ctx == NULL || !EVP_PKEY_CTX_IS_DERIVE_OP(ctx)) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        /* Uses the same return values as EVP_PKEY_CTX_ctrl */\n        return -2;\n    }\n\n    /* Code below to be removed when legacy support is dropped. */\n    if (ctx->op.kex.algctx == NULL)\n        return EVP_PKEY_CTX_ctrl_uint64(ctx, -1, op, ctrl, val);\n    /* end of legacy support */\n\n    *p++ = OSSL_PARAM_construct_uint64(param, &val);\n    *p = OSSL_PARAM_construct_end();\n\n    return EVP_PKEY_CTX_set_params(ctx, uint64_params);\n}\n\nint EVP_PKEY_CTX_set_scrypt_N(EVP_PKEY_CTX *ctx, uint64_t n)\n{\n    return evp_pkey_ctx_set_uint64(ctx, OSSL_KDF_PARAM_SCRYPT_N,\n                                   EVP_PKEY_OP_DERIVE, EVP_PKEY_CTRL_SCRYPT_N,\n                                   n);\n}\n\nint EVP_PKEY_CTX_set_scrypt_r(EVP_PKEY_CTX *ctx, uint64_t r)\n{\n    return evp_pkey_ctx_set_uint64(ctx, OSSL_KDF_PARAM_SCRYPT_R,\n                                   EVP_PKEY_OP_DERIVE, EVP_PKEY_CTRL_SCRYPT_R,\n                                   r);\n}\n\nint EVP_PKEY_CTX_set_scrypt_p(EVP_PKEY_CTX *ctx, uint64_t p)\n{\n    return evp_pkey_ctx_set_uint64(ctx, OSSL_KDF_PARAM_SCRYPT_P,\n                                   EVP_PKEY_OP_DERIVE, EVP_PKEY_CTRL_SCRYPT_P,\n                                   p);\n}\n\nint EVP_PKEY_CTX_set_scrypt_maxmem_bytes(EVP_PKEY_CTX *ctx,\n                                         uint64_t maxmem_bytes)\n{\n    return evp_pkey_ctx_set_uint64(ctx, OSSL_KDF_PARAM_SCRYPT_MAXMEM,\n                                   EVP_PKEY_OP_DERIVE,\n                                   EVP_PKEY_CTRL_SCRYPT_MAXMEM_BYTES,\n                                   maxmem_bytes);\n}\n\nint EVP_PKEY_CTX_set_mac_key(EVP_PKEY_CTX *ctx, const unsigned char *key,\n                             int keylen)\n{\n    return evp_pkey_ctx_set1_octet_string(ctx, ctx->op.keymgmt.genctx == NULL,\n                                          OSSL_PKEY_PARAM_PRIV_KEY,\n                                          EVP_PKEY_OP_KEYGEN,\n                                          EVP_PKEY_CTRL_SET_MAC_KEY,\n                                          key, keylen);\n}\n\nint EVP_PKEY_CTX_set_kem_op(EVP_PKEY_CTX *ctx, const char *op)\n{\n    OSSL_PARAM params[2], *p = params;\n\n    if (ctx == NULL || op == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_VALUE);\n        return 0;\n    }\n    if (!EVP_PKEY_CTX_IS_KEM_OP(ctx)) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        return -2;\n    }\n    *p++ = OSSL_PARAM_construct_utf8_string(OSSL_KEM_PARAM_OPERATION,\n                                            (char *)op, 0);\n    *p = OSSL_PARAM_construct_end();\n    return EVP_PKEY_CTX_set_params(ctx, params);\n}\n\nint EVP_PKEY_CTX_set1_id(EVP_PKEY_CTX *ctx, const void *id, int len)\n{\n    return EVP_PKEY_CTX_ctrl(ctx, -1, -1,\n                             EVP_PKEY_CTRL_SET1_ID, (int)len, (void*)(id));\n}\n\nint EVP_PKEY_CTX_get1_id(EVP_PKEY_CTX *ctx, void *id)\n{\n    return EVP_PKEY_CTX_ctrl(ctx, -1, -1, EVP_PKEY_CTRL_GET1_ID, 0, (void*)id);\n}\n\nint EVP_PKEY_CTX_get1_id_len(EVP_PKEY_CTX *ctx, size_t *id_len)\n{\n    return EVP_PKEY_CTX_ctrl(ctx, -1, -1,\n                             EVP_PKEY_CTRL_GET1_ID_LEN, 0, (void*)id_len);\n}\n\nstatic int evp_pkey_ctx_ctrl_int(EVP_PKEY_CTX *ctx, int keytype, int optype,\n                                 int cmd, int p1, void *p2)\n{\n    int ret = 0;\n\n    /*\n     * If the method has a |digest_custom| function, we can relax the\n     * operation type check, since this can be called before the operation\n     * is initialized.\n     */\n    if (ctx->pmeth == NULL || ctx->pmeth->digest_custom == NULL) {\n        if (ctx->operation == EVP_PKEY_OP_UNDEFINED) {\n            ERR_raise(ERR_LIB_EVP, EVP_R_NO_OPERATION_SET);\n            return -1;\n        }\n\n        if ((optype != -1) && !(ctx->operation & optype)) {\n            ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_OPERATION);\n            return -1;\n        }\n    }\n\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        return evp_pkey_ctx_ctrl_to_param(ctx, keytype, optype, cmd, p1, p2);\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        if (ctx->pmeth == NULL || ctx->pmeth->ctrl == NULL) {\n            ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n            return -2;\n        }\n        if ((keytype != -1) && (ctx->pmeth->pkey_id != keytype))\n            return -1;\n\n        ret = ctx->pmeth->ctrl(ctx, cmd, p1, p2);\n\n        if (ret == -2)\n            ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        break;\n    }\n    return ret;\n}\n\nint EVP_PKEY_CTX_ctrl(EVP_PKEY_CTX *ctx, int keytype, int optype,\n                      int cmd, int p1, void *p2)\n{\n    int ret = 0;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        return -2;\n    }\n    /* If unsupported, we don't want that reported here */\n    ERR_set_mark();\n    ret = evp_pkey_ctx_store_cached_data(ctx, keytype, optype,\n                                         cmd, NULL, p2, p1);\n    if (ret == -2) {\n        ERR_pop_to_mark();\n    } else {\n        ERR_clear_last_mark();\n        /*\n         * If there was an error, there was an error.\n         * If the operation isn't initialized yet, we also return, as\n         * the saved values will be used then anyway.\n         */\n        if (ret < 1 || ctx->operation == EVP_PKEY_OP_UNDEFINED)\n            return ret;\n    }\n    return evp_pkey_ctx_ctrl_int(ctx, keytype, optype, cmd, p1, p2);\n}\n\nint EVP_PKEY_CTX_ctrl_uint64(EVP_PKEY_CTX *ctx, int keytype, int optype,\n                             int cmd, uint64_t value)\n{\n    return EVP_PKEY_CTX_ctrl(ctx, keytype, optype, cmd, 0, &value);\n}\n\n\nstatic int evp_pkey_ctx_ctrl_str_int(EVP_PKEY_CTX *ctx,\n                                     const char *name, const char *value)\n{\n    int ret = 0;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        return -2;\n    }\n\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        return evp_pkey_ctx_ctrl_str_to_param(ctx, name, value);\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        if (ctx == NULL || ctx->pmeth == NULL || ctx->pmeth->ctrl_str == NULL) {\n            ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n            return -2;\n        }\n        if (strcmp(name, \"digest\") == 0)\n            ret = EVP_PKEY_CTX_md(ctx,\n                                  EVP_PKEY_OP_TYPE_SIG | EVP_PKEY_OP_TYPE_CRYPT,\n                                  EVP_PKEY_CTRL_MD, value);\n        else\n            ret = ctx->pmeth->ctrl_str(ctx, name, value);\n        break;\n    }\n\n    return ret;\n}\n\nint EVP_PKEY_CTX_ctrl_str(EVP_PKEY_CTX *ctx,\n                          const char *name, const char *value)\n"}, {"id": "04439C1EC4765BBC", "name": "EVP_PKEY_CTX_ctrl", "path": "openssl/crypto/evp/pmeth_lib.c", "start": {"line": 1249, "col": 1}, "end": {"line": 1275, "col": 1}, "code": "                      int cmd, int p1, void *p2)\n{\n    int ret = 0;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        return -2;\n    }\n    /* If unsupported, we don't want that reported here */\n    ERR_set_mark();\n    ret = evp_pkey_ctx_store_cached_data(ctx, keytype, optype,\n                                         cmd, NULL, p2, p1);\n    if (ret == -2) {\n        ERR_pop_to_mark();\n    } else {\n        ERR_clear_last_mark();\n        /*\n         * If there was an error, there was an error.\n         * If the operation isn't initialized yet, we also return, as\n         * the saved values will be used then anyway.\n         */\n        if (ret < 1 || ctx->operation == EVP_PKEY_OP_UNDEFINED)\n            return ret;\n    }\n    return evp_pkey_ctx_ctrl_int(ctx, keytype, optype, cmd, p1, p2);\n}\n\nint EVP_PKEY_CTX_ctrl_uint64(EVP_PKEY_CTX *ctx, int keytype, int optype,\n                             int cmd, uint64_t value)\n{\n    return EVP_PKEY_CTX_ctrl(ctx, keytype, optype, cmd, 0, &value);\n}\n\n\nstatic int evp_pkey_ctx_ctrl_str_int(EVP_PKEY_CTX *ctx,\n                                     const char *name, const char *value)\n{\n    int ret = 0;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        return -2;\n    }\n\n    switch (evp_pkey_ctx_state(ctx)) {\n    case EVP_PKEY_STATE_PROVIDER:\n        return evp_pkey_ctx_ctrl_str_to_param(ctx, name, value);\n    case EVP_PKEY_STATE_UNKNOWN:\n    case EVP_PKEY_STATE_LEGACY:\n        if (ctx == NULL || ctx->pmeth == NULL || ctx->pmeth->ctrl_str == NULL) {\n            ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n            return -2;\n        }\n        if (strcmp(name, \"digest\") == 0)\n            ret = EVP_PKEY_CTX_md(ctx,\n                                  EVP_PKEY_OP_TYPE_SIG | EVP_PKEY_OP_TYPE_CRYPT,\n                                  EVP_PKEY_CTRL_MD, value);\n        else\n            ret = ctx->pmeth->ctrl_str(ctx, name, value);\n        break;\n    }\n\n    return ret;\n}\n\nint EVP_PKEY_CTX_ctrl_str(EVP_PKEY_CTX *ctx,\n                          const char *name, const char *value)\n{\n    int ret = 0;\n\n    /* If unsupported, we don't want that reported here */\n    ERR_set_mark();\n    ret = evp_pkey_ctx_store_cached_data(ctx, -1, -1, -1,\n                                         name, value, strlen(value) + 1);\n    if (ret == -2) {\n        ERR_pop_to_mark();\n    } else {\n        ERR_clear_last_mark();\n        /*\n         * If there was an error, there was an error.\n         * If the operation isn't initialized yet, we also return, as\n         * the saved values will be used then anyway.\n         */\n        if (ret < 1 || ctx->operation == EVP_PKEY_OP_UNDEFINED)\n            return ret;\n    }\n\n    return evp_pkey_ctx_ctrl_str_int(ctx, name, value);\n}\n\nstatic int decode_cmd(int cmd, const char *name)\n{\n    if (cmd == -1) {\n        /*\n         * The consequence of the assertion not being true is that this\n         * function will return -1, which will cause the calling functions\n         * to signal that the command is unsupported...  in non-debug mode.\n         */\n        if (ossl_assert(name != NULL))\n            if (strcmp(name, \"distid\") == 0 || strcmp(name, \"hexdistid\") == 0)\n                cmd = EVP_PKEY_CTRL_SET1_ID;\n    }\n\n    return cmd;\n}\n\nstatic int evp_pkey_ctx_store_cached_data(EVP_PKEY_CTX *ctx,\n                                          int keytype, int optype,\n                                          int cmd, const char *name,\n                                          const void *data, size_t data_len)\n{\n    /*\n     * Check that it's one of the supported commands.  The ctrl commands\n     * number cases here must correspond to the cases in the bottom switch\n     * in this function.\n     */\n    switch (cmd = decode_cmd(cmd, name)) {\n    case EVP_PKEY_CTRL_SET1_ID:\n        break;\n    default:\n        ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n        return -2;\n    }\n\n    if (keytype != -1) {\n        switch (evp_pkey_ctx_state(ctx)) {\n        case EVP_PKEY_STATE_PROVIDER:\n            if (ctx->keymgmt == NULL) {\n                ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n                return -2;\n            }\n            if (!EVP_KEYMGMT_is_a(ctx->keymgmt,\n                                  evp_pkey_type2name(keytype))) {\n                ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_OPERATION);\n                return -1;\n            }\n            break;\n        case EVP_PKEY_STATE_UNKNOWN:\n        case EVP_PKEY_STATE_LEGACY:\n            if (ctx->pmeth == NULL) {\n                ERR_raise(ERR_LIB_EVP, EVP_R_COMMAND_NOT_SUPPORTED);\n                return -2;\n            }\n            if (EVP_PKEY_type(ctx->pmeth->pkey_id) != EVP_PKEY_type(keytype)) {\n                ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_OPERATION);\n                return -1;\n            }\n            break;\n        }\n    }\n    if (optype != -1 && (ctx->operation & optype) == 0) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_OPERATION);\n        return -1;\n    }\n\n    switch (cmd) {\n    case EVP_PKEY_CTRL_SET1_ID:\n        evp_pkey_ctx_free_cached_data(ctx, cmd, name);\n        if (name != NULL) {\n            ctx->cached_parameters.dist_id_name = OPENSSL_strdup(name);\n            if (ctx->cached_parameters.dist_id_name == NULL)\n                return 0;\n        }\n        if (data_len > 0) {\n            ctx->cached_parameters.dist_id = OPENSSL_memdup(data, data_len);\n            if (ctx->cached_parameters.dist_id == NULL)\n                return 0;\n        }\n        ctx->cached_parameters.dist_id_set = 1;\n        ctx->cached_parameters.dist_id_len = data_len;\n        break;\n    }\n    return 1;\n}\n\nstatic void evp_pkey_ctx_free_cached_data(EVP_PKEY_CTX *ctx,\n                                          int cmd, const char *name)\n{\n    cmd = decode_cmd(cmd, name);\n    switch (cmd) {\n    case EVP_PKEY_CTRL_SET1_ID:\n        OPENSSL_free(ctx->cached_parameters.dist_id);\n        OPENSSL_free(ctx->cached_parameters.dist_id_name);\n        ctx->cached_parameters.dist_id = NULL;\n        ctx->cached_parameters.dist_id_name = NULL;\n        break;\n    }\n}\n\nstatic void evp_pkey_ctx_free_all_cached_data(EVP_PKEY_CTX *ctx)\n{\n    evp_pkey_ctx_free_cached_data(ctx, EVP_PKEY_CTRL_SET1_ID, NULL);\n}\n\nint evp_pkey_ctx_use_cached_data(EVP_PKEY_CTX *ctx)\n{\n    int ret = 1;\n\n    if (ret && ctx->cached_parameters.dist_id_set) {\n        const char *name = ctx->cached_parameters.dist_id_name;\n        const void *val = ctx->cached_parameters.dist_id;\n        size_t len = ctx->cached_parameters.dist_id_len;\n\n        if (name != NULL)\n            ret = evp_pkey_ctx_ctrl_str_int(ctx, name, val);\n        else\n            ret = evp_pkey_ctx_ctrl_int(ctx, -1, ctx->operation,\n                                        EVP_PKEY_CTRL_SET1_ID,\n                                        (int)len, (void *)val);\n    }\n\n    return ret;\n}\n\nOSSL_LIB_CTX *EVP_PKEY_CTX_get0_libctx(EVP_PKEY_CTX *ctx)\n{\n    return ctx->libctx;\n}\n\nconst char *EVP_PKEY_CTX_get0_propq(const EVP_PKEY_CTX *ctx)\n{\n    return ctx->propquery;\n}\n\nconst OSSL_PROVIDER *EVP_PKEY_CTX_get0_provider(const EVP_PKEY_CTX *ctx)\n{\n    if (EVP_PKEY_CTX_IS_SIGNATURE_OP(ctx)) {\n        if (ctx->op.sig.signature != NULL)\n            return EVP_SIGNATURE_get0_provider(ctx->op.sig.signature);\n    } else if (EVP_PKEY_CTX_IS_DERIVE_OP(ctx)) {\n        if (ctx->op.kex.exchange != NULL)\n            return EVP_KEYEXCH_get0_provider(ctx->op.kex.exchange);\n    } else if (EVP_PKEY_CTX_IS_KEM_OP(ctx)) {\n        if (ctx->op.encap.kem != NULL)\n            return EVP_KEM_get0_provider(ctx->op.encap.kem);\n    } else if (EVP_PKEY_CTX_IS_ASYM_CIPHER_OP(ctx)) {\n        if (ctx->op.ciph.cipher != NULL)\n            return EVP_ASYM_CIPHER_get0_provider(ctx->op.ciph.cipher);\n    } else if (EVP_PKEY_CTX_IS_GEN_OP(ctx)) {\n        if (ctx->keymgmt != NULL)\n            return EVP_KEYMGMT_get0_provider(ctx->keymgmt);\n    }\n\n    return NULL;\n}\n\n/* Utility functions to send a string of hex string to a ctrl */\n\nint EVP_PKEY_CTX_str2ctrl(EVP_PKEY_CTX *ctx, int cmd, const char *str)\n{\n    size_t len;\n\n    len = strlen(str);\n    if (len > INT_MAX)\n        return -1;\n    return ctx->pmeth->ctrl(ctx, cmd, len, (void *)str);\n}\n\nint EVP_PKEY_CTX_hex2ctrl(EVP_PKEY_CTX *ctx, int cmd, const char *hex)\n{\n    unsigned char *bin;\n    long binlen;\n    int rv = -1;\n\n    bin = OPENSSL_hexstr2buf(hex, &binlen);\n    if (bin == NULL)\n        return 0;\n    if (binlen <= INT_MAX)\n        rv = ctx->pmeth->ctrl(ctx, cmd, binlen, bin);\n    OPENSSL_free(bin);\n    return rv;\n}\n\n/* Pass a message digest to a ctrl */\nint EVP_PKEY_CTX_md(EVP_PKEY_CTX *ctx, int optype, int cmd, const char *md)\n{\n    const EVP_MD *m;\n\n    if (md == NULL || (m = EVP_get_digestbyname(md)) == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_INVALID_DIGEST);\n        return 0;\n    }\n    return EVP_PKEY_CTX_ctrl(ctx, -1, optype, cmd, 0, (void *)m);\n}\n\nint EVP_PKEY_CTX_get_operation(EVP_PKEY_CTX *ctx)\n{\n    return ctx->operation;\n}\n\nvoid EVP_PKEY_CTX_set0_keygen_info(EVP_PKEY_CTX *ctx, int *dat, int datlen)\n{\n    ctx->keygen_info = dat;\n    ctx->keygen_info_count = datlen;\n}\n\nvoid EVP_PKEY_CTX_set_data(EVP_PKEY_CTX *ctx, void *data)\n{\n    ctx->data = data;\n}\n\nvoid *EVP_PKEY_CTX_get_data(const EVP_PKEY_CTX *ctx)\n{\n    return ctx->data;\n}\n\nEVP_PKEY *EVP_PKEY_CTX_get0_pkey(EVP_PKEY_CTX *ctx)\n{\n    return ctx->pkey;\n}\n\nEVP_PKEY *EVP_PKEY_CTX_get0_peerkey(EVP_PKEY_CTX *ctx)\n{\n    return ctx->peerkey;\n}\n\nvoid EVP_PKEY_CTX_set_app_data(EVP_PKEY_CTX *ctx, void *data)\n{\n    ctx->app_data = data;\n}\n\nvoid *EVP_PKEY_CTX_get_app_data(EVP_PKEY_CTX *ctx)\n{\n    return ctx->app_data;\n}\n\nvoid EVP_PKEY_meth_set_init(EVP_PKEY_METHOD *pmeth,\n                            int (*init) (EVP_PKEY_CTX *ctx))\n{\n    pmeth->init = init;\n}\n\nvoid EVP_PKEY_meth_set_copy(EVP_PKEY_METHOD *pmeth,\n                            int (*copy) (EVP_PKEY_CTX *dst,\n                                         const EVP_PKEY_CTX *src))\n{\n    pmeth->copy = copy;\n}\n\nvoid EVP_PKEY_meth_set_cleanup(EVP_PKEY_METHOD *pmeth,\n                               void (*cleanup) (EVP_PKEY_CTX *ctx))\n{\n    pmeth->cleanup = cleanup;\n}\n\nvoid EVP_PKEY_meth_set_paramgen(EVP_PKEY_METHOD *pmeth,\n                                int (*paramgen_init) (EVP_PKEY_CTX *ctx),\n                                int (*paramgen) (EVP_PKEY_CTX *ctx,\n                                                 EVP_PKEY *pkey))\n{\n    pmeth->paramgen_init = paramgen_init;\n    pmeth->paramgen = paramgen;\n}\n\nvoid EVP_PKEY_meth_set_keygen(EVP_PKEY_METHOD *pmeth,\n                              int (*keygen_init) (EVP_PKEY_CTX *ctx),\n                              int (*keygen) (EVP_PKEY_CTX *ctx,\n                                             EVP_PKEY *pkey))\n{\n    pmeth->keygen_init = keygen_init;\n    pmeth->keygen = keygen;\n}\n\nvoid EVP_PKEY_meth_set_sign(EVP_PKEY_METHOD *pmeth,\n                            int (*sign_init) (EVP_PKEY_CTX *ctx),\n                            int (*sign) (EVP_PKEY_CTX *ctx,\n                                         unsigned char *sig, size_t *siglen,\n                                         const unsigned char *tbs,\n                                         size_t tbslen))\n{\n    pmeth->sign_init = sign_init;\n    pmeth->sign = sign;\n}\n\nvoid EVP_PKEY_meth_set_verify(EVP_PKEY_METHOD *pmeth,\n                              int (*verify_init) (EVP_PKEY_CTX *ctx),\n                              int (*verify) (EVP_PKEY_CTX *ctx,\n                                             const unsigned char *sig,\n                                             size_t siglen,\n                                             const unsigned char *tbs,\n                                             size_t tbslen))\n{\n    pmeth->verify_init = verify_init;\n    pmeth->verify = verify;\n}\n\nvoid EVP_PKEY_meth_set_verify_recover(EVP_PKEY_METHOD *pmeth,\n                                      int (*verify_recover_init) (EVP_PKEY_CTX\n                                                                  *ctx),\n                                      int (*verify_recover) (EVP_PKEY_CTX\n                                                             *ctx,\n                                                             unsigned char\n                                                             *sig,\n                                                             size_t *siglen,\n                                                             const unsigned\n                                                             char *tbs,\n                                                             size_t tbslen))\n{\n    pmeth->verify_recover_init = verify_recover_init;\n    pmeth->verify_recover = verify_recover;\n}\n\nvoid EVP_PKEY_meth_set_signctx(EVP_PKEY_METHOD *pmeth,\n                               int (*signctx_init) (EVP_PKEY_CTX *ctx,\n                                                    EVP_MD_CTX *mctx),\n                               int (*signctx) (EVP_PKEY_CTX *ctx,\n                                               unsigned char *sig,\n                                               size_t *siglen,\n                                               EVP_MD_CTX *mctx))\n{\n    pmeth->signctx_init = signctx_init;\n    pmeth->signctx = signctx;\n}\n\nvoid EVP_PKEY_meth_set_verifyctx(EVP_PKEY_METHOD *pmeth,\n                                 int (*verifyctx_init) (EVP_PKEY_CTX *ctx,\n                                                        EVP_MD_CTX *mctx),\n                                 int (*verifyctx) (EVP_PKEY_CTX *ctx,\n                                                   const unsigned char *sig,\n                                                   int siglen,\n                                                   EVP_MD_CTX *mctx))\n{\n    pmeth->verifyctx_init = verifyctx_init;\n    pmeth->verifyctx = verifyctx;\n}\n\nvoid EVP_PKEY_meth_set_encrypt(EVP_PKEY_METHOD *pmeth,\n                               int (*encrypt_init) (EVP_PKEY_CTX *ctx),\n                               int (*encryptfn) (EVP_PKEY_CTX *ctx,\n                                                 unsigned char *out,\n                                                 size_t *outlen,\n                                                 const unsigned char *in,\n                                                 size_t inlen))\n{\n    pmeth->encrypt_init = encrypt_init;\n    pmeth->encrypt = encryptfn;\n}\n\nvoid EVP_PKEY_meth_set_decrypt(EVP_PKEY_METHOD *pmeth,\n                               int (*decrypt_init) (EVP_PKEY_CTX *ctx),\n                               int (*decrypt) (EVP_PKEY_CTX *ctx,\n                                               unsigned char *out,\n                                               size_t *outlen,\n                                               const unsigned char *in,\n                                               size_t inlen))\n{\n    pmeth->decrypt_init = decrypt_init;\n    pmeth->decrypt = decrypt;\n}\n\nvoid EVP_PKEY_meth_set_derive(EVP_PKEY_METHOD *pmeth,\n                              int (*derive_init) (EVP_PKEY_CTX *ctx),\n                              int (*derive) (EVP_PKEY_CTX *ctx,\n                                             unsigned char *key,\n                                             size_t *keylen))\n{\n    pmeth->derive_init = derive_init;\n    pmeth->derive = derive;\n}\n\nvoid EVP_PKEY_meth_set_ctrl(EVP_PKEY_METHOD *pmeth,\n                            int (*ctrl) (EVP_PKEY_CTX *ctx, int type, int p1,\n                                         void *p2),\n                            int (*ctrl_str) (EVP_PKEY_CTX *ctx,\n                                             const char *type,\n                                             const char *value))\n{\n    pmeth->ctrl = ctrl;\n    pmeth->ctrl_str = ctrl_str;\n}\n\nvoid EVP_PKEY_meth_set_digestsign(EVP_PKEY_METHOD *pmeth,\n    int (*digestsign) (EVP_MD_CTX *ctx, unsigned char *sig, size_t *siglen,\n                       const unsigned char *tbs, size_t tbslen))\n{\n    pmeth->digestsign = digestsign;\n}\n\nvoid EVP_PKEY_meth_set_digestverify(EVP_PKEY_METHOD *pmeth,\n    int (*digestverify) (EVP_MD_CTX *ctx, const unsigned char *sig,\n                         size_t siglen, const unsigned char *tbs,\n                         size_t tbslen))\n{\n    pmeth->digestverify = digestverify;\n}\n\nvoid EVP_PKEY_meth_set_check(EVP_PKEY_METHOD *pmeth,\n                             int (*check) (EVP_PKEY *pkey))\n{\n    pmeth->check = check;\n}\n\nvoid EVP_PKEY_meth_set_public_check(EVP_PKEY_METHOD *pmeth,\n                                    int (*check) (EVP_PKEY *pkey))\n{\n    pmeth->public_check = check;\n}\n\nvoid EVP_PKEY_meth_set_param_check(EVP_PKEY_METHOD *pmeth,\n                                   int (*check) (EVP_PKEY *pkey))\n{\n    pmeth->param_check = check;\n}\n\nvoid EVP_PKEY_meth_set_digest_custom(EVP_PKEY_METHOD *pmeth,\n                                     int (*digest_custom) (EVP_PKEY_CTX *ctx,\n                                                           EVP_MD_CTX *mctx))\n{\n    pmeth->digest_custom = digest_custom;\n}\n\nvoid EVP_PKEY_meth_get_init(const EVP_PKEY_METHOD *pmeth,\n                            int (**pinit) (EVP_PKEY_CTX *ctx))\n{\n    *pinit = pmeth->init;\n}\n\nvoid EVP_PKEY_meth_get_copy(const EVP_PKEY_METHOD *pmeth,\n                            int (**pcopy) (EVP_PKEY_CTX *dst,\n                                           const EVP_PKEY_CTX *src))\n{\n    *pcopy = pmeth->copy;\n}\n\nvoid EVP_PKEY_meth_get_cleanup(const EVP_PKEY_METHOD *pmeth,\n                               void (**pcleanup) (EVP_PKEY_CTX *ctx))\n{\n    *pcleanup = pmeth->cleanup;\n}\n\nvoid EVP_PKEY_meth_get_paramgen(const EVP_PKEY_METHOD *pmeth,\n                                int (**pparamgen_init) (EVP_PKEY_CTX *ctx),\n                                int (**pparamgen) (EVP_PKEY_CTX *ctx,\n                                                   EVP_PKEY *pkey))\n{\n    if (pparamgen_init)\n        *pparamgen_init = pmeth->paramgen_init;\n    if (pparamgen)\n        *pparamgen = pmeth->paramgen;\n}\n\nvoid EVP_PKEY_meth_get_keygen(const EVP_PKEY_METHOD *pmeth,\n                              int (**pkeygen_init) (EVP_PKEY_CTX *ctx),\n                              int (**pkeygen) (EVP_PKEY_CTX *ctx,\n                                               EVP_PKEY *pkey))\n{\n    if (pkeygen_init)\n        *pkeygen_init = pmeth->keygen_init;\n    if (pkeygen)\n        *pkeygen = pmeth->keygen;\n}\n\nvoid EVP_PKEY_meth_get_sign(const EVP_PKEY_METHOD *pmeth,\n                            int (**psign_init) (EVP_PKEY_CTX *ctx),\n                            int (**psign) (EVP_PKEY_CTX *ctx,\n                                           unsigned char *sig, size_t *siglen,\n                                           const unsigned char *tbs,\n                                           size_t tbslen))\n{\n    if (psign_init)\n        *psign_init = pmeth->sign_init;\n    if (psign)\n        *psign = pmeth->sign;\n}\n\nvoid EVP_PKEY_meth_get_verify(const EVP_PKEY_METHOD *pmeth,\n                              int (**pverify_init) (EVP_PKEY_CTX *ctx),\n                              int (**pverify) (EVP_PKEY_CTX *ctx,\n                                               const unsigned char *sig,\n                                               size_t siglen,\n                                               const unsigned char *tbs,\n                                               size_t tbslen))\n{\n    if (pverify_init)\n        *pverify_init = pmeth->verify_init;\n    if (pverify)\n        *pverify = pmeth->verify;\n}\n\nvoid EVP_PKEY_meth_get_verify_recover(const EVP_PKEY_METHOD *pmeth,\n                                      int (**pverify_recover_init) (EVP_PKEY_CTX\n                                                                    *ctx),\n                                      int (**pverify_recover) (EVP_PKEY_CTX\n                                                               *ctx,\n                                                               unsigned char\n                                                               *sig,\n                                                               size_t *siglen,\n                                                               const unsigned\n                                                               char *tbs,\n                                                               size_t tbslen))\n{\n    if (pverify_recover_init)\n        *pverify_recover_init = pmeth->verify_recover_init;\n    if (pverify_recover)\n        *pverify_recover = pmeth->verify_recover;\n}\n\nvoid EVP_PKEY_meth_get_signctx(const EVP_PKEY_METHOD *pmeth,\n                               int (**psignctx_init) (EVP_PKEY_CTX *ctx,\n                                                      EVP_MD_CTX *mctx),\n                               int (**psignctx) (EVP_PKEY_CTX *ctx,\n                                                 unsigned char *sig,\n                                                 size_t *siglen,\n                                                 EVP_MD_CTX *mctx))\n{\n    if (psignctx_init)\n        *psignctx_init = pmeth->signctx_init;\n    if (psignctx)\n        *psignctx = pmeth->signctx;\n}\n\nvoid EVP_PKEY_meth_get_verifyctx(const EVP_PKEY_METHOD *pmeth,\n                                 int (**pverifyctx_init) (EVP_PKEY_CTX *ctx,\n                                                          EVP_MD_CTX *mctx),\n                                 int (**pverifyctx) (EVP_PKEY_CTX *ctx,\n                                                     const unsigned char *sig,\n                                                     int siglen,\n                                                     EVP_MD_CTX *mctx))\n{\n    if (pverifyctx_init)\n        *pverifyctx_init = pmeth->verifyctx_init;\n    if (pverifyctx)\n        *pverifyctx = pmeth->verifyctx;\n}\n\nvoid EVP_PKEY_meth_get_encrypt(const EVP_PKEY_METHOD *pmeth,\n                               int (**pencrypt_init) (EVP_PKEY_CTX *ctx),\n                               int (**pencryptfn) (EVP_PKEY_CTX *ctx,\n                                                   unsigned char *out,\n                                                   size_t *outlen,\n                                                   const unsigned char *in,\n                                                   size_t inlen))\n{\n    if (pencrypt_init)\n        *pencrypt_init = pmeth->encrypt_init;\n    if (pencryptfn)\n        *pencryptfn = pmeth->encrypt;\n}\n\nvoid EVP_PKEY_meth_get_decrypt(const EVP_PKEY_METHOD *pmeth,\n                               int (**pdecrypt_init) (EVP_PKEY_CTX *ctx),\n                               int (**pdecrypt) (EVP_PKEY_CTX *ctx,\n                                                 unsigned char *out,\n                                                 size_t *outlen,\n                                                 const unsigned char *in,\n                                                 size_t inlen))\n{\n    if (pdecrypt_init)\n        *pdecrypt_init = pmeth->decrypt_init;\n    if (pdecrypt)\n        *pdecrypt = pmeth->decrypt;\n}\n\nvoid EVP_PKEY_meth_get_derive(const EVP_PKEY_METHOD *pmeth,\n                              int (**pderive_init) (EVP_PKEY_CTX *ctx),\n                              int (**pderive) (EVP_PKEY_CTX *ctx,\n                                               unsigned char *key,\n                                               size_t *keylen))\n{\n    if (pderive_init)\n        *pderive_init = pmeth->derive_init;\n    if (pderive)\n        *pderive = pmeth->derive;\n}\n\nvoid EVP_PKEY_meth_get_ctrl(const EVP_PKEY_METHOD *pmeth,\n                            int (**pctrl) (EVP_PKEY_CTX *ctx, int type, int p1,\n                                           void *p2),\n                            int (**pctrl_str) (EVP_PKEY_CTX *ctx,\n                                               const char *type,\n                                               const char *value))\n{\n    if (pctrl)\n        *pctrl = pmeth->ctrl;\n    if (pctrl_str)\n        *pctrl_str = pmeth->ctrl_str;\n}\n\nvoid EVP_PKEY_meth_get_digestsign(const EVP_PKEY_METHOD *pmeth,\n    int (**digestsign) (EVP_MD_CTX *ctx, unsigned char *sig, size_t *siglen,\n                        const unsigned char *tbs, size_t tbslen))\n{\n    if (digestsign)\n        *digestsign = pmeth->digestsign;\n}\n\nvoid EVP_PKEY_meth_get_digestverify(const EVP_PKEY_METHOD *pmeth,\n    int (**digestverify) (EVP_MD_CTX *ctx, const unsigned char *sig,\n                          size_t siglen, const unsigned char *tbs,\n                          size_t tbslen))\n{\n    if (digestverify)\n        *digestverify = pmeth->digestverify;\n}\n\nvoid EVP_PKEY_meth_get_check(const EVP_PKEY_METHOD *pmeth,\n                             int (**pcheck) (EVP_PKEY *pkey))\n{\n    if (pcheck != NULL)\n        *pcheck = pmeth->check;\n}\n\nvoid EVP_PKEY_meth_get_public_check(const EVP_PKEY_METHOD *pmeth,\n                                    int (**pcheck) (EVP_PKEY *pkey))\n{\n    if (pcheck != NULL)\n        *pcheck = pmeth->public_check;\n}\n\nvoid EVP_PKEY_meth_get_param_check(const EVP_PKEY_METHOD *pmeth,\n                                   int (**pcheck) (EVP_PKEY *pkey))\n{\n    if (pcheck != NULL)\n        *pcheck = pmeth->param_check;\n}\n\nvoid EVP_PKEY_meth_get_digest_custom(const EVP_PKEY_METHOD *pmeth,\n                                     int (**pdigest_custom) (EVP_PKEY_CTX *ctx,\n                                                             EVP_MD_CTX *mctx))\n{\n    if (pdigest_custom != NULL)\n        *pdigest_custom = pmeth->digest_custom;\n}\n\n#endif /* FIPS_MODULE */\n"}], "code": "int EVP_PKEY_CTX_get_rsa_oaep_md(EVP_PKEY_CTX *ctx, const EVP_MD **md)\n{\n    /* If key type not RSA return error */\n    if (!EVP_PKEY_CTX_is_a(ctx, \"RSA\"))\n        return -1;\n\n    return EVP_PKEY_CTX_ctrl(ctx, EVP_PKEY_RSA, EVP_PKEY_OP_TYPE_CRYPT,\n                             EVP_PKEY_CTRL_GET_RSA_OAEP_MD, 0, (void *)md);\n}\n"}, "6EA04EB8AF1579A0": {"calls": [{"id": "64ABBC9A9F3CFEE5", "name": "ossl_time_now", "path": "openssl/crypto/time.c", "start": {"line": 14, "col": 1}, "end": {"line": 48, "col": 1}, "code": "{\n    OSSL_TIME r;\n\n    struct timeval t;\n\n    if (gettimeofday(&t, NULL) < 0) {\n        ERR_raise_data(ERR_LIB_SYS, get_last_sys_error(),\n                       \"calling gettimeofday()\");\n        return ossl_time_zero();\n    }\n    if (t.tv_sec <= 0)\n        r.t = t.tv_usec <= 0 ? 0 : t.tv_usec * OSSL_TIME_US;\n    else\n        r.t = ((uint64_t)t.tv_sec * 1000000 + t.tv_usec) * OSSL_TIME_US;\n    return r;\n}\n"}, {"id": "3A8B9706005B4F1A", "name": "qeng", "path": "openssl/ssl/quic/quic_engine.c", "start": {"line": 77, "col": 50}, "end": {"line": 77, "col": 50}, "code": "{\n    if (qeng->now_cb == NULL)\n        return ossl_time_now();\n\n    return qeng->now_cb(qeng->now_cb_arg);\n}\n\nvoid ossl_quic_engine_set_inhibit_tick(QUIC_ENGINE *qeng, int inhibit)\n{\n    qeng->inhibit_tick = (inhibit != 0);\n}\n\n/*\n * QUIC Engine: Child Object Lifecycle Management\n * ==============================================\n */\n\nQUIC_PORT *ossl_quic_engine_create_port(QUIC_ENGINE *qeng,\n                                        const QUIC_PORT_ARGS *args)\n{\n    QUIC_PORT_ARGS largs = *args;\n\n    if (ossl_list_port_num(&qeng->port_list) > 0)\n        /* TODO(QUIC MULTIPORT): We currently support only one port. */\n        return NULL;\n\n    if (largs.engine != NULL)\n        return NULL;\n\n    largs.engine = qeng;\n    return ossl_quic_port_new(&largs);\n}\n\n/*\n * QUIC Engine: Ticker-Mutator\n * ==========================\n */\n\n/*\n * The central ticker function called by the reactor. This does everything, or\n * at least everything network I/O related. Best effort - not allowed to fail\n * \"loudly\".\n */\nstatic void qeng_tick(QUIC_TICK_RESULT *res, void *arg, uint32_t flags)\n{\n    QUIC_ENGINE *qeng = arg;\n    QUIC_PORT *port;\n\n    res->net_read_desired   = 0;\n    res->net_write_desired  = 0;\n    res->tick_deadline      = ossl_time_infinite();\n\n    if (qeng->inhibit_tick)\n        return;\n\n    /* Iterate through all ports and service them. */\n    LIST_FOREACH(port, port, &qeng->port_list) {\n        QUIC_TICK_RESULT subr = {0};\n\n        ossl_quic_port_subtick(port, &subr, flags);\n        ossl_quic_tick_result_merge_into(res, &subr);\n    }\n}\n"}, {"id": "82147AF676D36DA5", "name": "quic_engine_st::now_cb", "path": "openssl/ssl/quic/quic_engine_local.h", "start": {"line": 44, "col": 39}, "end": {"line": 44, "col": 39}, "code": "    void                            *now_cb_arg;\n\n    /* Asynchronous I/O reactor. */\n    QUIC_REACTOR                    rtor;\n\n    /* List of all child ports. */\n    OSSL_LIST(port)                 port_list;\n\n    /* Inhibit tick for testing purposes? */\n    unsigned int                    inhibit_tick                    : 1;\n};\n\n# endif\n\n#endif\n"}], "code": "OSSL_TIME ossl_quic_engine_get_time(QUIC_ENGINE *qeng)\n{\n    if (qeng->now_cb == NULL)\n        return ossl_time_now();\n\n    return qeng->now_cb(qeng->now_cb_arg);\n}\n"}, "88C2FB6CC13F3260": {"calls": [{"id": "A5C4484C9CF129C3", "name": "RAND_bytes_ex", "path": "openssl/crypto/rand/rand_lib.c", "start": {"line": 363, "col": 1}, "end": {"line": 383, "col": 1}, "code": "                  unsigned int strength)\n{\n    EVP_RAND_CTX *rand;\n#if !defined(OPENSSL_NO_DEPRECATED_3_0) && !defined(FIPS_MODULE)\n    const RAND_METHOD *meth = RAND_get_rand_method();\n\n    if (meth != NULL && meth != RAND_OpenSSL()) {\n        if (meth->bytes != NULL)\n            return meth->bytes(buf, num);\n        ERR_raise(ERR_LIB_RAND, RAND_R_FUNC_NOT_IMPLEMENTED);\n        return -1;\n    }\n#endif\n\n    rand = RAND_get0_public(ctx);\n    if (rand != NULL)\n        return EVP_RAND_generate(rand, buf, num, strength, 0, NULL, 0);\n\n    return 0;\n}\n\nint RAND_bytes(unsigned char *buf, int num)\n{\n    if (num < 0)\n        return 0;\n    return RAND_bytes_ex(NULL, buf, (size_t)num, 0);\n}\n\ntypedef struct rand_global_st {\n    /*\n     * The three shared DRBG instances\n     *\n     * There are three shared DRBG instances: <primary>, <public>, and\n     * <private>.  The <public> and <private> DRBGs are secondary ones.\n     * These are used for non-secret (e.g. nonces) and secret\n     * (e.g. private keys) data respectively.\n     */\n    CRYPTO_RWLOCK *lock;\n\n    EVP_RAND_CTX *seed;\n\n    /*\n     * The <primary> DRBG\n     *\n     * Not used directly by the application, only for reseeding the two other\n     * DRBGs. It reseeds itself by pulling either randomness from os entropy\n     * sources or by consuming randomness which was added by RAND_add().\n     *\n     * The <primary> DRBG is a global instance which is accessed concurrently by\n     * all threads. The necessary locking is managed automatically by its child\n     * DRBG instances during reseeding.\n     */\n    EVP_RAND_CTX *primary;\n\n    /*\n     * The <public> DRBG\n     *\n     * Used by default for generating random bytes using RAND_bytes().\n     *\n     * The <public> secondary DRBG is thread-local, i.e., there is one instance\n     * per thread.\n     */\n    CRYPTO_THREAD_LOCAL public;\n\n    /*\n     * The <private> DRBG\n     *\n     * Used by default for generating private keys using RAND_priv_bytes()\n     *\n     * The <private> secondary DRBG is thread-local, i.e., there is one\n     * instance per thread.\n     */\n    CRYPTO_THREAD_LOCAL private;\n\n    /* Which RNG is being used by default and it's configuration settings */\n    char *rng_name;\n    char *rng_cipher;\n    char *rng_digest;\n    char *rng_propq;\n\n    /* Allow the randomness source to be changed */\n    char *seed_name;\n    char *seed_propq;\n} RAND_GLOBAL;\n\n/*\n * Initialize the OSSL_LIB_CTX global DRBGs on first use.\n * Returns the allocated global data on success or NULL on failure.\n */\nvoid *ossl_rand_ctx_new(OSSL_LIB_CTX *libctx)\n{\n    RAND_GLOBAL *dgbl = OPENSSL_zalloc(sizeof(*dgbl));\n\n    if (dgbl == NULL)\n        return NULL;\n\n#ifndef FIPS_MODULE\n    /*\n     * We need to ensure that base libcrypto thread handling has been\n     * initialised.\n     */\n     OPENSSL_init_crypto(OPENSSL_INIT_BASE_ONLY, NULL);\n#endif\n\n    dgbl->lock = CRYPTO_THREAD_lock_new();\n    if (dgbl->lock == NULL)\n        goto err1;\n\n    if (!CRYPTO_THREAD_init_local(&dgbl->private, NULL))\n        goto err1;\n\n    if (!CRYPTO_THREAD_init_local(&dgbl->public, NULL))\n        goto err2;\n\n    return dgbl;\n\n err2:\n    CRYPTO_THREAD_cleanup_local(&dgbl->private);\n err1:\n    CRYPTO_THREAD_lock_free(dgbl->lock);\n    OPENSSL_free(dgbl);\n    return NULL;\n}\n\nvoid ossl_rand_ctx_free(void *vdgbl)\n{\n    RAND_GLOBAL *dgbl = vdgbl;\n\n    if (dgbl == NULL)\n        return;\n\n    CRYPTO_THREAD_lock_free(dgbl->lock);\n    CRYPTO_THREAD_cleanup_local(&dgbl->private);\n    CRYPTO_THREAD_cleanup_local(&dgbl->public);\n    EVP_RAND_CTX_free(dgbl->primary);\n    EVP_RAND_CTX_free(dgbl->seed);\n    OPENSSL_free(dgbl->rng_name);\n    OPENSSL_free(dgbl->rng_cipher);\n    OPENSSL_free(dgbl->rng_digest);\n    OPENSSL_free(dgbl->rng_propq);\n    OPENSSL_free(dgbl->seed_name);\n    OPENSSL_free(dgbl->seed_propq);\n\n    OPENSSL_free(dgbl);\n}\n\nstatic RAND_GLOBAL *rand_get_global(OSSL_LIB_CTX *libctx)\n{\n    return ossl_lib_ctx_get_data(libctx, OSSL_LIB_CTX_DRBG_INDEX);\n}\n\nstatic void rand_delete_thread_state(void *arg)\n{\n    OSSL_LIB_CTX *ctx = arg;\n    RAND_GLOBAL *dgbl = rand_get_global(ctx);\n    EVP_RAND_CTX *rand;\n\n    if (dgbl == NULL)\n        return;\n\n    rand = CRYPTO_THREAD_get_local(&dgbl->public);\n    CRYPTO_THREAD_set_local(&dgbl->public, NULL);\n    EVP_RAND_CTX_free(rand);\n\n    rand = CRYPTO_THREAD_get_local(&dgbl->private);\n    CRYPTO_THREAD_set_local(&dgbl->private, NULL);\n    EVP_RAND_CTX_free(rand);\n}\n\n#ifndef FIPS_MODULE\nstatic EVP_RAND_CTX *rand_new_seed(OSSL_LIB_CTX *libctx)\n{\n    EVP_RAND *rand;\n    RAND_GLOBAL *dgbl = rand_get_global(libctx);\n    EVP_RAND_CTX *ctx = NULL;\n    const char *propq;\n    char *name, *props = NULL;\n    size_t props_len;\n    OSSL_PROPERTY_LIST *pl1, *pl2, *pl3 = NULL;\n\n    if (dgbl == NULL)\n        return NULL;\n    propq = dgbl->seed_propq;\n    if (dgbl->seed_name != NULL) {\n        name = dgbl->seed_name;\n    } else {\n        /*\n         * Default to our internal seed source.  This isn't part of the FIPS\n         * provider so we need to override any FIPS properties.\n         */\n        if (propq == NULL || *propq == '\\0') {\n            propq = \"-fips\";\n        } else {\n            pl1 = ossl_parse_query(libctx, propq, 1);\n            if (pl1 == NULL) {\n                ERR_raise(ERR_LIB_RAND, RAND_R_INVALID_PROPERTY_QUERY);\n                return NULL;\n            }\n            pl2 = ossl_parse_query(libctx, \"-fips\", 1);\n            if (pl2 == NULL) {\n                ossl_property_free(pl1);\n                ERR_raise(ERR_LIB_RAND, ERR_R_INTERNAL_ERROR);\n                return NULL;\n            }\n            pl3 = ossl_property_merge(pl2, pl1);\n            ossl_property_free(pl1);\n            ossl_property_free(pl2);\n            if (pl3 == NULL) {\n                ERR_raise(ERR_LIB_RAND, ERR_R_INTERNAL_ERROR);\n                return NULL;\n            }\n            props_len = ossl_property_list_to_string(libctx, pl3, NULL, 0);\n            if (props_len == 0) {\n                /* Shouldn't happen since we added a query element */\n                ERR_raise(ERR_LIB_RAND, ERR_R_INTERNAL_ERROR);\n                goto err;\n            } else {\n                props = OPENSSL_malloc(props_len);\n                if (props == NULL) {\n                    ERR_raise(ERR_LIB_RAND, ERR_R_MALLOC_FAILURE);\n                    goto err;\n                }\n                if (ossl_property_list_to_string(libctx, pl3,\n                                                 props, props_len) == 0) {\n                    ERR_raise(ERR_LIB_RAND, ERR_R_INTERNAL_ERROR);\n                    goto err;\n                }\n                ossl_property_free(pl3);\n                pl3 = NULL;\n                propq = props;\n            }\n        }\n        name = \"SEED-SRC\";\n    }\n\n    rand = EVP_RAND_fetch(libctx, name, propq);\n    if (rand == NULL) {\n        ERR_raise(ERR_LIB_RAND, RAND_R_UNABLE_TO_FETCH_DRBG);\n        goto err;\n    }\n    ctx = EVP_RAND_CTX_new(rand, NULL);\n    EVP_RAND_free(rand);\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_RAND, RAND_R_UNABLE_TO_CREATE_DRBG);\n        goto err;\n    }\n    if (!EVP_RAND_instantiate(ctx, 0, 0, NULL, 0, NULL)) {\n        ERR_raise(ERR_LIB_RAND, RAND_R_ERROR_INSTANTIATING_DRBG);\n        goto err;\n    }\n    OPENSSL_free(props);\n    return ctx;\n err:\n    EVP_RAND_CTX_free(ctx);\n    ossl_property_free(pl3);\n    OPENSSL_free(props);\n    return NULL;\n}\n\nEVP_RAND_CTX *ossl_rand_get0_seed_noncreating(OSSL_LIB_CTX *ctx)\n{\n    RAND_GLOBAL *dgbl = rand_get_global(ctx);\n    EVP_RAND_CTX *ret;\n\n    if (dgbl == NULL)\n        return NULL;\n\n    if (!CRYPTO_THREAD_read_lock(dgbl->lock))\n        return NULL;\n    ret = dgbl->seed;\n    CRYPTO_THREAD_unlock(dgbl->lock);\n    return ret;\n}\n#endif\n\nstatic EVP_RAND_CTX *rand_new_drbg(OSSL_LIB_CTX *libctx, EVP_RAND_CTX *parent,\n                                   unsigned int reseed_interval,\n                                   time_t reseed_time_interval, int use_df)\n{\n    EVP_RAND *rand;\n    RAND_GLOBAL *dgbl = rand_get_global(libctx);\n    EVP_RAND_CTX *ctx;\n    OSSL_PARAM params[8], *p = params;\n    const OSSL_PARAM *settables;\n    char *name, *cipher;\n\n    if (dgbl == NULL)\n        return NULL;\n    name = dgbl->rng_name != NULL ? dgbl->rng_name : \"CTR-DRBG\";\n    rand = EVP_RAND_fetch(libctx, name, dgbl->rng_propq);\n    if (rand == NULL) {\n        ERR_raise(ERR_LIB_RAND, RAND_R_UNABLE_TO_FETCH_DRBG);\n        return NULL;\n    }\n    ctx = EVP_RAND_CTX_new(rand, parent);\n    EVP_RAND_free(rand);\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_RAND, RAND_R_UNABLE_TO_CREATE_DRBG);\n        return NULL;\n    }\n\n    settables = EVP_RAND_CTX_settable_params(ctx);\n    if (OSSL_PARAM_locate_const(settables, OSSL_DRBG_PARAM_CIPHER)) {\n        cipher = dgbl->rng_cipher != NULL ? dgbl->rng_cipher : \"AES-256-CTR\";\n        *p++ = OSSL_PARAM_construct_utf8_string(OSSL_DRBG_PARAM_CIPHER,\n                                                cipher, 0);\n    }\n    if (dgbl->rng_digest != NULL\n            && OSSL_PARAM_locate_const(settables, OSSL_DRBG_PARAM_DIGEST))\n        *p++ = OSSL_PARAM_construct_utf8_string(OSSL_DRBG_PARAM_DIGEST,\n                                                dgbl->rng_digest, 0);\n    if (dgbl->rng_propq != NULL)\n        *p++ = OSSL_PARAM_construct_utf8_string(OSSL_DRBG_PARAM_PROPERTIES,\n                                                dgbl->rng_propq, 0);\n    if (OSSL_PARAM_locate_const(settables, OSSL_ALG_PARAM_MAC))\n        *p++ = OSSL_PARAM_construct_utf8_string(OSSL_ALG_PARAM_MAC, \"HMAC\", 0);\n    if (OSSL_PARAM_locate_const(settables, OSSL_DRBG_PARAM_USE_DF))\n        *p++ = OSSL_PARAM_construct_int(OSSL_DRBG_PARAM_USE_DF, &use_df);\n    *p++ = OSSL_PARAM_construct_uint(OSSL_DRBG_PARAM_RESEED_REQUESTS,\n                                     &reseed_interval);\n    *p++ = OSSL_PARAM_construct_time_t(OSSL_DRBG_PARAM_RESEED_TIME_INTERVAL,\n                                       &reseed_time_interval);\n    *p = OSSL_PARAM_construct_end();\n    if (!EVP_RAND_instantiate(ctx, 0, 0, NULL, 0, params)) {\n        ERR_raise(ERR_LIB_RAND, RAND_R_ERROR_INSTANTIATING_DRBG);\n        EVP_RAND_CTX_free(ctx);\n        return NULL;\n    }\n    return ctx;\n}\n\n/*\n * Get the primary random generator.\n * Returns pointer to its EVP_RAND_CTX on success, NULL on failure.\n *\n */\nEVP_RAND_CTX *RAND_get0_primary(OSSL_LIB_CTX *ctx)\n{\n    RAND_GLOBAL *dgbl = rand_get_global(ctx);\n    EVP_RAND_CTX *ret;\n\n    if (dgbl == NULL)\n        return NULL;\n\n    if (!CRYPTO_THREAD_read_lock(dgbl->lock))\n        return NULL;\n\n    ret = dgbl->primary;\n    CRYPTO_THREAD_unlock(dgbl->lock);\n\n    if (ret != NULL)\n        return ret;\n\n    if (!CRYPTO_THREAD_write_lock(dgbl->lock))\n        return NULL;\n\n    ret = dgbl->primary;\n    if (ret != NULL) {\n        CRYPTO_THREAD_unlock(dgbl->lock);\n        return ret;\n    }\n\n#ifndef FIPS_MODULE\n    if (dgbl->seed == NULL) {\n        ERR_set_mark();\n        dgbl->seed = rand_new_seed(ctx);\n        ERR_pop_to_mark();\n    }\n#endif\n\n    ret = dgbl->primary = rand_new_drbg(ctx, dgbl->seed,\n                                        PRIMARY_RESEED_INTERVAL,\n                                        PRIMARY_RESEED_TIME_INTERVAL, 1);\n    /*\n    * The primary DRBG may be shared between multiple threads so we must\n    * enable locking.\n    */\n    if (ret != NULL && !EVP_RAND_enable_locking(ret)) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_UNABLE_TO_ENABLE_LOCKING);\n        EVP_RAND_CTX_free(ret);\n        ret = dgbl->primary = NULL;\n    }\n    CRYPTO_THREAD_unlock(dgbl->lock);\n\n"}], "code": "int ossl_quic_gen_rand_conn_id(OSSL_LIB_CTX *libctx, size_t len,\n                               QUIC_CONN_ID *cid)\n{\n    if (len > QUIC_MAX_CONN_ID_LEN)\n        return 0;\n\n    cid->id_len = (unsigned char)len;\n\n    if (RAND_bytes_ex(libctx, cid->id, len, len * 8) != 1) {\n        ERR_raise(ERR_LIB_SSL, ERR_R_RAND_LIB);\n        cid->id_len = 0;\n        return 0;\n    }\n\n    return 1;\n}\n"}, "E45BF6A232C49079": {"calls": [{"id": "60C8E50C68B60E18", "name": "OSSL_CMP_CTX_set_transfer_cb", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 846, "col": 1}, "end": {"line": 846, "col": 1}, "code": "\n/* Set argument optionally to be used by the transfer callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the transfer callback.\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, transfer_cb_arg, void *, NULL)\n\n/** Set the HTTP server port to be used */\nDEFINE_OSSL_set(OSSL_CMP_CTX, serverPort, int)\n\n/* Set the HTTP path to be used on the server (e.g \"pkix/\") */\nDEFINE_OSSL_CMP_CTX_set1(serverPath, char)\n\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "FF231E13D74EF1B0", "name": "set_name", "path": "openssl/apps/cmp.c", "start": {"line": 892, "col": 1}, "end": {"line": 909, "col": 1}, "code": "                    int (*set_fn) (OSSL_CMP_CTX *ctx, const X509_NAME *name),\n                    OSSL_CMP_CTX *ctx, const char *desc)\n{\n    if (str != NULL) {\n        X509_NAME *n = parse_name(str, MBSTRING_ASC, 1, desc);\n\n        if (n == NULL)\n            return 0;\n        if (!(*set_fn) (ctx, n)) {\n            X509_NAME_free(n);\n            CMP_err(\"out of memory\");\n            return 0;\n        }\n        X509_NAME_free(n);\n    }\n    return 1;\n}\n\nstatic int set_gennames(OSSL_CMP_CTX *ctx, char *names, const char *desc)\n{\n    char *next;\n\n    for (; names != NULL; names = next) {\n        GENERAL_NAME *n;\n\n        next = next_item(names);\n        if (strcmp(names, \"critical\") == 0) {\n            (void)OSSL_CMP_CTX_set_option(ctx,\n                                          OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL,\n                                          1);\n            continue;\n        }\n\n        /* try IP address first, then email/URI/domain name */\n        (void)ERR_set_mark();\n        n = a2i_GENERAL_NAME(NULL, NULL, NULL, GEN_IPADD, names, 0);\n        if (n == NULL)\n            n = a2i_GENERAL_NAME(NULL, NULL, NULL,\n                                 strchr(names, '@') != NULL ? GEN_EMAIL :\n                                 strchr(names, ':') != NULL ? GEN_URI : GEN_DNS,\n                                 names, 0);\n        (void)ERR_pop_to_mark();\n\n        if (n == NULL) {\n            CMP_err2(\"bad syntax of %s '%s'\", desc, names);\n            return 0;\n        }\n        if (!OSSL_CMP_CTX_push1_subjectAltName(ctx, n)) {\n            GENERAL_NAME_free(n);\n            CMP_err(\"out of memory\");\n            return 0;\n        }\n        GENERAL_NAME_free(n);\n    }\n    return 1;\n}\n\nstatic X509_STORE *load_trusted(char *input, int for_new_cert, const char *desc)\n{\n    X509_STORE *ts = load_certstore(input, opt_otherpass, desc, vpm);\n\n    if (ts == NULL)\n        return NULL;\n    X509_STORE_set_verify_cb(ts, X509_STORE_CTX_print_verify_cb);\n\n    /* copy vpm to store */\n    if (X509_STORE_set1_param(ts, vpm /* may be NULL */)\n            && (for_new_cert || truststore_set_host_etc(ts, NULL)))\n        return ts;\n    BIO_printf(bio_err, \"error setting verification parameters for %s\\n\", desc);\n    OSSL_CMP_CTX_print_errors(cmp_ctx);\n    X509_STORE_free(ts);\n    return NULL;\n}\n\ntypedef int (*add_X509_fn_t)(void *ctx, const X509 *cert);\nstatic int setup_cert(void *ctx, const char *file, const char *pass,\n                      const char *desc, add_X509_fn_t set1_fn)\n{\n    X509 *cert;\n    int ok;\n\n    if (file == NULL)\n        return 1;\n    if ((cert = load_cert_pwd(file, pass, desc)) == NULL)\n        return 0;\n    ok = (*set1_fn)(ctx, cert);\n    X509_free(cert);\n    return ok;\n}\n\ntypedef int (*add_X509_stack_fn_t)(void *ctx, const STACK_OF(X509) *certs);\nstatic int setup_certs(char *files, const char *desc, void *ctx,\n                       add_X509_stack_fn_t set1_fn)\n{\n    STACK_OF(X509) *certs;\n    int ok;\n\n    if (files == NULL)\n        return 1;\n    if ((certs = load_certs_multifile(files, opt_otherpass, desc, vpm)) == NULL)\n        return 0;\n    ok = (*set1_fn)(ctx, certs);\n    OSSL_STACK_OF_X509_free(certs);\n    return ok;\n}\n\n/*\n * parse and transform some options, checking their syntax.\n * Returns 1 on success, 0 on error\n */\nstatic int transform_opts(void)\n{\n    if (opt_cmd_s != NULL) {\n        if (!strcmp(opt_cmd_s, \"ir\")) {\n            opt_cmd = CMP_IR;\n        } else if (!strcmp(opt_cmd_s, \"kur\")) {\n            opt_cmd = CMP_KUR;\n        } else if (!strcmp(opt_cmd_s, \"cr\")) {\n            opt_cmd = CMP_CR;\n        } else if (!strcmp(opt_cmd_s, \"p10cr\")) {\n            opt_cmd = CMP_P10CR;\n        } else if (!strcmp(opt_cmd_s, \"rr\")) {\n            opt_cmd = CMP_RR;\n        } else if (!strcmp(opt_cmd_s, \"genm\")) {\n            opt_cmd = CMP_GENM;\n        } else {\n            CMP_err1(\"unknown cmp command '%s'\", opt_cmd_s);\n            return 0;\n        }\n    } else {\n        CMP_err(\"no cmp command to execute\");\n        return 0;\n    }\n\n# define FORMAT_OPTIONS (OPT_FMT_PEMDER | OPT_FMT_PKCS12)\n\n    if (opt_keyform_s != NULL\n            && !opt_format(opt_keyform_s, FORMAT_OPTIONS, &opt_keyform)) {\n        CMP_err(\"unknown option given for key loading format\");\n        return 0;\n    }\n\n#undef FORMAT_OPTIONS\n\n    if (opt_certform_s != NULL\n            && !opt_format(opt_certform_s, OPT_FMT_PEMDER, &opt_certform)) {\n        CMP_err(\"unknown option given for certificate storing format\");\n        return 0;\n    }\n\n    return 1;\n}\n\nstatic OSSL_CMP_SRV_CTX *setup_srv_ctx(ENGINE *engine)\n{\n    OSSL_CMP_CTX *ctx; /* extra CMP (client) ctx partly used by server */\n    OSSL_CMP_SRV_CTX *srv_ctx = ossl_cmp_mock_srv_new(app_get0_libctx(),\n                                                      app_get0_propq());\n\n    if (srv_ctx == NULL)\n        return NULL;\n    ctx = OSSL_CMP_SRV_CTX_get0_cmp_ctx(srv_ctx);\n\n    if (opt_srv_ref == NULL) {\n        if (opt_srv_cert == NULL) {\n            /* opt_srv_cert should determine the sender */\n            CMP_err(\"must give -srv_ref for mock server if no -srv_cert given\");\n            goto err;\n        }\n    } else {\n        if (!OSSL_CMP_CTX_set1_referenceValue(ctx, (unsigned char *)opt_srv_ref,\n                                              strlen(opt_srv_ref)))\n            goto err;\n    }\n\n    if (opt_srv_secret != NULL) {\n        int res;\n        char *pass_str = get_passwd(opt_srv_secret, \"PBMAC secret of mock server\");\n\n        if (pass_str != NULL) {\n            cleanse(opt_srv_secret);\n            res = OSSL_CMP_CTX_set1_secretValue(ctx, (unsigned char *)pass_str,\n                                                strlen(pass_str));\n            clear_free(pass_str);\n            if (res == 0)\n                goto err;\n        }\n    } else if (opt_srv_cert == NULL) {\n        CMP_err(\"server credentials (-srv_secret or -srv_cert) must be given if -use_mock_srv or -port is used\");\n        goto err;\n    } else {\n        CMP_warn(\"server will not be able to handle PBM-protected requests since -srv_secret is not given\");\n    }\n\n    if (opt_srv_secret == NULL\n            && ((opt_srv_cert == NULL) != (opt_srv_key == NULL))) {\n        CMP_err(\"must give both -srv_cert and -srv_key options or neither\");\n        goto err;\n    }\n    if (!setup_cert(ctx, opt_srv_cert, opt_srv_keypass,\n                    \"signer certificate of the mock server\",\n                    (add_X509_fn_t)OSSL_CMP_CTX_set1_cert))\n        goto err;\n    if (opt_srv_key != NULL) {\n        EVP_PKEY *pkey = load_key_pwd(opt_srv_key, opt_keyform,\n                                      opt_srv_keypass,\n                                      engine, \"private key for mock server cert\");\n\n        if (pkey == NULL || !OSSL_CMP_CTX_set1_pkey(ctx, pkey)) {\n            EVP_PKEY_free(pkey);\n            goto err;\n        }\n        EVP_PKEY_free(pkey);\n    }\n    cleanse(opt_srv_keypass);\n\n    if (opt_srv_trusted != NULL) {\n        X509_STORE *ts =\n            load_trusted(opt_srv_trusted, 0, \"certs trusted by mock server\");\n\n        if (ts == NULL || !OSSL_CMP_CTX_set0_trusted(ctx, ts)) {\n            X509_STORE_free(ts);\n            goto err;\n        }\n    } else {\n        CMP_warn(\"mock server will not be able to handle signature-protected requests since -srv_trusted is not given\");\n    }\n    if (!setup_certs(opt_srv_untrusted,\n                     \"untrusted certificates for mock server\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_untrusted))\n        goto err;\n\n    if (!setup_cert(srv_ctx, opt_ref_cert, opt_otherpass,\n                    \"reference cert to be expected by the mock server\",\n                    (add_X509_fn_t)ossl_cmp_mock_srv_set1_refCert))\n            goto err;\n    if (opt_rsp_cert == NULL) {\n        CMP_warn(\"no -rsp_cert given for mock server\");\n    } else {\n        if (!setup_cert(srv_ctx, opt_rsp_cert, opt_keypass,\n                        \"cert the mock server returns on certificate requests\",\n                        (add_X509_fn_t)ossl_cmp_mock_srv_set1_certOut))\n            goto err;\n    }\n    if (!setup_certs(opt_rsp_extracerts,\n                     \"CMP extra certificates for mock server\", srv_ctx,\n                     (add_X509_stack_fn_t)ossl_cmp_mock_srv_set1_chainOut))\n        goto err;\n    if (!setup_certs(opt_rsp_capubs, \"caPubs for mock server\", srv_ctx,\n                     (add_X509_stack_fn_t)ossl_cmp_mock_srv_set1_caPubsOut))\n        goto err;\n    if (!setup_cert(srv_ctx, opt_rsp_newwithnew, opt_otherpass,\n                    \"NewWithNew cert the mock server returns in rootCaKeyUpdate\",\n                    (add_X509_fn_t)ossl_cmp_mock_srv_set1_newWithNew)\n        || !setup_cert(srv_ctx, opt_rsp_newwithold, opt_otherpass,\n                       \"NewWithOld cert the mock server returns in rootCaKeyUpdate\",\n                       (add_X509_fn_t)ossl_cmp_mock_srv_set1_newWithOld)\n        || !setup_cert(srv_ctx, opt_rsp_oldwithnew, opt_otherpass,\n                       \"OldWithNew cert the mock server returns in rootCaKeyUpdate\",\n                       (add_X509_fn_t)ossl_cmp_mock_srv_set1_oldWithNew))\n        goto err;\n    (void)ossl_cmp_mock_srv_set_pollCount(srv_ctx, opt_poll_count);\n    (void)ossl_cmp_mock_srv_set_checkAfterTime(srv_ctx, opt_check_after);\n    if (opt_grant_implicitconf)\n        (void)OSSL_CMP_SRV_CTX_set_grant_implicit_confirm(srv_ctx, 1);\n\n    if (opt_failure != INT_MIN) { /* option has been set explicitly */\n        if (opt_failure < 0 || OSSL_CMP_PKIFAILUREINFO_MAX < opt_failure) {\n            CMP_err1(\"-failure out of range, should be >= 0 and <= %d\",\n                     OSSL_CMP_PKIFAILUREINFO_MAX);\n            goto err;\n        }\n        if (opt_failurebits != 0)\n            CMP_warn(\"-failurebits overrides -failure\");\n        else\n            opt_failurebits = 1 << opt_failure;\n    }\n    if ((unsigned)opt_failurebits > OSSL_CMP_PKIFAILUREINFO_MAX_BIT_PATTERN) {\n        CMP_err(\"-failurebits out of range\");\n        goto err;\n    }\n    if (!ossl_cmp_mock_srv_set_statusInfo(srv_ctx, opt_pkistatus,\n                                          opt_failurebits, opt_statusstring))\n        goto err;\n\n    if (opt_send_error)\n        (void)ossl_cmp_mock_srv_set_sendError(srv_ctx, 1);\n\n    if (opt_send_unprotected)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_SEND, 1);\n    if (opt_send_unprot_err)\n        (void)OSSL_CMP_SRV_CTX_set_send_unprotected_errors(srv_ctx, 1);\n    if (opt_accept_unprotected)\n        (void)OSSL_CMP_SRV_CTX_set_accept_unprotected(srv_ctx, 1);\n    if (opt_accept_unprot_err)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_ERRORS, 1);\n    if (opt_accept_raverified)\n        (void)OSSL_CMP_SRV_CTX_set_accept_raverified(srv_ctx, 1);\n\n    return srv_ctx;\n\n err:\n    ossl_cmp_mock_srv_free(srv_ctx);\n    return NULL;\n}\n\n/*\n * set up verification aspects of OSSL_CMP_CTX w.r.t. opts from config file/CLI.\n * Returns pointer on success, NULL on error\n */\nstatic int setup_verification_ctx(OSSL_CMP_CTX *ctx)\n{\n    if (!setup_certs(opt_untrusted, \"untrusted certificates\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_untrusted))\n        return 0;\n\n    if (opt_srvcert != NULL || opt_trusted != NULL) {\n        if (opt_srvcert != NULL) {\n            if (opt_trusted != NULL) {\n                CMP_warn(\"-trusted option is ignored since -srvcert option is present\");\n                opt_trusted = NULL;\n            }\n            if (opt_recipient != NULL) {\n                CMP_warn(\"-recipient option is ignored since -srvcert option is present\");\n                opt_recipient = NULL;\n            }\n            if (!setup_cert(ctx, opt_srvcert, opt_otherpass,\n                            \"directly trusted CMP server certificate\",\n                            (add_X509_fn_t)OSSL_CMP_CTX_set1_srvCert))\n                return 0;\n        }\n        if (opt_trusted != NULL) {\n            X509_STORE *ts;\n\n            /*\n             * the 0 arg below clears any expected host/ip/email address;\n             * opt_expect_sender is used instead\n             */\n            ts = load_trusted(opt_trusted, 0, \"certs trusted by client\");\n\n            if (ts == NULL || !OSSL_CMP_CTX_set0_trusted(ctx, ts)) {\n                X509_STORE_free(ts);\n                return 0;\n            }\n        }\n    }\n\n    if (opt_unprotected_errors)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_ERRORS, 1);\n\n    if (opt_out_trusted != NULL) { /* for use in OSSL_CMP_certConf_cb() */\n        X509_VERIFY_PARAM *out_vpm = NULL;\n        X509_STORE *out_trusted =\n            load_trusted(opt_out_trusted, 1,\n                         \"trusted certs for verifying newly enrolled cert\");\n\n        if (out_trusted == NULL)\n            return 0;\n        /* ignore any -attime here, new certs are current anyway */\n        out_vpm = X509_STORE_get0_param(out_trusted);\n        X509_VERIFY_PARAM_clear_flags(out_vpm, X509_V_FLAG_USE_CHECK_TIME);\n\n        (void)OSSL_CMP_CTX_set_certConf_cb_arg(ctx, out_trusted);\n    }\n\n    if (opt_disable_confirm)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_DISABLE_CONFIRM, 1);\n\n    if (opt_implicit_confirm)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_IMPLICIT_CONFIRM, 1);\n\n    return 1;\n}\n\n"}, {"id": "48674EA1CCA94FC0", "name": "setup_request_ctx", "path": "openssl/apps/cmp.c", "start": {"line": 1553, "col": 1}, "end": {"line": 1844, "col": 1}, "code": "{\n    X509_REQ *csr = NULL;\n    X509_EXTENSIONS *exts = NULL;\n    X509V3_CTX ext_ctx;\n\n    if (opt_subject == NULL\n            && opt_csr == NULL && opt_oldcert == NULL && opt_cert == NULL\n            && opt_cmd != CMP_RR && opt_cmd != CMP_GENM)\n        CMP_warn(\"no -subject given; no -csr or -oldcert or -cert available for fallback\");\n\n    if (!set_name(opt_issuer, OSSL_CMP_CTX_set1_issuer, ctx, \"issuer\"))\n        return 0;\n    if (opt_cmd == CMP_IR || opt_cmd == CMP_CR || opt_cmd == CMP_KUR) {\n        if (opt_newkey == NULL\n            && opt_key == NULL && opt_csr == NULL && opt_oldcert == NULL) {\n            CMP_err(\"missing -newkey (or -key) to be certified and no -csr, -oldcert, or -cert given for fallback public key\");\n            return 0;\n        }\n        if (opt_newkey == NULL\n            && opt_popo != OSSL_CRMF_POPO_NONE\n            && opt_popo != OSSL_CRMF_POPO_RAVERIFIED) {\n            if (opt_csr != NULL) {\n                CMP_err1(\"no -newkey option given with private key for POPO, -csr option only provides public key%s\",\n                        opt_key == NULL ? \"\" :\n                        \", and -key option superseded by -csr\");\n                return 0;\n            }\n            if (opt_key == NULL) {\n                CMP_err(\"missing -newkey (or -key) option for POPO\");\n                return 0;\n            }\n        }\n        if (opt_certout == NULL) {\n            CMP_err(\"-certout not given, nowhere to save newly enrolled certificate\");\n            return 0;\n        }\n        if (!set_name(opt_subject, OSSL_CMP_CTX_set1_subjectName, ctx, \"subject\"))\n            return 0;\n    } else {\n        const char *msg = \"option is ignored for commands other than 'ir', 'cr', and 'kur'\";\n\n        if (opt_subject != NULL) {\n            if (opt_ref == NULL && opt_cert == NULL) {\n                /* will use subject as sender unless oldcert subject is used */\n                if (!set_name(opt_subject, OSSL_CMP_CTX_set1_subjectName, ctx, \"subject\"))\n                    return 0;\n            } else {\n                CMP_warn1(\"-subject %s since sender is taken from -ref or -cert\", msg);\n            }\n        }\n        if (opt_issuer != NULL && opt_cmd != CMP_RR)\n            CMP_warn1(\"-issuer %s and 'rr'\", msg);\n        if (opt_reqexts != NULL)\n            CMP_warn1(\"-reqexts %s\", msg);\n        if (opt_san_nodefault)\n            CMP_warn1(\"-san_nodefault %s\", msg);\n        if (opt_sans != NULL)\n            CMP_warn1(\"-sans %s\", msg);\n        if (opt_policies != NULL)\n            CMP_warn1(\"-policies %s\", msg);\n        if (opt_policy_oids != NULL)\n            CMP_warn1(\"-policy_oids %s\", msg);\n        if (opt_cmd != CMP_P10CR) {\n            if (opt_implicit_confirm)\n                CMP_warn1(\"-implicit_confirm %s, and 'p10cr'\", msg);\n            if (opt_disable_confirm)\n                CMP_warn1(\"-disable_confirm %s, and 'p10cr'\", msg);\n            if (opt_certout != NULL)\n                CMP_warn1(\"-certout %s, and 'p10cr'\", msg);\n            if (opt_chainout != NULL)\n                CMP_warn1(\"-chainout %s, and 'p10cr'\", msg);\n        }\n    }\n    if (opt_cmd == CMP_KUR) {\n        char *ref_cert = opt_oldcert != NULL ? opt_oldcert : opt_cert;\n\n        if (ref_cert == NULL && opt_csr == NULL) {\n            CMP_err(\"missing -oldcert for certificate to be updated and no -csr given\");\n            return 0;\n        }\n        if (opt_subject != NULL)\n            CMP_warn2(\"given -subject '%s' overrides the subject of '%s' for KUR\",\n                      opt_subject, ref_cert != NULL ? ref_cert : opt_csr);\n    }\n    if (opt_cmd == CMP_RR) {\n        if (opt_issuer == NULL && opt_serial == NULL) {\n            if (opt_oldcert == NULL && opt_csr == NULL) {\n                CMP_err(\"missing -oldcert or -issuer and -serial for certificate to be revoked and no -csr given\");\n                return 0;\n            }\n            if (opt_oldcert != NULL && opt_csr != NULL)\n                CMP_warn(\"ignoring -csr since certificate to be revoked is given\");\n        } else {\n#define OSSL_CMP_RR_MSG \"since -issuer and -serial is given for command 'rr'\"\n            if (opt_issuer == NULL || opt_serial == NULL) {\n                CMP_err(\"Must give both -issuer and -serial options or neither\");\n                return 0;\n            }\n            if (opt_oldcert != NULL)\n                CMP_warn(\"Ignoring -oldcert \" OSSL_CMP_RR_MSG);\n            if (opt_csr != NULL)\n                CMP_warn(\"Ignoring -csr \" OSSL_CMP_RR_MSG);\n        }\n        if (opt_serial != NULL) {\n            ASN1_INTEGER *sno;\n\n            if ((sno = s2i_ASN1_INTEGER(NULL, opt_serial)) == NULL) {\n                CMP_err1(\"cannot read serial number: '%s'\", opt_serial);\n                return 0;\n            }\n            if (!OSSL_CMP_CTX_set1_serialNumber(ctx, sno)) {\n                ASN1_INTEGER_free(sno);\n                CMP_err(\"out of memory\");\n                return 0;\n            }\n            ASN1_INTEGER_free(sno);\n        }\n        if (opt_revreason > CRL_REASON_NONE)\n            (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_REVOCATION_REASON,\n                                          opt_revreason);\n    } else {\n        if (opt_serial != NULL)\n            CMP_warn(\"Ignoring -serial for command other than 'rr'\");\n    }\n    if (opt_cmd == CMP_P10CR && opt_csr == NULL) {\n        CMP_err(\"missing PKCS#10 CSR for p10cr\");\n        return 0;\n    }\n\n    if (opt_recipient == NULL && opt_srvcert == NULL && opt_issuer == NULL\n            && opt_oldcert == NULL && opt_cert == NULL)\n        CMP_warn(\"missing -recipient, -srvcert, -issuer, -oldcert or -cert; recipient will be set to \\\"NULL-DN\\\"\");\n\n    if (opt_cmd == CMP_P10CR || opt_cmd == CMP_RR || opt_cmd == CMP_GENM) {\n        const char *msg = \"option is ignored for 'p10cr', 'rr', and 'genm' commands\";\n\n        if (opt_newkeypass != NULL)\n            CMP_warn1(\"-newkeypass %s\", msg);\n        if (opt_newkey != NULL)\n            CMP_warn1(\"-newkey %s\", msg);\n        if (opt_days != 0)\n            CMP_warn1(\"-days %s\", msg);\n        if (opt_popo != OSSL_CRMF_POPO_NONE - 1)\n            CMP_warn1(\"-popo %s\", msg);\n        if (opt_out_trusted != NULL)\n            CMP_warn1(\"-out_trusted %s\", msg);\n    } else if (opt_newkey != NULL) {\n        const char *file = opt_newkey;\n        const int format = opt_keyform;\n        const char *pass = opt_newkeypass;\n        const char *desc = \"new private key for cert to be enrolled\";\n        EVP_PKEY *pkey;\n        int priv = 1;\n        BIO *bio_bak = bio_err;\n\n        bio_err = NULL; /* suppress diagnostics on first try loading key */\n        pkey = load_key_pwd(file, format, pass, engine, desc);\n        bio_err = bio_bak;\n        if (pkey == NULL) {\n            ERR_clear_error();\n            desc = opt_csr == NULL\n                ? \"fallback public key for cert to be enrolled\"\n                : \"public key for checking cert resulting from p10cr\";\n            pkey = load_pubkey(file, format, 0, pass, engine, desc);\n            priv = 0;\n        }\n        cleanse(opt_newkeypass);\n        if (pkey == NULL || !OSSL_CMP_CTX_set0_newPkey(ctx, priv, pkey)) {\n            EVP_PKEY_free(pkey);\n            return 0;\n        }\n    }\n\n    if (opt_days > 0\n            && !OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_VALIDITY_DAYS,\n                                        opt_days)) {\n        CMP_err(\"could not set requested cert validity period\");\n        return 0;\n    }\n\n    if (opt_policies != NULL && opt_policy_oids != NULL) {\n        CMP_err(\"cannot have policies both via -policies and via -policy_oids\");\n        return 0;\n    }\n\n    if (opt_csr != NULL) {\n        if (opt_cmd == CMP_GENM) {\n            CMP_warn(\"-csr option is ignored for 'genm' command\");\n        } else {\n            csr = load_csr_autofmt(opt_csr, FORMAT_UNDEF, NULL, \"PKCS#10 CSR\");\n            if (csr == NULL)\n                return 0;\n            if (!OSSL_CMP_CTX_set1_p10CSR(ctx, csr))\n                goto oom;\n        }\n    }\n    if (opt_reqexts != NULL || opt_policies != NULL) {\n        if ((exts = sk_X509_EXTENSION_new_null()) == NULL)\n            goto oom;\n        X509V3_set_ctx(&ext_ctx, NULL, NULL, csr, NULL, X509V3_CTX_REPLACE);\n        X509V3_set_nconf(&ext_ctx, conf);\n        if (opt_reqexts != NULL\n            && !X509V3_EXT_add_nconf_sk(conf, &ext_ctx, opt_reqexts, &exts)) {\n            CMP_err1(\"cannot load certificate request extension section '%s'\",\n                     opt_reqexts);\n            goto exts_err;\n        }\n        if (opt_policies != NULL\n            && !X509V3_EXT_add_nconf_sk(conf, &ext_ctx, opt_policies, &exts)) {\n            CMP_err1(\"cannot load policy cert request extension section '%s'\",\n                     opt_policies);\n            goto exts_err;\n        }\n        OSSL_CMP_CTX_set0_reqExtensions(ctx, exts);\n    }\n    X509_REQ_free(csr);\n    /* After here, must not goto oom/exts_err */\n\n    if (OSSL_CMP_CTX_reqExtensions_have_SAN(ctx) && opt_sans != NULL) {\n        CMP_err(\"cannot have Subject Alternative Names both via -reqexts and via -sans\");\n        return 0;\n    }\n    if (!set_gennames(ctx, opt_sans, \"Subject Alternative Name\"))\n        return 0;\n\n    if (opt_san_nodefault) {\n        if (opt_sans != NULL)\n            CMP_warn(\"-opt_san_nodefault has no effect when -sans is used\");\n        (void)OSSL_CMP_CTX_set_option(ctx,\n                                      OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT, 1);\n    }\n\n    if (opt_policy_oids_critical) {\n        if (opt_policy_oids == NULL)\n            CMP_warn(\"-opt_policy_oids_critical has no effect unless -policy_oids is given\");\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_POLICIES_CRITICAL, 1);\n    }\n\n    while (opt_policy_oids != NULL) {\n        ASN1_OBJECT *policy;\n        POLICYINFO *pinfo;\n        char *next = next_item(opt_policy_oids);\n\n        if ((policy = OBJ_txt2obj(opt_policy_oids, 1)) == 0) {\n            CMP_err1(\"Invalid -policy_oids arg '%s'\", opt_policy_oids);\n            return 0;\n        }\n        if (OBJ_obj2nid(policy) == NID_undef)\n            CMP_warn1(\"Unknown -policy_oids arg: %.40s\", opt_policy_oids);\n\n        if ((pinfo = POLICYINFO_new()) == NULL) {\n            ASN1_OBJECT_free(policy);\n            return 0;\n        }\n        pinfo->policyid = policy;\n\n        if (!OSSL_CMP_CTX_push0_policy(ctx, pinfo)) {\n            CMP_err1(\"cannot add policy with OID '%s'\", opt_policy_oids);\n            POLICYINFO_free(pinfo);\n            return 0;\n        }\n        opt_policy_oids = next;\n    }\n\n    if (opt_popo >= OSSL_CRMF_POPO_NONE)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_POPO_METHOD, opt_popo);\n\n    if (opt_oldcert != NULL) {\n        if (opt_cmd == CMP_GENM) {\n            CMP_warn(\"-oldcert option is ignored for 'genm' command\");\n        } else {\n            if (!setup_cert(ctx, opt_oldcert, opt_keypass,\n                            /* needed if opt_oldcert is encrypted PKCS12 file */\n                            opt_cmd == CMP_KUR ? \"certificate to be updated\" :\n                            opt_cmd == CMP_RR ? \"certificate to be revoked\" :\n                            \"reference certificate (oldcert)\",\n                            (add_X509_fn_t)OSSL_CMP_CTX_set1_oldCert))\n                return 0;\n        }\n    }\n    cleanse(opt_keypass);\n\n    return 1;\n\n oom:\n    CMP_err(\"out of memory\");\n exts_err:\n    sk_X509_EXTENSION_pop_free(exts, X509_EXTENSION_free);\n    X509_REQ_free(csr);\n    return 0;\n}\n\nstatic int add_certProfile(OSSL_CMP_CTX *ctx, const char *name)\n{\n    OSSL_CMP_ITAV *itav = NULL;\n    STACK_OF(ASN1_UTF8STRING) *sk;\n    ASN1_UTF8STRING *utf8string;\n\n    if (ctx == NULL || name == NULL)\n        return 0;\n\n    if ((sk = sk_ASN1_UTF8STRING_new_reserve(NULL, 1)) == NULL)\n        return 0;\n   if ((utf8string = ASN1_UTF8STRING_new()) == NULL)\n       goto err;\n   if (!ASN1_STRING_set(utf8string, name, (int)strlen(name))) {\n       ASN1_STRING_free(utf8string);\n       goto err;\n   }\n   /* Due to sk_ASN1_UTF8STRING_new_reserve(NULL, 1), this surely succeeds: */\n   (void)sk_ASN1_UTF8STRING_push(sk, utf8string);\n   if ((itav = OSSL_CMP_ITAV_new0_certProfile(sk)) == NULL)\n       goto err;\n   if (OSSL_CMP_CTX_push0_geninfo_ITAV(ctx, itav))\n       return 1;\n   OSSL_CMP_ITAV_free(itav);\n   return 0;\n\n err:\n    sk_ASN1_UTF8STRING_pop_free(sk, ASN1_UTF8STRING_free);\n    return 0;\n}\n\nstatic int handle_opt_geninfo(OSSL_CMP_CTX *ctx)\n{\n    ASN1_OBJECT *obj = NULL;\n    ASN1_TYPE *type = NULL;\n    long value;\n    ASN1_INTEGER *aint = NULL;\n    ASN1_UTF8STRING *text = NULL;\n    OSSL_CMP_ITAV *itav;\n    char *ptr = opt_geninfo, *oid, *end;\n\n    do {\n        while (isspace(_UC(*ptr)))\n            ptr++;\n        oid = ptr;\n        if ((ptr = strchr(oid, ':')) == NULL) {\n            CMP_err1(\"Missing ':' in -geninfo arg %.40s\", oid);\n            return 0;\n        }\n        *ptr++ = '\\0';\n        if ((obj = OBJ_txt2obj(oid, 0)) == NULL) {\n            CMP_err1(\"Invalid OID in -geninfo arg %.40s\", oid);\n            return 0;\n        }\n        if (OBJ_obj2nid(obj) == NID_undef)\n            CMP_warn1(\"Unknown OID in -geninfo arg: %.40s\", oid);\n        if ((type = ASN1_TYPE_new()) == NULL)\n            goto oom;\n\n        if (CHECK_AND_SKIP_CASE_PREFIX(ptr, \"int:\")) {\n            value = strtol(ptr, &end, 10);\n            if (end == ptr) {\n                CMP_err1(\"Cannot parse int in -geninfo arg %.40s\", ptr);\n                goto err;\n            }\n            ptr = end;\n            if (*ptr != '\\0') {\n                if (*ptr != ',') {\n                    CMP_err1(\"Missing ',' or end of -geninfo arg after int at %.40s\",\n                        ptr);\n                    goto err;\n                }\n                ptr++;\n            }\n\n            if ((aint = ASN1_INTEGER_new()) == NULL\n                    || !ASN1_INTEGER_set(aint, value))\n                goto oom;\n            ASN1_TYPE_set(type, V_ASN1_INTEGER, aint);\n            aint = NULL;\n\n        } else if (CHECK_AND_SKIP_CASE_PREFIX(ptr, \"str:\")) {\n            end = strchr(ptr, ',');\n            if (end == NULL)\n                end = ptr + strlen(ptr);\n            else\n                *end++ = '\\0';\n            if ((text = ASN1_UTF8STRING_new()) == NULL\n                    || !ASN1_STRING_set(text, ptr, -1))\n                goto oom;\n            ptr = end;\n            ASN1_TYPE_set(type, V_ASN1_UTF8STRING, text);\n            text = NULL;\n\n        } else {\n            CMP_err1(\"Missing 'int:' or 'str:' in -geninfo arg %.40s\", ptr);\n            goto err;\n        }\n\n        if ((itav = OSSL_CMP_ITAV_create(obj, type)) == NULL) {\n            CMP_err(\"Unable to create 'OSSL_CMP_ITAV' structure\");\n            goto err;\n        }\n        obj = NULL;\n        type = NULL;\n\n        if (!OSSL_CMP_CTX_push0_geninfo_ITAV(ctx, itav)) {\n            CMP_err(\"Failed to add ITAV for geninfo of the PKI message header\");\n            OSSL_CMP_ITAV_free(itav);\n            return 0;\n        }\n    } while (*ptr != '\\0');\n    return 1;\n\n oom:\n    CMP_err(\"out of memory\");\n err:\n    ASN1_OBJECT_free(obj);\n    ASN1_TYPE_free(type);\n    ASN1_INTEGER_free(aint);\n    ASN1_UTF8STRING_free(text);\n    return 0;\n}\n\n/*\n * set up the client-side OSSL_CMP_CTX based on options from config file/CLI\n * while parsing options and checking their consistency.\n * Prints reason for error to bio_err.\n * Returns 1 on success, 0 on error\n */\nstatic int setup_client_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    int ret = 0;\n    char *host = NULL, *port = NULL, *path = NULL, *used_path = opt_path;\n"}, {"id": "B9F19136D90DC27B", "name": "setup_protection_ctx", "path": "openssl/apps/cmp.c", "start": {"line": 1433, "col": 1}, "end": {"line": 1546, "col": 1}, "code": "{\n    if (!opt_unprotected_requests && opt_secret == NULL && opt_key == NULL) {\n        CMP_err(\"must give -key or -secret unless -unprotected_requests is used\");\n        return 0;\n    }\n\n    if (opt_ref == NULL && opt_cert == NULL && opt_subject == NULL) {\n        /* cert or subject should determine the sender */\n        CMP_err(\"must give -ref if no -cert and no -subject given\");\n        return 0;\n    }\n    if (opt_secret == NULL && ((opt_cert == NULL) != (opt_key == NULL))) {\n        CMP_err(\"must give both -cert and -key options or neither\");\n        return 0;\n    }\n    if (opt_secret != NULL) {\n        char *pass_string = get_passwd(opt_secret, \"PBMAC\");\n        int res;\n\n        if (pass_string != NULL) {\n            cleanse(opt_secret);\n            res = OSSL_CMP_CTX_set1_secretValue(ctx,\n                                                (unsigned char *)pass_string,\n                                                strlen(pass_string));\n            clear_free(pass_string);\n            if (res == 0)\n                return 0;\n        }\n        if (opt_cert != NULL || opt_key != NULL)\n            CMP_warn(\"-cert and -key not used for protection since -secret is given\");\n    }\n    if (opt_ref != NULL\n            && !OSSL_CMP_CTX_set1_referenceValue(ctx, (unsigned char *)opt_ref,\n                                                 strlen(opt_ref)))\n        return 0;\n\n    if (opt_key != NULL) {\n        EVP_PKEY *pkey = load_key_pwd(opt_key, opt_keyform, opt_keypass, engine,\n                                      \"private key for CMP client certificate\");\n\n        if (pkey == NULL || !OSSL_CMP_CTX_set1_pkey(ctx, pkey)) {\n            EVP_PKEY_free(pkey);\n            return 0;\n        }\n        EVP_PKEY_free(pkey);\n    }\n    if (opt_secret == NULL && opt_srvcert == NULL && opt_trusted == NULL)\n        CMP_warn(\"will not authenticate server due to missing -secret, -trusted, or -srvcert\");\n\n    if (opt_cert != NULL) {\n        X509 *cert;\n        STACK_OF(X509) *certs = NULL;\n        X509_STORE *own_trusted = NULL;\n        int ok;\n\n        if (!load_cert_certs(opt_cert, &cert, &certs, 0, opt_keypass,\n                             \"CMP client certificate (optionally with chain)\",\n                             vpm))\n            /* opt_keypass is needed if opt_cert is an encrypted PKCS#12 file */\n            return 0;\n        ok = OSSL_CMP_CTX_set1_cert(ctx, cert);\n        X509_free(cert);\n        if (!ok) {\n            CMP_err(\"out of memory\");\n        } else {\n            if (opt_own_trusted != NULL) {\n                own_trusted = load_trusted(opt_own_trusted, 0,\n                                           \"trusted certs for verifying own CMP signer cert\");\n                ok = own_trusted != NULL;\n            }\n            ok = ok && OSSL_CMP_CTX_build_cert_chain(ctx, own_trusted, certs);\n        }\n        X509_STORE_free(own_trusted);\n        OSSL_STACK_OF_X509_free(certs);\n        if (!ok)\n            return 0;\n    } else if (opt_own_trusted != NULL) {\n        CMP_warn(\"-own_trusted option is ignored without -cert\");\n    }\n\n    if (!setup_certs(opt_extracerts, \"extra certificates for CMP\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_extraCertsOut))\n        return 0;\n    cleanse(opt_otherpass);\n\n    if (opt_unprotected_requests)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_SEND, 1);\n\n    if (opt_digest != NULL) {\n        int digest = OBJ_ln2nid(opt_digest);\n\n        if (digest == NID_undef) {\n            CMP_err1(\"digest algorithm name not recognized: '%s'\", opt_digest);\n            return 0;\n        }\n        if (!OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_DIGEST_ALGNID, digest)\n            || !OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_OWF_ALGNID, digest)) {\n            CMP_err1(\"digest algorithm name not supported: '%s'\", opt_digest);\n            return 0;\n        }\n    }\n\n    if (opt_mac != NULL) {\n        int mac = OBJ_ln2nid(opt_mac);\n\n        if (mac == NID_undef) {\n            CMP_err1(\"MAC algorithm name not recognized: '%s'\", opt_mac);\n            return 0;\n        }\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_MAC_ALGNID, mac);\n    }\n    return 1;\n}\n\n/*\n * Set up IR/CR/P10CR/KUR/CertConf/RR/GENM specific parts of the OSSL_CMP_CTX\n * based on options from CLI and/or config file.\n * Returns 1 on success, 0 on error\n */\nstatic int setup_request_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    X509_REQ *csr = NULL;\n    X509_EXTENSIONS *exts = NULL;\n    X509V3_CTX ext_ctx;\n\n    if (opt_subject == NULL\n            && opt_csr == NULL && opt_oldcert == NULL && opt_cert == NULL\n            && opt_cmd != CMP_RR && opt_cmd != CMP_GENM)\n        CMP_warn(\"no -subject given; no -csr or -oldcert or -cert available for fallback\");\n\n    if (!set_name(opt_issuer, OSSL_CMP_CTX_set1_issuer, ctx, \"issuer\"))\n        return 0;\n    if (opt_cmd == CMP_IR || opt_cmd == CMP_CR || opt_cmd == CMP_KUR) {\n        if (opt_newkey == NULL\n            && opt_key == NULL && opt_csr == NULL && opt_oldcert == NULL) {\n            CMP_err(\"missing -newkey (or -key) to be certified and no -csr, -oldcert, or -cert given for fallback public key\");\n            return 0;\n        }\n        if (opt_newkey == NULL\n            && opt_popo != OSSL_CRMF_POPO_NONE\n            && opt_popo != OSSL_CRMF_POPO_RAVERIFIED) {\n            if (opt_csr != NULL) {\n                CMP_err1(\"no -newkey option given with private key for POPO, -csr option only provides public key%s\",\n                        opt_key == NULL ? \"\" :\n                        \", and -key option superseded by -csr\");\n                return 0;\n            }\n            if (opt_key == NULL) {\n                CMP_err(\"missing -newkey (or -key) option for POPO\");\n                return 0;\n            }\n        }\n        if (opt_certout == NULL) {\n            CMP_err(\"-certout not given, nowhere to save newly enrolled certificate\");\n            return 0;\n        }\n        if (!set_name(opt_subject, OSSL_CMP_CTX_set1_subjectName, ctx, \"subject\"))\n            return 0;\n    } else {\n        const char *msg = \"option is ignored for commands other than 'ir', 'cr', and 'kur'\";\n\n        if (opt_subject != NULL) {\n            if (opt_ref == NULL && opt_cert == NULL) {\n                /* will use subject as sender unless oldcert subject is used */\n                if (!set_name(opt_subject, OSSL_CMP_CTX_set1_subjectName, ctx, \"subject\"))\n                    return 0;\n            } else {\n                CMP_warn1(\"-subject %s since sender is taken from -ref or -cert\", msg);\n            }\n        }\n        if (opt_issuer != NULL && opt_cmd != CMP_RR)\n            CMP_warn1(\"-issuer %s and 'rr'\", msg);\n        if (opt_reqexts != NULL)\n            CMP_warn1(\"-reqexts %s\", msg);\n        if (opt_san_nodefault)\n            CMP_warn1(\"-san_nodefault %s\", msg);\n        if (opt_sans != NULL)\n            CMP_warn1(\"-sans %s\", msg);\n        if (opt_policies != NULL)\n            CMP_warn1(\"-policies %s\", msg);\n        if (opt_policy_oids != NULL)\n            CMP_warn1(\"-policy_oids %s\", msg);\n        if (opt_cmd != CMP_P10CR) {\n            if (opt_implicit_confirm)\n                CMP_warn1(\"-implicit_confirm %s, and 'p10cr'\", msg);\n            if (opt_disable_confirm)\n                CMP_warn1(\"-disable_confirm %s, and 'p10cr'\", msg);\n            if (opt_certout != NULL)\n                CMP_warn1(\"-certout %s, and 'p10cr'\", msg);\n            if (opt_chainout != NULL)\n                CMP_warn1(\"-chainout %s, and 'p10cr'\", msg);\n        }\n    }\n    if (opt_cmd == CMP_KUR) {\n        char *ref_cert = opt_oldcert != NULL ? opt_oldcert : opt_cert;\n\n        if (ref_cert == NULL && opt_csr == NULL) {\n            CMP_err(\"missing -oldcert for certificate to be updated and no -csr given\");\n            return 0;\n        }\n        if (opt_subject != NULL)\n            CMP_warn2(\"given -subject '%s' overrides the subject of '%s' for KUR\",\n                      opt_subject, ref_cert != NULL ? ref_cert : opt_csr);\n    }\n    if (opt_cmd == CMP_RR) {\n        if (opt_issuer == NULL && opt_serial == NULL) {\n            if (opt_oldcert == NULL && opt_csr == NULL) {\n                CMP_err(\"missing -oldcert or -issuer and -serial for certificate to be revoked and no -csr given\");\n                return 0;\n            }\n            if (opt_oldcert != NULL && opt_csr != NULL)\n                CMP_warn(\"ignoring -csr since certificate to be revoked is given\");\n        } else {\n#define OSSL_CMP_RR_MSG \"since -issuer and -serial is given for command 'rr'\"\n            if (opt_issuer == NULL || opt_serial == NULL) {\n                CMP_err(\"Must give both -issuer and -serial options or neither\");\n                return 0;\n            }\n            if (opt_oldcert != NULL)\n                CMP_warn(\"Ignoring -oldcert \" OSSL_CMP_RR_MSG);\n            if (opt_csr != NULL)\n                CMP_warn(\"Ignoring -csr \" OSSL_CMP_RR_MSG);\n        }\n        if (opt_serial != NULL) {\n            ASN1_INTEGER *sno;\n\n            if ((sno = s2i_ASN1_INTEGER(NULL, opt_serial)) == NULL) {\n                CMP_err1(\"cannot read serial number: '%s'\", opt_serial);\n                return 0;\n            }\n            if (!OSSL_CMP_CTX_set1_serialNumber(ctx, sno)) {\n                ASN1_INTEGER_free(sno);\n                CMP_err(\"out of memory\");\n                return 0;\n            }\n            ASN1_INTEGER_free(sno);\n        }\n        if (opt_revreason > CRL_REASON_NONE)\n            (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_REVOCATION_REASON,\n                                          opt_revreason);\n    } else {\n        if (opt_serial != NULL)\n            CMP_warn(\"Ignoring -serial for command other than 'rr'\");\n    }\n    if (opt_cmd == CMP_P10CR && opt_csr == NULL) {\n        CMP_err(\"missing PKCS#10 CSR for p10cr\");\n        return 0;\n    }\n\n    if (opt_recipient == NULL && opt_srvcert == NULL && opt_issuer == NULL\n            && opt_oldcert == NULL && opt_cert == NULL)\n        CMP_warn(\"missing -recipient, -srvcert, -issuer, -oldcert or -cert; recipient will be set to \\\"NULL-DN\\\"\");\n\n    if (opt_cmd == CMP_P10CR || opt_cmd == CMP_RR || opt_cmd == CMP_GENM) {\n        const char *msg = \"option is ignored for 'p10cr', 'rr', and 'genm' commands\";\n\n        if (opt_newkeypass != NULL)\n            CMP_warn1(\"-newkeypass %s\", msg);\n        if (opt_newkey != NULL)\n            CMP_warn1(\"-newkey %s\", msg);\n        if (opt_days != 0)\n            CMP_warn1(\"-days %s\", msg);\n        if (opt_popo != OSSL_CRMF_POPO_NONE - 1)\n            CMP_warn1(\"-popo %s\", msg);\n        if (opt_out_trusted != NULL)\n            CMP_warn1(\"-out_trusted %s\", msg);\n    } else if (opt_newkey != NULL) {\n        const char *file = opt_newkey;\n        const int format = opt_keyform;\n        const char *pass = opt_newkeypass;\n        const char *desc = \"new private key for cert to be enrolled\";\n        EVP_PKEY *pkey;\n        int priv = 1;\n        BIO *bio_bak = bio_err;\n\n        bio_err = NULL; /* suppress diagnostics on first try loading key */\n        pkey = load_key_pwd(file, format, pass, engine, desc);\n        bio_err = bio_bak;\n        if (pkey == NULL) {\n            ERR_clear_error();\n            desc = opt_csr == NULL\n                ? \"fallback public key for cert to be enrolled\"\n                : \"public key for checking cert resulting from p10cr\";\n            pkey = load_pubkey(file, format, 0, pass, engine, desc);\n            priv = 0;\n        }\n        cleanse(opt_newkeypass);\n        if (pkey == NULL || !OSSL_CMP_CTX_set0_newPkey(ctx, priv, pkey)) {\n            EVP_PKEY_free(pkey);\n            return 0;\n        }\n    }\n\n    if (opt_days > 0\n            && !OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_VALIDITY_DAYS,\n                                        opt_days)) {\n        CMP_err(\"could not set requested cert validity period\");\n        return 0;\n    }\n\n    if (opt_policies != NULL && opt_policy_oids != NULL) {\n        CMP_err(\"cannot have policies both via -policies and via -policy_oids\");\n        return 0;\n    }\n\n    if (opt_csr != NULL) {\n        if (opt_cmd == CMP_GENM) {\n            CMP_warn(\"-csr option is ignored for 'genm' command\");\n        } else {\n            csr = load_csr_autofmt(opt_csr, FORMAT_UNDEF, NULL, \"PKCS#10 CSR\");\n            if (csr == NULL)\n                return 0;\n            if (!OSSL_CMP_CTX_set1_p10CSR(ctx, csr))\n                goto oom;\n        }\n    }\n    if (opt_reqexts != NULL || opt_policies != NULL) {\n        if ((exts = sk_X509_EXTENSION_new_null()) == NULL)\n            goto oom;\n        X509V3_set_ctx(&ext_ctx, NULL, NULL, csr, NULL, X509V3_CTX_REPLACE);\n        X509V3_set_nconf(&ext_ctx, conf);\n        if (opt_reqexts != NULL\n            && !X509V3_EXT_add_nconf_sk(conf, &ext_ctx, opt_reqexts, &exts)) {\n            CMP_err1(\"cannot load certificate request extension section '%s'\",\n                     opt_reqexts);\n            goto exts_err;\n        }\n        if (opt_policies != NULL\n            && !X509V3_EXT_add_nconf_sk(conf, &ext_ctx, opt_policies, &exts)) {\n            CMP_err1(\"cannot load policy cert request extension section '%s'\",\n                     opt_policies);\n            goto exts_err;\n        }\n        OSSL_CMP_CTX_set0_reqExtensions(ctx, exts);\n    }\n    X509_REQ_free(csr);\n    /* After here, must not goto oom/exts_err */\n\n    if (OSSL_CMP_CTX_reqExtensions_have_SAN(ctx) && opt_sans != NULL) {\n        CMP_err(\"cannot have Subject Alternative Names both via -reqexts and via -sans\");\n        return 0;\n    }\n    if (!set_gennames(ctx, opt_sans, \"Subject Alternative Name\"))\n        return 0;\n\n    if (opt_san_nodefault) {\n        if (opt_sans != NULL)\n            CMP_warn(\"-opt_san_nodefault has no effect when -sans is used\");\n        (void)OSSL_CMP_CTX_set_option(ctx,\n                                      OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT, 1);\n    }\n\n    if (opt_policy_oids_critical) {\n        if (opt_policy_oids == NULL)\n            CMP_warn(\"-opt_policy_oids_critical has no effect unless -policy_oids is given\");\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_POLICIES_CRITICAL, 1);\n    }\n\n    while (opt_policy_oids != NULL) {\n        ASN1_OBJECT *policy;\n        POLICYINFO *pinfo;\n        char *next = next_item(opt_policy_oids);\n\n        if ((policy = OBJ_txt2obj(opt_policy_oids, 1)) == 0) {\n            CMP_err1(\"Invalid -policy_oids arg '%s'\", opt_policy_oids);\n            return 0;\n        }\n        if (OBJ_obj2nid(policy) == NID_undef)\n            CMP_warn1(\"Unknown -policy_oids arg: %.40s\", opt_policy_oids);\n\n        if ((pinfo = POLICYINFO_new()) == NULL) {\n            ASN1_OBJECT_free(policy);\n            return 0;\n        }\n        pinfo->policyid = policy;\n\n        if (!OSSL_CMP_CTX_push0_policy(ctx, pinfo)) {\n            CMP_err1(\"cannot add policy with OID '%s'\", opt_policy_oids);\n            POLICYINFO_free(pinfo);\n            return 0;\n        }\n        opt_policy_oids = next;\n    }\n\n    if (opt_popo >= OSSL_CRMF_POPO_NONE)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_POPO_METHOD, opt_popo);\n\n    if (opt_oldcert != NULL) {\n        if (opt_cmd == CMP_GENM) {\n            CMP_warn(\"-oldcert option is ignored for 'genm' command\");\n        } else {\n            if (!setup_cert(ctx, opt_oldcert, opt_keypass,\n                            /* needed if opt_oldcert is encrypted PKCS12 file */\n                            opt_cmd == CMP_KUR ? \"certificate to be updated\" :\n                            opt_cmd == CMP_RR ? \"certificate to be revoked\" :\n                            \"reference certificate (oldcert)\",\n                            (add_X509_fn_t)OSSL_CMP_CTX_set1_oldCert))\n                return 0;\n        }\n    }\n    cleanse(opt_keypass);\n\n    return 1;\n\n oom:\n    CMP_err(\"out of memory\");\n exts_err:\n    sk_X509_EXTENSION_pop_free(exts, X509_EXTENSION_free);\n    X509_REQ_free(csr);\n    return 0;\n}\n\nstatic int add_certProfile(OSSL_CMP_CTX *ctx, const char *name)\n{\n    OSSL_CMP_ITAV *itav = NULL;\n    STACK_OF(ASN1_UTF8STRING) *sk;\n    ASN1_UTF8STRING *utf8string;\n\n    if (ctx == NULL || name == NULL)\n        return 0;\n\n    if ((sk = sk_ASN1_UTF8STRING_new_reserve(NULL, 1)) == NULL)\n        return 0;\n   if ((utf8string = ASN1_UTF8STRING_new()) == NULL)\n       goto err;\n   if (!ASN1_STRING_set(utf8string, name, (int)strlen(name))) {\n       ASN1_STRING_free(utf8string);\n       goto err;\n   }\n   /* Due to sk_ASN1_UTF8STRING_new_reserve(NULL, 1), this surely succeeds: */\n   (void)sk_ASN1_UTF8STRING_push(sk, utf8string);\n   if ((itav = OSSL_CMP_ITAV_new0_certProfile(sk)) == NULL)\n       goto err;\n   if (OSSL_CMP_CTX_push0_geninfo_ITAV(ctx, itav))\n       return 1;\n   OSSL_CMP_ITAV_free(itav);\n   return 0;\n\n err:\n    sk_ASN1_UTF8STRING_pop_free(sk, ASN1_UTF8STRING_free);\n    return 0;\n}\n\nstatic int handle_opt_geninfo(OSSL_CMP_CTX *ctx)\n{\n    ASN1_OBJECT *obj = NULL;\n    ASN1_TYPE *type = NULL;\n    long value;\n    ASN1_INTEGER *aint = NULL;\n    ASN1_UTF8STRING *text = NULL;\n    OSSL_CMP_ITAV *itav;\n    char *ptr = opt_geninfo, *oid, *end;\n\n    do {\n        while (isspace(_UC(*ptr)))\n            ptr++;\n        oid = ptr;\n        if ((ptr = strchr(oid, ':')) == NULL) {\n            CMP_err1(\"Missing ':' in -geninfo arg %.40s\", oid);\n            return 0;\n        }\n        *ptr++ = '\\0';\n        if ((obj = OBJ_txt2obj(oid, 0)) == NULL) {\n            CMP_err1(\"Invalid OID in -geninfo arg %.40s\", oid);\n            return 0;\n        }\n        if (OBJ_obj2nid(obj) == NID_undef)\n            CMP_warn1(\"Unknown OID in -geninfo arg: %.40s\", oid);\n        if ((type = ASN1_TYPE_new()) == NULL)\n            goto oom;\n\n        if (CHECK_AND_SKIP_CASE_PREFIX(ptr, \"int:\")) {\n            value = strtol(ptr, &end, 10);\n            if (end == ptr) {\n                CMP_err1(\"Cannot parse int in -geninfo arg %.40s\", ptr);\n                goto err;\n            }\n            ptr = end;\n            if (*ptr != '\\0') {\n                if (*ptr != ',') {\n                    CMP_err1(\"Missing ',' or end of -geninfo arg after int at %.40s\",\n                        ptr);\n                    goto err;\n                }\n                ptr++;\n            }\n\n            if ((aint = ASN1_INTEGER_new()) == NULL\n                    || !ASN1_INTEGER_set(aint, value))\n                goto oom;\n            ASN1_TYPE_set(type, V_ASN1_INTEGER, aint);\n            aint = NULL;\n\n        } else if (CHECK_AND_SKIP_CASE_PREFIX(ptr, \"str:\")) {\n            end = strchr(ptr, ',');\n            if (end == NULL)\n                end = ptr + strlen(ptr);\n            else\n                *end++ = '\\0';\n            if ((text = ASN1_UTF8STRING_new()) == NULL\n                    || !ASN1_STRING_set(text, ptr, -1))\n                goto oom;\n            ptr = end;\n            ASN1_TYPE_set(type, V_ASN1_UTF8STRING, text);\n            text = NULL;\n\n        } else {\n            CMP_err1(\"Missing 'int:' or 'str:' in -geninfo arg %.40s\", ptr);\n            goto err;\n        }\n\n        if ((itav = OSSL_CMP_ITAV_create(obj, type)) == NULL) {\n            CMP_err(\"Unable to create 'OSSL_CMP_ITAV' structure\");\n            goto err;\n        }\n        obj = NULL;\n        type = NULL;\n\n        if (!OSSL_CMP_CTX_push0_geninfo_ITAV(ctx, itav)) {\n            CMP_err(\"Failed to add ITAV for geninfo of the PKI message header\");\n            OSSL_CMP_ITAV_free(itav);\n            return 0;\n        }\n    } while (*ptr != '\\0');\n    return 1;\n\n oom:\n    CMP_err(\"out of memory\");\n err:\n    ASN1_OBJECT_free(obj);\n    ASN1_TYPE_free(type);\n    ASN1_INTEGER_free(aint);\n    ASN1_UTF8STRING_free(text);\n    return 0;\n}\n\n/*\n * set up the client-side OSSL_CMP_CTX based on options from config file/CLI\n * while parsing options and checking their consistency.\n * Prints reason for error to bio_err.\n * Returns 1 on success, 0 on error\n */\nstatic int setup_client_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    int ret = 0;\n    char *host = NULL, *port = NULL, *path = NULL, *used_path = opt_path;\n"}, {"id": "9423EAE4F4307665", "name": "OSSL_CMP_CTX_set_http_cb", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 833, "col": 1}, "end": {"line": 833, "col": 1}, "code": "\n/* Set argument optionally to be used by the http connect/disconnect callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, http_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the http connect/disconnect callback\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, http_cb_arg, void *, NULL)\n#endif\n\n/* Set callback function for sending CMP request and receiving response */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb, OSSL_CMP_transfer_cb_t)\n\n/* Set argument optionally to be used by the transfer callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the transfer callback.\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, transfer_cb_arg, void *, NULL)\n\n/** Set the HTTP server port to be used */\nDEFINE_OSSL_set(OSSL_CMP_CTX, serverPort, int)\n\n/* Set the HTTP path to be used on the server (e.g \"pkix/\") */\nDEFINE_OSSL_CMP_CTX_set1(serverPath, char)\n\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "8E0A80B833F766F9", "name": "OSSL_CMP_CTX_get_option", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 988, "col": 1}, "end": {"line": 1042, "col": 1}, "code": "{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "90CAC87CA2DA670D", "name": "setup_ssl_ctx", "path": "openssl/apps/cmp.c", "start": {"line": 1277, "col": 1}, "end": {"line": 1425, "col": 1}, "code": "                              ENGINE *engine)\n{\n    STACK_OF(X509) *untrusted = OSSL_CMP_CTX_get0_untrusted(ctx);\n    EVP_PKEY *pkey = NULL;\n    X509_STORE *trust_store = NULL;\n    SSL_CTX *ssl_ctx;\n    int i;\n\n    ssl_ctx = SSL_CTX_new(TLS_client_method());\n    if (ssl_ctx == NULL)\n        return NULL;\n\n    if (opt_tls_trusted != NULL) {\n        trust_store = load_trusted(opt_tls_trusted, 0, \"trusted TLS certs\");\n        if (trust_store == NULL)\n            goto err;\n        SSL_CTX_set_cert_store(ssl_ctx, trust_store);\n        SSL_CTX_set_verify(ssl_ctx, SSL_VERIFY_PEER, NULL);\n    } else {\n        CMP_warn(\"-tls_used given without -tls_trusted; will not authenticate the TLS server\");\n    }\n\n    if (opt_tls_cert != NULL && opt_tls_key != NULL) {\n        X509 *cert;\n        STACK_OF(X509) *certs = NULL;\n        int ok;\n\n        if (!load_cert_certs(opt_tls_cert, &cert, &certs, 0, opt_tls_keypass,\n                             \"TLS client certificate (optionally with chain)\",\n                             vpm))\n            /* need opt_tls_keypass if opt_tls_cert is encrypted PKCS#12 file */\n            goto err;\n\n        ok = SSL_CTX_use_certificate(ssl_ctx, cert) > 0;\n        X509_free(cert);\n\n        /*\n         * Any further certs and any untrusted certs are used for constructing\n         * the chain to be provided with the TLS client cert to the TLS server.\n         */\n        if (!ok || !SSL_CTX_set0_chain(ssl_ctx, certs)) {\n            CMP_err1(\"unable to use client TLS certificate file '%s'\",\n                     opt_tls_cert);\n            OSSL_STACK_OF_X509_free(certs);\n            goto err;\n        }\n        for (i = 0; i < sk_X509_num(untrusted); i++) {\n            cert = sk_X509_value(untrusted, i);\n            if (!SSL_CTX_add1_chain_cert(ssl_ctx, cert)) {\n                CMP_err(\"could not add untrusted cert to TLS client cert chain\");\n                goto err;\n            }\n        }\n\n        {\n            X509_VERIFY_PARAM *tls_vpm = NULL;\n            unsigned long bak_flags = 0; /* compiler warns without init */\n\n            if (trust_store != NULL) {\n                tls_vpm = X509_STORE_get0_param(trust_store);\n                bak_flags = X509_VERIFY_PARAM_get_flags(tls_vpm);\n                /* disable any cert status/revocation checking etc. */\n                X509_VERIFY_PARAM_clear_flags(tls_vpm,\n                                              ~(X509_V_FLAG_USE_CHECK_TIME\n                                                | X509_V_FLAG_NO_CHECK_TIME\n                                                | X509_V_FLAG_PARTIAL_CHAIN\n                                                | X509_V_FLAG_POLICY_CHECK));\n            }\n            CMP_debug(\"trying to build cert chain for own TLS cert\");\n            if (SSL_CTX_build_cert_chain(ssl_ctx,\n                                         SSL_BUILD_CHAIN_FLAG_UNTRUSTED |\n                                         SSL_BUILD_CHAIN_FLAG_NO_ROOT)) {\n                CMP_debug(\"success building cert chain for own TLS cert\");\n            } else {\n                OSSL_CMP_CTX_print_errors(ctx);\n                CMP_warn(\"could not build cert chain for own TLS cert\");\n            }\n            if (trust_store != NULL)\n                X509_VERIFY_PARAM_set_flags(tls_vpm, bak_flags);\n        }\n\n        /* If present we append to the list also the certs from opt_tls_extra */\n        if (opt_tls_extra != NULL) {\n            STACK_OF(X509) *tls_extra = load_certs_multifile(opt_tls_extra,\n                                                             opt_otherpass,\n                                                             \"extra certificates for TLS\",\n                                                             vpm);\n            int res = 1;\n\n            if (tls_extra == NULL)\n                goto err;\n            for (i = 0; i < sk_X509_num(tls_extra); i++) {\n                cert = sk_X509_value(tls_extra, i);\n                if (res != 0)\n                    res = SSL_CTX_add_extra_chain_cert(ssl_ctx, cert);\n                if (res == 0)\n                    X509_free(cert);\n            }\n            sk_X509_free(tls_extra);\n            if (res == 0) {\n                BIO_printf(bio_err, \"error: unable to add TLS extra certs\\n\");\n                goto err;\n            }\n        }\n\n        pkey = load_key_pwd(opt_tls_key, opt_keyform, opt_tls_keypass,\n                            engine, \"TLS client private key\");\n        cleanse(opt_tls_keypass);\n        if (pkey == NULL)\n            goto err;\n        /*\n         * verify the key matches the cert,\n         * not using SSL_CTX_check_private_key(ssl_ctx)\n         * because it gives poor and sometimes misleading diagnostics\n         */\n        if (!X509_check_private_key(SSL_CTX_get0_certificate(ssl_ctx),\n                                    pkey)) {\n            CMP_err2(\"TLS private key '%s' does not match the TLS certificate '%s'\\n\",\n                     opt_tls_key, opt_tls_cert);\n            EVP_PKEY_free(pkey);\n            pkey = NULL; /* otherwise, for some reason double free! */\n            goto err;\n        }\n        if (SSL_CTX_use_PrivateKey(ssl_ctx, pkey) <= 0) {\n            CMP_err1(\"unable to use TLS client private key '%s'\", opt_tls_key);\n            EVP_PKEY_free(pkey);\n            pkey = NULL; /* otherwise, for some reason double free! */\n            goto err;\n        }\n        EVP_PKEY_free(pkey); /* we do not need the handle any more */\n    } else {\n        CMP_warn(\"-tls_used given without -tls_key; cannot authenticate to the TLS server\");\n    }\n    if (trust_store != NULL) {\n        /*\n         * Enable and parameterize server hostname/IP address check.\n         * If we did this before checking our own TLS cert\n         * the expected hostname would mislead the check.\n         */\n        if (!truststore_set_host_etc(trust_store,\n                                     opt_tls_host != NULL ? opt_tls_host : host))\n            goto err;\n    }\n    return ssl_ctx;\n err:\n    SSL_CTX_free(ssl_ctx);\n    return NULL;\n}\n\n/*\n * set up protection aspects of OSSL_CMP_CTX based on options from config\n * file/CLI while parsing options and checking their consistency.\n * Returns 1 on success, 0 on error\n */\nstatic int setup_protection_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    if (!opt_unprotected_requests && opt_secret == NULL && opt_key == NULL) {\n        CMP_err(\"must give -key or -secret unless -unprotected_requests is used\");\n        return 0;\n    }\n\n    if (opt_ref == NULL && opt_cert == NULL && opt_subject == NULL) {\n        /* cert or subject should determine the sender */\n        CMP_err(\"must give -ref if no -cert and no -subject given\");\n        return 0;\n    }\n    if (opt_secret == NULL && ((opt_cert == NULL) != (opt_key == NULL))) {\n        CMP_err(\"must give both -cert and -key options or neither\");\n        return 0;\n    }\n    if (opt_secret != NULL) {\n        char *pass_string = get_passwd(opt_secret, \"PBMAC\");\n        int res;\n\n        if (pass_string != NULL) {\n            cleanse(opt_secret);\n            res = OSSL_CMP_CTX_set1_secretValue(ctx,\n                                                (unsigned char *)pass_string,\n                                                strlen(pass_string));\n            clear_free(pass_string);\n            if (res == 0)\n                return 0;\n        }\n        if (opt_cert != NULL || opt_key != NULL)\n            CMP_warn(\"-cert and -key not used for protection since -secret is given\");\n    }\n    if (opt_ref != NULL\n            && !OSSL_CMP_CTX_set1_referenceValue(ctx, (unsigned char *)opt_ref,\n                                                 strlen(opt_ref)))\n        return 0;\n\n    if (opt_key != NULL) {\n        EVP_PKEY *pkey = load_key_pwd(opt_key, opt_keyform, opt_keypass, engine,\n                                      \"private key for CMP client certificate\");\n\n        if (pkey == NULL || !OSSL_CMP_CTX_set1_pkey(ctx, pkey)) {\n            EVP_PKEY_free(pkey);\n            return 0;\n        }\n        EVP_PKEY_free(pkey);\n    }\n    if (opt_secret == NULL && opt_srvcert == NULL && opt_trusted == NULL)\n        CMP_warn(\"will not authenticate server due to missing -secret, -trusted, or -srvcert\");\n\n    if (opt_cert != NULL) {\n        X509 *cert;\n        STACK_OF(X509) *certs = NULL;\n        X509_STORE *own_trusted = NULL;\n        int ok;\n\n        if (!load_cert_certs(opt_cert, &cert, &certs, 0, opt_keypass,\n                             \"CMP client certificate (optionally with chain)\",\n                             vpm))\n            /* opt_keypass is needed if opt_cert is an encrypted PKCS#12 file */\n            return 0;\n        ok = OSSL_CMP_CTX_set1_cert(ctx, cert);\n        X509_free(cert);\n        if (!ok) {\n            CMP_err(\"out of memory\");\n        } else {\n            if (opt_own_trusted != NULL) {\n                own_trusted = load_trusted(opt_own_trusted, 0,\n                                           \"trusted certs for verifying own CMP signer cert\");\n                ok = own_trusted != NULL;\n            }\n            ok = ok && OSSL_CMP_CTX_build_cert_chain(ctx, own_trusted, certs);\n        }\n        X509_STORE_free(own_trusted);\n        OSSL_STACK_OF_X509_free(certs);\n        if (!ok)\n            return 0;\n    } else if (opt_own_trusted != NULL) {\n        CMP_warn(\"-own_trusted option is ignored without -cert\");\n    }\n\n    if (!setup_certs(opt_extracerts, \"extra certificates for CMP\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_extraCertsOut))\n        return 0;\n    cleanse(opt_otherpass);\n\n    if (opt_unprotected_requests)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_SEND, 1);\n\n    if (opt_digest != NULL) {\n        int digest = OBJ_ln2nid(opt_digest);\n\n        if (digest == NID_undef) {\n            CMP_err1(\"digest algorithm name not recognized: '%s'\", opt_digest);\n            return 0;\n        }\n        if (!OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_DIGEST_ALGNID, digest)\n            || !OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_OWF_ALGNID, digest)) {\n            CMP_err1(\"digest algorithm name not supported: '%s'\", opt_digest);\n            return 0;\n        }\n    }\n\n    if (opt_mac != NULL) {\n        int mac = OBJ_ln2nid(opt_mac);\n\n        if (mac == NID_undef) {\n            CMP_err1(\"MAC algorithm name not recognized: '%s'\", opt_mac);\n            return 0;\n        }\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_MAC_ALGNID, mac);\n    }\n    return 1;\n}\n\n/*\n * Set up IR/CR/P10CR/KUR/CertConf/RR/GENM specific parts of the OSSL_CMP_CTX\n * based on options from CLI and/or config file.\n * Returns 1 on success, 0 on error\n */\nstatic int setup_request_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    X509_REQ *csr = NULL;\n    X509_EXTENSIONS *exts = NULL;\n    X509V3_CTX ext_ctx;\n\n    if (opt_subject == NULL\n            && opt_csr == NULL && opt_oldcert == NULL && opt_cert == NULL\n            && opt_cmd != CMP_RR && opt_cmd != CMP_GENM)\n        CMP_warn(\"no -subject given; no -csr or -oldcert or -cert available for fallback\");\n\n    if (!set_name(opt_issuer, OSSL_CMP_CTX_set1_issuer, ctx, \"issuer\"))\n        return 0;\n    if (opt_cmd == CMP_IR || opt_cmd == CMP_CR || opt_cmd == CMP_KUR) {\n        if (opt_newkey == NULL\n            && opt_key == NULL && opt_csr == NULL && opt_oldcert == NULL) {\n            CMP_err(\"missing -newkey (or -key) to be certified and no -csr, -oldcert, or -cert given for fallback public key\");\n            return 0;\n        }\n        if (opt_newkey == NULL\n            && opt_popo != OSSL_CRMF_POPO_NONE\n            && opt_popo != OSSL_CRMF_POPO_RAVERIFIED) {\n            if (opt_csr != NULL) {\n                CMP_err1(\"no -newkey option given with private key for POPO, -csr option only provides public key%s\",\n                        opt_key == NULL ? \"\" :\n                        \", and -key option superseded by -csr\");\n                return 0;\n            }\n            if (opt_key == NULL) {\n                CMP_err(\"missing -newkey (or -key) option for POPO\");\n                return 0;\n            }\n        }\n        if (opt_certout == NULL) {\n            CMP_err(\"-certout not given, nowhere to save newly enrolled certificate\");\n            return 0;\n        }\n        if (!set_name(opt_subject, OSSL_CMP_CTX_set1_subjectName, ctx, \"subject\"))\n            return 0;\n    } else {\n        const char *msg = \"option is ignored for commands other than 'ir', 'cr', and 'kur'\";\n\n        if (opt_subject != NULL) {\n            if (opt_ref == NULL && opt_cert == NULL) {\n                /* will use subject as sender unless oldcert subject is used */\n                if (!set_name(opt_subject, OSSL_CMP_CTX_set1_subjectName, ctx, \"subject\"))\n                    return 0;\n            } else {\n                CMP_warn1(\"-subject %s since sender is taken from -ref or -cert\", msg);\n            }\n        }\n        if (opt_issuer != NULL && opt_cmd != CMP_RR)\n            CMP_warn1(\"-issuer %s and 'rr'\", msg);\n        if (opt_reqexts != NULL)\n            CMP_warn1(\"-reqexts %s\", msg);\n        if (opt_san_nodefault)\n            CMP_warn1(\"-san_nodefault %s\", msg);\n        if (opt_sans != NULL)\n            CMP_warn1(\"-sans %s\", msg);\n        if (opt_policies != NULL)\n            CMP_warn1(\"-policies %s\", msg);\n        if (opt_policy_oids != NULL)\n            CMP_warn1(\"-policy_oids %s\", msg);\n        if (opt_cmd != CMP_P10CR) {\n            if (opt_implicit_confirm)\n                CMP_warn1(\"-implicit_confirm %s, and 'p10cr'\", msg);\n            if (opt_disable_confirm)\n                CMP_warn1(\"-disable_confirm %s, and 'p10cr'\", msg);\n            if (opt_certout != NULL)\n                CMP_warn1(\"-certout %s, and 'p10cr'\", msg);\n            if (opt_chainout != NULL)\n                CMP_warn1(\"-chainout %s, and 'p10cr'\", msg);\n        }\n    }\n    if (opt_cmd == CMP_KUR) {\n        char *ref_cert = opt_oldcert != NULL ? opt_oldcert : opt_cert;\n\n        if (ref_cert == NULL && opt_csr == NULL) {\n            CMP_err(\"missing -oldcert for certificate to be updated and no -csr given\");\n            return 0;\n        }\n        if (opt_subject != NULL)\n            CMP_warn2(\"given -subject '%s' overrides the subject of '%s' for KUR\",\n                      opt_subject, ref_cert != NULL ? ref_cert : opt_csr);\n    }\n    if (opt_cmd == CMP_RR) {\n        if (opt_issuer == NULL && opt_serial == NULL) {\n            if (opt_oldcert == NULL && opt_csr == NULL) {\n                CMP_err(\"missing -oldcert or -issuer and -serial for certificate to be revoked and no -csr given\");\n                return 0;\n            }\n            if (opt_oldcert != NULL && opt_csr != NULL)\n                CMP_warn(\"ignoring -csr since certificate to be revoked is given\");\n        } else {\n#define OSSL_CMP_RR_MSG \"since -issuer and -serial is given for command 'rr'\"\n            if (opt_issuer == NULL || opt_serial == NULL) {\n                CMP_err(\"Must give both -issuer and -serial options or neither\");\n                return 0;\n            }\n            if (opt_oldcert != NULL)\n                CMP_warn(\"Ignoring -oldcert \" OSSL_CMP_RR_MSG);\n            if (opt_csr != NULL)\n                CMP_warn(\"Ignoring -csr \" OSSL_CMP_RR_MSG);\n        }\n        if (opt_serial != NULL) {\n            ASN1_INTEGER *sno;\n\n            if ((sno = s2i_ASN1_INTEGER(NULL, opt_serial)) == NULL) {\n                CMP_err1(\"cannot read serial number: '%s'\", opt_serial);\n                return 0;\n            }\n            if (!OSSL_CMP_CTX_set1_serialNumber(ctx, sno)) {\n                ASN1_INTEGER_free(sno);\n                CMP_err(\"out of memory\");\n                return 0;\n            }\n            ASN1_INTEGER_free(sno);\n        }\n        if (opt_revreason > CRL_REASON_NONE)\n            (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_REVOCATION_REASON,\n                                          opt_revreason);\n    } else {\n        if (opt_serial != NULL)\n            CMP_warn(\"Ignoring -serial for command other than 'rr'\");\n    }\n    if (opt_cmd == CMP_P10CR && opt_csr == NULL) {\n        CMP_err(\"missing PKCS#10 CSR for p10cr\");\n        return 0;\n    }\n\n    if (opt_recipient == NULL && opt_srvcert == NULL && opt_issuer == NULL\n            && opt_oldcert == NULL && opt_cert == NULL)\n        CMP_warn(\"missing -recipient, -srvcert, -issuer, -oldcert or -cert; recipient will be set to \\\"NULL-DN\\\"\");\n\n    if (opt_cmd == CMP_P10CR || opt_cmd == CMP_RR || opt_cmd == CMP_GENM) {\n        const char *msg = \"option is ignored for 'p10cr', 'rr', and 'genm' commands\";\n\n        if (opt_newkeypass != NULL)\n            CMP_warn1(\"-newkeypass %s\", msg);\n        if (opt_newkey != NULL)\n            CMP_warn1(\"-newkey %s\", msg);\n        if (opt_days != 0)\n            CMP_warn1(\"-days %s\", msg);\n        if (opt_popo != OSSL_CRMF_POPO_NONE - 1)\n            CMP_warn1(\"-popo %s\", msg);\n        if (opt_out_trusted != NULL)\n            CMP_warn1(\"-out_trusted %s\", msg);\n    } else if (opt_newkey != NULL) {\n        const char *file = opt_newkey;\n        const int format = opt_keyform;\n        const char *pass = opt_newkeypass;\n        const char *desc = \"new private key for cert to be enrolled\";\n        EVP_PKEY *pkey;\n        int priv = 1;\n        BIO *bio_bak = bio_err;\n\n        bio_err = NULL; /* suppress diagnostics on first try loading key */\n        pkey = load_key_pwd(file, format, pass, engine, desc);\n        bio_err = bio_bak;\n        if (pkey == NULL) {\n            ERR_clear_error();\n            desc = opt_csr == NULL\n                ? \"fallback public key for cert to be enrolled\"\n                : \"public key for checking cert resulting from p10cr\";\n            pkey = load_pubkey(file, format, 0, pass, engine, desc);\n            priv = 0;\n        }\n        cleanse(opt_newkeypass);\n        if (pkey == NULL || !OSSL_CMP_CTX_set0_newPkey(ctx, priv, pkey)) {\n            EVP_PKEY_free(pkey);\n            return 0;\n        }\n    }\n\n    if (opt_days > 0\n            && !OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_VALIDITY_DAYS,\n                                        opt_days)) {\n        CMP_err(\"could not set requested cert validity period\");\n        return 0;\n    }\n\n    if (opt_policies != NULL && opt_policy_oids != NULL) {\n        CMP_err(\"cannot have policies both via -policies and via -policy_oids\");\n        return 0;\n    }\n\n    if (opt_csr != NULL) {\n        if (opt_cmd == CMP_GENM) {\n            CMP_warn(\"-csr option is ignored for 'genm' command\");\n        } else {\n            csr = load_csr_autofmt(opt_csr, FORMAT_UNDEF, NULL, \"PKCS#10 CSR\");\n            if (csr == NULL)\n                return 0;\n            if (!OSSL_CMP_CTX_set1_p10CSR(ctx, csr))\n                goto oom;\n        }\n    }\n    if (opt_reqexts != NULL || opt_policies != NULL) {\n        if ((exts = sk_X509_EXTENSION_new_null()) == NULL)\n            goto oom;\n        X509V3_set_ctx(&ext_ctx, NULL, NULL, csr, NULL, X509V3_CTX_REPLACE);\n        X509V3_set_nconf(&ext_ctx, conf);\n        if (opt_reqexts != NULL\n            && !X509V3_EXT_add_nconf_sk(conf, &ext_ctx, opt_reqexts, &exts)) {\n            CMP_err1(\"cannot load certificate request extension section '%s'\",\n                     opt_reqexts);\n            goto exts_err;\n        }\n        if (opt_policies != NULL\n            && !X509V3_EXT_add_nconf_sk(conf, &ext_ctx, opt_policies, &exts)) {\n            CMP_err1(\"cannot load policy cert request extension section '%s'\",\n                     opt_policies);\n            goto exts_err;\n        }\n        OSSL_CMP_CTX_set0_reqExtensions(ctx, exts);\n    }\n    X509_REQ_free(csr);\n    /* After here, must not goto oom/exts_err */\n\n    if (OSSL_CMP_CTX_reqExtensions_have_SAN(ctx) && opt_sans != NULL) {\n        CMP_err(\"cannot have Subject Alternative Names both via -reqexts and via -sans\");\n        return 0;\n    }\n    if (!set_gennames(ctx, opt_sans, \"Subject Alternative Name\"))\n        return 0;\n\n    if (opt_san_nodefault) {\n        if (opt_sans != NULL)\n            CMP_warn(\"-opt_san_nodefault has no effect when -sans is used\");\n        (void)OSSL_CMP_CTX_set_option(ctx,\n                                      OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT, 1);\n    }\n\n    if (opt_policy_oids_critical) {\n        if (opt_policy_oids == NULL)\n            CMP_warn(\"-opt_policy_oids_critical has no effect unless -policy_oids is given\");\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_POLICIES_CRITICAL, 1);\n    }\n\n    while (opt_policy_oids != NULL) {\n        ASN1_OBJECT *policy;\n        POLICYINFO *pinfo;\n        char *next = next_item(opt_policy_oids);\n\n        if ((policy = OBJ_txt2obj(opt_policy_oids, 1)) == 0) {\n            CMP_err1(\"Invalid -policy_oids arg '%s'\", opt_policy_oids);\n            return 0;\n        }\n        if (OBJ_obj2nid(policy) == NID_undef)\n            CMP_warn1(\"Unknown -policy_oids arg: %.40s\", opt_policy_oids);\n\n        if ((pinfo = POLICYINFO_new()) == NULL) {\n            ASN1_OBJECT_free(policy);\n            return 0;\n        }\n        pinfo->policyid = policy;\n\n        if (!OSSL_CMP_CTX_push0_policy(ctx, pinfo)) {\n            CMP_err1(\"cannot add policy with OID '%s'\", opt_policy_oids);\n            POLICYINFO_free(pinfo);\n            return 0;\n        }\n        opt_policy_oids = next;\n    }\n\n    if (opt_popo >= OSSL_CRMF_POPO_NONE)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_POPO_METHOD, opt_popo);\n\n    if (opt_oldcert != NULL) {\n        if (opt_cmd == CMP_GENM) {\n            CMP_warn(\"-oldcert option is ignored for 'genm' command\");\n        } else {\n            if (!setup_cert(ctx, opt_oldcert, opt_keypass,\n                            /* needed if opt_oldcert is encrypted PKCS12 file */\n                            opt_cmd == CMP_KUR ? \"certificate to be updated\" :\n                            opt_cmd == CMP_RR ? \"certificate to be revoked\" :\n                            \"reference certificate (oldcert)\",\n                            (add_X509_fn_t)OSSL_CMP_CTX_set1_oldCert))\n                return 0;\n        }\n    }\n    cleanse(opt_keypass);\n\n    return 1;\n\n oom:\n    CMP_err(\"out of memory\");\n exts_err:\n    sk_X509_EXTENSION_pop_free(exts, X509_EXTENSION_free);\n    X509_REQ_free(csr);\n    return 0;\n}\n\nstatic int add_certProfile(OSSL_CMP_CTX *ctx, const char *name)\n{\n    OSSL_CMP_ITAV *itav = NULL;\n    STACK_OF(ASN1_UTF8STRING) *sk;\n    ASN1_UTF8STRING *utf8string;\n\n    if (ctx == NULL || name == NULL)\n        return 0;\n\n    if ((sk = sk_ASN1_UTF8STRING_new_reserve(NULL, 1)) == NULL)\n        return 0;\n   if ((utf8string = ASN1_UTF8STRING_new()) == NULL)\n       goto err;\n   if (!ASN1_STRING_set(utf8string, name, (int)strlen(name))) {\n       ASN1_STRING_free(utf8string);\n       goto err;\n   }\n   /* Due to sk_ASN1_UTF8STRING_new_reserve(NULL, 1), this surely succeeds: */\n   (void)sk_ASN1_UTF8STRING_push(sk, utf8string);\n   if ((itav = OSSL_CMP_ITAV_new0_certProfile(sk)) == NULL)\n       goto err;\n   if (OSSL_CMP_CTX_push0_geninfo_ITAV(ctx, itav))\n       return 1;\n   OSSL_CMP_ITAV_free(itav);\n   return 0;\n\n err:\n    sk_ASN1_UTF8STRING_pop_free(sk, ASN1_UTF8STRING_free);\n    return 0;\n}\n\nstatic int handle_opt_geninfo(OSSL_CMP_CTX *ctx)\n{\n    ASN1_OBJECT *obj = NULL;\n    ASN1_TYPE *type = NULL;\n    long value;\n    ASN1_INTEGER *aint = NULL;\n    ASN1_UTF8STRING *text = NULL;\n    OSSL_CMP_ITAV *itav;\n    char *ptr = opt_geninfo, *oid, *end;\n\n    do {\n        while (isspace(_UC(*ptr)))\n            ptr++;\n        oid = ptr;\n        if ((ptr = strchr(oid, ':')) == NULL) {\n            CMP_err1(\"Missing ':' in -geninfo arg %.40s\", oid);\n            return 0;\n        }\n        *ptr++ = '\\0';\n        if ((obj = OBJ_txt2obj(oid, 0)) == NULL) {\n            CMP_err1(\"Invalid OID in -geninfo arg %.40s\", oid);\n            return 0;\n        }\n        if (OBJ_obj2nid(obj) == NID_undef)\n            CMP_warn1(\"Unknown OID in -geninfo arg: %.40s\", oid);\n        if ((type = ASN1_TYPE_new()) == NULL)\n            goto oom;\n\n        if (CHECK_AND_SKIP_CASE_PREFIX(ptr, \"int:\")) {\n            value = strtol(ptr, &end, 10);\n            if (end == ptr) {\n                CMP_err1(\"Cannot parse int in -geninfo arg %.40s\", ptr);\n                goto err;\n            }\n            ptr = end;\n            if (*ptr != '\\0') {\n                if (*ptr != ',') {\n                    CMP_err1(\"Missing ',' or end of -geninfo arg after int at %.40s\",\n                        ptr);\n                    goto err;\n                }\n                ptr++;\n            }\n\n            if ((aint = ASN1_INTEGER_new()) == NULL\n                    || !ASN1_INTEGER_set(aint, value))\n                goto oom;\n            ASN1_TYPE_set(type, V_ASN1_INTEGER, aint);\n            aint = NULL;\n\n        } else if (CHECK_AND_SKIP_CASE_PREFIX(ptr, \"str:\")) {\n            end = strchr(ptr, ',');\n            if (end == NULL)\n                end = ptr + strlen(ptr);\n            else\n                *end++ = '\\0';\n            if ((text = ASN1_UTF8STRING_new()) == NULL\n                    || !ASN1_STRING_set(text, ptr, -1))\n                goto oom;\n            ptr = end;\n            ASN1_TYPE_set(type, V_ASN1_UTF8STRING, text);\n            text = NULL;\n\n        } else {\n            CMP_err1(\"Missing 'int:' or 'str:' in -geninfo arg %.40s\", ptr);\n            goto err;\n        }\n\n        if ((itav = OSSL_CMP_ITAV_create(obj, type)) == NULL) {\n            CMP_err(\"Unable to create 'OSSL_CMP_ITAV' structure\");\n            goto err;\n        }\n        obj = NULL;\n        type = NULL;\n\n        if (!OSSL_CMP_CTX_push0_geninfo_ITAV(ctx, itav)) {\n            CMP_err(\"Failed to add ITAV for geninfo of the PKI message header\");\n            OSSL_CMP_ITAV_free(itav);\n            return 0;\n        }\n    } while (*ptr != '\\0');\n    return 1;\n\n oom:\n    CMP_err(\"out of memory\");\n err:\n    ASN1_OBJECT_free(obj);\n    ASN1_TYPE_free(type);\n    ASN1_INTEGER_free(aint);\n    ASN1_UTF8STRING_free(text);\n    return 0;\n}\n\n/*\n * set up the client-side OSSL_CMP_CTX based on options from config file/CLI\n * while parsing options and checking their consistency.\n * Prints reason for error to bio_err.\n * Returns 1 on success, 0 on error\n */\nstatic int setup_client_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    int ret = 0;\n    char *host = NULL, *port = NULL, *path = NULL, *used_path = opt_path;\n"}, {"id": "61336E16898B7812", "name": "OSSL_CMP_CTX_set_http_cb_arg", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 836, "col": 1}, "end": {"line": 836, "col": 1}, "code": "\n/*\n * Get argument optionally to be used by the http connect/disconnect callback\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, http_cb_arg, void *, NULL)\n#endif\n\n/* Set callback function for sending CMP request and receiving response */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb, OSSL_CMP_transfer_cb_t)\n\n/* Set argument optionally to be used by the transfer callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the transfer callback.\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, transfer_cb_arg, void *, NULL)\n\n/** Set the HTTP server port to be used */\nDEFINE_OSSL_set(OSSL_CMP_CTX, serverPort, int)\n\n/* Set the HTTP path to be used on the server (e.g \"pkix/\") */\nDEFINE_OSSL_CMP_CTX_set1(serverPath, char)\n\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "20E426DACCDA51FC", "name": "OSSL_CMP_CTX_get_http_cb_arg", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 842, "col": 44}, "end": {"line": 842, "col": 1}, "code": "#endif\n\n/* Set callback function for sending CMP request and receiving response */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb, OSSL_CMP_transfer_cb_t)\n\n/* Set argument optionally to be used by the transfer callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the transfer callback.\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, transfer_cb_arg, void *, NULL)\n\n/** Set the HTTP server port to be used */\nDEFINE_OSSL_set(OSSL_CMP_CTX, serverPort, int)\n\n/* Set the HTTP path to be used on the server (e.g \"pkix/\") */\nDEFINE_OSSL_CMP_CTX_set1(serverPath, char)\n\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "F7FDB3E2C183C1F1", "name": "APP_HTTP_TLS_INFO_free", "path": "openssl/apps/lib/apps.c", "start": {"line": 2591, "col": 1}, "end": {"line": 2597, "col": 1}, "code": "{\n    if (info != NULL) {\n        SSL_CTX_free(info->ssl_ctx);\n        OPENSSL_free(info);\n    }\n}\n\nASN1_VALUE *app_http_get_asn1(const char *url, const char *proxy,\n                              const char *no_proxy, SSL_CTX *ssl_ctx,\n                              const STACK_OF(CONF_VALUE) *headers,\n                              long timeout, const char *expected_content_type,\n                              const ASN1_ITEM *it)\n{\n    APP_HTTP_TLS_INFO info;\n    char *server;\n    char *port;\n    int use_ssl;\n    BIO *mem;\n    ASN1_VALUE *resp = NULL;\n\n    if (url == NULL || it == NULL) {\n        ERR_raise(ERR_LIB_HTTP, ERR_R_PASSED_NULL_PARAMETER);\n        return NULL;\n    }\n\n    if (!OSSL_HTTP_parse_url(url, &use_ssl, NULL /* userinfo */, &server, &port,\n                             NULL /* port_num, */, NULL, NULL, NULL))\n        return NULL;\n    if (use_ssl && ssl_ctx == NULL) {\n        ERR_raise_data(ERR_LIB_HTTP, ERR_R_PASSED_NULL_PARAMETER,\n                       \"missing SSL_CTX\");\n        goto end;\n    }\n    if (!use_ssl && ssl_ctx != NULL) {\n        ERR_raise_data(ERR_LIB_HTTP, ERR_R_PASSED_INVALID_ARGUMENT,\n                       \"SSL_CTX given but use_ssl == 0\");\n        goto end;\n    }\n\n    info.server = server;\n    info.port = port;\n    info.use_proxy = /* workaround for callback design flaw, see #17088 */\n        OSSL_HTTP_adapt_proxy(proxy, no_proxy, server, use_ssl) != NULL;\n    info.timeout = timeout;\n    info.ssl_ctx = ssl_ctx;\n    mem = OSSL_HTTP_get(url, proxy, no_proxy, NULL /* bio */, NULL /* rbio */,\n                        app_http_tls_cb, &info, 0 /* buf_size */, headers,\n                        expected_content_type, 1 /* expect_asn1 */,\n                        OSSL_HTTP_DEFAULT_MAX_RESP_LEN, timeout);\n    resp = ASN1_item_d2i_bio(it, mem, NULL);\n    BIO_free(mem);\n\n end:\n    OPENSSL_free(server);\n    OPENSSL_free(port);\n    return resp;\n\n}\n\nASN1_VALUE *app_http_post_asn1(const char *host, const char *port,\n                               const char *path, const char *proxy,\n                               const char *no_proxy, SSL_CTX *ssl_ctx,\n                               const STACK_OF(CONF_VALUE) *headers,\n                               const char *content_type,\n                               ASN1_VALUE *req, const ASN1_ITEM *req_it,\n                               const char *expected_content_type,\n                               long timeout, const ASN1_ITEM *rsp_it)\n{\n    int use_ssl = ssl_ctx != NULL;\n    APP_HTTP_TLS_INFO info;\n    BIO *rsp, *req_mem = ASN1_item_i2d_mem_bio(req_it, req);\n    ASN1_VALUE *res;\n\n    if (req_mem == NULL)\n        return NULL;\n\n    info.server = host;\n    info.port = port;\n    info.use_proxy = /* workaround for callback design flaw, see #17088 */\n        OSSL_HTTP_adapt_proxy(proxy, no_proxy, host, use_ssl) != NULL;\n    info.timeout = timeout;\n    info.ssl_ctx = ssl_ctx;\n    rsp = OSSL_HTTP_transfer(NULL, host, port, path, use_ssl,\n                             proxy, no_proxy, NULL /* bio */, NULL /* rbio */,\n                             app_http_tls_cb, &info,\n                             0 /* buf_size */, headers, content_type, req_mem,\n                             expected_content_type, 1 /* expect_asn1 */,\n                             OSSL_HTTP_DEFAULT_MAX_RESP_LEN, timeout,\n                             0 /* keep_alive */);\n    BIO_free(req_mem);\n    res = ASN1_item_d2i_bio(rsp_it, rsp, NULL);\n    BIO_free(rsp);\n    return res;\n}\n\n\n/*\n * Platform-specific sections\n */\n"}, {"id": "4F44CC031BE4EBFE", "name": "OSSL_CMP_CTX_set_option", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 873, "col": 1}, "end": {"line": 982, "col": 1}, "code": "{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "4416BD8C05D40191", "name": "setup_verification_ctx", "path": "openssl/apps/cmp.c", "start": {"line": 1208, "col": 1}, "end": {"line": 1270, "col": 1}, "code": "{\n    if (!setup_certs(opt_untrusted, \"untrusted certificates\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_untrusted))\n        return 0;\n\n    if (opt_srvcert != NULL || opt_trusted != NULL) {\n        if (opt_srvcert != NULL) {\n            if (opt_trusted != NULL) {\n                CMP_warn(\"-trusted option is ignored since -srvcert option is present\");\n                opt_trusted = NULL;\n            }\n            if (opt_recipient != NULL) {\n                CMP_warn(\"-recipient option is ignored since -srvcert option is present\");\n                opt_recipient = NULL;\n            }\n            if (!setup_cert(ctx, opt_srvcert, opt_otherpass,\n                            \"directly trusted CMP server certificate\",\n                            (add_X509_fn_t)OSSL_CMP_CTX_set1_srvCert))\n                return 0;\n        }\n        if (opt_trusted != NULL) {\n            X509_STORE *ts;\n\n            /*\n             * the 0 arg below clears any expected host/ip/email address;\n             * opt_expect_sender is used instead\n             */\n            ts = load_trusted(opt_trusted, 0, \"certs trusted by client\");\n\n            if (ts == NULL || !OSSL_CMP_CTX_set0_trusted(ctx, ts)) {\n                X509_STORE_free(ts);\n                return 0;\n            }\n        }\n    }\n\n    if (opt_unprotected_errors)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_ERRORS, 1);\n\n    if (opt_out_trusted != NULL) { /* for use in OSSL_CMP_certConf_cb() */\n        X509_VERIFY_PARAM *out_vpm = NULL;\n        X509_STORE *out_trusted =\n            load_trusted(opt_out_trusted, 1,\n                         \"trusted certs for verifying newly enrolled cert\");\n\n        if (out_trusted == NULL)\n            return 0;\n        /* ignore any -attime here, new certs are current anyway */\n        out_vpm = X509_STORE_get0_param(out_trusted);\n        X509_VERIFY_PARAM_clear_flags(out_vpm, X509_V_FLAG_USE_CHECK_TIME);\n\n        (void)OSSL_CMP_CTX_set_certConf_cb_arg(ctx, out_trusted);\n    }\n\n    if (opt_disable_confirm)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_DISABLE_CONFIRM, 1);\n\n    if (opt_implicit_confirm)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_IMPLICIT_CONFIRM, 1);\n\n    return 1;\n}\n\n"}, {"id": "115D275E039C80B1", "name": "OBJ_sn2nid", "path": "openssl/crypto/objects/obj_dat.c", "start": {"line": 651, "col": 1}, "end": {"line": 676, "col": 1}, "code": "{\n    ASN1_OBJECT o;\n    const ASN1_OBJECT *oo = &o;\n    ADDED_OBJ ad, *adp;\n    const unsigned int *op;\n    int nid = NID_undef;\n\n    o.sn = s;\n    op = OBJ_bsearch_sn(&oo, sn_objs, NUM_SN);\n    if (op != NULL)\n        return nid_objs[*op].nid;\n    if (!ossl_obj_read_lock(1)) {\n        ERR_raise(ERR_LIB_OBJ, ERR_R_UNABLE_TO_GET_READ_LOCK);\n        return NID_undef;\n    }\n    if (added != NULL) {\n        ad.type = ADDED_SNAME;\n        ad.obj = &o;\n        adp = lh_ADDED_OBJ_retrieve(added, &ad);\n        if (adp != NULL)\n            nid = adp->obj->nid;\n    }\n    ossl_obj_unlock(1);\n    return nid;\n}\n\nconst void *OBJ_bsearch_(const void *key, const void *base, int num, int size,\n                         int (*cmp) (const void *, const void *))\n{\n    return OBJ_bsearch_ex_(key, base, num, size, cmp, 0);\n}\n\nconst void *OBJ_bsearch_ex_(const void *key, const void *base, int num,\n                            int size,\n                            int (*cmp) (const void *, const void *),\n                            int flags)\n{\n    const char *p = ossl_bsearch(key, base, num, size, cmp, flags);\n\n#ifdef CHARSET_EBCDIC\n    /*\n     * THIS IS A KLUDGE - Because the *_obj is sorted in ASCII order, and I\n     * don't have perl (yet), we revert to a *LINEAR* search when the object\n     * wasn't found in the binary search.\n     */\n    if (p == NULL) {\n        const char *base_ = base;\n        int l, h, i = 0, c = 0;\n        char *p1;\n\n        for (i = 0; i < num; ++i) {\n            p1 = &(base_[i * size]);\n            c = (*cmp) (key, p1);\n            if (c == 0\n                || (c < 0 && (flags & OBJ_BSEARCH_VALUE_ON_NOMATCH)))\n                return p1;\n        }\n    }\n#endif\n    return p;\n}\n\n/*\n * Parse a BIO sink to create some extra oid's objects.\n * Line format:<OID:isdigit or '.']><isspace><SN><isspace><LN>\n */\nint OBJ_create_objects(BIO *in)\n{\n    char buf[512];\n    int i, num = 0;\n    char *o, *s, *l = NULL;\n\n    for (;;) {\n        s = o = NULL;\n        i = BIO_gets(in, buf, 512);\n        if (i <= 0)\n            return num;\n        buf[i - 1] = '\\0';\n        if (!ossl_isalnum(buf[0]))\n            return num;\n        o = s = buf;\n        while (ossl_isdigit(*s) || *s == '.')\n            s++;\n        if (*s != '\\0') {\n            *(s++) = '\\0';\n            while (ossl_isspace(*s))\n                s++;\n            if (*s == '\\0') {\n                s = NULL;\n            } else {\n                l = s;\n                while (*l != '\\0' && !ossl_isspace(*l))\n                    l++;\n                if (*l != '\\0') {\n                    *(l++) = '\\0';\n                    while (ossl_isspace(*l))\n                        l++;\n                    if (*l == '\\0') {\n                        l = NULL;\n                    }\n                } else {\n                    l = NULL;\n                }\n            }\n        } else {\n            s = NULL;\n        }\n        if (*o == '\\0')\n            return num;\n        if (!OBJ_create(o, s, l))\n            return num;\n        num++;\n    }\n}\n\nint OBJ_create(const char *oid, const char *sn, const char *ln)\n{\n    ASN1_OBJECT *tmpoid = NULL;\n    int ok = 0;\n\n    /* With no arguments at all, nothing can be done */\n    if (oid == NULL && sn == NULL && ln == NULL) {\n        ERR_raise(ERR_LIB_OBJ, ERR_R_PASSED_INVALID_ARGUMENT);\n        return 0;\n    }\n\n    /* Check to see if short or long name already present */\n    if ((sn != NULL && OBJ_sn2nid(sn) != NID_undef)\n            || (ln != NULL && OBJ_ln2nid(ln) != NID_undef)) {\n        ERR_raise(ERR_LIB_OBJ, OBJ_R_OID_EXISTS);\n        return 0;\n    }\n\n    if (oid != NULL) {\n        /* Convert numerical OID string to an ASN1_OBJECT structure */\n        tmpoid = OBJ_txt2obj(oid, 1);\n        if (tmpoid == NULL)\n            return 0;\n    } else {\n        /* Create a no-OID ASN1_OBJECT */\n        tmpoid = ASN1_OBJECT_new();\n        if (tmpoid == NULL) {\n            ERR_raise(ERR_LIB_OBJ, ERR_R_ASN1_LIB);\n            return 0;\n        }\n    }\n\n    if (!ossl_obj_write_lock(1)) {\n        ERR_raise(ERR_LIB_OBJ, ERR_R_UNABLE_TO_GET_WRITE_LOCK);\n        ASN1_OBJECT_free(tmpoid);\n        return 0;\n    }\n\n    /* If NID is not NID_undef then object already exists */\n    if (oid != NULL\n        && ossl_obj_obj2nid(tmpoid, 0) != NID_undef) {\n        ERR_raise(ERR_LIB_OBJ, OBJ_R_OID_EXISTS);\n        goto err;\n    }\n\n    tmpoid->nid = obj_new_nid_unlocked(1);\n\n    if (tmpoid->nid == NID_undef)\n        goto err;\n\n    tmpoid->sn = (char *)sn;\n    tmpoid->ln = (char *)ln;\n\n    ok = ossl_obj_add_object(tmpoid, 0);\n\n    tmpoid->sn = NULL;\n    tmpoid->ln = NULL;\n\n err:\n    ossl_obj_unlock(1);\n    ASN1_OBJECT_free(tmpoid);\n    return ok;\n}\n\nsize_t OBJ_length(const ASN1_OBJECT *obj)\n{\n    if (obj == NULL)\n        return 0;\n    return obj->length;\n}\n\nconst unsigned char *OBJ_get0_data(const ASN1_OBJECT *obj)\n{\n    if (obj == NULL)\n        return NULL;\n    return obj->data;\n}\n\nint OBJ_add_object(const ASN1_OBJECT *obj)\n{\n    return ossl_obj_add_object(obj, 1);\n}\n\nint OBJ_obj2nid(const ASN1_OBJECT *a)\n{\n    return ossl_obj_obj2nid(a, 1);\n}\n"}, {"id": "D14AECEB8F4412C2", "name": "strlen", "path": "/usr/include/string.h", "start": {"line": 407, "col": 1}, "end": {"line": 408, "col": 33}}, {"id": "43B3DAC0000BE98B", "name": "strncat", "path": "/usr/include/string.h", "start": {"line": 152, "col": 1}, "end": {"line": 153, "col": 29}}, {"id": "F05D6EEFA38CDF7F", "name": "transform_opts", "path": "openssl/apps/cmp.c", "start": {"line": 1004, "col": 1}, "end": {"line": 1049, "col": 1}, "code": "{\n    if (opt_cmd_s != NULL) {\n        if (!strcmp(opt_cmd_s, \"ir\")) {\n            opt_cmd = CMP_IR;\n        } else if (!strcmp(opt_cmd_s, \"kur\")) {\n            opt_cmd = CMP_KUR;\n        } else if (!strcmp(opt_cmd_s, \"cr\")) {\n            opt_cmd = CMP_CR;\n        } else if (!strcmp(opt_cmd_s, \"p10cr\")) {\n            opt_cmd = CMP_P10CR;\n        } else if (!strcmp(opt_cmd_s, \"rr\")) {\n            opt_cmd = CMP_RR;\n        } else if (!strcmp(opt_cmd_s, \"genm\")) {\n            opt_cmd = CMP_GENM;\n        } else {\n            CMP_err1(\"unknown cmp command '%s'\", opt_cmd_s);\n            return 0;\n        }\n    } else {\n        CMP_err(\"no cmp command to execute\");\n        return 0;\n    }\n\n# define FORMAT_OPTIONS (OPT_FMT_PEMDER | OPT_FMT_PKCS12)\n\n    if (opt_keyform_s != NULL\n            && !opt_format(opt_keyform_s, FORMAT_OPTIONS, &opt_keyform)) {\n        CMP_err(\"unknown option given for key loading format\");\n        return 0;\n    }\n\n#undef FORMAT_OPTIONS\n\n    if (opt_certform_s != NULL\n            && !opt_format(opt_certform_s, OPT_FMT_PEMDER, &opt_certform)) {\n        CMP_err(\"unknown option given for certificate storing format\");\n        return 0;\n    }\n\n    return 1;\n}\n\nstatic OSSL_CMP_SRV_CTX *setup_srv_ctx(ENGINE *engine)\n{\n    OSSL_CMP_CTX *ctx; /* extra CMP (client) ctx partly used by server */\n    OSSL_CMP_SRV_CTX *srv_ctx = ossl_cmp_mock_srv_new(app_get0_libctx(),\n                                                      app_get0_propq());\n\n    if (srv_ctx == NULL)\n        return NULL;\n    ctx = OSSL_CMP_SRV_CTX_get0_cmp_ctx(srv_ctx);\n\n    if (opt_srv_ref == NULL) {\n        if (opt_srv_cert == NULL) {\n            /* opt_srv_cert should determine the sender */\n            CMP_err(\"must give -srv_ref for mock server if no -srv_cert given\");\n            goto err;\n        }\n    } else {\n        if (!OSSL_CMP_CTX_set1_referenceValue(ctx, (unsigned char *)opt_srv_ref,\n                                              strlen(opt_srv_ref)))\n            goto err;\n    }\n\n    if (opt_srv_secret != NULL) {\n        int res;\n        char *pass_str = get_passwd(opt_srv_secret, \"PBMAC secret of mock server\");\n\n        if (pass_str != NULL) {\n            cleanse(opt_srv_secret);\n            res = OSSL_CMP_CTX_set1_secretValue(ctx, (unsigned char *)pass_str,\n                                                strlen(pass_str));\n            clear_free(pass_str);\n            if (res == 0)\n                goto err;\n        }\n    } else if (opt_srv_cert == NULL) {\n        CMP_err(\"server credentials (-srv_secret or -srv_cert) must be given if -use_mock_srv or -port is used\");\n        goto err;\n    } else {\n        CMP_warn(\"server will not be able to handle PBM-protected requests since -srv_secret is not given\");\n    }\n\n    if (opt_srv_secret == NULL\n            && ((opt_srv_cert == NULL) != (opt_srv_key == NULL))) {\n        CMP_err(\"must give both -srv_cert and -srv_key options or neither\");\n        goto err;\n    }\n    if (!setup_cert(ctx, opt_srv_cert, opt_srv_keypass,\n                    \"signer certificate of the mock server\",\n                    (add_X509_fn_t)OSSL_CMP_CTX_set1_cert))\n        goto err;\n    if (opt_srv_key != NULL) {\n        EVP_PKEY *pkey = load_key_pwd(opt_srv_key, opt_keyform,\n                                      opt_srv_keypass,\n                                      engine, \"private key for mock server cert\");\n\n        if (pkey == NULL || !OSSL_CMP_CTX_set1_pkey(ctx, pkey)) {\n            EVP_PKEY_free(pkey);\n            goto err;\n        }\n        EVP_PKEY_free(pkey);\n    }\n    cleanse(opt_srv_keypass);\n\n    if (opt_srv_trusted != NULL) {\n        X509_STORE *ts =\n            load_trusted(opt_srv_trusted, 0, \"certs trusted by mock server\");\n\n        if (ts == NULL || !OSSL_CMP_CTX_set0_trusted(ctx, ts)) {\n            X509_STORE_free(ts);\n            goto err;\n        }\n    } else {\n        CMP_warn(\"mock server will not be able to handle signature-protected requests since -srv_trusted is not given\");\n    }\n    if (!setup_certs(opt_srv_untrusted,\n                     \"untrusted certificates for mock server\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_untrusted))\n        goto err;\n\n    if (!setup_cert(srv_ctx, opt_ref_cert, opt_otherpass,\n                    \"reference cert to be expected by the mock server\",\n                    (add_X509_fn_t)ossl_cmp_mock_srv_set1_refCert))\n            goto err;\n    if (opt_rsp_cert == NULL) {\n        CMP_warn(\"no -rsp_cert given for mock server\");\n    } else {\n        if (!setup_cert(srv_ctx, opt_rsp_cert, opt_keypass,\n                        \"cert the mock server returns on certificate requests\",\n                        (add_X509_fn_t)ossl_cmp_mock_srv_set1_certOut))\n            goto err;\n    }\n    if (!setup_certs(opt_rsp_extracerts,\n                     \"CMP extra certificates for mock server\", srv_ctx,\n                     (add_X509_stack_fn_t)ossl_cmp_mock_srv_set1_chainOut))\n        goto err;\n    if (!setup_certs(opt_rsp_capubs, \"caPubs for mock server\", srv_ctx,\n                     (add_X509_stack_fn_t)ossl_cmp_mock_srv_set1_caPubsOut))\n        goto err;\n    if (!setup_cert(srv_ctx, opt_rsp_newwithnew, opt_otherpass,\n                    \"NewWithNew cert the mock server returns in rootCaKeyUpdate\",\n                    (add_X509_fn_t)ossl_cmp_mock_srv_set1_newWithNew)\n        || !setup_cert(srv_ctx, opt_rsp_newwithold, opt_otherpass,\n                       \"NewWithOld cert the mock server returns in rootCaKeyUpdate\",\n                       (add_X509_fn_t)ossl_cmp_mock_srv_set1_newWithOld)\n        || !setup_cert(srv_ctx, opt_rsp_oldwithnew, opt_otherpass,\n                       \"OldWithNew cert the mock server returns in rootCaKeyUpdate\",\n                       (add_X509_fn_t)ossl_cmp_mock_srv_set1_oldWithNew))\n        goto err;\n    (void)ossl_cmp_mock_srv_set_pollCount(srv_ctx, opt_poll_count);\n    (void)ossl_cmp_mock_srv_set_checkAfterTime(srv_ctx, opt_check_after);\n    if (opt_grant_implicitconf)\n        (void)OSSL_CMP_SRV_CTX_set_grant_implicit_confirm(srv_ctx, 1);\n\n    if (opt_failure != INT_MIN) { /* option has been set explicitly */\n        if (opt_failure < 0 || OSSL_CMP_PKIFAILUREINFO_MAX < opt_failure) {\n            CMP_err1(\"-failure out of range, should be >= 0 and <= %d\",\n                     OSSL_CMP_PKIFAILUREINFO_MAX);\n            goto err;\n        }\n        if (opt_failurebits != 0)\n            CMP_warn(\"-failurebits overrides -failure\");\n        else\n            opt_failurebits = 1 << opt_failure;\n    }\n    if ((unsigned)opt_failurebits > OSSL_CMP_PKIFAILUREINFO_MAX_BIT_PATTERN) {\n        CMP_err(\"-failurebits out of range\");\n        goto err;\n    }\n    if (!ossl_cmp_mock_srv_set_statusInfo(srv_ctx, opt_pkistatus,\n                                          opt_failurebits, opt_statusstring))\n        goto err;\n\n    if (opt_send_error)\n        (void)ossl_cmp_mock_srv_set_sendError(srv_ctx, 1);\n\n    if (opt_send_unprotected)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_SEND, 1);\n    if (opt_send_unprot_err)\n        (void)OSSL_CMP_SRV_CTX_set_send_unprotected_errors(srv_ctx, 1);\n    if (opt_accept_unprotected)\n        (void)OSSL_CMP_SRV_CTX_set_accept_unprotected(srv_ctx, 1);\n    if (opt_accept_unprot_err)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_ERRORS, 1);\n    if (opt_accept_raverified)\n        (void)OSSL_CMP_SRV_CTX_set_accept_raverified(srv_ctx, 1);\n\n    return srv_ctx;\n\n err:\n    ossl_cmp_mock_srv_free(srv_ctx);\n    return NULL;\n}\n\n/*\n * set up verification aspects of OSSL_CMP_CTX w.r.t. opts from config file/CLI.\n * Returns pointer on success, NULL on error\n */\nstatic int setup_verification_ctx(OSSL_CMP_CTX *ctx)\n{\n    if (!setup_certs(opt_untrusted, \"untrusted certificates\", ctx,\n                     (add_X509_stack_fn_t)OSSL_CMP_CTX_set1_untrusted))\n        return 0;\n\n    if (opt_srvcert != NULL || opt_trusted != NULL) {\n        if (opt_srvcert != NULL) {\n            if (opt_trusted != NULL) {\n                CMP_warn(\"-trusted option is ignored since -srvcert option is present\");\n                opt_trusted = NULL;\n            }\n            if (opt_recipient != NULL) {\n                CMP_warn(\"-recipient option is ignored since -srvcert option is present\");\n                opt_recipient = NULL;\n            }\n            if (!setup_cert(ctx, opt_srvcert, opt_otherpass,\n                            \"directly trusted CMP server certificate\",\n                            (add_X509_fn_t)OSSL_CMP_CTX_set1_srvCert))\n                return 0;\n        }\n        if (opt_trusted != NULL) {\n            X509_STORE *ts;\n\n            /*\n             * the 0 arg below clears any expected host/ip/email address;\n             * opt_expect_sender is used instead\n             */\n            ts = load_trusted(opt_trusted, 0, \"certs trusted by client\");\n\n            if (ts == NULL || !OSSL_CMP_CTX_set0_trusted(ctx, ts)) {\n                X509_STORE_free(ts);\n                return 0;\n            }\n        }\n    }\n\n    if (opt_unprotected_errors)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_UNPROTECTED_ERRORS, 1);\n\n    if (opt_out_trusted != NULL) { /* for use in OSSL_CMP_certConf_cb() */\n        X509_VERIFY_PARAM *out_vpm = NULL;\n        X509_STORE *out_trusted =\n            load_trusted(opt_out_trusted, 1,\n                         \"trusted certs for verifying newly enrolled cert\");\n\n        if (out_trusted == NULL)\n            return 0;\n        /* ignore any -attime here, new certs are current anyway */\n        out_vpm = X509_STORE_get0_param(out_trusted);\n        X509_VERIFY_PARAM_clear_flags(out_vpm, X509_V_FLAG_USE_CHECK_TIME);\n\n        (void)OSSL_CMP_CTX_set_certConf_cb_arg(ctx, out_trusted);\n    }\n\n    if (opt_disable_confirm)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_DISABLE_CONFIRM, 1);\n\n    if (opt_implicit_confirm)\n        (void)OSSL_CMP_CTX_set_option(ctx, OSSL_CMP_OPT_IMPLICIT_CONFIRM, 1);\n\n    return 1;\n}\n\n"}, {"id": "7371246F9FD563ED", "name": "OSSL_CMP_CTX_set1_serverPath", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 861, "col": 1}, "end": {"line": 861, "col": 1}, "code": "\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "F16AF07654F97FCA", "name": "OSSL_HTTP_adapt_proxy", "path": "openssl/crypto/http/http_lib.c", "start": {"line": 278, "col": 1}, "end": {"line": 293, "col": 1}, "code": "                                  const char *server, int use_ssl)\n{\n    /*\n     * using environment variable names, both lowercase and uppercase variants,\n     * compatible with other HTTP client implementations like wget, curl and git\n     */\n    if (proxy == NULL)\n        proxy = ossl_safe_getenv(use_ssl ? \"https_proxy\" : \"http_proxy\");\n    if (proxy == NULL)\n        proxy = ossl_safe_getenv(use_ssl ? OPENSSL_HTTP_PROXY : OPENSSL_HTTPS_PROXY);\n\n    if (proxy == NULL || *proxy == '\\0' || !use_proxy(no_proxy, server))\n        return NULL;\n    return proxy;\n}\n"}, {"id": "C2565327538F20FC", "name": "OSSL_CMP_CTX_set_serverPort", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 858, "col": 1}, "end": {"line": 858, "col": 1}, "code": "\n/* Set the HTTP path to be used on the server (e.g \"pkix/\") */\nDEFINE_OSSL_CMP_CTX_set1(serverPath, char)\n\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}, {"id": "4ABC8F8E9525846B", "name": "OSSL_CMP_CTX_set1_server", "path": "openssl/crypto/cmp/cmp_ctx.c", "start": {"line": 826, "col": 1}, "end": {"line": 826, "col": 1}, "code": "\n/* Set the server exclusion list of the HTTP proxy server */\nDEFINE_OSSL_CMP_CTX_set1(no_proxy, char)\n\n#ifndef OPENSSL_NO_HTTP\n/* Set the http connect/disconnect callback function to be used for HTTP(S) */\nDEFINE_OSSL_set(OSSL_CMP_CTX, http_cb, OSSL_HTTP_bio_cb_t)\n\n/* Set argument optionally to be used by the http connect/disconnect callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, http_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the http connect/disconnect callback\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, http_cb_arg, void *, NULL)\n#endif\n\n/* Set callback function for sending CMP request and receiving response */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb, OSSL_CMP_transfer_cb_t)\n\n/* Set argument optionally to be used by the transfer callback */\nDEFINE_OSSL_set(OSSL_CMP_CTX, transfer_cb_arg, void *)\n\n/*\n * Get argument optionally to be used by the transfer callback.\n * Returns callback argument set previously (NULL if not set or on error)\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, transfer_cb_arg, void *, NULL)\n\n/** Set the HTTP server port to be used */\nDEFINE_OSSL_set(OSSL_CMP_CTX, serverPort, int)\n\n/* Set the HTTP path to be used on the server (e.g \"pkix/\") */\nDEFINE_OSSL_CMP_CTX_set1(serverPath, char)\n\n/* Set the failInfo error code as bit encoding in OSSL_CMP_CTX */\nDEFINE_OSSL_set(ossl_cmp_ctx, failInfoCode, int)\n\n/*\n * Get the failInfo error code in OSSL_CMP_CTX as bit encoding.\n * Returns bit string as integer on success, -1 on error\n */\nDEFINE_OSSL_get(OSSL_CMP_CTX, failInfoCode, int, -1)\n\n/* Set a Boolean or integer option of the context to the \"val\" arg */\nint OSSL_CMP_CTX_set_option(OSSL_CMP_CTX *ctx, int opt, int val)\n{\n    int min_val;\n\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        min_val = OCSP_REVOKED_STATUS_NOSTATUS;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        min_val = OSSL_CRMF_POPO_NONE;\n        break;\n    default:\n        min_val = 0;\n        break;\n    }\n    if (val < min_val) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_SMALL);\n        return 0;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        if (val > OSSL_CMP_LOG_MAX) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->log_verbosity = val;\n        break;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        ctx->implicitConfirm = val;\n        break;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        ctx->disableConfirm = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        ctx->unprotectedSend = val;\n        break;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        ctx->unprotectedErrors = val;\n        break;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        ctx->noCacheExtraCerts = val;\n        break;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        ctx->days = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        ctx->SubjectAltName_nodefault = val;\n        break;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        ctx->setSubjectAltNameCritical = val;\n        break;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        ctx->setPoliciesCritical = val;\n        break;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        ctx->ignore_keyusage = val;\n        break;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        if (val > OSSL_CRMF_POPO_KEYAGREE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->popoMethod = val;\n        break;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->digest, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        if (!cmp_ctx_set_md(ctx, &ctx->pbm_owf, val))\n            return 0;\n        break;\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        ctx->pbm_mac = val;\n        break;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        ctx->keep_alive = val;\n        break;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        ctx->msg_timeout = val;\n        break;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        ctx->total_timeout = val;\n        break;\n    case OSSL_CMP_OPT_USE_TLS:\n        ctx->tls_used = val;\n        break;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        ctx->permitTAInExtraCertsForIR = val;\n        break;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        if (val > OCSP_REVOKED_STATUS_AACOMPROMISE) {\n            ERR_raise(ERR_LIB_CMP, CMP_R_VALUE_TOO_LARGE);\n            return 0;\n        }\n        ctx->revocationReason = val;\n        break;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return 0;\n    }\n\n    return 1;\n}\n\n/*\n * Reads a Boolean or integer option value from the context.\n * Returns -1 on error (which is the default OSSL_CMP_OPT_REVOCATION_REASON)\n */\nint OSSL_CMP_CTX_get_option(const OSSL_CMP_CTX *ctx, int opt)\n{\n    if (ctx == NULL) {\n        ERR_raise(ERR_LIB_CMP, CMP_R_NULL_ARGUMENT);\n        return -1;\n    }\n\n    switch (opt) {\n    case OSSL_CMP_OPT_LOG_VERBOSITY:\n        return ctx->log_verbosity;\n    case OSSL_CMP_OPT_IMPLICIT_CONFIRM:\n        return ctx->implicitConfirm;\n    case OSSL_CMP_OPT_DISABLE_CONFIRM:\n        return ctx->disableConfirm;\n    case OSSL_CMP_OPT_UNPROTECTED_SEND:\n        return ctx->unprotectedSend;\n    case OSSL_CMP_OPT_UNPROTECTED_ERRORS:\n        return ctx->unprotectedErrors;\n    case OSSL_CMP_OPT_NO_CACHE_EXTRACERTS:\n        return ctx->noCacheExtraCerts;\n    case OSSL_CMP_OPT_VALIDITY_DAYS:\n        return ctx->days;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_NODEFAULT:\n        return ctx->SubjectAltName_nodefault;\n    case OSSL_CMP_OPT_SUBJECTALTNAME_CRITICAL:\n        return ctx->setSubjectAltNameCritical;\n    case OSSL_CMP_OPT_POLICIES_CRITICAL:\n        return ctx->setPoliciesCritical;\n    case OSSL_CMP_OPT_IGNORE_KEYUSAGE:\n        return ctx->ignore_keyusage;\n    case OSSL_CMP_OPT_POPO_METHOD:\n        return ctx->popoMethod;\n    case OSSL_CMP_OPT_DIGEST_ALGNID:\n        return EVP_MD_get_type(ctx->digest);\n    case OSSL_CMP_OPT_OWF_ALGNID:\n        return EVP_MD_get_type(ctx->pbm_owf);\n    case OSSL_CMP_OPT_MAC_ALGNID:\n        return ctx->pbm_mac;\n    case OSSL_CMP_OPT_KEEP_ALIVE:\n        return ctx->keep_alive;\n    case OSSL_CMP_OPT_MSG_TIMEOUT:\n        return ctx->msg_timeout;\n    case OSSL_CMP_OPT_TOTAL_TIMEOUT:\n        return ctx->total_timeout;\n    case OSSL_CMP_OPT_USE_TLS:\n        return ctx->tls_used;\n    case OSSL_CMP_OPT_PERMIT_TA_IN_EXTRACERTS_FOR_IR:\n        return ctx->permitTAInExtraCertsForIR;\n    case OSSL_CMP_OPT_REVOCATION_REASON:\n        return ctx->revocationReason;\n    default:\n        ERR_raise(ERR_LIB_CMP, CMP_R_INVALID_OPTION);\n        return -1;\n    }\n}\n"}], "code": "static int setup_client_ctx(OSSL_CMP_CTX *ctx, ENGINE *engine)\n{\n    int ret = 0;\n    char *host = NULL, *port = NULL, *path = NULL, *used_path = opt_path;\n"}, "4FD107FA558F51A2": {"calls": [{"id": "C621676DC8D8C2ED", "name": "lh_SRTM_ITEM_free", "path": "openssl/ssl/quic/quic_srtm.c", "start": {"line": 24, "col": 1}, "end": {"line": 24, "col": 1}, "code": "\n/*\n * The SRTM is implemented using two LHASH instances, one matching opaque pointers to\n * an item structure, and another matching a SRT-derived value to an item\n * structure. Multiple items with different seq_num values under a given opaque,\n * and duplicate SRTs, are handled using sorted singly-linked lists.\n *\n * The O(n) insert and lookup performance is tolerated on the basis that the\n * total number of entries for a given opaque (total number of extant CIDs for a\n * connection) should be quite small, and the QUIC protocol allows us to place a\n * hard limit on this via the active_connection_id_limit TPARAM. Thus there is\n * no risk of a large number of SRTs needing to be registered under a given\n * opaque.\n *\n * It is expected one SRTM will exist per QUIC_PORT and track all SRTs across\n * all connections for that QUIC_PORT.\n */\nstruct srtm_item_st {\n    SRTM_ITEM                   *next_by_srt_blinded; /* SORT BY opaque  DESC */\n    SRTM_ITEM                   *next_by_seq_num;     /* SORT BY seq_num DESC */\n    void                        *opaque; /* \\__ unique identity for item */\n    uint64_t                    seq_num; /* /                            */\n    QUIC_STATELESS_RESET_TOKEN  srt;\n    unsigned char               srt_blinded[BLINDED_SRT_LEN]; /* H(srt) */\n\n"}, {"id": "21BF9AD42E862E67", "name": "lh_SRTM_ITEM_doall", "path": "openssl/ssl/quic/quic_srtm.c", "start": {"line": 24, "col": 1}, "end": {"line": 24, "col": 1}, "code": "\n/*\n * The SRTM is implemented using two LHASH instances, one matching opaque pointers to\n * an item structure, and another matching a SRT-derived value to an item\n * structure. Multiple items with different seq_num values under a given opaque,\n * and duplicate SRTs, are handled using sorted singly-linked lists.\n *\n * The O(n) insert and lookup performance is tolerated on the basis that the\n * total number of entries for a given opaque (total number of extant CIDs for a\n * connection) should be quite small, and the QUIC protocol allows us to place a\n * hard limit on this via the active_connection_id_limit TPARAM. Thus there is\n * no risk of a large number of SRTs needing to be registered under a given\n * opaque.\n *\n * It is expected one SRTM will exist per QUIC_PORT and track all SRTs across\n * all connections for that QUIC_PORT.\n */\nstruct srtm_item_st {\n    SRTM_ITEM                   *next_by_srt_blinded; /* SORT BY opaque  DESC */\n    SRTM_ITEM                   *next_by_seq_num;     /* SORT BY seq_num DESC */\n    void                        *opaque; /* \\__ unique identity for item */\n    uint64_t                    seq_num; /* /                            */\n    QUIC_STATELESS_RESET_TOKEN  srt;\n    unsigned char               srt_blinded[BLINDED_SRT_LEN]; /* H(srt) */\n\n"}, {"id": "7384F3292DB4C38B", "name": "EVP_CIPHER_CTX_free", "path": "openssl/crypto/evp/evp_enc.c", "start": {"line": 84, "col": 1}, "end": {"line": 90, "col": 1}, "code": "{\n    if (ctx == NULL)\n        return;\n    EVP_CIPHER_CTX_reset(ctx);\n    OPENSSL_free(ctx);\n}\n\nstatic int evp_cipher_init_internal(EVP_CIPHER_CTX *ctx,\n                                    const EVP_CIPHER *cipher,\n                                    ENGINE *impl, const unsigned char *key,\n                                    const unsigned char *iv, int enc,\n                                    const OSSL_PARAM params[])\n{\n    int n;\n#if !defined(OPENSSL_NO_ENGINE) && !defined(FIPS_MODULE)\n    ENGINE *tmpimpl = NULL;\n#endif\n\n    /*\n     * enc == 1 means we are encrypting.\n     * enc == 0 means we are decrypting.\n     * enc == -1 means, use the previously initialised value for encrypt/decrypt\n     */\n    if (enc == -1) {\n        enc = ctx->encrypt;\n    } else {\n        if (enc)\n            enc = 1;\n        ctx->encrypt = enc;\n    }\n\n    if (cipher == NULL && ctx->cipher == NULL) {\n        ERR_raise(ERR_LIB_EVP, EVP_R_NO_CIPHER_SET);\n        return 0;\n    }\n\n    /* Code below to be removed when legacy support is dropped. */\n\n#if !defined(OPENSSL_NO_ENGINE) && !defined(FIPS_MODULE)\n    /*\n     * Whether it's nice or not, \"Inits\" can be used on \"Final\"'d contexts so\n     * this context may already have an ENGINE! Try to avoid releasing the\n     * previous handle, re-querying for an ENGINE, and having a\n     * reinitialisation, when it may all be unnecessary.\n     */\n    if (ctx->engine && ctx->cipher\n        && (cipher == NULL || cipher->nid == ctx->cipher->nid))\n        goto skip_to_init;\n\n    if (cipher != NULL && impl == NULL) {\n         /* Ask if an ENGINE is reserved for this job */\n        tmpimpl = ENGINE_get_cipher_engine(cipher->nid);\n    }\n#endif\n\n    /*\n     * If there are engines involved then we should use legacy handling for now.\n     */\n    if (ctx->engine != NULL\n#if !defined(OPENSSL_NO_ENGINE) && !defined(FIPS_MODULE)\n            || tmpimpl != NULL\n#endif\n            || impl != NULL\n            || (cipher != NULL && cipher->origin == EVP_ORIG_METH)\n            || (cipher == NULL && ctx->cipher != NULL\n                               && ctx->cipher->origin == EVP_ORIG_METH)) {\n        if (ctx->cipher == ctx->fetched_cipher)\n            ctx->cipher = NULL;\n        EVP_CIPHER_free(ctx->fetched_cipher);\n        ctx->fetched_cipher = NULL;\n        goto legacy;\n    }\n    /*\n     * Ensure a context left lying around from last time is cleared\n     * (legacy code)\n     */\n    if (cipher != NULL && ctx->cipher != NULL) {\n        if (ctx->cipher->cleanup != NULL && !ctx->cipher->cleanup(ctx))\n            return 0;\n        OPENSSL_clear_free(ctx->cipher_data, ctx->cipher->ctx_size);\n        ctx->cipher_data = NULL;\n    }\n\n    /* Start of non-legacy code below */\n\n    /* Ensure a context left lying around from last time is cleared */\n    if (cipher != NULL && ctx->cipher != NULL) {\n        unsigned long flags = ctx->flags;\n\n        EVP_CIPHER_CTX_reset(ctx);\n        /* Restore encrypt and flags */\n"}], "code": "void ossl_quic_srtm_free(QUIC_SRTM *srtm)\n{\n    if (srtm == NULL)\n        return;\n\n    lh_SRTM_ITEM_free(srtm->items_rev);\n    if (srtm->items_fwd != NULL) {\n        lh_SRTM_ITEM_doall(srtm->items_fwd, srtm_free_each);\n        lh_SRTM_ITEM_free(srtm->items_fwd);\n    }\n\n    EVP_CIPHER_CTX_free(srtm->blind_ctx);\n    OPENSSL_free(srtm);\n}\n"}, "218D0EC0FABB76A1": {"calls": [{"id": "A4054E2DC1F6C9B1", "name": "ossl_lib_ctx_get_data", "path": "openssl/crypto/context.c", "start": {"line": 544, "col": 1}, "end": {"line": 633, "col": 1}, "code": "{\n    void *p;\n\n    ctx = ossl_lib_ctx_get_concrete(ctx);\n    if (ctx == NULL)\n        return NULL;\n\n    switch (index) {\n    case OSSL_LIB_CTX_PROPERTY_STRING_INDEX:\n        return ctx->property_string_data;\n    case OSSL_LIB_CTX_EVP_METHOD_STORE_INDEX:\n        return ctx->evp_method_store;\n    case OSSL_LIB_CTX_PROVIDER_STORE_INDEX:\n        return ctx->provider_store;\n    case OSSL_LIB_CTX_NAMEMAP_INDEX:\n        return ctx->namemap;\n    case OSSL_LIB_CTX_PROPERTY_DEFN_INDEX:\n        return ctx->property_defns;\n    case OSSL_LIB_CTX_GLOBAL_PROPERTIES:\n        return ctx->global_properties;\n    case OSSL_LIB_CTX_DRBG_INDEX:\n        return ctx->drbg;\n    case OSSL_LIB_CTX_DRBG_NONCE_INDEX:\n        return ctx->drbg_nonce;\n"}], "code": "OSSL_PROPERTY_LIST **ossl_ctx_global_properties(OSSL_LIB_CTX *libctx,\n                                                ossl_unused int loadconfig)\n{\n    OSSL_GLOBAL_PROPERTIES *globp;\n\n#if !defined(FIPS_MODULE) && !defined(OPENSSL_NO_AUTOLOAD_CONFIG)\n    if (loadconfig && !OPENSSL_init_crypto(OPENSSL_INIT_LOAD_CONFIG, NULL))\n        return NULL;\n#endif\n    globp = ossl_lib_ctx_get_data(libctx, OSSL_LIB_CTX_GLOBAL_PROPERTIES);\n\n    return globp != NULL ? &globp->list : NULL;\n}\n"}, "BA863A3BCB7C141B": {"calls": [{"id": "859F2D0D348D4244", "name": "ossl_statm_get_rtt_info", "path": "openssl/ssl/quic/quic_statm.c", "start": {"line": 70, "col": 1}, "end": {"line": 76, "col": 1}, "code": "{\n    rtt_info->min_rtt           = statm->min_rtt;\n    rtt_info->latest_rtt        = statm->latest_rtt;\n    rtt_info->smoothed_rtt      = statm->smoothed_rtt;\n    rtt_info->rtt_variance      = statm->rtt_variance;\n}\n"}, {"id": "053AE7EFFFF687B6", "name": "ossl_time_add", "path": "openssl/include/internal/time.h", "start": {"line": 170, "col": 1}, "end": {"line": 178, "col": 1}, "code": "OSSL_TIME ossl_time_add(OSSL_TIME a, OSSL_TIME b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_add_time(a.t, b.t, &err);\n    return err ? ossl_time_infinite() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_subtract(OSSL_TIME a, OSSL_TIME b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_sub_time(a.t, b.t, &err);\n    return err ? ossl_time_zero() : r;\n}\n\n/* Returns |a - b|. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_abs_difference(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t > b.t ? ossl_time_subtract(a, b)\n                     : ossl_time_subtract(b, a);\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_multiply(OSSL_TIME a, uint64_t b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_mul_time(a.t, b, &err);\n    return err ? ossl_time_infinite() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_divide(OSSL_TIME a, uint64_t b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_div_time(a.t, b, &err);\n    return err ? ossl_time_zero() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_muldiv(OSSL_TIME a, uint64_t b, uint64_t c)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_muldiv_time(a.t, b, c, &err);\n    return err ? ossl_time_zero() : r;\n}\n\n/* Return higher of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_max(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t > b.t ? a : b;\n}\n\n/* Return the lower of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_min(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t < b.t ? a : b;\n}\n\n#endif\n"}, {"id": "5238544AAAA34D0D", "name": "ossl_time_max", "path": "openssl/include/internal/time.h", "start": {"line": 229, "col": 1}, "end": {"line": 233, "col": 1}, "code": "OSSL_TIME ossl_time_max(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t > b.t ? a : b;\n}\n\n/* Return the lower of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_min(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t < b.t ? a : b;\n}\n\n#endif\n"}, {"id": "B322FAF4DC2AC1EA", "name": "ossl_time_multiply", "path": "openssl/include/internal/time.h", "start": {"line": 198, "col": 1}, "end": {"line": 206, "col": 1}, "code": "OSSL_TIME ossl_time_multiply(OSSL_TIME a, uint64_t b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_mul_time(a.t, b, &err);\n    return err ? ossl_time_infinite() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_divide(OSSL_TIME a, uint64_t b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_div_time(a.t, b, &err);\n    return err ? ossl_time_zero() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_muldiv(OSSL_TIME a, uint64_t b, uint64_t c)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_muldiv_time(a.t, b, c, &err);\n    return err ? ossl_time_zero() : r;\n}\n\n/* Return higher of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_max(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t > b.t ? a : b;\n}\n\n/* Return the lower of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_min(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t < b.t ? a : b;\n}\n\n#endif\n"}, {"id": "D71980019339D30A", "name": "ossl_ticks2time", "path": "openssl/include/internal/time.h", "start": {"line": 56, "col": 1}, "end": {"line": 63, "col": 1}, "code": "OSSL_TIME ossl_ticks2time(uint64_t ticks)\n{\n    OSSL_TIME r;\n\n    r.t = ticks;\n    return r;\n}\n\n/* Convert a time to a tick count */\nstatic ossl_unused ossl_inline\nuint64_t ossl_time2ticks(OSSL_TIME t)\n{\n    return t.t;\n}\n\n/* Get current time */\nOSSL_TIME ossl_time_now(void);\n\n/* The beginning and end of the time range */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_zero(void)\n{\n    return ossl_ticks2time(0);\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_infinite(void)\n{\n    return ossl_ticks2time(~(uint64_t)0);\n}\n\n\n/* Convert time to timeval */\nstatic ossl_unused ossl_inline\nstruct timeval ossl_time_to_timeval(OSSL_TIME t)\n{\n    struct timeval tv;\n    int err = 0;\n\n    /*\n     * Round up any nano secs which struct timeval doesn't support. Ensures that\n     * we never return a zero time if the input time is non zero\n     */\n    t.t = safe_add_time(t.t, OSSL_TIME_US - 1, &err);\n    if (err)\n        t = ossl_time_infinite();\n\n    tv.tv_sec = (time_t)(t.t / OSSL_TIME_SECOND);\n    tv.tv_usec = (t.t % OSSL_TIME_SECOND) / OSSL_TIME_US;\n    return tv;\n}\n\n/* Convert timeval to time */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_from_timeval(struct timeval tv)\n{\n    OSSL_TIME t;\n\n"}, {"id": "69B366807A55C80C", "name": "ossl_time_is_infinite", "path": "openssl/include/internal/time.h", "start": {"line": 164, "col": 1}, "end": {"line": 168, "col": 1}, "code": "int ossl_time_is_infinite(OSSL_TIME t)\n{\n    return ossl_time_compare(t, ossl_time_infinite()) == 0;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_add(OSSL_TIME a, OSSL_TIME b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_add_time(a.t, b.t, &err);\n    return err ? ossl_time_infinite() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_subtract(OSSL_TIME a, OSSL_TIME b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_sub_time(a.t, b.t, &err);\n    return err ? ossl_time_zero() : r;\n}\n\n/* Returns |a - b|. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_abs_difference(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t > b.t ? ossl_time_subtract(a, b)\n                     : ossl_time_subtract(b, a);\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_multiply(OSSL_TIME a, uint64_t b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_mul_time(a.t, b, &err);\n    return err ? ossl_time_infinite() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_divide(OSSL_TIME a, uint64_t b)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_div_time(a.t, b, &err);\n    return err ? ossl_time_zero() : r;\n}\n\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_muldiv(OSSL_TIME a, uint64_t b, uint64_t c)\n{\n    OSSL_TIME r;\n    int err = 0;\n\n    r.t = safe_muldiv_time(a.t, b, c, &err);\n    return err ? ossl_time_zero() : r;\n}\n\n/* Return higher of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_max(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t > b.t ? a : b;\n}\n\n/* Return the lower of the two given time values. */\nstatic ossl_unused ossl_inline\nOSSL_TIME ossl_time_min(OSSL_TIME a, OSSL_TIME b)\n{\n    return a.t < b.t ? a : b;\n}\n\n#endif\n"}], "code": "OSSL_TIME ossl_ackm_get_pto_duration(OSSL_ACKM *ackm)\n{\n    OSSL_TIME duration;\n    OSSL_RTT_INFO rtt;\n\n    ossl_statm_get_rtt_info(ackm->statm, &rtt);\n\n    duration = ossl_time_add(rtt.smoothed_rtt,\n                             ossl_time_max(ossl_time_multiply(rtt.rtt_variance, 4),\n                                           ossl_ticks2time(K_GRANULARITY)));\n    if (!ossl_time_is_infinite(ackm->rx_max_ack_delay))\n        duration = ossl_time_add(duration, ackm->rx_max_ack_delay);\n\n    return duration;\n}\n"}, "268C244B2DAF749A": {"calls": [{"id": "1C3CF0E1F469918D", "name": "ring_buf_init", "path": "openssl/include/internal/ring_buf.h", "start": {"line": 47, "col": 1}, "end": {"line": 53, "col": 1}, "code": "{\n    r->start = NULL;\n    r->alloc = 0;\n    r->head_offset = r->ctail_offset = 0;\n    return 1;\n}\n\nstatic ossl_inline void ring_buf_destroy(struct ring_buf *r, int cleanse)\n{\n    if (cleanse)\n        OPENSSL_clear_free(r->start, r->alloc);\n    else\n        OPENSSL_free(r->start);\n    r->start = NULL;\n    r->alloc = 0;\n}\n\nstatic ossl_inline size_t ring_buf_used(struct ring_buf *r)\n{\n    return (size_t)(r->head_offset - r->ctail_offset);\n}\n\nstatic ossl_inline size_t ring_buf_avail(struct ring_buf *r)\n{\n    return r->alloc - ring_buf_used(r);\n}\n\nstatic ossl_inline int ring_buf_write_at(struct ring_buf *r,\n                                         uint64_t logical_offset,\n                                         const unsigned char *buf,\n                                         size_t buf_len)\n{\n    size_t avail, idx, l;\n    unsigned char *start = r->start;\n    int i, err = 0;\n\n    avail = ring_buf_avail(r);\n    if (logical_offset < r->ctail_offset\n        || safe_add_u64(logical_offset, buf_len, &err)\n           > safe_add_u64(r->head_offset, avail, &err)\n        || safe_add_u64(r->head_offset, buf_len, &err)\n           > MAX_OFFSET\n        || err)\n        return 0;\n\n    for (i = 0; buf_len > 0 && i < 2; ++i) {\n        idx = logical_offset % r->alloc;\n        l = r->alloc - idx;\n        if (buf_len < l)\n            l = buf_len;\n\n        memcpy(start + idx, buf, l);\n        if (r->head_offset < logical_offset + l)\n            r->head_offset = logical_offset + l;\n"}, {"id": "FB8346D00A974912", "name": "ring_buf_resize", "path": "openssl/include/internal/ring_buf.h", "start": {"line": 231, "col": 1}, "end": {"line": 275, "col": 1}, "code": "                                       int cleanse)\n{\n    struct ring_buf rnew = {0};\n    const unsigned char *src = NULL;\n    size_t src_len = 0, copied = 0;\n\n    if (num_bytes == r->alloc)\n        return 1;\n\n    if (num_bytes < ring_buf_used(r))\n        return 0;\n\n    rnew.start = OPENSSL_malloc(num_bytes);\n    if (rnew.start == NULL)\n        return 0;\n\n    rnew.alloc          = num_bytes;\n    rnew.head_offset    = r->head_offset - ring_buf_used(r);\n    rnew.ctail_offset   = rnew.head_offset;\n\n    for (;;) {\n        if (!ring_buf_get_buf_at(r, r->ctail_offset + copied, &src, &src_len)) {\n            OPENSSL_free(rnew.start);\n            return 0;\n        }\n\n        if (src_len == 0)\n            break;\n\n        if (ring_buf_push(&rnew, src, src_len) != src_len) {\n            OPENSSL_free(rnew.start);\n            return 0;\n        }\n\n        copied += src_len;\n    }\n\n    assert(rnew.head_offset == r->head_offset);\n    rnew.ctail_offset = r->ctail_offset;\n\n    ring_buf_destroy(r, cleanse);\n    memcpy(r, &rnew, sizeof(*r));\n    return 1;\n}\n\n#endif                          /* OSSL_INTERNAL_RING_BUF_H */\n"}, {"id": "7759E58234D6D7A1", "name": "ossl_sframe_list_init", "path": "openssl/ssl/quic/quic_sf_list.c", "start": {"line": 48, "col": 1}, "end": {"line": 51, "col": 1}, "code": "{\n    memset(fl, 0, sizeof(*fl));\n}\n\nvoid ossl_sframe_list_destroy(SFRAME_LIST *fl)\n{\n    STREAM_FRAME *sf, *next_frame;\n\n    for (sf = fl->head; sf != NULL; sf = next_frame) {\n        next_frame = sf->next;\n        stream_frame_free(fl, sf);\n    }\n}\n\nstatic int append_frame(SFRAME_LIST *fl, UINT_RANGE *range,\n                        OSSL_QRX_PKT *pkt,\n                        const unsigned char *data)\n{\n    STREAM_FRAME *new_frame;\n\n    if ((new_frame = stream_frame_new(range, pkt, data)) == NULL)\n        return 0;\n    new_frame->prev = fl->tail;\n    if (fl->tail != NULL)\n        fl->tail->next = new_frame;\n    fl->tail = new_frame;\n    ++fl->num_frames;\n    return 1;\n}\n\nint ossl_sframe_list_insert(SFRAME_LIST *fl, UINT_RANGE *range,\n                            OSSL_QRX_PKT *pkt,\n                            const unsigned char *data, int fin)\n{\n    STREAM_FRAME *sf, *new_frame, *prev_frame, *next_frame;\n#ifndef NDEBUG\n    uint64_t curr_end = fl->tail != NULL ? fl->tail->range.end\n                                         : fl->offset;\n\n    /* This check for FINAL_SIZE_ERROR is handled by QUIC FC already */\n    assert((!fin || curr_end <= range->end)\n           && (!fl->fin || curr_end >= range->end));\n#endif\n\n    if (fl->offset >= range->end)\n        goto end;\n\n    /* nothing there yet */\n    if (fl->tail == NULL) {\n        fl->tail = fl->head = stream_frame_new(range, pkt, data);\n        if (fl->tail == NULL)\n            return 0;\n"}], "code": "QUIC_RSTREAM *ossl_quic_rstream_new(QUIC_RXFC *rxfc,\n                                    OSSL_STATM *statm, size_t rbuf_size)\n{\n    QUIC_RSTREAM *ret = OPENSSL_zalloc(sizeof(*ret));\n\n    if (ret == NULL)\n        return NULL;\n\n    ring_buf_init(&ret->rbuf);\n    if (!ring_buf_resize(&ret->rbuf, rbuf_size, 0)) {\n        OPENSSL_free(ret);\n        return NULL;\n    }\n\n    ossl_sframe_list_init(&ret->fl);\n    ret->rxfc = rxfc;\n    ret->statm = statm;\n    return ret;\n}\n"}, "DA30567D7A096837": {"calls": [{"id": "3F06B3D98ADFDC09", "name": "CRYPTO_UP_REF", "path": "openssl/include/internal/refcount.h", "start": {"line": 71, "col": 1}, "end": {"line": 75, "col": 1}, "code": "{\n    *ret = __atomic_fetch_add(&refcnt->val, 1, __ATOMIC_RELAXED) + 1;\n    return 1;\n}\n\nstatic __inline__ int CRYPTO_DOWN_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = __atomic_fetch_sub(&refcnt->val, 1, __ATOMIC_RELAXED) - 1;\n    if (*ret == 0)\n        __atomic_thread_fence(__ATOMIC_ACQUIRE);\n    return 1;\n}\n\nstatic __inline__ int CRYPTO_GET_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = __atomic_load_n(&refcnt->val, __ATOMIC_RELAXED);\n    return 1;\n}\n\n#  elif defined(__ICL) && defined(_WIN32)\n#   define HAVE_ATOMICS 1\n\ntypedef struct {\n    volatile int val;\n} CRYPTO_REF_COUNT;\n\nstatic __inline int CRYPTO_UP_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = _InterlockedExchangeAdd((void *)&refcnt->val, 1) + 1;\n    return 1;\n}\n\nstatic __inline int CRYPTO_DOWN_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = _InterlockedExchangeAdd((void *)&refcnt->val, -1) - 1;\n    return 1;\n}\n\nstatic __inline int CRYPTO_GET_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = _InterlockedOr((void *)&refcnt->val, 0);\n    return 1;\n}\n\n#  elif defined(_MSC_VER) && _MSC_VER>=1200\n\n#   define HAVE_ATOMICS 1\n\ntypedef struct {\n    volatile int val;\n} CRYPTO_REF_COUNT;\n\n#   if (defined(_M_ARM) && _M_ARM>=7 && !defined(_WIN32_WCE)) || defined(_M_ARM64)\n#    include <intrin.h>\n#    if defined(_M_ARM64) && !defined(_ARM_BARRIER_ISH)\n#     define _ARM_BARRIER_ISH _ARM64_BARRIER_ISH\n#    endif\n\nstatic __inline int CRYPTO_UP_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = _InterlockedExchangeAdd_nf(&refcnt->val, 1) + 1;\n    return 1;\n}\n\nstatic __inline int CRYPTO_DOWN_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = _InterlockedExchangeAdd_nf(&refcnt->val, -1) - 1;\n    if (*ret == 0)\n        __dmb(_ARM_BARRIER_ISH);\n    return 1;\n}\n\nstatic __inline int CRYPTO_GET_REF(CRYPTO_REF_COUNT *refcnt, int *ret)\n{\n    *ret = _InterlockedOr_nf((void *)&refcnt->val, 0);\n    return 1;\n"}], "code": "int RSA_up_ref(RSA *r)\n{\n    int i;\n\n    if (CRYPTO_UP_REF(&r->references, &i) <= 0)\n        return 0;\n\n    REF_PRINT_COUNT(\"RSA\", r);\n    REF_ASSERT_ISNT(i < 2);\n    return i > 1 ? 1 : 0;\n}\n"}, "9D43EF18D6478D03": {"calls": [{"id": "866FE93109EB4D7F", "name": "ossl_provider_up_ref", "path": "openssl/crypto/provider_core.c", "start": {"line": 476, "col": 1}, "end": {"line": 493, "col": 1}, "code": "{\n    int ref = 0;\n\n    if (CRYPTO_UP_REF(&prov->refcnt, &ref) <= 0)\n        return 0;\n\n"}], "code": "static OSSL_STORE_LOADER *new_loader(OSSL_PROVIDER *prov)\n{\n    OSSL_STORE_LOADER *loader;\n\n    if ((loader = OPENSSL_zalloc(sizeof(*loader))) == NULL\n        || !CRYPTO_NEW_REF(&loader->refcnt, 1)) {\n        OPENSSL_free(loader);\n        return NULL;\n    }\n    loader->prov = prov;\n    ossl_provider_up_ref(prov);\n\n    return loader;\n}\n"}, "F16AF07654F97FCA": {"calls": [{"id": "DD704EE2ADDE622F", "name": "ossl_safe_getenv", "path": "openssl/crypto/getenv.c", "start": {"line": 18, "col": 1}, "end": {"line": 103, "col": 1}, "code": "{\n#if defined(_WIN32) && defined(CP_UTF8) && !defined(_WIN32_WCE)\n    if (GetEnvironmentVariableW(L\"OPENSSL_WIN32_UTF8\", NULL, 0) != 0) {\n        char *val = NULL;\n        int vallen = 0;\n        WCHAR *namew = NULL;\n        WCHAR *valw = NULL;\n        DWORD envlen = 0;\n        DWORD dwFlags = MB_ERR_INVALID_CHARS;\n        int rsize, fsize;\n        UINT curacp;\n\n        curacp = GetACP();\n\n        /*\n         * For the code pages listed below, dwFlags must be set to 0.\n         * Otherwise, the function fails with ERROR_INVALID_FLAGS.\n         */\n        if (curacp == 50220 || curacp == 50221 || curacp == 50222 ||\n            curacp == 50225 || curacp == 50227 || curacp == 50229 ||\n            (57002 <= curacp && curacp <=57011) || curacp == 65000 ||\n            curacp == 42)\n            dwFlags = 0;\n\n        /* query for buffer len */\n        rsize = MultiByteToWideChar(curacp, dwFlags, name, -1, NULL, 0);\n        /* if name is valid string and can be converted to wide string */\n        if (rsize > 0)\n            namew = _malloca(rsize * sizeof(WCHAR));\n\n        if (NULL != namew) {\n            /* convert name to wide string */\n            fsize = MultiByteToWideChar(curacp, dwFlags, name, -1, namew, rsize);\n            /* if conversion is ok, then determine value string size in wchars */\n            if (fsize > 0)\n                envlen = GetEnvironmentVariableW(namew, NULL, 0);\n        }\n\n        if (envlen > 0)\n            valw = _malloca(envlen * sizeof(WCHAR));\n\n        if (NULL != valw) {\n            /* if can get env value as wide string */\n            if (GetEnvironmentVariableW(namew, valw, envlen) < envlen) {\n                /* determine value string size in utf-8 */\n                vallen = WideCharToMultiByte(CP_UTF8, 0, valw, -1, NULL, 0,\n                                             NULL, NULL);\n            }\n        }\n\n        if (vallen > 0)\n            val = OPENSSL_malloc(vallen);\n\n        if (NULL != val) {\n            /* convert value string from wide to utf-8 */\n            if (WideCharToMultiByte(CP_UTF8, 0, valw, -1, val, vallen,\n                                    NULL, NULL) == 0) {\n                OPENSSL_free(val);\n                val = NULL;\n            }\n        }\n\n        if (NULL != namew)\n            _freea(namew);\n\n        if (NULL != valw)\n            _freea(valw);\n\n        return val;\n    }\n#endif\n\n#if defined(__GLIBC__) && defined(__GLIBC_PREREQ)\n# if __GLIBC_PREREQ(2, 17)\n#  define SECURE_GETENV\n    return secure_getenv(name);\n# endif\n#endif\n\n#ifndef SECURE_GETENV\n    if (OPENSSL_issetugid())\n        return NULL;\n    return getenv(name);\n#endif\n}\n"}], "code": "const char *OSSL_HTTP_adapt_proxy(const char *proxy, const char *no_proxy,\n                                  const char *server, int use_ssl)\n{\n    /*\n     * using environment variable names, both lowercase and uppercase variants,\n     * compatible with other HTTP client implementations like wget, curl and git\n     */\n    if (proxy == NULL)\n        proxy = ossl_safe_getenv(use_ssl ? \"https_proxy\" : \"http_proxy\");\n    if (proxy == NULL)\n        proxy = ossl_safe_getenv(use_ssl ? OPENSSL_HTTP_PROXY : OPENSSL_HTTPS_PROXY);\n\n    if (proxy == NULL || *proxy == '\\0' || !use_proxy(no_proxy, server))\n        return NULL;\n    return proxy;\n}\n"}, "44DA538004568DB5": {"calls": [{"id": "8D0255E6FBAEE244", "name": "BN_rshift", "path": "openssl/crypto/bn/bn_shift.c", "start": {"line": 150, "col": 1}, "end": {"line": 165, "col": 1}, "code": "{\n    int ret = 0;\n\n    if (n < 0) {\n        ERR_raise(ERR_LIB_BN, BN_R_INVALID_SHIFT);\n        return 0;\n    }\n\n    ret = bn_rshift_fixed_top(r, a, n);\n\n    bn_correct_top(r);\n    bn_check_top(r);\n\n    return ret;\n}\n\n/*\n * In respect to shift factor the execution time is invariant of\n * |n % BN_BITS2|, but not |n / BN_BITS2|. Or in other words pre-condition\n * for constant-time-ness for sufficiently[!] zero-padded inputs is\n * |n < BN_BITS2| or |n / BN_BITS2| being non-secret.\n */\nint bn_rshift_fixed_top(BIGNUM *r, const BIGNUM *a, int n)\n{\n    int i, top, nw;\n    unsigned int lb, rb;\n    BN_ULONG *t, *f;\n    BN_ULONG l, m, mask;\n\n    bn_check_top(r);\n    bn_check_top(a);\n\n    assert(n >= 0);\n\n    nw = n / BN_BITS2;\n    if (nw >= a->top) {\n        /* shouldn't happen, but formally required */\n        BN_zero(r);\n        return 1;\n    }\n\n    rb = (unsigned int)n % BN_BITS2;\n    lb = BN_BITS2 - rb;\n    lb %= BN_BITS2;            /* say no to undefined behaviour */\n    mask = (BN_ULONG)0 - lb;   /* mask = 0 - (lb != 0) */\n    mask |= mask >> 8;\n    top = a->top - nw;\n    if (r != a && bn_wexpand(r, top) == NULL)\n        return 0;\n\n    t = &(r->d[0]);\n    f = &(a->d[nw]);\n    l = f[0];\n    for (i = 0; i < top - 1; i++) {\n        m = f[i + 1];\n        t[i] = (l >> rb) | ((m << lb) & mask);\n        l = m;\n    }\n    t[i] = l >> rb;\n\n    r->neg = a->neg;\n    r->top = top;\n    r->flags |= BN_FLG_FIXED_TOP;\n\n    return 1;\n}\n"}], "code": "static int bits2int(BIGNUM *out, int qlen_bits,\n                    const unsigned char *in, size_t inlen)\n{\n    int blen_bits = inlen * 8;\n    int shift;\n\n    if (BN_bin2bn(in, (int)inlen, out) == NULL)\n        return 0;\n\n    shift = blen_bits - qlen_bits;\n    if (shift > 0)\n        return BN_rshift(out, out, shift);\n    return 1;\n}\n"}, "769D23EEF3F25E42": {"calls": [{"id": "A4054E2DC1F6C9B1", "name": "ossl_lib_ctx_get_data", "path": "openssl/crypto/context.c", "start": {"line": 544, "col": 1}, "end": {"line": 633, "col": 1}, "code": "{\n    void *p;\n\n    ctx = ossl_lib_ctx_get_concrete(ctx);\n    if (ctx == NULL)\n        return NULL;\n\n    switch (index) {\n    case OSSL_LIB_CTX_PROPERTY_STRING_INDEX:\n        return ctx->property_string_data;\n    case OSSL_LIB_CTX_EVP_METHOD_STORE_INDEX:\n        return ctx->evp_method_store;\n    case OSSL_LIB_CTX_PROVIDER_STORE_INDEX:\n        return ctx->provider_store;\n    case OSSL_LIB_CTX_NAMEMAP_INDEX:\n        return ctx->namemap;\n    case OSSL_LIB_CTX_PROPERTY_DEFN_INDEX:\n        return ctx->property_defns;\n    case OSSL_LIB_CTX_GLOBAL_PROPERTIES:\n        return ctx->global_properties;\n    case OSSL_LIB_CTX_DRBG_INDEX:\n        return ctx->drbg;\n    case OSSL_LIB_CTX_DRBG_NONCE_INDEX:\n        return ctx->drbg_nonce;\n"}, {"id": "B7D4306A24EAD28D", "name": "lh_PROPERTY_DEFN_ELEM_retrieve", "path": "openssl/crypto/property/defn_cache.c", "start": {"line": 32, "col": 1}, "end": {"line": 32, "col": 1}, "code": "\nstatic unsigned long property_defn_hash(const PROPERTY_DEFN_ELEM *a)\n{\n    return OPENSSL_LH_strhash(a->prop);\n}\n\nstatic int property_defn_cmp(const PROPERTY_DEFN_ELEM *a,\n                             const PROPERTY_DEFN_ELEM *b)\n{\n    return strcmp(a->prop, b->prop);\n}\n\nstatic void property_defn_free(PROPERTY_DEFN_ELEM *elem)\n{\n    ossl_property_free(elem->defn);\n    OPENSSL_free(elem);\n}\n\nvoid ossl_property_defns_free(void *vproperty_defns)\n{\n    LHASH_OF(PROPERTY_DEFN_ELEM) *property_defns = vproperty_defns;\n\n    if (property_defns != NULL) {\n        lh_PROPERTY_DEFN_ELEM_doall(property_defns,\n                                    &property_defn_free);\n        lh_PROPERTY_DEFN_ELEM_free(property_defns);\n    }\n}\n\nvoid *ossl_property_defns_new(OSSL_LIB_CTX *ctx) {\n    return lh_PROPERTY_DEFN_ELEM_new(&property_defn_hash, &property_defn_cmp);\n}\n\n"}, {"id": "078B31D76C92EEDD", "name": "ossl_lib_ctx_unlock", "path": "openssl/crypto/context.c", "start": {"line": 64, "col": 1}, "end": {"line": 67, "col": 1}, "code": "{\n    return CRYPTO_THREAD_unlock(ossl_lib_ctx_get_concrete(ctx)->lock);\n}\n\nint ossl_lib_ctx_is_child(OSSL_LIB_CTX *ctx)\n{\n    ctx = ossl_lib_ctx_get_concrete(ctx);\n\n    if (ctx == NULL)\n        return 0;\n    return ctx->ischild;\n}\n\nstatic void context_deinit_objs(OSSL_LIB_CTX *ctx);\n\nstatic int context_init(OSSL_LIB_CTX *ctx)\n{\n    int exdata_done = 0;\n\n    ctx->lock = CRYPTO_THREAD_lock_new();\n    if (ctx->lock == NULL)\n        return 0;\n\n    ctx->rand_crngt_lock = CRYPTO_THREAD_lock_new();\n    if (ctx->rand_crngt_lock == NULL)\n        goto err;\n\n    /* Initialize ex_data. */\n    if (!ossl_do_ex_data_init(ctx))\n        goto err;\n    exdata_done = 1;\n\n    /* P2. We want evp_method_store to be cleaned up before the provider store */\n    ctx->evp_method_store = ossl_method_store_new(ctx);\n    if (ctx->evp_method_store == NULL)\n        goto err;\n\n#ifndef FIPS_MODULE\n    /* P2. Must be freed before the provider store is freed */\n    ctx->provider_conf = ossl_prov_conf_ctx_new(ctx);\n    if (ctx->provider_conf == NULL)\n        goto err;\n#endif\n\n    /* P2. */\n    ctx->drbg = ossl_rand_ctx_new(ctx);\n    if (ctx->drbg == NULL)\n        goto err;\n\n#ifndef FIPS_MODULE\n    /*\n     * P2. We want decoder_store/decoder_cache to be cleaned up before the\n     * provider store\n     */\n    ctx->decoder_store = ossl_method_store_new(ctx);\n    if (ctx->decoder_store == NULL)\n        goto err;\n    ctx->decoder_cache = ossl_decoder_cache_new(ctx);\n    if (ctx->decoder_cache == NULL)\n        goto err;\n\n    /* P2. We want encoder_store to be cleaned up before the provider store */\n    ctx->encoder_store = ossl_method_store_new(ctx);\n    if (ctx->encoder_store == NULL)\n        goto err;\n\n    /* P2. We want loader_store to be cleaned up before the provider store */\n    ctx->store_loader_store = ossl_method_store_new(ctx);\n"}], "code": "OSSL_PROPERTY_LIST *ossl_prop_defn_get(OSSL_LIB_CTX *ctx, const char *prop)\n{\n    PROPERTY_DEFN_ELEM elem, *r;\n    LHASH_OF(PROPERTY_DEFN_ELEM) *property_defns;\n\n    property_defns = ossl_lib_ctx_get_data(ctx,\n                                           OSSL_LIB_CTX_PROPERTY_DEFN_INDEX);\n    if (!ossl_assert(property_defns != NULL) || !ossl_lib_ctx_read_lock(ctx))\n        return NULL;\n\n    elem.prop = prop;\n    r = lh_PROPERTY_DEFN_ELEM_retrieve(property_defns, &elem);\n    ossl_lib_ctx_unlock(ctx);\n    if (r == NULL || !ossl_assert(r->defn != NULL))\n        return NULL;\n    return r->defn;\n}\n"}, "E6935D22AC352B5A": {"calls": [], "code": "OSSL_QTX *ossl_qtx_new(const OSSL_QTX_ARGS *args)\n{\n    OSSL_QTX *qtx;\n\n    if (args->mdpl < QUIC_MIN_INITIAL_DGRAM_LEN)\n        return 0;\n\n    qtx = OPENSSL_zalloc(sizeof(OSSL_QTX));\n    if (qtx == NULL)\n        return 0;\n\n    qtx->libctx             = args->libctx;\n    qtx->propq              = args->propq;\n    qtx->bio                = args->bio;\n    qtx->mdpl               = args->mdpl;\n    qtx->qlog               = args->qlog;\n    return qtx;\n}\n"}, "719446CC9497E0DF": {"calls": [], "code": "int ossl_quic_lcidm_generate_initial(QUIC_LCIDM *lcidm,\n                                     void *opaque,\n                                     QUIC_CONN_ID *initial_lcid)\n{\n    return lcidm_generate(lcidm, opaque, LCID_TYPE_INITIAL,\n                          initial_lcid, NULL);\n}\n"}, "66E66FBDB4E847D3": {"calls": [], "code": "static int obj_new_nid_unlocked(int num)\n{\n    static TSAN_QUALIFIER int new_nid = NUM_NID;\n    return tsan_add(&new_nid, num);\n}\n"}, "EBF660A72E74BE1C": {"calls": [], "code": "int ossl_quic_rxfc_init_standalone(QUIC_RXFC *rxfc,\n                                   uint64_t initial_window_size,\n                                   OSSL_TIME (*now)(void *arg),\n                                   void *now_arg)\n{\n    if (!ossl_quic_rxfc_init(rxfc, NULL,\n                             initial_window_size, initial_window_size,\n                             now, now_arg))\n        return 0;\n\n    rxfc->standalone = 1;\n    return 1;\n}\n"}, "DBCCC2264AA08AAB": {"calls": [], "code": "void ossl_quic_tx_packetiser_set_ack_tx_cb(OSSL_QUIC_TX_PACKETISER *txp,\n                                           void (*cb)(const OSSL_QUIC_FRAME_ACK *ack,\n                                                      uint32_t pn_space,\n                                                      void *arg),\n                                           void *cb_arg)\n{\n    txp->ack_tx_cb      = cb;\n    txp->ack_tx_cb_arg  = cb_arg;\n}\n"}, "4C9907D4F94F29B5": {"calls": [], "code": "void ossl_quic_channel_set_incoming_stream_auto_reject(QUIC_CHANNEL *ch,\n                                                       int enable,\n                                                       uint64_t aec)\n{\n    ch->incoming_stream_auto_reject     = (enable != 0);\n    ch->incoming_stream_auto_reject_aec = aec;\n}\n"}, "41D90C0C118C1A88": {"calls": [], "code": "static ossl_inline int ssl_has_cert(const SSL_CONNECTION *s, int idx)\n{\n    if (idx < 0 || idx >= (int)s->ssl_pkey_num)\n        return 0;\n\n    /* If RPK is enabled for this SSL... only require private key */\n    if (ssl_has_cert_type(s, TLSEXT_cert_type_rpk))\n        return s->cert->pkeys[idx].privatekey != NULL;\n\n    return s->cert->pkeys[idx].x509 != NULL\n        && s->cert->pkeys[idx].privatekey != NULL;\n}\n"}, "D24E1897A054FB1E": {"calls": [], "code": "static const SIGALG_LOOKUP *tls1_lookup_sigalg(const SSL_CONNECTION *s,\n                                               uint16_t sigalg)\n{\n    size_t i;\n    const SIGALG_LOOKUP *lu;\n\n    for (i = 0, lu = SSL_CONNECTION_GET_CTX(s)->sigalg_lookup_cache;\n         i < SSL_CONNECTION_GET_CTX(s)->tls12_sigalgs_len;\n         lu++, i++) {\n        if (lu->sigalg == sigalg) {\n            if (!lu->enabled)\n                return NULL;\n            return lu;\n        }\n    }\n    return NULL;\n}\n"}, "E255542D4F8240B0": {"calls": [], "code": "void ossl_quic_demux_set_default_handler(QUIC_DEMUX *demux,\n                                         ossl_quic_demux_cb_fn *cb,\n                                         void *cb_arg)\n{\n    demux->default_cb       = cb;\n    demux->default_cb_arg   = cb_arg;\n}\n"}, "290803D9285A97DF": {"calls": [], "code": "void ossl_sframe_list_destroy(SFRAME_LIST *fl)\n{\n    STREAM_FRAME *sf, *next_frame;\n\n    for (sf = fl->head; sf != NULL; sf = next_frame) {\n        next_frame = sf->next;\n        stream_frame_free(fl, sf);\n    }\n}\n"}, "C3F07A0B34E39E13": {"calls": [], "code": "static int get_compressed_certificate_alg(SSL_CONNECTION *sc)\n{\n#ifndef OPENSSL_NO_COMP_ALG\n    int *alg = sc->ext.compress_certificate_from_peer;\n\n    if (sc->s3.tmp.cert == NULL)\n        return TLSEXT_comp_cert_none;\n\n    for (; *alg != TLSEXT_comp_cert_none; alg++) {\n        if (sc->s3.tmp.cert->comp_cert[*alg] != NULL)\n            return *alg;\n    }\n#endif\n    return TLSEXT_comp_cert_none;\n}\n"}, "F26B5D118AC8365C": {"calls": [], "code": "OSSL_STORE_SEARCH *OSSL_STORE_SEARCH_by_name(X509_NAME *name)\n{\n    OSSL_STORE_SEARCH *search = OPENSSL_zalloc(sizeof(*search));\n\n    if (search == NULL)\n        return NULL;\n\n    search->search_type = OSSL_STORE_SEARCH_BY_NAME;\n    search->name = name;\n    return search;\n}\n"}, "9C5181DDD3BA18D0": {"calls": [], "code": "int ossl_quic_txfc_init(QUIC_TXFC *txfc, QUIC_TXFC *conn_txfc)\n{\n    if (conn_txfc != NULL && conn_txfc->parent != NULL)\n        return 0;\n\n    txfc->swm                   = 0;\n    txfc->cwm                   = 0;\n    txfc->parent                = conn_txfc;\n    txfc->has_become_blocked    = 0;\n    return 1;\n}\n"}, "ACC2F8D9A0A4B244": {"calls": [], "code": "void X509_VERIFY_PARAM_move_peername(X509_VERIFY_PARAM *to,\n                                     X509_VERIFY_PARAM *from)\n{\n    char *peername = (from != NULL) ? from->peername : NULL;\n\n    if (to->peername != peername) {\n        OPENSSL_free(to->peername);\n        to->peername = peername;\n    }\n    if (from != NULL)\n        from->peername = NULL;\n}\n"}, "8DB27DCC9D8540B9": {"calls": [{"id": "B09F2EA95EC15D65", "name": "redisConnect", "path": "redis/deps/hiredis/hiredis.c", "start": {"line": 875, "col": 1}, "end": {"line": 879, "col": 1}, "code": "    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectWithTimeout(const char *ip, int port, const struct timeval tv) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.connect_timeout = &tv;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectNonBlock(const char *ip, int port) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.options |= REDIS_OPT_NONBLOCK;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectBindNonBlock(const char *ip, int port,\n                                       const char *source_addr) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.endpoint.tcp.source_addr = source_addr;\n    options.options |= REDIS_OPT_NONBLOCK;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectBindNonBlockWithReuse(const char *ip, int port,\n                                                const char *source_addr) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.endpoint.tcp.source_addr = source_addr;\n    options.options |= REDIS_OPT_NONBLOCK|REDIS_OPT_REUSEADDR;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectUnix(const char *path) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_UNIX(&options, path);\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectUnixWithTimeout(const char *path, const struct timeval tv) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_UNIX(&options, path);\n    options.connect_timeout = &tv;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectUnixNonBlock(const char *path) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_UNIX(&options, path);\n    options.options |= REDIS_OPT_NONBLOCK;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectFd(redisFD fd) {\n    redisOptions options = {0};\n    options.type = REDIS_CONN_USERFD;\n    options.endpoint.fd = fd;\n    return redisConnectWithOptions(&options);\n}\n\n/* Set read/write timeout on a blocking socket. */\nint redisSetTimeout(redisContext *c, const struct timeval tv) {\n    if (c->flags & REDIS_BLOCK)\n        return redisContextSetTimeout(c,tv);\n    return REDIS_ERR;\n}\n\nint redisEnableKeepAliveWithInterval(redisContext *c, int interval) {\n    return redisKeepAlive(c, interval);\n}\n\n/* Enable connection KeepAlive. */\nint redisEnableKeepAlive(redisContext *c) {\n    return redisKeepAlive(c, REDIS_KEEPALIVE_INTERVAL);\n}\n\n/* Set the socket option TCP_USER_TIMEOUT. */\nint redisSetTcpUserTimeout(redisContext *c, unsigned int timeout) {\n    return redisContextSetTcpUserTimeout(c, timeout);\n}\n\n/* Set a user provided RESP3 PUSH handler and return any old one set. */\nredisPushFn *redisSetPushCallback(redisContext *c, redisPushFn *fn) {\n    redisPushFn *old = c->push_cb;\n    c->push_cb = fn;\n    return old;\n}\n\n/* Use this function to handle a read event on the descriptor. It will try\n * and read some bytes from the socket and feed them to the reply parser.\n *\n * After this function is called, you may use redisGetReplyFromReader to\n * see if there is a reply available. */\nint redisBufferRead(redisContext *c) {\n    char buf[1024*16];\n    int nread;\n\n    /* Return early when the context has seen an error. */\n    if (c->err)\n        return REDIS_ERR;\n\n    nread = c->funcs->read(c, buf, sizeof(buf));\n    if (nread < 0) {\n        return REDIS_ERR;\n    }\n    if (nread > 0 && redisReaderFeed(c->reader, buf, nread) != REDIS_OK) {\n        __redisSetError(c, c->reader->err, c->reader->errstr);\n        return REDIS_ERR;\n    }\n    return REDIS_OK;\n}\n\n/* Write the output buffer to the socket.\n *\n * Returns REDIS_OK when the buffer is empty, or (a part of) the buffer was\n * successfully written to the socket. When the buffer is empty after the\n * write operation, \"done\" is set to 1 (if given).\n *\n * Returns REDIS_ERR if an unrecoverable error occurred in the underlying\n * c->funcs->write function.\n */\nint redisBufferWrite(redisContext *c, int *done) {\n\n    /* Return early when the context has seen an error. */\n    if (c->err)\n        return REDIS_ERR;\n\n    if (hi_sdslen(c->obuf) > 0) {\n        ssize_t nwritten = c->funcs->write(c);\n        if (nwritten < 0) {\n            return REDIS_ERR;\n        } else if (nwritten > 0) {\n            if (nwritten == (ssize_t)hi_sdslen(c->obuf)) {\n                hi_sdsfree(c->obuf);\n                c->obuf = hi_sdsempty();\n                if (c->obuf == NULL)\n                    goto oom;\n            } else {\n                if (hi_sdsrange(c->obuf,nwritten,-1) < 0) goto oom;\n            }\n        }\n    }\n    if (done != NULL) *done = (hi_sdslen(c->obuf) == 0);\n    return REDIS_OK;\n\noom:\n    __redisSetError(c, REDIS_ERR_OOM, \"Out of memory\");\n    return REDIS_ERR;\n}\n\n/* Internal helper that returns 1 if the reply was a RESP3 PUSH\n * message and we handled it with a user-provided callback. */\nstatic int redisHandledPushReply(redisContext *c, void *reply) {\n    if (reply && c->push_cb && redisIsPushReply(reply)) {\n        c->push_cb(c->privdata, reply);\n        return 1;\n    }\n\n    return 0;\n}\n\n/* Get a reply from our reader or set an error in the context. */\nint redisGetReplyFromReader(redisContext *c, void **reply) {\n    if (redisReaderGetReply(c->reader, reply) == REDIS_ERR) {\n        __redisSetError(c,c->reader->err,c->reader->errstr);\n        return REDIS_ERR;\n    }\n\n    return REDIS_OK;\n}\n\n/* Internal helper to get the next reply from our reader while handling\n * any PUSH messages we encounter along the way.  This is separate from\n * redisGetReplyFromReader so as to not change its behavior. */\nstatic int redisNextInBandReplyFromReader(redisContext *c, void **reply) {\n    do {\n        if (redisGetReplyFromReader(c, reply) == REDIS_ERR)\n            return REDIS_ERR;\n    } while (redisHandledPushReply(c, *reply));\n\n    return REDIS_OK;\n}\n\nint redisGetReply(redisContext *c, void **reply) {\n    int wdone = 0;\n    void *aux = NULL;\n\n    /* Try to read pending replies */\n    if (redisNextInBandReplyFromReader(c,&aux) == REDIS_ERR)\n        return REDIS_ERR;\n\n    /* For the blocking context, flush output buffer and read reply */\n    if (aux == NULL && c->flags & REDIS_BLOCK) {\n        /* Write until done */\n        do {\n            if (redisBufferWrite(c,&wdone) == REDIS_ERR)\n                return REDIS_ERR;\n        } while (!wdone);\n\n        /* Read until there is a reply */\n        do {\n            if (redisBufferRead(c) == REDIS_ERR)\n                return REDIS_ERR;\n\n            if (redisNextInBandReplyFromReader(c,&aux) == REDIS_ERR)\n                return REDIS_ERR;\n        } while (aux == NULL);\n    }\n\n    /* Set reply or free it if we were passed NULL */\n    if (reply != NULL) {\n        *reply = aux;\n    } else {\n        freeReplyObject(aux);\n    }\n\n    return REDIS_OK;\n}\n\n\n/* Helper function for the redisAppendCommand* family of functions.\n *\n * Write a formatted command to the output buffer. When this family\n * is used, you need to call redisGetReply yourself to retrieve\n * the reply (or replies in pub/sub).\n */\nint __redisAppendCommand(redisContext *c, const char *cmd, size_t len) {\n    hisds newbuf;\n\n    newbuf = hi_sdscatlen(c->obuf,cmd,len);\n    if (newbuf == NULL) {\n        __redisSetError(c,REDIS_ERR_OOM,\"Out of memory\");\n        return REDIS_ERR;\n    }\n\n    c->obuf = newbuf;\n    return REDIS_OK;\n}\n\nint redisAppendFormattedCommand(redisContext *c, const char *cmd, size_t len) {\n\n    if (__redisAppendCommand(c, cmd, len) != REDIS_OK) {\n        return REDIS_ERR;\n    }\n\n    return REDIS_OK;\n}\n\nint redisvAppendCommand(redisContext *c, const char *format, va_list ap) {\n    char *cmd;\n    int len;\n\n    len = redisvFormatCommand(&cmd,format,ap);\n    if (len == -1) {\n        __redisSetError(c,REDIS_ERR_OOM,\"Out of memory\");\n        return REDIS_ERR;\n    } else if (len == -2) {\n        __redisSetError(c,REDIS_ERR_OTHER,\"Invalid format string\");\n        return REDIS_ERR;\n    }\n\n    if (__redisAppendCommand(c,cmd,len) != REDIS_OK) {\n        hi_free(cmd);\n        return REDIS_ERR;\n    }\n\n    hi_free(cmd);\n    return REDIS_OK;\n}\n\nint redisAppendCommand(redisContext *c, const char *format, ...) {\n    va_list ap;\n    int ret;\n\n    va_start(ap,format);\n    ret = redisvAppendCommand(c,format,ap);\n    va_end(ap);\n    return ret;\n}\n\nint redisAppendCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen) {\n    hisds cmd;\n    long long len;\n\n    len = redisFormatSdsCommandArgv(&cmd,argc,argv,argvlen);\n    if (len == -1) {\n        __redisSetError(c,REDIS_ERR_OOM,\"Out of memory\");\n        return REDIS_ERR;\n    }\n\n    if (__redisAppendCommand(c,cmd,len) != REDIS_OK) {\n        hi_sdsfree(cmd);\n        return REDIS_ERR;\n    }\n\n    hi_sdsfree(cmd);\n    return REDIS_OK;\n}\n\n/* Helper function for the redisCommand* family of functions.\n *\n * Write a formatted command to the output buffer. If the given context is\n * blocking, immediately read the reply into the \"reply\" pointer. When the\n * context is non-blocking, the \"reply\" pointer will not be used and the\n * command is simply appended to the write buffer.\n *\n * Returns the reply when a reply was successfully retrieved. Returns NULL\n * otherwise. When NULL is returned in a blocking context, the error field\n * in the context will be set.\n */\nstatic void *__redisBlockForReply(redisContext *c) {\n    void *reply;\n\n    if (c->flags & REDIS_BLOCK) {\n        if (redisGetReply(c,&reply) != REDIS_OK)\n            return NULL;\n        return reply;\n    }\n    return NULL;\n}\n\nvoid *redisvCommand(redisContext *c, const char *format, va_list ap) {\n    if (redisvAppendCommand(c,format,ap) != REDIS_OK)\n        return NULL;\n    return __redisBlockForReply(c);\n}\n\nvoid *redisCommand(redisContext *c, const char *format, ...) {\n    va_list ap;\n    va_start(ap,format);\n    void *reply = redisvCommand(c,format,ap);\n    va_end(ap);\n    return reply;\n}\n\nvoid *redisCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen) {\n    if (redisAppendCommandArgv(c,argc,argv,argvlen) != REDIS_OK)\n        return NULL;\n    return __redisBlockForReply(c);\n}\n"}, {"id": "23AA257FB6ED9A7B", "name": "redisConnectWithTimeout", "path": "redis/deps/hiredis/hiredis.c", "start": {"line": 881, "col": 1}, "end": {"line": 886, "col": 1}, "code": "    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.connect_timeout = &tv;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectNonBlock(const char *ip, int port) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.options |= REDIS_OPT_NONBLOCK;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectBindNonBlock(const char *ip, int port,\n                                       const char *source_addr) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.endpoint.tcp.source_addr = source_addr;\n    options.options |= REDIS_OPT_NONBLOCK;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectBindNonBlockWithReuse(const char *ip, int port,\n                                                const char *source_addr) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_TCP(&options, ip, port);\n    options.endpoint.tcp.source_addr = source_addr;\n    options.options |= REDIS_OPT_NONBLOCK|REDIS_OPT_REUSEADDR;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectUnix(const char *path) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_UNIX(&options, path);\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectUnixWithTimeout(const char *path, const struct timeval tv) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_UNIX(&options, path);\n    options.connect_timeout = &tv;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectUnixNonBlock(const char *path) {\n    redisOptions options = {0};\n    REDIS_OPTIONS_SET_UNIX(&options, path);\n    options.options |= REDIS_OPT_NONBLOCK;\n    return redisConnectWithOptions(&options);\n}\n\nredisContext *redisConnectFd(redisFD fd) {\n    redisOptions options = {0};\n    options.type = REDIS_CONN_USERFD;\n    options.endpoint.fd = fd;\n    return redisConnectWithOptions(&options);\n}\n\n/* Set read/write timeout on a blocking socket. */\nint redisSetTimeout(redisContext *c, const struct timeval tv) {\n    if (c->flags & REDIS_BLOCK)\n        return redisContextSetTimeout(c,tv);\n    return REDIS_ERR;\n}\n\nint redisEnableKeepAliveWithInterval(redisContext *c, int interval) {\n    return redisKeepAlive(c, interval);\n}\n\n/* Enable connection KeepAlive. */\nint redisEnableKeepAlive(redisContext *c) {\n    return redisKeepAlive(c, REDIS_KEEPALIVE_INTERVAL);\n}\n\n/* Set the socket option TCP_USER_TIMEOUT. */\nint redisSetTcpUserTimeout(redisContext *c, unsigned int timeout) {\n    return redisContextSetTcpUserTimeout(c, timeout);\n}\n\n/* Set a user provided RESP3 PUSH handler and return any old one set. */\nredisPushFn *redisSetPushCallback(redisContext *c, redisPushFn *fn) {\n    redisPushFn *old = c->push_cb;\n    c->push_cb = fn;\n    return old;\n}\n\n/* Use this function to handle a read event on the descriptor. It will try\n * and read some bytes from the socket and feed them to the reply parser.\n *\n * After this function is called, you may use redisGetReplyFromReader to\n * see if there is a reply available. */\nint redisBufferRead(redisContext *c) {\n    char buf[1024*16];\n    int nread;\n\n    /* Return early when the context has seen an error. */\n    if (c->err)\n        return REDIS_ERR;\n\n    nread = c->funcs->read(c, buf, sizeof(buf));\n    if (nread < 0) {\n        return REDIS_ERR;\n    }\n    if (nread > 0 && redisReaderFeed(c->reader, buf, nread) != REDIS_OK) {\n        __redisSetError(c, c->reader->err, c->reader->errstr);\n        return REDIS_ERR;\n    }\n    return REDIS_OK;\n}\n\n/* Write the output buffer to the socket.\n *\n * Returns REDIS_OK when the buffer is empty, or (a part of) the buffer was\n * successfully written to the socket. When the buffer is empty after the\n * write operation, \"done\" is set to 1 (if given).\n *\n * Returns REDIS_ERR if an unrecoverable error occurred in the underlying\n * c->funcs->write function.\n */\nint redisBufferWrite(redisContext *c, int *done) {\n\n    /* Return early when the context has seen an error. */\n    if (c->err)\n        return REDIS_ERR;\n\n    if (hi_sdslen(c->obuf) > 0) {\n        ssize_t nwritten = c->funcs->write(c);\n        if (nwritten < 0) {\n            return REDIS_ERR;\n        } else if (nwritten > 0) {\n            if (nwritten == (ssize_t)hi_sdslen(c->obuf)) {\n                hi_sdsfree(c->obuf);\n                c->obuf = hi_sdsempty();\n                if (c->obuf == NULL)\n                    goto oom;\n            } else {\n                if (hi_sdsrange(c->obuf,nwritten,-1) < 0) goto oom;\n            }\n        }\n    }\n    if (done != NULL) *done = (hi_sdslen(c->obuf) == 0);\n    return REDIS_OK;\n\noom:\n    __redisSetError(c, REDIS_ERR_OOM, \"Out of memory\");\n    return REDIS_ERR;\n}\n\n/* Internal helper that returns 1 if the reply was a RESP3 PUSH\n * message and we handled it with a user-provided callback. */\nstatic int redisHandledPushReply(redisContext *c, void *reply) {\n    if (reply && c->push_cb && redisIsPushReply(reply)) {\n        c->push_cb(c->privdata, reply);\n        return 1;\n    }\n\n    return 0;\n}\n\n/* Get a reply from our reader or set an error in the context. */\nint redisGetReplyFromReader(redisContext *c, void **reply) {\n    if (redisReaderGetReply(c->reader, reply) == REDIS_ERR) {\n        __redisSetError(c,c->reader->err,c->reader->errstr);\n        return REDIS_ERR;\n    }\n\n    return REDIS_OK;\n}\n\n/* Internal helper to get the next reply from our reader while handling\n * any PUSH messages we encounter along the way.  This is separate from\n * redisGetReplyFromReader so as to not change its behavior. */\nstatic int redisNextInBandReplyFromReader(redisContext *c, void **reply) {\n    do {\n        if (redisGetReplyFromReader(c, reply) == REDIS_ERR)\n            return REDIS_ERR;\n    } while (redisHandledPushReply(c, *reply));\n\n    return REDIS_OK;\n}\n\nint redisGetReply(redisContext *c, void **reply) {\n    int wdone = 0;\n    void *aux = NULL;\n\n    /* Try to read pending replies */\n    if (redisNextInBandReplyFromReader(c,&aux) == REDIS_ERR)\n        return REDIS_ERR;\n\n    /* For the blocking context, flush output buffer and read reply */\n    if (aux == NULL && c->flags & REDIS_BLOCK) {\n        /* Write until done */\n        do {\n            if (redisBufferWrite(c,&wdone) == REDIS_ERR)\n                return REDIS_ERR;\n        } while (!wdone);\n\n        /* Read until there is a reply */\n        do {\n            if (redisBufferRead(c) == REDIS_ERR)\n                return REDIS_ERR;\n\n            if (redisNextInBandReplyFromReader(c,&aux) == REDIS_ERR)\n                return REDIS_ERR;\n        } while (aux == NULL);\n    }\n\n    /* Set reply or free it if we were passed NULL */\n    if (reply != NULL) {\n        *reply = aux;\n    } else {\n        freeReplyObject(aux);\n    }\n\n    return REDIS_OK;\n}\n\n\n/* Helper function for the redisAppendCommand* family of functions.\n *\n * Write a formatted command to the output buffer. When this family\n * is used, you need to call redisGetReply yourself to retrieve\n * the reply (or replies in pub/sub).\n */\nint __redisAppendCommand(redisContext *c, const char *cmd, size_t len) {\n    hisds newbuf;\n\n    newbuf = hi_sdscatlen(c->obuf,cmd,len);\n    if (newbuf == NULL) {\n        __redisSetError(c,REDIS_ERR_OOM,\"Out of memory\");\n        return REDIS_ERR;\n    }\n\n    c->obuf = newbuf;\n    return REDIS_OK;\n}\n\nint redisAppendFormattedCommand(redisContext *c, const char *cmd, size_t len) {\n\n    if (__redisAppendCommand(c, cmd, len) != REDIS_OK) {\n        return REDIS_ERR;\n    }\n\n    return REDIS_OK;\n}\n\nint redisvAppendCommand(redisContext *c, const char *format, va_list ap) {\n    char *cmd;\n    int len;\n\n    len = redisvFormatCommand(&cmd,format,ap);\n    if (len == -1) {\n        __redisSetError(c,REDIS_ERR_OOM,\"Out of memory\");\n        return REDIS_ERR;\n    } else if (len == -2) {\n        __redisSetError(c,REDIS_ERR_OTHER,\"Invalid format string\");\n        return REDIS_ERR;\n    }\n\n    if (__redisAppendCommand(c,cmd,len) != REDIS_OK) {\n        hi_free(cmd);\n        return REDIS_ERR;\n    }\n\n    hi_free(cmd);\n    return REDIS_OK;\n}\n\nint redisAppendCommand(redisContext *c, const char *format, ...) {\n    va_list ap;\n    int ret;\n\n    va_start(ap,format);\n    ret = redisvAppendCommand(c,format,ap);\n    va_end(ap);\n    return ret;\n}\n\nint redisAppendCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen) {\n    hisds cmd;\n    long long len;\n\n    len = redisFormatSdsCommandArgv(&cmd,argc,argv,argvlen);\n    if (len == -1) {\n        __redisSetError(c,REDIS_ERR_OOM,\"Out of memory\");\n        return REDIS_ERR;\n    }\n\n    if (__redisAppendCommand(c,cmd,len) != REDIS_OK) {\n        hi_sdsfree(cmd);\n        return REDIS_ERR;\n    }\n\n    hi_sdsfree(cmd);\n    return REDIS_OK;\n}\n\n/* Helper function for the redisCommand* family of functions.\n *\n * Write a formatted command to the output buffer. If the given context is\n * blocking, immediately read the reply into the \"reply\" pointer. When the\n * context is non-blocking, the \"reply\" pointer will not be used and the\n * command is simply appended to the write buffer.\n *\n * Returns the reply when a reply was successfully retrieved. Returns NULL\n * otherwise. When NULL is returned in a blocking context, the error field\n * in the context will be set.\n */\nstatic void *__redisBlockForReply(redisContext *c) {\n    void *reply;\n\n    if (c->flags & REDIS_BLOCK) {\n        if (redisGetReply(c,&reply) != REDIS_OK)\n            return NULL;\n        return reply;\n    }\n    return NULL;\n}\n\nvoid *redisvCommand(redisContext *c, const char *format, va_list ap) {\n    if (redisvAppendCommand(c,format,ap) != REDIS_OK)\n        return NULL;\n    return __redisBlockForReply(c);\n}\n\nvoid *redisCommand(redisContext *c, const char *format, ...) {\n    va_list ap;\n    va_start(ap,format);\n    void *reply = redisvCommand(c,format,ap);\n    va_end(ap);\n    return reply;\n}\n\nvoid *redisCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen) {\n    if (redisAppendCommandArgv(c,argc,argv,argvlen) != REDIS_OK)\n        return NULL;\n    return __redisBlockForReply(c);\n}\n"}], "code": "redisContext *redisConnectWrapper(const char *ip, int port, const struct timeval tv) {\n    if (tv.tv_sec == 0 && tv.tv_usec == 0) {\n        return redisConnect(ip, port);\n    } else {\n        return redisConnectWithTimeout(ip, port, tv);\n    }\n}\n"}, "9E709D637B4875DE": {"calls": [{"id": "FE191249BFEBF363", "name": "d", "path": "redis/src/dict.c", "start": {"line": 350, "col": 46}, "end": {"line": 350, "col": 46}, "code": "    if (d->ht_used[0] != 0) return 0;\n    \n    if (d->type->rehashingCompleted) d->type->rehashingCompleted(d);\n    zfree(d->ht_table[0]);\n    /* Copy the new ht onto the old one */\n    d->ht_table[0] = d->ht_table[1];\n    d->ht_used[0] = d->ht_used[1];\n    d->ht_size_exp[0] = d->ht_size_exp[1];\n    _dictReset(d, 1);\n    d->rehashidx = -1;\n    return 1;\n}\n\n/* Performs N steps of incremental rehashing. Returns 1 if there are still\n * keys to move from the old to the new hash table, otherwise 0 is returned.\n *\n * Note that a rehashing step consists in moving a bucket (that may have more\n * than one key as we use chaining) from the old to the new hash table, however\n * since part of the hash table may be composed of empty spaces, it is not\n * guaranteed that this function will rehash even a single bucket, since it\n * will visit at max N*10 empty buckets in total, otherwise the amount of\n * work it does would be unbound and the function may block for a long time. */\nint dictRehash(dict *d, int n) {\n    int empty_visits = n*10; /* Max number of empty buckets to visit. */\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n\n    while(n-- && d->ht_used[0] != 0) {\n        /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(DICTHT_SIZE(d->ht_size_exp[0]) > (unsigned long)d->rehashidx);\n        while(d->ht_table[0][d->rehashidx] == NULL) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        /* Move all the keys in this bucket from the old to the new hash HT */\n        rehashEntriesInBucketAtIndex(d, d->rehashidx);\n        d->rehashidx++;\n    }\n\n    return !dictCheckRehashingCompleted(d);\n}\n\nlong long timeInMilliseconds(void) {\n    struct timeval tv;\n\n    gettimeofday(&tv,NULL);\n    return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);\n}\n\n/* Rehash in us+\"delta\" microseconds. The value of \"delta\" is larger\n * than 0, and is smaller than 1000 in most cases. The exact upper bound\n * depends on the running time of dictRehash(d,100).*/\nint dictRehashMicroseconds(dict *d, uint64_t us) {\n    if (d->pauserehash > 0) return 0;\n\n    monotime timer;\n    elapsedStart(&timer);\n    int rehashes = 0;\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (elapsedUs(timer) >= us) break;\n    }\n    return rehashes;\n}\n\n/* This function performs just a step of rehashing, and only if hashing has\n * not been paused for our hash table. When we have iterators in the\n * middle of a rehashing we can't mess with the two hash tables otherwise\n * some elements can be missed or duplicated.\n *\n * This function is called by common lookup or update operations in the\n * dictionary so that the hash table automatically migrates from H1 to H2\n * while it is actively used. */\nstatic void _dictRehashStep(dict *d) {\n    if (d->pauserehash == 0) dictRehash(d,1);\n}\n\n/* Performs rehashing on a single bucket. */\nint _dictBucketRehash(dict *d, uint64_t idx) {\n    if (d->pauserehash != 0) return 0;\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n    rehashEntriesInBucketAtIndex(d, idx);\n    dictCheckRehashingCompleted(d);\n    return 1;\n}\n\n/* Add an element to the target hash table */\nint dictAdd(dict *d, void *key, void *val)\n{\n    dictEntry *entry = dictAddRaw(d,key,NULL);\n\n    if (!entry) return DICT_ERR;\n    if (!d->type->no_value) dictSetVal(d, entry, val);\n    return DICT_OK;\n}\n\n/* Low level add or find:\n * This function adds the entry but instead of setting a value returns the\n * dictEntry structure to the user, that will make sure to fill the value\n * field as they wish.\n *\n * This function is also directly exposed to the user API to be called\n * mainly in order to store non-pointers inside the hash value, example:\n *\n * entry = dictAddRaw(dict,mykey,NULL);\n * if (entry != NULL) dictSetSignedIntegerVal(entry,1000);\n *\n * Return values:\n *\n * If key already exists NULL is returned, and \"*existing\" is populated\n * with the existing entry if existing is not NULL.\n *\n * If key was added, the hash entry is returned to be manipulated by the caller.\n */\ndictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)\n{\n    /* Get the position for the new key or NULL if the key already exists. */\n    void *position = dictFindPositionForInsert(d, key, existing);\n    if (!position) return NULL;\n\n    /* Dup the key if necessary. */\n    if (d->type->keyDup) key = d->type->keyDup(d, key);\n\n    return dictInsertAtPosition(d, key, position);\n}\n\n/* Adds a key in the dict's hashtable at the position returned by a preceding\n * call to dictFindPositionForInsert. This is a low level function which allows\n * splitting dictAddRaw in two parts. Normally, dictAddRaw or dictAdd should be\n * used instead. */\ndictEntry *dictInsertAtPosition(dict *d, void *key, void *position) {\n    dictEntry **bucket = position; /* It's a bucket, but the API hides that. */\n    dictEntry *entry;\n    /* If rehashing is ongoing, we insert in table 1, otherwise in table 0.\n     * Assert that the provided bucket is the right table. */\n    int htidx = dictIsRehashing(d) ? 1 : 0;\n    assert(bucket >= &d->ht_table[htidx][0] &&\n           bucket <= &d->ht_table[htidx][DICTHT_SIZE_MASK(d->ht_size_exp[htidx])]);\n    if (d->type->no_value) {\n        if (d->type->keys_are_odd && !*bucket) {\n            /* We can store the key directly in the destination bucket without the\n             * allocated entry.\n             *\n             * TODO: Add a flag 'keys_are_even' and if set, we can use this\n             * optimization for these dicts too. We can set the LSB bit when\n             * stored as a dict entry and clear it again when we need the key\n             * back. */\n            entry = key;\n            assert(entryIsKey(entry));\n        } else {\n            /* Allocate an entry without value. */\n            entry = createEntryNoValue(key, *bucket);\n        }\n    } else {\n        /* Allocate the memory and store the new entry.\n         * Insert the element in top, with the assumption that in a database\n         * system it is more likely that recently added entries are accessed\n         * more frequently. */\n        entry = zmalloc(sizeof(*entry));\n        assert(entryIsNormal(entry)); /* Check alignment of allocation */\n        entry->key = key;\n        entry->next = *bucket;\n    }\n    *bucket = entry;\n    d->ht_used[htidx]++;\n\n    return entry;\n}\n\n/* Add or Overwrite:\n * Add an element, discarding the old value if the key already exists.\n * Return 1 if the key was added from scratch, 0 if there was already an\n * element with such key and dictReplace() just performed a value update\n * operation. */\nint dictReplace(dict *d, void *key, void *val)\n{\n    dictEntry *entry, *existing;\n\n    /* Try to add the element. If the key\n     * does not exists dictAdd will succeed. */\n    entry = dictAddRaw(d,key,&existing);\n    if (entry) {\n        dictSetVal(d, entry, val);\n        return 1;\n    }\n\n    /* Set the new value and free the old one. Note that it is important\n     * to do that in this order, as the value may just be exactly the same\n     * as the previous one. In this context, think to reference counting,\n     * you want to increment (set), and then decrement (free), and not the\n     * reverse. */\n    void *oldval = dictGetVal(existing);\n    dictSetVal(d, existing, val);\n    if (d->type->valDestructor)\n        d->type->valDestructor(d, oldval);\n    return 0;\n}\n\n/* Add or Find:\n * dictAddOrFind() is simply a version of dictAddRaw() that always\n * returns the hash entry of the specified key, even if the key already\n * exists and can't be added (in that case the entry of the already\n * existing key is returned.)\n *\n * See dictAddRaw() for more information. */\ndictEntry *dictAddOrFind(dict *d, void *key) {\n    dictEntry *entry, *existing;\n    entry = dictAddRaw(d,key,&existing);\n    return entry ? entry : existing;\n}\n\n/* Search and remove an element. This is a helper function for\n * dictDelete() and dictUnlink(), please check the top comment\n * of those functions. */\nstatic dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) {\n    uint64_t h, idx;\n    dictEntry *he, *prevHe;\n    int table;\n\n    /* dict is empty */\n    if (dictSize(d) == 0) return NULL;\n\n    h = dictHashKey(d, key);\n    idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        he = d->ht_table[table][idx];\n        prevHe = NULL;\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                /* Unlink the element from the list */\n                if (prevHe)\n                    dictSetNext(prevHe, dictGetNext(he));\n                else\n                    d->ht_table[table][idx] = dictGetNext(he);\n                if (!nofree) {\n                    dictFreeUnlinkedEntry(d, he);\n                }\n                d->ht_used[table]--;\n                _dictShrinkIfNeeded(d);\n                return he;\n            }\n            prevHe = he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n    return NULL; /* not found */\n}\n\n/* Remove an element, returning DICT_OK on success or DICT_ERR if the\n * element was not found. */\nint dictDelete(dict *ht, const void *key) {\n    return dictGenericDelete(ht,key,0) ? DICT_OK : DICT_ERR;\n}\n\n/* Remove an element from the table, but without actually releasing\n * the key, value and dictionary entry. The dictionary entry is returned\n * if the element was found (and unlinked from the table), and the user\n * should later call `dictFreeUnlinkedEntry()` with it in order to release it.\n * Otherwise if the key is not found, NULL is returned.\n *\n * This function is useful when we want to remove something from the hash\n * table but want to use its value before actually deleting the entry.\n * Without this function the pattern would require two lookups:\n *\n *  entry = dictFind(...);\n *  // Do something with entry\n *  dictDelete(dictionary,entry);\n *\n * Thanks to this function it is possible to avoid this, and use\n * instead:\n *\n * entry = dictUnlink(dictionary,entry);\n * // Do something with entry\n * dictFreeUnlinkedEntry(entry); // <- This does not need to lookup again.\n */\ndictEntry *dictUnlink(dict *d, const void *key) {\n    return dictGenericDelete(d,key,1);\n}\n\n/* You need to call this function to really free the entry after a call\n * to dictUnlink(). It's safe to call this function with 'he' = NULL. */\nvoid dictFreeUnlinkedEntry(dict *d, dictEntry *he) {\n    if (he == NULL) return;\n    dictFreeKey(d, he);\n    dictFreeVal(d, he);\n    if (!entryIsKey(he)) zfree(decodeMaskedPtr(he));\n}\n\n/* Destroy an entire dictionary */\nint _dictClear(dict *d, int htidx, void(callback)(dict*)) {\n    unsigned long i;\n\n    /* Free all the elements */\n    for (i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]) && d->ht_used[htidx] > 0; i++) {\n        dictEntry *he, *nextHe;\n\n        if (callback && (i & 65535) == 0) callback(d);\n\n        if ((he = d->ht_table[htidx][i]) == NULL) continue;\n        while(he) {\n            nextHe = dictGetNext(he);\n            dictFreeKey(d, he);\n            dictFreeVal(d, he);\n            if (!entryIsKey(he)) zfree(decodeMaskedPtr(he));\n            d->ht_used[htidx]--;\n            he = nextHe;\n        }\n    }\n    /* Free the table and the allocated cache structure */\n    zfree(d->ht_table[htidx]);\n    /* Re-initialize the table */\n"}, {"id": "84E963A94F3784FC", "name": "dictType::rehashingCompleted", "path": "redis/src/dict.h", "start": {"line": 66, "col": 12}, "end": {"line": 66, "col": 12}, "code": "    /* Allow a dict to carry extra caller-defined metadata. The\n     * extra memory is initialized to 0 when a dict is allocated. */\n    size_t (*dictMetadataBytes)(dict *d);\n\n    /* Data */\n    void *userdata;\n\n    /* Flags */\n    /* The 'no_value' flag, if set, indicates that values are not used, i.e. the\n     * dict is a set. When this flag is set, it's not possible to access the\n     * value of a dictEntry and it's also impossible to use dictSetKey(). Entry\n     * metadata can also not be used. */\n    unsigned int no_value:1;\n    /* If no_value = 1 and all keys are odd (LSB=1), setting keys_are_odd = 1\n     * enables one more optimization: to store a key without an allocated\n     * dictEntry. */\n    unsigned int keys_are_odd:1;\n    /* TODO: Add a 'keys_are_even' flag and use a similar optimization if that\n     * flag is set. */\n} dictType;\n\n#define DICTHT_SIZE(exp) ((exp) == -1 ? 0 : (unsigned long)1<<(exp))\n#define DICTHT_SIZE_MASK(exp) ((exp) == -1 ? 0 : (DICTHT_SIZE(exp))-1)\n\nstruct dict {\n    dictType *type;\n\n    dictEntry **ht_table[2];\n    unsigned long ht_used[2];\n\n    long rehashidx; /* rehashing not in progress if rehashidx == -1 */\n\n    /* Keep small vars at end for optimal (minimal) struct padding */\n    int16_t pauserehash; /* If >0 rehashing is paused (<0 indicates coding error) */\n    signed char ht_size_exp[2]; /* exponent of size. (size = 1<<exp) */\n    int16_t pauseAutoResize;  /* If >0 automatic resizing is disallowed (<0 indicates coding error) */\n    void *metadata[];\n};\n\n/* If safe is set to 1 this is a safe iterator, that means, you can call\n * dictAdd, dictFind, and other functions against the dictionary even while\n * iterating. Otherwise it is a non safe iterator, and only dictNext()\n * should be called while iterating. */\ntypedef struct dictIterator {\n    dict *d;\n    long index;\n    int table, safe;\n    dictEntry *entry, *nextEntry;\n    /* unsafe iterator fingerprint for misuse detection. */\n    unsigned long long fingerprint;\n} dictIterator;\n\ntypedef struct dictStats {\n    int htidx;\n    unsigned long buckets;\n    unsigned long maxChainLen;\n    unsigned long totalChainLen;\n    unsigned long htSize;\n    unsigned long htUsed;\n    unsigned long *clvector;\n} dictStats;\n\ntypedef void (dictScanFunction)(void *privdata, const dictEntry *de);\ntypedef void *(dictDefragAllocFunction)(void *ptr);\ntypedef struct {\n    dictDefragAllocFunction *defragAlloc; /* Used for entries etc. */\n    dictDefragAllocFunction *defragKey;   /* Defrag-realloc keys (optional) */\n"}, {"id": "0099D3133B207CDF", "name": "zfree", "path": "redis/src/zmalloc.c", "start": {"line": 364, "col": 1}, "end": {"line": 380, "col": 1}, "code": ""}, {"id": "71E1A30429875546", "name": "_dictReset", "path": "redis/deps/hiredis/dict.c", "start": {"line": 66, "col": 1}, "end": {"line": 71, "col": 1}, "code": "    ht->table = NULL;\n    ht->size = 0;\n    ht->sizemask = 0;\n    ht->used = 0;\n}\n\n/* Create a new hash table */\nstatic dict *dictCreate(dictType *type, void *privDataPtr) {\n    dict *ht = hi_malloc(sizeof(*ht));\n    if (ht == NULL)\n        return NULL;\n\n    _dictInit(ht,type,privDataPtr);\n    return ht;\n}\n\n/* Initialize the hash table */\nstatic int _dictInit(dict *ht, dictType *type, void *privDataPtr) {\n    _dictReset(ht);\n    ht->type = type;\n    ht->privdata = privDataPtr;\n    return DICT_OK;\n}\n\n/* Expand or create the hashtable */\nstatic int dictExpand(dict *ht, unsigned long size) {\n    dict n; /* the new hashtable */\n    unsigned long realsize = _dictNextPower(size), i;\n\n    /* the size is invalid if it is smaller than the number of\n     * elements already inside the hashtable */\n    if (ht->used > size)\n        return DICT_ERR;\n\n    _dictInit(&n, ht->type, ht->privdata);\n    n.size = realsize;\n    n.sizemask = realsize-1;\n    n.table = hi_calloc(realsize,sizeof(dictEntry*));\n    if (n.table == NULL)\n        return DICT_ERR;\n\n    /* Copy all the elements from the old to the new table:\n     * note that if the old hash table is empty ht->size is zero,\n     * so dictExpand just creates an hash table. */\n    n.used = ht->used;\n    for (i = 0; i < ht->size && ht->used > 0; i++) {\n        dictEntry *he, *nextHe;\n\n        if (ht->table[i] == NULL) continue;\n\n        /* For each hash entry on this slot... */\n        he = ht->table[i];\n        while(he) {\n            unsigned int h;\n\n            nextHe = he->next;\n            /* Get the new element index */\n            h = dictHashKey(ht, he->key) & n.sizemask;\n            he->next = n.table[h];\n            n.table[h] = he;\n            ht->used--;\n            /* Pass to the next element */\n            he = nextHe;\n        }\n    }\n    assert(ht->used == 0);\n    hi_free(ht->table);\n\n    /* Remap the new hashtable in the old */\n    *ht = n;\n    return DICT_OK;\n}\n"}], "code": "static int dictCheckRehashingCompleted(dict *d) {\n    if (d->ht_used[0] != 0) return 0;\n    \n    if (d->type->rehashingCompleted) d->type->rehashingCompleted(d);\n    zfree(d->ht_table[0]);\n    /* Copy the new ht onto the old one */\n    d->ht_table[0] = d->ht_table[1];\n    d->ht_used[0] = d->ht_used[1];\n    d->ht_size_exp[0] = d->ht_size_exp[1];\n    _dictReset(d, 1);\n    d->rehashidx = -1;\n    return 1;\n}\n"}, "B7AED9E236EBEC25": {"calls": [{"id": "7EEA793CDAA4DB5B", "name": "fpconv_dtoa", "path": "redis/deps/fpconv/fpconv_dtoa.c", "start": {"line": 349, "col": 1}, "end": {"line": 373, "col": 1}, "code": "    char digits[18];\n\n    int str_len = 0;\n    bool neg = false;\n\n    if (get_dbits(d) & signmask) {\n        dest[0] = '-';\n        str_len++;\n        neg = true;\n    }\n\n    int spec = filter_special(d, dest + str_len);\n\n    if (spec) {\n        return str_len + spec;\n    }\n\n    int K = 0;\n    int ndigits = grisu2(d, digits, &K);\n\n    str_len += emit_digits(digits, ndigits, dest + str_len, K, neg);\n\n    return str_len;\n}\n"}], "code": "size_t rioWriteBulkDouble(rio *r, double d) {\n    char dbuf[128];\n    unsigned int dlen;\n    dlen = fpconv_dtoa(d, dbuf);\n    dbuf[dlen] = '\\0';\n    return rioWriteBulkString(r,dbuf,dlen);\n}\n"}, "917B2B41B044128F": {"calls": [{"id": "39996EA8651D2B82", "name": "sdscatfmt", "path": "redis/src/sds.c", "start": {"line": 626, "col": 1}, "end": {"line": 719, "col": 1}, "code": "    size_t initlen = sdslen(s);\n    const char *f = fmt;\n    long i;\n    va_list ap;\n\n    /* To avoid continuous reallocations, let's start with a buffer that\n     * can hold at least two times the format string itself. It's not the\n     * best heuristic but seems to work in practice. */\n    s = sdsMakeRoomFor(s, strlen(fmt)*2);\n    va_start(ap,fmt);\n    f = fmt;    /* Next format specifier byte to process. */\n    i = initlen; /* Position of the next byte to write to dest str. */\n    while(*f) {\n        char next, *str;\n        size_t l;\n        long long num;\n        unsigned long long unum;\n\n        /* Make sure there is always space for at least 1 char. */\n        if (sdsavail(s)==0) {\n            s = sdsMakeRoomFor(s,1);\n        }\n\n        switch(*f) {\n        case '%':\n            next = *(f+1);\n            if (next == '\\0') break;\n            f++;\n            switch(next) {\n            case 's':\n            case 'S':\n                str = va_arg(ap,char*);\n                l = (next == 's') ? strlen(str) : sdslen(str);\n                if (sdsavail(s) < l) {\n                    s = sdsMakeRoomFor(s,l);\n                }\n                memcpy(s+i,str,l);\n                sdsinclen(s,l);\n                i += l;\n                break;\n            case 'i':\n            case 'I':\n                if (next == 'i')\n                    num = va_arg(ap,int);\n                else\n                    num = va_arg(ap,long long);\n                {\n                    char buf[LONG_STR_SIZE];\n                    l = ll2string(buf,sizeof(buf),num);\n                    if (sdsavail(s) < l) {\n                        s = sdsMakeRoomFor(s,l);\n                    }\n                    memcpy(s+i,buf,l);\n                    sdsinclen(s,l);\n                    i += l;\n                }\n                break;\n            case 'u':\n            case 'U':\n                if (next == 'u')\n                    unum = va_arg(ap,unsigned int);\n                else\n                    unum = va_arg(ap,unsigned long long);\n                {\n                    char buf[LONG_STR_SIZE];\n                    l = ull2string(buf,sizeof(buf),unum);\n                    if (sdsavail(s) < l) {\n                        s = sdsMakeRoomFor(s,l);\n                    }\n                    memcpy(s+i,buf,l);\n                    sdsinclen(s,l);\n                    i += l;\n                }\n                break;\n            default: /* Handle %% and generally %<unknown>. */\n                s[i++] = next;\n                sdsinclen(s,1);\n                break;\n            }\n            break;\n        default:\n            s[i++] = *f;\n            sdsinclen(s,1);\n            break;\n        }\n        f++;\n    }\n    va_end(ap);\n\n    /* Add null-term */\n    s[i] = '\\0';\n    return s;\n}\n\n/* Remove the part of the string from left and from right composed just of\n * contiguous characters found in 'cset', that is a null terminated C string.\n *\n * After the call, the modified sds string is no longer valid and all the\n * references must be substituted with the new pointer returned by the call.\n *\n * Example:\n *\n * s = sdsnew(\"AA...AA.a.aa.aHelloWorld     :::\");\n * s = sdstrim(s,\"Aa. :\");\n * printf(\"%s\\n\", s);\n *\n * Output will be just \"HelloWorld\".\n */\nsds sdstrim(sds s, const char *cset) {\n    char *end, *sp, *ep;\n    size_t len;\n\n    sp = s;\n    ep = end = s+sdslen(s)-1;\n    while(sp <= end && strchr(cset, *sp)) sp++;\n    while(ep > sp && strchr(cset, *ep)) ep--;\n    len = (ep-sp)+1;\n    if (s != sp) memmove(s, sp, len);\n    s[len] = '\\0';\n    sdssetlen(s,len);\n    return s;\n}\n\n/* Changes the input string to be a subset of the original.\n * It does not release the free space in the string, so a call to\n * sdsRemoveFreeSpace may be wise after. */\nvoid sdssubstr(sds s, size_t start, size_t len) {\n    /* Clamp out of range input */\n    size_t oldlen = sdslen(s);\n    if (start >= oldlen) start = len = 0;\n    if (len > oldlen-start) len = oldlen-start;\n\n    /* Move the data */\n    if (len) memmove(s, s+start, len);\n    s[len] = 0;\n    sdssetlen(s,len);\n}\n\n/* Turn the string into a smaller (or equal) string containing only the\n * substring specified by the 'start' and 'end' indexes.\n *\n * start and end can be negative, where -1 means the last character of the\n * string, -2 the penultimate character, and so forth.\n *\n * The interval is inclusive, so the start and end characters will be part\n * of the resulting string.\n *\n * The string is modified in-place.\n *\n * NOTE: this function can be misleading and can have unexpected behaviour,\n * specifically when you want the length of the new string to be 0.\n * Having start==end will result in a string with one character.\n * please consider using sdssubstr instead.\n *\n * Example:\n *\n * s = sdsnew(\"Hello World\");\n * sdsrange(s,1,-1); => \"ello World\"\n */\nvoid sdsrange(sds s, ssize_t start, ssize_t end) {\n    size_t newlen, len = sdslen(s);\n    if (len == 0) return;\n    if (start < 0)\n        start = len + start;\n    if (end < 0)\n        end = len + end;\n    newlen = (start > end) ? 0 : (end-start)+1;\n    sdssubstr(s, start, newlen);\n}\n\n/* Apply tolower() to every character of the sds string 's'. */\nvoid sdstolower(sds s) {\n    size_t len = sdslen(s), j;\n\n    for (j = 0; j < len; j++) s[j] = tolower(s[j]);\n}\n\n/* Apply toupper() to every character of the sds string 's'. */\nvoid sdstoupper(sds s) {\n    size_t len = sdslen(s), j;\n\n    for (j = 0; j < len; j++) s[j] = toupper(s[j]);\n}\n\n/* Compare two sds strings s1 and s2 with memcmp().\n *\n * Return value:\n *\n *     positive if s1 > s2.\n *     negative if s1 < s2.\n *     0 if s1 and s2 are exactly the same binary string.\n *\n * If two strings share exactly the same prefix, but one of the two has\n * additional characters, the longer string is considered to be greater than\n * the smaller one. */\nint sdscmp(const sds s1, const sds s2) {\n    size_t l1, l2, minlen;\n    int cmp;\n\n    l1 = sdslen(s1);\n    l2 = sdslen(s2);\n    minlen = (l1 < l2) ? l1 : l2;\n    cmp = memcmp(s1,s2,minlen);\n    if (cmp == 0) return l1>l2? 1: (l1<l2? -1: 0);\n    return cmp;\n}\n\n/* Split 's' with separator in 'sep'. An array\n * of sds strings is returned. *count will be set\n * by reference to the number of tokens returned.\n *\n * On out of memory, zero length string, zero length\n * separator, NULL is returned.\n *\n * Note that 'sep' is able to split a string using\n * a multi-character separator. For example\n * sdssplit(\"foo_-_bar\",\"_-_\"); will return two\n * elements \"foo\" and \"bar\".\n *\n * This version of the function is binary-safe but\n * requires length arguments. sdssplit() is just the\n * same function but for zero-terminated strings.\n */\nsds *sdssplitlen(const char *s, ssize_t len, const char *sep, int seplen, int *count) {\n    int elements = 0, slots = 5;\n    long start = 0, j;\n    sds *tokens;\n\n    if (seplen < 1 || len <= 0) {\n        *count = 0;\n        return NULL;\n    }\n    tokens = s_malloc(sizeof(sds)*slots);\n    if (tokens == NULL) return NULL;\n\n    for (j = 0; j < (len-(seplen-1)); j++) {\n        /* make sure there is room for the next element and the final one */\n        if (slots < elements+2) {\n            sds *newtokens;\n\n            slots *= 2;\n            newtokens = s_realloc(tokens,sizeof(sds)*slots);\n            if (newtokens == NULL) goto cleanup;\n            tokens = newtokens;\n        }\n        /* search the separator */\n        if ((seplen == 1 && *(s+j) == sep[0]) || (memcmp(s+j,sep,seplen) == 0)) {\n            tokens[elements] = sdsnewlen(s+start,j-start);\n            if (tokens[elements] == NULL) goto cleanup;\n            elements++;\n            start = j+seplen;\n            j = j+seplen-1; /* skip the separator */\n        }\n    }\n    /* Add the final element. We are sure there is room in the tokens array. */\n    tokens[elements] = sdsnewlen(s+start,len-start);\n    if (tokens[elements] == NULL) goto cleanup;\n    elements++;\n    *count = elements;\n    return tokens;\n\ncleanup:\n    {\n        int i;\n        for (i = 0; i < elements; i++) sdsfree(tokens[i]);\n        s_free(tokens);\n        *count = 0;\n        return NULL;\n    }\n}\n\n/* Free the result returned by sdssplitlen(), or do nothing if 'tokens' is NULL. */\nvoid sdsfreesplitres(sds *tokens, int count) {\n    if (!tokens) return;\n    while(count--)\n        sdsfree(tokens[count]);\n    s_free(tokens);\n}\n\n/* Append to the sds string \"s\" an escaped string representation where\n * all the non-printable characters (tested with isprint()) are turned into\n * escapes in the form \"\\n\\r\\a....\" or \"\\x<hex-number>\".\n *\n * After the call, the modified sds string is no longer valid and all the\n * references must be substituted with the new pointer returned by the call. */\nsds sdscatrepr(sds s, const char *p, size_t len) {\n    s = sdsMakeRoomFor(s, len + 2);\n    s = sdscatlen(s,\"\\\"\",1);\n    while(len--) {\n        switch(*p) {\n        case '\\\\':\n        case '\"':\n            s = sdscatprintf(s,\"\\\\%c\",*p);\n            break;\n        case '\\n': s = sdscatlen(s,\"\\\\n\",2); break;\n        case '\\r': s = sdscatlen(s,\"\\\\r\",2); break;\n        case '\\t': s = sdscatlen(s,\"\\\\t\",2); break;\n        case '\\a': s = sdscatlen(s,\"\\\\a\",2); break;\n        case '\\b': s = sdscatlen(s,\"\\\\b\",2); break;\n        default:\n            if (isprint(*p))\n                s = sdscatlen(s, p, 1);\n            else\n                s = sdscatprintf(s,\"\\\\x%02x\",(unsigned char)*p);\n            break;\n        }\n        p++;\n    }\n    return sdscatlen(s,\"\\\"\",1);\n}\n\n/* Returns one if the string contains characters to be escaped\n * by sdscatrepr(), zero otherwise.\n *\n * Typically, this should be used to help protect aggregated strings in a way\n * that is compatible with sdssplitargs(). For this reason, also spaces will be\n * treated as needing an escape.\n */\nint sdsneedsrepr(const sds s) {\n    size_t len = sdslen(s);\n    const char *p = s;\n\n    while (len--) {\n        if (*p == '\\\\' || *p == '\"' || *p == '\\n' || *p == '\\r' ||\n            *p == '\\t' || *p == '\\a' || *p == '\\b' || !isprint(*p) || isspace(*p)) return 1;\n        p++;\n    }\n\n    return 0;\n}\n\n/* Helper function for sdssplitargs() that returns non zero if 'c'\n * is a valid hex digit. */\nint is_hex_digit(char c) {\n    return (c >= '0' && c <= '9') || (c >= 'a' && c <= 'f') ||\n           (c >= 'A' && c <= 'F');\n}\n\n/* Helper function for sdssplitargs() that converts a hex digit into an\n * integer from 0 to 15 */\nint hex_digit_to_int(char c) {\n    switch(c) {\n    case '0': return 0;\n    case '1': return 1;\n    case '2': return 2;\n    case '3': return 3;\n    case '4': return 4;\n    case '5': return 5;\n    case '6': return 6;\n    case '7': return 7;\n    case '8': return 8;\n    case '9': return 9;\n    case 'a': case 'A': return 10;\n    case 'b': case 'B': return 11;\n    case 'c': case 'C': return 12;\n    case 'd': case 'D': return 13;\n    case 'e': case 'E': return 14;\n    case 'f': case 'F': return 15;\n    default: return 0;\n    }\n}\n\n/* Split a line into arguments, where every argument can be in the\n * following programming-language REPL-alike form:\n *\n * foo bar \"newline are supported\\n\" and \"\\xff\\x00otherstuff\"\n *\n * The number of arguments is stored into *argc, and an array\n * of sds is returned.\n *\n * The caller should free the resulting array of sds strings with\n * sdsfreesplitres().\n *\n * Note that sdscatrepr() is able to convert back a string into\n * a quoted string in the same format sdssplitargs() is able to parse.\n *\n * The function returns the allocated tokens on success, even when the\n * input string is empty, or NULL if the input contains unbalanced\n * quotes or closed quotes followed by non space characters\n * as in: \"foo\"bar or \"foo'\n */\nsds *sdssplitargs(const char *line, int *argc) {\n    const char *p = line;\n    char *current = NULL;\n    char **vector = NULL;\n\n    *argc = 0;\n    while(1) {\n        /* skip blanks */\n        while(*p && isspace(*p)) p++;\n        if (*p) {\n            /* get a token */\n            int inq=0;  /* set to 1 if we are in \"quotes\" */\n            int insq=0; /* set to 1 if we are in 'single quotes' */\n            int done=0;\n\n            if (current == NULL) current = sdsempty();\n            while(!done) {\n                if (inq) {\n                    if (*p == '\\\\' && *(p+1) == 'x' &&\n                                             is_hex_digit(*(p+2)) &&\n                                             is_hex_digit(*(p+3)))\n                    {\n                        unsigned char byte;\n\n                        byte = (hex_digit_to_int(*(p+2))*16)+\n                                hex_digit_to_int(*(p+3));\n                        current = sdscatlen(current,(char*)&byte,1);\n                        p += 3;\n                    } else if (*p == '\\\\' && *(p+1)) {\n                        char c;\n\n                        p++;\n                        switch(*p) {\n                        case 'n': c = '\\n'; break;\n                        case 'r': c = '\\r'; break;\n                        case 't': c = '\\t'; break;\n                        case 'b': c = '\\b'; break;\n                        case 'a': c = '\\a'; break;\n                        default: c = *p; break;\n                        }\n                        current = sdscatlen(current,&c,1);\n                    } else if (*p == '\"') {\n                        /* closing quote must be followed by a space or\n                         * nothing at all. */\n                        if (*(p+1) && !isspace(*(p+1))) goto err;\n                        done=1;\n                    } else if (!*p) {\n                        /* unterminated quotes */\n                        goto err;\n                    } else {\n                        current = sdscatlen(current,p,1);\n                    }\n                } else if (insq) {\n                    if (*p == '\\\\' && *(p+1) == '\\'') {\n                        p++;\n                        current = sdscatlen(current,\"'\",1);\n                    } else if (*p == '\\'') {\n                        /* closing quote must be followed by a space or\n                         * nothing at all. */\n                        if (*(p+1) && !isspace(*(p+1))) goto err;\n                        done=1;\n                    } else if (!*p) {\n                        /* unterminated quotes */\n                        goto err;\n                    } else {\n                        current = sdscatlen(current,p,1);\n                    }\n                } else {\n                    switch(*p) {\n                    case ' ':\n                    case '\\n':\n                    case '\\r':\n                    case '\\t':\n                    case '\\0':\n                        done=1;\n                        break;\n                    case '\"':\n                        inq=1;\n                        break;\n                    case '\\'':\n                        insq=1;\n                        break;\n                    default:\n                        current = sdscatlen(current,p,1);\n                        break;\n                    }\n                }\n                if (*p) p++;\n            }\n            /* add the token to the vector */\n            vector = s_realloc(vector,((*argc)+1)*sizeof(char*));\n            vector[*argc] = current;\n            (*argc)++;\n            current = NULL;\n        } else {\n            /* Even on empty input string return something not NULL. */\n            if (vector == NULL) vector = s_malloc(sizeof(void*));\n            return vector;\n        }\n    }\n\nerr:\n    while((*argc)--)\n        sdsfree(vector[*argc]);\n    s_free(vector);\n    if (current) sdsfree(current);\n    *argc = 0;\n    return NULL;\n}\n\n/* Modify the string substituting all the occurrences of the set of\n * characters specified in the 'from' string to the corresponding character\n * in the 'to' array.\n *\n * For instance: sdsmapchars(mystring, \"ho\", \"01\", 2)\n * will have the effect of turning the string \"hello\" into \"0ell1\".\n *\n * The function returns the sds string pointer, that is always the same\n * as the input pointer since no resize is needed. */\nsds sdsmapchars(sds s, const char *from, const char *to, size_t setlen) {\n    size_t j, i, l = sdslen(s);\n\n    for (j = 0; j < l; j++) {\n        for (i = 0; i < setlen; i++) {\n            if (s[j] == from[i]) {\n                s[j] = to[i];\n                break;\n            }\n        }\n    }\n    return s;\n}\n\n/* Join an array of C strings using the specified separator (also a C string).\n * Returns the result as an sds string. */\nsds sdsjoin(char **argv, int argc, char *sep) {\n    sds join = sdsempty();\n    int j;\n\n    for (j = 0; j < argc; j++) {\n        join = sdscat(join, argv[j]);\n        if (j != argc-1) join = sdscat(join,sep);\n    }\n    return join;\n}\n\n/* Like sdsjoin, but joins an array of SDS strings. */\nsds sdsjoinsds(sds *argv, int argc, const char *sep, size_t seplen) {\n    sds join = sdsempty();\n    int j;\n\n    for (j = 0; j < argc; j++) {\n        join = sdscatsds(join, argv[j]);\n        if (j != argc-1) join = sdscatlen(join,sep,seplen);\n    }\n    return join;\n}\n\n/* Wrappers to the allocators used by SDS. Note that SDS will actually\n * just use the macros defined into sdsalloc.h in order to avoid to pay\n * the overhead of function calls. Here we define these wrappers only for\n * the programs SDS is linked to, if they want to touch the SDS internals\n * even if they use a different allocator. */\nvoid *sds_malloc(size_t size) { return s_malloc(size); }\nvoid *sds_realloc(void *ptr, size_t size) { return s_realloc(ptr,size); }\nvoid sds_free(void *ptr) { s_free(ptr); }\n\n/* Perform expansion of a template string and return the result as a newly\n * allocated sds.\n *\n * Template variables are specified using curly brackets, e.g. {variable}.\n * An opening bracket can be quoted by repeating it twice.\n */\nsds sdstemplate(const char *template, sdstemplate_callback_t cb_func, void *cb_arg)\n{\n    sds res = sdsempty();\n    const char *p = template;\n\n    while (*p) {\n        /* Find next variable, copy everything until there */\n        const char *sv = strchr(p, '{');\n        if (!sv) {\n            /* Not found: copy till rest of template and stop */\n            res = sdscat(res, p);\n            break;\n        } else if (sv > p) {\n            /* Found: copy anything up to the beginning of the variable */\n            res = sdscatlen(res, p, sv - p);\n        }\n\n        /* Skip into variable name, handle premature end or quoting */\n        sv++;\n        if (!*sv) goto error;       /* Premature end of template */\n        if (*sv == '{') {\n            /* Quoted '{' */\n            p = sv + 1;\n            res = sdscat(res, \"{\");\n            continue;\n        }\n\n        /* Find end of variable name, handle premature end of template */\n        const char *ev = strchr(sv, '}');\n        if (!ev) goto error;\n\n        /* Pass variable name to callback and obtain value. If callback failed,\n         * abort. */\n        sds varname = sdsnewlen(sv, ev - sv);\n        sds value = cb_func(varname, cb_arg);\n        sdsfree(varname);\n        if (!value) goto error;\n\n        /* Append value to result and continue */\n        res = sdscat(res, value);\n        sdsfree(value);\n        p = ev + 1;\n    }\n\n    return res;\n\nerror:\n    sdsfree(res);\n    return NULL;\n}\n\n#ifdef REDIS_TEST\n#include <stdio.h>\n#include <limits.h>\n#include \"testhelp.h\"\n\n#define UNUSED(x) (void)(x)\n\nstatic sds sdsTestTemplateCallback(sds varname, void *arg) {\n    UNUSED(arg);\n    static const char *_var1 = \"variable1\";\n    static const char *_var2 = \"variable2\";\n\n    if (!strcmp(varname, _var1)) return sdsnew(\"value1\");\n    else if (!strcmp(varname, _var2)) return sdsnew(\"value2\");\n    else return NULL;\n}\n\nint sdsTest(int argc, char **argv, int flags) {\n    UNUSED(argc);\n    UNUSED(argv);\n    UNUSED(flags);\n\n    {\n        sds x = sdsnew(\"foo\"), y;\n\n        test_cond(\"Create a string and obtain the length\",\n            sdslen(x) == 3 && memcmp(x,\"foo\\0\",4) == 0);\n\n        sdsfree(x);\n        x = sdsnewlen(\"foo\",2);\n        test_cond(\"Create a string with specified length\",\n            sdslen(x) == 2 && memcmp(x,\"fo\\0\",3) == 0);\n\n        x = sdscat(x,\"bar\");\n        test_cond(\"Strings concatenation\",\n            sdslen(x) == 5 && memcmp(x,\"fobar\\0\",6) == 0);\n\n        x = sdscpy(x,\"a\");\n        test_cond(\"sdscpy() against an originally longer string\",\n            sdslen(x) == 1 && memcmp(x,\"a\\0\",2) == 0);\n\n        x = sdscpy(x,\"xyzxxxxxxxxxxyyyyyyyyyykkkkkkkkkk\");\n        test_cond(\"sdscpy() against an originally shorter string\",\n            sdslen(x) == 33 &&\n            memcmp(x,\"xyzxxxxxxxxxxyyyyyyyyyykkkkkkkkkk\\0\",33) == 0);\n\n        sdsfree(x);\n        x = sdscatprintf(sdsempty(),\"%d\",123);\n        test_cond(\"sdscatprintf() seems working in the base case\",\n            sdslen(x) == 3 && memcmp(x,\"123\\0\",4) == 0);\n\n        sdsfree(x);\n        x = sdscatprintf(sdsempty(),\"a%cb\",0);\n        test_cond(\"sdscatprintf() seems working with \\\\0 inside of result\",\n            sdslen(x) == 3 && memcmp(x,\"a\\0\"\"b\\0\",4) == 0);\n\n        {\n            sdsfree(x);\n            char etalon[1024*1024];\n            for (size_t i = 0; i < sizeof(etalon); i++) {\n                etalon[i] = '0';\n            }\n            x = sdscatprintf(sdsempty(),\"%0*d\",(int)sizeof(etalon),0);\n            test_cond(\"sdscatprintf() can print 1MB\",\n                sdslen(x) == sizeof(etalon) && memcmp(x,etalon,sizeof(etalon)) == 0);\n        }\n\n        sdsfree(x);\n        x = sdsnew(\"--\");\n        x = sdscatfmt(x, \"Hello %s World %I,%I--\", \"Hi!\", LLONG_MIN,LLONG_MAX);\n        test_cond(\"sdscatfmt() seems working in the base case\",\n            sdslen(x) == 60 &&\n            memcmp(x,\"--Hello Hi! World -9223372036854775808,\"\n                     \"9223372036854775807--\",60) == 0);\n        printf(\"[%s]\\n\",x);\n\n        sdsfree(x);\n        x = sdsnew(\"--\");\n        x = sdscatfmt(x, \"%u,%U--\", UINT_MAX, ULLONG_MAX);\n        test_cond(\"sdscatfmt() seems working with unsigned numbers\",\n            sdslen(x) == 35 &&\n            memcmp(x,\"--4294967295,18446744073709551615--\",35) == 0);\n\n        sdsfree(x);\n        x = sdsnew(\" x \");\n        sdstrim(x,\" x\");\n        test_cond(\"sdstrim() works when all chars match\",\n            sdslen(x) == 0);\n\n        sdsfree(x);\n        x = sdsnew(\" x \");\n        sdstrim(x,\" \");\n        test_cond(\"sdstrim() works when a single char remains\",\n            sdslen(x) == 1 && x[0] == 'x');\n\n        sdsfree(x);\n        x = sdsnew(\"xxciaoyyy\");\n        sdstrim(x,\"xy\");\n        test_cond(\"sdstrim() correctly trims characters\",\n            sdslen(x) == 4 && memcmp(x,\"ciao\\0\",5) == 0);\n\n        y = sdsdup(x);\n        sdsrange(y,1,1);\n        test_cond(\"sdsrange(...,1,1)\",\n            sdslen(y) == 1 && memcmp(y,\"i\\0\",2) == 0);\n\n        sdsfree(y);\n        y = sdsdup(x);\n        sdsrange(y,1,-1);\n        test_cond(\"sdsrange(...,1,-1)\",\n            sdslen(y) == 3 && memcmp(y,\"iao\\0\",4) == 0);\n\n        sdsfree(y);\n        y = sdsdup(x);\n        sdsrange(y,-2,-1);\n"}, {"id": "53286A9E8F92B8FF", "name": "sdscatprintf", "path": "redis/src/sds.c", "start": {"line": 601, "col": 1}, "end": {"line": 608, "col": 1}, "code": "    va_list ap;\n    char *t;\n    va_start(ap, fmt);\n    t = sdscatvprintf(s,fmt,ap);\n    va_end(ap);\n    return t;\n}\n\n/* This function is similar to sdscatprintf, but much faster as it does\n * not rely on sprintf() family functions implemented by the libc that\n * are often very slow. Moreover directly handling the sds string as\n * new data is concatenated provides a performance improvement.\n *\n * However this function only handles an incompatible subset of printf-alike\n * format specifiers:\n *\n * %s - C String\n * %S - SDS string\n * %i - signed int\n * %I - 64 bit signed integer (long long, int64_t)\n * %u - unsigned int\n * %U - 64 bit unsigned integer (unsigned long long, uint64_t)\n * %% - Verbatim \"%\" character.\n */\nsds sdscatfmt(sds s, char const *fmt, ...) {\n    size_t initlen = sdslen(s);\n    const char *f = fmt;\n    long i;\n    va_list ap;\n\n    /* To avoid continuous reallocations, let's start with a buffer that\n     * can hold at least two times the format string itself. It's not the\n     * best heuristic but seems to work in practice. */\n    s = sdsMakeRoomFor(s, strlen(fmt)*2);\n    va_start(ap,fmt);\n    f = fmt;    /* Next format specifier byte to process. */\n    i = initlen; /* Position of the next byte to write to dest str. */\n    while(*f) {\n        char next, *str;\n        size_t l;\n        long long num;\n        unsigned long long unum;\n\n        /* Make sure there is always space for at least 1 char. */\n        if (sdsavail(s)==0) {\n            s = sdsMakeRoomFor(s,1);\n        }\n\n        switch(*f) {\n        case '%':\n            next = *(f+1);\n            if (next == '\\0') break;\n            f++;\n            switch(next) {\n            case 's':\n            case 'S':\n                str = va_arg(ap,char*);\n                l = (next == 's') ? strlen(str) : sdslen(str);\n                if (sdsavail(s) < l) {\n                    s = sdsMakeRoomFor(s,l);\n                }\n                memcpy(s+i,str,l);\n                sdsinclen(s,l);\n                i += l;\n                break;\n            case 'i':\n            case 'I':\n                if (next == 'i')\n                    num = va_arg(ap,int);\n                else\n                    num = va_arg(ap,long long);\n                {\n                    char buf[LONG_STR_SIZE];\n                    l = ll2string(buf,sizeof(buf),num);\n                    if (sdsavail(s) < l) {\n                        s = sdsMakeRoomFor(s,l);\n                    }\n                    memcpy(s+i,buf,l);\n                    sdsinclen(s,l);\n                    i += l;\n                }\n                break;\n            case 'u':\n            case 'U':\n                if (next == 'u')\n                    unum = va_arg(ap,unsigned int);\n                else\n                    unum = va_arg(ap,unsigned long long);\n                {\n                    char buf[LONG_STR_SIZE];\n                    l = ull2string(buf,sizeof(buf),unum);\n                    if (sdsavail(s) < l) {\n                        s = sdsMakeRoomFor(s,l);\n                    }\n                    memcpy(s+i,buf,l);\n                    sdsinclen(s,l);\n                    i += l;\n                }\n                break;\n            default: /* Handle %% and generally %<unknown>. */\n                s[i++] = next;\n                sdsinclen(s,1);\n                break;\n            }\n            break;\n        default:\n            s[i++] = *f;\n            sdsinclen(s,1);\n            break;\n        }\n        f++;\n    }\n    va_end(ap);\n\n    /* Add null-term */\n    s[i] = '\\0';\n    return s;\n}\n\n/* Remove the part of the string from left and from right composed just of\n * contiguous characters found in 'cset', that is a null terminated C string.\n *\n * After the call, the modified sds string is no longer valid and all the\n * references must be substituted with the new pointer returned by the call.\n *\n * Example:\n *\n * s = sdsnew(\"AA...AA.a.aa.aHelloWorld     :::\");\n * s = sdstrim(s,\"Aa. :\");\n * printf(\"%s\\n\", s);\n *\n * Output will be just \"HelloWorld\".\n */\nsds sdstrim(sds s, const char *cset) {\n    char *end, *sp, *ep;\n    size_t len;\n\n    sp = s;\n    ep = end = s+sdslen(s)-1;\n    while(sp <= end && strchr(cset, *sp)) sp++;\n    while(ep > sp && strchr(cset, *ep)) ep--;\n    len = (ep-sp)+1;\n    if (s != sp) memmove(s, sp, len);\n    s[len] = '\\0';\n    sdssetlen(s,len);\n    return s;\n}\n\n/* Changes the input string to be a subset of the original.\n * It does not release the free space in the string, so a call to\n * sdsRemoveFreeSpace may be wise after. */\nvoid sdssubstr(sds s, size_t start, size_t len) {\n    /* Clamp out of range input */\n    size_t oldlen = sdslen(s);\n    if (start >= oldlen) start = len = 0;\n    if (len > oldlen-start) len = oldlen-start;\n\n    /* Move the data */\n    if (len) memmove(s, s+start, len);\n    s[len] = 0;\n    sdssetlen(s,len);\n}\n\n/* Turn the string into a smaller (or equal) string containing only the\n * substring specified by the 'start' and 'end' indexes.\n *\n * start and end can be negative, where -1 means the last character of the\n * string, -2 the penultimate character, and so forth.\n *\n * The interval is inclusive, so the start and end characters will be part\n * of the resulting string.\n *\n * The string is modified in-place.\n *\n * NOTE: this function can be misleading and can have unexpected behaviour,\n * specifically when you want the length of the new string to be 0.\n * Having start==end will result in a string with one character.\n * please consider using sdssubstr instead.\n *\n * Example:\n *\n * s = sdsnew(\"Hello World\");\n * sdsrange(s,1,-1); => \"ello World\"\n */\nvoid sdsrange(sds s, ssize_t start, ssize_t end) {\n    size_t newlen, len = sdslen(s);\n    if (len == 0) return;\n    if (start < 0)\n        start = len + start;\n    if (end < 0)\n        end = len + end;\n    newlen = (start > end) ? 0 : (end-start)+1;\n    sdssubstr(s, start, newlen);\n}\n\n/* Apply tolower() to every character of the sds string 's'. */\nvoid sdstolower(sds s) {\n    size_t len = sdslen(s), j;\n\n    for (j = 0; j < len; j++) s[j] = tolower(s[j]);\n}\n\n/* Apply toupper() to every character of the sds string 's'. */\nvoid sdstoupper(sds s) {\n    size_t len = sdslen(s), j;\n\n    for (j = 0; j < len; j++) s[j] = toupper(s[j]);\n}\n\n/* Compare two sds strings s1 and s2 with memcmp().\n *\n * Return value:\n *\n *     positive if s1 > s2.\n *     negative if s1 < s2.\n *     0 if s1 and s2 are exactly the same binary string.\n *\n * If two strings share exactly the same prefix, but one of the two has\n * additional characters, the longer string is considered to be greater than\n * the smaller one. */\nint sdscmp(const sds s1, const sds s2) {\n    size_t l1, l2, minlen;\n    int cmp;\n\n    l1 = sdslen(s1);\n    l2 = sdslen(s2);\n    minlen = (l1 < l2) ? l1 : l2;\n    cmp = memcmp(s1,s2,minlen);\n    if (cmp == 0) return l1>l2? 1: (l1<l2? -1: 0);\n    return cmp;\n}\n\n/* Split 's' with separator in 'sep'. An array\n * of sds strings is returned. *count will be set\n * by reference to the number of tokens returned.\n *\n * On out of memory, zero length string, zero length\n * separator, NULL is returned.\n *\n * Note that 'sep' is able to split a string using\n * a multi-character separator. For example\n * sdssplit(\"foo_-_bar\",\"_-_\"); will return two\n * elements \"foo\" and \"bar\".\n *\n * This version of the function is binary-safe but\n * requires length arguments. sdssplit() is just the\n * same function but for zero-terminated strings.\n */\nsds *sdssplitlen(const char *s, ssize_t len, const char *sep, int seplen, int *count) {\n    int elements = 0, slots = 5;\n    long start = 0, j;\n    sds *tokens;\n\n    if (seplen < 1 || len <= 0) {\n        *count = 0;\n        return NULL;\n    }\n    tokens = s_malloc(sizeof(sds)*slots);\n    if (tokens == NULL) return NULL;\n\n    for (j = 0; j < (len-(seplen-1)); j++) {\n        /* make sure there is room for the next element and the final one */\n        if (slots < elements+2) {\n            sds *newtokens;\n\n            slots *= 2;\n            newtokens = s_realloc(tokens,sizeof(sds)*slots);\n            if (newtokens == NULL) goto cleanup;\n            tokens = newtokens;\n        }\n        /* search the separator */\n        if ((seplen == 1 && *(s+j) == sep[0]) || (memcmp(s+j,sep,seplen) == 0)) {\n            tokens[elements] = sdsnewlen(s+start,j-start);\n            if (tokens[elements] == NULL) goto cleanup;\n            elements++;\n            start = j+seplen;\n            j = j+seplen-1; /* skip the separator */\n        }\n    }\n    /* Add the final element. We are sure there is room in the tokens array. */\n    tokens[elements] = sdsnewlen(s+start,len-start);\n    if (tokens[elements] == NULL) goto cleanup;\n    elements++;\n    *count = elements;\n    return tokens;\n\ncleanup:\n    {\n        int i;\n        for (i = 0; i < elements; i++) sdsfree(tokens[i]);\n        s_free(tokens);\n        *count = 0;\n        return NULL;\n    }\n}\n\n/* Free the result returned by sdssplitlen(), or do nothing if 'tokens' is NULL. */\nvoid sdsfreesplitres(sds *tokens, int count) {\n    if (!tokens) return;\n    while(count--)\n        sdsfree(tokens[count]);\n    s_free(tokens);\n}\n\n/* Append to the sds string \"s\" an escaped string representation where\n * all the non-printable characters (tested with isprint()) are turned into\n * escapes in the form \"\\n\\r\\a....\" or \"\\x<hex-number>\".\n *\n * After the call, the modified sds string is no longer valid and all the\n * references must be substituted with the new pointer returned by the call. */\nsds sdscatrepr(sds s, const char *p, size_t len) {\n    s = sdsMakeRoomFor(s, len + 2);\n    s = sdscatlen(s,\"\\\"\",1);\n    while(len--) {\n        switch(*p) {\n        case '\\\\':\n        case '\"':\n            s = sdscatprintf(s,\"\\\\%c\",*p);\n            break;\n        case '\\n': s = sdscatlen(s,\"\\\\n\",2); break;\n        case '\\r': s = sdscatlen(s,\"\\\\r\",2); break;\n        case '\\t': s = sdscatlen(s,\"\\\\t\",2); break;\n        case '\\a': s = sdscatlen(s,\"\\\\a\",2); break;\n        case '\\b': s = sdscatlen(s,\"\\\\b\",2); break;\n        default:\n            if (isprint(*p))\n                s = sdscatlen(s, p, 1);\n            else\n                s = sdscatprintf(s,\"\\\\x%02x\",(unsigned char)*p);\n            break;\n        }\n        p++;\n    }\n    return sdscatlen(s,\"\\\"\",1);\n}\n\n/* Returns one if the string contains characters to be escaped\n * by sdscatrepr(), zero otherwise.\n *\n * Typically, this should be used to help protect aggregated strings in a way\n * that is compatible with sdssplitargs(). For this reason, also spaces will be\n * treated as needing an escape.\n */\nint sdsneedsrepr(const sds s) {\n    size_t len = sdslen(s);\n    const char *p = s;\n\n    while (len--) {\n        if (*p == '\\\\' || *p == '\"' || *p == '\\n' || *p == '\\r' ||\n            *p == '\\t' || *p == '\\a' || *p == '\\b' || !isprint(*p) || isspace(*p)) return 1;\n        p++;\n    }\n\n    return 0;\n}\n\n/* Helper function for sdssplitargs() that returns non zero if 'c'\n * is a valid hex digit. */\nint is_hex_digit(char c) {\n    return (c >= '0' && c <= '9') || (c >= 'a' && c <= 'f') ||\n           (c >= 'A' && c <= 'F');\n}\n\n/* Helper function for sdssplitargs() that converts a hex digit into an\n * integer from 0 to 15 */\nint hex_digit_to_int(char c) {\n    switch(c) {\n    case '0': return 0;\n    case '1': return 1;\n    case '2': return 2;\n    case '3': return 3;\n    case '4': return 4;\n    case '5': return 5;\n    case '6': return 6;\n    case '7': return 7;\n    case '8': return 8;\n    case '9': return 9;\n    case 'a': case 'A': return 10;\n    case 'b': case 'B': return 11;\n    case 'c': case 'C': return 12;\n    case 'd': case 'D': return 13;\n    case 'e': case 'E': return 14;\n    case 'f': case 'F': return 15;\n    default: return 0;\n    }\n}\n\n/* Split a line into arguments, where every argument can be in the\n * following programming-language REPL-alike form:\n *\n * foo bar \"newline are supported\\n\" and \"\\xff\\x00otherstuff\"\n *\n * The number of arguments is stored into *argc, and an array\n * of sds is returned.\n *\n * The caller should free the resulting array of sds strings with\n * sdsfreesplitres().\n *\n * Note that sdscatrepr() is able to convert back a string into\n * a quoted string in the same format sdssplitargs() is able to parse.\n *\n * The function returns the allocated tokens on success, even when the\n * input string is empty, or NULL if the input contains unbalanced\n * quotes or closed quotes followed by non space characters\n * as in: \"foo\"bar or \"foo'\n */\nsds *sdssplitargs(const char *line, int *argc) {\n    const char *p = line;\n    char *current = NULL;\n    char **vector = NULL;\n\n    *argc = 0;\n    while(1) {\n        /* skip blanks */\n        while(*p && isspace(*p)) p++;\n        if (*p) {\n            /* get a token */\n            int inq=0;  /* set to 1 if we are in \"quotes\" */\n            int insq=0; /* set to 1 if we are in 'single quotes' */\n            int done=0;\n\n            if (current == NULL) current = sdsempty();\n            while(!done) {\n                if (inq) {\n                    if (*p == '\\\\' && *(p+1) == 'x' &&\n                                             is_hex_digit(*(p+2)) &&\n                                             is_hex_digit(*(p+3)))\n                    {\n                        unsigned char byte;\n\n                        byte = (hex_digit_to_int(*(p+2))*16)+\n                                hex_digit_to_int(*(p+3));\n                        current = sdscatlen(current,(char*)&byte,1);\n                        p += 3;\n                    } else if (*p == '\\\\' && *(p+1)) {\n                        char c;\n\n                        p++;\n                        switch(*p) {\n                        case 'n': c = '\\n'; break;\n                        case 'r': c = '\\r'; break;\n                        case 't': c = '\\t'; break;\n                        case 'b': c = '\\b'; break;\n                        case 'a': c = '\\a'; break;\n                        default: c = *p; break;\n                        }\n                        current = sdscatlen(current,&c,1);\n                    } else if (*p == '\"') {\n                        /* closing quote must be followed by a space or\n                         * nothing at all. */\n                        if (*(p+1) && !isspace(*(p+1))) goto err;\n                        done=1;\n                    } else if (!*p) {\n                        /* unterminated quotes */\n                        goto err;\n                    } else {\n                        current = sdscatlen(current,p,1);\n                    }\n                } else if (insq) {\n                    if (*p == '\\\\' && *(p+1) == '\\'') {\n                        p++;\n                        current = sdscatlen(current,\"'\",1);\n                    } else if (*p == '\\'') {\n                        /* closing quote must be followed by a space or\n                         * nothing at all. */\n                        if (*(p+1) && !isspace(*(p+1))) goto err;\n                        done=1;\n                    } else if (!*p) {\n                        /* unterminated quotes */\n                        goto err;\n                    } else {\n                        current = sdscatlen(current,p,1);\n                    }\n                } else {\n                    switch(*p) {\n                    case ' ':\n                    case '\\n':\n                    case '\\r':\n                    case '\\t':\n                    case '\\0':\n                        done=1;\n                        break;\n                    case '\"':\n                        inq=1;\n                        break;\n                    case '\\'':\n                        insq=1;\n                        break;\n                    default:\n                        current = sdscatlen(current,p,1);\n                        break;\n                    }\n                }\n                if (*p) p++;\n            }\n            /* add the token to the vector */\n            vector = s_realloc(vector,((*argc)+1)*sizeof(char*));\n            vector[*argc] = current;\n            (*argc)++;\n            current = NULL;\n        } else {\n            /* Even on empty input string return something not NULL. */\n            if (vector == NULL) vector = s_malloc(sizeof(void*));\n            return vector;\n        }\n    }\n\nerr:\n    while((*argc)--)\n        sdsfree(vector[*argc]);\n    s_free(vector);\n    if (current) sdsfree(current);\n    *argc = 0;\n    return NULL;\n}\n\n/* Modify the string substituting all the occurrences of the set of\n * characters specified in the 'from' string to the corresponding character\n * in the 'to' array.\n *\n * For instance: sdsmapchars(mystring, \"ho\", \"01\", 2)\n * will have the effect of turning the string \"hello\" into \"0ell1\".\n *\n * The function returns the sds string pointer, that is always the same\n * as the input pointer since no resize is needed. */\nsds sdsmapchars(sds s, const char *from, const char *to, size_t setlen) {\n    size_t j, i, l = sdslen(s);\n\n    for (j = 0; j < l; j++) {\n        for (i = 0; i < setlen; i++) {\n            if (s[j] == from[i]) {\n                s[j] = to[i];\n                break;\n            }\n        }\n    }\n    return s;\n}\n\n/* Join an array of C strings using the specified separator (also a C string).\n * Returns the result as an sds string. */\nsds sdsjoin(char **argv, int argc, char *sep) {\n    sds join = sdsempty();\n    int j;\n\n    for (j = 0; j < argc; j++) {\n        join = sdscat(join, argv[j]);\n        if (j != argc-1) join = sdscat(join,sep);\n    }\n    return join;\n}\n\n/* Like sdsjoin, but joins an array of SDS strings. */\nsds sdsjoinsds(sds *argv, int argc, const char *sep, size_t seplen) {\n    sds join = sdsempty();\n    int j;\n\n    for (j = 0; j < argc; j++) {\n        join = sdscatsds(join, argv[j]);\n        if (j != argc-1) join = sdscatlen(join,sep,seplen);\n    }\n    return join;\n}\n\n/* Wrappers to the allocators used by SDS. Note that SDS will actually\n * just use the macros defined into sdsalloc.h in order to avoid to pay\n * the overhead of function calls. Here we define these wrappers only for\n * the programs SDS is linked to, if they want to touch the SDS internals\n * even if they use a different allocator. */\nvoid *sds_malloc(size_t size) { return s_malloc(size); }\nvoid *sds_realloc(void *ptr, size_t size) { return s_realloc(ptr,size); }\nvoid sds_free(void *ptr) { s_free(ptr); }\n\n/* Perform expansion of a template string and return the result as a newly\n * allocated sds.\n *\n * Template variables are specified using curly brackets, e.g. {variable}.\n * An opening bracket can be quoted by repeating it twice.\n */\nsds sdstemplate(const char *template, sdstemplate_callback_t cb_func, void *cb_arg)\n{\n    sds res = sdsempty();\n    const char *p = template;\n\n    while (*p) {\n        /* Find next variable, copy everything until there */\n        const char *sv = strchr(p, '{');\n        if (!sv) {\n            /* Not found: copy till rest of template and stop */\n            res = sdscat(res, p);\n            break;\n        } else if (sv > p) {\n            /* Found: copy anything up to the beginning of the variable */\n            res = sdscatlen(res, p, sv - p);\n        }\n\n        /* Skip into variable name, handle premature end or quoting */\n        sv++;\n        if (!*sv) goto error;       /* Premature end of template */\n        if (*sv == '{') {\n            /* Quoted '{' */\n            p = sv + 1;\n            res = sdscat(res, \"{\");\n            continue;\n        }\n\n        /* Find end of variable name, handle premature end of template */\n        const char *ev = strchr(sv, '}');\n        if (!ev) goto error;\n"}, {"id": "3955EFB3963649F0", "name": "hdr_value_at_percentile", "path": "redis/deps/hdr_histogram/hdr_histogram.c", "start": {"line": 687, "col": 1}, "end": {"line": 698, "col": 1}, "code": "{\n    double requested_percentile = percentile < 100.0 ? percentile : 100.0;\n    int64_t count_at_percentile =\n        (int64_t) (((requested_percentile / 100) * h->total_count) + 0.5);\n    int64_t value_from_idx = get_value_from_idx_up_to_count(h, count_at_percentile);\n    if (percentile == 0.0)\n    {\n        return lowest_equivalent_value(h, value_from_idx);\n    }\n    return highest_equivalent_value(h, value_from_idx);\n}\n\nint hdr_value_at_percentiles(const struct hdr_histogram *h, const double *percentiles, int64_t *values, size_t length)\n{\n    if (NULL == percentiles || NULL == values)\n    {\n        return EINVAL;\n    }\n\n    struct hdr_iter iter;\n    const int64_t total_count = h->total_count;\n    // to avoid allocations we use the values array for intermediate computation\n    // i.e. to store the expected cumulative count at each percentile\n    for (size_t i = 0; i < length; i++)\n    {\n        const double requested_percentile = percentiles[i] < 100.0 ? percentiles[i] : 100.0;\n        const int64_t count_at_percentile =\n        (int64_t) (((requested_percentile / 100) * total_count) + 0.5);\n        values[i] = count_at_percentile > 1 ? count_at_percentile : 1;\n    }\n\n    hdr_iter_init(&iter, h);\n    int64_t total = 0;\n    size_t at_pos = 0;\n    while (hdr_iter_next(&iter) && at_pos < length)\n    {\n        total += iter.count;\n        while (at_pos < length && total >= values[at_pos])\n        {\n            values[at_pos] = highest_equivalent_value(h, iter.value);\n            at_pos++;\n        }\n    }\n    return 0;\n}\n\ndouble hdr_mean(const struct hdr_histogram* h)\n{\n    struct hdr_iter iter;\n    int64_t total = 0;\n\n    hdr_iter_init(&iter, h);\n\n    while (hdr_iter_next(&iter))\n    {\n        if (0 != iter.count)\n        {\n            total += iter.count * hdr_median_equivalent_value(h, iter.value);\n        }\n    }\n\n    return (total * 1.0) / h->total_count;\n}\n\ndouble hdr_stddev(const struct hdr_histogram* h)\n{\n    double mean = hdr_mean(h);\n    double geometric_dev_total = 0.0;\n\n    struct hdr_iter iter;\n    hdr_iter_init(&iter, h);\n\n    while (hdr_iter_next(&iter))\n    {\n        if (0 != iter.count)\n        {\n            double dev = (hdr_median_equivalent_value(h, iter.value) * 1.0) - mean;\n            geometric_dev_total += (dev * dev) * iter.count;\n        }\n    }\n\n    return sqrt(geometric_dev_total / h->total_count);\n}\n\nbool hdr_values_are_equivalent(const struct hdr_histogram* h, int64_t a, int64_t b)\n{\n    return lowest_equivalent_value(h, a) == lowest_equivalent_value(h, b);\n}\n\nint64_t hdr_lowest_equivalent_value(const struct hdr_histogram* h, int64_t value)\n{\n    return lowest_equivalent_value(h, value);\n}\n\nint64_t hdr_count_at_value(const struct hdr_histogram* h, int64_t value)\n{\n    return counts_get_normalised(h, counts_index_for(h, value));\n}\n\nint64_t hdr_count_at_index(const struct hdr_histogram* h, int32_t index)\n{\n    return counts_get_normalised(h, index);\n}\n\n\n/* #### ######## ######## ########     ###    ########  #######  ########   ######  */\n/*  ##     ##    ##       ##     ##   ## ##      ##    ##     ## ##     ## ##    ## */\n/*  ##     ##    ##       ##     ##  ##   ##     ##    ##     ## ##     ## ##       */\n/*  ##     ##    ######   ########  ##     ##    ##    ##     ## ########   ######  */\n/*  ##     ##    ##       ##   ##   #########    ##    ##     ## ##   ##         ## */\n/*  ##     ##    ##       ##    ##  ##     ##    ##    ##     ## ##    ##  ##    ## */\n/* ####    ##    ######## ##     ## ##     ##    ##     #######  ##     ##  ######  */\n\n\nstatic bool has_buckets(struct hdr_iter* iter)\n{\n    return iter->counts_index < iter->h->counts_len;\n}\n\nstatic bool has_next(struct hdr_iter* iter)\n{\n    return iter->cumulative_count < iter->total_count;\n}\n\nstatic bool move_next(struct hdr_iter* iter)\n{\n    iter->counts_index++;\n\n    if (!has_buckets(iter))\n    {\n        return false;\n    }\n\n    iter->count = counts_get_normalised(iter->h, iter->counts_index);\n    iter->cumulative_count += iter->count;\n    const int64_t value = hdr_value_at_index(iter->h, iter->counts_index);\n    const int32_t bucket_index = get_bucket_index(iter->h, value);\n    const int32_t sub_bucket_index = get_sub_bucket_index(value, bucket_index, iter->h->unit_magnitude);\n    const int64_t leq = lowest_equivalent_value_given_bucket_indices(iter->h, bucket_index, sub_bucket_index);\n    const int64_t size_of_equivalent_value_range = size_of_equivalent_value_range_given_bucket_indices(\n        iter->h, bucket_index, sub_bucket_index);\n    iter->lowest_equivalent_value = leq;\n    iter->value = value;\n    iter->highest_equivalent_value = leq + size_of_equivalent_value_range - 1;\n    iter->median_equivalent_value = leq + (size_of_equivalent_value_range >> 1);\n\n    return true;\n}\n\nstatic int64_t peek_next_value_from_index(struct hdr_iter* iter)\n{\n    return hdr_value_at_index(iter->h, iter->counts_index + 1);\n}\n\nstatic bool next_value_greater_than_reporting_level_upper_bound(\n    struct hdr_iter *iter, int64_t reporting_level_upper_bound)\n{\n    if (iter->counts_index >= iter->h->counts_len)\n    {\n        return false;\n    }\n\n    return peek_next_value_from_index(iter) > reporting_level_upper_bound;\n}\n\nstatic bool basic_iter_next(struct hdr_iter *iter)\n{\n    if (!has_next(iter) || iter->counts_index >= iter->h->counts_len)\n    {\n        return false;\n    }\n\n    move_next(iter);\n\n    return true;\n}\n\nstatic void update_iterated_values(struct hdr_iter* iter, int64_t new_value_iterated_to)\n{\n    iter->value_iterated_from = iter->value_iterated_to;\n    iter->value_iterated_to = new_value_iterated_to;\n}\n\nstatic bool all_values_iter_next(struct hdr_iter* iter)\n{\n    bool result = move_next(iter);\n\n    if (result)\n    {\n        update_iterated_values(iter, iter->value);\n    }\n\n    return result;\n}\n\nvoid hdr_iter_init(struct hdr_iter* iter, const struct hdr_histogram* h)\n{\n    iter->h = h;\n\n    iter->counts_index = -1;\n    iter->total_count = h->total_count;\n    iter->count = 0;\n    iter->cumulative_count = 0;\n    iter->value = 0;\n    iter->highest_equivalent_value = 0;\n    iter->value_iterated_from = 0;\n    iter->value_iterated_to = 0;\n\n    iter->_next_fp = all_values_iter_next;\n}\n\nbool hdr_iter_next(struct hdr_iter* iter)\n{\n    return iter->_next_fp(iter);\n}\n\n/* ########  ######## ########   ######  ######## ##    ## ######## #### ##       ########  ######  */\n/* ##     ## ##       ##     ## ##    ## ##       ###   ##    ##     ##  ##       ##       ##    ## */\n/* ##     ## ##       ##     ## ##       ##       ####  ##    ##     ##  ##       ##       ##       */\n/* ########  ######   ########  ##       ######   ## ## ##    ##     ##  ##       ######    ######  */\n/* ##        ##       ##   ##   ##       ##       ##  ####    ##     ##  ##       ##             ## */\n/* ##        ##       ##    ##  ##    ## ##       ##   ###    ##     ##  ##       ##       ##    ## */\n/* ##        ######## ##     ##  ######  ######## ##    ##    ##    #### ######## ########  ######  */\n\nstatic bool percentile_iter_next(struct hdr_iter* iter)\n{\n    int64_t temp, half_distance, percentile_reporting_ticks;\n\n    struct hdr_iter_percentiles* percentiles = &iter->specifics.percentiles;\n\n    if (!has_next(iter))\n    {\n        if (percentiles->seen_last_value)\n        {\n            return false;\n        }\n\n        percentiles->seen_last_value = true;\n        percentiles->percentile = 100.0;\n\n        return true;\n    }\n\n    if (iter->counts_index == -1 && !basic_iter_next(iter))\n    {\n        return false;\n    }\n\n    do\n    {\n        double current_percentile = (100.0 * (double) iter->cumulative_count) / iter->h->total_count;\n        if (iter->count != 0 &&\n                percentiles->percentile_to_iterate_to <= current_percentile)\n        {\n            update_iterated_values(iter, highest_equivalent_value(iter->h, iter->value));\n\n            percentiles->percentile = percentiles->percentile_to_iterate_to;\n            temp = (int64_t)(log(100 / (100.0 - (percentiles->percentile_to_iterate_to))) / log(2)) + 1;\n            half_distance = (int64_t) pow(2, (double) temp);\n            percentile_reporting_ticks = percentiles->ticks_per_half_distance * half_distance;\n            percentiles->percentile_to_iterate_to += 100.0 / percentile_reporting_ticks;\n\n            return true;\n        }\n    }\n    while (basic_iter_next(iter));\n\n    return true;\n}\n\nvoid hdr_iter_percentile_init(struct hdr_iter* iter, const struct hdr_histogram* h, int32_t ticks_per_half_distance)\n{\n    iter->h = h;\n\n    hdr_iter_init(iter, h);\n\n    iter->specifics.percentiles.seen_last_value          = false;\n    iter->specifics.percentiles.ticks_per_half_distance  = ticks_per_half_distance;\n    iter->specifics.percentiles.percentile_to_iterate_to = 0.0;\n    iter->specifics.percentiles.percentile               = 0.0;\n\n    iter->_next_fp = percentile_iter_next;\n}\n\nstatic void format_line_string(char* str, size_t len, int significant_figures, format_type format)\n{\n#if defined(_MSC_VER)\n#define snprintf _snprintf\n#pragma warning(push)\n#pragma warning(disable: 4996)\n#endif\n    const char* format_str = \"%s%d%s\";\n\n    switch (format)\n    {\n        case CSV:\n            snprintf(str, len, format_str, \"%.\", significant_figures, \"f,%f,%d,%.2f\\n\");\n            break;\n        case CLASSIC:\n            snprintf(str, len, format_str, \"%12.\", significant_figures, \"f %12f %12d %12.2f\\n\");\n            break;\n        default:\n            snprintf(str, len, format_str, \"%12.\", significant_figures, \"f %12f %12d %12.2f\\n\");\n    }\n#if defined(_MSC_VER)\n#undef snprintf\n#pragma warning(pop)\n#endif\n}\n\n\n/* ########  ########  ######   #######  ########  ########  ######## ########   */\n/* ##     ## ##       ##    ## ##     ## ##     ## ##     ## ##       ##     ##  */\n/* ##     ## ##       ##       ##     ## ##     ## ##     ## ##       ##     ##  */\n/* ########  ######   ##       ##     ## ########  ##     ## ######   ##     ##  */\n/* ##   ##   ##       ##       ##     ## ##   ##   ##     ## ##       ##     ##  */\n/* ##    ##  ##       ##    ## ##     ## ##    ##  ##     ## ##       ##     ##  */\n/* ##     ## ########  ######   #######  ##     ## ########  ######## ########   */\n\n\nstatic bool recorded_iter_next(struct hdr_iter* iter)\n{\n    while (basic_iter_next(iter))\n    {\n        if (iter->count != 0)\n        {\n            update_iterated_values(iter, iter->value);\n\n            iter->specifics.recorded.count_added_in_this_iteration_step = iter->count;\n            return true;\n        }\n    }\n\n    return false;\n}\n\nvoid hdr_iter_recorded_init(struct hdr_iter* iter, const struct hdr_histogram* h)\n{\n    hdr_iter_init(iter, h);\n\n    iter->specifics.recorded.count_added_in_this_iteration_step = 0;\n\n    iter->_next_fp = recorded_iter_next;\n}\n\n/* ##       #### ##    ## ########    ###    ########  */\n/* ##        ##  ###   ## ##         ## ##   ##     ## */\n/* ##        ##  ####  ## ##        ##   ##  ##     ## */\n/* ##        ##  ## ## ## ######   ##     ## ########  */\n/* ##        ##  ##  #### ##       ######### ##   ##   */\n/* ##        ##  ##   ### ##       ##     ## ##    ##  */\n/* ######## #### ##    ## ######## ##     ## ##     ## */\n\n\nstatic bool iter_linear_next(struct hdr_iter* iter)\n{\n    struct hdr_iter_linear* linear = &iter->specifics.linear;\n\n    linear->count_added_in_this_iteration_step = 0;\n\n    if (has_next(iter) ||\n        next_value_greater_than_reporting_level_upper_bound(\n            iter, linear->next_value_reporting_level_lowest_equivalent))\n    {\n        do\n        {\n            if (iter->value >= linear->next_value_reporting_level_lowest_equivalent)\n            {\n                update_iterated_values(iter, linear->next_value_reporting_level);\n\n                linear->next_value_reporting_level += linear->value_units_per_bucket;\n                linear->next_value_reporting_level_lowest_equivalent =\n                    lowest_equivalent_value(iter->h, linear->next_value_reporting_level);\n\n                return true;\n            }\n\n            if (!move_next(iter))\n            {\n                return true;\n            }\n\n            linear->count_added_in_this_iteration_step += iter->count;\n        }\n        while (true);\n    }\n\n    return false;\n}\n\n\nvoid hdr_iter_linear_init(struct hdr_iter* iter, const struct hdr_histogram* h, int64_t value_units_per_bucket)\n{\n    hdr_iter_init(iter, h);\n\n    iter->specifics.linear.count_added_in_this_iteration_step = 0;\n    iter->specifics.linear.value_units_per_bucket = value_units_per_bucket;\n    iter->specifics.linear.next_value_reporting_level = value_units_per_bucket;\n    iter->specifics.linear.next_value_reporting_level_lowest_equivalent = lowest_equivalent_value(h, value_units_per_bucket);\n\n    iter->_next_fp = iter_linear_next;\n}\n\nvoid hdr_iter_linear_set_value_units_per_bucket(struct hdr_iter* iter, int64_t value_units_per_bucket)\n{\n    iter->specifics.linear.value_units_per_bucket = value_units_per_bucket;\n}\n\n/* ##        #######   ######      ###    ########  #### ######## ##     ## ##     ## ####  ######  */\n/* ##       ##     ## ##    ##    ## ##   ##     ##  ##     ##    ##     ## ###   ###  ##  ##    ## */\n/* ##       ##     ## ##         ##   ##  ##     ##  ##     ##    ##     ## #### ####  ##  ##       */\n/* ##       ##     ## ##   #### ##     ## ########   ##     ##    ######### ## ### ##  ##  ##       */\n/* ##       ##     ## ##    ##  ######### ##   ##    ##     ##    ##     ## ##     ##  ##  ##       */\n/* ##       ##     ## ##    ##  ##     ## ##    ##   ##     ##    ##     ## ##     ##  ##  ##    ## */\n/* ########  #######   ######   ##     ## ##     ## ####    ##    ##     ## ##     ## ####  ######  */\n\nstatic bool log_iter_next(struct hdr_iter *iter)\n{\n    struct hdr_iter_log* logarithmic = &iter->specifics.log;\n\n    logarithmic->count_added_in_this_iteration_step = 0;\n\n    if (has_next(iter) ||\n        next_value_greater_than_reporting_level_upper_bound(\n            iter, logarithmic->next_value_reporting_level_lowest_equivalent))\n    {\n        do\n        {\n            if (iter->value >= logarithmic->next_value_reporting_level_lowest_equivalent)\n            {\n                update_iterated_values(iter, logarithmic->next_value_reporting_level);\n\n                logarithmic->next_value_reporting_level *= (int64_t)logarithmic->log_base;\n                logarithmic->next_value_reporting_level_lowest_equivalent = lowest_equivalent_value(iter->h, logarithmic->next_value_reporting_level);\n\n                return true;\n            }\n\n            if (!move_next(iter))\n            {\n                return true;\n            }\n\n            logarithmic->count_added_in_this_iteration_step += iter->count;\n        }\n        while (true);\n    }\n\n    return false;\n}\n\nvoid hdr_iter_log_init(\n        struct hdr_iter* iter,\n        const struct hdr_histogram* h,\n        int64_t value_units_first_bucket,\n        double log_base)\n{\n    hdr_iter_init(iter, h);\n    iter->specifics.log.count_added_in_this_iteration_step = 0;\n    iter->specifics.log.log_base = log_base;\n    iter->specifics.log.next_value_reporting_level = value_units_first_bucket;\n    iter->specifics.log.next_value_reporting_level_lowest_equivalent = lowest_equivalent_value(h, value_units_first_bucket);\n\n    iter->_next_fp = log_iter_next;\n}\n\n/* Printing. */\n\nstatic const char* format_head_string(format_type format)\n{\n    switch (format)\n    {\n        case CSV:\n            return \"%s,%s,%s,%s\\n\";\n        case CLASSIC:\n        default:\n            return \"%12s %12s %12s %12s\\n\\n\";\n    }\n}\n\nstatic const char CLASSIC_FOOTER[] =\n    \"#[Mean    = %12.3f, StdDeviation   = %12.3f]\\n\"\n    \"#[Max     = %12.3f, Total count    = %12\" PRIu64 \"]\\n\"\n    \"#[Buckets = %12d, SubBuckets     = %12d]\\n\";\n\nint hdr_percentiles_print(\n        struct hdr_histogram* h, FILE* stream, int32_t ticks_per_half_distance,\n        double value_scale, format_type format)\n{\n    char line_format[25];\n    const char* head_format;\n    int rc = 0;\n    struct hdr_iter iter;\n    struct hdr_iter_percentiles * percentiles;\n\n    format_line_string(line_format, 25, h->significant_figures, format);\n    head_format = format_head_string(format);\n\n    hdr_iter_percentile_init(&iter, h, ticks_per_half_distance);\n\n    if (fprintf(\n            stream, head_format,\n            \"Value\", \"Percentile\", \"TotalCount\", \"1/(1-Percentile)\") < 0)\n    {\n        rc = EIO;\n        goto cleanup;\n    }\n\n    percentiles = &iter.specifics.percentiles;\n    while (hdr_iter_next(&iter))\n    {\n        double  value               = iter.highest_equivalent_value / value_scale;\n        double  percentile          = percentiles->percentile / 100.0;\n        int64_t total_count         = iter.cumulative_count;\n        double  inverted_percentile = (1.0 / (1.0 - percentile));\n\n        if (fprintf(\n                stream, line_format, value, percentile, total_count, inverted_percentile) < 0)\n        {\n            rc = EIO;\n            goto cleanup;\n        }\n    }\n\n    if (CLASSIC == format)\n    {\n        double mean   = hdr_mean(h)   / value_scale;\n        double stddev = hdr_stddev(h) / value_scale;\n        double max    = hdr_max(h)    / value_scale;\n\n        if (fprintf(\n                stream, CLASSIC_FOOTER,  mean, stddev, max,\n                h->total_count, h->bucket_count, h->sub_bucket_count) < 0)\n        {\n            rc = EIO;\n            goto cleanup;\n        }\n    }\n\n    cleanup:\n    return rc;\n}\n"}], "code": "sds fillPercentileDistributionLatencies(sds info, const char* histogram_name, struct hdr_histogram* histogram) {\n    info = sdscatfmt(info,\"latency_percentiles_usec_%s:\",histogram_name);\n    for (int j = 0; j < server.latency_tracking_info_percentiles_len; j++) {\n        char fbuf[128];\n        size_t len = snprintf(fbuf, sizeof(fbuf), \"%f\", server.latency_tracking_info_percentiles[j]);\n        trimDoubleString(fbuf, len);\n        info = sdscatprintf(info,\"p%s=%.3f\", fbuf,\n            ((double)hdr_value_at_percentile(histogram,server.latency_tracking_info_percentiles[j]))/1000.0f);\n        if (j != server.latency_tracking_info_percentiles_len-1)\n            info = sdscatlen(info,\",\",1);\n        }\n    info = sdscatprintf(info,\"\\r\\n\");\n    return info;\n}\n"}, "63BD3C16404EFF44": {"calls": [{"id": "7B9AC0D107BE5BEA", "name": "lua_setfield", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 657, "col": 1}, "end": {"line": 668, "col": 1}, "code": "  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\nLUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  StkId fi;\n  lua_lock(L);\n  fi = index2adr(L, funcindex);\n  api_checknelems(L, 1);\n  name = aux_upvalue(fi, n, &val);\n  if (name) {\n    L->top--;\n    setobj(L, val, L->top);\n    luaC_barrier(L, clvalue(fi), L->top);\n  }\n  lua_unlock(L);\n  return name;\n}\n\nLUA_API void lua_enablereadonlytable (lua_State *L, int objindex, int enabled) {\n  const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  t->readonly = enabled;\n}\n\nLUA_API int lua_isreadonlytable (lua_State *L, int objindex) {\n    const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  return t->readonly;\n}\n\n"}, {"id": "30E60BCF6A158292", "name": "lua_setmetatable", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 701, "col": 1}, "end": {"line": 737, "col": 1}, "code": "  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\nLUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  StkId fi;\n  lua_lock(L);\n  fi = index2adr(L, funcindex);\n  api_checknelems(L, 1);\n  name = aux_upvalue(fi, n, &val);\n  if (name) {\n    L->top--;\n    setobj(L, val, L->top);\n    luaC_barrier(L, clvalue(fi), L->top);\n  }\n  lua_unlock(L);\n  return name;\n}\n\nLUA_API void lua_enablereadonlytable (lua_State *L, int objindex, int enabled) {\n  const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  t->readonly = enabled;\n}\n\nLUA_API int lua_isreadonlytable (lua_State *L, int objindex) {\n    const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  return t->readonly;\n}\n\n"}], "code": "void luaSetErrorMetatable(lua_State *lua) {\n    lua_newtable(lua); /* push metatable */\n    lua_pushcfunction(lua, luaProtectedTableError); /* push get error handler */\n    lua_setfield(lua, -2, \"__index\");\n    lua_setmetatable(lua, -2);\n}\n"}, "91E59A8BE2E5834C": {"calls": [{"id": "6553C99DF16B4514", "name": "lua_isstring", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 267, "col": 1}, "end": {"line": 270, "col": 1}, "code": "  int t = lua_type(L, idx);\n  return (t == LUA_TSTRING || t == LUA_TNUMBER);\n}\n\n\nLUA_API int lua_isuserdata (lua_State *L, int idx) {\n  const TValue *o = index2adr(L, idx);\n  return (ttisuserdata(o) || ttislightuserdata(o));\n}\n\n\nLUA_API int lua_rawequal (lua_State *L, int index1, int index2) {\n  StkId o1 = index2adr(L, index1);\n  StkId o2 = index2adr(L, index2);\n  return (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0\n         : luaO_rawequalObj(o1, o2);\n}\n\n\nLUA_API int lua_equal (lua_State *L, int index1, int index2) {\n  StkId o1, o2;\n  int i;\n  lua_lock(L);  /* may call tag method */\n  o1 = index2adr(L, index1);\n  o2 = index2adr(L, index2);\n  i = (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0 : equalobj(L, o1, o2);\n  lua_unlock(L);\n  return i;\n}\n\n\nLUA_API int lua_lessthan (lua_State *L, int index1, int index2) {\n  StkId o1, o2;\n  int i;\n  lua_lock(L);  /* may call tag method */\n  o1 = index2adr(L, index1);\n  o2 = index2adr(L, index2);\n  i = (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0\n       : luaV_lessthan(L, o1, o2);\n  lua_unlock(L);\n  return i;\n}\n\n\n\nLUA_API lua_Number lua_tonumber (lua_State *L, int idx) {\n  TValue n;\n  const TValue *o = index2adr(L, idx);\n  if (tonumber(o, &n))\n    return nvalue(o);\n  else\n    return 0;\n}\n\n\nLUA_API lua_Integer lua_tointeger (lua_State *L, int idx) {\n  TValue n;\n  const TValue *o = index2adr(L, idx);\n  if (tonumber(o, &n)) {\n    lua_Integer res;\n    lua_Number num = nvalue(o);\n    lua_number2integer(res, num);\n    return res;\n  }\n  else\n    return 0;\n}\n\n\nLUA_API int lua_toboolean (lua_State *L, int idx) {\n  const TValue *o = index2adr(L, idx);\n  return !l_isfalse(o);\n}\n\n\nLUA_API const char *lua_tolstring (lua_State *L, int idx, size_t *len) {\n  StkId o = index2adr(L, idx);\n  if (!ttisstring(o)) {\n    lua_lock(L);  /* `luaV_tostring' may create a new string */\n    if (!luaV_tostring(L, o)) {  /* conversion failed? */\n      if (len != NULL) *len = 0;\n      lua_unlock(L);\n      return NULL;\n    }\n    luaC_checkGC(L);\n    o = index2adr(L, idx);  /* previous call may reallocate the stack */\n    lua_unlock(L);\n  }\n  if (len != NULL) *len = tsvalue(o)->len;\n  return svalue(o);\n}\n\n\nLUA_API size_t lua_objlen (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  switch (ttype(o)) {\n    case LUA_TSTRING: return tsvalue(o)->len;\n    case LUA_TUSERDATA: return uvalue(o)->len;\n    case LUA_TTABLE: return luaH_getn(hvalue(o));\n    case LUA_TNUMBER: {\n      size_t l;\n      lua_lock(L);  /* `luaV_tostring' may create a new string */\n      l = (luaV_tostring(L, o) ? tsvalue(o)->len : 0);\n      lua_unlock(L);\n      return l;\n    }\n    default: return 0;\n  }\n}\n\n\nLUA_API lua_CFunction lua_tocfunction (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  return (!iscfunction(o)) ? NULL : clvalue(o)->c.f;\n}\n\n\nLUA_API void *lua_touserdata (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  switch (ttype(o)) {\n    case LUA_TUSERDATA: return (rawuvalue(o) + 1);\n    case LUA_TLIGHTUSERDATA: return pvalue(o);\n    default: return NULL;\n  }\n}\n\n\nLUA_API lua_State *lua_tothread (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  return (!ttisthread(o)) ? NULL : thvalue(o);\n}\n\n\nLUA_API const void *lua_topointer (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  switch (ttype(o)) {\n    case LUA_TTABLE: return hvalue(o);\n    case LUA_TFUNCTION: return clvalue(o);\n    case LUA_TTHREAD: return thvalue(o);\n    case LUA_TUSERDATA:\n    case LUA_TLIGHTUSERDATA:\n      return lua_touserdata(L, idx);\n    default: return NULL;\n  }\n}\n\n\n\n/*\n** push functions (C -> stack)\n*/\n\n\nLUA_API void lua_pushnil (lua_State *L) {\n  lua_lock(L);\n  setnilvalue(L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushnumber (lua_State *L, lua_Number n) {\n  lua_lock(L);\n  setnvalue(L->top, n);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushinteger (lua_State *L, lua_Integer n) {\n  lua_lock(L);\n  setnvalue(L->top, cast_num(n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlstring (lua_State *L, const char *s, size_t len) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  setsvalue2s(L, L->top, luaS_newlstr(L, s, len));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushstring (lua_State *L, const char *s) {\n  if (s == NULL)\n    lua_pushnil(L);\n  else\n    lua_pushlstring(L, s, strlen(s));\n}\n\n\nLUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,\n                                      va_list argp) {\n  const char *ret;\n  lua_lock(L);\n  luaC_checkGC(L);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {\n  const char *ret;\n  va_list argp;\n  lua_lock(L);\n  luaC_checkGC(L);\n  va_start(argp, fmt);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  va_end(argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {\n  Closure *cl;\n  lua_lock(L);\n  luaC_checkGC(L);\n  api_checknelems(L, n);\n  cl = luaF_newCclosure(L, n, getcurrenv(L));\n  cl->c.f = fn;\n  L->top -= n;\n  while (n--)\n    setobj2n(L, &cl->c.upvalue[n], L->top+n);\n  setclvalue(L, L->top, cl);\n  lua_assert(iswhite(obj2gco(cl)));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushboolean (lua_State *L, int b) {\n  lua_lock(L);\n  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlightuserdata (lua_State *L, void *p) {\n  lua_lock(L);\n  setpvalue(L->top, p);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_pushthread (lua_State *L) {\n  lua_lock(L);\n  setthvalue(L, L->top, L);\n  api_incr_top(L);\n  lua_unlock(L);\n  return (G(L)->mainthread == L);\n}\n\n\n\n/*\n** get functions (Lua -> stack)\n*/\n\n\nLUA_API void lua_gettable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n"}], "code": "sds luaGetStringSds(lua_State *lua, int index) {\n    if (!lua_isstring(lua, index)) {\n        return NULL;\n    }\n\n    size_t len;\n    const char *str = lua_tolstring(lua, index, &len);\n    sds str_sds = sdsnewlen(str, len);\n    return str_sds;\n}\n"}, "C3CB2474A9CFDEB8": {"calls": [{"id": "0D52ADAC56D29522", "name": "sdslen", "path": "redis/src/sds.h", "start": {"line": 87, "col": 1}, "end": {"line": 102, "col": 1}, "code": "    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            return SDS_TYPE_5_LEN(flags);\n        case SDS_TYPE_8:\n            return SDS_HDR(8,s)->len;\n        case SDS_TYPE_16:\n            return SDS_HDR(16,s)->len;\n        case SDS_TYPE_32:\n            return SDS_HDR(32,s)->len;\n        case SDS_TYPE_64:\n            return SDS_HDR(64,s)->len;\n    }\n    return 0;\n}\n\nstatic inline size_t sdsavail(const sds s) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5: {\n            return 0;\n        }\n        case SDS_TYPE_8: {\n            SDS_HDR_VAR(8,s);\n            return sh->alloc - sh->len;\n        }\n        case SDS_TYPE_16: {\n            SDS_HDR_VAR(16,s);\n            return sh->alloc - sh->len;\n        }\n        case SDS_TYPE_32: {\n            SDS_HDR_VAR(32,s);\n            return sh->alloc - sh->len;\n        }\n        case SDS_TYPE_64: {\n            SDS_HDR_VAR(64,s);\n            return sh->alloc - sh->len;\n        }\n    }\n    return 0;\n}\n\nstatic inline void sdssetlen(sds s, size_t newlen) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            {\n                unsigned char *fp = ((unsigned char*)s)-1;\n                *fp = SDS_TYPE_5 | (newlen << SDS_TYPE_BITS);\n            }\n            break;\n        case SDS_TYPE_8:\n            SDS_HDR(8,s)->len = newlen;\n            break;\n        case SDS_TYPE_16:\n            SDS_HDR(16,s)->len = newlen;\n            break;\n        case SDS_TYPE_32:\n            SDS_HDR(32,s)->len = newlen;\n            break;\n        case SDS_TYPE_64:\n            SDS_HDR(64,s)->len = newlen;\n            break;\n    }\n}\n\nstatic inline void sdsinclen(sds s, size_t inc) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            {\n                unsigned char *fp = ((unsigned char*)s)-1;\n                unsigned char newlen = SDS_TYPE_5_LEN(flags)+inc;\n                *fp = SDS_TYPE_5 | (newlen << SDS_TYPE_BITS);\n            }\n            break;\n        case SDS_TYPE_8:\n            SDS_HDR(8,s)->len += inc;\n            break;\n        case SDS_TYPE_16:\n            SDS_HDR(16,s)->len += inc;\n            break;\n        case SDS_TYPE_32:\n            SDS_HDR(32,s)->len += inc;\n            break;\n        case SDS_TYPE_64:\n            SDS_HDR(64,s)->len += inc;\n            break;\n    }\n}\n\n/* sdsalloc() = sdsavail() + sdslen() */\nstatic inline size_t sdsalloc(const sds s) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            return SDS_TYPE_5_LEN(flags);\n        case SDS_TYPE_8:\n            return SDS_HDR(8,s)->alloc;\n        case SDS_TYPE_16:\n            return SDS_HDR(16,s)->alloc;\n        case SDS_TYPE_32:\n            return SDS_HDR(32,s)->alloc;\n"}, {"id": "1927A3C3D1E9F6F4", "name": "lua_rawseti", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 686, "col": 1}, "end": {"line": 698, "col": 1}, "code": "  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\nLUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  StkId fi;\n  lua_lock(L);\n  fi = index2adr(L, funcindex);\n  api_checknelems(L, 1);\n  name = aux_upvalue(fi, n, &val);\n  if (name) {\n    L->top--;\n    setobj(L, val, L->top);\n    luaC_barrier(L, clvalue(fi), L->top);\n  }\n  lua_unlock(L);\n  return name;\n}\n\nLUA_API void lua_enablereadonlytable (lua_State *L, int objindex, int enabled) {\n  const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  t->readonly = enabled;\n}\n\nLUA_API int lua_isreadonlytable (lua_State *L, int objindex) {\n    const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  return t->readonly;\n}\n\n"}], "code": "static void luaCreateArray(lua_State *lua, robj **elev, int elec) {\n    int j;\n\n    lua_newtable(lua);\n    for (j = 0; j < elec; j++) {\n        lua_pushlstring(lua,(char*)elev[j]->ptr,sdslen(elev[j]->ptr));\n        lua_rawseti(lua,-2,j+1);\n    }\n}\n"}, "BFD3412F5AA28A38": {"calls": [{"id": "99EE7064DF8D6D05", "name": "hdr_init", "path": "redis/deps/hdr_histogram/hdr_histogram.c", "start": {"line": 408, "col": 1}, "end": {"line": 443, "col": 1}, "code": "        int64_t lowest_discernible_value,\n        int64_t highest_trackable_value,\n        int significant_figures,\n        struct hdr_histogram** result)\n{\n    int64_t* counts;\n    struct hdr_histogram_bucket_config cfg;\n    struct hdr_histogram* histogram;\n\n    int r = hdr_calculate_bucket_config(lowest_discernible_value, highest_trackable_value, significant_figures, &cfg);\n    if (r)\n    {\n        return r;\n    }\n\n    counts = (int64_t*) hdr_calloc((size_t) cfg.counts_len, sizeof(int64_t));\n    if (!counts)\n    {\n        return ENOMEM;\n    }\n\n    histogram = (struct hdr_histogram*) hdr_calloc(1, sizeof(struct hdr_histogram));\n    if (!histogram)\n    {\n        hdr_free(counts);\n        return ENOMEM;\n    }\n\n    histogram->counts = counts;\n\n    hdr_init_preallocated(histogram, &cfg);\n    *result = histogram;\n\n    return 0;\n}\n\nvoid hdr_close(struct hdr_histogram* h)\n{\n    if (h) {\n\thdr_free(h->counts);\n\thdr_free(h);\n    }\n}\n\nint hdr_alloc(int64_t highest_trackable_value, int significant_figures, struct hdr_histogram** result)\n{\n    return hdr_init(1, highest_trackable_value, significant_figures, result);\n}\n\n/* reset a histogram to zero. */\nvoid hdr_reset(struct hdr_histogram *h)\n{\n     h->total_count=0;\n     h->min_value = INT64_MAX;\n     h->max_value = 0;\n     memset(h->counts, 0, (sizeof(int64_t) * h->counts_len));\n}\n\nsize_t hdr_get_memory_size(struct hdr_histogram *h)\n{\n    return sizeof(struct hdr_histogram) + h->counts_len * sizeof(int64_t);\n}\n\n/* ##     ## ########  ########     ###    ######## ########  ######  */\n/* ##     ## ##     ## ##     ##   ## ##      ##    ##       ##    ## */\n/* ##     ## ##     ## ##     ##  ##   ##     ##    ##       ##       */\n/* ##     ## ########  ##     ## ##     ##    ##    ######    ######  */\n/* ##     ## ##        ##     ## #########    ##    ##             ## */\n/* ##     ## ##        ##     ## ##     ##    ##    ##       ##    ## */\n/*  #######  ##        ########  ##     ##    ##    ########  ######  */\n\n\nbool hdr_record_value(struct hdr_histogram* h, int64_t value)\n{\n    return hdr_record_values(h, value, 1);\n}\n\nbool hdr_record_value_atomic(struct hdr_histogram* h, int64_t value)\n{\n    return hdr_record_values_atomic(h, value, 1);\n}\n\nbool hdr_record_values(struct hdr_histogram* h, int64_t value, int64_t count)\n{\n    int32_t counts_index;\n\n    if (value < 0)\n    {\n        return false;\n    }\n\n    counts_index = counts_index_for(h, value);\n\n    if (counts_index < 0 || h->counts_len <= counts_index)\n    {\n        return false;\n    }\n\n    counts_inc_normalised(h, counts_index, count);\n    update_min_max(h, value);\n\n    return true;\n}\n\nbool hdr_record_values_atomic(struct hdr_histogram* h, int64_t value, int64_t count)\n{\n    int32_t counts_index;\n\n    if (value < 0)\n    {\n        return false;\n    }\n\n    counts_index = counts_index_for(h, value);\n\n    if (counts_index < 0 || h->counts_len <= counts_index)\n    {\n        return false;\n    }\n\n    counts_inc_normalised_atomic(h, counts_index, count);\n    update_min_max_atomic(h, value);\n\n    return true;\n}\n\nbool hdr_record_corrected_value(struct hdr_histogram* h, int64_t value, int64_t expected_interval)\n{\n    return hdr_record_corrected_values(h, value, 1, expected_interval);\n}\n\nbool hdr_record_corrected_value_atomic(struct hdr_histogram* h, int64_t value, int64_t expected_interval)\n{\n    return hdr_record_corrected_values_atomic(h, value, 1, expected_interval);\n}\n\nbool hdr_record_corrected_values(struct hdr_histogram* h, int64_t value, int64_t count, int64_t expected_interval)\n{\n    int64_t missing_value;\n\n    if (!hdr_record_values(h, value, count))\n    {\n        return false;\n    }\n\n    if (expected_interval <= 0 || value <= expected_interval)\n    {\n        return true;\n    }\n\n    missing_value = value - expected_interval;\n    for (; missing_value >= expected_interval; missing_value -= expected_interval)\n    {\n        if (!hdr_record_values(h, missing_value, count))\n        {\n            return false;\n        }\n    }\n\n    return true;\n}\n\nbool hdr_record_corrected_values_atomic(struct hdr_histogram* h, int64_t value, int64_t count, int64_t expected_interval)\n{\n    int64_t missing_value;\n\n    if (!hdr_record_values_atomic(h, value, count))\n    {\n        return false;\n    }\n\n    if (expected_interval <= 0 || value <= expected_interval)\n    {\n        return true;\n    }\n\n    missing_value = value - expected_interval;\n    for (; missing_value >= expected_interval; missing_value -= expected_interval)\n    {\n        if (!hdr_record_values_atomic(h, missing_value, count))\n        {\n            return false;\n        }\n    }\n\n    return true;\n}\n\nint64_t hdr_add(struct hdr_histogram* h, const struct hdr_histogram* from)\n{\n    struct hdr_iter iter;\n    int64_t dropped = 0;\n    hdr_iter_recorded_init(&iter, from);\n\n    while (hdr_iter_next(&iter))\n    {\n        int64_t value = iter.value;\n        int64_t count = iter.count;\n\n        if (!hdr_record_values(h, value, count))\n        {\n            dropped += count;\n        }\n    }\n\n    return dropped;\n}\n\nint64_t hdr_add_while_correcting_for_coordinated_omission(\n        struct hdr_histogram* h, struct hdr_histogram* from, int64_t expected_interval)\n{\n    struct hdr_iter iter;\n    int64_t dropped = 0;\n    hdr_iter_recorded_init(&iter, from);\n\n    while (hdr_iter_next(&iter))\n    {\n        int64_t value = iter.value;\n        int64_t count = iter.count;\n\n        if (!hdr_record_corrected_values(h, value, count, expected_interval))\n        {\n            dropped += count;\n        }\n    }\n\n    return dropped;\n}\n\n\n\n/* ##     ##    ###    ##       ##     ## ########  ######  */\n/* ##     ##   ## ##   ##       ##     ## ##       ##    ## */\n/* ##     ##  ##   ##  ##       ##     ## ##       ##       */\n/* ##     ## ##     ## ##       ##     ## ######    ######  */\n/*  ##   ##  ######### ##       ##     ## ##             ## */\n/*   ## ##   ##     ## ##       ##     ## ##       ##    ## */\n/*    ###    ##     ## ########  #######  ########  ######  */\n\n\nint64_t hdr_max(const struct hdr_histogram* h)\n{\n    if (0 == h->max_value)\n    {\n        return 0;\n    }\n\n    return highest_equivalent_value(h, h->max_value);\n}\n\nint64_t hdr_min(const struct hdr_histogram* h)\n{\n    if (0 < hdr_count_at_index(h, 0))\n    {\n        return 0;\n    }\n\n    return non_zero_min(h);\n}\n\nstatic int64_t get_value_from_idx_up_to_count(const struct hdr_histogram* h, int64_t count_at_percentile)\n{\n    int64_t count_to_idx = 0;\n\n    count_at_percentile = 0 < count_at_percentile ? count_at_percentile : 1;\n    for (int32_t idx = 0; idx < h->counts_len; idx++)\n    {\n        count_to_idx += h->counts[idx];\n        if (count_to_idx >= count_at_percentile)\n        {\n            return hdr_value_at_index(h, idx);\n        }\n    }\n\n    return 0;\n}\n\n\nint64_t hdr_value_at_percentile(const struct hdr_histogram* h, double percentile)\n{\n    double requested_percentile = percentile < 100.0 ? percentile : 100.0;\n    int64_t count_at_percentile =\n        (int64_t) (((requested_percentile / 100) * h->total_count) + 0.5);\n    int64_t value_from_idx = get_value_from_idx_up_to_count(h, count_at_percentile);\n    if (percentile == 0.0)\n    {\n        return lowest_equivalent_value(h, value_from_idx);\n    }\n    return highest_equivalent_value(h, value_from_idx);\n}\n\nint hdr_value_at_percentiles(const struct hdr_histogram *h, const double *percentiles, int64_t *values, size_t length)\n{\n    if (NULL == percentiles || NULL == values)\n    {\n        return EINVAL;\n    }\n\n    struct hdr_iter iter;\n    const int64_t total_count = h->total_count;\n    // to avoid allocations we use the values array for intermediate computation\n    // i.e. to store the expected cumulative count at each percentile\n    for (size_t i = 0; i < length; i++)\n    {\n        const double requested_percentile = percentiles[i] < 100.0 ? percentiles[i] : 100.0;\n        const int64_t count_at_percentile =\n        (int64_t) (((requested_percentile / 100) * total_count) + 0.5);\n        values[i] = count_at_percentile > 1 ? count_at_percentile : 1;\n    }\n\n    hdr_iter_init(&iter, h);\n    int64_t total = 0;\n    size_t at_pos = 0;\n    while (hdr_iter_next(&iter) && at_pos < length)\n    {\n        total += iter.count;\n        while (at_pos < length && total >= values[at_pos])\n        {\n            values[at_pos] = highest_equivalent_value(h, iter.value);\n            at_pos++;\n        }\n    }\n    return 0;\n}\n\ndouble hdr_mean(const struct hdr_histogram* h)\n{\n    struct hdr_iter iter;\n    int64_t total = 0;\n\n    hdr_iter_init(&iter, h);\n\n    while (hdr_iter_next(&iter))\n    {\n        if (0 != iter.count)\n        {\n            total += iter.count * hdr_median_equivalent_value(h, iter.value);\n        }\n    }\n\n    return (total * 1.0) / h->total_count;\n}\n\ndouble hdr_stddev(const struct hdr_histogram* h)\n{\n    double mean = hdr_mean(h);\n    double geometric_dev_total = 0.0;\n\n    struct hdr_iter iter;\n    hdr_iter_init(&iter, h);\n\n    while (hdr_iter_next(&iter))\n    {\n        if (0 != iter.count)\n        {\n            double dev = (hdr_median_equivalent_value(h, iter.value) * 1.0) - mean;\n            geometric_dev_total += (dev * dev) * iter.count;\n        }\n    }\n\n    return sqrt(geometric_dev_total / h->total_count);\n}\n\nbool hdr_values_are_equivalent(const struct hdr_histogram* h, int64_t a, int64_t b)\n{\n    return lowest_equivalent_value(h, a) == lowest_equivalent_value(h, b);\n}\n\nint64_t hdr_lowest_equivalent_value(const struct hdr_histogram* h, int64_t value)\n{\n    return lowest_equivalent_value(h, value);\n}\n\nint64_t hdr_count_at_value(const struct hdr_histogram* h, int64_t value)\n{\n    return counts_get_normalised(h, counts_index_for(h, value));\n}\n\nint64_t hdr_count_at_index(const struct hdr_histogram* h, int32_t index)\n{\n    return counts_get_normalised(h, index);\n}\n\n\n/* #### ######## ######## ########     ###    ########  #######  ########   ######  */\n/*  ##     ##    ##       ##     ##   ## ##      ##    ##     ## ##     ## ##    ## */\n/*  ##     ##    ##       ##     ##  ##   ##     ##    ##     ## ##     ## ##       */\n/*  ##     ##    ######   ########  ##     ##    ##    ##     ## ########   ######  */\n/*  ##     ##    ##       ##   ##   #########    ##    ##     ## ##   ##         ## */\n/*  ##     ##    ##       ##    ##  ##     ##    ##    ##     ## ##    ##  ##    ## */\n/* ####    ##    ######## ##     ## ##     ##    ##     #######  ##     ##  ######  */\n\n\nstatic bool has_buckets(struct hdr_iter* iter)\n{\n    return iter->counts_index < iter->h->counts_len;\n}\n\nstatic bool has_next(struct hdr_iter* iter)\n{\n    return iter->cumulative_count < iter->total_count;\n}\n\nstatic bool move_next(struct hdr_iter* iter)\n{\n    iter->counts_index++;\n\n    if (!has_buckets(iter))\n    {\n        return false;\n    }\n\n    iter->count = counts_get_normalised(iter->h, iter->counts_index);\n    iter->cumulative_count += iter->count;\n    const int64_t value = hdr_value_at_index(iter->h, iter->counts_index);\n    const int32_t bucket_index = get_bucket_index(iter->h, value);\n    const int32_t sub_bucket_index = get_sub_bucket_index(value, bucket_index, iter->h->unit_magnitude);\n    const int64_t leq = lowest_equivalent_value_given_bucket_indices(iter->h, bucket_index, sub_bucket_index);\n    const int64_t size_of_equivalent_value_range = size_of_equivalent_value_range_given_bucket_indices(\n        iter->h, bucket_index, sub_bucket_index);\n    iter->lowest_equivalent_value = leq;\n    iter->value = value;\n    iter->highest_equivalent_value = leq + size_of_equivalent_value_range - 1;\n    iter->median_equivalent_value = leq + (size_of_equivalent_value_range >> 1);\n\n    return true;\n}\n\nstatic int64_t peek_next_value_from_index(struct hdr_iter* iter)\n{\n    return hdr_value_at_index(iter->h, iter->counts_index + 1);\n}\n\nstatic bool next_value_greater_than_reporting_level_upper_bound(\n    struct hdr_iter *iter, int64_t reporting_level_upper_bound)\n{\n    if (iter->counts_index >= iter->h->counts_len)\n    {\n        return false;\n    }\n\n    return peek_next_value_from_index(iter) > reporting_level_upper_bound;\n}\n\n"}], "code": "void updateCommandLatencyHistogram(struct hdr_histogram **latency_histogram, int64_t duration_hist){\n    if (duration_hist < LATENCY_HISTOGRAM_MIN_VALUE)\n        duration_hist=LATENCY_HISTOGRAM_MIN_VALUE;\n    if (duration_hist>LATENCY_HISTOGRAM_MAX_VALUE)\n        duration_hist=LATENCY_HISTOGRAM_MAX_VALUE;\n    if (*latency_histogram==NULL)\n        hdr_init(LATENCY_HISTOGRAM_MIN_VALUE,LATENCY_HISTOGRAM_MAX_VALUE,LATENCY_HISTOGRAM_PRECISION,latency_histogram);\n    hdr_record_value(*latency_histogram,duration_hist);\n}\n"}, "8C34082F9371FB54": {"calls": [{"id": "7CCDA4A627DA6C15", "name": "lua_pushstring", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 454, "col": 1}, "end": {"line": 459, "col": 1}, "code": "  if (s == NULL)\n    lua_pushnil(L);\n  else\n    lua_pushlstring(L, s, strlen(s));\n}\n\n\nLUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,\n                                      va_list argp) {\n  const char *ret;\n  lua_lock(L);\n  luaC_checkGC(L);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {\n  const char *ret;\n  va_list argp;\n  lua_lock(L);\n  luaC_checkGC(L);\n  va_start(argp, fmt);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  va_end(argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {\n  Closure *cl;\n  lua_lock(L);\n  luaC_checkGC(L);\n  api_checknelems(L, n);\n  cl = luaF_newCclosure(L, n, getcurrenv(L));\n  cl->c.f = fn;\n  L->top -= n;\n  while (n--)\n    setobj2n(L, &cl->c.upvalue[n], L->top+n);\n  setclvalue(L, L->top, cl);\n  lua_assert(iswhite(obj2gco(cl)));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushboolean (lua_State *L, int b) {\n  lua_lock(L);\n  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlightuserdata (lua_State *L, void *p) {\n  lua_lock(L);\n  setpvalue(L->top, p);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_pushthread (lua_State *L) {\n  lua_lock(L);\n  setthvalue(L, L->top, L);\n  api_incr_top(L);\n  lua_unlock(L);\n  return (G(L)->mainthread == L);\n}\n\n\n\n/*\n** get functions (Lua -> stack)\n*/\n\n\nLUA_API void lua_gettable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_gettable(L, t, L->top - 1, L->top - 1);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_getfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_gettable(L, t, &key, L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawget (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawgeti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n"}, {"id": "D15534810A5E6325", "name": "lua_call", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 782, "col": 1}, "end": {"line": 791, "col": 1}, "code": "  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\nLUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  StkId fi;\n  lua_lock(L);\n  fi = index2adr(L, funcindex);\n  api_checknelems(L, 1);\n  name = aux_upvalue(fi, n, &val);\n  if (name) {\n    L->top--;\n    setobj(L, val, L->top);\n    luaC_barrier(L, clvalue(fi), L->top);\n  }\n  lua_unlock(L);\n  return name;\n}\n\nLUA_API void lua_enablereadonlytable (lua_State *L, int objindex, int enabled) {\n  const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  t->readonly = enabled;\n}\n\nLUA_API int lua_isreadonlytable (lua_State *L, int objindex) {\n    const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  return t->readonly;\n}\n\n"}], "code": "static void luaLoadLib(lua_State *lua, const char *libname, lua_CFunction luafunc) {\n  lua_pushcfunction(lua, luafunc);\n  lua_pushstring(lua, libname);\n  lua_call(lua, 1, 0);\n}\n"}, "49B52B607F6CE286": {"calls": [{"id": "7CCDA4A627DA6C15", "name": "lua_pushstring", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 454, "col": 1}, "end": {"line": 459, "col": 1}, "code": "  if (s == NULL)\n    lua_pushnil(L);\n  else\n    lua_pushlstring(L, s, strlen(s));\n}\n\n\nLUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,\n                                      va_list argp) {\n  const char *ret;\n  lua_lock(L);\n  luaC_checkGC(L);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {\n  const char *ret;\n  va_list argp;\n  lua_lock(L);\n  luaC_checkGC(L);\n  va_start(argp, fmt);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  va_end(argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {\n  Closure *cl;\n  lua_lock(L);\n  luaC_checkGC(L);\n  api_checknelems(L, n);\n  cl = luaF_newCclosure(L, n, getcurrenv(L));\n  cl->c.f = fn;\n  L->top -= n;\n  while (n--)\n    setobj2n(L, &cl->c.upvalue[n], L->top+n);\n  setclvalue(L, L->top, cl);\n  lua_assert(iswhite(obj2gco(cl)));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushboolean (lua_State *L, int b) {\n  lua_lock(L);\n  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlightuserdata (lua_State *L, void *p) {\n  lua_lock(L);\n  setpvalue(L->top, p);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_pushthread (lua_State *L) {\n  lua_lock(L);\n  setthvalue(L, L->top, L);\n  api_incr_top(L);\n  lua_unlock(L);\n  return (G(L)->mainthread == L);\n}\n\n\n\n/*\n** get functions (Lua -> stack)\n*/\n\n\nLUA_API void lua_gettable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_gettable(L, t, L->top - 1, L->top - 1);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_getfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_gettable(L, t, &key, L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawget (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawgeti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n"}, {"id": "F60717945B6029F5", "name": "lua_pushlightuserdata", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 511, "col": 1}, "end": {"line": 516, "col": 1}, "code": "  lua_lock(L);\n  setpvalue(L->top, p);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_pushthread (lua_State *L) {\n  lua_lock(L);\n  setthvalue(L, L->top, L);\n  api_incr_top(L);\n  lua_unlock(L);\n  return (G(L)->mainthread == L);\n}\n\n\n\n/*\n** get functions (Lua -> stack)\n*/\n\n\nLUA_API void lua_gettable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_gettable(L, t, L->top - 1, L->top - 1);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_getfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_gettable(L, t, &key, L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawget (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawgeti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n"}, {"id": "32474C60AB11C27B", "name": "lua_pushnil", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 421, "col": 1}, "end": {"line": 426, "col": 1}, "code": "  lua_lock(L);\n  setnilvalue(L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushnumber (lua_State *L, lua_Number n) {\n  lua_lock(L);\n  setnvalue(L->top, n);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushinteger (lua_State *L, lua_Integer n) {\n  lua_lock(L);\n  setnvalue(L->top, cast_num(n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlstring (lua_State *L, const char *s, size_t len) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  setsvalue2s(L, L->top, luaS_newlstr(L, s, len));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushstring (lua_State *L, const char *s) {\n  if (s == NULL)\n    lua_pushnil(L);\n  else\n    lua_pushlstring(L, s, strlen(s));\n}\n\n\nLUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,\n                                      va_list argp) {\n  const char *ret;\n  lua_lock(L);\n  luaC_checkGC(L);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {\n  const char *ret;\n  va_list argp;\n  lua_lock(L);\n  luaC_checkGC(L);\n  va_start(argp, fmt);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  va_end(argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {\n  Closure *cl;\n  lua_lock(L);\n  luaC_checkGC(L);\n  api_checknelems(L, n);\n  cl = luaF_newCclosure(L, n, getcurrenv(L));\n  cl->c.f = fn;\n  L->top -= n;\n  while (n--)\n    setobj2n(L, &cl->c.upvalue[n], L->top+n);\n  setclvalue(L, L->top, cl);\n  lua_assert(iswhite(obj2gco(cl)));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushboolean (lua_State *L, int b) {\n  lua_lock(L);\n  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlightuserdata (lua_State *L, void *p) {\n  lua_lock(L);\n  setpvalue(L->top, p);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_pushthread (lua_State *L) {\n  lua_lock(L);\n  setthvalue(L, L->top, L);\n  api_incr_top(L);\n  lua_unlock(L);\n  return (G(L)->mainthread == L);\n}\n\n\n\n/*\n** get functions (Lua -> stack)\n*/\n\n\nLUA_API void lua_gettable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_gettable(L, t, L->top - 1, L->top - 1);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_getfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_gettable(L, t, &key, L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawget (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawgeti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n"}, {"id": "890192A6EE151362", "name": "lua_settable", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 645, "col": 1}, "end": {"line": 654, "col": 1}, "code": "  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\nLUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  StkId fi;\n  lua_lock(L);\n  fi = index2adr(L, funcindex);\n  api_checknelems(L, 1);\n  name = aux_upvalue(fi, n, &val);\n  if (name) {\n    L->top--;\n    setobj(L, val, L->top);\n    luaC_barrier(L, clvalue(fi), L->top);\n  }\n  lua_unlock(L);\n  return name;\n}\n\nLUA_API void lua_enablereadonlytable (lua_State *L, int objindex, int enabled) {\n  const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  t->readonly = enabled;\n}\n\nLUA_API int lua_isreadonlytable (lua_State *L, int objindex) {\n    const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  return t->readonly;\n}\n\n"}], "code": "void luaSaveOnRegistry(lua_State* lua, const char* name, void* ptr) {\n    lua_pushstring(lua, name);\n    if (ptr) {\n        lua_pushlightuserdata(lua, ptr);\n    } else {\n        lua_pushnil(lua);\n    }\n    lua_settable(lua, LUA_REGISTRYINDEX);\n}\n"}, "EE3BEF081FCA3E6A": {"calls": [{"id": "F888D319FC2A2B2F", "name": "freeLuaScriptsAsync", "path": "redis/src/lazyfree.c", "start": {"line": 199, "col": 1}, "end": {"line": 206, "col": 1}, "code": "    if (dictSize(lua_scripts) > LAZYFREE_THRESHOLD) {\n        atomicIncr(lazyfree_objects,dictSize(lua_scripts));\n        bioCreateLazyFreeJob(lazyFreeLuaScripts,1,lua_scripts);\n    } else {\n        dictRelease(lua_scripts);\n    }\n}\n\n/* Free functions ctx, if the functions ctx contains enough functions, free it in async way. */\nvoid freeFunctionsAsync(functionsLibCtx *functions_lib_ctx) {\n    if (functionsLibCtxFunctionsLen(functions_lib_ctx) > LAZYFREE_THRESHOLD) {\n        atomicIncr(lazyfree_objects,functionsLibCtxFunctionsLen(functions_lib_ctx));\n        bioCreateLazyFreeJob(lazyFreeFunctionsCtx,1,functions_lib_ctx);\n    } else {\n        functionsLibCtxFree(functions_lib_ctx);\n    }\n}\n\n/* Free replication backlog referencing buffer blocks and rax index. */\nvoid freeReplicationBacklogRefMemAsync(list *blocks, rax *index) {\n    if (listLength(blocks) > LAZYFREE_THRESHOLD ||\n        raxSize(index) > LAZYFREE_THRESHOLD)\n    {\n        atomicIncr(lazyfree_objects,listLength(blocks)+raxSize(index));\n        bioCreateLazyFreeJob(lazyFreeReplicationBacklogRefMem,2,blocks,index);\n    } else {\n        listRelease(blocks);\n        raxFree(index);\n    }\n}\n"}, {"id": "50165A2C72336822", "name": "dictRelease", "path": "redis/src/dict.c", "start": {"line": 707, "col": 1}, "end": {"line": 712, "col": 1}, "code": "{\n    _dictClear(d,0,NULL);\n    _dictClear(d,1,NULL);\n    zfree(d);\n}\n\ndictEntry *dictFind(dict *d, const void *key)\n{\n    dictEntry *he;\n    uint64_t h, idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n\n    h = dictHashKey(d, key);\n    idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\nvoid *dictFetchValue(dict *d, const void *key) {\n    dictEntry *he;\n\n    he = dictFind(d,key);\n    return he ? dictGetVal(he) : NULL;\n}\n\n/* Find an element from the table, also get the plink of the entry. The entry\n * is returned if the element is found, and the user should later call\n * `dictTwoPhaseUnlinkFree` with it in order to unlink and release it. Otherwise if\n * the key is not found, NULL is returned. These two functions should be used in pair.\n * `dictTwoPhaseUnlinkFind` pauses rehash and `dictTwoPhaseUnlinkFree` resumes rehash.\n *\n * We can use like this:\n *\n * dictEntry *de = dictTwoPhaseUnlinkFind(db->dict,key->ptr,&plink, &table);\n * // Do something, but we can't modify the dict\n * dictTwoPhaseUnlinkFree(db->dict,de,plink,table); // We don't need to lookup again\n *\n * If we want to find an entry before delete this entry, this an optimization to avoid\n * dictFind followed by dictDelete. i.e. the first API is a find, and it gives some info\n * to the second one to avoid repeating the lookup\n */\ndictEntry *dictTwoPhaseUnlinkFind(dict *d, const void *key, dictEntry ***plink, int *table_index) {\n    uint64_t h, idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    h = dictHashKey(d, key);\n\n    for (table = 0; table <= 1; table++) {\n        idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        dictEntry **ref = &d->ht_table[table][idx];\n        while (ref && *ref) {\n            void *de_key = dictGetKey(*ref);\n            if (key == de_key || dictCompareKeys(d, key, de_key)) {\n                *table_index = table;\n                *plink = ref;\n                dictPauseRehashing(d);\n                return *ref;\n            }\n            ref = dictGetNextRef(*ref);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\nvoid dictTwoPhaseUnlinkFree(dict *d, dictEntry *he, dictEntry **plink, int table_index) {\n    if (he == NULL) return;\n    d->ht_used[table_index]--;\n    *plink = dictGetNext(he);\n    dictFreeKey(d, he);\n    dictFreeVal(d, he);\n    if (!entryIsKey(he)) zfree(decodeMaskedPtr(he));\n    _dictShrinkIfNeeded(d);\n    dictResumeRehashing(d);\n}\n\nvoid dictSetKey(dict *d, dictEntry* de, void *key) {\n    assert(!d->type->no_value);\n    if (d->type->keyDup)\n        de->key = d->type->keyDup(d, key);\n    else\n        de->key = key;\n}\n\nvoid dictSetVal(dict *d, dictEntry *de, void *val) {\n    assert(entryHasValue(de));\n    de->v.val = d->type->valDup ? d->type->valDup(d, val) : val;\n}\n\nvoid dictSetSignedIntegerVal(dictEntry *de, int64_t val) {\n    assert(entryHasValue(de));\n    de->v.s64 = val;\n}\n\nvoid dictSetUnsignedIntegerVal(dictEntry *de, uint64_t val) {\n    assert(entryHasValue(de));\n    de->v.u64 = val;\n}\n\nvoid dictSetDoubleVal(dictEntry *de, double val) {\n    assert(entryHasValue(de));\n    de->v.d = val;\n}\n\nint64_t dictIncrSignedIntegerVal(dictEntry *de, int64_t val) {\n    assert(entryHasValue(de));\n    return de->v.s64 += val;\n}\n\nuint64_t dictIncrUnsignedIntegerVal(dictEntry *de, uint64_t val) {\n    assert(entryHasValue(de));\n    return de->v.u64 += val;\n}\n\ndouble dictIncrDoubleVal(dictEntry *de, double val) {\n    assert(entryHasValue(de));\n    return de->v.d += val;\n}\n\nvoid *dictGetKey(const dictEntry *de) {\n    if (entryIsKey(de)) return (void*)de;\n    if (entryIsNoValue(de)) return decodeEntryNoValue(de)->key;\n    return de->key;\n}\n\nvoid *dictGetVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.val;\n}\n\nint64_t dictGetSignedIntegerVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.s64;\n}\n\nuint64_t dictGetUnsignedIntegerVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.u64;\n}\n\ndouble dictGetDoubleVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.d;\n}\n\n/* Returns a mutable reference to the value as a double within the entry. */\ndouble *dictGetDoubleValPtr(dictEntry *de) {\n    assert(entryHasValue(de));\n    return &de->v.d;\n}\n\n/* Returns the 'next' field of the entry or NULL if the entry doesn't have a\n * 'next' field. */\nstatic dictEntry *dictGetNext(const dictEntry *de) {\n    if (entryIsKey(de)) return NULL; /* there's no next */\n    if (entryIsNoValue(de)) return decodeEntryNoValue(de)->next;\n    return de->next;\n}\n\n/* Returns a pointer to the 'next' field in the entry or NULL if the entry\n * doesn't have a next field. */\nstatic dictEntry **dictGetNextRef(dictEntry *de) {\n    if (entryIsKey(de)) return NULL;\n    if (entryIsNoValue(de)) return &decodeEntryNoValue(de)->next;\n    return &de->next;\n}\n\nstatic void dictSetNext(dictEntry *de, dictEntry *next) {\n    assert(!entryIsKey(de));\n    if (entryIsNoValue(de)) {\n        dictEntryNoValue *entry = decodeEntryNoValue(de);\n        entry->next = next;\n    } else {\n        de->next = next;\n    }\n}\n\n/* Returns the memory usage in bytes of the dict, excluding the size of the keys\n * and values. */\nsize_t dictMemUsage(const dict *d) {\n    return dictSize(d) * sizeof(dictEntry) +\n        dictBuckets(d) * sizeof(dictEntry*);\n}\n\nsize_t dictEntryMemUsage(void) {\n    return sizeof(dictEntry);\n}\n\n/* A fingerprint is a 64 bit number that represents the state of the dictionary\n * at a given time, it's just a few dict properties xored together.\n * When an unsafe iterator is initialized, we get the dict fingerprint, and check\n * the fingerprint again when the iterator is released.\n * If the two fingerprints are different it means that the user of the iterator\n * performed forbidden operations against the dictionary while iterating. */\nunsigned long long dictFingerprint(dict *d) {\n    unsigned long long integers[6], hash = 0;\n    int j;\n\n    integers[0] = (long) d->ht_table[0];\n    integers[1] = d->ht_size_exp[0];\n    integers[2] = d->ht_used[0];\n    integers[3] = (long) d->ht_table[1];\n    integers[4] = d->ht_size_exp[1];\n    integers[5] = d->ht_used[1];\n\n    /* We hash N integers by summing every successive integer with the integer\n     * hashing of the previous sum. Basically:\n     *\n     * Result = hash(hash(hash(int1)+int2)+int3) ...\n     *\n     * This way the same set of integers in a different order will (likely) hash\n     * to a different number. */\n    for (j = 0; j < 6; j++) {\n        hash += integers[j];\n        /* For the hashing step we use Tomas Wang's 64 bit integer hash. */\n        hash = (~hash) + (hash << 21); // hash = (hash << 21) - hash - 1;\n        hash = hash ^ (hash >> 24);\n        hash = (hash + (hash << 3)) + (hash << 8); // hash * 265\n        hash = hash ^ (hash >> 14);\n        hash = (hash + (hash << 2)) + (hash << 4); // hash * 21\n        hash = hash ^ (hash >> 28);\n        hash = hash + (hash << 31);\n    }\n    return hash;\n}\n\nvoid dictInitIterator(dictIterator *iter, dict *d)\n{\n    iter->d = d;\n    iter->table = 0;\n    iter->index = -1;\n    iter->safe = 0;\n    iter->entry = NULL;\n    iter->nextEntry = NULL;\n}\n\nvoid dictInitSafeIterator(dictIterator *iter, dict *d)\n{\n    dictInitIterator(iter, d);\n    iter->safe = 1;\n}\n\nvoid dictResetIterator(dictIterator *iter)\n{\n    if (!(iter->index == -1 && iter->table == 0)) {\n        if (iter->safe)\n            dictResumeRehashing(iter->d);\n        else\n            assert(iter->fingerprint == dictFingerprint(iter->d));\n    }\n}\n\ndictIterator *dictGetIterator(dict *d)\n{\n    dictIterator *iter = zmalloc(sizeof(*iter));\n    dictInitIterator(iter, d);\n    return iter;\n}\n\ndictIterator *dictGetSafeIterator(dict *d) {\n    dictIterator *i = dictGetIterator(d);\n\n    i->safe = 1;\n    return i;\n}\n\ndictEntry *dictNext(dictIterator *iter)\n{\n    while (1) {\n        if (iter->entry == NULL) {\n            if (iter->index == -1 && iter->table == 0) {\n                if (iter->safe)\n                    dictPauseRehashing(iter->d);\n                else\n                    iter->fingerprint = dictFingerprint(iter->d);\n\n                /* skip the rehashed slots in table[0] */\n                if (dictIsRehashing(iter->d)) {\n                    iter->index = iter->d->rehashidx - 1;\n                }\n            }\n            iter->index++;\n            if (iter->index >= (long) DICTHT_SIZE(iter->d->ht_size_exp[iter->table])) {\n                if (dictIsRehashing(iter->d) && iter->table == 0) {\n                    iter->table++;\n                    iter->index = 0;\n                } else {\n                    break;\n                }\n            }\n            iter->entry = iter->d->ht_table[iter->table][iter->index];\n        } else {\n            iter->entry = iter->nextEntry;\n        }\n        if (iter->entry) {\n            /* We need to save the 'next' here, the iterator user\n             * may delete the entry we are returning. */\n            iter->nextEntry = dictGetNext(iter->entry);\n            return iter->entry;\n        }\n    }\n    return NULL;\n}\n\nvoid dictReleaseIterator(dictIterator *iter)\n{\n    dictResetIterator(iter);\n    zfree(iter);\n}\n\n/* Return a random entry from the hash table. Useful to\n * implement randomized algorithms */\ndictEntry *dictGetRandomKey(dict *d)\n{\n    dictEntry *he, *orighe;\n    unsigned long h;\n    int listlen, listele;\n\n    if (dictSize(d) == 0) return NULL;\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    if (dictIsRehashing(d)) {\n        unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n        do {\n            /* We are sure there are no elements in indexes from 0\n             * to rehashidx-1 */\n            h = d->rehashidx + (randomULong() % (dictBuckets(d) - d->rehashidx));\n            he = (h >= s0) ? d->ht_table[1][h - s0] : d->ht_table[0][h];\n        } while(he == NULL);\n    } else {\n        unsigned long m = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n        do {\n            h = randomULong() & m;\n            he = d->ht_table[0][h];\n        } while(he == NULL);\n    }\n\n    /* Now we found a non empty bucket, but it is a linked\n     * list and we need to get a random element from the list.\n     * The only sane way to do so is counting the elements and\n     * select a random index. */\n    listlen = 0;\n    orighe = he;\n    while(he) {\n        he = dictGetNext(he);\n        listlen++;\n    }\n    listele = random() % listlen;\n    he = orighe;\n    while(listele--) he = dictGetNext(he);\n    return he;\n}\n\n/* This function samples the dictionary to return a few keys from random\n * locations.\n *\n * It does not guarantee to return all the keys specified in 'count', nor\n * it does guarantee to return non-duplicated elements, however it will make\n * some effort to do both things.\n *\n * Returned pointers to hash table entries are stored into 'des' that\n * points to an array of dictEntry pointers. The array must have room for\n * at least 'count' elements, that is the argument we pass to the function\n * to tell how many random elements we need.\n *\n * The function returns the number of items stored into 'des', that may\n * be less than 'count' if the hash table has less than 'count' elements\n * inside, or if not enough elements were found in a reasonable amount of\n * steps.\n *\n * Note that this function is not suitable when you need a good distribution\n * of the returned items, but only when you need to \"sample\" a given number\n * of continuous elements to run some kind of algorithm or to produce\n * statistics. However the function is much faster than dictGetRandomKey()\n * at producing N elements. */\nunsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) {\n    unsigned long j; /* internal hash table id, 0 or 1. */\n    unsigned long tables; /* 1 or 2 tables? */\n    unsigned long stored = 0, maxsizemask;\n    unsigned long maxsteps;\n\n    if (dictSize(d) < count) count = dictSize(d);\n    maxsteps = count*10;\n\n    /* Try to do a rehashing work proportional to 'count'. */\n    for (j = 0; j < count; j++) {\n        if (dictIsRehashing(d))\n            _dictRehashStep(d);\n        else\n            break;\n    }\n\n    tables = dictIsRehashing(d) ? 2 : 1;\n    maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n    if (tables > 1 && maxsizemask < DICTHT_SIZE_MASK(d->ht_size_exp[1]))\n        maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n\n    /* Pick a random point inside the larger table. */\n    unsigned long i = randomULong() & maxsizemask;\n    unsigned long emptylen = 0; /* Continuous empty entries so far. */\n    while(stored < count && maxsteps--) {\n        for (j = 0; j < tables; j++) {\n            /* Invariant of the dict.c rehashing: up to the indexes already\n             * visited in ht[0] during the rehashing, there are no populated\n             * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */\n            if (tables == 2 && j == 0 && i < (unsigned long) d->rehashidx) {\n                /* Moreover, if we are currently out of range in the second\n                 * table, there will be no elements in both tables up to\n                 * the current rehashing index, so we jump if possible.\n                 * (this happens when going from big to small table). */\n                if (i >= DICTHT_SIZE(d->ht_size_exp[1]))\n                    i = d->rehashidx;\n                else\n                    continue;\n            }\n            if (i >= DICTHT_SIZE(d->ht_size_exp[j])) continue; /* Out of range for this table. */\n            dictEntry *he = d->ht_table[j][i];\n\n            /* Count contiguous empty buckets, and jump to other\n             * locations if they reach 'count' (with a minimum of 5). */\n            if (he == NULL) {\n                emptylen++;\n                if (emptylen >= 5 && emptylen > count) {\n                    i = randomULong() & maxsizemask;\n                    emptylen = 0;\n                }\n            } else {\n                emptylen = 0;\n                while (he) {\n                    /* Collect all the elements of the buckets found non empty while iterating.\n                     * To avoid the issue of being unable to sample the end of a long chain,\n                     * we utilize the Reservoir Sampling algorithm to optimize the sampling process.\n                     * This means that even when the maximum number of samples has been reached,\n                     * we continue sampling until we reach the end of the chain.\n                     * See https://en.wikipedia.org/wiki/Reservoir_sampling. */\n                    if (stored < count) {\n                        des[stored] = he;\n                    } else {\n                        unsigned long r = randomULong() % (stored + 1);\n                        if (r < count) des[r] = he;\n                    }\n\n                    he = dictGetNext(he);\n                    stored++;\n                }\n                if (stored >= count) goto end;\n            }\n        }\n        i = (i+1) & maxsizemask;\n    }\n\nend:\n    return stored > count ? count : stored;\n}\n\n\n/* Reallocate the dictEntry, key and value allocations in a bucket using the\n * provided allocation functions in order to defrag them. */\nstatic void dictDefragBucket(dictEntry **bucketref, dictDefragFunctions *defragfns) {\n    dictDefragAllocFunction *defragalloc = defragfns->defragAlloc;\n    dictDefragAllocFunction *defragkey = defragfns->defragKey;\n    dictDefragAllocFunction *defragval = defragfns->defragVal;\n    while (bucketref && *bucketref) {\n        dictEntry *de = *bucketref, *newde = NULL;\n        void *newkey = defragkey ? defragkey(dictGetKey(de)) : NULL;\n        void *newval = defragval ? defragval(dictGetVal(de)) : NULL;\n        if (entryIsKey(de)) {\n            if (newkey) *bucketref = newkey;\n            assert(entryIsKey(*bucketref));\n        } else if (entryIsNoValue(de)) {\n            dictEntryNoValue *entry = decodeEntryNoValue(de), *newentry;\n            if ((newentry = defragalloc(entry))) {\n                newde = encodeMaskedPtr(newentry, ENTRY_PTR_NO_VALUE);\n                entry = newentry;\n            }\n            if (newkey) entry->key = newkey;\n        } else {\n            assert(entryIsNormal(de));\n            newde = defragalloc(de);\n            if (newde) de = newde;\n            if (newkey) de->key = newkey;\n            if (newval) de->v.val = newval;\n        }\n        if (newde) {\n            *bucketref = newde;\n        }\n        bucketref = dictGetNextRef(*bucketref);\n    }\n}\n\n/* This is like dictGetRandomKey() from the POV of the API, but will do more\n * work to ensure a better distribution of the returned element.\n *\n * This function improves the distribution because the dictGetRandomKey()\n * problem is that it selects a random bucket, then it selects a random\n * element from the chain in the bucket. However elements being in different\n * chain lengths will have different probabilities of being reported. With\n * this function instead what we do is to consider a \"linear\" range of the table\n * that may be constituted of N buckets with chains of different lengths\n * appearing one after the other. Then we report a random element in the range.\n * In this way we smooth away the problem of different chain lengths. */\n#define GETFAIR_NUM_ENTRIES 15\ndictEntry *dictGetFairRandomKey(dict *d) {\n    dictEntry *entries[GETFAIR_NUM_ENTRIES];\n    unsigned int count = dictGetSomeKeys(d,entries,GETFAIR_NUM_ENTRIES);\n    /* Note that dictGetSomeKeys() may return zero elements in an unlucky\n     * run() even if there are actually elements inside the hash table. So\n     * when we get zero, we call the true dictGetRandomKey() that will always\n     * yield the element if the hash table has at least one. */\n    if (count == 0) return dictGetRandomKey(d);\n    unsigned int idx = rand() % count;\n    return entries[idx];\n}\n\n/* Function to reverse bits. Algorithm from:\n * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */\nstatic unsigned long rev(unsigned long v) {\n    unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2\n    unsigned long mask = ~0UL;\n    while ((s >>= 1) > 0) {\n        mask ^= (mask << s);\n        v = ((v >> s) & mask) | ((v << s) & ~mask);\n    }\n    return v;\n}\n\n/* dictScan() is used to iterate over the elements of a dictionary.\n *\n * Iterating works the following way:\n *\n * 1) Initially you call the function using a cursor (v) value of 0.\n * 2) The function performs one step of the iteration, and returns the\n *    new cursor value you must use in the next call.\n * 3) When the returned cursor is 0, the iteration is complete.\n *\n * The function guarantees all elements present in the\n * dictionary get returned between the start and end of the iteration.\n * However it is possible some elements get returned multiple times.\n *\n * For every element returned, the callback argument 'fn' is\n * called with 'privdata' as first argument and the dictionary entry\n * 'de' as second argument.\n *\n * HOW IT WORKS.\n *\n * The iteration algorithm was designed by Pieter Noordhuis.\n * The main idea is to increment a cursor starting from the higher order\n * bits. That is, instead of incrementing the cursor normally, the bits\n * of the cursor are reversed, then the cursor is incremented, and finally\n * the bits are reversed again.\n *\n * This strategy is needed because the hash table may be resized between\n * iteration calls.\n *\n * dict.c hash tables are always power of two in size, and they\n * use chaining, so the position of an element in a given table is given\n * by computing the bitwise AND between Hash(key) and SIZE-1\n * (where SIZE-1 is always the mask that is equivalent to taking the rest\n *  of the division between the Hash of the key and SIZE).\n *\n * For example if the current hash table size is 16, the mask is\n * (in binary) 1111. The position of a key in the hash table will always be\n * the last four bits of the hash output, and so forth.\n *\n * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE?\n *\n * If the hash table grows, elements can go anywhere in one multiple of\n * the old bucket: for example let's say we already iterated with\n * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16).\n *\n * If the hash table will be resized to 64 elements, then the new mask will\n * be 111111. The new buckets you obtain by substituting in ??1100\n * with either 0 or 1 can be targeted only by keys we already visited\n * when scanning the bucket 1100 in the smaller hash table.\n *\n * By iterating the higher bits first, because of the inverted counter, the\n * cursor does not need to restart if the table size gets bigger. It will\n * continue iterating using cursors without '1100' at the end, and also\n * without any other combination of the final 4 bits already explored.\n *\n * Similarly when the table size shrinks over time, for example going from\n * 16 to 8, if a combination of the lower three bits (the mask for size 8\n * is 111) were already completely explored, it would not be visited again\n * because we are sure we tried, for example, both 0111 and 1111 (all the\n * variations of the higher bit) so we don't need to test it again.\n *\n * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING!\n *\n * Yes, this is true, but we always iterate the smaller table first, then\n * we test all the expansions of the current cursor into the larger\n * table. For example if the current cursor is 101 and we also have a\n * larger table of size 16, we also test (0)101 and (1)101 inside the larger\n * table. This reduces the problem back to having only one table, where\n * the larger one, if it exists, is just an expansion of the smaller one.\n *\n * LIMITATIONS\n *\n * This iterator is completely stateless, and this is a huge advantage,\n * including no additional memory used.\n *\n * The disadvantages resulting from this design are:\n *\n * 1) It is possible we return elements more than once. However this is usually\n *    easy to deal with in the application level.\n * 2) The iterator must return multiple elements per call, as it needs to always\n *    return all the keys chained in a given bucket, and all the expansions, so\n *    we are sure we don't miss keys moving during rehashing.\n * 3) The reverse cursor is somewhat hard to understand at first, but this\n *    comment is supposed to help.\n */\nunsigned long dictScan(dict *d,\n                       unsigned long v,\n                       dictScanFunction *fn,\n                       void *privdata)\n{\n    return dictScanDefrag(d, v, fn, NULL, privdata);\n}\n\n/* Like dictScan, but additionally reallocates the memory used by the dict\n * entries using the provided allocation function. This feature was added for\n * the active defrag feature.\n *\n * The 'defragfns' callbacks are called with a pointer to memory that callback\n * can reallocate. The callbacks should return a new memory address or NULL,\n * where NULL means that no reallocation happened and the old memory is still\n * valid. */\nunsigned long dictScanDefrag(dict *d,\n                             unsigned long v,\n                             dictScanFunction *fn,\n                             dictDefragFunctions *defragfns,\n                             void *privdata)\n{\n    int htidx0, htidx1;\n    const dictEntry *de, *next;\n    unsigned long m0, m1;\n\n    if (dictSize(d) == 0) return 0;\n\n    /* This is needed in case the scan callback tries to do dictFind or alike. */\n    dictPauseRehashing(d);\n\n    if (!dictIsRehashing(d)) {\n        htidx0 = 0;\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Set unmasked bits so incrementing the reversed cursor\n         * operates on the masked bits */\n        v |= ~m0;\n\n        /* Increment the reverse cursor */\n        v = rev(v);\n        v++;\n        v = rev(v);\n\n    } else {\n        htidx0 = 0;\n        htidx1 = 1;\n\n        /* Make sure t0 is the smaller and t1 is the bigger table */\n        if (DICTHT_SIZE(d->ht_size_exp[htidx0]) > DICTHT_SIZE(d->ht_size_exp[htidx1])) {\n            htidx0 = 1;\n            htidx1 = 0;\n        }\n\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n        m1 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx1]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n"}, {"id": "E0C987F1C8B0FBD9", "name": "lua_close", "path": "redis/deps/lua/src/lstate.c", "start": {"line": 199, "col": 1}, "end": {"line": 213, "col": 1}, "code": "  L = G(L)->mainthread;  /* only the main thread can be closed */\n  lua_lock(L);\n  luaF_close(L, L->stack);  /* close all upvalues for this thread */\n  luaC_separateudata(L, 1);  /* separate udata that have GC metamethods */\n  L->errfunc = 0;  /* no error function during GC metamethods */\n  do {  /* repeat until no more errors */\n    L->ci = L->base_ci;\n    L->base = L->top = L->ci->base;\n    L->nCcalls = L->baseCcalls = 0;\n  } while (luaD_rawrunprotected(L, callallgcTM, NULL) != 0);\n  lua_assert(G(L)->tmudata == NULL);\n  luai_userstateclose(L);\n  close_state(L);\n}\n\n"}], "code": "void scriptingRelease(int async) {\n    if (async)\n        freeLuaScriptsAsync(lctx.lua_scripts);\n    else\n        dictRelease(lctx.lua_scripts);\n    lctx.lua_scripts_mem = 0;\n    lua_close(lctx.lua);\n}\n"}, "79DA9CB3C0C6D261": {"calls": [{"id": "7CCDA4A627DA6C15", "name": "lua_pushstring", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 454, "col": 1}, "end": {"line": 459, "col": 1}, "code": "  if (s == NULL)\n    lua_pushnil(L);\n  else\n    lua_pushlstring(L, s, strlen(s));\n}\n\n\nLUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,\n                                      va_list argp) {\n  const char *ret;\n  lua_lock(L);\n  luaC_checkGC(L);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {\n  const char *ret;\n  va_list argp;\n  lua_lock(L);\n  luaC_checkGC(L);\n  va_start(argp, fmt);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  va_end(argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {\n  Closure *cl;\n  lua_lock(L);\n  luaC_checkGC(L);\n  api_checknelems(L, n);\n  cl = luaF_newCclosure(L, n, getcurrenv(L));\n  cl->c.f = fn;\n  L->top -= n;\n  while (n--)\n    setobj2n(L, &cl->c.upvalue[n], L->top+n);\n  setclvalue(L, L->top, cl);\n  lua_assert(iswhite(obj2gco(cl)));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushboolean (lua_State *L, int b) {\n  lua_lock(L);\n  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlightuserdata (lua_State *L, void *p) {\n  lua_lock(L);\n  setpvalue(L->top, p);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_pushthread (lua_State *L) {\n  lua_lock(L);\n  setthvalue(L, L->top, L);\n  api_incr_top(L);\n  lua_unlock(L);\n  return (G(L)->mainthread == L);\n}\n\n\n\n/*\n** get functions (Lua -> stack)\n*/\n\n\nLUA_API void lua_gettable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_gettable(L, t, L->top - 1, L->top - 1);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_getfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_gettable(L, t, &key, L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawget (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawgeti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n"}, {"id": "EB3D1F76E96C2A48", "name": "lua_gettable", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 534, "col": 1}, "end": {"line": 541, "col": 1}, "code": "  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_gettable(L, t, L->top - 1, L->top - 1);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_getfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_gettable(L, t, &key, L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawget (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawgeti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\n"}, {"id": "7EB0D1A6219EE04D", "name": "lua_rawgeti", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 567, "col": 1}, "end": {"line": 575, "col": 1}, "code": "  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_createtable (lua_State *L, int narray, int nrec) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  sethvalue(L, L->top, luaH_new(L, narray, nrec));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_getmetatable (lua_State *L, int objindex) {\n  const TValue *obj;\n  Table *mt = NULL;\n  int res;\n  lua_lock(L);\n  obj = index2adr(L, objindex);\n  switch (ttype(obj)) {\n    case LUA_TTABLE:\n      mt = hvalue(obj)->metatable;\n      break;\n    case LUA_TUSERDATA:\n      mt = uvalue(obj)->metatable;\n      break;\n    default:\n      mt = G(L)->mt[ttype(obj)];\n      break;\n  }\n  if (mt == NULL)\n    res = 0;\n  else {\n    sethvalue(L, L->top, mt);\n    api_incr_top(L);\n    res = 1;\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\nLUA_API void lua_getfenv (lua_State *L, int idx) {\n  StkId o;\n  lua_lock(L);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      sethvalue(L, L->top, clvalue(o)->c.env);\n      break;\n    case LUA_TUSERDATA:\n      sethvalue(L, L->top, uvalue(o)->env);\n      break;\n    case LUA_TTHREAD:\n      setobj2s(L, L->top,  gt(thvalue(o)));\n      break;\n    default:\n      setnilvalue(L->top);\n      break;\n  }\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\n/*\n** set functions (stack -> Lua)\n*/\n\n\nLUA_API void lua_settable (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  luaV_settable(L, t, L->top - 2, L->top - 1);\n  L->top -= 2;  /* pop index and value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_setfield (lua_State *L, int idx, const char *k) {\n  StkId t;\n  TValue key;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  t = index2adr(L, idx);\n  api_checkvalidindex(L, t);\n  setsvalue(L, &key, luaS_new(L, k));\n  luaV_settable(L, t, &key, L->top - 1);\n  L->top--;  /* pop value */\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawset (lua_State *L, int idx) {\n  StkId t;\n  lua_lock(L);\n  api_checknelems(L, 2);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  if (hvalue(t)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);\n  luaC_barriert(L, hvalue(t), L->top-1);\n  L->top -= 2;\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_rawseti (lua_State *L, int idx, int n) {\n  StkId o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_check(L, ttistable(o));\n  if (hvalue(o)->readonly)\n    luaG_runerror(L, \"Attempt to modify a readonly table\");\n  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);\n  luaC_barriert(L, hvalue(o), L->top-1);\n  L->top--;\n  lua_unlock(L);\n}\n\n\nLUA_API int lua_setmetatable (lua_State *L, int objindex) {\n  TValue *obj;\n  Table *mt;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  obj = index2adr(L, objindex);\n  api_checkvalidindex(L, obj);\n  if (ttisnil(L->top - 1))\n    mt = NULL;\n  else {\n    api_check(L, ttistable(L->top - 1));\n    mt = hvalue(L->top - 1);\n  }\n  switch (ttype(obj)) {\n    case LUA_TTABLE: {\n      if (hvalue(obj)->readonly)\n        luaG_runerror(L, \"Attempt to modify a readonly table\");\n      hvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarriert(L, hvalue(obj), mt);\n      break;\n    }\n    case LUA_TUSERDATA: {\n      uvalue(obj)->metatable = mt;\n      if (mt)\n        luaC_objbarrier(L, rawuvalue(obj), mt);\n      break;\n    }\n    default: {\n      G(L)->mt[ttype(obj)] = mt;\n      break;\n    }\n  }\n  L->top--;\n  lua_unlock(L);\n  return 1;\n}\n\n\nLUA_API int lua_setfenv (lua_State *L, int idx) {\n  StkId o;\n  int res = 1;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = index2adr(L, idx);\n  api_checkvalidindex(L, o);\n  api_check(L, ttistable(L->top - 1));\n  switch (ttype(o)) {\n    case LUA_TFUNCTION:\n      clvalue(o)->c.env = hvalue(L->top - 1);\n      break;\n    case LUA_TUSERDATA:\n      uvalue(o)->env = hvalue(L->top - 1);\n      break;\n    case LUA_TTHREAD:\n      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));\n      break;\n    default:\n      res = 0;\n      break;\n  }\n  if (res) luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));\n  L->top--;\n  lua_unlock(L);\n  return res;\n}\n\n\n/*\n** `load' and `call' functions (run Lua code)\n*/\n\n\n#define adjustresults(L,nres) \\\n    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }\n\n\n#define checkresults(L,na,nr) \\\n     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))\n\t\n\nLUA_API void lua_call (lua_State *L, int nargs, int nresults) {\n  StkId func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  func = L->top - (nargs+1);\n  luaD_call(L, func, nresults);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n}\n\n\n\n/*\n** Execute a protected call.\n*/\nstruct CallS {  /* data to `f_call' */\n  StkId func;\n  int nresults;\n};\n\n\nstatic void f_call (lua_State *L, void *ud) {\n  struct CallS *c = cast(struct CallS *, ud);\n  luaD_call(L, c->func, c->nresults);\n}\n\n\n\nLUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {\n  struct CallS c;\n  int status;\n  ptrdiff_t func;\n  lua_lock(L);\n  api_checknelems(L, nargs+1);\n  checkresults(L, nargs, nresults);\n  if (errfunc == 0)\n    func = 0;\n  else {\n    StkId o = index2adr(L, errfunc);\n    api_checkvalidindex(L, o);\n    func = savestack(L, o);\n  }\n  c.func = L->top - (nargs+1);  /* function to be called */\n  c.nresults = nresults;\n  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);\n  adjustresults(L, nresults);\n  lua_unlock(L);\n  return status;\n}\n\n\n/*\n** Execute a protected C call.\n*/\nstruct CCallS {  /* data to `f_Ccall' */\n  lua_CFunction func;\n  void *ud;\n};\n\n\nstatic void f_Ccall (lua_State *L, void *ud) {\n  struct CCallS *c = cast(struct CCallS *, ud);\n  Closure *cl;\n  cl = luaF_newCclosure(L, 0, getcurrenv(L));\n  cl->c.f = c->func;\n  setclvalue(L, L->top, cl);  /* push function */\n  api_incr_top(L);\n  setpvalue(L->top, c->ud);  /* push only argument */\n  api_incr_top(L);\n  luaD_call(L, L->top - 2, 0);\n}\n\n\nLUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {\n  struct CCallS c;\n  int status;\n  lua_lock(L);\n  c.func = func;\n  c.ud = ud;\n  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,\n                      const char *chunkname) {\n  ZIO z;\n  int status;\n  lua_lock(L);\n  if (!chunkname) chunkname = \"?\";\n  luaZ_init(L, &z, reader, data);\n  status = luaD_protectedparser(L, &z, chunkname);\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {\n  int status;\n  TValue *o;\n  lua_lock(L);\n  api_checknelems(L, 1);\n  o = L->top - 1;\n  if (isLfunction(o))\n    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);\n  else\n    status = 1;\n  lua_unlock(L);\n  return status;\n}\n\n\nLUA_API int  lua_status (lua_State *L) {\n  return L->status;\n}\n\n\n/*\n** Garbage-collection function\n*/\n\nLUA_API int lua_gc (lua_State *L, int what, int data) {\n  int res = 0;\n  global_State *g;\n  lua_lock(L);\n  g = G(L);\n  switch (what) {\n    case LUA_GCSTOP: {\n      g->GCthreshold = MAX_LUMEM;\n      break;\n    }\n    case LUA_GCRESTART: {\n      g->GCthreshold = g->totalbytes;\n      break;\n    }\n    case LUA_GCCOLLECT: {\n      luaC_fullgc(L);\n      break;\n    }\n    case LUA_GCCOUNT: {\n      /* GC values are expressed in Kbytes: #bytes/2^10 */\n      res = cast_int(g->totalbytes >> 10);\n      break;\n    }\n    case LUA_GCCOUNTB: {\n      res = cast_int(g->totalbytes & 0x3ff);\n      break;\n    }\n    case LUA_GCSTEP: {\n      lu_mem a = (cast(lu_mem, data) << 10);\n      if (a <= g->totalbytes)\n        g->GCthreshold = g->totalbytes - a;\n      else\n        g->GCthreshold = 0;\n      while (g->GCthreshold <= g->totalbytes) {\n        luaC_step(L);\n        if (g->gcstate == GCSpause) {  /* end of cycle? */\n          res = 1;  /* signal it */\n          break;\n        }\n      }\n      break;\n    }\n    case LUA_GCSETPAUSE: {\n      res = g->gcpause;\n      g->gcpause = data;\n      break;\n    }\n    case LUA_GCSETSTEPMUL: {\n      res = g->gcstepmul;\n      g->gcstepmul = data;\n      break;\n    }\n    default: res = -1;  /* invalid option */\n  }\n  lua_unlock(L);\n  return res;\n}\n\n\n\n/*\n** miscellaneous functions\n*/\n\n\nLUA_API int lua_error (lua_State *L) {\n  lua_lock(L);\n  api_checknelems(L, 1);\n  luaG_errormsg(L);\n  lua_unlock(L);\n  return 0;  /* to avoid warnings */\n}\n\n\nLUA_API int lua_next (lua_State *L, int idx) {\n  StkId t;\n  int more;\n  lua_lock(L);\n  t = index2adr(L, idx);\n  api_check(L, ttistable(t));\n  more = luaH_next(L, hvalue(t), L->top - 1);\n  if (more) {\n    api_incr_top(L);\n  }\n  else  /* no more elements */\n    L->top -= 1;  /* remove key */\n  lua_unlock(L);\n  return more;\n}\n\n\nLUA_API void lua_concat (lua_State *L, int n) {\n  lua_lock(L);\n  api_checknelems(L, n);\n  if (n >= 2) {\n    luaC_checkGC(L);\n    luaV_concat(L, n, cast_int(L->top - L->base) - 1);\n    L->top -= (n-1);\n  }\n  else if (n == 0) {  /* push empty string */\n    setsvalue2s(L, L->top, luaS_newlstr(L, \"\", 0));\n    api_incr_top(L);\n  }\n  /* else n == 1; nothing to do */\n  lua_unlock(L);\n}\n\n\nLUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {\n  lua_Alloc f;\n  lua_lock(L);\n  if (ud) *ud = G(L)->ud;\n  f = G(L)->frealloc;\n  lua_unlock(L);\n  return f;\n}\n\n\nLUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {\n  lua_lock(L);\n  G(L)->ud = ud;\n  G(L)->frealloc = f;\n  lua_unlock(L);\n}\n\n\nLUA_API void *lua_newuserdata (lua_State *L, size_t size) {\n  Udata *u;\n  lua_lock(L);\n  luaC_checkGC(L);\n  u = luaS_newudata(L, size, getcurrenv(L));\n  setuvalue(L, L->top, u);\n  api_incr_top(L);\n  lua_unlock(L);\n  return u + 1;\n}\n\n\n\n\nstatic const char *aux_upvalue (StkId fi, int n, TValue **val) {\n  Closure *f;\n  if (!ttisfunction(fi)) return NULL;\n  f = clvalue(fi);\n  if (f->c.isC) {\n    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;\n    *val = &f->c.upvalue[n-1];\n    return \"\";\n  }\n  else {\n    Proto *p = f->l.p;\n    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;\n    *val = f->l.upvals[n-1]->v;\n    return getstr(p->upvalues[n-1]);\n  }\n}\n\n\nLUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  lua_lock(L);\n  name = aux_upvalue(index2adr(L, funcindex), n, &val);\n  if (name) {\n    setobj2s(L, L->top, val);\n    api_incr_top(L);\n  }\n  lua_unlock(L);\n  return name;\n}\n\n\nLUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {\n  const char *name;\n  TValue *val;\n  StkId fi;\n  lua_lock(L);\n  fi = index2adr(L, funcindex);\n  api_checknelems(L, 1);\n  name = aux_upvalue(fi, n, &val);\n  if (name) {\n    L->top--;\n    setobj(L, val, L->top);\n    luaC_barrier(L, clvalue(fi), L->top);\n  }\n  lua_unlock(L);\n  return name;\n}\n\nLUA_API void lua_enablereadonlytable (lua_State *L, int objindex, int enabled) {\n  const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  t->readonly = enabled;\n}\n\nLUA_API int lua_isreadonlytable (lua_State *L, int objindex) {\n    const TValue* o = index2adr(L, objindex);\n  api_check(L, ttistable(o));\n  Table* t = hvalue(o);\n  api_check(L, t != hvalue(registry(L)));\n  return t->readonly;\n}\n\n"}, {"id": "836CB611094047F3", "name": "lua_type", "path": "redis/deps/lua/src/lapi.c", "start": {"line": 242, "col": 1}, "end": {"line": 245, "col": 1}, "code": "  StkId o = index2adr(L, idx);\n  return (o == luaO_nilobject) ? LUA_TNONE : ttype(o);\n}\n\n\nLUA_API const char *lua_typename (lua_State *L, int t) {\n  UNUSED(L);\n  return (t == LUA_TNONE) ? \"no value\" : luaT_typenames[t];\n}\n\n\nLUA_API int lua_iscfunction (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  return iscfunction(o);\n}\n\n\nLUA_API int lua_isnumber (lua_State *L, int idx) {\n  TValue n;\n  const TValue *o = index2adr(L, idx);\n  return tonumber(o, &n);\n}\n\n\nLUA_API int lua_isstring (lua_State *L, int idx) {\n  int t = lua_type(L, idx);\n  return (t == LUA_TSTRING || t == LUA_TNUMBER);\n}\n\n\nLUA_API int lua_isuserdata (lua_State *L, int idx) {\n  const TValue *o = index2adr(L, idx);\n  return (ttisuserdata(o) || ttislightuserdata(o));\n}\n\n\nLUA_API int lua_rawequal (lua_State *L, int index1, int index2) {\n  StkId o1 = index2adr(L, index1);\n  StkId o2 = index2adr(L, index2);\n  return (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0\n         : luaO_rawequalObj(o1, o2);\n}\n\n\nLUA_API int lua_equal (lua_State *L, int index1, int index2) {\n  StkId o1, o2;\n  int i;\n  lua_lock(L);  /* may call tag method */\n  o1 = index2adr(L, index1);\n  o2 = index2adr(L, index2);\n  i = (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0 : equalobj(L, o1, o2);\n  lua_unlock(L);\n  return i;\n}\n\n\nLUA_API int lua_lessthan (lua_State *L, int index1, int index2) {\n  StkId o1, o2;\n  int i;\n  lua_lock(L);  /* may call tag method */\n  o1 = index2adr(L, index1);\n  o2 = index2adr(L, index2);\n  i = (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0\n       : luaV_lessthan(L, o1, o2);\n  lua_unlock(L);\n  return i;\n}\n\n\n\nLUA_API lua_Number lua_tonumber (lua_State *L, int idx) {\n  TValue n;\n  const TValue *o = index2adr(L, idx);\n  if (tonumber(o, &n))\n    return nvalue(o);\n  else\n    return 0;\n}\n\n\nLUA_API lua_Integer lua_tointeger (lua_State *L, int idx) {\n  TValue n;\n  const TValue *o = index2adr(L, idx);\n  if (tonumber(o, &n)) {\n    lua_Integer res;\n    lua_Number num = nvalue(o);\n    lua_number2integer(res, num);\n    return res;\n  }\n  else\n    return 0;\n}\n\n\nLUA_API int lua_toboolean (lua_State *L, int idx) {\n  const TValue *o = index2adr(L, idx);\n  return !l_isfalse(o);\n}\n\n\nLUA_API const char *lua_tolstring (lua_State *L, int idx, size_t *len) {\n  StkId o = index2adr(L, idx);\n  if (!ttisstring(o)) {\n    lua_lock(L);  /* `luaV_tostring' may create a new string */\n    if (!luaV_tostring(L, o)) {  /* conversion failed? */\n      if (len != NULL) *len = 0;\n      lua_unlock(L);\n      return NULL;\n    }\n    luaC_checkGC(L);\n    o = index2adr(L, idx);  /* previous call may reallocate the stack */\n    lua_unlock(L);\n  }\n  if (len != NULL) *len = tsvalue(o)->len;\n  return svalue(o);\n}\n\n\nLUA_API size_t lua_objlen (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  switch (ttype(o)) {\n    case LUA_TSTRING: return tsvalue(o)->len;\n    case LUA_TUSERDATA: return uvalue(o)->len;\n    case LUA_TTABLE: return luaH_getn(hvalue(o));\n    case LUA_TNUMBER: {\n      size_t l;\n      lua_lock(L);  /* `luaV_tostring' may create a new string */\n      l = (luaV_tostring(L, o) ? tsvalue(o)->len : 0);\n      lua_unlock(L);\n      return l;\n    }\n    default: return 0;\n  }\n}\n\n\nLUA_API lua_CFunction lua_tocfunction (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  return (!iscfunction(o)) ? NULL : clvalue(o)->c.f;\n}\n\n\nLUA_API void *lua_touserdata (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  switch (ttype(o)) {\n    case LUA_TUSERDATA: return (rawuvalue(o) + 1);\n    case LUA_TLIGHTUSERDATA: return pvalue(o);\n    default: return NULL;\n  }\n}\n\n\nLUA_API lua_State *lua_tothread (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  return (!ttisthread(o)) ? NULL : thvalue(o);\n}\n\n\nLUA_API const void *lua_topointer (lua_State *L, int idx) {\n  StkId o = index2adr(L, idx);\n  switch (ttype(o)) {\n    case LUA_TTABLE: return hvalue(o);\n    case LUA_TFUNCTION: return clvalue(o);\n    case LUA_TTHREAD: return thvalue(o);\n    case LUA_TUSERDATA:\n    case LUA_TLIGHTUSERDATA:\n      return lua_touserdata(L, idx);\n    default: return NULL;\n  }\n}\n\n\n\n/*\n** push functions (C -> stack)\n*/\n\n\nLUA_API void lua_pushnil (lua_State *L) {\n  lua_lock(L);\n  setnilvalue(L->top);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushnumber (lua_State *L, lua_Number n) {\n  lua_lock(L);\n  setnvalue(L->top, n);\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushinteger (lua_State *L, lua_Integer n) {\n  lua_lock(L);\n  setnvalue(L->top, cast_num(n));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushlstring (lua_State *L, const char *s, size_t len) {\n  lua_lock(L);\n  luaC_checkGC(L);\n  setsvalue2s(L, L->top, luaS_newlstr(L, s, len));\n  api_incr_top(L);\n  lua_unlock(L);\n}\n\n\nLUA_API void lua_pushstring (lua_State *L, const char *s) {\n  if (s == NULL)\n    lua_pushnil(L);\n  else\n    lua_pushlstring(L, s, strlen(s));\n}\n\n\nLUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,\n                                      va_list argp) {\n  const char *ret;\n  lua_lock(L);\n  luaC_checkGC(L);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {\n  const char *ret;\n  va_list argp;\n  lua_lock(L);\n  luaC_checkGC(L);\n  va_start(argp, fmt);\n  ret = luaO_pushvfstring(L, fmt, argp);\n  va_end(argp);\n  lua_unlock(L);\n  return ret;\n}\n\n\nLUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {\n  Closure *cl;\n  lua_lock(L);\n"}, {"id": "A9399BBB2383B9B4", "name": "luaCallFunction", "path": "redis/src/script_lua.c", "start": {"line": 1615, "col": 1}, "end": {"line": 1718, "col": 1}, "code": "    client* c = run_ctx->original_client;\n    int delhook = 0;\n\n    /* We must set it before we set the Lua hook, theoretically the\n     * Lua hook might be called wheneven we run any Lua instruction\n     * such as 'luaSetGlobalArray' and we want the run_ctx to be available\n     * each time the Lua hook is invoked. */\n    luaSaveOnRegistry(lua, REGISTRY_RUN_CTX_NAME, run_ctx);\n\n    if (server.busy_reply_threshold > 0 && !debug_enabled) {\n        lua_sethook(lua,luaMaskCountHook,LUA_MASKCOUNT,100000);\n        delhook = 1;\n    } else if (debug_enabled) {\n        lua_sethook(lua,luaLdbLineHook,LUA_MASKLINE|LUA_MASKCOUNT,100000);\n        delhook = 1;\n    }\n\n    /* Populate the argv and keys table accordingly to the arguments that\n     * EVAL received. */\n    luaCreateArray(lua,keys,nkeys);\n    /* On eval, keys and arguments are globals. */\n    if (run_ctx->flags & SCRIPT_EVAL_MODE){\n        /* open global protection to set KEYS */\n        lua_enablereadonlytable(lua, LUA_GLOBALSINDEX, 0);\n        lua_setglobal(lua,\"KEYS\");\n        lua_enablereadonlytable(lua, LUA_GLOBALSINDEX, 1);\n    }\n    luaCreateArray(lua,args,nargs);\n    if (run_ctx->flags & SCRIPT_EVAL_MODE){\n        /* open global protection to set ARGV */\n        lua_enablereadonlytable(lua, LUA_GLOBALSINDEX, 0);\n        lua_setglobal(lua,\"ARGV\");\n        lua_enablereadonlytable(lua, LUA_GLOBALSINDEX, 1);\n    }\n\n    /* At this point whether this script was never seen before or if it was\n     * already defined, we can call it.\n     * On eval mode, we have zero arguments and expect a single return value.\n     * In addition the error handler is located on position -2 on the Lua stack.\n     * On function mode, we pass 2 arguments (the keys and args tables),\n     * and the error handler is located on position -4 (stack: error_handler, callback, keys, args) */\n    int err;\n    if (run_ctx->flags & SCRIPT_EVAL_MODE) {\n        err = lua_pcall(lua,0,1,-2);\n    } else {\n        err = lua_pcall(lua,2,1,-4);\n    }\n\n    /* Call the Lua garbage collector from time to time to avoid a\n     * full cycle performed by Lua, which adds too latency.\n     *\n     * The call is performed every LUA_GC_CYCLE_PERIOD executed commands\n     * (and for LUA_GC_CYCLE_PERIOD collection steps) because calling it\n     * for every command uses too much CPU. */\n    #define LUA_GC_CYCLE_PERIOD 50\n    {\n        static long gc_count = 0;\n\n        gc_count++;\n        if (gc_count == LUA_GC_CYCLE_PERIOD) {\n            lua_gc(lua,LUA_GCSTEP,LUA_GC_CYCLE_PERIOD);\n            gc_count = 0;\n        }\n    }\n\n    if (err) {\n        /* Error object is a table of the following format:\n         * {err='<error msg>', source='<source file>', line=<line>}\n         * We can construct the error message from this information */\n        if (!lua_istable(lua, -1)) {\n            const char *msg = \"execution failure\";\n            if (lua_isstring(lua, -1)) {\n                msg = lua_tostring(lua, -1);\n            }\n            addReplyErrorFormat(c,\"Error running script %s, %.100s\\n\", run_ctx->funcname, msg);\n        } else {\n            errorInfo err_info = {0};\n            sds final_msg = sdsempty();\n            luaExtractErrorInformation(lua, &err_info);\n            final_msg = sdscatfmt(final_msg, \"-%s\",\n                                  err_info.msg);\n            if (err_info.line && err_info.source) {\n                final_msg = sdscatfmt(final_msg, \" script: %s, on %s:%s.\",\n                                      run_ctx->funcname,\n                                      err_info.source,\n                                      err_info.line);\n            }\n            addReplyErrorSdsEx(c, final_msg, err_info.ignore_err_stats_update? ERR_REPLY_FLAG_NO_STATS_UPDATE : 0);\n            luaErrorInformationDiscard(&err_info);\n        }\n        lua_pop(lua,1); /* Consume the Lua error */\n    } else {\n        /* On success convert the Lua return value into Redis protocol, and\n         * send it to * the client. */\n        luaReplyToRedisReply(c, run_ctx->c, lua); /* Convert and consume the reply. */\n    }\n\n    /* Perform some cleanup that we need to do both on error and success. */\n    if (delhook) lua_sethook(lua,NULL,0,0); /* Disable hook */\n\n    /* remove run_ctx from registry, its only applicable for the current script. */\n    luaSaveOnRegistry(lua, REGISTRY_RUN_CTX_NAME, NULL);\n}\n\nunsigned long luaMemory(lua_State *lua) {\n    return lua_gc(lua, LUA_GCCOUNT, 0) * 1024LL;\n}\n"}], "code": "static void luaEngineCall(scriptRunCtx *run_ctx,\n                          void *engine_ctx,\n                          void *compiled_function,\n                          robj **keys,\n                          size_t nkeys,\n                          robj **args,\n                          size_t nargs)\n{\n    luaEngineCtx *lua_engine_ctx = engine_ctx;\n    lua_State *lua = lua_engine_ctx->lua;\n    luaFunctionCtx *f_ctx = compiled_function;\n\n    /* Push error handler */\n    lua_pushstring(lua, REGISTRY_ERROR_HANDLER_NAME);\n    lua_gettable(lua, LUA_REGISTRYINDEX);\n\n    lua_rawgeti(lua, LUA_REGISTRYINDEX, f_ctx->lua_function_ref);\n\n    serverAssert(lua_isfunction(lua, -1));\n\n    luaCallFunction(run_ctx, lua, keys, nkeys, args, nargs, 0);\n    lua_pop(lua, 1); /* Pop error handler */\n}\n"}, "145F9153FF2001AA": {"calls": [{"id": "AB3FB84DC3A5CF1C", "name": "sigemptyset", "path": "/usr/include/signal.h", "start": {"line": 199, "col": 1}, "end": {"line": 199, "col": 50}}], "code": "void ThreadsManager_init(void) {\n    /* Register signal handler */\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    /* Not setting SA_RESTART flag means that If a signal handler is invoked while a\n    system call or library function call is blocked, use the default behavior\n    i.e., the call fails with the error EINTR */\n    act.sa_flags = 0;\n    act.sa_handler = invoke_callback;\n    sigaction(SIGUSR2, &act, NULL);\n}\n"}, "0CBA565430D94C57": {"calls": [{"id": "1720ADC0A63B3A6B", "name": "pow", "path": "/usr/include/x86_64-linux-gnu/bits/mathcalls.h", "start": {"line": 140, "col": 17}, "end": {"line": 140, "col": 17}}], "code": "static unsigned long evictionTimeLimitUs(void) {\n    serverAssert(server.maxmemory_eviction_tenacity >= 0);\n    serverAssert(server.maxmemory_eviction_tenacity <= 100);\n\n    if (server.maxmemory_eviction_tenacity <= 10) {\n        /* A linear progression from 0..500us */\n        return 50uL * server.maxmemory_eviction_tenacity;\n    }\n\n    if (server.maxmemory_eviction_tenacity < 100) {\n        /* A 15% geometric progression, resulting in a limit of ~2 min at tenacity==99  */\n        return (unsigned long)(500.0 * pow(1.15, server.maxmemory_eviction_tenacity - 10.0));\n    }\n\n    return ULONG_MAX;   /* No limit to eviction time */\n}\n"}, "340C2A92AAB661BC": {"calls": [{"id": "F3B6C114265377A8", "name": "strcasecmp", "path": "/usr/include/strings.h", "start": {"line": 116, "col": 12}, "end": {"line": 116, "col": 12}}], "code": "static int matchToken(char **nextword, cliCommandArg *arg) {\n    if (strcasecmp(arg->token, nextword[0]) != 0) {\n        return 0;\n    }\n    arg->matched_token = 1;\n    arg->matched = 1;\n    return 1;\n}\n"}, "D1F436E96A24FDB2": {"calls": [{"id": "C0F60B0605A7EE0E", "name": "tcsetattr", "path": "/usr/include/termios.h", "start": {"line": 70, "col": 1}, "end": {"line": 71, "col": 44}}], "code": "void cliRestoreTTY(void) {\n    if (orig_termios_saved)\n        tcsetattr(STDIN_FILENO, TCSANOW, &orig_termios);\n}\n"}, "F82D2410AAC6480A": {"calls": [{"id": "5E1F1D5F08FFEE4C", "name": "isatty", "path": "/usr/include/unistd.h", "start": {"line": 809, "col": 1}, "end": {"line": 809, "col": 30}}, {"id": "6A9E52F0A3724356", "name": "tcgetattr", "path": "/usr/include/termios.h", "start": {"line": 66, "col": 1}, "end": {"line": 66, "col": 62}}, {"id": "270246FE8D902939", "name": "atexit", "path": "/usr/include/stdlib.h", "start": {"line": 602, "col": 1}, "end": {"line": 602, "col": 51}}, {"id": "C0F60B0605A7EE0E", "name": "tcsetattr", "path": "/usr/include/termios.h", "start": {"line": 70, "col": 1}, "end": {"line": 71, "col": 44}}], "code": "static void cliPressAnyKeyTTY(void) {\n    if (!isatty(STDIN_FILENO)) return;\n    if (!orig_termios_saved) {\n        if (tcgetattr(STDIN_FILENO, &orig_termios) == -1) return;\n        atexit(cliRestoreTTY);\n        orig_termios_saved = 1;\n    }\n    struct termios mode = orig_termios;\n    mode.c_lflag &= ~(ECHO | ICANON); /* echoing off, canonical off */\n    tcsetattr(STDIN_FILENO, TCSANOW, &mode);\n}\n"}, "9B049E7250A7BADF": {"calls": [{"id": "8B255E4FEDD81999", "name": "pthread_mutex_lock", "path": "/usr/include/pthread.h", "start": {"line": 794, "col": 1}, "end": {"line": 795, "col": 16}}, {"id": "6164D5568AAE28CF", "name": "pthread_mutex_unlock", "path": "/usr/include/pthread.h", "start": {"line": 835, "col": 1}, "end": {"line": 836, "col": 16}}], "code": "unsigned long bioPendingJobsOfType(int type) {\n    unsigned int worker = bio_job_to_worker[type];\n\n    pthread_mutex_lock(&bio_mutex[worker]);\n    unsigned long val = bio_jobs_counter[type];\n    pthread_mutex_unlock(&bio_mutex[worker]);\n\n    return val;\n}\n"}, "BADD1866448F8D09": {"calls": [{"id": "B0DD9B92581922F2", "name": "posix_fadvise", "path": "/usr/include/fcntl.h", "start": {"line": 277, "col": 1}, "end": {"line": 277, "col": 12}}], "code": "int reclaimFilePageCache(int fd, size_t offset, size_t length) {\n    UNUSED(fd);\n    UNUSED(offset);\n    UNUSED(length);\n    return 0;\n}\n"}, "5A7030DACAB7E146": {"calls": [{"id": "BDAF2D05E789E812", "name": "snprintf", "path": "/usr/include/stdio.h", "start": {"line": 378, "col": 12}, "end": {"line": 378, "col": 12}}, {"id": "DD749D6E7C066000", "name": "strchr", "path": "/usr/include/string.h", "start": {"line": 246, "col": 14}, "end": {"line": 246, "col": 14}}], "code": "static inline int formatAddr(char *buf, size_t buf_len, char *ip, int port) {\n    return snprintf(buf, buf_len, strchr(ip,':') ?\n           \"[%s]:%d\" : \"%s:%d\", ip, port);\n}\n"}, "E2463C73985C1A58": {"calls": [{"id": "BDAF2D05E789E812", "name": "snprintf", "path": "/usr/include/stdio.h", "start": {"line": 378, "col": 12}, "end": {"line": 378, "col": 12}}], "code": "void genClientAddrString(client *client, char *addr,\n                         size_t addr_len, int remote) {\n    if (client->flags & CLIENT_UNIX_SOCKET) {\n        /* Unix socket client. */\n        snprintf(addr,addr_len,\"%s:0\",server.unixsocket);\n    } else {\n        /* TCP client. */\n        connFormatAddr(client->conn,addr,addr_len,remote);\n    }\n}\n"}, "1F81C060E269517F": {"calls": [{"id": "22EC6865BA1F5C13", "name": "open", "path": "/usr/include/fcntl.h", "start": {"line": 184, "col": 1}, "end": {"line": 185, "col": 6}}, {"id": "21628F5C60AA58CF", "name": "strerror", "path": "/usr/include/string.h", "start": {"line": 419, "col": 14}, "end": {"line": 419, "col": 14}}, {"id": "65289070D24367CF", "name": "__errno_location", "path": "/usr/include/errno.h", "start": {"line": 37, "col": 1}, "end": {"line": 37, "col": 45}}, {"id": "B4C1B92EA4A3D36A", "name": "flock", "path": "/usr/include/x86_64-linux-gnu/sys/file.h", "start": {"line": 50, "col": 1}, "end": {"line": 50, "col": 46}}, {"id": "E10BDECF9B450180", "name": "close", "path": "/usr/include/unistd.h", "start": {"line": 358, "col": 1}, "end": {"line": 358, "col": 27}}], "code": "int clusterLockConfig(char *filename) {\n/* flock() does not exist on Solaris\n * and a fcntl-based solution won't help, as we constantly re-open that file,\n * which will release _all_ locks anyway\n */\n    UNUSED(filename);\n\n    return C_OK;\n}\n"}, "2EFBDA204288D7E9": {"calls": [{"id": "E6C8D0C8C1A1519E", "name": "strtod", "path": "/usr/include/stdlib.h", "start": {"line": 118, "col": 15}, "end": {"line": 118, "col": 15}}], "code": "int string2d(const char *s, size_t slen, double *dp) {\n    errno = 0;\n    char *eptr;\n    *dp = strtod(s, &eptr);\n    if (slen == 0 ||\n        isspace(((const char*)s)[0]) ||\n        (size_t)(eptr-(char*)s) != slen ||\n        (errno == ERANGE &&\n            (*dp == HUGE_VAL || *dp == -HUGE_VAL || fpclassify(*dp) == FP_ZERO)) ||\n        isnan(*dp))\n        return 0;\n    return 1;\n}\n"}, "1B66C0C661BF77ED": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}], "code": "double zzlStrtod(unsigned char *vstr, unsigned int vlen) {\n    char buf[128];\n    if (vlen > sizeof(buf) - 1)\n        vlen = sizeof(buf) - 1;\n    memcpy(buf,vstr,vlen);\n    buf[vlen] = '\\0';\n    return strtod(buf,NULL);\n }\n"}, "DAFD43712C86427A": {"calls": [{"id": "3ED3A88DB6E3ACEA", "name": "random", "path": "/usr/include/stdlib.h", "start": {"line": 402, "col": 1}, "end": {"line": 402, "col": 31}}], "code": "int zslRandomLevel(void) {\n    static const int threshold = ZSKIPLIST_P*RAND_MAX;\n    int level = 1;\n    while (random() < threshold)\n        level += 1;\n    return (level<ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;\n}\n"}, "56885AFA07B9F858": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}], "code": "REDIS_NO_SANITIZE(\"bounds\")\nsize_t _addReplyToBuffer(client *c, const char *s, size_t len) {\n    size_t available = c->buf_usable_size - c->bufpos;\n\n    /* If there already are entries in the reply list, we cannot\n     * add anything more to the static buffer. */\n    if (listLength(c->reply) > 0) return 0;\n\n    size_t reply_len = len > available ? available : len;\n    memcpy(c->buf+c->bufpos,s,reply_len);\n    c->bufpos+=reply_len;\n    /* We update the buffer peak after appending the reply to the buffer */\n    if(c->buf_peak < (size_t)c->bufpos)\n        c->buf_peak = (size_t)c->bufpos;\n    return reply_len;\n}\n"}, "F363CFD77CB13669": {"calls": [], "code": "unsigned long kvstoreBuckets(kvstore *kvs) {\n    if (kvs->num_dicts != 1) {\n        return kvs->bucket_count;\n    } else {\n        return kvs->dicts[0]? dictBuckets(kvs->dicts[0]) : 0;\n    }\n}\n"}, "C9AD0CB2169AB708": {"calls": [], "code": "long getTimeZone(void) {\n    struct timezone tz;\n\n    gettimeofday(NULL, &tz);\n\n    return tz.tz_minuteswest * 60L;\n}\n"}, "2F6791789BCEDFFA": {"calls": [], "code": "void dictRehashingInfo(dict *d, unsigned long long *from_size, unsigned long long *to_size) {\n    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n"}, "252B6857A9882E34": {"calls": [], "code": "size_t dictMemUsage(const dict *d) {\n    return dictSize(d) * sizeof(dictEntry) +\n        dictBuckets(d) * sizeof(dictEntry*);\n}\n"}, "744001044C7F2F92": {"calls": [], "code": "static void* getAndSetMcontextEip(ucontext_t *uc, void *eip) {\n#define NOT_SUPPORTED() do {\\\n    UNUSED(uc);\\\n    UNUSED(eip);\\\n    return NULL;\\\n} while(0)\n#define GET_SET_RETURN(target_var, new_val) do {\\\n    void *old_val = (void*)target_var; \\\n    if (new_val) { \\\n        void **temp = (void**)&target_var; \\\n        *temp = new_val; \\\n    } \\\n    return old_val; \\\n} while(0)\n    NOT_SUPPORTED();\n#undef NOT_SUPPORTED\n}\n"}, "1888551133AB0C37": {"calls": [], "code": "char *getObjectTypeName(robj *o) {\n    if (o == NULL) {\n        return \"none\";\n    }\n\n    serverAssert(o->type >= 0 && o->type < OBJ_TYPE_MAX);\n\n    if (o->type == OBJ_MODULE) {\n        moduleValue *mv = o->ptr;\n        return mv->type->name;\n    } else {\n        return obj_type_name[o->type];\n    }\n}\n"}, "3EABC43DB66CDE6D": {"calls": [], "code": "void totalNumberOfBlockingKeys(unsigned long *blocking_keys, unsigned long *bloking_keys_on_nokey) {\n    unsigned long bkeys=0, bkeys_on_nokey=0;\n    for (int j = 0; j < server.dbnum; j++) {\n        bkeys += dictSize(server.db[j].blocking_keys);\n        bkeys_on_nokey += dictSize(server.db[j].blocking_keys_unblock_on_nokey);\n    }\n    if (blocking_keys)\n        *blocking_keys = bkeys;\n    if (bloking_keys_on_nokey)\n        *bloking_keys_on_nokey = bkeys_on_nokey;\n}\n"}, "53226269E2E8F8F7": {"calls": [], "code": "int cmdHasPushAsReply(struct redisCommand *cmd) {\n    if (!cmd) return 0;\n    return cmd->proc == subscribeCommand  || cmd->proc == unsubscribeCommand ||\n           cmd->proc == psubscribeCommand || cmd->proc == punsubscribeCommand ||\n           cmd->proc == ssubscribeCommand || cmd->proc == sunsubscribeCommand;\n}\n"}, "83A7FD4CE5361D05": {"calls": [], "code": "static connection *connCreateSocket(void) {\n    connection *conn = zcalloc(sizeof(connection));\n    conn->type = &CT_Socket;\n    conn->fd = -1;\n    conn->iovcnt = IOV_MAX;\n\n    return conn;\n}\n"}, "C09BE7C7570CD694": {"calls": [], "code": "void trackInstantaneousMetric(int metric, long long current_value, long long current_base, long long factor) {\n    if (server.inst_metric[metric].last_sample_base > 0) {\n        long long base = current_base - server.inst_metric[metric].last_sample_base;\n        long long value = current_value - server.inst_metric[metric].last_sample_value;\n        long long avg = base > 0 ? (value * factor / base) : 0;\n        server.inst_metric[metric].samples[server.inst_metric[metric].idx] = avg;\n        server.inst_metric[metric].idx++;\n        server.inst_metric[metric].idx %= STATS_METRIC_SAMPLES;\n    }\n    server.inst_metric[metric].last_sample_base = current_base;\n    server.inst_metric[metric].last_sample_value = current_value;\n}\n"}, "F586455FB012D15B": {"calls": [], "code": "monotonic_clock_type monotonicGetType(void) {\n    if (getMonotonicUs == getMonotonicUs_posix)\n        return MONOTONIC_CLOCK_POSIX;\n    return MONOTONIC_CLOCK_HW;\n}\n"}, "FA12006B2296E11D": {"calls": [], "code": "unsigned long functionsMemoryOverhead(void) {\n    size_t memory_overhead = dictMemUsage(engines);\n    memory_overhead += dictMemUsage(curr_functions_lib_ctx->functions);\n    memory_overhead += sizeof(functionsLibCtx);\n    memory_overhead += curr_functions_lib_ctx->cache_memory;\n    memory_overhead += engine_cache_memory;\n\n    return memory_overhead;\n}\n"}, "C113A3386E49EAAF": {"calls": [], "code": "void addReplyErrorFormatInternal(client *c, int flags, const char *fmt, va_list ap) {\n    va_list cpy;\n    va_copy(cpy,ap);\n    sds s = sdscatvprintf(sdsempty(),fmt,cpy);\n    va_end(cpy);\n    /* Trim any newlines at the end (ones will be added by addReplyErrorLength) */\n    s = sdstrim(s, \"\\r\\n\");\n    /* Make sure there are no newlines in the middle of the string, otherwise\n     * invalid protocol is emitted. */\n    s = sdsmapchars(s, \"\\r\\n\", \"  \",  2);\n    addReplyErrorLength(c,s,sdslen(s));\n    afterErrorReply(c,s,sdslen(s),flags);\n    sdsfree(s);\n}\n"}, "C15524E7A8A6A858": {"calls": [], "code": "static inline void *ztrycalloc_usable_internal(size_t size, size_t *usable) {\n    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */\n    if (size >= SIZE_MAX/2) return NULL;\n    void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);\n    if (ptr == NULL) return NULL;\n\n    size = zmalloc_size(ptr);\n    update_zmalloc_stat_alloc(size);\n    if (usable) *usable = size;\n    return ptr;\n}\n"}, "1D4A8BB4C20DCE3F": {"calls": [{"id": "59A6299B6CAE3F96", "name": "kvstoreSize", "path": "redis/src/kvstore.c", "start": {"line": 304, "col": 1}, "end": {"line": 310, "col": 1}, "code": "    if (kvs->num_dicts != 1) {\n        return kvs->key_count;\n    } else {\n        return kvs->dicts[0]? dictSize(kvs->dicts[0]) : 0;\n    }\n}\n\n/* This method provides the cumulative sum of all the dictionary buckets\n * across dictionaries in a database. */\nunsigned long kvstoreBuckets(kvstore *kvs) {\n    if (kvs->num_dicts != 1) {\n        return kvs->bucket_count;\n    } else {\n        return kvs->dicts[0]? dictBuckets(kvs->dicts[0]) : 0;\n    }\n}\n\nsize_t kvstoreMemUsage(kvstore *kvs) {\n    size_t mem = sizeof(*kvs);\n\n    unsigned long long keys_count = kvstoreSize(kvs);\n    mem += keys_count * dictEntryMemUsage() +\n           kvstoreBuckets(kvs) * sizeof(dictEntry*) +\n           kvs->allocated_dicts * (sizeof(dict) + kvstoreDictMetadataSize(NULL));\n\n    /* Values are dict* shared with kvs->dicts */\n    mem += listLength(kvs->rehashing) * sizeof(listNode);\n\n    if (kvs->dict_size_index)\n        mem += sizeof(unsigned long long) * (kvs->num_dicts + 1);\n\n    return mem;\n}\n\n/*\n * This method is used to iterate over the elements of the entire kvstore specifically across dicts.\n * It's a three pronged approach.\n *\n * 1. It uses the provided cursor `cursor` to retrieve the dict index from it.\n * 2. If the dictionary is in a valid state checked through the provided callback `dictScanValidFunction`,\n *    it performs a dictScan over the appropriate `keyType` dictionary of `db`.\n * 3. If the dict is entirely scanned i.e. the cursor has reached 0, the next non empty dict is discovered.\n *    The dict information is embedded into the cursor and returned.\n *\n * To restrict the scan to a single dict, pass a valid dict index as\n * 'onlydidx', otherwise pass -1.\n */\nunsigned long long kvstoreScan(kvstore *kvs, unsigned long long cursor,\n                               int onlydidx, dictScanFunction *scan_cb,\n                               kvstoreScanShouldSkipDict *skip_cb,\n                               void *privdata)\n{\n    unsigned long long _cursor = 0;\n    /* During dictionary traversal, 48 upper bits in the cursor are used for positioning in the HT.\n     * Following lower bits are used for the dict index number, ranging from 0 to 2^num_dicts_bits-1.\n     * Dict index is always 0 at the start of iteration and can be incremented only if there are\n     * multiple dicts. */\n    int didx = getAndClearDictIndexFromCursor(kvs, &cursor);\n    if (onlydidx >= 0) {\n        if (didx < onlydidx) {\n            /* Fast-forward to onlydidx. */\n            assert(onlydidx < kvs->num_dicts);\n            didx = onlydidx;\n            cursor = 0;\n        } else if (didx > onlydidx) {\n            /* The cursor is already past onlydidx. */\n            return 0;\n        }\n    }\n\n    dict *d = kvstoreGetDict(kvs, didx);\n\n    int skip = !d || (skip_cb && skip_cb(d));\n    if (!skip) {\n        _cursor = dictScan(d, cursor, scan_cb, privdata);\n    }\n    /* scanning done for the current dictionary or if the scanning wasn't possible, move to the next dict index. */\n    if (_cursor == 0 || skip) {\n        if (onlydidx >= 0)\n            return 0;\n        didx = kvstoreGetNextNonEmptyDictIndex(kvs, didx);\n    }\n    if (didx == -1) {\n        return 0;\n    }\n    addDictIndexToCursor(kvs, didx, &_cursor);\n    return _cursor;\n}\n\n/*\n * This functions increases size of kvstore to match desired number.\n * It resizes all individual dictionaries, unless skip_cb indicates otherwise.\n *\n * Based on the parameter `try_expand`, appropriate dict expand API is invoked.\n * if try_expand is set to 1, `dictTryExpand` is used else `dictExpand`.\n * The return code is either `DICT_OK`/`DICT_ERR` for both the API(s).\n * `DICT_OK` response is for successful expansion. However ,`DICT_ERR` response signifies failure in allocation in\n * `dictTryExpand` call and in case of `dictExpand` call it signifies no expansion was performed.\n */\nint kvstoreExpand(kvstore *kvs, uint64_t newsize, int try_expand, kvstoreExpandShouldSkipDictIndex *skip_cb) {\n    for (int i = 0; i < kvs->num_dicts; i++) {\n        dict *d = kvstoreGetDict(kvs, i);\n        if (!d || (skip_cb && skip_cb(i)))\n            continue;\n        int result = try_expand ? dictTryExpand(d, newsize) : dictExpand(d, newsize);\n        if (try_expand && result == DICT_ERR)\n            return 0;\n    }\n\n    return 1;\n}\n\n/* Returns fair random dict index, probability of each dict being returned is proportional to the number of elements that dictionary holds.\n * This function guarantees that it returns a dict-index of a non-empty dict, unless the entire kvstore is empty.\n * Time complexity of this function is O(log(kvs->num_dicts)). */\nint kvstoreGetFairRandomDictIndex(kvstore *kvs) {\n    unsigned long target = kvstoreSize(kvs) ? (randomULong() % kvstoreSize(kvs)) + 1 : 0;\n    return kvstoreFindDictIndexByKeyIndex(kvs, target);\n}\n\nvoid kvstoreGetStats(kvstore *kvs, char *buf, size_t bufsize, int full) {\n    buf[0] = '\\0';\n\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n    dictStats *mainHtStats = NULL;\n    dictStats *rehashHtStats = NULL;\n    dict *d;\n    kvstoreIterator *kvs_it = kvstoreIteratorInit(kvs);\n    while ((d = kvstoreIteratorNextDict(kvs_it))) {\n        dictStats *stats = dictGetStatsHt(d, 0, full);\n        if (!mainHtStats) {\n            mainHtStats = stats;\n        } else {\n            dictCombineStats(stats, mainHtStats);\n            dictFreeStats(stats);\n        }\n        if (dictIsRehashing(d)) {\n            stats = dictGetStatsHt(d, 1, full);\n            if (!rehashHtStats) {\n                rehashHtStats = stats;\n            } else {\n                dictCombineStats(stats, rehashHtStats);\n                dictFreeStats(stats);\n            }\n        }\n    }\n    kvstoreIteratorRelease(kvs_it);\n\n    if (mainHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n        dictFreeStats(mainHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n\n    if (rehashHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n    /* Make sure there is a NULL term at the end. */\n    if (orig_bufsize) orig_buf[orig_bufsize - 1] = '\\0';\n}\n\n/* Finds a dict containing target element in a key space ordered by dict index.\n * Consider this example. Dictionaries are represented by brackets and keys by dots:\n *  #0   #1   #2     #3    #4\n * [..][....][...][.......][.]\n *                    ^\n *                 target\n *\n * In this case dict #3 contains key that we are trying to find.\n *\n * The return value is 0 based dict-index, and the range of the target is [1..kvstoreSize], kvstoreSize inclusive.\n *\n * To find the dict, we start with the root node of the binary index tree and search through its children\n * from the highest index (2^num_dicts_bits in our case) to the lowest index. At each node, we check if the target\n * value is greater than the node's value. If it is, we remove the node's value from the target and recursively\n * search for the new target using the current node as the parent.\n * Time complexity of this function is O(log(kvs->num_dicts))\n */\nint kvstoreFindDictIndexByKeyIndex(kvstore *kvs, unsigned long target) {\n    if (kvs->num_dicts == 1 || kvstoreSize(kvs) == 0)\n        return 0;\n    assert(target <= kvstoreSize(kvs));\n\n    int result = 0, bit_mask = 1 << kvs->num_dicts_bits;\n    for (int i = bit_mask; i != 0; i >>= 1) {\n        int current = result + i;\n        /* When the target index is greater than 'current' node value the we will update\n         * the target and search in the 'current' node tree. */\n        if (target > kvs->dict_size_index[current]) {\n            target -= kvs->dict_size_index[current];\n            result = current;\n        }\n    }\n    /* Adjust the result to get the correct dict:\n     * 1. result += 1;\n     *    After the calculations, the index of target in dict_size_index should be the next one,\n     *    so we should add 1.\n     * 2. result -= 1;\n     *    Unlike BIT(dict_size_index is 1-based), dict indices are 0-based, so we need to subtract 1.\n     * As the addition and subtraction cancel each other out, we can simply return the result. */\n    return result;\n}\n\n/* Returns next non-empty dict index strictly after given one, or -1 if provided didx is the last one. */\nint kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n"}], "code": "static unsigned long long cumulativeKeyCountRead(kvstore *kvs, int didx) {\n    if (kvs->num_dicts == 1) {\n        assert(didx == 0);\n        return kvstoreSize(kvs);\n    }\n    int idx = didx + 1;\n    unsigned long long sum = 0;\n    while (idx > 0) {\n        sum += kvs->dict_size_index[idx];\n        idx -= (idx & -idx);\n    }\n    return sum;\n}\n"}, "53097E4BA66791C4": {"calls": [{"id": "59A6299B6CAE3F96", "name": "kvstoreSize", "path": "redis/src/kvstore.c", "start": {"line": 304, "col": 1}, "end": {"line": 310, "col": 1}, "code": "    if (kvs->num_dicts != 1) {\n        return kvs->key_count;\n    } else {\n        return kvs->dicts[0]? dictSize(kvs->dicts[0]) : 0;\n    }\n}\n\n/* This method provides the cumulative sum of all the dictionary buckets\n * across dictionaries in a database. */\nunsigned long kvstoreBuckets(kvstore *kvs) {\n    if (kvs->num_dicts != 1) {\n        return kvs->bucket_count;\n    } else {\n        return kvs->dicts[0]? dictBuckets(kvs->dicts[0]) : 0;\n    }\n}\n\nsize_t kvstoreMemUsage(kvstore *kvs) {\n    size_t mem = sizeof(*kvs);\n\n    unsigned long long keys_count = kvstoreSize(kvs);\n    mem += keys_count * dictEntryMemUsage() +\n           kvstoreBuckets(kvs) * sizeof(dictEntry*) +\n           kvs->allocated_dicts * (sizeof(dict) + kvstoreDictMetadataSize(NULL));\n\n    /* Values are dict* shared with kvs->dicts */\n    mem += listLength(kvs->rehashing) * sizeof(listNode);\n\n    if (kvs->dict_size_index)\n        mem += sizeof(unsigned long long) * (kvs->num_dicts + 1);\n\n    return mem;\n}\n\n/*\n * This method is used to iterate over the elements of the entire kvstore specifically across dicts.\n * It's a three pronged approach.\n *\n * 1. It uses the provided cursor `cursor` to retrieve the dict index from it.\n * 2. If the dictionary is in a valid state checked through the provided callback `dictScanValidFunction`,\n *    it performs a dictScan over the appropriate `keyType` dictionary of `db`.\n * 3. If the dict is entirely scanned i.e. the cursor has reached 0, the next non empty dict is discovered.\n *    The dict information is embedded into the cursor and returned.\n *\n * To restrict the scan to a single dict, pass a valid dict index as\n * 'onlydidx', otherwise pass -1.\n */\nunsigned long long kvstoreScan(kvstore *kvs, unsigned long long cursor,\n                               int onlydidx, dictScanFunction *scan_cb,\n                               kvstoreScanShouldSkipDict *skip_cb,\n                               void *privdata)\n{\n    unsigned long long _cursor = 0;\n    /* During dictionary traversal, 48 upper bits in the cursor are used for positioning in the HT.\n     * Following lower bits are used for the dict index number, ranging from 0 to 2^num_dicts_bits-1.\n     * Dict index is always 0 at the start of iteration and can be incremented only if there are\n     * multiple dicts. */\n    int didx = getAndClearDictIndexFromCursor(kvs, &cursor);\n    if (onlydidx >= 0) {\n        if (didx < onlydidx) {\n            /* Fast-forward to onlydidx. */\n            assert(onlydidx < kvs->num_dicts);\n            didx = onlydidx;\n            cursor = 0;\n        } else if (didx > onlydidx) {\n            /* The cursor is already past onlydidx. */\n            return 0;\n        }\n    }\n\n    dict *d = kvstoreGetDict(kvs, didx);\n\n    int skip = !d || (skip_cb && skip_cb(d));\n    if (!skip) {\n        _cursor = dictScan(d, cursor, scan_cb, privdata);\n    }\n    /* scanning done for the current dictionary or if the scanning wasn't possible, move to the next dict index. */\n    if (_cursor == 0 || skip) {\n        if (onlydidx >= 0)\n            return 0;\n        didx = kvstoreGetNextNonEmptyDictIndex(kvs, didx);\n    }\n    if (didx == -1) {\n        return 0;\n    }\n    addDictIndexToCursor(kvs, didx, &_cursor);\n    return _cursor;\n}\n\n/*\n * This functions increases size of kvstore to match desired number.\n * It resizes all individual dictionaries, unless skip_cb indicates otherwise.\n *\n * Based on the parameter `try_expand`, appropriate dict expand API is invoked.\n * if try_expand is set to 1, `dictTryExpand` is used else `dictExpand`.\n * The return code is either `DICT_OK`/`DICT_ERR` for both the API(s).\n * `DICT_OK` response is for successful expansion. However ,`DICT_ERR` response signifies failure in allocation in\n * `dictTryExpand` call and in case of `dictExpand` call it signifies no expansion was performed.\n */\nint kvstoreExpand(kvstore *kvs, uint64_t newsize, int try_expand, kvstoreExpandShouldSkipDictIndex *skip_cb) {\n    for (int i = 0; i < kvs->num_dicts; i++) {\n        dict *d = kvstoreGetDict(kvs, i);\n        if (!d || (skip_cb && skip_cb(i)))\n            continue;\n        int result = try_expand ? dictTryExpand(d, newsize) : dictExpand(d, newsize);\n        if (try_expand && result == DICT_ERR)\n            return 0;\n    }\n\n    return 1;\n}\n\n/* Returns fair random dict index, probability of each dict being returned is proportional to the number of elements that dictionary holds.\n * This function guarantees that it returns a dict-index of a non-empty dict, unless the entire kvstore is empty.\n * Time complexity of this function is O(log(kvs->num_dicts)). */\nint kvstoreGetFairRandomDictIndex(kvstore *kvs) {\n    unsigned long target = kvstoreSize(kvs) ? (randomULong() % kvstoreSize(kvs)) + 1 : 0;\n    return kvstoreFindDictIndexByKeyIndex(kvs, target);\n}\n\nvoid kvstoreGetStats(kvstore *kvs, char *buf, size_t bufsize, int full) {\n    buf[0] = '\\0';\n\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n    dictStats *mainHtStats = NULL;\n    dictStats *rehashHtStats = NULL;\n    dict *d;\n    kvstoreIterator *kvs_it = kvstoreIteratorInit(kvs);\n    while ((d = kvstoreIteratorNextDict(kvs_it))) {\n        dictStats *stats = dictGetStatsHt(d, 0, full);\n        if (!mainHtStats) {\n            mainHtStats = stats;\n        } else {\n            dictCombineStats(stats, mainHtStats);\n            dictFreeStats(stats);\n        }\n        if (dictIsRehashing(d)) {\n            stats = dictGetStatsHt(d, 1, full);\n            if (!rehashHtStats) {\n                rehashHtStats = stats;\n            } else {\n                dictCombineStats(stats, rehashHtStats);\n                dictFreeStats(stats);\n            }\n        }\n    }\n    kvstoreIteratorRelease(kvs_it);\n\n    if (mainHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n        dictFreeStats(mainHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n\n    if (rehashHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n    /* Make sure there is a NULL term at the end. */\n    if (orig_bufsize) orig_buf[orig_bufsize - 1] = '\\0';\n}\n\n/* Finds a dict containing target element in a key space ordered by dict index.\n * Consider this example. Dictionaries are represented by brackets and keys by dots:\n *  #0   #1   #2     #3    #4\n * [..][....][...][.......][.]\n *                    ^\n *                 target\n *\n * In this case dict #3 contains key that we are trying to find.\n *\n * The return value is 0 based dict-index, and the range of the target is [1..kvstoreSize], kvstoreSize inclusive.\n *\n * To find the dict, we start with the root node of the binary index tree and search through its children\n * from the highest index (2^num_dicts_bits in our case) to the lowest index. At each node, we check if the target\n * value is greater than the node's value. If it is, we remove the node's value from the target and recursively\n * search for the new target using the current node as the parent.\n * Time complexity of this function is O(log(kvs->num_dicts))\n */\nint kvstoreFindDictIndexByKeyIndex(kvstore *kvs, unsigned long target) {\n    if (kvs->num_dicts == 1 || kvstoreSize(kvs) == 0)\n        return 0;\n    assert(target <= kvstoreSize(kvs));\n\n    int result = 0, bit_mask = 1 << kvs->num_dicts_bits;\n    for (int i = bit_mask; i != 0; i >>= 1) {\n        int current = result + i;\n        /* When the target index is greater than 'current' node value the we will update\n         * the target and search in the 'current' node tree. */\n        if (target > kvs->dict_size_index[current]) {\n            target -= kvs->dict_size_index[current];\n            result = current;\n        }\n    }\n    /* Adjust the result to get the correct dict:\n     * 1. result += 1;\n     *    After the calculations, the index of target in dict_size_index should be the next one,\n     *    so we should add 1.\n     * 2. result -= 1;\n     *    Unlike BIT(dict_size_index is 1-based), dict indices are 0-based, so we need to subtract 1.\n     * As the addition and subtraction cancel each other out, we can simply return the result. */\n    return result;\n}\n\n/* Returns next non-empty dict index strictly after given one, or -1 if provided didx is the last one. */\nint kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n"}, {"id": "54375F226D8E122B", "name": "kvstoreFindDictIndexByKeyIndex", "path": "redis/src/kvstore.c", "start": {"line": 489, "col": 1}, "end": {"line": 512, "col": 1}, "code": "    if (kvs->num_dicts == 1 || kvstoreSize(kvs) == 0)\n        return 0;\n    assert(target <= kvstoreSize(kvs));\n\n    int result = 0, bit_mask = 1 << kvs->num_dicts_bits;\n    for (int i = bit_mask; i != 0; i >>= 1) {\n        int current = result + i;\n        /* When the target index is greater than 'current' node value the we will update\n         * the target and search in the 'current' node tree. */\n        if (target > kvs->dict_size_index[current]) {\n            target -= kvs->dict_size_index[current];\n            result = current;\n        }\n    }\n    /* Adjust the result to get the correct dict:\n     * 1. result += 1;\n     *    After the calculations, the index of target in dict_size_index should be the next one,\n     *    so we should add 1.\n     * 2. result -= 1;\n     *    Unlike BIT(dict_size_index is 1-based), dict indices are 0-based, so we need to subtract 1.\n     * As the addition and subtraction cancel each other out, we can simply return the result. */\n    return result;\n}\n\n/* Returns next non-empty dict index strictly after given one, or -1 if provided didx is the last one. */\nint kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n            break;  /* Reached the time limit. */\n        }\n        dictRehashMicroseconds(listNodeValue(node), threshold_us - elapsed_us);\n    }\n    assert(elapsed_us != UINT64_MAX);\n    return elapsed_us;\n}\n\nunsigned long kvstoreDictSize(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictSize(d);\n}\n\nkvstoreDictIterator *kvstoreGetDictIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\nkvstoreDictIterator *kvstoreGetDictSafeIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitSafeIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\n/* Free the kvs_di returned by kvstoreGetDictIterator and kvstoreGetDictSafeIterator. */\nvoid kvstoreReleaseDictIterator(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    if (kvstoreGetDict(kvs_di->kvs, kvs_di->didx)) dictResetIterator(&kvs_di->di);\n\n    zfree(kvs_di);\n}\n\n/* Get the next element of the dict through kvstoreDictIterator and dictNext. */\ndictEntry *kvstoreDictIteratorNext(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    dict *d = kvstoreGetDict(kvs_di->kvs, kvs_di->didx);\n    if (!d) return NULL;\n\n    return dictNext(&kvs_di->di);\n}\n\ndictEntry *kvstoreDictGetRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetRandomKey(d);\n}\n\ndictEntry *kvstoreDictGetFairRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetFairRandomKey(d);\n}\n\ndictEntry *kvstoreDictFindEntryByPtrAndHash(kvstore *kvs, int didx, const void *oldptr, uint64_t hash)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFindEntryByPtrAndHash(d, oldptr, hash);\n}\n\nunsigned int kvstoreDictGetSomeKeys(kvstore *kvs, int didx, dictEntry **des, unsigned int count)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictGetSomeKeys(d, des, count);\n}\n\nint kvstoreDictExpand(kvstore *kvs, int didx, unsigned long size)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    return dictExpand(d, size);\n}\n\nunsigned long kvstoreDictScanDefrag(kvstore *kvs, int didx, unsigned long v, dictScanFunction *fn, dictDefragFunctions *defragfns, void *privdata)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictScanDefrag(d, v, fn, defragfns, privdata);\n}\n\nuint64_t kvstoreGetHash(kvstore *kvs, const void *key)\n{\n    return kvs->dtype.hashFunction(key);\n}\n\nvoid *kvstoreDictFetchValue(kvstore *kvs, int didx, const void *key)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFetchValue(d, key);\n}\n\ndictEntry *kvstoreDictFind(kvstore *kvs, int didx, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFind(d, key);\n}\n\ndictEntry *kvstoreDictAddRaw(kvstore *kvs, int didx, void *key, dictEntry **existing) {\n    createDictIfNeeded(kvs, didx);\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictEntry *ret = dictAddRaw(d, key, existing);\n    if (ret)\n        cumulativeKeyCountAdd(kvs, didx, 1);\n    return ret;\n}\n\nvoid kvstoreDictSetKey(kvstore *kvs, int didx, dictEntry* de, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetKey(d, de, key);\n}\n\nvoid kvstoreDictSetVal(kvstore *kvs, int didx, dictEntry *de, void *val) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}], "code": "int kvstoreGetFairRandomDictIndex(kvstore *kvs) {\n    unsigned long target = kvstoreSize(kvs) ? (randomULong() % kvstoreSize(kvs)) + 1 : 0;\n    return kvstoreFindDictIndexByKeyIndex(kvs, target);\n}\n"}, "4301A1FCF0E2E43E": {"calls": [{"id": "1D4A8BB4C20DCE3F", "name": "cumulativeKeyCountRead", "path": "redis/src/kvstore.c", "start": {"line": 97, "col": 1}, "end": {"line": 109, "col": 1}, "code": "    if (kvs->num_dicts == 1) {\n        assert(didx == 0);\n        return kvstoreSize(kvs);\n    }\n    int idx = didx + 1;\n    unsigned long long sum = 0;\n    while (idx > 0) {\n        sum += kvs->dict_size_index[idx];\n        idx -= (idx & -idx);\n    }\n    return sum;\n}\n\nstatic void addDictIndexToCursor(kvstore *kvs, int didx, unsigned long long *cursor) {\n    if (kvs->num_dicts == 1)\n        return;\n    /* didx can be -1 when iteration is over and there are no more dicts to visit. */\n    if (didx < 0)\n        return;\n    *cursor = (*cursor << kvs->num_dicts_bits) | didx;\n}\n\nstatic int getAndClearDictIndexFromCursor(kvstore *kvs, unsigned long long *cursor) {\n    if (kvs->num_dicts == 1)\n        return 0;\n    int didx = (int) (*cursor & (kvs->num_dicts-1));\n    *cursor = *cursor >> kvs->num_dicts_bits;\n    return didx;\n}\n\n/* Updates binary index tree (also known as Fenwick tree), increasing key count for a given dict.\n * You can read more about this data structure here https://en.wikipedia.org/wiki/Fenwick_tree\n * Time complexity is O(log(kvs->num_dicts)). */\nstatic void cumulativeKeyCountAdd(kvstore *kvs, int didx, long delta) {\n    kvs->key_count += delta;\n\n    dict *d = kvstoreGetDict(kvs, didx);\n    size_t dsize = dictSize(d);\n    int non_empty_dicts_delta = dsize == 1? 1 : dsize == 0? -1 : 0;\n    kvs->non_empty_dicts += non_empty_dicts_delta;\n\n    /* BIT does not need to be calculated when there's only one dict. */\n    if (kvs->num_dicts == 1)\n        return;\n\n    /* Update the BIT */\n    int idx = didx + 1; /* Unlike dict indices, BIT is 1-based, so we need to add 1. */\n    while (idx <= kvs->num_dicts) {\n        if (delta < 0) {\n            assert(kvs->dict_size_index[idx] >= (unsigned long long)labs(delta));\n        }\n        kvs->dict_size_index[idx] += delta;\n        idx += (idx & -idx);\n    }\n}\n\nstatic void createDictIfNeeded(kvstore *kvs, int didx) {\n    if (kvstoreGetDict(kvs, didx))\n        return;\n    kvs->dicts[didx] = dictCreate(&kvs->dtype);\n    kvs->allocated_dicts++;\n}\n\nstatic void freeDictIfNeeded(kvstore *kvs, int didx) {\n    if (!(kvs->flags & KVSTORE_FREE_EMPTY_DICTS) ||\n        !kvstoreGetDict(kvs, didx) ||\n        kvstoreDictSize(kvs, didx) != 0)\n        return;\n    dictRelease(kvs->dicts[didx]);\n    kvs->dicts[didx] = NULL;\n    kvs->allocated_dicts--;\n}\n\n/**********************************/\n/*** dict callbacks ***************/\n/**********************************/\n\n/* Adds dictionary to the rehashing list, which allows us\n * to quickly find rehash targets during incremental rehashing.\n *\n * If there are multiple dicts, updates the bucket count for the given dictionary\n * in a DB, bucket count incremented with the new ht size during the rehashing phase.\n * If there's one dict, bucket count can be retrieved directly from single dict bucket. */\nstatic void kvstoreDictRehashingStarted(dict *d) {\n    kvstore *kvs = d->type->userdata;\n    kvstoreDictMetadata *metadata = (kvstoreDictMetadata *)dictMetadata(d);\n    listAddNodeTail(kvs->rehashing, d);\n    metadata->rehashing_node = listLast(kvs->rehashing);\n\n    if (kvs->num_dicts == 1)\n        return;\n    unsigned long long from, to;\n    dictRehashingInfo(d, &from, &to);\n    kvs->bucket_count += to; /* Started rehashing (Add the new ht size) */\n}\n\n/* Remove dictionary from the rehashing list.\n *\n * Updates the bucket count for the given dictionary in a DB. It removes\n * the old ht size of the dictionary from the total sum of buckets for a DB.  */\nstatic void kvstoreDictRehashingCompleted(dict *d) {\n    kvstore *kvs = d->type->userdata;\n    kvstoreDictMetadata *metadata = (kvstoreDictMetadata *)dictMetadata(d);\n    if (metadata->rehashing_node) {\n        listDelNode(kvs->rehashing, metadata->rehashing_node);\n        metadata->rehashing_node = NULL;\n    }\n\n    if (kvs->num_dicts == 1)\n        return;\n"}, {"id": "59A6299B6CAE3F96", "name": "kvstoreSize", "path": "redis/src/kvstore.c", "start": {"line": 304, "col": 1}, "end": {"line": 310, "col": 1}, "code": "    if (kvs->num_dicts != 1) {\n        return kvs->key_count;\n    } else {\n        return kvs->dicts[0]? dictSize(kvs->dicts[0]) : 0;\n    }\n}\n\n/* This method provides the cumulative sum of all the dictionary buckets\n * across dictionaries in a database. */\nunsigned long kvstoreBuckets(kvstore *kvs) {\n    if (kvs->num_dicts != 1) {\n        return kvs->bucket_count;\n    } else {\n        return kvs->dicts[0]? dictBuckets(kvs->dicts[0]) : 0;\n    }\n}\n\nsize_t kvstoreMemUsage(kvstore *kvs) {\n    size_t mem = sizeof(*kvs);\n\n    unsigned long long keys_count = kvstoreSize(kvs);\n    mem += keys_count * dictEntryMemUsage() +\n           kvstoreBuckets(kvs) * sizeof(dictEntry*) +\n           kvs->allocated_dicts * (sizeof(dict) + kvstoreDictMetadataSize(NULL));\n\n    /* Values are dict* shared with kvs->dicts */\n    mem += listLength(kvs->rehashing) * sizeof(listNode);\n\n    if (kvs->dict_size_index)\n        mem += sizeof(unsigned long long) * (kvs->num_dicts + 1);\n\n    return mem;\n}\n\n/*\n * This method is used to iterate over the elements of the entire kvstore specifically across dicts.\n * It's a three pronged approach.\n *\n * 1. It uses the provided cursor `cursor` to retrieve the dict index from it.\n * 2. If the dictionary is in a valid state checked through the provided callback `dictScanValidFunction`,\n *    it performs a dictScan over the appropriate `keyType` dictionary of `db`.\n * 3. If the dict is entirely scanned i.e. the cursor has reached 0, the next non empty dict is discovered.\n *    The dict information is embedded into the cursor and returned.\n *\n * To restrict the scan to a single dict, pass a valid dict index as\n * 'onlydidx', otherwise pass -1.\n */\nunsigned long long kvstoreScan(kvstore *kvs, unsigned long long cursor,\n                               int onlydidx, dictScanFunction *scan_cb,\n                               kvstoreScanShouldSkipDict *skip_cb,\n                               void *privdata)\n{\n    unsigned long long _cursor = 0;\n    /* During dictionary traversal, 48 upper bits in the cursor are used for positioning in the HT.\n     * Following lower bits are used for the dict index number, ranging from 0 to 2^num_dicts_bits-1.\n     * Dict index is always 0 at the start of iteration and can be incremented only if there are\n     * multiple dicts. */\n    int didx = getAndClearDictIndexFromCursor(kvs, &cursor);\n    if (onlydidx >= 0) {\n        if (didx < onlydidx) {\n            /* Fast-forward to onlydidx. */\n            assert(onlydidx < kvs->num_dicts);\n            didx = onlydidx;\n            cursor = 0;\n        } else if (didx > onlydidx) {\n            /* The cursor is already past onlydidx. */\n            return 0;\n        }\n    }\n\n    dict *d = kvstoreGetDict(kvs, didx);\n\n    int skip = !d || (skip_cb && skip_cb(d));\n    if (!skip) {\n        _cursor = dictScan(d, cursor, scan_cb, privdata);\n    }\n    /* scanning done for the current dictionary or if the scanning wasn't possible, move to the next dict index. */\n    if (_cursor == 0 || skip) {\n        if (onlydidx >= 0)\n            return 0;\n        didx = kvstoreGetNextNonEmptyDictIndex(kvs, didx);\n    }\n    if (didx == -1) {\n        return 0;\n    }\n    addDictIndexToCursor(kvs, didx, &_cursor);\n    return _cursor;\n}\n\n/*\n * This functions increases size of kvstore to match desired number.\n * It resizes all individual dictionaries, unless skip_cb indicates otherwise.\n *\n * Based on the parameter `try_expand`, appropriate dict expand API is invoked.\n * if try_expand is set to 1, `dictTryExpand` is used else `dictExpand`.\n * The return code is either `DICT_OK`/`DICT_ERR` for both the API(s).\n * `DICT_OK` response is for successful expansion. However ,`DICT_ERR` response signifies failure in allocation in\n * `dictTryExpand` call and in case of `dictExpand` call it signifies no expansion was performed.\n */\nint kvstoreExpand(kvstore *kvs, uint64_t newsize, int try_expand, kvstoreExpandShouldSkipDictIndex *skip_cb) {\n    for (int i = 0; i < kvs->num_dicts; i++) {\n        dict *d = kvstoreGetDict(kvs, i);\n        if (!d || (skip_cb && skip_cb(i)))\n            continue;\n        int result = try_expand ? dictTryExpand(d, newsize) : dictExpand(d, newsize);\n        if (try_expand && result == DICT_ERR)\n            return 0;\n    }\n\n    return 1;\n}\n\n/* Returns fair random dict index, probability of each dict being returned is proportional to the number of elements that dictionary holds.\n * This function guarantees that it returns a dict-index of a non-empty dict, unless the entire kvstore is empty.\n * Time complexity of this function is O(log(kvs->num_dicts)). */\nint kvstoreGetFairRandomDictIndex(kvstore *kvs) {\n    unsigned long target = kvstoreSize(kvs) ? (randomULong() % kvstoreSize(kvs)) + 1 : 0;\n    return kvstoreFindDictIndexByKeyIndex(kvs, target);\n}\n\nvoid kvstoreGetStats(kvstore *kvs, char *buf, size_t bufsize, int full) {\n    buf[0] = '\\0';\n\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n    dictStats *mainHtStats = NULL;\n    dictStats *rehashHtStats = NULL;\n    dict *d;\n    kvstoreIterator *kvs_it = kvstoreIteratorInit(kvs);\n    while ((d = kvstoreIteratorNextDict(kvs_it))) {\n        dictStats *stats = dictGetStatsHt(d, 0, full);\n        if (!mainHtStats) {\n            mainHtStats = stats;\n        } else {\n            dictCombineStats(stats, mainHtStats);\n            dictFreeStats(stats);\n        }\n        if (dictIsRehashing(d)) {\n            stats = dictGetStatsHt(d, 1, full);\n            if (!rehashHtStats) {\n                rehashHtStats = stats;\n            } else {\n                dictCombineStats(stats, rehashHtStats);\n                dictFreeStats(stats);\n            }\n        }\n    }\n    kvstoreIteratorRelease(kvs_it);\n\n    if (mainHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n        dictFreeStats(mainHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n\n    if (rehashHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n    /* Make sure there is a NULL term at the end. */\n    if (orig_bufsize) orig_buf[orig_bufsize - 1] = '\\0';\n}\n\n/* Finds a dict containing target element in a key space ordered by dict index.\n * Consider this example. Dictionaries are represented by brackets and keys by dots:\n *  #0   #1   #2     #3    #4\n * [..][....][...][.......][.]\n *                    ^\n *                 target\n *\n * In this case dict #3 contains key that we are trying to find.\n *\n * The return value is 0 based dict-index, and the range of the target is [1..kvstoreSize], kvstoreSize inclusive.\n *\n * To find the dict, we start with the root node of the binary index tree and search through its children\n * from the highest index (2^num_dicts_bits in our case) to the lowest index. At each node, we check if the target\n * value is greater than the node's value. If it is, we remove the node's value from the target and recursively\n * search for the new target using the current node as the parent.\n * Time complexity of this function is O(log(kvs->num_dicts))\n */\nint kvstoreFindDictIndexByKeyIndex(kvstore *kvs, unsigned long target) {\n    if (kvs->num_dicts == 1 || kvstoreSize(kvs) == 0)\n        return 0;\n    assert(target <= kvstoreSize(kvs));\n\n    int result = 0, bit_mask = 1 << kvs->num_dicts_bits;\n    for (int i = bit_mask; i != 0; i >>= 1) {\n        int current = result + i;\n        /* When the target index is greater than 'current' node value the we will update\n         * the target and search in the 'current' node tree. */\n        if (target > kvs->dict_size_index[current]) {\n            target -= kvs->dict_size_index[current];\n            result = current;\n        }\n    }\n    /* Adjust the result to get the correct dict:\n     * 1. result += 1;\n     *    After the calculations, the index of target in dict_size_index should be the next one,\n     *    so we should add 1.\n     * 2. result -= 1;\n     *    Unlike BIT(dict_size_index is 1-based), dict indices are 0-based, so we need to subtract 1.\n     * As the addition and subtraction cancel each other out, we can simply return the result. */\n    return result;\n}\n\n/* Returns next non-empty dict index strictly after given one, or -1 if provided didx is the last one. */\nint kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n"}, {"id": "54375F226D8E122B", "name": "kvstoreFindDictIndexByKeyIndex", "path": "redis/src/kvstore.c", "start": {"line": 489, "col": 1}, "end": {"line": 512, "col": 1}, "code": "    if (kvs->num_dicts == 1 || kvstoreSize(kvs) == 0)\n        return 0;\n    assert(target <= kvstoreSize(kvs));\n\n    int result = 0, bit_mask = 1 << kvs->num_dicts_bits;\n    for (int i = bit_mask; i != 0; i >>= 1) {\n        int current = result + i;\n        /* When the target index is greater than 'current' node value the we will update\n         * the target and search in the 'current' node tree. */\n        if (target > kvs->dict_size_index[current]) {\n            target -= kvs->dict_size_index[current];\n            result = current;\n        }\n    }\n    /* Adjust the result to get the correct dict:\n     * 1. result += 1;\n     *    After the calculations, the index of target in dict_size_index should be the next one,\n     *    so we should add 1.\n     * 2. result -= 1;\n     *    Unlike BIT(dict_size_index is 1-based), dict indices are 0-based, so we need to subtract 1.\n     * As the addition and subtraction cancel each other out, we can simply return the result. */\n    return result;\n}\n\n/* Returns next non-empty dict index strictly after given one, or -1 if provided didx is the last one. */\nint kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n            break;  /* Reached the time limit. */\n        }\n        dictRehashMicroseconds(listNodeValue(node), threshold_us - elapsed_us);\n    }\n    assert(elapsed_us != UINT64_MAX);\n    return elapsed_us;\n}\n\nunsigned long kvstoreDictSize(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictSize(d);\n}\n\nkvstoreDictIterator *kvstoreGetDictIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\nkvstoreDictIterator *kvstoreGetDictSafeIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitSafeIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\n/* Free the kvs_di returned by kvstoreGetDictIterator and kvstoreGetDictSafeIterator. */\nvoid kvstoreReleaseDictIterator(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    if (kvstoreGetDict(kvs_di->kvs, kvs_di->didx)) dictResetIterator(&kvs_di->di);\n\n    zfree(kvs_di);\n}\n\n/* Get the next element of the dict through kvstoreDictIterator and dictNext. */\ndictEntry *kvstoreDictIteratorNext(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    dict *d = kvstoreGetDict(kvs_di->kvs, kvs_di->didx);\n    if (!d) return NULL;\n\n    return dictNext(&kvs_di->di);\n}\n\ndictEntry *kvstoreDictGetRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetRandomKey(d);\n}\n\ndictEntry *kvstoreDictGetFairRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetFairRandomKey(d);\n}\n\ndictEntry *kvstoreDictFindEntryByPtrAndHash(kvstore *kvs, int didx, const void *oldptr, uint64_t hash)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFindEntryByPtrAndHash(d, oldptr, hash);\n}\n\nunsigned int kvstoreDictGetSomeKeys(kvstore *kvs, int didx, dictEntry **des, unsigned int count)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictGetSomeKeys(d, des, count);\n}\n\nint kvstoreDictExpand(kvstore *kvs, int didx, unsigned long size)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    return dictExpand(d, size);\n}\n\nunsigned long kvstoreDictScanDefrag(kvstore *kvs, int didx, unsigned long v, dictScanFunction *fn, dictDefragFunctions *defragfns, void *privdata)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictScanDefrag(d, v, fn, defragfns, privdata);\n}\n\nuint64_t kvstoreGetHash(kvstore *kvs, const void *key)\n{\n    return kvs->dtype.hashFunction(key);\n}\n\nvoid *kvstoreDictFetchValue(kvstore *kvs, int didx, const void *key)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFetchValue(d, key);\n}\n\ndictEntry *kvstoreDictFind(kvstore *kvs, int didx, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFind(d, key);\n}\n\ndictEntry *kvstoreDictAddRaw(kvstore *kvs, int didx, void *key, dictEntry **existing) {\n    createDictIfNeeded(kvs, didx);\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictEntry *ret = dictAddRaw(d, key, existing);\n    if (ret)\n        cumulativeKeyCountAdd(kvs, didx, 1);\n    return ret;\n}\n\nvoid kvstoreDictSetKey(kvstore *kvs, int didx, dictEntry* de, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetKey(d, de, key);\n}\n\nvoid kvstoreDictSetVal(kvstore *kvs, int didx, dictEntry *de, void *val) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}], "code": "int kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n"}, "BB017E58605FED92": {"calls": [{"id": "4301A1FCF0E2E43E", "name": "kvstoreGetNextNonEmptyDictIndex", "path": "redis/src/kvstore.c", "start": {"line": 515, "col": 1}, "end": {"line": 518, "col": 1}, "code": "    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n            break;  /* Reached the time limit. */\n        }\n        dictRehashMicroseconds(listNodeValue(node), threshold_us - elapsed_us);\n    }\n    assert(elapsed_us != UINT64_MAX);\n    return elapsed_us;\n}\n\nunsigned long kvstoreDictSize(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictSize(d);\n}\n\nkvstoreDictIterator *kvstoreGetDictIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\nkvstoreDictIterator *kvstoreGetDictSafeIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitSafeIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\n/* Free the kvs_di returned by kvstoreGetDictIterator and kvstoreGetDictSafeIterator. */\nvoid kvstoreReleaseDictIterator(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    if (kvstoreGetDict(kvs_di->kvs, kvs_di->didx)) dictResetIterator(&kvs_di->di);\n\n    zfree(kvs_di);\n}\n\n/* Get the next element of the dict through kvstoreDictIterator and dictNext. */\ndictEntry *kvstoreDictIteratorNext(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    dict *d = kvstoreGetDict(kvs_di->kvs, kvs_di->didx);\n    if (!d) return NULL;\n\n    return dictNext(&kvs_di->di);\n}\n\ndictEntry *kvstoreDictGetRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetRandomKey(d);\n}\n\ndictEntry *kvstoreDictGetFairRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetFairRandomKey(d);\n}\n\ndictEntry *kvstoreDictFindEntryByPtrAndHash(kvstore *kvs, int didx, const void *oldptr, uint64_t hash)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFindEntryByPtrAndHash(d, oldptr, hash);\n}\n\nunsigned int kvstoreDictGetSomeKeys(kvstore *kvs, int didx, dictEntry **des, unsigned int count)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictGetSomeKeys(d, des, count);\n}\n\nint kvstoreDictExpand(kvstore *kvs, int didx, unsigned long size)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    return dictExpand(d, size);\n}\n\nunsigned long kvstoreDictScanDefrag(kvstore *kvs, int didx, unsigned long v, dictScanFunction *fn, dictDefragFunctions *defragfns, void *privdata)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictScanDefrag(d, v, fn, defragfns, privdata);\n}\n\nuint64_t kvstoreGetHash(kvstore *kvs, const void *key)\n{\n    return kvs->dtype.hashFunction(key);\n}\n\nvoid *kvstoreDictFetchValue(kvstore *kvs, int didx, const void *key)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFetchValue(d, key);\n}\n\ndictEntry *kvstoreDictFind(kvstore *kvs, int didx, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFind(d, key);\n}\n\ndictEntry *kvstoreDictAddRaw(kvstore *kvs, int didx, void *key, dictEntry **existing) {\n    createDictIfNeeded(kvs, didx);\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictEntry *ret = dictAddRaw(d, key, existing);\n    if (ret)\n        cumulativeKeyCountAdd(kvs, didx, 1);\n    return ret;\n}\n\nvoid kvstoreDictSetKey(kvstore *kvs, int didx, dictEntry* de, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetKey(d, de, key);\n}\n\nvoid kvstoreDictSetVal(kvstore *kvs, int didx, dictEntry *de, void *val) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}], "code": "dict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n"}, "8AF415B62FB4C87E": {"calls": [{"id": "3308BB05757B8B49", "name": "_dictExpand", "path": "redis/src/dict.c", "start": {"line": 269, "col": 1}, "end": {"line": 275, "col": 1}, "code": "    /* the size is invalid if it is smaller than the size of the hash table \n     * or smaller than the number of elements already inside the hash table */\n    if (dictIsRehashing(d) || d->ht_used[0] > size || DICTHT_SIZE(d->ht_size_exp[0]) >= size)\n        return DICT_ERR;\n    return _dictResize(d, size, malloc_failed);\n}\n\n/* return DICT_ERR if expand was not performed */\nint dictExpand(dict *d, unsigned long size) {\n    return _dictExpand(d, size, NULL);\n}\n\n/* return DICT_ERR if expand failed due to memory allocation failure */\nint dictTryExpand(dict *d, unsigned long size) {\n    int malloc_failed = 0;\n    _dictExpand(d, size, &malloc_failed);\n    return malloc_failed? DICT_ERR : DICT_OK;\n}\n\n/* return DICT_ERR if shrink was not performed */\nint dictShrink(dict *d, unsigned long size) {\n    /* the size is invalid if it is bigger than the size of the hash table\n     * or smaller than the number of elements already inside the hash table */\n    if (dictIsRehashing(d) || d->ht_used[0] > size || DICTHT_SIZE(d->ht_size_exp[0]) <= size)\n        return DICT_ERR;\n    return _dictResize(d, size, NULL);\n}\n\n/* Helper function for `dictRehash` and `dictBucketRehash` which rehashes all the keys\n * in a bucket at index `idx` from the old to the new hash HT. */\nstatic void rehashEntriesInBucketAtIndex(dict *d, uint64_t idx) {\n    dictEntry *de = d->ht_table[0][idx];\n    uint64_t h;\n    dictEntry *nextde;\n    while (de) {\n        nextde = dictGetNext(de);\n        void *key = dictGetKey(de);\n        /* Get the index in the new hash table */\n        if (d->ht_size_exp[1] > d->ht_size_exp[0]) {\n            h = dictHashKey(d, key) & DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n        } else {\n            /* We're shrinking the table. The tables sizes are powers of\n             * two, so we simply mask the bucket index in the larger table\n             * to get the bucket index in the smaller table. */\n            h = idx & DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n        }\n        if (d->type->no_value) {\n            if (d->type->keys_are_odd && !d->ht_table[1][h]) {\n                /* Destination bucket is empty and we can store the key\n                 * directly without an allocated entry. Free the old entry\n                 * if it's an allocated entry.\n                 *\n                 * TODO: Add a flag 'keys_are_even' and if set, we can use\n                 * this optimization for these dicts too. We can set the LSB\n                 * bit when stored as a dict entry and clear it again when\n                 * we need the key back. */\n                assert(entryIsKey(key));\n                if (!entryIsKey(de)) zfree(decodeMaskedPtr(de));\n                de = key;\n            } else if (entryIsKey(de)) {\n                /* We don't have an allocated entry but we need one. */\n                de = createEntryNoValue(key, d->ht_table[1][h]);\n            } else {\n                /* Just move the existing entry to the destination table and\n                 * update the 'next' field. */\n                assert(entryIsNoValue(de));\n                dictSetNext(de, d->ht_table[1][h]);\n            }\n        } else {\n            dictSetNext(de, d->ht_table[1][h]);\n        }\n        d->ht_table[1][h] = de;\n        d->ht_used[0]--;\n        d->ht_used[1]++;\n        de = nextde;\n    }\n    d->ht_table[0][idx] = NULL;\n}\n\n/* This checks if we already rehashed the whole table and if more rehashing is required */\nstatic int dictCheckRehashingCompleted(dict *d) {\n    if (d->ht_used[0] != 0) return 0;\n    \n    if (d->type->rehashingCompleted) d->type->rehashingCompleted(d);\n    zfree(d->ht_table[0]);\n    /* Copy the new ht onto the old one */\n    d->ht_table[0] = d->ht_table[1];\n    d->ht_used[0] = d->ht_used[1];\n    d->ht_size_exp[0] = d->ht_size_exp[1];\n    _dictReset(d, 1);\n    d->rehashidx = -1;\n    return 1;\n}\n\n/* Performs N steps of incremental rehashing. Returns 1 if there are still\n * keys to move from the old to the new hash table, otherwise 0 is returned.\n *\n * Note that a rehashing step consists in moving a bucket (that may have more\n * than one key as we use chaining) from the old to the new hash table, however\n * since part of the hash table may be composed of empty spaces, it is not\n * guaranteed that this function will rehash even a single bucket, since it\n * will visit at max N*10 empty buckets in total, otherwise the amount of\n * work it does would be unbound and the function may block for a long time. */\nint dictRehash(dict *d, int n) {\n    int empty_visits = n*10; /* Max number of empty buckets to visit. */\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n\n    while(n-- && d->ht_used[0] != 0) {\n        /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(DICTHT_SIZE(d->ht_size_exp[0]) > (unsigned long)d->rehashidx);\n        while(d->ht_table[0][d->rehashidx] == NULL) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        /* Move all the keys in this bucket from the old to the new hash HT */\n        rehashEntriesInBucketAtIndex(d, d->rehashidx);\n        d->rehashidx++;\n    }\n\n    return !dictCheckRehashingCompleted(d);\n}\n\nlong long timeInMilliseconds(void) {\n    struct timeval tv;\n\n    gettimeofday(&tv,NULL);\n    return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);\n}\n\n/* Rehash in us+\"delta\" microseconds. The value of \"delta\" is larger\n * than 0, and is smaller than 1000 in most cases. The exact upper bound\n * depends on the running time of dictRehash(d,100).*/\nint dictRehashMicroseconds(dict *d, uint64_t us) {\n    if (d->pauserehash > 0) return 0;\n\n    monotime timer;\n    elapsedStart(&timer);\n    int rehashes = 0;\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (elapsedUs(timer) >= us) break;\n    }\n    return rehashes;\n}\n\n/* This function performs just a step of rehashing, and only if hashing has\n * not been paused for our hash table. When we have iterators in the\n * middle of a rehashing we can't mess with the two hash tables otherwise\n * some elements can be missed or duplicated.\n *\n * This function is called by common lookup or update operations in the\n * dictionary so that the hash table automatically migrates from H1 to H2\n * while it is actively used. */\nstatic void _dictRehashStep(dict *d) {\n    if (d->pauserehash == 0) dictRehash(d,1);\n}\n\n/* Performs rehashing on a single bucket. */\nint _dictBucketRehash(dict *d, uint64_t idx) {\n    if (d->pauserehash != 0) return 0;\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n    rehashEntriesInBucketAtIndex(d, idx);\n    dictCheckRehashingCompleted(d);\n    return 1;\n}\n\n/* Add an element to the target hash table */\nint dictAdd(dict *d, void *key, void *val)\n{\n    dictEntry *entry = dictAddRaw(d,key,NULL);\n\n    if (!entry) return DICT_ERR;\n    if (!d->type->no_value) dictSetVal(d, entry, val);\n    return DICT_OK;\n}\n\n/* Low level add or find:\n * This function adds the entry but instead of setting a value returns the\n * dictEntry structure to the user, that will make sure to fill the value\n * field as they wish.\n *\n * This function is also directly exposed to the user API to be called\n * mainly in order to store non-pointers inside the hash value, example:\n *\n * entry = dictAddRaw(dict,mykey,NULL);\n * if (entry != NULL) dictSetSignedIntegerVal(entry,1000);\n *\n * Return values:\n *\n * If key already exists NULL is returned, and \"*existing\" is populated\n * with the existing entry if existing is not NULL.\n *\n * If key was added, the hash entry is returned to be manipulated by the caller.\n */\ndictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)\n{\n    /* Get the position for the new key or NULL if the key already exists. */\n    void *position = dictFindPositionForInsert(d, key, existing);\n    if (!position) return NULL;\n\n    /* Dup the key if necessary. */\n    if (d->type->keyDup) key = d->type->keyDup(d, key);\n\n    return dictInsertAtPosition(d, key, position);\n}\n\n/* Adds a key in the dict's hashtable at the position returned by a preceding\n * call to dictFindPositionForInsert. This is a low level function which allows\n * splitting dictAddRaw in two parts. Normally, dictAddRaw or dictAdd should be\n * used instead. */\ndictEntry *dictInsertAtPosition(dict *d, void *key, void *position) {\n    dictEntry **bucket = position; /* It's a bucket, but the API hides that. */\n    dictEntry *entry;\n    /* If rehashing is ongoing, we insert in table 1, otherwise in table 0.\n     * Assert that the provided bucket is the right table. */\n    int htidx = dictIsRehashing(d) ? 1 : 0;\n    assert(bucket >= &d->ht_table[htidx][0] &&\n           bucket <= &d->ht_table[htidx][DICTHT_SIZE_MASK(d->ht_size_exp[htidx])]);\n    if (d->type->no_value) {\n        if (d->type->keys_are_odd && !*bucket) {\n            /* We can store the key directly in the destination bucket without the\n             * allocated entry.\n             *\n             * TODO: Add a flag 'keys_are_even' and if set, we can use this\n             * optimization for these dicts too. We can set the LSB bit when\n             * stored as a dict entry and clear it again when we need the key\n             * back. */\n            entry = key;\n            assert(entryIsKey(entry));\n        } else {\n            /* Allocate an entry without value. */\n            entry = createEntryNoValue(key, *bucket);\n        }\n    } else {\n        /* Allocate the memory and store the new entry.\n         * Insert the element in top, with the assumption that in a database\n         * system it is more likely that recently added entries are accessed\n         * more frequently. */\n        entry = zmalloc(sizeof(*entry));\n        assert(entryIsNormal(entry)); /* Check alignment of allocation */\n        entry->key = key;\n        entry->next = *bucket;\n    }\n    *bucket = entry;\n    d->ht_used[htidx]++;\n\n    return entry;\n}\n\n/* Add or Overwrite:\n * Add an element, discarding the old value if the key already exists.\n * Return 1 if the key was added from scratch, 0 if there was already an\n"}], "code": "int dictTryExpand(dict *d, unsigned long size) {\n    int malloc_failed = 0;\n    _dictExpand(d, size, &malloc_failed);\n    return malloc_failed? DICT_ERR : DICT_OK;\n}\n"}, "8146BBD51D425734": {"calls": [{"id": "C1C8A16D3FA62084", "name": "setsockopt", "path": "/usr/include/x86_64-linux-gnu/sys/socket.h", "start": {"line": 277, "col": 1}, "end": {"line": 278, "col": 52}}, {"id": "7F53C39C4E3A9036", "name": "anetSetError", "path": "redis/src/anet.c", "start": {"line": 55, "col": 1}, "end": {"line": 63, "col": 1}, "code": "{\n    va_list ap;\n\n    if (!err) return;\n    va_start(ap, fmt);\n    vsnprintf(err, ANET_ERR_LEN, fmt, ap);\n    va_end(ap);\n}\n\nint anetGetError(int fd) {\n    int sockerr = 0;\n    socklen_t errlen = sizeof(sockerr);\n\n    if (getsockopt(fd, SOL_SOCKET, SO_ERROR, &sockerr, &errlen) == -1)\n        sockerr = errno;\n    return sockerr;\n}\n\nint anetSetBlock(char *err, int fd, int non_block) {\n    int flags;\n\n    /* Set the socket blocking (if non_block is zero) or non-blocking.\n     * Note that fcntl(2) for F_GETFL and F_SETFL can't be\n     * interrupted by a signal. */\n    if ((flags = fcntl(fd, F_GETFL)) == -1) {\n        anetSetError(err, \"fcntl(F_GETFL): %s\", strerror(errno));\n        return ANET_ERR;\n    }\n\n    /* Check if this flag has been set or unset, if so,\n     * then there is no need to call fcntl to set/unset it again. */\n    if (!!(flags & O_NONBLOCK) == !!non_block)\n        return ANET_OK;\n\n    if (non_block)\n        flags |= O_NONBLOCK;\n    else\n        flags &= ~O_NONBLOCK;\n\n    if (fcntl(fd, F_SETFL, flags) == -1) {\n        anetSetError(err, \"fcntl(F_SETFL,O_NONBLOCK): %s\", strerror(errno));\n        return ANET_ERR;\n    }\n    return ANET_OK;\n}\n\nint anetNonBlock(char *err, int fd) {\n    return anetSetBlock(err,fd,1);\n}\n\nint anetBlock(char *err, int fd) {\n    return anetSetBlock(err,fd,0);\n}\n\n/* Enable the FD_CLOEXEC on the given fd to avoid fd leaks.\n * This function should be invoked for fd's on specific places\n * where fork + execve system calls are called. */\nint anetCloexec(int fd) {\n    int r;\n    int flags;\n\n    do {\n        r = fcntl(fd, F_GETFD);\n    } while (r == -1 && errno == EINTR);\n"}, {"id": "21628F5C60AA58CF", "name": "strerror", "path": "/usr/include/string.h", "start": {"line": 419, "col": 14}, "end": {"line": 419, "col": 14}}], "code": "int anetKeepAlive(char *err, int fd, int interval)\n{\n    int enabled = 1;\n    if (setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &enabled, sizeof(enabled)))\n    {\n        anetSetError(err, \"setsockopt SO_KEEPALIVE: %s\", strerror(errno));\n        return ANET_ERR;\n    }\n\n    return ANET_OK;\n}\n"}, "0662CB892CF59881": {"calls": [{"id": "6104732257AC688B", "name": "raxGetData", "path": "redis/src/rax.c", "start": {"line": 234, "col": 1}, "end": {"line": 240, "col": 1}, "code": "    if (n->isnull) return NULL;\n    void **ndata =(void**)((char*)n+raxNodeCurrentLength(n)-sizeof(void*));\n    void *data;\n    memcpy(&data,ndata,sizeof(data));\n    return data;\n}\n\n/* Add a new child to the node 'n' representing the character 'c' and return\n * its new pointer, as well as the child pointer by reference. Additionally\n * '***parentlink' is populated with the raxNode pointer-to-pointer of where\n * the new child was stored, which is useful for the caller to replace the\n * child pointer if it gets reallocated.\n *\n * On success the new parent node pointer is returned (it may change because\n * of the realloc, so the caller should discard 'n' and use the new value).\n * On out of memory NULL is returned, and the old node is still valid. */\nraxNode *raxAddChild(raxNode *n, unsigned char c, raxNode **childptr, raxNode ***parentlink) {\n    assert(n->iscompr == 0);\n\n    size_t curlen = raxNodeCurrentLength(n);\n    n->size++;\n    size_t newlen = raxNodeCurrentLength(n);\n    n->size--; /* For now restore the original size. We'll update it only on\n                  success at the end. */\n\n    /* Alloc the new child we will link to 'n'. */\n    raxNode *child = raxNewNode(0,0);\n    if (child == NULL) return NULL;\n\n    /* Make space in the original node. */\n    raxNode *newn = rax_realloc(n,newlen);\n    if (newn == NULL) {\n        rax_free(child);\n        return NULL;\n    }\n    n = newn;\n\n    /* After the reallocation, we have up to 8/16 (depending on the system\n     * pointer size, and the required node padding) bytes at the end, that is,\n     * the additional char in the 'data' section, plus one pointer to the new\n     * child, plus the padding needed in order to store addresses into aligned\n     * locations.\n     *\n     * So if we start with the following node, having \"abde\" edges.\n     *\n     * Note:\n     * - We assume 4 bytes pointer for simplicity.\n     * - Each space below corresponds to one byte\n     *\n     * [HDR*][abde][Aptr][Bptr][Dptr][Eptr]|AUXP|\n     *\n     * After the reallocation we need: 1 byte for the new edge character\n     * plus 4 bytes for a new child pointer (assuming 32 bit machine).\n     * However after adding 1 byte to the edge char, the header + the edge\n     * characters are no longer aligned, so we also need 3 bytes of padding.\n     * In total the reallocation will add 1+4+3 bytes = 8 bytes:\n     *\n     * (Blank bytes are represented by \".\")\n     *\n     * [HDR*][abde][Aptr][Bptr][Dptr][Eptr]|AUXP|[....][....]\n     *\n     * Let's find where to insert the new child in order to make sure\n     * it is inserted in-place lexicographically. Assuming we are adding\n     * a child \"c\" in our case pos will be = 2 after the end of the following\n     * loop. */\n    int pos;\n    for (pos = 0; pos < n->size; pos++) {\n        if (n->data[pos] > c) break;\n    }\n\n    /* Now, if present, move auxiliary data pointer at the end\n     * so that we can mess with the other data without overwriting it.\n     * We will obtain something like that:\n     *\n     * [HDR*][abde][Aptr][Bptr][Dptr][Eptr][....][....]|AUXP|\n     */\n    unsigned char *src, *dst;\n    if (n->iskey && !n->isnull) {\n        src = ((unsigned char*)n+curlen-sizeof(void*));\n        dst = ((unsigned char*)n+newlen-sizeof(void*));\n        memmove(dst,src,sizeof(void*));\n    }\n\n    /* Compute the \"shift\", that is, how many bytes we need to move the\n     * pointers section forward because of the addition of the new child\n     * byte in the string section. Note that if we had no padding, that\n     * would be always \"1\", since we are adding a single byte in the string\n     * section of the node (where now there is \"abde\" basically).\n     *\n     * However we have padding, so it could be zero, or up to 8.\n     *\n     * Another way to think at the shift is, how many bytes we need to\n     * move child pointers forward *other than* the obvious sizeof(void*)\n     * needed for the additional pointer itself. */\n    size_t shift = newlen - curlen - sizeof(void*);\n\n    /* We said we are adding a node with edge 'c'. The insertion\n     * point is between 'b' and 'd', so the 'pos' variable value is\n     * the index of the first child pointer that we need to move forward\n     * to make space for our new pointer.\n     *\n     * To start, move all the child pointers after the insertion point\n     * of shift+sizeof(pointer) bytes on the right, to obtain:\n     *\n     * [HDR*][abde][Aptr][Bptr][....][....][Dptr][Eptr]|AUXP|\n     */\n    src = n->data+n->size+\n          raxPadding(n->size)+\n          sizeof(raxNode*)*pos;\n    memmove(src+shift+sizeof(raxNode*),src,sizeof(raxNode*)*(n->size-pos));\n\n    /* Move the pointers to the left of the insertion position as well. Often\n     * we don't need to do anything if there was already some padding to use. In\n     * that case the final destination of the pointers will be the same, however\n     * in our example there was no pre-existing padding, so we added one byte\n     * plus three bytes of padding. After the next memmove() things will look\n     * like that:\n     *\n     * [HDR*][abde][....][Aptr][Bptr][....][Dptr][Eptr]|AUXP|\n     */\n    if (shift) {\n        src = (unsigned char*) raxNodeFirstChildPtr(n);\n        memmove(src+shift,src,sizeof(raxNode*)*pos);\n    }\n\n    /* Now make the space for the additional char in the data section,\n     * but also move the pointers before the insertion point to the right\n     * by shift bytes, in order to obtain the following:\n     *\n     * [HDR*][ab.d][e...][Aptr][Bptr][....][Dptr][Eptr]|AUXP|\n     */\n    src = n->data+pos;\n    memmove(src+1,src,n->size-pos);\n\n    /* We can now set the character and its child node pointer to get:\n     *\n     * [HDR*][abcd][e...][Aptr][Bptr][....][Dptr][Eptr]|AUXP|\n     * [HDR*][abcd][e...][Aptr][Bptr][Cptr][Dptr][Eptr]|AUXP|\n     */\n    n->data[pos] = c;\n    n->size++;\n    src = (unsigned char*) raxNodeFirstChildPtr(n);\n    raxNode **childfield = (raxNode**)(src+sizeof(raxNode*)*pos);\n    memcpy(childfield,&child,sizeof(child));\n    *childptr = child;\n    *parentlink = childfield;\n    return n;\n}\n\n/* Turn the node 'n', that must be a node without any children, into a\n * compressed node representing a set of nodes linked one after the other\n * and having exactly one child each. The node can be a key or not: this\n * property and the associated value if any will be preserved.\n *\n * The function also returns a child node, since the last node of the\n * compressed chain cannot be part of the chain: it has zero children while\n * we can only compress inner nodes with exactly one child each. */\nraxNode *raxCompressNode(raxNode *n, unsigned char *s, size_t len, raxNode **child) {\n    assert(n->size == 0 && n->iscompr == 0);\n    void *data = NULL; /* Initialized only to avoid warnings. */\n    size_t newsize;\n\n    debugf(\"Compress node: %.*s\\n\", (int)len,s);\n\n    /* Allocate the child to link to this node. */\n    *child = raxNewNode(0,0);\n    if (*child == NULL) return NULL;\n\n    /* Make space in the parent node. */\n    newsize = sizeof(raxNode)+len+raxPadding(len)+sizeof(raxNode*);\n    if (n->iskey) {\n        data = raxGetData(n); /* To restore it later. */\n        if (!n->isnull) newsize += sizeof(void*);\n    }\n    raxNode *newn = rax_realloc(n,newsize);\n    if (newn == NULL) {\n        rax_free(*child);\n        return NULL;\n    }\n    n = newn;\n\n    n->iscompr = 1;\n    n->size = len;\n    memcpy(n->data,s,len);\n    if (n->iskey) raxSetData(n,data);\n    raxNode **childfield = raxNodeLastChildPtr(n);\n    memcpy(childfield,child,sizeof(*child));\n    return n;\n}\n\n/* Low level function that walks the tree looking for the string\n * 's' of 'len' bytes. The function returns the number of characters\n * of the key that was possible to process: if the returned integer\n * is the same as 'len', then it means that the node corresponding to the\n * string was found (however it may not be a key in case the node->iskey is\n * zero or if simply we stopped in the middle of a compressed node, so that\n * 'splitpos' is non zero).\n *\n * Otherwise if the returned integer is not the same as 'len', there was an\n * early stop during the tree walk because of a character mismatch.\n *\n * The node where the search ended (because the full string was processed\n * or because there was an early stop) is returned by reference as\n * '*stopnode' if the passed pointer is not NULL. This node link in the\n * parent's node is returned as '*plink' if not NULL. Finally, if the\n * search stopped in a compressed node, '*splitpos' returns the index\n * inside the compressed node where the search ended. This is useful to\n * know where to split the node for insertion.\n *\n * Note that when we stop in the middle of a compressed node with\n * a perfect match, this function will return a length equal to the\n * 'len' argument (all the key matched), and will return a *splitpos which is\n * always positive (that will represent the index of the character immediately\n * *after* the last match in the current compressed node).\n *\n * When instead we stop at a compressed node and *splitpos is zero, it\n * means that the current node represents the key (that is, none of the\n * compressed node characters are needed to represent the key, just all\n * its parents nodes). */\nstatic inline size_t raxLowWalk(rax *rax, unsigned char *s, size_t len, raxNode **stopnode, raxNode ***plink, int *splitpos, raxStack *ts) {\n    raxNode *h = rax->head;\n    raxNode **parentlink = &rax->head;\n\n    size_t i = 0; /* Position in the string. */\n    size_t j = 0; /* Position in the node children (or bytes if compressed).*/\n    while(h->size && i < len) {\n        debugnode(\"Lookup current node\",h);\n        unsigned char *v = h->data;\n\n        if (h->iscompr) {\n            for (j = 0; j < h->size && i < len; j++, i++) {\n                if (v[j] != s[i]) break;\n            }\n            if (j != h->size) break;\n        } else {\n            /* Even when h->size is large, linear scan provides good\n             * performances compared to other approaches that are in theory\n             * more sounding, like performing a binary search. */\n            for (j = 0; j < h->size; j++) {\n                if (v[j] == s[i]) break;\n            }\n"}], "code": "int raxFind(rax *rax, unsigned char *s, size_t len, void **value) {\n    raxNode *h;\n\n    debugf(\"### Lookup: %.*s\\n\", (int)len, s);\n    int splitpos = 0;\n    size_t i = raxLowWalk(rax,s,len,&h,NULL,&splitpos,NULL);\n    if (i != len || (h->iscompr && splitpos != 0) || !h->iskey)\n        return 0;\n    if (value != NULL) *value = raxGetData(h);\n    return 1;\n}\n"}, "8BE29A91E9BFE43F": {"calls": [{"id": "0FBC1172457E9DA5", "name": "serverLogRawFromHandler", "path": "redis/src/server.c", "start": {"line": 172, "col": 1}, "end": {"line": 197, "col": 1}, "code": "    int fd;\n    int log_to_stdout = server.logfile[0] == '\\0';\n    char buf[64];\n\n    if ((level&0xff) < server.verbosity || (log_to_stdout && server.daemonize))\n        return;\n    fd = log_to_stdout ? STDOUT_FILENO :\n                         open(server.logfile, O_APPEND|O_CREAT|O_WRONLY, 0644);\n    if (fd == -1) return;\n    if (level & LL_RAW) {\n        if (write(fd,msg,strlen(msg)) == -1) goto err;\n    }\n    else {\n        ll2string(buf,sizeof(buf),getpid());\n        if (write(fd,buf,strlen(buf)) == -1) goto err;\n        if (write(fd,\":signal-handler (\",17) == -1) goto err;\n        ll2string(buf,sizeof(buf),time(NULL));\n        if (write(fd,buf,strlen(buf)) == -1) goto err;\n        if (write(fd,\") \",2) == -1) goto err;\n        if (write(fd,msg,strlen(msg)) == -1) goto err;\n        if (write(fd,\"\\n\",1) == -1) goto err;\n    }\nerr:\n    if (!log_to_stdout) close(fd);\n}\n\n/* An async-signal-safe version of serverLog. if LL_RAW is not included in level flags,\n * The message format is: <pid>:signal-handler (<time>) <msg> \\n\n * with LL_RAW flag only the msg is printed (with no new line at the end)\n *\n * We actually use this only for signals that are not fatal from the point\n * of view of Redis. Signals that are going to kill the server anyway and\n * where we need printf-alike features are served by serverLog(). */\nvoid serverLogFromHandler(int level, const char *fmt, ...) {\n    va_list ap;\n    char msg[LOG_MAX_LEN];\n\n    va_start(ap, fmt);\n    vsnprintf_async_signal_safe(msg, sizeof(msg), fmt, ap);\n    va_end(ap);\n\n    serverLogRawFromHandler(level, msg);\n}\n\n/* Return the UNIX time in microseconds */\nlong long ustime(void) {\n    struct timeval tv;\n    long long ust;\n\n    gettimeofday(&tv, NULL);\n    ust = ((long long)tv.tv_sec)*1000000;\n    ust += tv.tv_usec;\n    return ust;\n}\n\n/* Return the UNIX time in milliseconds */\nmstime_t mstime(void) {\n    return ustime()/1000;\n}\n\n/* Return the command time snapshot in milliseconds.\n * The time the command started is the logical time it runs,\n * and all the time readings during the execution time should\n * reflect the same time.\n * More details can be found in the comments below. */\nmstime_t commandTimeSnapshot(void) {\n    /* When we are in the middle of a command execution, we want to use a\n     * reference time that does not change: in that case we just use the\n     * cached time, that we update before each call in the call() function.\n     * This way we avoid that commands such as RPOPLPUSH or similar, that\n     * may re-open the same key multiple times, can invalidate an already\n     * open object in a next call, if the next call will see the key expired,\n     * while the first did not.\n     * This is specifically important in the context of scripts, where we\n     * pretend that time freezes. This way a key can expire only the first time\n     * it is accessed and not in the middle of the script execution, making\n     * propagation to slaves / AOF consistent. See issue #1525 for more info.\n     * Note that we cannot use the cached server.mstime because it can change\n     * in processEventsWhileBlocked etc. */\n    return server.cmd_time_snapshot;\n}\n\n/* After an RDB dump or AOF rewrite we exit from children using _exit() instead of\n * exit(), because the latter may interact with the same file objects used by\n * the parent process. However if we are testing the coverage normal exit() is\n * used in order to obtain the right coverage information. */\nvoid exitFromChild(int retcode) {\n    _exit(retcode);\n}\n\n/*====================== Hash table type implementation  ==================== */\n\n/* This is a hash table type that uses the SDS dynamic strings library as\n * keys and redis objects as values (objects can hold SDS strings,\n * lists, sets). */\n\nvoid dictVanillaFree(dict *d, void *val)\n{\n    UNUSED(d);\n    zfree(val);\n}\n\nvoid dictListDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    listRelease((list*)val);\n}\n\nvoid dictDictDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    dictRelease((dict*)val);\n}\n\nint dictSdsKeyCompare(dict *d, const void *key1,\n        const void *key2)\n{\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = sdslen((sds)key1);\n    l2 = sdslen((sds)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\n/* A case insensitive version used for the command lookup table and other\n * places where case insensitive non binary-safe comparison is needed. */\nint dictSdsKeyCaseCompare(dict *d, const void *key1,\n        const void *key2)\n{\n    UNUSED(d);\n    return strcasecmp(key1, key2) == 0;\n}\n\nvoid dictObjectDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    if (val == NULL) return; /* Lazy freeing will set value to NULL. */\n    decrRefCount(val);\n}\n\nvoid dictSdsDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    sdsfree(val);\n}\n\nvoid *dictSdsDup(dict *d, const void *key) {\n    UNUSED(d);\n    return sdsdup((const sds) key);\n}\n\nint dictObjKeyCompare(dict *d, const void *key1,\n        const void *key2)\n{\n    const robj *o1 = key1, *o2 = key2;\n    return dictSdsKeyCompare(d, o1->ptr,o2->ptr);\n}\n\nuint64_t dictObjHash(const void *key) {\n    const robj *o = key;\n    return dictGenHashFunction(o->ptr, sdslen((sds)o->ptr));\n}\n\nuint64_t dictSdsHash(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, sdslen((char*)key));\n}\n\nuint64_t dictSdsCaseHash(const void *key) {\n    return dictGenCaseHashFunction((unsigned char*)key, sdslen((char*)key));\n}\n\n/* Dict hash function for null terminated string */\nuint64_t dictCStrHash(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\n/* Dict hash function for null terminated string */\nuint64_t dictCStrCaseHash(const void *key) {\n    return dictGenCaseHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\n/* Dict hash function for client */\nuint64_t dictClientHash(const void *key) {\n    return ((client *)key)->id;\n}\n\n/* Dict compare function for client */\nint dictClientKeyCompare(dict *d, const void *key1, const void *key2) {\n    UNUSED(d);\n    return ((client *)key1)->id == ((client *)key2)->id;\n}\n\n"}, {"id": "7DF316E1D67A7BE1", "name": "exitFromChild", "path": "redis/src/server.c", "start": {"line": 259, "col": 1}, "end": {"line": 265, "col": 1}, "code": "    _exit(retcode);\n}\n\n/*====================== Hash table type implementation  ==================== */\n\n/* This is a hash table type that uses the SDS dynamic strings library as\n * keys and redis objects as values (objects can hold SDS strings,\n * lists, sets). */\n\nvoid dictVanillaFree(dict *d, void *val)\n{\n    UNUSED(d);\n    zfree(val);\n}\n\nvoid dictListDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    listRelease((list*)val);\n}\n\nvoid dictDictDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    dictRelease((dict*)val);\n}\n\nint dictSdsKeyCompare(dict *d, const void *key1,\n        const void *key2)\n{\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = sdslen((sds)key1);\n    l2 = sdslen((sds)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\n/* A case insensitive version used for the command lookup table and other\n * places where case insensitive non binary-safe comparison is needed. */\nint dictSdsKeyCaseCompare(dict *d, const void *key1,\n        const void *key2)\n{\n    UNUSED(d);\n    return strcasecmp(key1, key2) == 0;\n}\n\nvoid dictObjectDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    if (val == NULL) return; /* Lazy freeing will set value to NULL. */\n    decrRefCount(val);\n}\n\nvoid dictSdsDestructor(dict *d, void *val)\n{\n    UNUSED(d);\n    sdsfree(val);\n}\n\nvoid *dictSdsDup(dict *d, const void *key) {\n    UNUSED(d);\n    return sdsdup((const sds) key);\n}\n\nint dictObjKeyCompare(dict *d, const void *key1,\n        const void *key2)\n{\n    const robj *o1 = key1, *o2 = key2;\n    return dictSdsKeyCompare(d, o1->ptr,o2->ptr);\n}\n\nuint64_t dictObjHash(const void *key) {\n    const robj *o = key;\n    return dictGenHashFunction(o->ptr, sdslen((sds)o->ptr));\n}\n\nuint64_t dictSdsHash(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, sdslen((char*)key));\n}\n\nuint64_t dictSdsCaseHash(const void *key) {\n    return dictGenCaseHashFunction((unsigned char*)key, sdslen((char*)key));\n}\n\n/* Dict hash function for null terminated string */\nuint64_t dictCStrHash(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\n/* Dict hash function for null terminated string */\nuint64_t dictCStrCaseHash(const void *key) {\n    return dictGenCaseHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\n/* Dict hash function for client */\nuint64_t dictClientHash(const void *key) {\n    return ((client *)key)->id;\n}\n\n/* Dict compare function for client */\nint dictClientKeyCompare(dict *d, const void *key1, const void *key2) {\n    UNUSED(d);\n    return ((client *)key1)->id == ((client *)key2)->id;\n}\n\n/* Dict compare function for null terminated string */\nint dictCStrKeyCompare(dict *d, const void *key1, const void *key2) {\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = strlen((char*)key1);\n    l2 = strlen((char*)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\n/* Dict case insensitive compare function for null terminated string */\nint dictCStrKeyCaseCompare(dict *d, const void *key1, const void *key2) {\n    UNUSED(d);\n    return strcasecmp(key1, key2) == 0;\n}\n\nint dictEncObjKeyCompare(dict *d, const void *key1, const void *key2)\n{\n    robj *o1 = (robj*) key1, *o2 = (robj*) key2;\n    int cmp;\n\n    if (o1->encoding == OBJ_ENCODING_INT &&\n        o2->encoding == OBJ_ENCODING_INT)\n            return o1->ptr == o2->ptr;\n\n    /* Due to OBJ_STATIC_REFCOUNT, we avoid calling getDecodedObject() without\n     * good reasons, because it would incrRefCount() the object, which\n     * is invalid. So we check to make sure dictFind() works with static\n     * objects as well. */\n    if (o1->refcount != OBJ_STATIC_REFCOUNT) o1 = getDecodedObject(o1);\n    if (o2->refcount != OBJ_STATIC_REFCOUNT) o2 = getDecodedObject(o2);\n    cmp = dictSdsKeyCompare(d,o1->ptr,o2->ptr);\n    if (o1->refcount != OBJ_STATIC_REFCOUNT) decrRefCount(o1);\n    if (o2->refcount != OBJ_STATIC_REFCOUNT) decrRefCount(o2);\n    return cmp;\n}\n\nuint64_t dictEncObjHash(const void *key) {\n    robj *o = (robj*) key;\n\n    if (sdsEncodedObject(o)) {\n        return dictGenHashFunction(o->ptr, sdslen((sds)o->ptr));\n    } else if (o->encoding == OBJ_ENCODING_INT) {\n        char buf[32];\n        int len;\n\n        len = ll2string(buf,32,(long)o->ptr);\n        return dictGenHashFunction((unsigned char*)buf, len);\n    } else {\n        serverPanic(\"Unknown string encoding\");\n    }\n}\n\n/* Return 1 if currently we allow dict to expand. Dict may allocate huge\n * memory to contain hash buckets when dict expands, that may lead redis\n * rejects user's requests or evicts some keys, we can stop dict to expand\n * provisionally if used memory will be over maxmemory after dict expands,\n * but to guarantee the performance of redis, we still allow dict to expand\n * if dict load factor exceeds HASHTABLE_MAX_LOAD_FACTOR. */\nint dictResizeAllowed(size_t moreMem, double usedRatio) {\n    /* for debug purposes: dict is not allowed to be resized. */\n    if (!server.dict_resizing) return 0;\n\n    if (usedRatio <= HASHTABLE_MAX_LOAD_FACTOR) {\n        return !overMaxmemoryAfterAlloc(moreMem);\n    } else {\n        return 1;\n    }\n}\n\n/* Generic hash table type where keys are Redis Objects, Values\n * dummy pointers. */\ndictType objectKeyPointerValueDictType = {\n    dictEncObjHash,            /* hash function */\n    NULL,                      /* key dup */\n    NULL,                      /* val dup */\n    dictEncObjKeyCompare,      /* key compare */\n    dictObjectDestructor,      /* key destructor */\n    NULL,                      /* val destructor */\n    NULL                       /* allow to expand */\n};\n\n/* Like objectKeyPointerValueDictType(), but values can be destroyed, if\n * not NULL, calling zfree(). */\ndictType objectKeyHeapPointerValueDictType = {\n    dictEncObjHash,            /* hash function */\n    NULL,                      /* key dup */\n    NULL,                      /* val dup */\n    dictEncObjKeyCompare,      /* key compare */\n    dictObjectDestructor,      /* key destructor */\n    dictVanillaFree,           /* val destructor */\n    NULL                       /* allow to expand */\n};\n\n/* Set dictionary type. Keys are SDS strings, values are not used. */\ndictType setDictType = {\n    dictSdsHash,               /* hash function */\n    NULL,                      /* key dup */\n    NULL,                      /* val dup */\n    dictSdsKeyCompare,         /* key compare */\n    dictSdsDestructor,         /* key destructor */\n    NULL,                      /* val destructor */\n    NULL,                      /* allow to expand */\n    .no_value = 1,             /* no values in this dict */\n    .keys_are_odd = 1          /* an SDS string is always an odd pointer */\n};\n\n/* Sorted sets hash (note: a skiplist is used in addition to the hash table) */\ndictType zsetDictType = {\n    dictSdsHash,               /* hash function */\n    NULL,                      /* key dup */\n    NULL,                      /* val dup */\n    dictSdsKeyCompare,         /* key compare */\n    NULL,                      /* Note: SDS string shared & freed by skiplist */\n    NULL,                      /* val destructor */\n    NULL,                      /* allow to expand */\n};\n\n/* Db->dict, keys are sds strings, vals are Redis objects. */\ndictType dbDictType = {\n    dictSdsHash,                /* hash function */\n    NULL,                       /* key dup */\n    NULL,                       /* val dup */\n    dictSdsKeyCompare,          /* key compare */\n    dictSdsDestructor,          /* key destructor */\n    dictObjectDestructor,       /* val destructor */\n    dictResizeAllowed,          /* allow to resize */\n};\n\n/* Db->expires */\ndictType dbExpiresDictType = {\n    dictSdsHash,                /* hash function */\n    NULL,                       /* key dup */\n    NULL,                       /* val dup */\n    dictSdsKeyCompare,          /* key compare */\n    NULL,                       /* key destructor */\n    NULL,                       /* val destructor */\n    dictResizeAllowed,          /* allow to resize */\n};\n\n/* Command table. sds string -> command struct pointer. */\ndictType commandTableDictType = {\n    dictSdsCaseHash,            /* hash function */\n    NULL,                       /* key dup */\n    NULL,                       /* val dup */\n    dictSdsKeyCaseCompare,      /* key compare */\n    dictSdsDestructor,          /* key destructor */\n    NULL,                       /* val destructor */\n    NULL                        /* allow to expand */\n};\n\n/* Hash type hash table (note that small hashes are represented with listpacks) */\ndictType hashDictType = {\n    dictSdsHash,                /* hash function */\n"}], "code": "static void sigKillChildHandler(int sig) {\n    UNUSED(sig);\n    int level = server.in_fork_child == CHILD_TYPE_MODULE? LL_VERBOSE: LL_WARNING;\n    serverLogRawFromHandler(level, \"Received SIGUSR1 in child, exiting now.\");\n    exitFromChild(SERVER_CHILD_NOERROR_RETVAL);\n}\n"}, "4E9473BD7ADA756A": {"calls": [{"id": "881481995F73C0AF", "name": "ACLAddCommandCategory", "path": "redis/src/acl.c", "start": {"line": 108, "col": 1}, "end": {"line": 114, "col": 1}, "code": "    if (nextCommandCategory >= ACL_MAX_CATEGORIES) return 0;\n    ACLCommandCategories[nextCommandCategory].name = zstrdup(name);\n    ACLCommandCategories[nextCommandCategory].flag = flag != 0 ? flag : (1ULL<<nextCommandCategory);\n    nextCommandCategory++;\n    return 1;\n}\n\n/* Initializes ACLCommandCategories with default ACL categories and allocates space for \n * new ACL categories.\n */\nvoid ACLInitCommandCategories(void) {\n    ACLCommandCategories = zcalloc(sizeof(struct ACLCategoryItem) * (ACL_MAX_CATEGORIES + 1));\n    for (int j = 0; ACLDefaultCommandCategories[j].flag; j++) {\n        serverAssert(ACLAddCommandCategory(ACLDefaultCommandCategories[j].name, ACLDefaultCommandCategories[j].flag));\n    }\n}\n\n/* This function removes the specified number of categories from the trailing end of\n * the `ACLCommandCategories` array.\n * The purpose of this is to remove the categories added by modules that fail\n * during the onload function.\n */\nvoid ACLCleanupCategoriesOnFailure(size_t num_acl_categories_added) {\n    for (size_t j = nextCommandCategory - num_acl_categories_added; j < nextCommandCategory; j++) {\n        zfree(ACLCommandCategories[j].name);\n        ACLCommandCategories[j].name = NULL;\n        ACLCommandCategories[j].flag = 0;\n    }\n    nextCommandCategory -= num_acl_categories_added;\n}\n\nstruct ACLUserFlag {\n    const char *name;\n    uint64_t flag;\n} ACLUserFlags[] = {\n    /* Note: the order here dictates the emitted order at ACLDescribeUser */\n    {\"on\", USER_FLAG_ENABLED},\n    {\"off\", USER_FLAG_DISABLED},\n    {\"nopass\", USER_FLAG_NOPASS},\n    {\"skip-sanitize-payload\", USER_FLAG_SANITIZE_PAYLOAD_SKIP},\n    {\"sanitize-payload\", USER_FLAG_SANITIZE_PAYLOAD},\n    {NULL,0} /* Terminator. */\n};\n\nstruct ACLSelectorFlags {\n    const char *name;\n    uint64_t flag;\n} ACLSelectorFlags[] = {\n    /* Note: the order here dictates the emitted order at ACLDescribeUser */\n    {\"allkeys\", SELECTOR_FLAG_ALLKEYS},\n    {\"allchannels\", SELECTOR_FLAG_ALLCHANNELS},\n    {\"allcommands\", SELECTOR_FLAG_ALLCOMMANDS},\n    {NULL,0} /* Terminator. */\n};\n\n/* ACL selectors are private and not exposed outside of acl.c. */\ntypedef struct {\n    uint32_t flags; /* See SELECTOR_FLAG_* */\n    /* The bit in allowed_commands is set if this user has the right to\n     * execute this command.\n     *\n     * If the bit for a given command is NOT set and the command has\n     * allowed first-args, Redis will also check allowed_firstargs in order to\n     * understand if the command can be executed. */\n    uint64_t allowed_commands[USER_COMMAND_BITS_COUNT/64];\n    /* allowed_firstargs is used by ACL rules to block access to a command unless a\n     * specific argv[1] is given.\n     *\n     * For each command ID (corresponding to the command bit set in allowed_commands),\n     * This array points to an array of SDS strings, terminated by a NULL pointer,\n     * with all the first-args that are allowed for this command. When no first-arg\n     * matching is used, the field is just set to NULL to avoid allocating\n     * USER_COMMAND_BITS_COUNT pointers. */\n    sds **allowed_firstargs;\n    list *patterns;  /* A list of allowed key patterns. If this field is NULL\n                        the user cannot mention any key in a command, unless\n                        the flag ALLKEYS is set in the user. */\n    list *channels;  /* A list of allowed Pub/Sub channel patterns. If this\n                        field is NULL the user cannot mention any channel in a\n                        `PUBLISH` or [P][UNSUBSCRIBE] command, unless the flag\n                        ALLCHANNELS is set in the user. */\n    sds command_rules; /* A string representation of the ordered categories and commands, this\n                        * is used to regenerate the original ACL string for display. */\n} aclSelector;\n\nvoid ACLResetFirstArgsForCommand(aclSelector *selector, unsigned long id);\nvoid ACLResetFirstArgs(aclSelector *selector);\nvoid ACLAddAllowedFirstArg(aclSelector *selector, unsigned long id, const char *sub);\nvoid ACLFreeLogEntry(void *le);\nint ACLSetSelector(aclSelector *selector, const char *op, size_t oplen);\n\n/* The length of the string representation of a hashed password. */\n#define HASH_PASSWORD_LEN (SHA256_BLOCK_SIZE*2)\n\n/* =============================================================================\n * Helper functions for the rest of the ACL implementation\n * ==========================================================================*/\n\n/* Return zero if strings are the same, non-zero if they are not.\n * The comparison is performed in a way that prevents an attacker to obtain\n * information about the nature of the strings just monitoring the execution\n * time of the function. Note: The two strings must be the same length.\n */\nint time_independent_strcmp(char *a, char *b, int len) {\n    int diff = 0;\n    for (int j = 0; j < len; j++) {\n        diff |= (a[j] ^ b[j]);\n    }\n    return diff; /* If zero strings are the same. */\n}\n\n/* Given an SDS string, returns the SHA256 hex representation as a\n * new SDS string. */\nsds ACLHashPassword(unsigned char *cleartext, size_t len) {\n    SHA256_CTX ctx;\n"}], "code": "void ACLInitCommandCategories(void) {\n    ACLCommandCategories = zcalloc(sizeof(struct ACLCategoryItem) * (ACL_MAX_CATEGORIES + 1));\n    for (int j = 0; ACLDefaultCommandCategories[j].flag; j++) {\n        serverAssert(ACLAddCommandCategory(ACLDefaultCommandCategories[j].name, ACLDefaultCommandCategories[j].flag));\n    }\n}\n"}, "8A932B490A6BCD6E": {"calls": [{"id": "032F775CA568E399", "name": "getKeysPrepareResult", "path": "redis/src/db.c", "start": {"line": 1931, "col": 1}, "end": {"line": 1954, "col": 1}, "code": "    /* GETKEYS_RESULT_INIT initializes keys to NULL, point it to the pre-allocated stack\n     * buffer here. */\n    if (!result->keys) {\n        serverAssert(!result->numkeys);\n        result->keys = result->keysbuf;\n    }\n\n    /* Resize if necessary */\n    if (numkeys > result->size) {\n        if (result->keys != result->keysbuf) {\n            /* We're not using a static buffer, just (re)alloc */\n            result->keys = zrealloc(result->keys, numkeys * sizeof(keyReference));\n        } else {\n            /* We are using a static buffer, copy its contents */\n            result->keys = zmalloc(numkeys * sizeof(keyReference));\n            if (result->numkeys)\n                memcpy(result->keys, result->keysbuf, result->numkeys * sizeof(keyReference));\n        }\n        result->size = numkeys;\n    }\n\n    return result->keys;\n}\n\n/* Returns a bitmask with all the flags found in any of the key specs of the command.\n * The 'inv' argument means we'll return a mask with all flags that are missing in at least one spec. */\nint64_t getAllKeySpecsFlags(struct redisCommand *cmd, int inv) {\n    int64_t flags = 0;\n    for (int j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        flags |= inv? ~spec->flags : spec->flags;\n    }\n    return flags;\n}\n\n/* Fetch the keys based of the provided key specs. Returns the number of keys found, or -1 on error.\n * There are several flags that can be used to modify how this function finds keys in a command.\n * \n * GET_KEYSPEC_INCLUDE_NOT_KEYS: Return 'fake' keys as if they were keys.\n * GET_KEYSPEC_RETURN_PARTIAL:   Skips invalid and incomplete keyspecs but returns the keys\n *                               found in other valid keyspecs. \n */\nint getKeysUsingKeySpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    int j, i, last, first, step;\n    keyReference *keys;\n    serverAssert(result->numkeys == 0); /* caller should initialize or reset it */\n\n    for (j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        serverAssert(spec->begin_search_type != KSPEC_BS_INVALID);\n        /* Skip specs that represent 'fake' keys */\n        if ((spec->flags & CMD_KEY_NOT_KEY) && !(search_flags & GET_KEYSPEC_INCLUDE_NOT_KEYS)) {\n            continue;\n        }\n\n        first = 0;\n        if (spec->begin_search_type == KSPEC_BS_INDEX) {\n            first = spec->bs.index.pos;\n        } else if (spec->begin_search_type == KSPEC_BS_KEYWORD) {\n            int start_index = spec->bs.keyword.startfrom > 0 ? spec->bs.keyword.startfrom : argc+spec->bs.keyword.startfrom;\n            int end_index = spec->bs.keyword.startfrom > 0 ? argc-1: 1;\n            for (i = start_index; i != end_index; i = start_index <= end_index ? i + 1 : i - 1) {\n                if (i >= argc || i < 1)\n                    break;\n                if (!strcasecmp((char*)argv[i]->ptr,spec->bs.keyword.keyword)) {\n                    first = i+1;\n                    break;\n                }\n            }\n            /* keyword not found */\n            if (!first) {\n                continue;\n            }\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        if (spec->find_keys_type == KSPEC_FK_RANGE) {\n            step = spec->fk.range.keystep;\n            if (spec->fk.range.lastkey >= 0) {\n                last = first + spec->fk.range.lastkey;\n            } else {\n                if (!spec->fk.range.limit) {\n                    last = argc + spec->fk.range.lastkey;\n                } else {\n                    serverAssert(spec->fk.range.lastkey == -1);\n                    last = first + ((argc-first)/spec->fk.range.limit + spec->fk.range.lastkey);\n                }\n            }\n        } else if (spec->find_keys_type == KSPEC_FK_KEYNUM) {\n            step = spec->fk.keynum.keystep;\n            long long numkeys;\n            if (spec->fk.keynum.keynumidx >= argc)\n                goto invalid_spec;\n\n            sds keynum_str = argv[first + spec->fk.keynum.keynumidx]->ptr;\n            if (!string2ll(keynum_str,sdslen(keynum_str),&numkeys) || numkeys < 0) {\n                /* Unable to parse the numkeys argument or it was invalid */\n                goto invalid_spec;\n            }\n\n            first += spec->fk.keynum.firstkey;\n            last = first + (int)numkeys-1;\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        int count = ((last - first)+1);\n        keys = getKeysPrepareResult(result, result->numkeys + count);\n\n        /* First or last is out of bounds, which indicates a syntax error */\n        if (last >= argc || last < first || first >= argc) {\n            goto invalid_spec;\n        }\n\n        for (i = first; i <= last; i += step) {\n            if (i >= argc || i < first) {\n                /* Modules commands, and standard commands with a not fixed number\n                 * of arguments (negative arity parameter) do not have dispatch\n                 * time arity checks, so we need to handle the case where the user\n                 * passed an invalid number of arguments here. In this case we\n                 * return no keys and expect the command implementation to report\n                 * an arity or syntax error. */\n                if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                    continue;\n                } else {\n                    serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n                }\n            }\n            keys[result->numkeys].pos = i;\n            keys[result->numkeys].flags = spec->flags;\n            result->numkeys++;\n        }\n\n        /* Handle incomplete specs (only after we added the current spec\n         * to `keys`, just in case GET_KEYSPEC_RETURN_PARTIAL was given) */\n        if (spec->flags & CMD_KEY_INCOMPLETE) {\n            goto invalid_spec;\n        }\n\n        /* Done with this spec */\n        continue;\n\ninvalid_spec:\n        if (search_flags & GET_KEYSPEC_RETURN_PARTIAL) {\n            continue;\n        } else {\n            result->numkeys = 0;\n            return -1;\n        }\n    }\n\n    return result->numkeys;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv. \n * This function will eventually replace getKeysFromCommand.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the key.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getKeysFromCommandWithSpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    /* The command has at least one key-spec not marked as NOT_KEY */\n    int has_keyspec = (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);\n    /* The command has at least one key-spec marked as VARIABLE_FLAGS */\n    int has_varflags = (getAllKeySpecsFlags(cmd, 0) & CMD_KEY_VARIABLE_FLAGS);\n\n    /* We prefer key-specs if there are any, and their flags are reliable. */\n    if (has_keyspec && !has_varflags) {\n        int ret = getKeysUsingKeySpecs(cmd,argv,argc,search_flags,result);\n        if (ret >= 0)\n            return ret;\n        /* If the specs returned with an error (probably an INVALID or INCOMPLETE spec),\n         * fallback to the callback method. */\n    }\n\n    /* Resort to getkeys callback methods. */\n    if (cmd->flags & CMD_MODULE_GETKEYS)\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n\n    /* We use native getkeys as a last resort, since not all these native getkeys provide\n     * flags properly (only the ones that correspond to INVALID, INCOMPLETE or VARIABLE_FLAGS do.*/\n    if (cmd->getkeys_proc)\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    return 0;\n}\n\n/* This function returns a sanity check if the command may have keys. */\nint doesCommandHaveKeys(struct redisCommand *cmd) {\n    return cmd->getkeys_proc ||                                 /* has getkeys_proc (non modules) */\n        (cmd->flags & CMD_MODULE_GETKEYS) ||                    /* module with GETKEYS */\n        (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);        /* has at least one key-spec not marked as NOT_KEY */\n}\n\n/* A simplified channel spec table that contains all of the redis commands\n * and which channels they have and how they are accessed. */\ntypedef struct ChannelSpecs {\n    redisCommandProc *proc; /* Command procedure to match against */\n    uint64_t flags;         /* CMD_CHANNEL_* flags for this command */\n    int start;              /* The initial position of the first channel */\n    int count;              /* The number of channels, or -1 if all remaining\n                             * arguments are channels. */\n} ChannelSpecs;\n\nChannelSpecs commands_with_channels[] = {\n    {subscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {ssubscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {unsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {sunsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {psubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {punsubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {publishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {spublishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {NULL,0} /* Terminator. */\n};\n\n/* Returns 1 if the command may access any channels matched by the flags\n * argument. */\nint doesCommandHaveChannelsWithFlags(struct redisCommand *cmd, int flags) {\n    /* If a module declares get channels, we are just going to assume\n     * has channels. This API is allowed to return false positives. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return 1;\n    }\n    for (ChannelSpecs *spec = commands_with_channels; spec->proc != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            return !!(spec->flags & flags);\n        }\n    }\n    return 0;\n}\n\n/* Return all the arguments that are channels in the command passed via argc / argv. \n * This function behaves similar to getKeysFromCommandWithSpecs, but with channels \n * instead of keys.\n * \n * The command returns the positions of all the channel arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the channel.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getChannelsFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    /* If a module declares get channels, use that. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return moduleGetCommandChannelsViaAPI(cmd, argv, argc, result);\n    }\n    /* Otherwise check the channel spec table */\n    for (ChannelSpecs *spec = commands_with_channels; spec != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            int start = spec->start;\n            int stop = (spec->count == -1) ? argc : start + spec->count;\n            if (stop > argc) stop = argc;\n            int count = 0;\n            keys = getKeysPrepareResult(result, stop - start);\n            for (int i = start; i < stop; i++ ) {\n                keys[count].pos = i;\n                keys[count++].flags = spec->flags;\n            }\n            result->numkeys = count;\n            return count;\n        }\n    }\n    return 0;\n}\n\n/* The base case is to use the keys position as given in the command table\n * (firstkey, lastkey, step).\n * This function works only on command with the legacy_range_key_spec,\n * all other commands should be handled by getkeys_proc. \n * \n * If the commands keyspec is incomplete, no keys will be returned, and the provided\n * keys function should be called instead.\n * \n * NOTE: This function does not guarantee populating the flags for \n * the keys, in order to get flags you should use getKeysUsingKeySpecs. */\nint getKeysUsingLegacyRangeSpec(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int j, i = 0, last, first, step;\n    keyReference *keys;\n    UNUSED(argv);\n\n    if (cmd->legacy_range_key_spec.begin_search_type == KSPEC_BS_INVALID) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    first = cmd->legacy_range_key_spec.bs.index.pos;\n    last = cmd->legacy_range_key_spec.fk.range.lastkey;\n    if (last >= 0)\n        last += first;\n    step = cmd->legacy_range_key_spec.fk.range.keystep;\n\n    if (last < 0) last = argc+last;\n\n    int count = ((last - first)+1);\n    keys = getKeysPrepareResult(result, count);\n\n    for (j = first; j <= last; j += step) {\n        if (j >= argc || j < first) {\n            /* Modules commands, and standard commands with a not fixed number\n             * of arguments (negative arity parameter) do not have dispatch\n             * time arity checks, so we need to handle the case where the user\n             * passed an invalid number of arguments here. In this case we\n             * return no keys and expect the command implementation to report\n             * an arity or syntax error. */\n            if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                result->numkeys = 0;\n                return 0;\n            } else {\n                serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n            }\n        }\n        keys[i].pos = j;\n        /* Flags are omitted from legacy key specs */\n        keys[i++].flags = 0;\n    }\n    result->numkeys = i;\n    return i;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0].\n *\n * This function uses the command table if a command-specific helper function\n * is not required, otherwise it calls the command-specific function. */\nint getKeysFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    if (cmd->flags & CMD_MODULE_GETKEYS) {\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n    } else if (cmd->getkeys_proc) {\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    } else {\n        return getKeysUsingLegacyRangeSpec(cmd,argv,argc,result);\n    }\n}\n\n/* Free the result of getKeysFromCommand. */\nvoid getKeysFreeResult(getKeysResult *result) {\n    if (result && result->keys != result->keysbuf)\n        zfree(result->keys);\n}\n\n/* Helper function to extract keys from following commands:\n * COMMAND [destkey] <num-keys> <key> [...] <key> [...] ... <options>\n *\n * eg:\n * ZUNION <num-keys> <key> <key> ... <key> <options>\n * ZUNIONSTORE <destkey> <num-keys> <key> <key> ... <key> <options>\n *\n * 'storeKeyOfs': destkey index, 0 means destkey not exists.\n * 'keyCountOfs': num-keys index.\n * 'firstKeyOfs': firstkey index.\n * 'keyStep': the interval of each key, usually this value is 1.\n * \n * The commands using this function have a fully defined keyspec, so returning flags isn't needed. */\nint genericGetKeys(int storeKeyOfs, int keyCountOfs, int firstKeyOfs, int keyStep,\n                    robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n\n    num = atoi(argv[keyCountOfs]->ptr);\n    /* Sanity check. Don't return any key if the command is going to\n     * reply with syntax error. (no input keys). */\n    if (num < 1 || num > (argc - firstKeyOfs)/keyStep) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    int numkeys = storeKeyOfs ? num + 1 : num;\n    keys = getKeysPrepareResult(result, numkeys);\n    result->numkeys = numkeys;\n\n    /* Add all key positions for argv[firstKeyOfs...n] to keys[] */\n    for (i = 0; i < num; i++) {\n        keys[i].pos = firstKeyOfs+(i*keyStep);\n        keys[i].flags = 0;\n    } \n\n    if (storeKeyOfs) {\n        keys[num].pos = storeKeyOfs;\n        keys[num].flags = 0;\n    } \n    return result->numkeys;\n}\n\nint sintercardGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint zunionInterDiffStoreGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(1, 2, 3, 1, argv, argc, result);\n}\n\nint zunionInterDiffGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint evalGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint functionGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint lmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint blmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint zmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint bzmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\n/* Helper function to extract keys from the SORT RO command.\n *\n * SORT <sort-key>\n *\n * The second argument of SORT is always a key, however an arbitrary number of\n * keys may be accessed while doing the sort (the BY and GET args), so the\n * key-spec declares incomplete keys which is why we have to provide a concrete\n * implementation to fetch the keys.\n *\n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    result->numkeys = 1;\n    return result->numkeys;\n}\n\n/* Helper function to extract keys from the SORT command.\n *\n * SORT <sort-key> ... STORE <store-key> ...\n *\n * The first argument of SORT is always a key, however a list of options\n * follow in SQL-alike style. Here we parse just the minimum in order to\n * correctly identify keys in the \"STORE\" option. \n * \n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, found_store = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    num = 0;\n    keys = getKeysPrepareResult(result, 2); /* Alloc 2 places for the worst case. */\n    keys[num].pos = 1; /* <sort-key> is always present. */\n    keys[num++].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n\n    /* Search for STORE option. By default we consider options to don't\n     * have arguments, so if we find an unknown option name we scan the\n     * next. However there are options with 1 or 2 arguments, so we\n     * provide a list here in order to skip the right number of args. */\n    struct {\n        char *name;\n        int skip;\n    } skiplist[] = {\n        {\"limit\", 2},\n        {\"get\", 1},\n        {\"by\", 1},\n        {NULL, 0} /* End of elements. */\n    };\n\n    for (i = 2; i < argc; i++) {\n        for (j = 0; skiplist[j].name != NULL; j++) {\n            if (!strcasecmp(argv[i]->ptr,skiplist[j].name)) {\n                i += skiplist[j].skip;\n                break;\n            } else if (!strcasecmp(argv[i]->ptr,\"store\") && i+1 < argc) {\n                /* Note: we don't increment \"num\" here and continue the loop\n                 * to be sure to process the *last* \"STORE\" option if multiple\n                 * ones are provided. This is same behavior as SORT. */\n                found_store = 1;\n                keys[num].pos = i+1; /* <store-key> */\n                keys[num].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n                break;\n            }\n        }\n    }\n    result->numkeys = num + found_store;\n    return result->numkeys;\n}\n\n/* This command declares incomplete keys, so the flags are correctly set for this function */\nint migrateGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, first;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Assume the obvious form. */\n    first = 3;\n    num = 1;\n\n    /* But check for the extended one with the KEYS option. */\n    struct {\n        char* name;\n        int skip;\n    } skip_keywords[] = {       \n        {\"copy\", 0},\n        {\"replace\", 0},\n        {\"auth\", 1},\n        {\"auth2\", 2},\n        {NULL, 0}\n    };\n    if (argc > 6) {\n        for (i = 6; i < argc; i++) {\n            if (!strcasecmp(argv[i]->ptr, \"keys\")) {\n                if (sdslen(argv[3]->ptr) > 0) {\n                    /* This is a syntax error. So ignore the keys and leave\n                     * the syntax error to be handled by migrateCommand. */\n                    num = 0; \n                } else {\n                    first = i + 1;\n                    num = argc - first;\n                }\n                break;\n            }\n            for (j = 0; skip_keywords[j].name != NULL; j++) {\n                if (!strcasecmp(argv[i]->ptr, skip_keywords[j].name)) {\n                    i += skip_keywords[j].skip;\n                    break;\n                }\n            }\n        }\n    }\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = 0; i < num; i++) {\n        keys[i].pos = first+i;\n        keys[i].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_DELETE;\n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from following commands:\n * GEORADIUS key x y radius unit [WITHDIST] [WITHHASH] [WITHCOORD] [ASC|DESC]\n *                             [COUNT count] [STORE key|STOREDIST key]\n * GEORADIUSBYMEMBER key member radius unit ... options ...\n * \n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint georadiusGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Check for the presence of the stored key in the command */\n    int stored_key = -1;\n    for (i = 5; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        /* For the case when user specifies both \"store\" and \"storedist\" options, the\n         * second key specified would override the first key. This behavior is kept\n         * the same as in georadiusCommand method.\n         */\n        if ((!strcasecmp(arg, \"store\") || !strcasecmp(arg, \"storedist\")) && ((i+1) < argc)) {\n            stored_key = i+1;\n            i++;\n        }\n    }\n    num = 1 + (stored_key == -1 ? 0 : 1);\n\n    /* Keys in the command come from two places:\n     * argv[1] = key,\n     * argv[5...n] = stored key if present\n     */\n    keys = getKeysPrepareResult(result, num);\n\n    /* Add all key positions to keys[] */\n    keys[0].pos = 1;\n    keys[0].flags = 0;\n    if(num > 1) {\n         keys[1].pos = stored_key;\n         keys[1].flags = 0;\n    }\n    result->numkeys = num;\n    return num;\n}\n\n/* XREAD [BLOCK <milliseconds>] [COUNT <count>] [GROUP <groupname> <ttl>]\n *       STREAMS key_1 key_2 ... key_N ID_1 ID_2 ... ID_N\n *\n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint xreadGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* We need to parse the options of the command in order to seek the first\n     * \"STREAMS\" string which is actually the option. This is needed because\n     * \"STREAMS\" could also be the name of the consumer group and even the\n     * name of the stream key. */\n    int streams_pos = -1;\n    for (i = 1; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"block\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"count\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"group\")) {\n            i += 2; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"noack\")) {\n            /* Nothing to do. */\n        } else if (!strcasecmp(arg, \"streams\")) {\n            streams_pos = i;\n            break;\n        } else {\n            break; /* Syntax error. */\n        }\n    }\n    if (streams_pos != -1) num = argc - streams_pos - 1;\n\n    /* Syntax error. */\n    if (streams_pos == -1 || num == 0 || num % 2 != 0) {\n        result->numkeys = 0;\n        return 0;\n    }\n    num /= 2; /* We have half the keys as there are arguments because\n                 there are also the IDs, one per key. */\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = streams_pos+1; i < argc-num; i++) {\n        keys[i-streams_pos-1].pos = i;\n        keys[i-streams_pos-1].flags = 0; \n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from the SET command, which may have\n * a read flag if the GET argument is passed in. */\nint setGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 3; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if ((arg[0] == 'g' || arg[0] == 'G') &&\n            (arg[1] == 'e' || arg[1] == 'E') &&\n            (arg[2] == 't' || arg[2] == 'T') && arg[3] == '\\0')\n        {\n            keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n            return 1;\n        }\n    }\n\n    keys[0].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n    return 1;\n}\n\n/* Helper function to extract keys from the BITFIELD command, which may be\n * read-only if the BITFIELD GET subcommand is used. */\nint bitfieldGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    int readonly = 1;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 2; i < argc; i++) {\n        int remargs = argc - i - 1; /* Remaining args other than current. */\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"get\") && remargs >= 2) {\n            i += 2;\n        } else if ((!strcasecmp(arg, \"set\") || !strcasecmp(arg, \"incrby\")) && remargs >= 3) {\n            readonly = 0;\n            i += 3;\n            break;\n        } else if (!strcasecmp(arg, \"overflow\") && remargs >= 1) {\n            i += 1;\n        } else {\n            readonly = 0; /* Syntax error. safer to assume non-RO. */\n            break;\n        }\n    }\n\n    if (readonly) {\n        keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    } else {\n        keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n    }\n    return 1;\n}\n"}], "code": "int sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    result->numkeys = 1;\n    return result->numkeys;\n}\n"}, "BA9F49D506CE32B7": {"calls": [{"id": "C09417640F71FC72", "name": "defaultClientPort", "path": "redis/src/cluster_legacy.c", "start": {"line": 124, "col": 1}, "end": {"line": 126, "col": 1}, "code": "    return server.tls_cluster ? server.tls_port : server.port;\n}\n\n#define isSlotUnclaimed(slot) \\\n    (server.cluster->slots[slot] == NULL || \\\n        bitmapTestBit(server.cluster->owner_not_claiming_slot, slot))\n\n#define RCVBUF_INIT_LEN 1024\n#define RCVBUF_MAX_PREALLOC (1<<20) /* 1MB */\n\n/* Cluster nodes hash table, mapping nodes addresses 1.2.3.4:6379 to\n * clusterNode structures. */\ndictType clusterNodesDictType = {\n        dictSdsHash,                /* hash function */\n        NULL,                       /* key dup */\n        NULL,                       /* val dup */\n        dictSdsKeyCompare,          /* key compare */\n        dictSdsDestructor,          /* key destructor */\n        NULL,                       /* val destructor */\n        NULL                        /* allow to expand */\n};\n\n/* Cluster re-addition blacklist. This maps node IDs to the time\n * we can re-add this node. The goal is to avoid reading a removed\n * node for some time. */\ndictType clusterNodesBlackListDictType = {\n        dictSdsCaseHash,            /* hash function */\n        NULL,                       /* key dup */\n        NULL,                       /* val dup */\n        dictSdsKeyCaseCompare,      /* key compare */\n        dictSdsDestructor,          /* key destructor */\n        NULL,                       /* val destructor */\n        NULL                        /* allow to expand */\n};\n\n/* Cluster shards hash table, mapping shard id to list of nodes */\ndictType clusterSdsToListType = {\n        dictSdsHash,                /* hash function */\n        NULL,                       /* key dup */\n        NULL,                       /* val dup */\n        dictSdsKeyCompare,          /* key compare */\n        dictSdsDestructor,          /* key destructor */\n        dictListDestructor,         /* val destructor */\n        NULL                        /* allow to expand */\n};\n\n/* Aux fields are introduced in Redis 7.2 to support the persistence\n * of various important node properties, such as shard id, in nodes.conf.\n * Aux fields take an explicit format of name=value pairs and have no\n * intrinsic order among them. Aux fields are always grouped together\n * at the end of the second column of each row after the node's IP\n * address/port/cluster_port and the optional hostname. Aux fields\n * are separated by ','. */\n\n/* Aux field setter function prototype\n * return C_OK when the update is successful; C_ERR otherwise */\ntypedef int (aux_value_setter) (clusterNode* n, void *value, int length);\n/* Aux field getter function prototype\n * return an sds that is a concatenation of the input sds string and\n * the aux value */\ntypedef sds (aux_value_getter) (clusterNode* n, sds s);\n\ntypedef int (aux_value_present) (clusterNode* n);\n\ntypedef struct {\n    char *field;\n    aux_value_setter *setter;\n    aux_value_getter *getter;\n    aux_value_present *isPresent;\n} auxFieldHandler;\n\n/* Assign index to each aux field */\ntypedef enum {\n    af_shard_id,\n    af_human_nodename,\n    af_tcp_port,\n    af_tls_port,\n    af_count,\n} auxFieldIndex;\n\n/* Note that\n * 1. the order of the elements below must match that of their\n *    indices as defined in auxFieldIndex\n * 2. aux name can contain characters that pass the isValidAuxChar check only */\nauxFieldHandler auxFieldHandlers[] = {\n    {\"shard-id\", auxShardIdSetter, auxShardIdGetter, auxShardIdPresent},\n    {\"nodename\", auxHumanNodenameSetter, auxHumanNodenameGetter, auxHumanNodenamePresent},\n    {\"tcp-port\", auxTcpPortSetter, auxTcpPortGetter, auxTcpPortPresent},\n    {\"tls-port\", auxTlsPortSetter, auxTlsPortGetter, auxTlsPortPresent},\n};\n\nint auxShardIdSetter(clusterNode *n, void *value, int length) {\n    if (verifyClusterNodeId(value, length) == C_ERR) {\n        return C_ERR;\n    }\n    memcpy(n->shard_id, value, CLUSTER_NAMELEN);\n    /* if n already has replicas, make sure they all agree\n     * on the shard id */\n    for (int i = 0; i < n->numslaves; i++) {\n        if (memcmp(n->slaves[i]->shard_id, n->shard_id, CLUSTER_NAMELEN) != 0) {\n            return C_ERR;\n        }\n    }\n    clusterAddNodeToShard(value, n);\n    return C_OK;\n}\n\nsds auxShardIdGetter(clusterNode *n, sds s) {\n    return sdscatprintf(s, \"%.40s\", n->shard_id);\n}\n\nint auxShardIdPresent(clusterNode *n) {\n    return strlen(n->shard_id);\n}\n\nint auxHumanNodenameSetter(clusterNode *n, void *value, int length) {\n    if (n && !strncmp(value, n->human_nodename, length)) {\n        return C_OK;\n    } else if (!n && (length == 0)) {\n        return C_OK;\n    }\n    if (n) {\n        n->human_nodename = sdscpylen(n->human_nodename, value, length);\n    } else if (sdslen(n->human_nodename) != 0) {\n        sdsclear(n->human_nodename);\n    } else {\n        return C_ERR;\n"}], "code": "void deriveAnnouncedPorts(int *announced_tcp_port, int *announced_tls_port,\n                          int *announced_cport) {\n    /* Config overriding announced ports. */\n    *announced_tcp_port = server.cluster_announce_port ? \n                          server.cluster_announce_port : server.port;\n    *announced_tls_port = server.cluster_announce_tls_port ? \n                          server.cluster_announce_tls_port : server.tls_port;\n    /* Derive cluster bus port. */\n    if (server.cluster_announce_bus_port) {\n        *announced_cport = server.cluster_announce_bus_port;\n    } else if (server.cluster_port) {\n        *announced_cport = server.cluster_port;\n    } else {\n        *announced_cport = defaultClientPort() + CLUSTER_PORT_INCR;\n    }\n}\n"}, "D96D35EDDAADBECC": {"calls": [{"id": "3C9E784124A31F29", "name": "createStringObjectFromLongLongWithOptions", "path": "redis/src/object.c", "start": {"line": 149, "col": 1}, "end": {"line": 166, "col": 1}, "code": "    robj *o;\n\n    if (value >= 0 && value < OBJ_SHARED_INTEGERS && flag == LL2STROBJ_AUTO) {\n        o = shared.integers[value];\n    } else {\n        if ((value >= LONG_MIN && value <= LONG_MAX) && flag != LL2STROBJ_NO_INT_ENC) {\n            o = createObject(OBJ_STRING, NULL);\n            o->encoding = OBJ_ENCODING_INT;\n            o->ptr = (void*)((long)value);\n        } else {\n            char buf[LONG_STR_SIZE];\n            int len = ll2string(buf, sizeof(buf), value);\n            o = createStringObject(buf, len);\n        }\n    }\n    return o;\n}\n\n/* Wrapper for createStringObjectFromLongLongWithOptions() always demanding\n * to create a shared object if possible. */\nrobj *createStringObjectFromLongLong(long long value) {\n    return createStringObjectFromLongLongWithOptions(value, LL2STROBJ_AUTO);\n}\n\n/* The function avoids returning a shared integer when LFU/LRU info\n * are needed, that is, when the object is used as a value in the key\n * space(for instance when the INCR command is used), and Redis is\n * configured to evict based on LFU/LRU, so we want LFU/LRU values\n * specific for each key. */\nrobj *createStringObjectFromLongLongForValue(long long value) {\n    if (server.maxmemory == 0 || !(server.maxmemory_policy & MAXMEMORY_FLAG_NO_SHARED_INTEGERS)) {\n        /* If the maxmemory policy permits, we can still return shared integers */\n        return createStringObjectFromLongLongWithOptions(value, LL2STROBJ_AUTO);\n    } else {\n        return createStringObjectFromLongLongWithOptions(value, LL2STROBJ_NO_SHARED);\n    }\n}\n\n/* Create a string object that contains an sds inside it. That means it can't be\n * integer encoded (OBJ_ENCODING_INT), and it'll always be an EMBSTR type. */\nrobj *createStringObjectFromLongLongWithSds(long long value) {\n    return createStringObjectFromLongLongWithOptions(value, LL2STROBJ_NO_INT_ENC);\n}\n\n/* Create a string object from a long double. If humanfriendly is non-zero\n * it does not use exponential format and trims trailing zeroes at the end,\n * however this results in loss of precision. Otherwise exp format is used\n * and the output of snprintf() is not modified.\n *\n * The 'humanfriendly' option is used for INCRBYFLOAT and HINCRBYFLOAT. */\nrobj *createStringObjectFromLongDouble(long double value, int humanfriendly) {\n    char buf[MAX_LONG_DOUBLE_CHARS];\n    int len = ld2string(buf,sizeof(buf),value,humanfriendly? LD_STR_HUMAN: LD_STR_AUTO);\n    return createStringObject(buf,len);\n}\n\n/* Duplicate a string object, with the guarantee that the returned object\n * has the same encoding as the original one.\n *\n * This function also guarantees that duplicating a small integer object\n * (or a string object that contains a representation of a small integer)\n * will always result in a fresh object that is unshared (refcount == 1).\n *\n * The resulting object always has refcount set to 1. */\nrobj *dupStringObject(const robj *o) {\n    robj *d;\n\n    serverAssert(o->type == OBJ_STRING);\n\n    switch(o->encoding) {\n    case OBJ_ENCODING_RAW:\n        return createRawStringObject(o->ptr,sdslen(o->ptr));\n    case OBJ_ENCODING_EMBSTR:\n        return createEmbeddedStringObject(o->ptr,sdslen(o->ptr));\n    case OBJ_ENCODING_INT:\n        d = createObject(OBJ_STRING, NULL);\n        d->encoding = OBJ_ENCODING_INT;\n        d->ptr = o->ptr;\n        return d;\n    default:\n        serverPanic(\"Wrong encoding.\");\n        break;\n    }\n}\n\nrobj *createQuicklistObject(int fill, int compress) {\n    quicklist *l = quicklistNew(fill, compress);\n    robj *o = createObject(OBJ_LIST,l);\n    o->encoding = OBJ_ENCODING_QUICKLIST;\n    return o;\n}\n\nrobj *createListListpackObject(void) {\n    unsigned char *lp = lpNew(0);\n    robj *o = createObject(OBJ_LIST,lp);\n    o->encoding = OBJ_ENCODING_LISTPACK;\n    return o;\n}\n\nrobj *createSetObject(void) {\n    dict *d = dictCreate(&setDictType);\n    robj *o = createObject(OBJ_SET,d);\n    o->encoding = OBJ_ENCODING_HT;\n    return o;\n}\n\nrobj *createIntsetObject(void) {\n    intset *is = intsetNew();\n    robj *o = createObject(OBJ_SET,is);\n    o->encoding = OBJ_ENCODING_INTSET;\n    return o;\n}\n\nrobj *createSetListpackObject(void) {\n    unsigned char *lp = lpNew(0);\n    robj *o = createObject(OBJ_SET, lp);\n    o->encoding = OBJ_ENCODING_LISTPACK;\n    return o;\n}\n\nrobj *createHashObject(void) {\n    unsigned char *zl = lpNew(0);\n    robj *o = createObject(OBJ_HASH, zl);\n    o->encoding = OBJ_ENCODING_LISTPACK;\n    return o;\n}\n\nrobj *createZsetObject(void) {\n    zset *zs = zmalloc(sizeof(*zs));\n    robj *o;\n\n    zs->dict = dictCreate(&zsetDictType);\n    zs->zsl = zslCreate();\n    o = createObject(OBJ_ZSET,zs);\n    o->encoding = OBJ_ENCODING_SKIPLIST;\n    return o;\n}\n\nrobj *createZsetListpackObject(void) {\n    unsigned char *lp = lpNew(0);\n    robj *o = createObject(OBJ_ZSET,lp);\n    o->encoding = OBJ_ENCODING_LISTPACK;\n    return o;\n}\n\nrobj *createStreamObject(void) {\n    stream *s = streamNew();\n    robj *o = createObject(OBJ_STREAM,s);\n    o->encoding = OBJ_ENCODING_STREAM;\n    return o;\n}\n\nrobj *createModuleObject(moduleType *mt, void *value) {\n    moduleValue *mv = zmalloc(sizeof(*mv));\n    mv->type = mt;\n    mv->value = value;\n    return createObject(OBJ_MODULE,mv);\n}\n\nvoid freeStringObject(robj *o) {\n    if (o->encoding == OBJ_ENCODING_RAW) {\n        sdsfree(o->ptr);\n    }\n}\n\nvoid freeListObject(robj *o) {\n    if (o->encoding == OBJ_ENCODING_QUICKLIST) {\n"}], "code": "robj *createStringObjectFromLongLongForValue(long long value) {\n    if (server.maxmemory == 0 || !(server.maxmemory_policy & MAXMEMORY_FLAG_NO_SHARED_INTEGERS)) {\n        /* If the maxmemory policy permits, we can still return shared integers */\n        return createStringObjectFromLongLongWithOptions(value, LL2STROBJ_AUTO);\n    } else {\n        return createStringObjectFromLongLongWithOptions(value, LL2STROBJ_NO_SHARED);\n    }\n}\n"}, "8B7D3882CF9CBFEC": {"calls": [{"id": "1F4A2DF875CFFA31", "name": "getLRUClock", "path": "redis/src/evict.c", "start": {"line": 73, "col": 1}, "end": {"line": 75, "col": 1}, "code": "    return (mstime()/LRU_CLOCK_RESOLUTION) & LRU_CLOCK_MAX;\n}\n\n/* This function is used to obtain the current LRU clock.\n * If the current resolution is lower than the frequency we refresh the\n * LRU clock (as it should be in production servers) we return the\n * precomputed value, otherwise we need to resort to a system call. */\nunsigned int LRU_CLOCK(void) {\n    unsigned int lruclock;\n    if (1000/server.hz <= LRU_CLOCK_RESOLUTION) {\n        lruclock = server.lruclock;\n    } else {\n        lruclock = getLRUClock();\n    }\n    return lruclock;\n}\n\n/* Given an object returns the min number of milliseconds the object was never\n * requested, using an approximated LRU algorithm. */\nunsigned long long estimateObjectIdleTime(robj *o) {\n    unsigned long long lruclock = LRU_CLOCK();\n    if (lruclock >= o->lru) {\n        return (lruclock - o->lru) * LRU_CLOCK_RESOLUTION;\n    } else {\n        return (lruclock + (LRU_CLOCK_MAX - o->lru)) *\n                    LRU_CLOCK_RESOLUTION;\n    }\n}\n\n/* LRU approximation algorithm\n *\n * Redis uses an approximation of the LRU algorithm that runs in constant\n * memory. Every time there is a key to expire, we sample N keys (with\n * N very small, usually in around 5) to populate a pool of best keys to\n * evict of M keys (the pool size is defined by EVPOOL_SIZE).\n *\n * The N keys sampled are added in the pool of good keys to expire (the one\n * with an old access time) if they are better than one of the current keys\n * in the pool.\n *\n * After the pool is populated, the best key we have in the pool is expired.\n * However note that we don't remove keys from the pool when they are deleted\n * so the pool may contain keys that no longer exist.\n *\n * When we try to evict a key, and all the entries in the pool don't exist\n * we populate it again. This time we'll be sure that the pool has at least\n * one key that can be evicted, if there is at least one key that can be\n * evicted in the whole database. */\n\n/* Create a new eviction pool. */\nvoid evictionPoolAlloc(void) {\n    struct evictionPoolEntry *ep;\n    int j;\n\n    ep = zmalloc(sizeof(*ep)*EVPOOL_SIZE);\n    for (j = 0; j < EVPOOL_SIZE; j++) {\n        ep[j].idle = 0;\n        ep[j].key = NULL;\n        ep[j].cached = sdsnewlen(NULL,EVPOOL_CACHED_SDS_SIZE);\n        ep[j].dbid = 0;\n    }\n    EvictionPoolLRU = ep;\n}\n\n/* This is a helper function for performEvictions(), it is used in order\n * to populate the evictionPool with a few entries every time we want to\n * expire a key. Keys with idle time bigger than one of the current\n * keys are added. Keys are always added if there are free entries.\n *\n * We insert keys on place in ascending order, so keys with the smaller\n * idle time are on the left, and keys with the higher idle time on the\n * right. */\nint evictionPoolPopulate(redisDb *db, kvstore *samplekvs, struct evictionPoolEntry *pool) {\n    int j, k, count;\n    dictEntry *samples[server.maxmemory_samples];\n\n"}], "code": "unsigned int LRU_CLOCK(void) {\n    unsigned int lruclock;\n    if (1000/server.hz <= LRU_CLOCK_RESOLUTION) {\n        lruclock = server.lruclock;\n    } else {\n        lruclock = getLRUClock();\n    }\n    return lruclock;\n}\n"}, "CA200194ACEB9F7D": {"calls": [{"id": "E1D0417BD9E22EC0", "name": "zsetConvertAndExpand", "path": "redis/src/t_zset.c", "start": {"line": 1269, "col": 1}, "end": {"line": 1342, "col": 1}, "code": "    zset *zs;\n    zskiplistNode *node, *next;\n    sds ele;\n    double score;\n\n    if (zobj->encoding == encoding) return;\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n        unsigned char *vstr;\n        unsigned int vlen;\n        long long vlong;\n\n        if (encoding != OBJ_ENCODING_SKIPLIST)\n            serverPanic(\"Unknown target encoding\");\n\n        zs = zmalloc(sizeof(*zs));\n        zs->dict = dictCreate(&zsetDictType);\n        zs->zsl = zslCreate();\n\n        /* Presize the dict to avoid rehashing */\n        dictExpand(zs->dict, cap);\n\n        eptr = lpSeek(zl,0);\n        if (eptr != NULL) {\n            sptr = lpNext(zl,eptr);\n            serverAssertWithInfo(NULL,zobj,sptr != NULL);\n        }\n\n        while (eptr != NULL) {\n            score = zzlGetScore(sptr);\n            vstr = lpGetValue(eptr,&vlen,&vlong);\n            if (vstr == NULL)\n                ele = sdsfromlonglong(vlong);\n            else\n                ele = sdsnewlen((char*)vstr,vlen);\n\n            node = zslInsert(zs->zsl,score,ele);\n            serverAssert(dictAdd(zs->dict,ele,&node->score) == DICT_OK);\n            zzlNext(zl,&eptr,&sptr);\n        }\n\n        zfree(zobj->ptr);\n        zobj->ptr = zs;\n        zobj->encoding = OBJ_ENCODING_SKIPLIST;\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        unsigned char *zl = lpNew(0);\n\n        if (encoding != OBJ_ENCODING_LISTPACK)\n            serverPanic(\"Unknown target encoding\");\n\n        /* Approach similar to zslFree(), since we want to free the skiplist at\n         * the same time as creating the listpack. */\n        zs = zobj->ptr;\n        dictRelease(zs->dict);\n        node = zs->zsl->header->level[0].forward;\n        zfree(zs->zsl->header);\n        zfree(zs->zsl);\n\n        while (node) {\n            zl = zzlInsertAt(zl,NULL,node->ele,node->score);\n            next = node->level[0].forward;\n            zslFreeNode(node);\n            node = next;\n        }\n\n        zfree(zs);\n        zobj->ptr = zl;\n        zobj->encoding = OBJ_ENCODING_LISTPACK;\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n}\n\n/* Convert the sorted set object into a listpack if it is not already a listpack\n * and if the number of elements and the maximum element size and total elements size\n * are within the expected ranges. */\nvoid zsetConvertToListpackIfNeeded(robj *zobj, size_t maxelelen, size_t totelelen) {\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) return;\n    zset *zset = zobj->ptr;\n\n    if (zset->zsl->length <= server.zset_max_listpack_entries &&\n        maxelelen <= server.zset_max_listpack_value &&\n        lpSafeToAdd(NULL, totelelen))\n    {\n        zsetConvert(zobj,OBJ_ENCODING_LISTPACK);\n    }\n}\n\n/* Return (by reference) the score of the specified member of the sorted set\n * storing it into *score. If the element does not exist C_ERR is returned\n * otherwise C_OK is returned and *score is correctly populated.\n * If 'zobj' or 'member' is NULL, C_ERR is returned. */\nint zsetScore(robj *zobj, sds member, double *score) {\n    if (!zobj || !member) return C_ERR;\n\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) {\n        if (zzlFind(zobj->ptr, member, score) == NULL) return C_ERR;\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        dictEntry *de = dictFind(zs->dict, member);\n        if (de == NULL) return C_ERR;\n        *score = *(double*)dictGetVal(de);\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return C_OK;\n}\n\n/* Add a new element or update the score of an existing element in a sorted\n * set, regardless of its encoding.\n *\n * The set of flags change the command behavior. \n *\n * The input flags are the following:\n *\n * ZADD_INCR: Increment the current element score by 'score' instead of updating\n *            the current element score. If the element does not exist, we\n *            assume 0 as previous score.\n * ZADD_NX:   Perform the operation only if the element does not exist.\n * ZADD_XX:   Perform the operation only if the element already exist.\n * ZADD_GT:   Perform the operation on existing elements only if the new score is \n *            greater than the current score.\n * ZADD_LT:   Perform the operation on existing elements only if the new score is \n *            less than the current score.\n *\n * When ZADD_INCR is used, the new score of the element is stored in\n * '*newscore' if 'newscore' is not NULL.\n *\n * The returned flags are the following:\n *\n * ZADD_NAN:     The resulting score is not a number.\n * ZADD_ADDED:   The element was added (not present before the call).\n * ZADD_UPDATED: The element score was updated.\n * ZADD_NOP:     No operation was performed because of NX or XX.\n *\n * Return value:\n *\n * The function returns 1 on success, and sets the appropriate flags\n * ADDED or UPDATED to signal what happened during the operation (note that\n * none could be set if we re-added an element using the same score it used\n * to have, or in the case a zero increment is used).\n *\n * The function returns 0 on error, currently only when the increment\n * produces a NAN condition, or when the 'score' value is NAN since the\n * start.\n *\n * The command as a side effect of adding a new element may convert the sorted\n * set internal encoding from listpack to hashtable+skiplist.\n *\n * Memory management of 'ele':\n *\n * The function does not take ownership of the 'ele' SDS string, but copies\n * it if needed. */\nint zsetAdd(robj *zobj, double score, sds ele, int in_flags, int *out_flags, double *newscore) {\n    /* Turn options into simple to check vars. */\n    int incr = (in_flags & ZADD_IN_INCR) != 0;\n    int nx = (in_flags & ZADD_IN_NX) != 0;\n    int xx = (in_flags & ZADD_IN_XX) != 0;\n    int gt = (in_flags & ZADD_IN_GT) != 0;\n    int lt = (in_flags & ZADD_IN_LT) != 0;\n    *out_flags = 0; /* We'll return our response flags. */\n    double curscore;\n\n    /* NaN as input is an error regardless of all the other parameters. */\n    if (isnan(score)) {\n        *out_flags = ZADD_OUT_NAN;\n        return 0;\n    }\n\n    /* Update the sorted set according to its encoding. */\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) {\n        unsigned char *eptr;\n\n        if ((eptr = zzlFind(zobj->ptr,ele,&curscore)) != NULL) {\n            /* NX? Return, same element already exists. */\n            if (nx) {\n                *out_flags |= ZADD_OUT_NOP;\n                return 1;\n            }\n\n            /* Prepare the score for the increment if needed. */\n            if (incr) {\n                score += curscore;\n                if (isnan(score)) {\n                    *out_flags |= ZADD_OUT_NAN;\n                    return 0;\n                }\n            }\n\n            /* GT/LT? Only update if score is greater/less than current. */\n            if ((lt && score >= curscore) || (gt && score <= curscore)) {\n                *out_flags |= ZADD_OUT_NOP;\n                return 1;\n            }\n\n            if (newscore) *newscore = score;\n\n            /* Remove and re-insert when score changed. */\n            if (score != curscore) {\n                zobj->ptr = zzlDelete(zobj->ptr,eptr);\n                zobj->ptr = zzlInsert(zobj->ptr,ele,score);\n                *out_flags |= ZADD_OUT_UPDATED;\n            }\n            return 1;\n        } else if (!xx) {\n            /* check if the element is too large or the list\n             * becomes too long *before* executing zzlInsert. */\n            if (zzlLength(zobj->ptr)+1 > server.zset_max_listpack_entries ||\n                sdslen(ele) > server.zset_max_listpack_value ||\n                !lpSafeToAdd(zobj->ptr, sdslen(ele)))\n            {\n                zsetConvertAndExpand(zobj, OBJ_ENCODING_SKIPLIST, zsetLength(zobj) + 1);\n            } else {\n                zobj->ptr = zzlInsert(zobj->ptr,ele,score);\n                if (newscore) *newscore = score;\n                *out_flags |= ZADD_OUT_ADDED;\n                return 1;\n            }\n        } else {\n            *out_flags |= ZADD_OUT_NOP;\n            return 1;\n        }\n    }\n\n    /* Note that the above block handling listpack would have either returned or\n     * converted the key to skiplist. */\n    if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplistNode *znode;\n        dictEntry *de;\n\n        de = dictFind(zs->dict,ele);\n        if (de != NULL) {\n            /* NX? Return, same element already exists. */\n            if (nx) {\n                *out_flags |= ZADD_OUT_NOP;\n                return 1;\n            }\n\n            curscore = *(double*)dictGetVal(de);\n\n            /* Prepare the score for the increment if needed. */\n            if (incr) {\n                score += curscore;\n                if (isnan(score)) {\n                    *out_flags |= ZADD_OUT_NAN;\n                    return 0;\n                }\n            }\n\n            /* GT/LT? Only update if score is greater/less than current. */\n            if ((lt && score >= curscore) || (gt && score <= curscore)) {\n                *out_flags |= ZADD_OUT_NOP;\n                return 1;\n            }\n\n            if (newscore) *newscore = score;\n\n            /* Remove and re-insert when score changes. */\n            if (score != curscore) {\n                znode = zslUpdateScore(zs->zsl,curscore,ele,score);\n                /* Note that we did not removed the original element from\n                 * the hash table representing the sorted set, so we just\n                 * update the score. */\n                dictSetVal(zs->dict, de, &znode->score); /* Update score ptr. */\n                *out_flags |= ZADD_OUT_UPDATED;\n            }\n            return 1;\n        } else if (!xx) {\n            ele = sdsdup(ele);\n            znode = zslInsert(zs->zsl,score,ele);\n            serverAssert(dictAdd(zs->dict,ele,&znode->score) == DICT_OK);\n            *out_flags |= ZADD_OUT_ADDED;\n            if (newscore) *newscore = score;\n            return 1;\n        } else {\n            *out_flags |= ZADD_OUT_NOP;\n            return 1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return 0; /* Never reached. */\n}\n\n/* Deletes the element 'ele' from the sorted set encoded as a skiplist+dict,\n * returning 1 if the element existed and was deleted, 0 otherwise (the\n * element was not there). It does not resize the dict after deleting the\n * element. */\nstatic int zsetRemoveFromSkiplist(zset *zs, sds ele) {\n    dictEntry *de;\n    double score;\n\n    de = dictUnlink(zs->dict,ele);\n    if (de != NULL) {\n        /* Get the score in order to delete from the skiplist later. */\n        score = *(double*)dictGetVal(de);\n\n        /* Delete from the hash table and later from the skiplist.\n         * Note that the order is important: deleting from the skiplist\n         * actually releases the SDS string representing the element,\n         * which is shared between the skiplist and the hash table, so\n         * we need to delete from the skiplist as the final step. */\n        dictFreeUnlinkedEntry(zs->dict,de);\n\n        /* Delete from skiplist. */\n        int retval = zslDelete(zs->zsl,score,ele,NULL);\n        serverAssert(retval);\n\n        return 1;\n    }\n\n    return 0;\n}\n\n/* Delete the element 'ele' from the sorted set, returning 1 if the element\n * existed and was deleted, 0 otherwise (the element was not there). */\nint zsetDel(robj *zobj, sds ele) {\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) {\n        unsigned char *eptr;\n\n        if ((eptr = zzlFind(zobj->ptr,ele,NULL)) != NULL) {\n            zobj->ptr = zzlDelete(zobj->ptr,eptr);\n            return 1;\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        if (zsetRemoveFromSkiplist(zs, ele)) {\n            return 1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return 0; /* No such element found. */\n}\n\n/* Given a sorted set object returns the 0-based rank of the object or\n * -1 if the object does not exist.\n *\n * For rank we mean the position of the element in the sorted collection\n * of elements. So the first element has rank 0, the second rank 1, and so\n * forth up to length-1 elements.\n *\n * If 'reverse' is false, the rank is returned considering as first element\n * the one with the lowest score. Otherwise if 'reverse' is non-zero\n * the rank is computed considering as element with rank 0 the one with\n * the highest score. */\nlong zsetRank(robj *zobj, sds ele, int reverse, double *output_score) {\n    unsigned long llen;\n    unsigned long rank;\n\n    llen = zsetLength(zobj);\n\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) {\n        unsigned char *zl = zobj->ptr;\n        unsigned char *eptr, *sptr;\n\n        eptr = lpSeek(zl,0);\n        serverAssert(eptr != NULL);\n        sptr = lpNext(zl,eptr);\n        serverAssert(sptr != NULL);\n\n        rank = 1;\n        while(eptr != NULL) {\n            if (lpCompare(eptr,(unsigned char*)ele,sdslen(ele)))\n                break;\n            rank++;\n            zzlNext(zl,&eptr,&sptr);\n        }\n\n        if (eptr != NULL) {\n            if (output_score) \n                *output_score = zzlGetScore(sptr);\n            if (reverse)\n                return llen-rank;\n            else\n                return rank-1;\n        } else {\n            return -1;\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        zskiplist *zsl = zs->zsl;\n        dictEntry *de;\n        double score;\n\n        de = dictFind(zs->dict,ele);\n        if (de != NULL) {\n            score = *(double*)dictGetVal(de);\n            rank = zslGetRank(zsl,score,ele);\n            /* Existing elements always have a rank. */\n            serverAssert(rank != 0);\n            if (output_score)\n                *output_score = score;\n            if (reverse)\n                return llen-rank;\n            else\n                return rank-1;\n        } else {\n            return -1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n}\n\n/* This is a helper function for the COPY command.\n * Duplicate a sorted set object, with the guarantee that the returned object\n * has the same encoding as the original one.\n *\n * The resulting object always has refcount set to 1 */\nrobj *zsetDup(robj *o) {\n    robj *zobj;\n    zset *zs;\n    zset *new_zs;\n\n    serverAssert(o->type == OBJ_ZSET);\n\n    /* Create a new sorted set object that have the same encoding as the original object's encoding */\n    if (o->encoding == OBJ_ENCODING_LISTPACK) {\n        unsigned char *zl = o->ptr;\n        size_t sz = lpBytes(zl);\n        unsigned char *new_zl = zmalloc(sz);\n        memcpy(new_zl, zl, sz);\n        zobj = createObject(OBJ_ZSET, new_zl);\n        zobj->encoding = OBJ_ENCODING_LISTPACK;\n    } else if (o->encoding == OBJ_ENCODING_SKIPLIST) {\n        zobj = createZsetObject();\n        zs = o->ptr;\n        new_zs = zobj->ptr;\n        dictExpand(new_zs->dict,dictSize(zs->dict));\n        zskiplist *zsl = zs->zsl;\n        zskiplistNode *ln;\n        sds ele;\n        long llen = zsetLength(o);\n\n        /* We copy the skiplist elements from the greatest to the\n         * smallest (that's trivial since the elements are already ordered in\n         * the skiplist): this improves the load process, since the next loaded\n         * element will always be the smaller, so adding to the skiplist\n         * will always immediately stop at the head, making the insertion\n         * O(1) instead of O(log(N)). */\n        ln = zsl->tail;\n        while (llen--) {\n            ele = ln->ele;\n            sds new_ele = sdsdup(ele);\n            zskiplistNode *znode = zslInsert(new_zs->zsl,ln->score,new_ele);\n            dictAdd(new_zs->dict,new_ele,&znode->score);\n            ln = ln->backward;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n    return zobj;\n}\n\n/* Create a new sds string from the listpack entry. */\nsds zsetSdsFromListpackEntry(listpackEntry *e) {\n    return e->sval ? sdsnewlen(e->sval, e->slen) : sdsfromlonglong(e->lval);\n}\n\n/* Reply with bulk string from the listpack entry. */\nvoid zsetReplyFromListpackEntry(client *c, listpackEntry *e) {\n    if (e->sval)\n        addReplyBulkCBuffer(c, e->sval, e->slen);\n    else\n        addReplyBulkLongLong(c, e->lval);\n}\n\n\n/* Return random element from a non empty zset.\n * 'key' and 'val' will be set to hold the element.\n * The memory in `key` is not to be freed or modified by the caller.\n * 'score' can be NULL in which case it's not extracted. */\nvoid zsetTypeRandomElement(robj *zsetobj, unsigned long zsetsize, listpackEntry *key, double *score) {\n    if (zsetobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zsetobj->ptr;\n        dictEntry *de = dictGetFairRandomKey(zs->dict);\n        sds s = dictGetKey(de);\n        key->sval = (unsigned char*)s;\n        key->slen = sdslen(s);\n        if (score)\n            *score = *(double*)dictGetVal(de);\n    } else if (zsetobj->encoding == OBJ_ENCODING_LISTPACK) {\n        listpackEntry val;\n        lpRandomPair(zsetobj->ptr, zsetsize, key, &val);\n        if (score) {\n            if (val.sval) {\n                *score = zzlStrtod(val.sval,val.slen);\n            } else {\n                *score = (double)val.lval;\n            }\n        }\n    } else {\n        serverPanic(\"Unknown zset encoding\");\n    }\n}\n\n/*-----------------------------------------------------------------------------\n * Sorted set commands\n *----------------------------------------------------------------------------*/\n\n/* This generic command implements both ZADD and ZINCRBY. */\nvoid zaddGenericCommand(client *c, int flags) {\n    static char *nanerr = \"resulting score is not a number (NaN)\";\n    robj *key = c->argv[1];\n    robj *zobj;\n    sds ele;\n    double score = 0, *scores = NULL;\n    int j, elements, ch = 0;\n    int scoreidx = 0;\n    /* The following vars are used in order to track what the command actually\n     * did during the execution, to reply to the client and to trigger the\n     * notification of keyspace change. */\n    int added = 0;      /* Number of new elements added. */\n    int updated = 0;    /* Number of elements with updated score. */\n    int processed = 0;  /* Number of elements processed, may remain zero with\n                           options like XX. */\n\n    /* Parse options. At the end 'scoreidx' is set to the argument position\n     * of the score of the first score-element pair. */\n    scoreidx = 2;\n    while(scoreidx < c->argc) {\n        char *opt = c->argv[scoreidx]->ptr;\n        if (!strcasecmp(opt,\"nx\")) flags |= ZADD_IN_NX;\n        else if (!strcasecmp(opt,\"xx\")) flags |= ZADD_IN_XX;\n        else if (!strcasecmp(opt,\"ch\")) ch = 1; /* Return num of elements added or updated. */\n        else if (!strcasecmp(opt,\"incr\")) flags |= ZADD_IN_INCR;\n        else if (!strcasecmp(opt,\"gt\")) flags |= ZADD_IN_GT;\n        else if (!strcasecmp(opt,\"lt\")) flags |= ZADD_IN_LT;\n        else break;\n        scoreidx++;\n    }\n\n    /* Turn options into simple to check vars. */\n    int incr = (flags & ZADD_IN_INCR) != 0;\n    int nx = (flags & ZADD_IN_NX) != 0;\n    int xx = (flags & ZADD_IN_XX) != 0;\n    int gt = (flags & ZADD_IN_GT) != 0;\n    int lt = (flags & ZADD_IN_LT) != 0;\n\n    /* After the options, we expect to have an even number of args, since\n     * we expect any number of score-element pairs. */\n    elements = c->argc-scoreidx;\n    if (elements % 2 || !elements) {\n        addReplyErrorObject(c,shared.syntaxerr);\n        return;\n    }\n    elements /= 2; /* Now this holds the number of score-element pairs. */\n\n    /* Check for incompatible options. */\n    if (nx && xx) {\n        addReplyError(c,\n            \"XX and NX options at the same time are not compatible\");\n        return;\n    }\n    \n    if ((gt && nx) || (lt && nx) || (gt && lt)) {\n        addReplyError(c,\n            \"GT, LT, and/or NX options at the same time are not compatible\");\n        return;\n    }\n    /* Note that XX is compatible with either GT or LT */\n\n    if (incr && elements > 1) {\n        addReplyError(c,\n            \"INCR option supports a single increment-element pair\");\n        return;\n    }\n\n    /* Start parsing all the scores, we need to emit any syntax error\n     * before executing additions to the sorted set, as the command should\n     * either execute fully or nothing at all. */\n    scores = zmalloc(sizeof(double)*elements);\n    for (j = 0; j < elements; j++) {\n        if (getDoubleFromObjectOrReply(c,c->argv[scoreidx+j*2],&scores[j],NULL)\n            != C_OK) goto cleanup;\n    }\n\n    /* Lookup the key and create the sorted set if does not exist. */\n    zobj = lookupKeyWrite(c->db,key);\n    if (checkType(c,zobj,OBJ_ZSET)) goto cleanup;\n    if (zobj == NULL) {\n        if (xx) goto reply_to_client; /* No key + XX option: nothing to do. */\n        zobj = zsetTypeCreate(elements, sdslen(c->argv[scoreidx+1]->ptr));\n        dbAdd(c->db,key,zobj);\n    } else {\n        zsetTypeMaybeConvert(zobj, elements);\n    }\n\n    for (j = 0; j < elements; j++) {\n        double newscore;\n        score = scores[j];\n        int retflags = 0;\n\n        ele = c->argv[scoreidx+1+j*2]->ptr;\n        int retval = zsetAdd(zobj, score, ele, flags, &retflags, &newscore);\n        if (retval == 0) {\n            addReplyError(c,nanerr);\n            goto cleanup;\n        }\n        if (retflags & ZADD_OUT_ADDED) added++;\n        if (retflags & ZADD_OUT_UPDATED) updated++;\n        if (!(retflags & ZADD_OUT_NOP)) processed++;\n        score = newscore;\n    }\n    server.dirty += (added+updated);\n\nreply_to_client:\n    if (incr) { /* ZINCRBY or INCR option. */\n        if (processed)\n            addReplyDouble(c,score);\n        else\n            addReplyNull(c);\n    } else { /* ZADD. */\n        addReplyLongLong(c,ch ? added+updated : added);\n    }\n\ncleanup:\n    zfree(scores);\n    if (added || updated) {\n        signalModifiedKey(c,c->db,key);\n        notifyKeyspaceEvent(NOTIFY_ZSET,\n            incr ? \"zincr\" : \"zadd\", key, c->db->id);\n    }\n}\n\nvoid zaddCommand(client *c) {\n    zaddGenericCommand(c,ZADD_IN_NONE);\n}\n\nvoid zincrbyCommand(client *c) {\n    zaddGenericCommand(c,ZADD_IN_INCR);\n}\n\nvoid zremCommand(client *c) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    int deleted = 0, keyremoved = 0, j;\n\n    if ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) return;\n\n    for (j = 2; j < c->argc; j++) {\n        if (zsetDel(zobj,c->argv[j]->ptr)) deleted++;\n        if (zsetLength(zobj) == 0) {\n            dbDelete(c->db,key);\n            keyremoved = 1;\n            break;\n        }\n    }\n\n    if (deleted) {\n        notifyKeyspaceEvent(NOTIFY_ZSET,\"zrem\",key,c->db->id);\n        if (keyremoved)\n            notifyKeyspaceEvent(NOTIFY_GENERIC,\"del\",key,c->db->id);\n        signalModifiedKey(c,c->db,key);\n        server.dirty += deleted;\n    }\n    addReplyLongLong(c,deleted);\n}\n\ntypedef enum {\n    ZRANGE_AUTO = 0,\n    ZRANGE_RANK,\n    ZRANGE_SCORE,\n    ZRANGE_LEX,\n} zrange_type;\n\n/* Implements ZREMRANGEBYRANK, ZREMRANGEBYSCORE, ZREMRANGEBYLEX commands. */\nvoid zremrangeGenericCommand(client *c, zrange_type rangetype) {\n    robj *key = c->argv[1];\n    robj *zobj;\n    int keyremoved = 0;\n    unsigned long deleted = 0;\n    zrangespec range;\n    zlexrangespec lexrange;\n    long start, end, llen;\n    char *notify_type = NULL;\n\n    /* Step 1: Parse the range. */\n    if (rangetype == ZRANGE_RANK) {\n        notify_type = \"zremrangebyrank\";\n        if ((getLongFromObjectOrReply(c,c->argv[2],&start,NULL) != C_OK) ||\n            (getLongFromObjectOrReply(c,c->argv[3],&end,NULL) != C_OK))\n            return;\n    } else if (rangetype == ZRANGE_SCORE) {\n        notify_type = \"zremrangebyscore\";\n        if (zslParseRange(c->argv[2],c->argv[3],&range) != C_OK) {\n            addReplyError(c,\"min or max is not a float\");\n            return;\n        }\n    } else if (rangetype == ZRANGE_LEX) {\n        notify_type = \"zremrangebylex\";\n        if (zslParseLexRange(c->argv[2],c->argv[3],&lexrange) != C_OK) {\n            addReplyError(c,\"min or max not valid string range item\");\n            return;\n        }\n    } else {\n        serverPanic(\"unknown rangetype %d\", (int)rangetype);\n    }\n\n    /* Step 2: Lookup & range sanity checks if needed. */\n    if ((zobj = lookupKeyWriteOrReply(c,key,shared.czero)) == NULL ||\n        checkType(c,zobj,OBJ_ZSET)) goto cleanup;\n\n    if (rangetype == ZRANGE_RANK) {\n        /* Sanitize indexes. */\n        llen = zsetLength(zobj);\n        if (start < 0) start = llen+start;\n        if (end < 0) end = llen+end;\n        if (start < 0) start = 0;\n\n        /* Invariant: start >= 0, so this test will be true when end < 0.\n         * The range is empty when start > end or start >= length. */\n        if (start > end || start >= llen) {\n            addReply(c,shared.czero);\n            goto cleanup;\n        }\n        if (end >= llen) end = llen-1;\n    }\n\n    /* Step 3: Perform the range deletion operation. */\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK) {\n        switch(rangetype) {\n        case ZRANGE_AUTO:\n        case ZRANGE_RANK:\n            zobj->ptr = zzlDeleteRangeByRank(zobj->ptr,start+1,end+1,&deleted);\n            break;\n        case ZRANGE_SCORE:\n            zobj->ptr = zzlDeleteRangeByScore(zobj->ptr,&range,&deleted);\n            break;\n        case ZRANGE_LEX:\n            zobj->ptr = zzlDeleteRangeByLex(zobj->ptr,&lexrange,&deleted);\n            break;\n        }\n        if (zzlLength(zobj->ptr) == 0) {\n            dbDelete(c->db,key);\n            keyremoved = 1;\n        }\n    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n        zset *zs = zobj->ptr;\n        dictPauseAutoResize(zs->dict);\n        switch(rangetype) {\n        case ZRANGE_AUTO:\n        case ZRANGE_RANK:\n            deleted = zslDeleteRangeByRank(zs->zsl,start+1,end+1,zs->dict);\n            break;\n        case ZRANGE_SCORE:\n            deleted = zslDeleteRangeByScore(zs->zsl,&range,zs->dict);\n            break;\n        case ZRANGE_LEX:\n            deleted = zslDeleteRangeByLex(zs->zsl,&lexrange,zs->dict);\n            break;\n        }\n        dictResumeAutoResize(zs->dict);\n        dictShrinkIfNeeded(zs->dict);\n        if (dictSize(zs->dict) == 0) {\n            dbDelete(c->db,key);\n            keyremoved = 1;\n        }\n    } else {\n        serverPanic(\"Unknown sorted set encoding\");\n    }\n\n    /* Step 4: Notifications and reply. */\n    if (deleted) {\n        signalModifiedKey(c,c->db,key);\n        notifyKeyspaceEvent(NOTIFY_ZSET,notify_type,key,c->db->id);\n        if (keyremoved)\n            notifyKeyspaceEvent(NOTIFY_GENERIC,\"del\",key,c->db->id);\n    }\n    server.dirty += deleted;\n    addReplyLongLong(c,deleted);\n\ncleanup:\n    if (rangetype == ZRANGE_LEX) zslFreeLexRange(&lexrange);\n}\n\nvoid zremrangebyrankCommand(client *c) {\n    zremrangeGenericCommand(c,ZRANGE_RANK);\n}\n\nvoid zremrangebyscoreCommand(client *c) {\n    zremrangeGenericCommand(c,ZRANGE_SCORE);\n}\n\nvoid zremrangebylexCommand(client *c) {\n    zremrangeGenericCommand(c,ZRANGE_LEX);\n}\n\ntypedef struct {\n    robj *subject;\n    int type; /* Set, sorted set */\n    int encoding;\n    double weight;\n\n    union {\n        /* Set iterators. */\n        union _iterset {\n            struct {\n                intset *is;\n                int ii;\n            } is;\n            struct {\n                dict *dict;\n                dictIterator *di;\n                dictEntry *de;\n            } ht;\n            struct {\n                unsigned char *lp;\n                unsigned char *p;\n            } lp;\n        } set;\n\n        /* Sorted set iterators. */\n        union _iterzset {\n            struct {\n                unsigned char *zl;\n                unsigned char *eptr, *sptr;\n            } zl;\n            struct {\n                zset *zs;\n                zskiplistNode *node;\n            } sl;\n        } zset;\n    } iter;\n} zsetopsrc;\n\n\n/* Use dirty flags for pointers that need to be cleaned up in the next\n * iteration over the zsetopval. The dirty flag for the long long value is\n * special, since long long values don't need cleanup. Instead, it means that\n * we already checked that \"ell\" holds a long long, or tried to convert another\n * representation into a long long value. When this was successful,\n * OPVAL_VALID_LL is set as well. */\n#define OPVAL_DIRTY_SDS 1\n#define OPVAL_DIRTY_LL 2\n#define OPVAL_VALID_LL 4\n\n/* Store value retrieved from the iterator. */\ntypedef struct {\n    int flags;\n    unsigned char _buf[32]; /* Private buffer. */\n    sds ele;\n    unsigned char *estr;\n    unsigned int elen;\n    long long ell;\n    double score;\n} zsetopval;\n\ntypedef union _iterset iterset;\ntypedef union _iterzset iterzset;\n\nvoid zuiInitIterator(zsetopsrc *op) {\n    if (op->subject == NULL)\n        return;\n\n    if (op->type == OBJ_SET) {\n        iterset *it = &op->iter.set;\n        if (op->encoding == OBJ_ENCODING_INTSET) {\n            it->is.is = op->subject->ptr;\n            it->is.ii = 0;\n        } else if (op->encoding == OBJ_ENCODING_HT) {\n            it->ht.dict = op->subject->ptr;\n            it->ht.di = dictGetIterator(op->subject->ptr);\n            it->ht.de = dictNext(it->ht.di);\n        } else if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            it->lp.lp = op->subject->ptr;\n            it->lp.p = lpFirst(it->lp.lp);\n        } else {\n            serverPanic(\"Unknown set encoding\");\n        }\n    } else if (op->type == OBJ_ZSET) {\n        /* Sorted sets are traversed in reverse order to optimize for\n         * the insertion of the elements in a new list as in\n         * ZDIFF/ZINTER/ZUNION */\n        iterzset *it = &op->iter.zset;\n        if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            it->zl.zl = op->subject->ptr;\n            it->zl.eptr = lpSeek(it->zl.zl,-2);\n            if (it->zl.eptr != NULL) {\n                it->zl.sptr = lpNext(it->zl.zl,it->zl.eptr);\n                serverAssert(it->zl.sptr != NULL);\n            }\n        } else if (op->encoding == OBJ_ENCODING_SKIPLIST) {\n            it->sl.zs = op->subject->ptr;\n            it->sl.node = it->sl.zs->zsl->tail;\n        } else {\n            serverPanic(\"Unknown sorted set encoding\");\n        }\n    } else {\n        serverPanic(\"Unsupported type\");\n    }\n}\n\nvoid zuiClearIterator(zsetopsrc *op) {\n    if (op->subject == NULL)\n        return;\n\n    if (op->type == OBJ_SET) {\n        iterset *it = &op->iter.set;\n        if (op->encoding == OBJ_ENCODING_INTSET) {\n            UNUSED(it); /* skip */\n        } else if (op->encoding == OBJ_ENCODING_HT) {\n            dictReleaseIterator(it->ht.di);\n        } else if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            UNUSED(it);\n        } else {\n            serverPanic(\"Unknown set encoding\");\n        }\n    } else if (op->type == OBJ_ZSET) {\n        iterzset *it = &op->iter.zset;\n        if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            UNUSED(it); /* skip */\n        } else if (op->encoding == OBJ_ENCODING_SKIPLIST) {\n            UNUSED(it); /* skip */\n        } else {\n            serverPanic(\"Unknown sorted set encoding\");\n        }\n    } else {\n        serverPanic(\"Unsupported type\");\n    }\n}\n\nvoid zuiDiscardDirtyValue(zsetopval *val) {\n    if (val->flags & OPVAL_DIRTY_SDS) {\n        sdsfree(val->ele);\n        val->ele = NULL;\n        val->flags &= ~OPVAL_DIRTY_SDS;\n    }\n}\n\nunsigned long zuiLength(zsetopsrc *op) {\n    if (op->subject == NULL)\n        return 0;\n\n    if (op->type == OBJ_SET) {\n        return setTypeSize(op->subject);\n    } else if (op->type == OBJ_ZSET) {\n        if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            return zzlLength(op->subject->ptr);\n        } else if (op->encoding == OBJ_ENCODING_SKIPLIST) {\n            zset *zs = op->subject->ptr;\n            return zs->zsl->length;\n        } else {\n            serverPanic(\"Unknown sorted set encoding\");\n        }\n    } else {\n        serverPanic(\"Unsupported type\");\n    }\n}\n\n/* Check if the current value is valid. If so, store it in the passed structure\n * and move to the next element. If not valid, this means we have reached the\n * end of the structure and can abort. */\nint zuiNext(zsetopsrc *op, zsetopval *val) {\n    if (op->subject == NULL)\n        return 0;\n\n    zuiDiscardDirtyValue(val);\n\n    memset(val,0,sizeof(zsetopval));\n\n    if (op->type == OBJ_SET) {\n        iterset *it = &op->iter.set;\n        if (op->encoding == OBJ_ENCODING_INTSET) {\n            int64_t ell;\n\n            if (!intsetGet(it->is.is,it->is.ii,&ell))\n                return 0;\n            val->ell = ell;\n            val->score = 1.0;\n\n            /* Move to next element. */\n            it->is.ii++;\n        } else if (op->encoding == OBJ_ENCODING_HT) {\n            if (it->ht.de == NULL)\n                return 0;\n            val->ele = dictGetKey(it->ht.de);\n            val->score = 1.0;\n\n            /* Move to next element. */\n            it->ht.de = dictNext(it->ht.di);\n        } else if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            if (it->lp.p == NULL)\n                return 0;\n            val->estr = lpGetValue(it->lp.p, &val->elen, &val->ell);\n            val->score = 1.0;\n\n            /* Move to next element. */\n            it->lp.p = lpNext(it->lp.lp, it->lp.p);\n        } else {\n            serverPanic(\"Unknown set encoding\");\n        }\n    } else if (op->type == OBJ_ZSET) {\n        iterzset *it = &op->iter.zset;\n        if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            /* No need to check both, but better be explicit. */\n            if (it->zl.eptr == NULL || it->zl.sptr == NULL)\n                return 0;\n            val->estr = lpGetValue(it->zl.eptr,&val->elen,&val->ell);\n            val->score = zzlGetScore(it->zl.sptr);\n\n            /* Move to next element (going backwards, see zuiInitIterator). */\n            zzlPrev(it->zl.zl,&it->zl.eptr,&it->zl.sptr);\n        } else if (op->encoding == OBJ_ENCODING_SKIPLIST) {\n            if (it->sl.node == NULL)\n                return 0;\n            val->ele = it->sl.node->ele;\n            val->score = it->sl.node->score;\n\n            /* Move to next element. (going backwards, see zuiInitIterator) */\n            it->sl.node = it->sl.node->backward;\n        } else {\n            serverPanic(\"Unknown sorted set encoding\");\n        }\n    } else {\n        serverPanic(\"Unsupported type\");\n    }\n    return 1;\n}\n\nint zuiLongLongFromValue(zsetopval *val) {\n    if (!(val->flags & OPVAL_DIRTY_LL)) {\n        val->flags |= OPVAL_DIRTY_LL;\n\n        if (val->ele != NULL) {\n            if (string2ll(val->ele,sdslen(val->ele),&val->ell))\n                val->flags |= OPVAL_VALID_LL;\n        } else if (val->estr != NULL) {\n            if (string2ll((char*)val->estr,val->elen,&val->ell))\n                val->flags |= OPVAL_VALID_LL;\n        } else {\n            /* The long long was already set, flag as valid. */\n            val->flags |= OPVAL_VALID_LL;\n        }\n    }\n    return val->flags & OPVAL_VALID_LL;\n}\n\nsds zuiSdsFromValue(zsetopval *val) {\n    if (val->ele == NULL) {\n        if (val->estr != NULL) {\n            val->ele = sdsnewlen((char*)val->estr,val->elen);\n        } else {\n            val->ele = sdsfromlonglong(val->ell);\n        }\n        val->flags |= OPVAL_DIRTY_SDS;\n    }\n    return val->ele;\n}\n\n/* This is different from zuiSdsFromValue since returns a new SDS string\n * which is up to the caller to free. */\nsds zuiNewSdsFromValue(zsetopval *val) {\n    if (val->flags & OPVAL_DIRTY_SDS) {\n        /* We have already one to return! */\n        sds ele = val->ele;\n        val->flags &= ~OPVAL_DIRTY_SDS;\n        val->ele = NULL;\n        return ele;\n    } else if (val->ele) {\n        return sdsdup(val->ele);\n    } else if (val->estr) {\n        return sdsnewlen((char*)val->estr,val->elen);\n    } else {\n        return sdsfromlonglong(val->ell);\n    }\n}\n\nint zuiBufferFromValue(zsetopval *val) {\n    if (val->estr == NULL) {\n        if (val->ele != NULL) {\n            val->elen = sdslen(val->ele);\n            val->estr = (unsigned char*)val->ele;\n        } else {\n            val->elen = ll2string((char*)val->_buf,sizeof(val->_buf),val->ell);\n            val->estr = val->_buf;\n        }\n    }\n    return 1;\n}\n\n/* Find value pointed to by val in the source pointer to by op. When found,\n * return 1 and store its score in target. Return 0 otherwise. */\nint zuiFind(zsetopsrc *op, zsetopval *val, double *score) {\n    if (op->subject == NULL)\n        return 0;\n\n    if (op->type == OBJ_SET) {\n        char *str = val->ele ? val->ele : (char *)val->estr;\n        size_t len = val->ele ? sdslen(val->ele) : val->elen;\n        if (setTypeIsMemberAux(op->subject, str, len, val->ell, val->ele != NULL)) {\n            *score = 1.0;\n            return 1;\n        } else {\n            return 0;\n        }\n    } else if (op->type == OBJ_ZSET) {\n        zuiSdsFromValue(val);\n\n        if (op->encoding == OBJ_ENCODING_LISTPACK) {\n            if (zzlFind(op->subject->ptr,val->ele,score) != NULL) {\n                /* Score is already set by zzlFind. */\n                return 1;\n            } else {\n                return 0;\n            }\n        } else if (op->encoding == OBJ_ENCODING_SKIPLIST) {\n            zset *zs = op->subject->ptr;\n            dictEntry *de;\n            if ((de = dictFind(zs->dict,val->ele)) != NULL) {\n                *score = *(double*)dictGetVal(de);\n                return 1;\n            } else {\n                return 0;\n            }\n        } else {\n            serverPanic(\"Unknown sorted set encoding\");\n        }\n    } else {\n        serverPanic(\"Unsupported type\");\n    }\n}\n\nint zuiCompareByCardinality(const void *s1, const void *s2) {\n    unsigned long first = zuiLength((zsetopsrc*)s1);\n    unsigned long second = zuiLength((zsetopsrc*)s2);\n    if (first > second) return 1;\n    if (first < second) return -1;\n    return 0;\n}\n\nstatic int zuiCompareByRevCardinality(const void *s1, const void *s2) {\n    return zuiCompareByCardinality(s1, s2) * -1;\n}\n\n#define REDIS_AGGR_SUM 1\n#define REDIS_AGGR_MIN 2\n#define REDIS_AGGR_MAX 3\n#define zunionInterDictValue(_e) (dictGetVal(_e) == NULL ? 1.0 : *(double*)dictGetVal(_e))\n\ninline static void zunionInterAggregate(double *target, double val, int aggregate) {\n    if (aggregate == REDIS_AGGR_SUM) {\n        *target = *target + val;\n        /* The result of adding two doubles is NaN when one variable\n         * is +inf and the other is -inf. When these numbers are added,\n         * we maintain the convention of the result being 0.0. */\n        if (isnan(*target)) *target = 0.0;\n    } else if (aggregate == REDIS_AGGR_MIN) {\n        *target = val < *target ? val : *target;\n    } else if (aggregate == REDIS_AGGR_MAX) {\n        *target = val > *target ? val : *target;\n    } else {\n        /* safety net */\n        serverPanic(\"Unknown ZUNION/INTER aggregate type\");\n    }\n}\n\nstatic size_t zsetDictGetMaxElementLength(dict *d, size_t *totallen) {\n    dictIterator *di;\n    dictEntry *de;\n    size_t maxelelen = 0;\n\n    di = dictGetIterator(d);\n\n    while((de = dictNext(di)) != NULL) {\n        sds ele = dictGetKey(de);\n        if (sdslen(ele) > maxelelen) maxelelen = sdslen(ele);\n        if (totallen)\n            (*totallen) += sdslen(ele);\n    }\n\n    dictReleaseIterator(di);\n\n    return maxelelen;\n}\n\nstatic void zdiffAlgorithm1(zsetopsrc *src, long setnum, zset *dstzset, size_t *maxelelen, size_t *totelelen) {\n    /* DIFF Algorithm 1:\n     *\n     * We perform the diff by iterating all the elements of the first set,\n     * and only adding it to the target set if the element does not exist\n     * into all the other sets.\n     *\n     * This way we perform at max N*M operations, where N is the size of\n     * the first set, and M the number of sets.\n     *\n     * There is also a O(K*log(K)) cost for adding the resulting elements\n     * to the target set, where K is the final size of the target set.\n     *\n     * The final complexity of this algorithm is O(N*M + K*log(K)). */\n    int j;\n    zsetopval zval;\n    zskiplistNode *znode;\n    sds tmp;\n\n    /* With algorithm 1 it is better to order the sets to subtract\n     * by decreasing size, so that we are more likely to find\n     * duplicated elements ASAP. */\n    qsort(src+1,setnum-1,sizeof(zsetopsrc),zuiCompareByRevCardinality);\n\n    memset(&zval, 0, sizeof(zval));\n    zuiInitIterator(&src[0]);\n    while (zuiNext(&src[0],&zval)) {\n        double value;\n        int exists = 0;\n\n        for (j = 1; j < setnum; j++) {\n            /* It is not safe to access the zset we are\n             * iterating, so explicitly check for equal object.\n             * This check isn't really needed anymore since we already\n             * check for a duplicate set in the zsetChooseDiffAlgorithm\n             * function, but we're leaving it for future-proofing. */\n            if (src[j].subject == src[0].subject ||\n                zuiFind(&src[j],&zval,&value)) {\n                exists = 1;\n                break;\n            }\n        }\n\n        if (!exists) {\n            tmp = zuiNewSdsFromValue(&zval);\n            znode = zslInsert(dstzset->zsl,zval.score,tmp);\n            dictAdd(dstzset->dict,tmp,&znode->score);\n            if (sdslen(tmp) > *maxelelen) *maxelelen = sdslen(tmp);\n            (*totelelen) += sdslen(tmp);\n        }\n    }\n    zuiClearIterator(&src[0]);\n}\n\n\nstatic void zdiffAlgorithm2(zsetopsrc *src, long setnum, zset *dstzset, size_t *maxelelen, size_t *totelelen) {\n    /* DIFF Algorithm 2:\n     *\n     * Add all the elements of the first set to the auxiliary set.\n     * Then remove all the elements of all the next sets from it.\n     *\n\n     * This is O(L + (N-K)log(N)) where L is the sum of all the elements in every\n     * set, N is the size of the first set, and K is the size of the result set.\n     *\n     * Note that from the (L-N) dict searches, (N-K) got to the zsetRemoveFromSkiplist\n     * which costs log(N)\n     *\n     * There is also a O(K) cost at the end for finding the largest element\n     * size, but this doesn't change the algorithm complexity since K < L, and\n     * O(2L) is the same as O(L). */\n    int j;\n    int cardinality = 0;\n    zsetopval zval;\n    zskiplistNode *znode;\n    sds tmp;\n\n    for (j = 0; j < setnum; j++) {\n        if (zuiLength(&src[j]) == 0) continue;\n\n        memset(&zval, 0, sizeof(zval));\n        zuiInitIterator(&src[j]);\n        while (zuiNext(&src[j],&zval)) {\n            if (j == 0) {\n                tmp = zuiNewSdsFromValue(&zval);\n                znode = zslInsert(dstzset->zsl,zval.score,tmp);\n                dictAdd(dstzset->dict,tmp,&znode->score);\n                cardinality++;\n            } else {\n                dictPauseAutoResize(dstzset->dict);\n                tmp = zuiSdsFromValue(&zval);\n                if (zsetRemoveFromSkiplist(dstzset, tmp)) {\n                    cardinality--;\n                }\n                dictResumeAutoResize(dstzset->dict);\n            }\n\n            /* Exit if result set is empty as any additional removal\n                * of elements will have no effect. */\n            if (cardinality == 0) break;\n        }\n        zuiClearIterator(&src[j]);\n\n        if (cardinality == 0) break;\n    }\n\n    /* Resize dict if needed after removing multiple elements */\n    dictShrinkIfNeeded(dstzset->dict);\n\n    /* Using this algorithm, we can't calculate the max element as we go,\n     * we have to iterate through all elements to find the max one after. */\n    *maxelelen = zsetDictGetMaxElementLength(dstzset->dict, totelelen);\n}\n\nstatic int zsetChooseDiffAlgorithm(zsetopsrc *src, long setnum) {\n    int j;\n\n    /* Select what DIFF algorithm to use.\n     *\n     * Algorithm 1 is O(N*M + K*log(K)) where N is the size of the\n     * first set, M the total number of sets, and K is the size of the\n     * result set.\n     *\n     * Algorithm 2 is O(L + (N-K)log(N)) where L is the total number of elements\n     * in all the sets, N is the size of the first set, and K is the size of the\n     * result set.\n     *\n     * We compute what is the best bet with the current input here. */\n    long long algo_one_work = 0;\n    long long algo_two_work = 0;\n\n    for (j = 0; j < setnum; j++) {\n        /* If any other set is equal to the first set, there is nothing to be\n         * done, since we would remove all elements anyway. */\n        if (j > 0 && src[0].subject == src[j].subject) {\n            return 0;\n        }\n\n        algo_one_work += zuiLength(&src[0]);\n        algo_two_work += zuiLength(&src[j]);\n    }\n\n    /* Algorithm 1 has better constant times and performs less operations\n     * if there are elements in common. Give it some advantage. */\n    algo_one_work /= 2;\n    return (algo_one_work <= algo_two_work) ? 1 : 2;\n}\n\nstatic void zdiff(zsetopsrc *src, long setnum, zset *dstzset, size_t *maxelelen, size_t *totelelen) {\n    /* Skip everything if the smallest input is empty. */\n    if (zuiLength(&src[0]) > 0) {\n        int diff_algo = zsetChooseDiffAlgorithm(src, setnum);\n        if (diff_algo == 1) {\n            zdiffAlgorithm1(src, setnum, dstzset, maxelelen, totelelen);\n        } else if (diff_algo == 2) {\n            zdiffAlgorithm2(src, setnum, dstzset, maxelelen, totelelen);\n        } else if (diff_algo != 0) {\n            serverPanic(\"Unknown algorithm\");\n        }\n    }\n}\n\ndictType setAccumulatorDictType = {\n"}], "code": "void zsetTypeMaybeConvert(robj *zobj, size_t size_hint) {\n    if (zobj->encoding == OBJ_ENCODING_LISTPACK &&\n        size_hint > server.zset_max_listpack_entries)\n    {\n        zsetConvertAndExpand(zobj, OBJ_ENCODING_SKIPLIST, size_hint);\n    }\n}\n"}, "60BC84F411EBEAB3": {"calls": [{"id": "13695E64B2B66218", "name": "kvstoreGetDict", "path": "redis/src/kvstore.c", "start": {"line": 91, "col": 1}, "end": {"line": 93, "col": 1}, "code": "    return kvs->dicts[didx];\n}\n\n/* Returns total (cumulative) number of keys up until given dict-index (inclusive).\n * Time complexity is O(log(kvs->num_dicts)). */\nstatic unsigned long long cumulativeKeyCountRead(kvstore *kvs, int didx) {\n    if (kvs->num_dicts == 1) {\n        assert(didx == 0);\n        return kvstoreSize(kvs);\n    }\n    int idx = didx + 1;\n    unsigned long long sum = 0;\n    while (idx > 0) {\n        sum += kvs->dict_size_index[idx];\n        idx -= (idx & -idx);\n    }\n    return sum;\n}\n\nstatic void addDictIndexToCursor(kvstore *kvs, int didx, unsigned long long *cursor) {\n    if (kvs->num_dicts == 1)\n        return;\n    /* didx can be -1 when iteration is over and there are no more dicts to visit. */\n    if (didx < 0)\n        return;\n    *cursor = (*cursor << kvs->num_dicts_bits) | didx;\n}\n\nstatic int getAndClearDictIndexFromCursor(kvstore *kvs, unsigned long long *cursor) {\n    if (kvs->num_dicts == 1)\n        return 0;\n    int didx = (int) (*cursor & (kvs->num_dicts-1));\n    *cursor = *cursor >> kvs->num_dicts_bits;\n    return didx;\n}\n\n/* Updates binary index tree (also known as Fenwick tree), increasing key count for a given dict.\n * You can read more about this data structure here https://en.wikipedia.org/wiki/Fenwick_tree\n * Time complexity is O(log(kvs->num_dicts)). */\nstatic void cumulativeKeyCountAdd(kvstore *kvs, int didx, long delta) {\n    kvs->key_count += delta;\n\n    dict *d = kvstoreGetDict(kvs, didx);\n    size_t dsize = dictSize(d);\n    int non_empty_dicts_delta = dsize == 1? 1 : dsize == 0? -1 : 0;\n    kvs->non_empty_dicts += non_empty_dicts_delta;\n\n    /* BIT does not need to be calculated when there's only one dict. */\n    if (kvs->num_dicts == 1)\n        return;\n\n    /* Update the BIT */\n    int idx = didx + 1; /* Unlike dict indices, BIT is 1-based, so we need to add 1. */\n    while (idx <= kvs->num_dicts) {\n        if (delta < 0) {\n            assert(kvs->dict_size_index[idx] >= (unsigned long long)labs(delta));\n        }\n        kvs->dict_size_index[idx] += delta;\n        idx += (idx & -idx);\n    }\n}\n\nstatic void createDictIfNeeded(kvstore *kvs, int didx) {\n    if (kvstoreGetDict(kvs, didx))\n        return;\n    kvs->dicts[didx] = dictCreate(&kvs->dtype);\n    kvs->allocated_dicts++;\n}\n\nstatic void freeDictIfNeeded(kvstore *kvs, int didx) {\n    if (!(kvs->flags & KVSTORE_FREE_EMPTY_DICTS) ||\n        !kvstoreGetDict(kvs, didx) ||\n        kvstoreDictSize(kvs, didx) != 0)\n        return;\n    dictRelease(kvs->dicts[didx]);\n    kvs->dicts[didx] = NULL;\n    kvs->allocated_dicts--;\n}\n\n/**********************************/\n/*** dict callbacks ***************/\n/**********************************/\n\n/* Adds dictionary to the rehashing list, which allows us\n * to quickly find rehash targets during incremental rehashing.\n *\n * If there are multiple dicts, updates the bucket count for the given dictionary\n * in a DB, bucket count incremented with the new ht size during the rehashing phase.\n * If there's one dict, bucket count can be retrieved directly from single dict bucket. */\nstatic void kvstoreDictRehashingStarted(dict *d) {\n    kvstore *kvs = d->type->userdata;\n    kvstoreDictMetadata *metadata = (kvstoreDictMetadata *)dictMetadata(d);\n    listAddNodeTail(kvs->rehashing, d);\n    metadata->rehashing_node = listLast(kvs->rehashing);\n"}, {"id": "C19B40F28C46C433", "name": "skip_cb", "path": "redis/src/kvstore.c", "start": {"line": 404, "col": 101}, "end": {"line": 404, "col": 101}, "code": "    for (int i = 0; i < kvs->num_dicts; i++) {\n        dict *d = kvstoreGetDict(kvs, i);\n        if (!d || (skip_cb && skip_cb(i)))\n            continue;\n        int result = try_expand ? dictTryExpand(d, newsize) : dictExpand(d, newsize);\n        if (try_expand && result == DICT_ERR)\n            return 0;\n    }\n\n    return 1;\n}\n\n/* Returns fair random dict index, probability of each dict being returned is proportional to the number of elements that dictionary holds.\n * This function guarantees that it returns a dict-index of a non-empty dict, unless the entire kvstore is empty.\n * Time complexity of this function is O(log(kvs->num_dicts)). */\nint kvstoreGetFairRandomDictIndex(kvstore *kvs) {\n    unsigned long target = kvstoreSize(kvs) ? (randomULong() % kvstoreSize(kvs)) + 1 : 0;\n    return kvstoreFindDictIndexByKeyIndex(kvs, target);\n}\n\nvoid kvstoreGetStats(kvstore *kvs, char *buf, size_t bufsize, int full) {\n    buf[0] = '\\0';\n\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n    dictStats *mainHtStats = NULL;\n    dictStats *rehashHtStats = NULL;\n    dict *d;\n    kvstoreIterator *kvs_it = kvstoreIteratorInit(kvs);\n    while ((d = kvstoreIteratorNextDict(kvs_it))) {\n        dictStats *stats = dictGetStatsHt(d, 0, full);\n        if (!mainHtStats) {\n            mainHtStats = stats;\n        } else {\n            dictCombineStats(stats, mainHtStats);\n            dictFreeStats(stats);\n        }\n        if (dictIsRehashing(d)) {\n            stats = dictGetStatsHt(d, 1, full);\n            if (!rehashHtStats) {\n                rehashHtStats = stats;\n            } else {\n                dictCombineStats(stats, rehashHtStats);\n                dictFreeStats(stats);\n            }\n        }\n    }\n    kvstoreIteratorRelease(kvs_it);\n\n    if (mainHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n        dictFreeStats(mainHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n\n    if (rehashHtStats && bufsize > 0) {\n        l = dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n        buf += l;\n        bufsize -= l;\n    }\n    /* Make sure there is a NULL term at the end. */\n    if (orig_bufsize) orig_buf[orig_bufsize - 1] = '\\0';\n}\n\n/* Finds a dict containing target element in a key space ordered by dict index.\n * Consider this example. Dictionaries are represented by brackets and keys by dots:\n *  #0   #1   #2     #3    #4\n * [..][....][...][.......][.]\n *                    ^\n *                 target\n *\n * In this case dict #3 contains key that we are trying to find.\n *\n * The return value is 0 based dict-index, and the range of the target is [1..kvstoreSize], kvstoreSize inclusive.\n *\n * To find the dict, we start with the root node of the binary index tree and search through its children\n * from the highest index (2^num_dicts_bits in our case) to the lowest index. At each node, we check if the target\n * value is greater than the node's value. If it is, we remove the node's value from the target and recursively\n * search for the new target using the current node as the parent.\n * Time complexity of this function is O(log(kvs->num_dicts))\n */\nint kvstoreFindDictIndexByKeyIndex(kvstore *kvs, unsigned long target) {\n    if (kvs->num_dicts == 1 || kvstoreSize(kvs) == 0)\n        return 0;\n    assert(target <= kvstoreSize(kvs));\n\n    int result = 0, bit_mask = 1 << kvs->num_dicts_bits;\n    for (int i = bit_mask; i != 0; i >>= 1) {\n        int current = result + i;\n        /* When the target index is greater than 'current' node value the we will update\n         * the target and search in the 'current' node tree. */\n        if (target > kvs->dict_size_index[current]) {\n            target -= kvs->dict_size_index[current];\n            result = current;\n        }\n    }\n    /* Adjust the result to get the correct dict:\n     * 1. result += 1;\n     *    After the calculations, the index of target in dict_size_index should be the next one,\n     *    so we should add 1.\n     * 2. result -= 1;\n     *    Unlike BIT(dict_size_index is 1-based), dict indices are 0-based, so we need to subtract 1.\n     * As the addition and subtraction cancel each other out, we can simply return the result. */\n    return result;\n}\n\n/* Returns next non-empty dict index strictly after given one, or -1 if provided didx is the last one. */\nint kvstoreGetNextNonEmptyDictIndex(kvstore *kvs, int didx) {\n    unsigned long long next_key = cumulativeKeyCountRead(kvs, didx) + 1;\n    return next_key <= kvstoreSize(kvs) ? kvstoreFindDictIndexByKeyIndex(kvs, next_key) : -1;\n}\n\nint kvstoreNumNonEmptyDicts(kvstore *kvs) {\n    return kvs->non_empty_dicts;\n}\n\nint kvstoreNumDicts(kvstore *kvs) {\n    return kvs->num_dicts;\n}\n\n/* Returns kvstore iterator that can be used to iterate through sub-dictionaries.\n *\n * The caller should free the resulting kvs_it with kvstoreIteratorRelease. */\nkvstoreIterator *kvstoreIteratorInit(kvstore *kvs) {\n    kvstoreIterator *kvs_it = zmalloc(sizeof(*kvs_it));\n    kvs_it->kvs = kvs;\n    kvs_it->didx = -1;\n    kvs_it->next_didx = kvstoreFindDictIndexByKeyIndex(kvs_it->kvs, 1); /* Finds first non-empty dict index. */\n    dictInitSafeIterator(&kvs_it->di, NULL);\n    return kvs_it;\n}\n\n/* Free the kvs_it returned by kvstoreIteratorInit. */\nvoid kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n\n/* Returns next dictionary from the iterator, or NULL if iteration is complete. */\ndict *kvstoreIteratorNextDict(kvstoreIterator *kvs_it) {\n    if (kvs_it->next_didx == -1)\n        return NULL;\n    kvs_it->didx = kvs_it->next_didx;\n    kvs_it->next_didx = kvstoreGetNextNonEmptyDictIndex(kvs_it->kvs, kvs_it->didx);\n    return kvs_it->kvs->dicts[kvs_it->didx];\n}\n\nint kvstoreIteratorGetCurrentDictIndex(kvstoreIterator *kvs_it) {\n    assert(kvs_it->didx >= 0 && kvs_it->didx < kvs_it->kvs->num_dicts);\n    return kvs_it->didx;\n}\n\n/* Returns next entry. */\ndictEntry *kvstoreIteratorNext(kvstoreIterator *kvs_it) {\n    dictEntry *de = kvs_it->di.d ? dictNext(&kvs_it->di) : NULL;\n    if (!de) { /* No current dict or reached the end of the dictionary. */\n        dict *d = kvstoreIteratorNextDict(kvs_it);\n        if (!d)\n            return NULL;\n        if (kvs_it->di.d) {\n            /* Before we move to the next dict, reset the iter of the previous dict. */\n            dictIterator *iter = &kvs_it->di;\n            dictResetIterator(iter);\n        }\n        dictInitSafeIterator(&kvs_it->di, d);\n        de = dictNext(&kvs_it->di);\n    }\n    return de;\n}\n\n/* This method traverses through kvstore dictionaries and triggers a resize .\n * It first tries to shrink if needed, and if it isn't, it tries to expand. */\nvoid kvstoreTryResizeDicts(kvstore *kvs, int limit) {\n    if (limit > kvs->num_dicts)\n        limit = kvs->num_dicts;\n\n    for (int i = 0; i < limit; i++) {\n        int didx = kvs->resize_cursor;\n        dict *d = kvstoreGetDict(kvs, didx);\n        if (d && dictShrinkIfNeeded(d) == DICT_ERR) {\n            dictExpandIfNeeded(d);\n        }\n        kvs->resize_cursor = (didx + 1) % kvs->num_dicts;\n    }\n}\n\n/* Our hash table implementation performs rehashing incrementally while\n * we write/read from the hash table. Still if the server is idle, the hash\n * table will use two tables for a long time. So we try to use 1 millisecond\n * of CPU time at every call of this function to perform some rehashing.\n *\n * The function returns the amount of microsecs spent if some rehashing was\n * performed, otherwise 0 is returned. */\nuint64_t kvstoreIncrementallyRehash(kvstore *kvs, uint64_t threshold_us) {\n    if (listLength(kvs->rehashing) == 0)\n        return 0;\n\n    /* Our goal is to rehash as many dictionaries as we can before reaching predefined threshold,\n     * after each dictionary completes rehashing, it removes itself from the list. */\n    listNode *node;\n    monotime timer;\n    uint64_t elapsed_us = UINT64_MAX;\n    elapsedStart(&timer);\n    while ((node = listFirst(kvs->rehashing))) {\n        elapsed_us = elapsedUs(timer);\n        if (elapsed_us >= threshold_us) {\n            break;  /* Reached the time limit. */\n        }\n        dictRehashMicroseconds(listNodeValue(node), threshold_us - elapsed_us);\n    }\n    assert(elapsed_us != UINT64_MAX);\n    return elapsed_us;\n}\n\nunsigned long kvstoreDictSize(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictSize(d);\n}\n\nkvstoreDictIterator *kvstoreGetDictIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\nkvstoreDictIterator *kvstoreGetDictSafeIterator(kvstore *kvs, int didx)\n{\n    kvstoreDictIterator *kvs_di = zmalloc(sizeof(*kvs_di));\n    kvs_di->kvs = kvs;\n    kvs_di->didx = didx;\n    dictInitSafeIterator(&kvs_di->di, kvstoreGetDict(kvs, didx));\n    return kvs_di;\n}\n\n/* Free the kvs_di returned by kvstoreGetDictIterator and kvstoreGetDictSafeIterator. */\nvoid kvstoreReleaseDictIterator(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    if (kvstoreGetDict(kvs_di->kvs, kvs_di->didx)) dictResetIterator(&kvs_di->di);\n\n    zfree(kvs_di);\n}\n\n/* Get the next element of the dict through kvstoreDictIterator and dictNext. */\ndictEntry *kvstoreDictIteratorNext(kvstoreDictIterator *kvs_di)\n{\n    /* The dict may be deleted during the iteration process, so here need to check for NULL. */\n    dict *d = kvstoreGetDict(kvs_di->kvs, kvs_di->didx);\n    if (!d) return NULL;\n\n    return dictNext(&kvs_di->di);\n}\n\ndictEntry *kvstoreDictGetRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetRandomKey(d);\n}\n\ndictEntry *kvstoreDictGetFairRandomKey(kvstore *kvs, int didx)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictGetFairRandomKey(d);\n}\n\ndictEntry *kvstoreDictFindEntryByPtrAndHash(kvstore *kvs, int didx, const void *oldptr, uint64_t hash)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFindEntryByPtrAndHash(d, oldptr, hash);\n}\n\nunsigned int kvstoreDictGetSomeKeys(kvstore *kvs, int didx, dictEntry **des, unsigned int count)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictGetSomeKeys(d, des, count);\n}\n\nint kvstoreDictExpand(kvstore *kvs, int didx, unsigned long size)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    return dictExpand(d, size);\n}\n\nunsigned long kvstoreDictScanDefrag(kvstore *kvs, int didx, unsigned long v, dictScanFunction *fn, dictDefragFunctions *defragfns, void *privdata)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return 0;\n    return dictScanDefrag(d, v, fn, defragfns, privdata);\n}\n\nuint64_t kvstoreGetHash(kvstore *kvs, const void *key)\n{\n    return kvs->dtype.hashFunction(key);\n}\n\nvoid *kvstoreDictFetchValue(kvstore *kvs, int didx, const void *key)\n{\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFetchValue(d, key);\n}\n\ndictEntry *kvstoreDictFind(kvstore *kvs, int didx, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictFind(d, key);\n}\n\ndictEntry *kvstoreDictAddRaw(kvstore *kvs, int didx, void *key, dictEntry **existing) {\n    createDictIfNeeded(kvs, didx);\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictEntry *ret = dictAddRaw(d, key, existing);\n    if (ret)\n        cumulativeKeyCountAdd(kvs, didx, 1);\n    return ret;\n}\n\nvoid kvstoreDictSetKey(kvstore *kvs, int didx, dictEntry* de, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetKey(d, de, key);\n}\n\nvoid kvstoreDictSetVal(kvstore *kvs, int didx, dictEntry *de, void *val) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}, {"id": "8AF415B62FB4C87E", "name": "dictTryExpand", "path": "redis/src/dict.c", "start": {"line": 283, "col": 1}, "end": {"line": 287, "col": 1}, "code": "    int malloc_failed = 0;\n    _dictExpand(d, size, &malloc_failed);\n    return malloc_failed? DICT_ERR : DICT_OK;\n}\n\n/* return DICT_ERR if shrink was not performed */\nint dictShrink(dict *d, unsigned long size) {\n    /* the size is invalid if it is bigger than the size of the hash table\n     * or smaller than the number of elements already inside the hash table */\n    if (dictIsRehashing(d) || d->ht_used[0] > size || DICTHT_SIZE(d->ht_size_exp[0]) <= size)\n        return DICT_ERR;\n    return _dictResize(d, size, NULL);\n}\n\n/* Helper function for `dictRehash` and `dictBucketRehash` which rehashes all the keys\n * in a bucket at index `idx` from the old to the new hash HT. */\nstatic void rehashEntriesInBucketAtIndex(dict *d, uint64_t idx) {\n    dictEntry *de = d->ht_table[0][idx];\n    uint64_t h;\n    dictEntry *nextde;\n    while (de) {\n        nextde = dictGetNext(de);\n        void *key = dictGetKey(de);\n        /* Get the index in the new hash table */\n        if (d->ht_size_exp[1] > d->ht_size_exp[0]) {\n            h = dictHashKey(d, key) & DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n        } else {\n            /* We're shrinking the table. The tables sizes are powers of\n             * two, so we simply mask the bucket index in the larger table\n             * to get the bucket index in the smaller table. */\n            h = idx & DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n        }\n        if (d->type->no_value) {\n            if (d->type->keys_are_odd && !d->ht_table[1][h]) {\n                /* Destination bucket is empty and we can store the key\n                 * directly without an allocated entry. Free the old entry\n                 * if it's an allocated entry.\n                 *\n                 * TODO: Add a flag 'keys_are_even' and if set, we can use\n                 * this optimization for these dicts too. We can set the LSB\n                 * bit when stored as a dict entry and clear it again when\n                 * we need the key back. */\n                assert(entryIsKey(key));\n                if (!entryIsKey(de)) zfree(decodeMaskedPtr(de));\n                de = key;\n            } else if (entryIsKey(de)) {\n                /* We don't have an allocated entry but we need one. */\n                de = createEntryNoValue(key, d->ht_table[1][h]);\n            } else {\n                /* Just move the existing entry to the destination table and\n                 * update the 'next' field. */\n                assert(entryIsNoValue(de));\n                dictSetNext(de, d->ht_table[1][h]);\n            }\n        } else {\n            dictSetNext(de, d->ht_table[1][h]);\n        }\n        d->ht_table[1][h] = de;\n        d->ht_used[0]--;\n        d->ht_used[1]++;\n        de = nextde;\n    }\n    d->ht_table[0][idx] = NULL;\n}\n\n/* This checks if we already rehashed the whole table and if more rehashing is required */\nstatic int dictCheckRehashingCompleted(dict *d) {\n    if (d->ht_used[0] != 0) return 0;\n    \n    if (d->type->rehashingCompleted) d->type->rehashingCompleted(d);\n    zfree(d->ht_table[0]);\n    /* Copy the new ht onto the old one */\n    d->ht_table[0] = d->ht_table[1];\n    d->ht_used[0] = d->ht_used[1];\n    d->ht_size_exp[0] = d->ht_size_exp[1];\n    _dictReset(d, 1);\n    d->rehashidx = -1;\n    return 1;\n}\n\n/* Performs N steps of incremental rehashing. Returns 1 if there are still\n * keys to move from the old to the new hash table, otherwise 0 is returned.\n *\n * Note that a rehashing step consists in moving a bucket (that may have more\n * than one key as we use chaining) from the old to the new hash table, however\n * since part of the hash table may be composed of empty spaces, it is not\n * guaranteed that this function will rehash even a single bucket, since it\n * will visit at max N*10 empty buckets in total, otherwise the amount of\n * work it does would be unbound and the function may block for a long time. */\nint dictRehash(dict *d, int n) {\n    int empty_visits = n*10; /* Max number of empty buckets to visit. */\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n\n    while(n-- && d->ht_used[0] != 0) {\n        /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(DICTHT_SIZE(d->ht_size_exp[0]) > (unsigned long)d->rehashidx);\n        while(d->ht_table[0][d->rehashidx] == NULL) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        /* Move all the keys in this bucket from the old to the new hash HT */\n        rehashEntriesInBucketAtIndex(d, d->rehashidx);\n        d->rehashidx++;\n    }\n\n    return !dictCheckRehashingCompleted(d);\n}\n\nlong long timeInMilliseconds(void) {\n    struct timeval tv;\n\n    gettimeofday(&tv,NULL);\n    return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);\n}\n\n/* Rehash in us+\"delta\" microseconds. The value of \"delta\" is larger\n * than 0, and is smaller than 1000 in most cases. The exact upper bound\n * depends on the running time of dictRehash(d,100).*/\nint dictRehashMicroseconds(dict *d, uint64_t us) {\n    if (d->pauserehash > 0) return 0;\n\n    monotime timer;\n    elapsedStart(&timer);\n    int rehashes = 0;\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (elapsedUs(timer) >= us) break;\n    }\n    return rehashes;\n}\n\n/* This function performs just a step of rehashing, and only if hashing has\n * not been paused for our hash table. When we have iterators in the\n * middle of a rehashing we can't mess with the two hash tables otherwise\n * some elements can be missed or duplicated.\n *\n * This function is called by common lookup or update operations in the\n * dictionary so that the hash table automatically migrates from H1 to H2\n * while it is actively used. */\nstatic void _dictRehashStep(dict *d) {\n    if (d->pauserehash == 0) dictRehash(d,1);\n}\n\n/* Performs rehashing on a single bucket. */\nint _dictBucketRehash(dict *d, uint64_t idx) {\n    if (d->pauserehash != 0) return 0;\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n    rehashEntriesInBucketAtIndex(d, idx);\n    dictCheckRehashingCompleted(d);\n    return 1;\n}\n\n/* Add an element to the target hash table */\nint dictAdd(dict *d, void *key, void *val)\n{\n    dictEntry *entry = dictAddRaw(d,key,NULL);\n\n    if (!entry) return DICT_ERR;\n    if (!d->type->no_value) dictSetVal(d, entry, val);\n    return DICT_OK;\n}\n\n/* Low level add or find:\n * This function adds the entry but instead of setting a value returns the\n * dictEntry structure to the user, that will make sure to fill the value\n * field as they wish.\n *\n * This function is also directly exposed to the user API to be called\n * mainly in order to store non-pointers inside the hash value, example:\n *\n * entry = dictAddRaw(dict,mykey,NULL);\n * if (entry != NULL) dictSetSignedIntegerVal(entry,1000);\n *\n * Return values:\n *\n * If key already exists NULL is returned, and \"*existing\" is populated\n * with the existing entry if existing is not NULL.\n *\n * If key was added, the hash entry is returned to be manipulated by the caller.\n */\ndictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)\n{\n    /* Get the position for the new key or NULL if the key already exists. */\n    void *position = dictFindPositionForInsert(d, key, existing);\n    if (!position) return NULL;\n\n    /* Dup the key if necessary. */\n    if (d->type->keyDup) key = d->type->keyDup(d, key);\n\n    return dictInsertAtPosition(d, key, position);\n}\n\n/* Adds a key in the dict's hashtable at the position returned by a preceding\n * call to dictFindPositionForInsert. This is a low level function which allows\n * splitting dictAddRaw in two parts. Normally, dictAddRaw or dictAdd should be\n * used instead. */\ndictEntry *dictInsertAtPosition(dict *d, void *key, void *position) {\n    dictEntry **bucket = position; /* It's a bucket, but the API hides that. */\n    dictEntry *entry;\n    /* If rehashing is ongoing, we insert in table 1, otherwise in table 0.\n     * Assert that the provided bucket is the right table. */\n    int htidx = dictIsRehashing(d) ? 1 : 0;\n    assert(bucket >= &d->ht_table[htidx][0] &&\n           bucket <= &d->ht_table[htidx][DICTHT_SIZE_MASK(d->ht_size_exp[htidx])]);\n    if (d->type->no_value) {\n        if (d->type->keys_are_odd && !*bucket) {\n            /* We can store the key directly in the destination bucket without the\n             * allocated entry.\n             *\n             * TODO: Add a flag 'keys_are_even' and if set, we can use this\n             * optimization for these dicts too. We can set the LSB bit when\n             * stored as a dict entry and clear it again when we need the key\n             * back. */\n            entry = key;\n            assert(entryIsKey(entry));\n        } else {\n            /* Allocate an entry without value. */\n            entry = createEntryNoValue(key, *bucket);\n        }\n    } else {\n        /* Allocate the memory and store the new entry.\n         * Insert the element in top, with the assumption that in a database\n         * system it is more likely that recently added entries are accessed\n         * more frequently. */\n        entry = zmalloc(sizeof(*entry));\n        assert(entryIsNormal(entry)); /* Check alignment of allocation */\n        entry->key = key;\n        entry->next = *bucket;\n    }\n    *bucket = entry;\n    d->ht_used[htidx]++;\n\n    return entry;\n}\n\n/* Add or Overwrite:\n * Add an element, discarding the old value if the key already exists.\n * Return 1 if the key was added from scratch, 0 if there was already an\n * element with such key and dictReplace() just performed a value update\n * operation. */\nint dictReplace(dict *d, void *key, void *val)\n{\n    dictEntry *entry, *existing;\n\n    /* Try to add the element. If the key\n     * does not exists dictAdd will succeed. */\n    entry = dictAddRaw(d,key,&existing);\n    if (entry) {\n        dictSetVal(d, entry, val);\n        return 1;\n    }\n\n    /* Set the new value and free the old one. Note that it is important\n     * to do that in this order, as the value may just be exactly the same\n     * as the previous one. In this context, think to reference counting,\n     * you want to increment (set), and then decrement (free), and not the\n     * reverse. */\n    void *oldval = dictGetVal(existing);\n    dictSetVal(d, existing, val);\n    if (d->type->valDestructor)\n        d->type->valDestructor(d, oldval);\n    return 0;\n}\n\n"}, {"id": "7433E960CFCC64DF", "name": "dictExpand", "path": "redis/src/dict.c", "start": {"line": 278, "col": 1}, "end": {"line": 280, "col": 1}, "code": "    return _dictExpand(d, size, NULL);\n}\n\n/* return DICT_ERR if expand failed due to memory allocation failure */\nint dictTryExpand(dict *d, unsigned long size) {\n    int malloc_failed = 0;\n    _dictExpand(d, size, &malloc_failed);\n    return malloc_failed? DICT_ERR : DICT_OK;\n}\n\n/* return DICT_ERR if shrink was not performed */\nint dictShrink(dict *d, unsigned long size) {\n    /* the size is invalid if it is bigger than the size of the hash table\n     * or smaller than the number of elements already inside the hash table */\n    if (dictIsRehashing(d) || d->ht_used[0] > size || DICTHT_SIZE(d->ht_size_exp[0]) <= size)\n        return DICT_ERR;\n    return _dictResize(d, size, NULL);\n}\n\n/* Helper function for `dictRehash` and `dictBucketRehash` which rehashes all the keys\n * in a bucket at index `idx` from the old to the new hash HT. */\nstatic void rehashEntriesInBucketAtIndex(dict *d, uint64_t idx) {\n    dictEntry *de = d->ht_table[0][idx];\n    uint64_t h;\n    dictEntry *nextde;\n    while (de) {\n        nextde = dictGetNext(de);\n        void *key = dictGetKey(de);\n        /* Get the index in the new hash table */\n        if (d->ht_size_exp[1] > d->ht_size_exp[0]) {\n            h = dictHashKey(d, key) & DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n        } else {\n            /* We're shrinking the table. The tables sizes are powers of\n             * two, so we simply mask the bucket index in the larger table\n             * to get the bucket index in the smaller table. */\n            h = idx & DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n        }\n        if (d->type->no_value) {\n            if (d->type->keys_are_odd && !d->ht_table[1][h]) {\n                /* Destination bucket is empty and we can store the key\n                 * directly without an allocated entry. Free the old entry\n                 * if it's an allocated entry.\n                 *\n                 * TODO: Add a flag 'keys_are_even' and if set, we can use\n                 * this optimization for these dicts too. We can set the LSB\n                 * bit when stored as a dict entry and clear it again when\n                 * we need the key back. */\n                assert(entryIsKey(key));\n                if (!entryIsKey(de)) zfree(decodeMaskedPtr(de));\n                de = key;\n            } else if (entryIsKey(de)) {\n                /* We don't have an allocated entry but we need one. */\n                de = createEntryNoValue(key, d->ht_table[1][h]);\n            } else {\n                /* Just move the existing entry to the destination table and\n                 * update the 'next' field. */\n                assert(entryIsNoValue(de));\n                dictSetNext(de, d->ht_table[1][h]);\n            }\n        } else {\n            dictSetNext(de, d->ht_table[1][h]);\n        }\n        d->ht_table[1][h] = de;\n        d->ht_used[0]--;\n        d->ht_used[1]++;\n        de = nextde;\n    }\n    d->ht_table[0][idx] = NULL;\n}\n\n/* This checks if we already rehashed the whole table and if more rehashing is required */\nstatic int dictCheckRehashingCompleted(dict *d) {\n    if (d->ht_used[0] != 0) return 0;\n    \n    if (d->type->rehashingCompleted) d->type->rehashingCompleted(d);\n    zfree(d->ht_table[0]);\n    /* Copy the new ht onto the old one */\n    d->ht_table[0] = d->ht_table[1];\n    d->ht_used[0] = d->ht_used[1];\n    d->ht_size_exp[0] = d->ht_size_exp[1];\n    _dictReset(d, 1);\n    d->rehashidx = -1;\n    return 1;\n}\n\n/* Performs N steps of incremental rehashing. Returns 1 if there are still\n * keys to move from the old to the new hash table, otherwise 0 is returned.\n *\n * Note that a rehashing step consists in moving a bucket (that may have more\n * than one key as we use chaining) from the old to the new hash table, however\n * since part of the hash table may be composed of empty spaces, it is not\n * guaranteed that this function will rehash even a single bucket, since it\n * will visit at max N*10 empty buckets in total, otherwise the amount of\n * work it does would be unbound and the function may block for a long time. */\nint dictRehash(dict *d, int n) {\n    int empty_visits = n*10; /* Max number of empty buckets to visit. */\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n\n    while(n-- && d->ht_used[0] != 0) {\n        /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(DICTHT_SIZE(d->ht_size_exp[0]) > (unsigned long)d->rehashidx);\n        while(d->ht_table[0][d->rehashidx] == NULL) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        /* Move all the keys in this bucket from the old to the new hash HT */\n        rehashEntriesInBucketAtIndex(d, d->rehashidx);\n        d->rehashidx++;\n    }\n\n    return !dictCheckRehashingCompleted(d);\n}\n\nlong long timeInMilliseconds(void) {\n    struct timeval tv;\n\n    gettimeofday(&tv,NULL);\n    return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);\n}\n\n/* Rehash in us+\"delta\" microseconds. The value of \"delta\" is larger\n * than 0, and is smaller than 1000 in most cases. The exact upper bound\n * depends on the running time of dictRehash(d,100).*/\nint dictRehashMicroseconds(dict *d, uint64_t us) {\n    if (d->pauserehash > 0) return 0;\n\n    monotime timer;\n    elapsedStart(&timer);\n    int rehashes = 0;\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (elapsedUs(timer) >= us) break;\n    }\n    return rehashes;\n}\n\n/* This function performs just a step of rehashing, and only if hashing has\n * not been paused for our hash table. When we have iterators in the\n * middle of a rehashing we can't mess with the two hash tables otherwise\n * some elements can be missed or duplicated.\n *\n * This function is called by common lookup or update operations in the\n * dictionary so that the hash table automatically migrates from H1 to H2\n * while it is actively used. */\nstatic void _dictRehashStep(dict *d) {\n    if (d->pauserehash == 0) dictRehash(d,1);\n}\n\n/* Performs rehashing on a single bucket. */\nint _dictBucketRehash(dict *d, uint64_t idx) {\n    if (d->pauserehash != 0) return 0;\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n    rehashEntriesInBucketAtIndex(d, idx);\n    dictCheckRehashingCompleted(d);\n    return 1;\n}\n\n/* Add an element to the target hash table */\nint dictAdd(dict *d, void *key, void *val)\n{\n    dictEntry *entry = dictAddRaw(d,key,NULL);\n\n    if (!entry) return DICT_ERR;\n    if (!d->type->no_value) dictSetVal(d, entry, val);\n    return DICT_OK;\n}\n\n/* Low level add or find:\n * This function adds the entry but instead of setting a value returns the\n * dictEntry structure to the user, that will make sure to fill the value\n * field as they wish.\n *\n * This function is also directly exposed to the user API to be called\n * mainly in order to store non-pointers inside the hash value, example:\n *\n * entry = dictAddRaw(dict,mykey,NULL);\n * if (entry != NULL) dictSetSignedIntegerVal(entry,1000);\n *\n * Return values:\n *\n * If key already exists NULL is returned, and \"*existing\" is populated\n * with the existing entry if existing is not NULL.\n *\n * If key was added, the hash entry is returned to be manipulated by the caller.\n */\ndictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)\n{\n    /* Get the position for the new key or NULL if the key already exists. */\n    void *position = dictFindPositionForInsert(d, key, existing);\n    if (!position) return NULL;\n\n    /* Dup the key if necessary. */\n    if (d->type->keyDup) key = d->type->keyDup(d, key);\n\n    return dictInsertAtPosition(d, key, position);\n}\n\n/* Adds a key in the dict's hashtable at the position returned by a preceding\n * call to dictFindPositionForInsert. This is a low level function which allows\n * splitting dictAddRaw in two parts. Normally, dictAddRaw or dictAdd should be\n * used instead. */\ndictEntry *dictInsertAtPosition(dict *d, void *key, void *position) {\n    dictEntry **bucket = position; /* It's a bucket, but the API hides that. */\n    dictEntry *entry;\n    /* If rehashing is ongoing, we insert in table 1, otherwise in table 0.\n     * Assert that the provided bucket is the right table. */\n    int htidx = dictIsRehashing(d) ? 1 : 0;\n    assert(bucket >= &d->ht_table[htidx][0] &&\n           bucket <= &d->ht_table[htidx][DICTHT_SIZE_MASK(d->ht_size_exp[htidx])]);\n    if (d->type->no_value) {\n        if (d->type->keys_are_odd && !*bucket) {\n            /* We can store the key directly in the destination bucket without the\n             * allocated entry.\n             *\n             * TODO: Add a flag 'keys_are_even' and if set, we can use this\n             * optimization for these dicts too. We can set the LSB bit when\n             * stored as a dict entry and clear it again when we need the key\n             * back. */\n            entry = key;\n            assert(entryIsKey(entry));\n        } else {\n            /* Allocate an entry without value. */\n            entry = createEntryNoValue(key, *bucket);\n        }\n    } else {\n        /* Allocate the memory and store the new entry.\n         * Insert the element in top, with the assumption that in a database\n         * system it is more likely that recently added entries are accessed\n         * more frequently. */\n        entry = zmalloc(sizeof(*entry));\n        assert(entryIsNormal(entry)); /* Check alignment of allocation */\n        entry->key = key;\n        entry->next = *bucket;\n    }\n    *bucket = entry;\n    d->ht_used[htidx]++;\n\n    return entry;\n}\n\n/* Add or Overwrite:\n * Add an element, discarding the old value if the key already exists.\n * Return 1 if the key was added from scratch, 0 if there was already an\n * element with such key and dictReplace() just performed a value update\n * operation. */\nint dictReplace(dict *d, void *key, void *val)\n{\n    dictEntry *entry, *existing;\n\n    /* Try to add the element. If the key\n     * does not exists dictAdd will succeed. */\n    entry = dictAddRaw(d,key,&existing);\n    if (entry) {\n        dictSetVal(d, entry, val);\n        return 1;\n    }\n\n"}], "code": "int kvstoreExpand(kvstore *kvs, uint64_t newsize, int try_expand, kvstoreExpandShouldSkipDictIndex *skip_cb) {\n    for (int i = 0; i < kvs->num_dicts; i++) {\n        dict *d = kvstoreGetDict(kvs, i);\n        if (!d || (skip_cb && skip_cb(i)))\n            continue;\n        int result = try_expand ? dictTryExpand(d, newsize) : dictExpand(d, newsize);\n        if (try_expand && result == DICT_ERR)\n            return 0;\n    }\n\n    return 1;\n}\n"}, "6B610D8B9F68DAE1": {"calls": [{"id": "5DB68A4C7E84B70F", "name": "overMaxmemoryAfterAlloc", "path": "redis/src/evict.c", "start": {"line": 441, "col": 1}, "end": {"line": 451, "col": 1}, "code": "    if (!server.maxmemory) return  0; /* No limit. */\n\n    /* Check quickly. */\n    size_t mem_used = zmalloc_used_memory();\n    if (mem_used + moremem <= server.maxmemory) return 0;\n\n    size_t overhead = freeMemoryGetNotCountedMemory();\n    mem_used = (mem_used > overhead) ? mem_used - overhead : 0;\n    return mem_used + moremem > server.maxmemory;\n}\n\n/* The evictionTimeProc is started when \"maxmemory\" has been breached and\n * could not immediately be resolved.  This will spin the event loop with short\n * eviction cycles until the \"maxmemory\" condition has resolved or there are no\n * more evictable items.  */\nstatic int isEvictionProcRunning = 0;\nstatic int evictionTimeProc(\n        struct aeEventLoop *eventLoop, long long id, void *clientData) {\n    UNUSED(eventLoop);\n    UNUSED(id);\n    UNUSED(clientData);\n\n    if (performEvictions() == EVICT_RUNNING) return 0;  /* keep evicting */\n\n    /* For EVICT_OK - things are good, no need to keep evicting.\n     * For EVICT_FAIL - there is nothing left to evict.  */\n    isEvictionProcRunning = 0;\n    return AE_NOMORE;\n}\n\nvoid startEvictionTimeProc(void) {\n    if (!isEvictionProcRunning) {\n        isEvictionProcRunning = 1;\n        aeCreateTimeEvent(server.el, 0,\n                evictionTimeProc, NULL, NULL);\n    }\n}\n\n/* Check if it's safe to perform evictions.\n *   Returns 1 if evictions can be performed\n *   Returns 0 if eviction processing should be skipped\n */\nstatic int isSafeToPerformEvictions(void) {\n    /* - There must be no script in timeout condition.\n     * - Nor we are loading data right now.  */\n    if (isInsideYieldingLongCommand() || server.loading) return 0;\n\n    /* By default replicas should ignore maxmemory\n     * and just be masters exact copies. */\n    if (server.masterhost && server.repl_slave_ignore_maxmemory) return 0;\n\n    /* If 'evict' action is paused, for whatever reason, then return false */\n    if (isPausedActionsWithUpdate(PAUSE_ACTION_EVICT)) return 0;\n\n    return 1;\n}\n\n/* Algorithm for converting tenacity (0-100) to a time limit.  */\nstatic unsigned long evictionTimeLimitUs(void) {\n    serverAssert(server.maxmemory_eviction_tenacity >= 0);\n    serverAssert(server.maxmemory_eviction_tenacity <= 100);\n\n    if (server.maxmemory_eviction_tenacity <= 10) {\n        /* A linear progression from 0..500us */\n        return 50uL * server.maxmemory_eviction_tenacity;\n    }\n\n    if (server.maxmemory_eviction_tenacity < 100) {\n        /* A 15% geometric progression, resulting in a limit of ~2 min at tenacity==99  */\n        return (unsigned long)(500.0 * pow(1.15, server.maxmemory_eviction_tenacity - 10.0));\n    }\n\n    return ULONG_MAX;   /* No limit to eviction time */\n}\n\n/* Check that memory usage is within the current \"maxmemory\" limit.  If over\n * \"maxmemory\", attempt to free memory by evicting data (if it's safe to do so).\n *\n * It's possible for Redis to suddenly be significantly over the \"maxmemory\"\n * setting.  This can happen if there is a large allocation (like a hash table\n * resize) or even if the \"maxmemory\" setting is manually adjusted.  Because of\n * this, it's important to evict for a managed period of time - otherwise Redis\n * would become unresponsive while evicting.\n *\n * The goal of this function is to improve the memory situation - not to\n * immediately resolve it.  In the case that some items have been evicted but\n * the \"maxmemory\" limit has not been achieved, an aeTimeProc will be started\n * which will continue to evict items until memory limits are achieved or\n * nothing more is evictable.\n *\n * This should be called before execution of commands.  If EVICT_FAIL is\n * returned, commands which will result in increased memory usage should be\n * rejected.\n *\n * Returns:\n *   EVICT_OK       - memory is OK or it's not possible to perform evictions now\n *   EVICT_RUNNING  - memory is over the limit, but eviction is still processing\n *   EVICT_FAIL     - memory is over the limit, and there's nothing to evict\n * */\nint performEvictions(void) {\n    /* Note, we don't goto update_metrics here because this check skips eviction\n     * as if it wasn't triggered. it's a fake EVICT_OK. */\n    if (!isSafeToPerformEvictions()) return EVICT_OK;\n\n    int keys_freed = 0;\n    size_t mem_reported, mem_tofree;\n    long long mem_freed; /* May be negative */\n    mstime_t latency, eviction_latency;\n    long long delta;\n    int slaves = listLength(server.slaves);\n    int result = EVICT_FAIL;\n\n    if (getMaxmemoryState(&mem_reported,NULL,&mem_tofree,NULL) == C_OK) {\n        result = EVICT_OK;\n        goto update_metrics;\n    }\n\n    if (server.maxmemory_policy == MAXMEMORY_NO_EVICTION) {\n        result = EVICT_FAIL;  /* We need to free memory, but policy forbids. */\n        goto update_metrics;\n    }\n\n    unsigned long eviction_time_limit_us = evictionTimeLimitUs();\n\n    mem_freed = 0;\n\n    latencyStartMonitor(latency);\n\n    monotime evictionTimer;\n    elapsedStart(&evictionTimer);\n\n    /* Try to smoke-out bugs (server.also_propagate should be empty here) */\n    serverAssert(server.also_propagate.numops == 0);\n    /* Evictions are performed on random keys that have nothing to do with the current command slot. */\n\n    while (mem_freed < (long long)mem_tofree) {\n        int j, k, i;\n        static unsigned int next_db = 0;\n        sds bestkey = NULL;\n        int bestdbid;\n        redisDb *db;\n        dictEntry *de;\n\n        if (server.maxmemory_policy & (MAXMEMORY_FLAG_LRU|MAXMEMORY_FLAG_LFU) ||\n            server.maxmemory_policy == MAXMEMORY_VOLATILE_TTL)\n        {\n            struct evictionPoolEntry *pool = EvictionPoolLRU;\n            while (bestkey == NULL) {\n                unsigned long total_keys = 0;\n\n                /* We don't want to make local-db choices when expiring keys,\n                 * so to start populate the eviction pool sampling keys from\n                 * every DB. */\n                for (i = 0; i < server.dbnum; i++) {\n                    db = server.db+i;\n                    kvstore *kvs;\n                    if (server.maxmemory_policy & MAXMEMORY_FLAG_ALLKEYS) {\n                        kvs = db->keys;\n                    } else {\n                        kvs = db->expires;\n                    }\n                    unsigned long sampled_keys = 0;\n                    unsigned long current_db_keys = kvstoreSize(kvs);\n                    if (current_db_keys == 0) continue;\n\n                    total_keys += current_db_keys;\n                    int l = kvstoreNumNonEmptyDicts(kvs);\n                    /* Do not exceed the number of non-empty slots when looping. */\n                    while (l--) {\n                        sampled_keys += evictionPoolPopulate(db, kvs, pool);\n                        /* We have sampled enough keys in the current db, exit the loop. */\n                        if (sampled_keys >= (unsigned long) server.maxmemory_samples)\n                            break;\n                        /* If there are not a lot of keys in the current db, dict/s may be very\n                         * sparsely populated, exit the loop without meeting the sampling\n                         * requirement. */\n                        if (current_db_keys < (unsigned long) server.maxmemory_samples*10)\n                            break;\n                    }\n                }\n                if (!total_keys) break; /* No keys to evict. */\n\n                /* Go backward from best to worst element to evict. */\n                for (k = EVPOOL_SIZE-1; k >= 0; k--) {\n                    if (pool[k].key == NULL) continue;\n                    bestdbid = pool[k].dbid;\n\n                    kvstore *kvs;\n                    if (server.maxmemory_policy & MAXMEMORY_FLAG_ALLKEYS) {\n                        kvs = server.db[bestdbid].keys;\n                    } else {\n                        kvs = server.db[bestdbid].expires;\n                    }\n                    de = kvstoreDictFind(kvs, pool[k].slot, pool[k].key);\n\n                    /* Remove the entry from the pool. */\n                    if (pool[k].key != pool[k].cached)\n                        sdsfree(pool[k].key);\n                    pool[k].key = NULL;\n                    pool[k].idle = 0;\n\n                    /* If the key exists, is our pick. Otherwise it is\n                     * a ghost and we need to try the next element. */\n                    if (de) {\n                        bestkey = dictGetKey(de);\n                        break;\n                    } else {\n                        /* Ghost... Iterate again. */\n                    }\n                }\n            }\n        }\n\n        /* volatile-random and allkeys-random policy */\n        else if (server.maxmemory_policy == MAXMEMORY_ALLKEYS_RANDOM ||\n                 server.maxmemory_policy == MAXMEMORY_VOLATILE_RANDOM)\n        {\n            /* When evicting a random key, we try to evict a key for\n             * each DB, so we use the static 'next_db' variable to\n             * incrementally visit all DBs. */\n            for (i = 0; i < server.dbnum; i++) {\n                j = (++next_db) % server.dbnum;\n                db = server.db+j;\n                kvstore *kvs;\n                if (server.maxmemory_policy == MAXMEMORY_ALLKEYS_RANDOM) {\n                    kvs = db->keys;\n                } else {\n                    kvs = db->expires;\n                }\n                int slot = kvstoreGetFairRandomDictIndex(kvs);\n                de = kvstoreDictGetRandomKey(kvs, slot);\n                if (de) {\n                    bestkey = dictGetKey(de);\n                    bestdbid = j;\n                    break;\n                }\n            }\n        }\n\n        /* Finally remove the selected key. */\n        if (bestkey) {\n            db = server.db+bestdbid;\n            robj *keyobj = createStringObject(bestkey,sdslen(bestkey));\n            /* We compute the amount of memory freed by db*Delete() alone.\n             * It is possible that actually the memory needed to propagate\n             * the DEL in AOF and replication link is greater than the one\n             * we are freeing removing the key, but we can't account for\n             * that otherwise we would never exit the loop.\n             *\n             * Same for CSC invalidation messages generated by signalModifiedKey.\n             *\n             * AOF and Output buffer memory will be freed eventually so\n             * we only care about memory used by the key space. */\n            enterExecutionUnit(1, 0);\n            delta = (long long) zmalloc_used_memory();\n            latencyStartMonitor(eviction_latency);\n            dbGenericDelete(db,keyobj,server.lazyfree_lazy_eviction,DB_FLAG_KEY_EVICTED);\n            latencyEndMonitor(eviction_latency);\n            latencyAddSampleIfNeeded(\"eviction-del\",eviction_latency);\n            delta -= (long long) zmalloc_used_memory();\n            mem_freed += delta;\n            server.stat_evictedkeys++;\n            signalModifiedKey(NULL,db,keyobj);\n            notifyKeyspaceEvent(NOTIFY_EVICTED, \"evicted\",\n                keyobj, db->id);\n            propagateDeletion(db,keyobj,server.lazyfree_lazy_eviction);\n            exitExecutionUnit();\n            postExecutionUnitOperations();\n            decrRefCount(keyobj);\n            keys_freed++;\n\n            if (keys_freed % 16 == 0) {\n                /* When the memory to free starts to be big enough, we may\n                 * start spending so much time here that is impossible to\n                 * deliver data to the replicas fast enough, so we force the\n                 * transmission here inside the loop. */\n                if (slaves) flushSlavesOutputBuffers();\n\n                /* Normally our stop condition is the ability to release\n                 * a fixed, pre-computed amount of memory. However when we\n                 * are deleting objects in another thread, it's better to\n                 * check, from time to time, if we already reached our target\n                 * memory, since the \"mem_freed\" amount is computed only\n                 * across the dbAsyncDelete() call, while the thread can\n                 * release the memory all the time. */\n                if (server.lazyfree_lazy_eviction) {\n                    if (getMaxmemoryState(NULL,NULL,NULL,NULL) == C_OK) {\n                        break;\n                    }\n                }\n\n                /* After some time, exit the loop early - even if memory limit\n                 * hasn't been reached.  If we suddenly need to free a lot of\n                 * memory, don't want to spend too much time here.  */\n                if (elapsedUs(evictionTimer) > eviction_time_limit_us) {\n                    // We still need to free memory - start eviction timer proc\n                    startEvictionTimeProc();\n                    break;\n                }\n            }\n        } else {\n            goto cant_free; /* nothing to free... */\n        }\n    }\n    /* at this point, the memory is OK, or we have reached the time limit */\n    result = (isEvictionProcRunning) ? EVICT_RUNNING : EVICT_OK;\n\ncant_free:\n    if (result == EVICT_FAIL) {\n        /* At this point, we have run out of evictable items.  It's possible\n         * that some items are being freed in the lazyfree thread.  Perform a\n         * short wait here if such jobs exist, but don't wait long.  */\n        mstime_t lazyfree_latency;\n        latencyStartMonitor(lazyfree_latency);\n        while (bioPendingJobsOfType(BIO_LAZY_FREE) &&\n              elapsedUs(evictionTimer) < eviction_time_limit_us) {\n            if (getMaxmemoryState(NULL,NULL,NULL,NULL) == C_OK) {\n                result = EVICT_OK;\n                break;\n            }\n            usleep(eviction_time_limit_us < 1000 ? eviction_time_limit_us : 1000);\n        }\n        latencyEndMonitor(lazyfree_latency);\n        latencyAddSampleIfNeeded(\"eviction-lazyfree\",lazyfree_latency);\n    }\n\n    latencyEndMonitor(latency);\n    latencyAddSampleIfNeeded(\"eviction-cycle\",latency);\n\nupdate_metrics:\n    if (result == EVICT_RUNNING || result == EVICT_FAIL) {\n        if (server.stat_last_eviction_exceeded_time == 0)\n            elapsedStart(&server.stat_last_eviction_exceeded_time);\n    } else if (result == EVICT_OK) {\n        if (server.stat_last_eviction_exceeded_time != 0) {\n            server.stat_total_eviction_exceeded_time += elapsedUs(server.stat_last_eviction_exceeded_time);\n            server.stat_last_eviction_exceeded_time = 0;\n        }\n    }\n    return result;\n}\n"}], "code": "int dictResizeAllowed(size_t moreMem, double usedRatio) {\n    /* for debug purposes: dict is not allowed to be resized. */\n    if (!server.dict_resizing) return 0;\n\n    if (usedRatio <= HASHTABLE_MAX_LOAD_FACTOR) {\n        return !overMaxmemoryAfterAlloc(moreMem);\n    } else {\n        return 1;\n    }\n}\n"}, "8A27BFF462650406": {"calls": [{"id": "EF3BB8EE8414CA75", "name": "getKeySlot", "path": "redis/src/db.c", "start": {"line": 222, "col": 1}, "end": {"line": 234, "col": 1}, "code": "    /* This is performance optimization that uses pre-set slot id from the current command,\n     * in order to avoid calculation of the key hash.\n     * This optimization is only used when current_client flag `CLIENT_EXECUTING_COMMAND` is set.\n     * It only gets set during the execution of command under `call` method. Other flows requesting\n     * the key slot would fallback to calculateKeySlot.\n     */\n    if (server.current_client && server.current_client->slot >= 0 && server.current_client->flags & CLIENT_EXECUTING_COMMAND) {\n        debugServerAssertWithInfo(server.current_client, NULL, calculateKeySlot(key)==server.current_client->slot);\n        return server.current_client->slot;\n    }\n    return calculateKeySlot(key);\n}\n\n/* This is a special version of dbAdd() that is used only when loading\n * keys from the RDB file: the key is passed as an SDS string that is\n * retained by the function (and not freed by the caller).\n *\n * Moreover this function will not abort if the key is already busy, to\n * give more control to the caller, nor will signal the key as ready\n * since it is not useful in this context.\n *\n * The function returns 1 if the key was added to the database, taking\n * ownership of the SDS string, otherwise 0 is returned, and is up to the\n * caller to free the SDS string. */\nint dbAddRDBLoad(redisDb *db, sds key, robj *val) {\n    int slot = getKeySlot(key);\n    dictEntry *de = kvstoreDictAddRaw(db->keys, slot, key, NULL);\n    if (de == NULL) return 0;\n    initObjectLRUOrLFU(val);\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    return 1;\n}\n\n/* Overwrite an existing key with a new value. Incrementing the reference\n * count of the new value is up to the caller.\n * This function does not modify the expire time of the existing key.\n *\n * The 'overwrite' flag is an indication whether this is done as part of a\n * complete replacement of their key, which can be thought as a deletion and\n * replacement (in which case we need to emit deletion signals), or just an\n * update of a value of an existing key (when false).\n *\n * The dictEntry input is optional, can be used if we already have one.\n *\n * The program is aborted if the key was not already present. */\nstatic void dbSetValue(redisDb *db, robj *key, robj *val, int overwrite, dictEntry *de) {\n    int slot = getKeySlot(key->ptr);\n    if (!de) de = kvstoreDictFind(db->keys, slot, key->ptr);\n    serverAssertWithInfo(NULL,key,de != NULL);\n    robj *old = dictGetVal(de);\n\n    val->lru = old->lru;\n\n    if (overwrite) {\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain old */\n        incrRefCount(old);\n        /* Although the key is not really deleted from the database, we regard\n         * overwrite as two steps of unlink+add, so we still need to call the unlink\n         * callback of the module. */\n        moduleNotifyKeyUnlink(key,old,db->id,DB_FLAG_KEY_OVERWRITE);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,old->type);\n        decrRefCount(old);\n        /* Because of RM_StringDMA, old may be changed, so we need get old again */\n        old = dictGetVal(de);\n    }\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    if (server.lazyfree_lazy_server_del) {\n        freeObjAsync(key,old,db->id);\n    } else {\n        decrRefCount(old);\n    }\n}\n\n/* Replace an existing key with a new value, we just replace value and don't\n * emit any events */\nvoid dbReplaceValue(redisDb *db, robj *key, robj *val) {\n    dbSetValue(db, key, val, 0, NULL);\n}\n\n/* High level Set operation. This function can be used in order to set\n * a key, whatever it was existing or not, to a new object.\n *\n * 1) The ref count of the value object is incremented.\n * 2) clients WATCHing for the destination key notified.\n * 3) The expire time of the key is reset (the key is made persistent),\n *    unless 'SETKEY_KEEPTTL' is enabled in flags.\n * 4) The key lookup can take place outside this interface outcome will be\n *    delivered with 'SETKEY_ALREADY_EXIST' or 'SETKEY_DOESNT_EXIST'\n *\n * All the new keys in the database should be created via this interface.\n * The client 'c' argument may be set to NULL if the operation is performed\n * in a context where there is no clear client performing the operation. */\nvoid setKey(client *c, redisDb *db, robj *key, robj *val, int flags) {\n    int keyfound = 0;\n\n    if (flags & SETKEY_ALREADY_EXIST)\n        keyfound = 1;\n    else if (flags & SETKEY_ADD_OR_UPDATE)\n        keyfound = -1;\n    else if (!(flags & SETKEY_DOESNT_EXIST))\n        keyfound = (lookupKeyWrite(db,key) != NULL);\n\n    if (!keyfound) {\n        dbAdd(db,key,val);\n    } else if (keyfound<0) {\n        dbAddInternal(db,key,val,1);\n    } else {\n        dbSetValue(db,key,val,1,NULL);\n    }\n    incrRefCount(val);\n    if (!(flags & SETKEY_KEEPTTL)) removeExpire(db,key);\n    if (!(flags & SETKEY_NO_SIGNAL)) signalModifiedKey(c,db,key);\n}\n\n/* Return a random key, in form of a Redis object.\n * If there are no keys, NULL is returned.\n *\n * The function makes sure to return keys not already expired. */\nrobj *dbRandomKey(redisDb *db) {\n    dictEntry *de;\n    int maxtries = 100;\n    int allvolatile = kvstoreSize(db->keys) == kvstoreSize(db->expires);\n\n    while(1) {\n        sds key;\n        robj *keyobj;\n        int randomSlot = kvstoreGetFairRandomDictIndex(db->keys);\n        de = kvstoreDictGetFairRandomKey(db->keys, randomSlot);\n        if (de == NULL) return NULL;\n\n        key = dictGetKey(de);\n        keyobj = createStringObject(key,sdslen(key));\n        if (dbFindExpires(db, key)) {\n            if (allvolatile && server.masterhost && --maxtries == 0) {\n                /* If the DB is composed only of keys with an expire set,\n                 * it could happen that all the keys are already logically\n                 * expired in the slave, so the function cannot stop because\n                 * expireIfNeeded() is false, nor it can stop because\n                 * dictGetFairRandomKey() returns NULL (there are keys to return).\n                 * To prevent the infinite loop we do some tries, but if there\n                 * are the conditions for an infinite loop, eventually we\n                 * return a key name that may be already expired. */\n                return keyobj;\n            }\n            if (expireIfNeeded(db,keyobj,0)) {\n                decrRefCount(keyobj);\n                continue; /* search for another key. This expired. */\n            }\n        }\n        return keyobj;\n    }\n}\n\n/* Helper for sync and async delete. */\nint dbGenericDelete(redisDb *db, robj *key, int async, int flags) {\n    dictEntry **plink;\n    int table;\n    int slot = getKeySlot(key->ptr);\n    dictEntry *de = kvstoreDictTwoPhaseUnlinkFind(db->keys, slot, key->ptr, &plink, &table);\n    if (de) {\n        robj *val = dictGetVal(de);\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain val */\n        incrRefCount(val);\n        /* Tells the module that the key has been unlinked from the database. */\n        moduleNotifyKeyUnlink(key,val,db->id,flags);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,val->type);\n        /* We should call decr before freeObjAsync. If not, the refcount may be\n         * greater than 1, so freeObjAsync doesn't work */\n        decrRefCount(val);\n        if (async) {\n            /* Because of dbUnshareStringValue, the val in de may change. */\n            freeObjAsync(key, dictGetVal(de), db->id);\n            kvstoreDictSetVal(db->keys, slot, de, NULL);\n        }\n        /* Deleting an entry from the expires dict will not free the sds of\n         * the key, because it is shared with the main dictionary. */\n        kvstoreDictDelete(db->expires, slot, key->ptr);\n\n        kvstoreDictTwoPhaseUnlinkFree(db->keys, slot, de, plink, table);\n        return 1;\n    } else {\n        return 0;\n    }\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB */\nint dbSyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB. If\n * the value consists of many allocations, it may be freed asynchronously. */\nint dbAsyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);\n}\n\n/* This is a wrapper whose behavior depends on the Redis lazy free\n * configuration. Deletes the key synchronously or asynchronously. */\nint dbDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, server.lazyfree_lazy_server_del, DB_FLAG_KEY_DELETED);\n}\n\n/* Prepare the string object stored at 'key' to be modified destructively\n * to implement commands like SETBIT or APPEND.\n *\n * An object is usually ready to be modified unless one of the two conditions\n * are true:\n *\n * 1) The object 'o' is shared (refcount > 1), we don't want to affect\n *    other users.\n * 2) The object encoding is not \"RAW\".\n *\n * If the object is found in one of the above conditions (or both) by the\n * function, an unshared / not-encoded copy of the string object is stored\n * at 'key' in the specified 'db'. Otherwise the object 'o' itself is\n * returned.\n *\n * USAGE:\n *\n * The object 'o' is what the caller already obtained by looking up 'key'\n * in 'db', the usage pattern looks like this:\n *\n * o = lookupKeyWrite(db,key);\n * if (checkType(c,o,OBJ_STRING)) return;\n * o = dbUnshareStringValue(db,key,o);\n *\n * At this point the caller is ready to modify the object, for example\n * using an sdscat() call to append some data, or anything else.\n */\nrobj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) {\n    serverAssert(o->type == OBJ_STRING);\n"}, {"id": "674B217200CF2045", "name": "kvstoreDictAddRaw", "path": "redis/src/kvstore.c", "start": {"line": 737, "col": 1}, "end": {"line": 744, "col": 1}, "code": "    createDictIfNeeded(kvs, didx);\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictEntry *ret = dictAddRaw(d, key, existing);\n    if (ret)\n        cumulativeKeyCountAdd(kvs, didx, 1);\n    return ret;\n}\n\nvoid kvstoreDictSetKey(kvstore *kvs, int didx, dictEntry* de, void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetKey(d, de, key);\n}\n\nvoid kvstoreDictSetVal(kvstore *kvs, int didx, dictEntry *de, void *val) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}, {"id": "AFF71DA3ED82AA2F", "name": "dbSetValue", "path": "redis/src/db.c", "start": {"line": 268, "col": 1}, "end": {"line": 296, "col": 1}, "code": "    int slot = getKeySlot(key->ptr);\n    if (!de) de = kvstoreDictFind(db->keys, slot, key->ptr);\n    serverAssertWithInfo(NULL,key,de != NULL);\n    robj *old = dictGetVal(de);\n\n    val->lru = old->lru;\n\n    if (overwrite) {\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain old */\n        incrRefCount(old);\n        /* Although the key is not really deleted from the database, we regard\n         * overwrite as two steps of unlink+add, so we still need to call the unlink\n         * callback of the module. */\n        moduleNotifyKeyUnlink(key,old,db->id,DB_FLAG_KEY_OVERWRITE);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,old->type);\n        decrRefCount(old);\n        /* Because of RM_StringDMA, old may be changed, so we need get old again */\n        old = dictGetVal(de);\n    }\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    if (server.lazyfree_lazy_server_del) {\n        freeObjAsync(key,old,db->id);\n    } else {\n        decrRefCount(old);\n    }\n}\n\n/* Replace an existing key with a new value, we just replace value and don't\n * emit any events */\nvoid dbReplaceValue(redisDb *db, robj *key, robj *val) {\n    dbSetValue(db, key, val, 0, NULL);\n}\n\n/* High level Set operation. This function can be used in order to set\n * a key, whatever it was existing or not, to a new object.\n *\n * 1) The ref count of the value object is incremented.\n * 2) clients WATCHing for the destination key notified.\n * 3) The expire time of the key is reset (the key is made persistent),\n *    unless 'SETKEY_KEEPTTL' is enabled in flags.\n * 4) The key lookup can take place outside this interface outcome will be\n *    delivered with 'SETKEY_ALREADY_EXIST' or 'SETKEY_DOESNT_EXIST'\n *\n * All the new keys in the database should be created via this interface.\n * The client 'c' argument may be set to NULL if the operation is performed\n * in a context where there is no clear client performing the operation. */\nvoid setKey(client *c, redisDb *db, robj *key, robj *val, int flags) {\n    int keyfound = 0;\n\n    if (flags & SETKEY_ALREADY_EXIST)\n        keyfound = 1;\n    else if (flags & SETKEY_ADD_OR_UPDATE)\n        keyfound = -1;\n    else if (!(flags & SETKEY_DOESNT_EXIST))\n        keyfound = (lookupKeyWrite(db,key) != NULL);\n\n    if (!keyfound) {\n        dbAdd(db,key,val);\n    } else if (keyfound<0) {\n        dbAddInternal(db,key,val,1);\n    } else {\n        dbSetValue(db,key,val,1,NULL);\n    }\n    incrRefCount(val);\n    if (!(flags & SETKEY_KEEPTTL)) removeExpire(db,key);\n    if (!(flags & SETKEY_NO_SIGNAL)) signalModifiedKey(c,db,key);\n}\n\n/* Return a random key, in form of a Redis object.\n * If there are no keys, NULL is returned.\n *\n * The function makes sure to return keys not already expired. */\nrobj *dbRandomKey(redisDb *db) {\n    dictEntry *de;\n    int maxtries = 100;\n    int allvolatile = kvstoreSize(db->keys) == kvstoreSize(db->expires);\n\n    while(1) {\n        sds key;\n        robj *keyobj;\n        int randomSlot = kvstoreGetFairRandomDictIndex(db->keys);\n        de = kvstoreDictGetFairRandomKey(db->keys, randomSlot);\n        if (de == NULL) return NULL;\n\n        key = dictGetKey(de);\n        keyobj = createStringObject(key,sdslen(key));\n        if (dbFindExpires(db, key)) {\n            if (allvolatile && server.masterhost && --maxtries == 0) {\n                /* If the DB is composed only of keys with an expire set,\n                 * it could happen that all the keys are already logically\n                 * expired in the slave, so the function cannot stop because\n                 * expireIfNeeded() is false, nor it can stop because\n                 * dictGetFairRandomKey() returns NULL (there are keys to return).\n                 * To prevent the infinite loop we do some tries, but if there\n                 * are the conditions for an infinite loop, eventually we\n                 * return a key name that may be already expired. */\n                return keyobj;\n            }\n            if (expireIfNeeded(db,keyobj,0)) {\n                decrRefCount(keyobj);\n                continue; /* search for another key. This expired. */\n            }\n        }\n        return keyobj;\n    }\n}\n\n/* Helper for sync and async delete. */\nint dbGenericDelete(redisDb *db, robj *key, int async, int flags) {\n    dictEntry **plink;\n    int table;\n    int slot = getKeySlot(key->ptr);\n    dictEntry *de = kvstoreDictTwoPhaseUnlinkFind(db->keys, slot, key->ptr, &plink, &table);\n    if (de) {\n        robj *val = dictGetVal(de);\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain val */\n        incrRefCount(val);\n        /* Tells the module that the key has been unlinked from the database. */\n        moduleNotifyKeyUnlink(key,val,db->id,flags);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,val->type);\n        /* We should call decr before freeObjAsync. If not, the refcount may be\n         * greater than 1, so freeObjAsync doesn't work */\n        decrRefCount(val);\n        if (async) {\n            /* Because of dbUnshareStringValue, the val in de may change. */\n            freeObjAsync(key, dictGetVal(de), db->id);\n            kvstoreDictSetVal(db->keys, slot, de, NULL);\n        }\n        /* Deleting an entry from the expires dict will not free the sds of\n         * the key, because it is shared with the main dictionary. */\n        kvstoreDictDelete(db->expires, slot, key->ptr);\n\n        kvstoreDictTwoPhaseUnlinkFree(db->keys, slot, de, plink, table);\n        return 1;\n    } else {\n        return 0;\n    }\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB */\nint dbSyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB. If\n * the value consists of many allocations, it may be freed asynchronously. */\nint dbAsyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);\n}\n\n/* This is a wrapper whose behavior depends on the Redis lazy free\n * configuration. Deletes the key synchronously or asynchronously. */\nint dbDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, server.lazyfree_lazy_server_del, DB_FLAG_KEY_DELETED);\n}\n\n/* Prepare the string object stored at 'key' to be modified destructively\n * to implement commands like SETBIT or APPEND.\n *\n * An object is usually ready to be modified unless one of the two conditions\n * are true:\n *\n * 1) The object 'o' is shared (refcount > 1), we don't want to affect\n *    other users.\n * 2) The object encoding is not \"RAW\".\n *\n * If the object is found in one of the above conditions (or both) by the\n * function, an unshared / not-encoded copy of the string object is stored\n * at 'key' in the specified 'db'. Otherwise the object 'o' itself is\n * returned.\n *\n * USAGE:\n *\n * The object 'o' is what the caller already obtained by looking up 'key'\n * in 'db', the usage pattern looks like this:\n *\n * o = lookupKeyWrite(db,key);\n * if (checkType(c,o,OBJ_STRING)) return;\n * o = dbUnshareStringValue(db,key,o);\n *\n * At this point the caller is ready to modify the object, for example\n * using an sdscat() call to append some data, or anything else.\n */\nrobj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) {\n    serverAssert(o->type == OBJ_STRING);\n    if (o->refcount != 1 || o->encoding != OBJ_ENCODING_RAW) {\n        robj *decoded = getDecodedObject(o);\n        o = createRawStringObject(decoded->ptr, sdslen(decoded->ptr));\n        decrRefCount(decoded);\n        dbReplaceValue(db,key,o);\n    }\n    return o;\n}\n\n/* Remove all keys from the database(s) structure. The dbarray argument\n * may not be the server main DBs (could be a temporary DB).\n *\n * The dbnum can be -1 if all the DBs should be emptied, or the specified\n * DB index if we want to empty only a single database.\n * The function returns the number of keys removed from the database(s). */\nlong long emptyDbStructure(redisDb *dbarray, int dbnum, int async,\n                           void(callback)(dict*))\n{\n    long long removed = 0;\n    int startdb, enddb;\n\n    if (dbnum == -1) {\n        startdb = 0;\n        enddb = server.dbnum-1;\n    } else {\n        startdb = enddb = dbnum;\n    }\n\n    for (int j = startdb; j <= enddb; j++) {\n        removed += kvstoreSize(dbarray[j].keys);\n        if (async) {\n            emptyDbAsync(&dbarray[j]);\n        } else {\n            kvstoreEmpty(dbarray[j].keys, callback);\n            kvstoreEmpty(dbarray[j].expires, callback);\n        }\n        /* Because all keys of database are removed, reset average ttl. */\n        dbarray[j].avg_ttl = 0;\n        dbarray[j].expires_cursor = 0;\n    }\n\n    return removed;\n}\n\n/* Remove all data (keys and functions) from all the databases in a\n * Redis server. If callback is given the function is called from\n * time to time to signal that work is in progress.\n *\n * The dbnum can be -1 if all the DBs should be flushed, or the specified\n * DB number if we want to flush only a single Redis database number.\n *\n * Flags are be EMPTYDB_NO_FLAGS if no special flags are specified or\n * EMPTYDB_ASYNC if we want the memory to be freed in a different thread\n * and the function to return ASAP. EMPTYDB_NOFUNCTIONS can also be set\n * to specify that we do not want to delete the functions.\n *\n * On success the function returns the number of keys removed from the\n * database(s). Otherwise -1 is returned in the specific case the\n * DB number is out of range, and errno is set to EINVAL. */\nlong long emptyData(int dbnum, int flags, void(callback)(dict*)) {\n    int async = (flags & EMPTYDB_ASYNC);\n    int with_functions = !(flags & EMPTYDB_NOFUNCTIONS);\n    RedisModuleFlushInfoV1 fi = {REDISMODULE_FLUSHINFO_VERSION,!async,dbnum};\n    long long removed = 0;\n\n    if (dbnum < -1 || dbnum >= server.dbnum) {\n        errno = EINVAL;\n        return -1;\n    }\n\n    /* Fire the flushdb modules event. */\n    moduleFireServerEvent(REDISMODULE_EVENT_FLUSHDB,\n                          REDISMODULE_SUBEVENT_FLUSHDB_START,\n                          &fi);\n\n    /* Make sure the WATCHed keys are affected by the FLUSH* commands.\n     * Note that we need to call the function while the keys are still\n     * there. */\n    signalFlushedDb(dbnum, async);\n\n    /* Empty redis database structure. */\n    removed = emptyDbStructure(server.db, dbnum, async, callback);\n\n    if (dbnum == -1) flushSlaveKeysWithExpireList();\n\n    if (with_functions) {\n        serverAssert(dbnum == -1);\n        functionsLibCtxClearCurrent(async);\n    }\n\n    /* Also fire the end event. Note that this event will fire almost\n     * immediately after the start event if the flush is asynchronous. */\n    moduleFireServerEvent(REDISMODULE_EVENT_FLUSHDB,\n                          REDISMODULE_SUBEVENT_FLUSHDB_END,\n                          &fi);\n\n    return removed;\n}\n\n/* Initialize temporary db on replica for use during diskless replication. */\nredisDb *initTempDb(void) {\n    redisDb *tempDb = zcalloc(sizeof(redisDb)*server.dbnum);\n    for (int i=0; i<server.dbnum; i++) {\n        tempDb[i].id = i;\n        int slotCountBits = server.cluster_enabled? CLUSTER_SLOT_MASK_BITS : 0;\n        tempDb[i].keys = kvstoreCreate(&dbDictType, slotCountBits, KVSTORE_ALLOCATE_DICTS_ON_DEMAND);\n        tempDb[i].expires = kvstoreCreate(&dbExpiresDictType, slotCountBits, KVSTORE_ALLOCATE_DICTS_ON_DEMAND);\n    }\n"}, {"id": "F1849F8C74C163D2", "name": "kvstoreDictSetKey", "path": "redis/src/kvstore.c", "start": {"line": 746, "col": 1}, "end": {"line": 749, "col": 1}, "code": "    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetKey(d, de, key);\n}\n\nvoid kvstoreDictSetVal(kvstore *kvs, int didx, dictEntry *de, void *val) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}, {"id": "2894F02D7D38E7C1", "name": "sdsdup", "path": "redis/src/sds.c", "start": {"line": 190, "col": 1}, "end": {"line": 192, "col": 1}, "code": "    return sdsnewlen(s, sdslen(s));\n}\n\n/* Free an sds string. No operation is performed if 's' is NULL. */\nvoid sdsfree(sds s) {\n    if (s == NULL) return;\n    s_free((char*)s-sdsHdrSize(s[-1]));\n}\n\n/* Set the sds string length to the length as obtained with strlen(), so\n * considering as content only up to the first null term character.\n *\n * This function is useful when the sds string is hacked manually in some\n * way, like in the following example:\n *\n * s = sdsnew(\"foobar\");\n * s[2] = '\\0';\n * sdsupdatelen(s);\n * printf(\"%d\\n\", sdslen(s));\n *\n * The output will be \"2\", but if we comment out the call to sdsupdatelen()\n * the output will be \"6\" as the string was modified but the logical length\n * remains 6 bytes. */\nvoid sdsupdatelen(sds s) {\n    size_t reallen = strlen(s);\n    sdssetlen(s, reallen);\n}\n\n/* Modify an sds string in-place to make it empty (zero length).\n * However all the existing buffer is not discarded but set as free space\n * so that next append operations will not require allocations up to the\n * number of bytes previously available. */\nvoid sdsclear(sds s) {\n    sdssetlen(s, 0);\n    s[0] = '\\0';\n}\n\n/* Enlarge the free space at the end of the sds string so that the caller\n * is sure that after calling this function can overwrite up to addlen\n * bytes after the end of the string, plus one more byte for nul term.\n * If there's already sufficient free space, this function returns without any\n * action, if there isn't sufficient free space, it'll allocate what's missing,\n * and possibly more:\n * When greedy is 1, enlarge more than needed, to avoid need for future reallocs\n * on incremental growth.\n * When greedy is 0, enlarge just enough so that there's free space for 'addlen'.\n *\n * Note: this does not change the *length* of the sds string as returned\n * by sdslen(), but only the free buffer space we have. */\nsds _sdsMakeRoomFor(sds s, size_t addlen, int greedy) {\n    void *sh, *newsh;\n    size_t avail = sdsavail(s);\n    size_t len, newlen, reqlen;\n    char type, oldtype = s[-1] & SDS_TYPE_MASK;\n    int hdrlen;\n    size_t usable;\n\n    /* Return ASAP if there is enough space left. */\n    if (avail >= addlen) return s;\n\n    len = sdslen(s);\n    sh = (char*)s-sdsHdrSize(oldtype);\n    reqlen = newlen = (len+addlen);\n    assert(newlen > len);   /* Catch size_t overflow */\n    if (greedy == 1) {\n        if (newlen < SDS_MAX_PREALLOC)\n            newlen *= 2;\n        else\n            newlen += SDS_MAX_PREALLOC;\n    }\n\n    type = sdsReqType(newlen);\n\n    /* Don't use type 5: the user is appending to the string and type 5 is\n     * not able to remember empty space, so sdsMakeRoomFor() must be called\n     * at every appending operation. */\n    if (type == SDS_TYPE_5) type = SDS_TYPE_8;\n\n    hdrlen = sdsHdrSize(type);\n    assert(hdrlen + newlen + 1 > reqlen);  /* Catch size_t overflow */\n    if (oldtype==type) {\n        newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);\n        if (newsh == NULL) return NULL;\n        s = (char*)newsh+hdrlen;\n    } else {\n        /* Since the header size changes, need to move the string forward,\n         * and can't use realloc */\n        newsh = s_malloc_usable(hdrlen+newlen+1, &usable);\n        if (newsh == NULL) return NULL;\n        memcpy((char*)newsh+hdrlen, s, len+1);\n        s_free(sh);\n        s = (char*)newsh+hdrlen;\n        s[-1] = type;\n        sdssetlen(s, len);\n    }\n    usable = usable-hdrlen-1;\n    if (usable > sdsTypeMaxSize(type))\n        usable = sdsTypeMaxSize(type);\n    sdssetalloc(s, usable);\n    return s;\n}\n\n/* Enlarge the free space at the end of the sds string more than needed,\n * This is useful to avoid repeated re-allocations when repeatedly appending to the sds. */\nsds sdsMakeRoomFor(sds s, size_t addlen) {\n    return _sdsMakeRoomFor(s, addlen, 1);\n}\n\n/* Unlike sdsMakeRoomFor(), this one just grows to the necessary size. */\nsds sdsMakeRoomForNonGreedy(sds s, size_t addlen) {\n    return _sdsMakeRoomFor(s, addlen, 0);\n}\n\n/* Reallocate the sds string so that it has no free space at the end. The\n * contained string remains not altered, but next concatenation operations\n * will require a reallocation.\n *\n * After the call, the passed sds string is no longer valid and all the\n * references must be substituted with the new pointer returned by the call. */\nsds sdsRemoveFreeSpace(sds s, int would_regrow) {\n    return sdsResize(s, sdslen(s), would_regrow);\n}\n\n/* Resize the allocation, this can make the allocation bigger or smaller,\n * if the size is smaller than currently used len, the data will be truncated.\n *\n * The when the would_regrow argument is set to 1, it prevents the use of\n * SDS_TYPE_5, which is desired when the sds is likely to be changed again.\n *\n * The sdsAlloc size will be set to the requested size regardless of the actual\n * allocation size, this is done in order to avoid repeated calls to this\n * function when the caller detects that it has excess space. */\nsds sdsResize(sds s, size_t size, int would_regrow) {\n    void *sh, *newsh;\n    char type, oldtype = s[-1] & SDS_TYPE_MASK;\n    int hdrlen, oldhdrlen = sdsHdrSize(oldtype);\n    size_t len = sdslen(s);\n    sh = (char*)s-oldhdrlen;\n\n    /* Return ASAP if the size is already good. */\n    if (sdsalloc(s) == size) return s;\n\n    /* Truncate len if needed. */\n    if (size < len) len = size;\n\n    /* Check what would be the minimum SDS header that is just good enough to\n     * fit this string. */\n    type = sdsReqType(size);\n    if (would_regrow) {\n        /* Don't use type 5, it is not good for strings that are expected to grow back. */\n        if (type == SDS_TYPE_5) type = SDS_TYPE_8;\n    }\n    hdrlen = sdsHdrSize(type);\n\n    /* If the type is the same, or can hold the size in it with low overhead\n     * (larger than SDS_TYPE_8), we just realloc(), letting the allocator\n     * to do the copy only if really needed. Otherwise if the change is\n     * huge, we manually reallocate the string to use the different header\n     * type. */\n    int use_realloc = (oldtype==type || (type < oldtype && type > SDS_TYPE_8));\n    size_t newlen = use_realloc ? oldhdrlen+size+1 : hdrlen+size+1;\n\n    if (use_realloc) {\n        int alloc_already_optimal = 0;\n        #if defined(USE_JEMALLOC)\n            /* je_nallocx returns the expected allocation size for the newlen.\n             * We aim to avoid calling realloc() when using Jemalloc if there is no\n             * change in the allocation size, as it incurs a cost even if the\n             * allocation size stays the same. */\n            alloc_already_optimal = (je_nallocx(newlen, 0) == zmalloc_size(sh));\n        #endif\n        if (!alloc_already_optimal) {\n            newsh = s_realloc(sh, newlen);\n            if (newsh == NULL) return NULL;\n            s = (char*)newsh+oldhdrlen;\n        }\n    } else {\n        newsh = s_malloc(newlen);\n        if (newsh == NULL) return NULL;\n        memcpy((char*)newsh+hdrlen, s, len);\n        s_free(sh);\n        s = (char*)newsh+hdrlen;\n        s[-1] = type;\n    }\n    s[len] = 0;\n    sdssetlen(s, len);\n    sdssetalloc(s, size);\n    return s;\n}\n\n/* Return the total size of the allocation of the specified sds string,\n * including:\n * 1) The sds header before the pointer.\n"}, {"id": "505C547C33FE1EEC", "name": "initObjectLRUOrLFU", "path": "redis/src/object.c", "start": {"line": 53, "col": 1}, "end": {"line": 64, "col": 1}, "code": "    if (o->refcount == OBJ_SHARED_REFCOUNT)\n        return;\n    /* Set the LRU to the current lruclock (minutes resolution), or\n     * alternatively the LFU counter. */\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n        o->lru = (LFUGetTimeInMinutes() << 8) | LFU_INIT_VAL;\n    } else {\n        o->lru = LRU_CLOCK();\n    }\n    return;\n}\n\n/* Set a special refcount in the object to make it \"shared\":\n * incrRefCount and decrRefCount() will test for this special refcount\n * and will not touch the object. This way it is free to access shared\n * objects such as small integers from different threads without any\n * mutex.\n *\n * A common pattern to create shared objects:\n *\n * robj *myobject = makeObjectShared(createObject(...));\n *\n */\nrobj *makeObjectShared(robj *o) {\n    serverAssert(o->refcount == 1);\n    o->refcount = OBJ_SHARED_REFCOUNT;\n    return o;\n}\n\n/* Create a string object with encoding OBJ_ENCODING_RAW, that is a plain\n * string object where o->ptr points to a proper sds string. */\nrobj *createRawStringObject(const char *ptr, size_t len) {\n    return createObject(OBJ_STRING, sdsnewlen(ptr,len));\n}\n\n/* Create a string object with encoding OBJ_ENCODING_EMBSTR, that is\n * an object where the sds string is actually an unmodifiable string\n * allocated in the same chunk as the object itself. */\nrobj *createEmbeddedStringObject(const char *ptr, size_t len) {\n    robj *o = zmalloc(sizeof(robj)+sizeof(struct sdshdr8)+len+1);\n    struct sdshdr8 *sh = (void*)(o+1);\n\n    o->type = OBJ_STRING;\n    o->encoding = OBJ_ENCODING_EMBSTR;\n    o->ptr = sh+1;\n    o->refcount = 1;\n    o->lru = 0;\n\n    sh->len = len;\n    sh->alloc = len;\n    sh->flags = SDS_TYPE_8;\n    if (ptr == SDS_NOINIT)\n        sh->buf[len] = '\\0';\n    else if (ptr) {\n        memcpy(sh->buf,ptr,len);\n        sh->buf[len] = '\\0';\n    } else {\n        memset(sh->buf,0,len+1);\n    }\n    return o;\n}\n\n/* Create a string object with EMBSTR encoding if it is smaller than\n * OBJ_ENCODING_EMBSTR_SIZE_LIMIT, otherwise the RAW encoding is\n * used.\n"}, {"id": "5062C754DD8A1D07", "name": "kvstoreDictSetVal", "path": "redis/src/kvstore.c", "start": {"line": 751, "col": 1}, "end": {"line": 754, "col": 1}, "code": "    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}, {"id": "7D7D2697AAE4AE85", "name": "signalKeyAsReady", "path": "redis/src/blocked.c", "start": {"line": 551, "col": 1}, "end": {"line": 553, "col": 1}, "code": "    signalKeyAsReadyLogic(db, key, type, 0);\n}\n\nvoid signalDeletedKeyAsReady(redisDb *db, robj *key, int type) {\n    signalKeyAsReadyLogic(db, key, type, 1);\n}\n\n/* Helper function for handleClientsBlockedOnKeys(). This function is called\n * whenever a key is ready. we iterate over all the clients blocked on this key\n * and try to re-execute the command (in case the key is still available). */\nstatic void handleClientsBlockedOnKey(readyList *rl) {\n\n    /* We serve clients in the same order they blocked for\n     * this key, from the first blocked to the last. */\n    dictEntry *de = dictFind(rl->db->blocking_keys,rl->key);\n\n    if (de) {\n        list *clients = dictGetVal(de);\n        listNode *ln;\n        listIter li;\n        listRewind(clients,&li);\n\n        /* Avoid processing more than the initial count so that we're not stuck\n         * in an endless loop in case the reprocessing of the command blocks again. */\n        long count = listLength(clients);\n        while ((ln = listNext(&li)) && count--) {\n            client *receiver = listNodeValue(ln);\n            robj *o = lookupKeyReadWithFlags(rl->db, rl->key, LOOKUP_NOEFFECTS);\n            /* 1. In case new key was added/touched we need to verify it satisfy the\n             *    blocked type, since we might process the wrong key type.\n             * 2. We want to serve clients blocked on module keys\n             *    regardless of the object type: we don't know what the\n             *    module is trying to accomplish right now.\n             * 3. In case of XREADGROUP call we will want to unblock on any change in object type\n             *    or in case the key was deleted, since the group is no longer valid. */\n            if ((o != NULL && (receiver->bstate.btype == getBlockedTypeByType(o->type))) ||\n                (o != NULL && (receiver->bstate.btype == BLOCKED_MODULE)) ||\n                (receiver->bstate.unblock_on_nokey))\n            {\n                if (receiver->bstate.btype != BLOCKED_MODULE)\n                    unblockClientOnKey(receiver, rl->key);\n                else\n                    moduleUnblockClientOnKey(receiver, rl->key);\n            }\n        }\n    }\n}\n\n/* block a client due to wait command */\nvoid blockForReplication(client *c, mstime_t timeout, long long offset, long numreplicas) {\n    c->bstate.timeout = timeout;\n    c->bstate.reploffset = offset;\n    c->bstate.numreplicas = numreplicas;\n    listAddNodeHead(server.clients_waiting_acks,c);\n    blockClient(c,BLOCKED_WAIT);\n}\n\n/* block a client due to waitaof command */\nvoid blockForAofFsync(client *c, mstime_t timeout, long long offset, int numlocal, long numreplicas) {\n    c->bstate.timeout = timeout;\n    c->bstate.reploffset = offset;\n    c->bstate.numreplicas = numreplicas;\n    c->bstate.numlocal = numlocal;\n    listAddNodeHead(server.clients_waiting_acks,c);\n    blockClient(c,BLOCKED_WAITAOF);\n}\n\n/* Postpone client from executing a command. For example the server might be busy\n * requesting to avoid processing clients commands which will be processed later\n * when the it is ready to accept them. */\nvoid blockPostponeClient(client *c) {\n    c->bstate.timeout = 0;\n    blockClient(c,BLOCKED_POSTPONE);\n    listAddNodeTail(server.postponed_clients, c);\n    c->postponed_list_node = listLast(server.postponed_clients);\n    /* Mark this client to execute its command */\n    c->flags |= CLIENT_PENDING_COMMAND;\n}\n\n/* Block client due to shutdown command */\nvoid blockClientShutdown(client *c) {\n    blockClient(c, BLOCKED_SHUTDOWN);\n}\n\n/* Unblock a client once a specific key became available for it.\n * This function will remove the client from the list of clients blocked on this key\n * and also remove the key from the dictionary of keys this client is blocked on.\n * in case the client has a command pending it will process it immediately.  */\nstatic void unblockClientOnKey(client *c, robj *key) {\n    dictEntry *de;\n\n    de = dictFind(c->bstate.keys, key);\n    releaseBlockedEntry(c, de, 1);\n\n    /* Only in case of blocking API calls, we might be blocked on several keys.\n       however we should force unblock the entire blocking keys */\n    serverAssert(c->bstate.btype == BLOCKED_STREAM ||\n                c->bstate.btype == BLOCKED_LIST   ||\n                c->bstate.btype == BLOCKED_ZSET);\n\n    /* We need to unblock the client before calling processCommandAndResetClient\n     * because it checks the CLIENT_BLOCKED flag */\n    unblockClient(c, 0);\n    /* In case this client was blocked on keys during command\n     * we need to re process the command again */\n    if (c->flags & CLIENT_PENDING_COMMAND) {\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n        /* We want the command processing and the unblock handler (see RM_Call 'K' option)\n         * to run atomically, this is why we must enter the execution unit here before\n         * running the command, and exit the execution unit after calling the unblock handler (if exists).\n         * Notice that we also must set the current client so it will be available\n         * when we will try to send the client side caching notification (done on 'afterCommand'). */\n        client *old_client = server.current_client;\n        server.current_client = c;\n        enterExecutionUnit(1, 0);\n        processCommandAndResetClient(c);\n        if (!(c->flags & CLIENT_BLOCKED)) {\n            if (c->flags & CLIENT_MODULE) {\n                moduleCallCommandUnblockedHandler(c);\n            } else {\n                queueClientForReprocessing(c);\n            }\n        }\n        exitExecutionUnit();\n        afterCommand(c);\n        server.current_client = old_client;\n    }\n}\n\n/* Unblock a client blocked on the specific key from module context.\n * This function will try to serve the module call, and in case it succeeds,\n * it will add the client to the list of module unblocked clients which will\n * be processed in moduleHandleBlockedClients. */\nstatic void moduleUnblockClientOnKey(client *c, robj *key) {\n    long long prev_error_replies = server.stat_total_error_replies;\n    client *old_client = server.current_client;\n    server.current_client = c;\n    monotime replyTimer;\n    elapsedStart(&replyTimer);\n\n    if (moduleTryServeClientBlockedOnKey(c, key)) {\n        updateStatsOnUnblock(c, 0, elapsedUs(replyTimer), server.stat_total_error_replies != prev_error_replies);\n        moduleUnblockClient(c);\n    }\n    /* We need to call afterCommand even if the client was not unblocked\n     * in order to propagate any changes that could have been done inside\n     * moduleTryServeClientBlockedOnKey */\n    afterCommand(c);\n    server.current_client = old_client;\n}\n\n/* Unblock a client which is currently Blocked on and provided a timeout.\n * The implementation will first reply to the blocked client with null response\n * or, in case of module blocked client the timeout callback will be used.\n * In this case since we might have a command pending\n * we want to remove the pending flag to indicate we already responded to the\n * command with timeout reply. */\nvoid unblockClientOnTimeout(client *c) {\n    /* The client has been unlocked (in the moduleUnblocked list), return ASAP. */\n    if (c->bstate.btype == BLOCKED_MODULE && isModuleClientUnblocked(c)) return;\n\n    replyToBlockedClientTimedOut(c);\n    if (c->flags & CLIENT_PENDING_COMMAND)\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n    unblockClient(c, 1);\n}\n\n/* Unblock a client which is currently Blocked with error.\n * If err_str is provided it will be used to reply to the blocked client */\nvoid unblockClientOnError(client *c, const char *err_str) {\n    if (err_str)\n        addReplyError(c, err_str);\n    updateStatsOnUnblock(c, 0, 0, 1);\n    if (c->flags & CLIENT_PENDING_COMMAND)\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n    unblockClient(c, 1);\n}\n\n/* sets blocking_keys to the total number of keys which has at least one client blocked on them\n * sets blocking_keys_on_nokey to the total number of keys which has at least one client\n * blocked on them to be written or deleted */\nvoid totalNumberOfBlockingKeys(unsigned long *blocking_keys, unsigned long *bloking_keys_on_nokey) {\n    unsigned long bkeys=0, bkeys_on_nokey=0;\n    for (int j = 0; j < server.dbnum; j++) {\n        bkeys += dictSize(server.db[j].blocking_keys);\n        bkeys_on_nokey += dictSize(server.db[j].blocking_keys_unblock_on_nokey);\n    }\n    if (blocking_keys)\n        *blocking_keys = bkeys;\n    if (bloking_keys_on_nokey)\n        *bloking_keys_on_nokey = bkeys_on_nokey;\n}\n\nvoid blockedBeforeSleep(void) {\n    /* Handle precise timeouts of blocked clients. */\n    handleBlockedClientsTimeout();\n\n    /* Unblock all the clients blocked for synchronous replication\n     * in WAIT or WAITAOF. */\n    if (listLength(server.clients_waiting_acks))\n        processClientsWaitingReplicas();\n\n    /* Try to process blocked clients every once in while.\n     *\n     * Example: A module calls RM_SignalKeyAsReady from within a timer callback\n     * (So we don't visit processCommand() at all).\n     *\n     * This may unblock clients, so must be done before processUnblockedClients */\n    handleClientsBlockedOnKeys();\n\n    /* Check if there are clients unblocked by modules that implement\n     * blocking commands. */\n    if (moduleCount())\n        moduleHandleBlockedClients();\n\n    /* Try to process pending commands for clients that were just unblocked. */\n    if (listLength(server.unblocked_clients))\n        processUnblockedClients();\n}\n"}, {"id": "0D641D5FC360FA87", "name": "notifyKeyspaceEvent", "path": "redis/src/notify.c", "start": {"line": 104, "col": 1}, "end": {"line": 145, "col": 1}, "code": "    sds chan;\n    robj *chanobj, *eventobj;\n    int len = -1;\n    char buf[24];\n\n    /* If any modules are interested in events, notify the module system now.\n     * This bypasses the notifications configuration, but the module engine\n     * will only call event subscribers if the event type matches the types\n     * they are interested in. */\n     moduleNotifyKeyspaceEvent(type, event, key, dbid);\n\n    /* If notifications for this class of events are off, return ASAP. */\n    if (!(server.notify_keyspace_events & type)) return;\n\n    eventobj = createStringObject(event,strlen(event));\n\n    /* __keyspace@<db>__:<key> <event> notifications. */\n    if (server.notify_keyspace_events & NOTIFY_KEYSPACE) {\n        chan = sdsnewlen(\"__keyspace@\",11);\n        len = ll2string(buf,sizeof(buf),dbid);\n        chan = sdscatlen(chan, buf, len);\n        chan = sdscatlen(chan, \"__:\", 3);\n        chan = sdscatsds(chan, key->ptr);\n        chanobj = createObject(OBJ_STRING, chan);\n        pubsubPublishMessage(chanobj, eventobj, 0);\n        decrRefCount(chanobj);\n    }\n\n    /* __keyevent@<db>__:<event> <key> notifications. */\n    if (server.notify_keyspace_events & NOTIFY_KEYEVENT) {\n        chan = sdsnewlen(\"__keyevent@\",11);\n        if (len == -1) len = ll2string(buf,sizeof(buf),dbid);\n        chan = sdscatlen(chan, buf, len);\n        chan = sdscatlen(chan, \"__:\", 3);\n        chan = sdscatsds(chan, eventobj->ptr);\n        chanobj = createObject(OBJ_STRING, chan);\n        pubsubPublishMessage(chanobj, key, 0);\n        decrRefCount(chanobj);\n    }\n    decrRefCount(eventobj);\n}\n"}], "code": "static void dbAddInternal(redisDb *db, robj *key, robj *val, int update_if_existing) {\n    dictEntry *existing;\n    int slot = getKeySlot(key->ptr);\n    dictEntry *de = kvstoreDictAddRaw(db->keys, slot, key->ptr, &existing);\n    if (update_if_existing && existing) {\n        dbSetValue(db, key, val, 1, existing);\n        return;\n    }\n    serverAssertWithInfo(NULL, key, de != NULL);\n    kvstoreDictSetKey(db->keys, slot, de, sdsdup(key->ptr));\n    initObjectLRUOrLFU(val);\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    signalKeyAsReady(db, key, val->type);\n    notifyKeyspaceEvent(NOTIFY_NEW,\"new\",key,db->id);\n}\n"}, "051CCB38BF73BF65": {"calls": [{"id": "EF3BB8EE8414CA75", "name": "getKeySlot", "path": "redis/src/db.c", "start": {"line": 222, "col": 1}, "end": {"line": 234, "col": 1}, "code": "    /* This is performance optimization that uses pre-set slot id from the current command,\n     * in order to avoid calculation of the key hash.\n     * This optimization is only used when current_client flag `CLIENT_EXECUTING_COMMAND` is set.\n     * It only gets set during the execution of command under `call` method. Other flows requesting\n     * the key slot would fallback to calculateKeySlot.\n     */\n    if (server.current_client && server.current_client->slot >= 0 && server.current_client->flags & CLIENT_EXECUTING_COMMAND) {\n        debugServerAssertWithInfo(server.current_client, NULL, calculateKeySlot(key)==server.current_client->slot);\n        return server.current_client->slot;\n    }\n    return calculateKeySlot(key);\n}\n\n/* This is a special version of dbAdd() that is used only when loading\n * keys from the RDB file: the key is passed as an SDS string that is\n * retained by the function (and not freed by the caller).\n *\n * Moreover this function will not abort if the key is already busy, to\n * give more control to the caller, nor will signal the key as ready\n * since it is not useful in this context.\n *\n * The function returns 1 if the key was added to the database, taking\n * ownership of the SDS string, otherwise 0 is returned, and is up to the\n * caller to free the SDS string. */\nint dbAddRDBLoad(redisDb *db, sds key, robj *val) {\n    int slot = getKeySlot(key);\n    dictEntry *de = kvstoreDictAddRaw(db->keys, slot, key, NULL);\n    if (de == NULL) return 0;\n    initObjectLRUOrLFU(val);\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    return 1;\n}\n\n/* Overwrite an existing key with a new value. Incrementing the reference\n * count of the new value is up to the caller.\n * This function does not modify the expire time of the existing key.\n *\n * The 'overwrite' flag is an indication whether this is done as part of a\n * complete replacement of their key, which can be thought as a deletion and\n * replacement (in which case we need to emit deletion signals), or just an\n * update of a value of an existing key (when false).\n *\n * The dictEntry input is optional, can be used if we already have one.\n *\n * The program is aborted if the key was not already present. */\nstatic void dbSetValue(redisDb *db, robj *key, robj *val, int overwrite, dictEntry *de) {\n    int slot = getKeySlot(key->ptr);\n    if (!de) de = kvstoreDictFind(db->keys, slot, key->ptr);\n    serverAssertWithInfo(NULL,key,de != NULL);\n    robj *old = dictGetVal(de);\n\n    val->lru = old->lru;\n\n    if (overwrite) {\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain old */\n        incrRefCount(old);\n        /* Although the key is not really deleted from the database, we regard\n         * overwrite as two steps of unlink+add, so we still need to call the unlink\n         * callback of the module. */\n        moduleNotifyKeyUnlink(key,old,db->id,DB_FLAG_KEY_OVERWRITE);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,old->type);\n        decrRefCount(old);\n        /* Because of RM_StringDMA, old may be changed, so we need get old again */\n        old = dictGetVal(de);\n    }\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    if (server.lazyfree_lazy_server_del) {\n        freeObjAsync(key,old,db->id);\n    } else {\n        decrRefCount(old);\n    }\n}\n\n/* Replace an existing key with a new value, we just replace value and don't\n * emit any events */\nvoid dbReplaceValue(redisDb *db, robj *key, robj *val) {\n    dbSetValue(db, key, val, 0, NULL);\n}\n\n/* High level Set operation. This function can be used in order to set\n * a key, whatever it was existing or not, to a new object.\n *\n * 1) The ref count of the value object is incremented.\n * 2) clients WATCHing for the destination key notified.\n * 3) The expire time of the key is reset (the key is made persistent),\n *    unless 'SETKEY_KEEPTTL' is enabled in flags.\n * 4) The key lookup can take place outside this interface outcome will be\n *    delivered with 'SETKEY_ALREADY_EXIST' or 'SETKEY_DOESNT_EXIST'\n *\n * All the new keys in the database should be created via this interface.\n * The client 'c' argument may be set to NULL if the operation is performed\n * in a context where there is no clear client performing the operation. */\nvoid setKey(client *c, redisDb *db, robj *key, robj *val, int flags) {\n    int keyfound = 0;\n\n    if (flags & SETKEY_ALREADY_EXIST)\n        keyfound = 1;\n    else if (flags & SETKEY_ADD_OR_UPDATE)\n        keyfound = -1;\n    else if (!(flags & SETKEY_DOESNT_EXIST))\n        keyfound = (lookupKeyWrite(db,key) != NULL);\n\n    if (!keyfound) {\n        dbAdd(db,key,val);\n    } else if (keyfound<0) {\n        dbAddInternal(db,key,val,1);\n    } else {\n        dbSetValue(db,key,val,1,NULL);\n    }\n    incrRefCount(val);\n    if (!(flags & SETKEY_KEEPTTL)) removeExpire(db,key);\n    if (!(flags & SETKEY_NO_SIGNAL)) signalModifiedKey(c,db,key);\n}\n\n/* Return a random key, in form of a Redis object.\n * If there are no keys, NULL is returned.\n *\n * The function makes sure to return keys not already expired. */\nrobj *dbRandomKey(redisDb *db) {\n    dictEntry *de;\n    int maxtries = 100;\n    int allvolatile = kvstoreSize(db->keys) == kvstoreSize(db->expires);\n\n    while(1) {\n        sds key;\n        robj *keyobj;\n        int randomSlot = kvstoreGetFairRandomDictIndex(db->keys);\n        de = kvstoreDictGetFairRandomKey(db->keys, randomSlot);\n        if (de == NULL) return NULL;\n\n        key = dictGetKey(de);\n        keyobj = createStringObject(key,sdslen(key));\n        if (dbFindExpires(db, key)) {\n            if (allvolatile && server.masterhost && --maxtries == 0) {\n                /* If the DB is composed only of keys with an expire set,\n                 * it could happen that all the keys are already logically\n                 * expired in the slave, so the function cannot stop because\n                 * expireIfNeeded() is false, nor it can stop because\n                 * dictGetFairRandomKey() returns NULL (there are keys to return).\n                 * To prevent the infinite loop we do some tries, but if there\n                 * are the conditions for an infinite loop, eventually we\n                 * return a key name that may be already expired. */\n                return keyobj;\n            }\n            if (expireIfNeeded(db,keyobj,0)) {\n                decrRefCount(keyobj);\n                continue; /* search for another key. This expired. */\n            }\n        }\n        return keyobj;\n    }\n}\n\n/* Helper for sync and async delete. */\nint dbGenericDelete(redisDb *db, robj *key, int async, int flags) {\n    dictEntry **plink;\n    int table;\n    int slot = getKeySlot(key->ptr);\n    dictEntry *de = kvstoreDictTwoPhaseUnlinkFind(db->keys, slot, key->ptr, &plink, &table);\n    if (de) {\n        robj *val = dictGetVal(de);\n        /* RM_StringDMA may call dbUnshareStringValue which may free val, so we\n         * need to incr to retain val */\n        incrRefCount(val);\n        /* Tells the module that the key has been unlinked from the database. */\n        moduleNotifyKeyUnlink(key,val,db->id,flags);\n        /* We want to try to unblock any module clients or clients using a blocking XREADGROUP */\n        signalDeletedKeyAsReady(db,key,val->type);\n        /* We should call decr before freeObjAsync. If not, the refcount may be\n         * greater than 1, so freeObjAsync doesn't work */\n        decrRefCount(val);\n        if (async) {\n            /* Because of dbUnshareStringValue, the val in de may change. */\n            freeObjAsync(key, dictGetVal(de), db->id);\n            kvstoreDictSetVal(db->keys, slot, de, NULL);\n        }\n        /* Deleting an entry from the expires dict will not free the sds of\n         * the key, because it is shared with the main dictionary. */\n        kvstoreDictDelete(db->expires, slot, key->ptr);\n\n        kvstoreDictTwoPhaseUnlinkFree(db->keys, slot, de, plink, table);\n        return 1;\n    } else {\n        return 0;\n    }\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB */\nint dbSyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 0, DB_FLAG_KEY_DELETED);\n}\n\n/* Delete a key, value, and associated expiration entry if any, from the DB. If\n * the value consists of many allocations, it may be freed asynchronously. */\nint dbAsyncDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, 1, DB_FLAG_KEY_DELETED);\n}\n\n/* This is a wrapper whose behavior depends on the Redis lazy free\n * configuration. Deletes the key synchronously or asynchronously. */\nint dbDelete(redisDb *db, robj *key) {\n    return dbGenericDelete(db, key, server.lazyfree_lazy_server_del, DB_FLAG_KEY_DELETED);\n}\n\n/* Prepare the string object stored at 'key' to be modified destructively\n * to implement commands like SETBIT or APPEND.\n *\n * An object is usually ready to be modified unless one of the two conditions\n * are true:\n *\n * 1) The object 'o' is shared (refcount > 1), we don't want to affect\n *    other users.\n * 2) The object encoding is not \"RAW\".\n *\n * If the object is found in one of the above conditions (or both) by the\n * function, an unshared / not-encoded copy of the string object is stored\n * at 'key' in the specified 'db'. Otherwise the object 'o' itself is\n * returned.\n *\n * USAGE:\n *\n * The object 'o' is what the caller already obtained by looking up 'key'\n * in 'db', the usage pattern looks like this:\n *\n * o = lookupKeyWrite(db,key);\n * if (checkType(c,o,OBJ_STRING)) return;\n * o = dbUnshareStringValue(db,key,o);\n *\n * At this point the caller is ready to modify the object, for example\n * using an sdscat() call to append some data, or anything else.\n */\nrobj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) {\n    serverAssert(o->type == OBJ_STRING);\n"}, {"id": "505C547C33FE1EEC", "name": "initObjectLRUOrLFU", "path": "redis/src/object.c", "start": {"line": 53, "col": 1}, "end": {"line": 64, "col": 1}, "code": "    if (o->refcount == OBJ_SHARED_REFCOUNT)\n        return;\n    /* Set the LRU to the current lruclock (minutes resolution), or\n     * alternatively the LFU counter. */\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {\n        o->lru = (LFUGetTimeInMinutes() << 8) | LFU_INIT_VAL;\n    } else {\n        o->lru = LRU_CLOCK();\n    }\n    return;\n}\n\n/* Set a special refcount in the object to make it \"shared\":\n * incrRefCount and decrRefCount() will test for this special refcount\n * and will not touch the object. This way it is free to access shared\n * objects such as small integers from different threads without any\n * mutex.\n *\n * A common pattern to create shared objects:\n *\n * robj *myobject = makeObjectShared(createObject(...));\n *\n */\nrobj *makeObjectShared(robj *o) {\n    serverAssert(o->refcount == 1);\n    o->refcount = OBJ_SHARED_REFCOUNT;\n    return o;\n}\n\n/* Create a string object with encoding OBJ_ENCODING_RAW, that is a plain\n * string object where o->ptr points to a proper sds string. */\nrobj *createRawStringObject(const char *ptr, size_t len) {\n    return createObject(OBJ_STRING, sdsnewlen(ptr,len));\n}\n\n/* Create a string object with encoding OBJ_ENCODING_EMBSTR, that is\n * an object where the sds string is actually an unmodifiable string\n * allocated in the same chunk as the object itself. */\nrobj *createEmbeddedStringObject(const char *ptr, size_t len) {\n    robj *o = zmalloc(sizeof(robj)+sizeof(struct sdshdr8)+len+1);\n    struct sdshdr8 *sh = (void*)(o+1);\n\n    o->type = OBJ_STRING;\n    o->encoding = OBJ_ENCODING_EMBSTR;\n    o->ptr = sh+1;\n    o->refcount = 1;\n    o->lru = 0;\n\n    sh->len = len;\n    sh->alloc = len;\n    sh->flags = SDS_TYPE_8;\n    if (ptr == SDS_NOINIT)\n        sh->buf[len] = '\\0';\n    else if (ptr) {\n        memcpy(sh->buf,ptr,len);\n        sh->buf[len] = '\\0';\n    } else {\n        memset(sh->buf,0,len+1);\n    }\n    return o;\n}\n\n/* Create a string object with EMBSTR encoding if it is smaller than\n * OBJ_ENCODING_EMBSTR_SIZE_LIMIT, otherwise the RAW encoding is\n * used.\n"}, {"id": "5062C754DD8A1D07", "name": "kvstoreDictSetVal", "path": "redis/src/kvstore.c", "start": {"line": 751, "col": 1}, "end": {"line": 754, "col": 1}, "code": "    dict *d = kvstoreGetDict(kvs, didx);\n    dictSetVal(d, de, val);\n}\n\ndictEntry *kvstoreDictTwoPhaseUnlinkFind(kvstore *kvs, int didx, const void *key, dictEntry ***plink, int *table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return NULL;\n    return dictTwoPhaseUnlinkFind(kvstoreGetDict(kvs, didx), key, plink, table_index);\n}\n\nvoid kvstoreDictTwoPhaseUnlinkFree(kvstore *kvs, int didx, dictEntry *he, dictEntry **plink, int table_index) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    dictTwoPhaseUnlinkFree(d, he, plink, table_index);\n    cumulativeKeyCountAdd(kvs, didx, -1);\n    freeDictIfNeeded(kvs, didx);\n}\n\nint kvstoreDictDelete(kvstore *kvs, int didx, const void *key) {\n    dict *d = kvstoreGetDict(kvs, didx);\n    if (!d)\n        return DICT_ERR;\n    int ret = dictDelete(kvstoreGetDict(kvs, didx), key);\n    if (ret == DICT_OK) {\n        cumulativeKeyCountAdd(kvs, didx, -1);\n        freeDictIfNeeded(kvs, didx);\n    }\n    return ret;\n}\n"}], "code": "int dbAddRDBLoad(redisDb *db, sds key, robj *val) {\n    int slot = getKeySlot(key);\n    dictEntry *de = kvstoreDictAddRaw(db->keys, slot, key, NULL);\n    if (de == NULL) return 0;\n    initObjectLRUOrLFU(val);\n    kvstoreDictSetVal(db->keys, slot, de, val);\n    return 1;\n}\n"}, "3676B55A0684B8C4": {"calls": [{"id": "246E283E527B4A81", "name": "listAddNodeTail", "path": "redis/src/adlist.c", "start": {"line": 124, "col": 1}, "end": {"line": 133, "col": 1}, "code": "{\n    listNode *node;\n\n    if ((node = zmalloc(sizeof(*node))) == NULL)\n        return NULL;\n    node->value = value;\n    listLinkNodeTail(list, node);\n    return list;\n}\n\n/*\n * Add a node that has already been allocated to the tail of list\n */\nvoid listLinkNodeTail(list *list, listNode *node) {\n    if (list->len == 0) {\n        list->head = list->tail = node;\n        node->prev = node->next = NULL;\n    } else {\n        node->prev = list->tail;\n        node->next = NULL;\n        list->tail->next = node;\n        list->tail = node;\n    }\n    list->len++;\n}\n\nlist *listInsertNode(list *list, listNode *old_node, void *value, int after) {\n    listNode *node;\n\n    if ((node = zmalloc(sizeof(*node))) == NULL)\n        return NULL;\n    node->value = value;\n    if (after) {\n        node->prev = old_node;\n        node->next = old_node->next;\n        if (list->tail == old_node) {\n            list->tail = node;\n        }\n    } else {\n        node->next = old_node;\n        node->prev = old_node->prev;\n        if (list->head == old_node) {\n            list->head = node;\n        }\n    }\n    if (node->prev != NULL) {\n        node->prev->next = node;\n    }\n    if (node->next != NULL) {\n        node->next->prev = node;\n    }\n    list->len++;\n    return list;\n}\n\n/* Remove the specified node from the specified list.\n * The node is freed. If free callback is provided the value is freed as well.\n *\n * This function can't fail. */\nvoid listDelNode(list *list, listNode *node)\n{\n    listUnlinkNode(list, node);\n    if (list->free) list->free(node->value);\n    zfree(node);\n}\n\n/*\n * Remove the specified node from the list without freeing it.\n */\nvoid listUnlinkNode(list *list, listNode *node) {\n    if (node->prev)\n        node->prev->next = node->next;\n    else\n        list->head = node->next;\n    if (node->next)\n        node->next->prev = node->prev;\n    else\n        list->tail = node->prev;\n\n    node->next = NULL;\n    node->prev = NULL;\n\n    list->len--;\n}\n\n/* Returns a list iterator 'iter'. After the initialization every\n * call to listNext() will return the next element of the list.\n *\n * This function can't fail. */\nlistIter *listGetIterator(list *list, int direction)\n{\n    listIter *iter;\n\n    if ((iter = zmalloc(sizeof(*iter))) == NULL) return NULL;\n    if (direction == AL_START_HEAD)\n        iter->next = list->head;\n    else\n        iter->next = list->tail;\n    iter->direction = direction;\n    return iter;\n}\n\n/* Release the iterator memory */\nvoid listReleaseIterator(listIter *iter) {\n    zfree(iter);\n}\n\n/* Create an iterator in the list private iterator structure */\nvoid listRewind(list *list, listIter *li) {\n    li->next = list->head;\n    li->direction = AL_START_HEAD;\n}\n\nvoid listRewindTail(list *list, listIter *li) {\n    li->next = list->tail;\n    li->direction = AL_START_TAIL;\n}\n\n/* Return the next element of an iterator.\n * It's valid to remove the currently returned element using\n * listDelNode(), but not to remove other elements.\n *\n * The function returns a pointer to the next element of the list,\n * or NULL if there are no more elements, so the classical usage\n * pattern is:\n *\n * iter = listGetIterator(list,<direction>);\n * while ((node = listNext(iter)) != NULL) {\n *     doSomethingWith(listNodeValue(node));\n * }\n *\n * */\nlistNode *listNext(listIter *iter)\n{\n"}, {"id": "2F6791789BCEDFFA", "name": "dictRehashingInfo", "path": "redis/src/dict.c", "start": {"line": 1632, "col": 1}, "end": {"line": 1637, "col": 1}, "code": "    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n\n/* ------------------------------- Debugging ---------------------------------*/\n#define DICT_STATS_VECTLEN 50\nvoid dictFreeStats(dictStats *stats) {\n    zfree(stats->clvector);\n    zfree(stats);\n}\n\nvoid dictCombineStats(dictStats *from, dictStats *into) {\n    into->buckets += from->buckets;\n    into->maxChainLen = (from->maxChainLen > into->maxChainLen) ? from->maxChainLen : into->maxChainLen;\n    into->totalChainLen += from->totalChainLen;\n    into->htSize += from->htSize;\n    into->htUsed += from->htUsed;\n    for (int i = 0; i < DICT_STATS_VECTLEN; i++) {\n        into->clvector[i] += from->clvector[i];\n    }\n}\n\ndictStats *dictGetStatsHt(dict *d, int htidx, int full) {\n    unsigned long *clvector = zcalloc(sizeof(unsigned long) * DICT_STATS_VECTLEN);\n    dictStats *stats = zcalloc(sizeof(dictStats));\n    stats->htidx = htidx;\n    stats->clvector = clvector;\n    stats->htSize = DICTHT_SIZE(d->ht_size_exp[htidx]);\n    stats->htUsed = d->ht_used[htidx];\n    if (!full) return stats;\n    /* Compute stats. */\n    for (unsigned long i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]); i++) {\n        dictEntry *he;\n\n        if (d->ht_table[htidx][i] == NULL) {\n            clvector[0]++;\n            continue;\n        }\n        stats->buckets++;\n        /* For each hash entry on this slot... */\n        unsigned long chainlen = 0;\n        he = d->ht_table[htidx][i];\n        while(he) {\n            chainlen++;\n            he = dictGetNext(he);\n        }\n        clvector[(chainlen < DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++;\n        if (chainlen > stats->maxChainLen) stats->maxChainLen = chainlen;\n        stats->totalChainLen += chainlen;\n    }\n\n    return stats;\n}\n\n/* Generates human readable stats. */\nsize_t dictGetStatsMsg(char *buf, size_t bufsize, dictStats *stats, int full) {\n    if (stats->htUsed == 0) {\n        return snprintf(buf,bufsize,\n            \"Hash table %d stats (%s):\\n\"\n            \"No stats available for empty dictionaries\\n\",\n            stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\");\n    }\n    size_t l = 0;\n    l += snprintf(buf + l, bufsize - l,\n                  \"Hash table %d stats (%s):\\n\"\n                  \" table size: %lu\\n\"\n                  \" number of elements: %lu\\n\",\n                  stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\",\n                  stats->htSize, stats->htUsed);\n    if (full) {\n        l += snprintf(buf + l, bufsize - l,\n                      \" different slots: %lu\\n\"\n                      \" max chain length: %lu\\n\"\n                      \" avg chain length (counted): %.02f\\n\"\n                      \" avg chain length (computed): %.02f\\n\"\n                      \" Chain length distribution:\\n\",\n                      stats->buckets, stats->maxChainLen,\n                      (float) stats->totalChainLen / stats->buckets, (float) stats->htUsed / stats->buckets);\n\n        for (unsigned long i = 0; i < DICT_STATS_VECTLEN - 1; i++) {\n            if (stats->clvector[i] == 0) continue;\n            if (l >= bufsize) break;\n            l += snprintf(buf + l, bufsize - l,\n                          \"   %ld: %ld (%.02f%%)\\n\",\n                          i, stats->clvector[i], ((float) stats->clvector[i] / stats->htSize) * 100);\n        }\n    }\n\n    /* Make sure there is a NULL term at the end. */\n    buf[bufsize-1] = '\\0';\n    /* Unlike snprintf(), return the number of characters actually written. */\n    return strlen(buf);\n}\n\nvoid dictGetStats(char *buf, size_t bufsize, dict *d, int full) {\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n\n    dictStats *mainHtStats = dictGetStatsHt(d, 0, full);\n    l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n    dictFreeStats(mainHtStats);\n    buf += l;\n    bufsize -= l;\n    if (dictIsRehashing(d) && bufsize > 0) {\n        dictStats *rehashHtStats = dictGetStatsHt(d, 1, full);\n        dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n    }\n    /* Make sure there is a NULL term at the end. */\n    orig_buf[orig_bufsize-1] = '\\0';\n}\n\n/* ------------------------------- Benchmark ---------------------------------*/\n\n#ifdef REDIS_TEST\n#include \"testhelp.h\"\n\n#define UNUSED(V) ((void) V)\n#define TEST(name) printf(\"test \u2014 %s\\n\", name);\n\nuint64_t hashCallback(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\nint compareCallback(dict *d, const void *key1, const void *key2) {\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = strlen((char*)key1);\n    l2 = strlen((char*)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\nvoid freeCallback(dict *d, void *val) {\n    UNUSED(d);\n\n    zfree(val);\n}\n\nchar *stringFromLongLong(long long value) {\n    char buf[32];\n    int len;\n    char *s;\n\n    len = snprintf(buf,sizeof(buf),\"%lld\",value);\n    s = zmalloc(len+1);\n    memcpy(s, buf, len);\n    s[len] = '\\0';\n    return s;\n}\n\ndictType BenchmarkDictType = {\n    hashCallback,\n    NULL,\n    NULL,\n    compareCallback,\n    freeCallback,\n    NULL,\n    NULL\n};\n\n#define start_benchmark() start = timeInMilliseconds()\n#define end_benchmark(msg) do { \\\n    elapsed = timeInMilliseconds()-start; \\\n    printf(msg \": %ld items in %lld ms\\n\", count, elapsed); \\\n} while(0)\n\n/* ./redis-server test dict [<count> | --accurate] */\nint dictTest(int argc, char **argv, int flags) {\n    long j;\n    long long start, elapsed;\n    int retval;\n    dict *dict = dictCreate(&BenchmarkDictType);\n    long count = 0;\n    unsigned long new_dict_size, current_dict_used, remain_keys;\n    int accurate = (flags & REDIS_TEST_ACCURATE);\n\n    if (argc == 4) {\n        if (accurate) {\n            count = 5000000;\n        } else {\n            count = strtol(argv[3],NULL,10);\n        }\n    } else {\n        count = 5000;\n    }\n\n    TEST(\"Add 16 keys and verify dict resize is ok\") {\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        for (j = 0; j < 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 16);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and pad to (dict_force_resize_ratio * 16)\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict resize, and pad\n         * the number of keys to (dict_force_resize_ratio * 16), so we can satisfy\n         * dict_force_resize_ratio in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        for (j = 16; j < (long)dict_force_resize_ratio * 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = dict_force_resize_ratio * 16;\n        assert(dictSize(dict) == current_dict_used);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Add one more key, trigger the dict resize\") {\n        retval = dictAdd(dict,stringFromLongLong(current_dict_used),(void*)(current_dict_used));\n        assert(retval == DICT_OK);\n        current_dict_used++;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 16);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete keys until we can trigger shrink in next test\") {\n        /* Delete keys until we can satisfy (1 / HASHTABLE_MIN_FILL) in the next test. */\n        for (j = new_dict_size / HASHTABLE_MIN_FILL + 1; j < (long)current_dict_used; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = new_dict_size / HASHTABLE_MIN_FILL + 1;\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        unsigned long oldDictSize = new_dict_size;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == oldDictSize);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Empty the dictionary and add 128 keys\") {\n        dictEmpty(dict, NULL);\n        for (j = 0; j < 128; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 128);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and reduce to 3\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict reset, and reduce\n         * the number of keys until we can trigger shrinking in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        remain_keys = DICTHT_SIZE(dict->ht_size_exp[0]) / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) + 1;\n        for (j = remain_keys; j < 128; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = remain_keys;\n        assert(dictSize(dict) == remain_keys);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 128);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Restore to original state\") {\n        dictEmpty(dict, NULL);\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n        assert(retval == DICT_OK);\n    }\n    end_benchmark(\"Inserting\");\n    assert((long)dictSize(dict) == count);\n\n    /* Wait for rehashing. */\n    while (dictIsRehashing(dict)) {\n        dictRehashMicroseconds(dict,100*1000);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Linear access of existing elements\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Linear access of existing elements (2nd round)\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(rand() % count);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Random access of existing elements\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        dictEntry *de = dictGetRandomKey(dict);\n        assert(de != NULL);\n    }\n    end_benchmark(\"Accessing random keys\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(rand() % count);\n        key[0] = 'X';\n        dictEntry *de = dictFind(dict,key);\n        assert(de == NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Accessing missing\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        retval = dictDelete(dict,key);\n        assert(retval == DICT_OK);\n        key[0] += 17; /* Change first number to letter. */\n        retval = dictAdd(dict,key,(void*)j);\n        assert(retval == DICT_OK);\n    }\n    end_benchmark(\"Removing and adding\");\n    dictRelease(dict);\n    return 0;\n}\n#endif\n"}], "code": "static void kvstoreDictRehashingStarted(dict *d) {\n    kvstore *kvs = d->type->userdata;\n    kvstoreDictMetadata *metadata = (kvstoreDictMetadata *)dictMetadata(d);\n    listAddNodeTail(kvs->rehashing, d);\n    metadata->rehashing_node = listLast(kvs->rehashing);\n\n    if (kvs->num_dicts == 1)\n        return;\n    unsigned long long from, to;\n    dictRehashingInfo(d, &from, &to);\n    kvs->bucket_count += to; /* Started rehashing (Add the new ht size) */\n}\n"}, "235340703317EEF1": {"calls": [{"id": "6092E10D5242AB2C", "name": "dictResetIterator", "path": "redis/src/dict.c", "start": {"line": 977, "col": 1}, "end": {"line": 985, "col": 1}, "code": "{\n    if (!(iter->index == -1 && iter->table == 0)) {\n        if (iter->safe)\n            dictResumeRehashing(iter->d);\n        else\n            assert(iter->fingerprint == dictFingerprint(iter->d));\n    }\n}\n\ndictIterator *dictGetIterator(dict *d)\n{\n    dictIterator *iter = zmalloc(sizeof(*iter));\n    dictInitIterator(iter, d);\n    return iter;\n}\n\ndictIterator *dictGetSafeIterator(dict *d) {\n    dictIterator *i = dictGetIterator(d);\n\n    i->safe = 1;\n    return i;\n}\n\ndictEntry *dictNext(dictIterator *iter)\n{\n    while (1) {\n        if (iter->entry == NULL) {\n            if (iter->index == -1 && iter->table == 0) {\n                if (iter->safe)\n                    dictPauseRehashing(iter->d);\n                else\n                    iter->fingerprint = dictFingerprint(iter->d);\n\n                /* skip the rehashed slots in table[0] */\n                if (dictIsRehashing(iter->d)) {\n                    iter->index = iter->d->rehashidx - 1;\n                }\n            }\n            iter->index++;\n            if (iter->index >= (long) DICTHT_SIZE(iter->d->ht_size_exp[iter->table])) {\n                if (dictIsRehashing(iter->d) && iter->table == 0) {\n                    iter->table++;\n                    iter->index = 0;\n                } else {\n                    break;\n                }\n            }\n            iter->entry = iter->d->ht_table[iter->table][iter->index];\n        } else {\n            iter->entry = iter->nextEntry;\n        }\n        if (iter->entry) {\n            /* We need to save the 'next' here, the iterator user\n             * may delete the entry we are returning. */\n            iter->nextEntry = dictGetNext(iter->entry);\n            return iter->entry;\n        }\n    }\n    return NULL;\n}\n\nvoid dictReleaseIterator(dictIterator *iter)\n{\n    dictResetIterator(iter);\n    zfree(iter);\n}\n\n/* Return a random entry from the hash table. Useful to\n * implement randomized algorithms */\ndictEntry *dictGetRandomKey(dict *d)\n{\n    dictEntry *he, *orighe;\n    unsigned long h;\n    int listlen, listele;\n\n    if (dictSize(d) == 0) return NULL;\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    if (dictIsRehashing(d)) {\n        unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n        do {\n            /* We are sure there are no elements in indexes from 0\n             * to rehashidx-1 */\n            h = d->rehashidx + (randomULong() % (dictBuckets(d) - d->rehashidx));\n            he = (h >= s0) ? d->ht_table[1][h - s0] : d->ht_table[0][h];\n        } while(he == NULL);\n    } else {\n        unsigned long m = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n        do {\n            h = randomULong() & m;\n            he = d->ht_table[0][h];\n        } while(he == NULL);\n    }\n\n    /* Now we found a non empty bucket, but it is a linked\n     * list and we need to get a random element from the list.\n     * The only sane way to do so is counting the elements and\n     * select a random index. */\n    listlen = 0;\n    orighe = he;\n    while(he) {\n        he = dictGetNext(he);\n        listlen++;\n    }\n    listele = random() % listlen;\n    he = orighe;\n    while(listele--) he = dictGetNext(he);\n    return he;\n}\n\n/* This function samples the dictionary to return a few keys from random\n * locations.\n *\n * It does not guarantee to return all the keys specified in 'count', nor\n * it does guarantee to return non-duplicated elements, however it will make\n * some effort to do both things.\n *\n * Returned pointers to hash table entries are stored into 'des' that\n * points to an array of dictEntry pointers. The array must have room for\n * at least 'count' elements, that is the argument we pass to the function\n * to tell how many random elements we need.\n *\n * The function returns the number of items stored into 'des', that may\n * be less than 'count' if the hash table has less than 'count' elements\n * inside, or if not enough elements were found in a reasonable amount of\n * steps.\n *\n * Note that this function is not suitable when you need a good distribution\n * of the returned items, but only when you need to \"sample\" a given number\n * of continuous elements to run some kind of algorithm or to produce\n * statistics. However the function is much faster than dictGetRandomKey()\n * at producing N elements. */\nunsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) {\n    unsigned long j; /* internal hash table id, 0 or 1. */\n    unsigned long tables; /* 1 or 2 tables? */\n    unsigned long stored = 0, maxsizemask;\n    unsigned long maxsteps;\n\n    if (dictSize(d) < count) count = dictSize(d);\n    maxsteps = count*10;\n\n    /* Try to do a rehashing work proportional to 'count'. */\n    for (j = 0; j < count; j++) {\n        if (dictIsRehashing(d))\n            _dictRehashStep(d);\n        else\n            break;\n    }\n\n    tables = dictIsRehashing(d) ? 2 : 1;\n    maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n    if (tables > 1 && maxsizemask < DICTHT_SIZE_MASK(d->ht_size_exp[1]))\n        maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n\n    /* Pick a random point inside the larger table. */\n    unsigned long i = randomULong() & maxsizemask;\n    unsigned long emptylen = 0; /* Continuous empty entries so far. */\n    while(stored < count && maxsteps--) {\n        for (j = 0; j < tables; j++) {\n            /* Invariant of the dict.c rehashing: up to the indexes already\n             * visited in ht[0] during the rehashing, there are no populated\n             * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */\n            if (tables == 2 && j == 0 && i < (unsigned long) d->rehashidx) {\n                /* Moreover, if we are currently out of range in the second\n                 * table, there will be no elements in both tables up to\n                 * the current rehashing index, so we jump if possible.\n                 * (this happens when going from big to small table). */\n                if (i >= DICTHT_SIZE(d->ht_size_exp[1]))\n                    i = d->rehashidx;\n                else\n                    continue;\n            }\n            if (i >= DICTHT_SIZE(d->ht_size_exp[j])) continue; /* Out of range for this table. */\n            dictEntry *he = d->ht_table[j][i];\n\n            /* Count contiguous empty buckets, and jump to other\n             * locations if they reach 'count' (with a minimum of 5). */\n            if (he == NULL) {\n                emptylen++;\n                if (emptylen >= 5 && emptylen > count) {\n                    i = randomULong() & maxsizemask;\n                    emptylen = 0;\n                }\n            } else {\n                emptylen = 0;\n                while (he) {\n                    /* Collect all the elements of the buckets found non empty while iterating.\n                     * To avoid the issue of being unable to sample the end of a long chain,\n                     * we utilize the Reservoir Sampling algorithm to optimize the sampling process.\n                     * This means that even when the maximum number of samples has been reached,\n                     * we continue sampling until we reach the end of the chain.\n                     * See https://en.wikipedia.org/wiki/Reservoir_sampling. */\n                    if (stored < count) {\n                        des[stored] = he;\n                    } else {\n                        unsigned long r = randomULong() % (stored + 1);\n                        if (r < count) des[r] = he;\n                    }\n\n                    he = dictGetNext(he);\n                    stored++;\n                }\n                if (stored >= count) goto end;\n            }\n        }\n        i = (i+1) & maxsizemask;\n    }\n\nend:\n    return stored > count ? count : stored;\n}\n\n\n/* Reallocate the dictEntry, key and value allocations in a bucket using the\n * provided allocation functions in order to defrag them. */\nstatic void dictDefragBucket(dictEntry **bucketref, dictDefragFunctions *defragfns) {\n    dictDefragAllocFunction *defragalloc = defragfns->defragAlloc;\n    dictDefragAllocFunction *defragkey = defragfns->defragKey;\n    dictDefragAllocFunction *defragval = defragfns->defragVal;\n    while (bucketref && *bucketref) {\n        dictEntry *de = *bucketref, *newde = NULL;\n        void *newkey = defragkey ? defragkey(dictGetKey(de)) : NULL;\n        void *newval = defragval ? defragval(dictGetVal(de)) : NULL;\n        if (entryIsKey(de)) {\n            if (newkey) *bucketref = newkey;\n            assert(entryIsKey(*bucketref));\n        } else if (entryIsNoValue(de)) {\n            dictEntryNoValue *entry = decodeEntryNoValue(de), *newentry;\n            if ((newentry = defragalloc(entry))) {\n                newde = encodeMaskedPtr(newentry, ENTRY_PTR_NO_VALUE);\n                entry = newentry;\n            }\n            if (newkey) entry->key = newkey;\n        } else {\n            assert(entryIsNormal(de));\n            newde = defragalloc(de);\n            if (newde) de = newde;\n            if (newkey) de->key = newkey;\n            if (newval) de->v.val = newval;\n        }\n        if (newde) {\n            *bucketref = newde;\n        }\n        bucketref = dictGetNextRef(*bucketref);\n    }\n}\n\n/* This is like dictGetRandomKey() from the POV of the API, but will do more\n * work to ensure a better distribution of the returned element.\n *\n * This function improves the distribution because the dictGetRandomKey()\n * problem is that it selects a random bucket, then it selects a random\n * element from the chain in the bucket. However elements being in different\n * chain lengths will have different probabilities of being reported. With\n * this function instead what we do is to consider a \"linear\" range of the table\n * that may be constituted of N buckets with chains of different lengths\n * appearing one after the other. Then we report a random element in the range.\n * In this way we smooth away the problem of different chain lengths. */\n#define GETFAIR_NUM_ENTRIES 15\ndictEntry *dictGetFairRandomKey(dict *d) {\n    dictEntry *entries[GETFAIR_NUM_ENTRIES];\n    unsigned int count = dictGetSomeKeys(d,entries,GETFAIR_NUM_ENTRIES);\n    /* Note that dictGetSomeKeys() may return zero elements in an unlucky\n     * run() even if there are actually elements inside the hash table. So\n     * when we get zero, we call the true dictGetRandomKey() that will always\n     * yield the element if the hash table has at least one. */\n    if (count == 0) return dictGetRandomKey(d);\n    unsigned int idx = rand() % count;\n    return entries[idx];\n}\n\n/* Function to reverse bits. Algorithm from:\n * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */\nstatic unsigned long rev(unsigned long v) {\n    unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2\n    unsigned long mask = ~0UL;\n    while ((s >>= 1) > 0) {\n        mask ^= (mask << s);\n        v = ((v >> s) & mask) | ((v << s) & ~mask);\n    }\n    return v;\n}\n\n/* dictScan() is used to iterate over the elements of a dictionary.\n *\n * Iterating works the following way:\n *\n * 1) Initially you call the function using a cursor (v) value of 0.\n * 2) The function performs one step of the iteration, and returns the\n *    new cursor value you must use in the next call.\n * 3) When the returned cursor is 0, the iteration is complete.\n *\n * The function guarantees all elements present in the\n * dictionary get returned between the start and end of the iteration.\n * However it is possible some elements get returned multiple times.\n *\n * For every element returned, the callback argument 'fn' is\n * called with 'privdata' as first argument and the dictionary entry\n * 'de' as second argument.\n *\n * HOW IT WORKS.\n *\n * The iteration algorithm was designed by Pieter Noordhuis.\n * The main idea is to increment a cursor starting from the higher order\n * bits. That is, instead of incrementing the cursor normally, the bits\n * of the cursor are reversed, then the cursor is incremented, and finally\n * the bits are reversed again.\n *\n * This strategy is needed because the hash table may be resized between\n * iteration calls.\n *\n * dict.c hash tables are always power of two in size, and they\n * use chaining, so the position of an element in a given table is given\n * by computing the bitwise AND between Hash(key) and SIZE-1\n * (where SIZE-1 is always the mask that is equivalent to taking the rest\n *  of the division between the Hash of the key and SIZE).\n *\n * For example if the current hash table size is 16, the mask is\n * (in binary) 1111. The position of a key in the hash table will always be\n * the last four bits of the hash output, and so forth.\n *\n * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE?\n *\n * If the hash table grows, elements can go anywhere in one multiple of\n * the old bucket: for example let's say we already iterated with\n * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16).\n *\n * If the hash table will be resized to 64 elements, then the new mask will\n * be 111111. The new buckets you obtain by substituting in ??1100\n * with either 0 or 1 can be targeted only by keys we already visited\n * when scanning the bucket 1100 in the smaller hash table.\n *\n * By iterating the higher bits first, because of the inverted counter, the\n * cursor does not need to restart if the table size gets bigger. It will\n * continue iterating using cursors without '1100' at the end, and also\n * without any other combination of the final 4 bits already explored.\n *\n * Similarly when the table size shrinks over time, for example going from\n * 16 to 8, if a combination of the lower three bits (the mask for size 8\n * is 111) were already completely explored, it would not be visited again\n * because we are sure we tried, for example, both 0111 and 1111 (all the\n * variations of the higher bit) so we don't need to test it again.\n *\n * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING!\n *\n * Yes, this is true, but we always iterate the smaller table first, then\n * we test all the expansions of the current cursor into the larger\n * table. For example if the current cursor is 101 and we also have a\n * larger table of size 16, we also test (0)101 and (1)101 inside the larger\n * table. This reduces the problem back to having only one table, where\n * the larger one, if it exists, is just an expansion of the smaller one.\n *\n * LIMITATIONS\n *\n * This iterator is completely stateless, and this is a huge advantage,\n * including no additional memory used.\n *\n * The disadvantages resulting from this design are:\n *\n * 1) It is possible we return elements more than once. However this is usually\n *    easy to deal with in the application level.\n * 2) The iterator must return multiple elements per call, as it needs to always\n *    return all the keys chained in a given bucket, and all the expansions, so\n *    we are sure we don't miss keys moving during rehashing.\n * 3) The reverse cursor is somewhat hard to understand at first, but this\n *    comment is supposed to help.\n */\nunsigned long dictScan(dict *d,\n                       unsigned long v,\n                       dictScanFunction *fn,\n                       void *privdata)\n{\n    return dictScanDefrag(d, v, fn, NULL, privdata);\n}\n\n/* Like dictScan, but additionally reallocates the memory used by the dict\n * entries using the provided allocation function. This feature was added for\n * the active defrag feature.\n *\n * The 'defragfns' callbacks are called with a pointer to memory that callback\n * can reallocate. The callbacks should return a new memory address or NULL,\n * where NULL means that no reallocation happened and the old memory is still\n * valid. */\nunsigned long dictScanDefrag(dict *d,\n                             unsigned long v,\n                             dictScanFunction *fn,\n                             dictDefragFunctions *defragfns,\n                             void *privdata)\n{\n    int htidx0, htidx1;\n    const dictEntry *de, *next;\n    unsigned long m0, m1;\n\n    if (dictSize(d) == 0) return 0;\n\n    /* This is needed in case the scan callback tries to do dictFind or alike. */\n    dictPauseRehashing(d);\n\n    if (!dictIsRehashing(d)) {\n        htidx0 = 0;\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Set unmasked bits so incrementing the reversed cursor\n         * operates on the masked bits */\n        v |= ~m0;\n\n        /* Increment the reverse cursor */\n        v = rev(v);\n        v++;\n        v = rev(v);\n\n    } else {\n        htidx0 = 0;\n        htidx1 = 1;\n\n        /* Make sure t0 is the smaller and t1 is the bigger table */\n        if (DICTHT_SIZE(d->ht_size_exp[htidx0]) > DICTHT_SIZE(d->ht_size_exp[htidx1])) {\n            htidx0 = 1;\n            htidx1 = 0;\n        }\n\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n        m1 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx1]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Iterate over indices in larger table that are the expansion\n         * of the index pointed to by the cursor in the smaller table */\n        do {\n            /* Emit entries at cursor */\n            if (defragfns) {\n                dictDefragBucket(&d->ht_table[htidx1][v & m1], defragfns);\n            }\n            de = d->ht_table[htidx1][v & m1];\n            while (de) {\n                next = dictGetNext(de);\n                fn(privdata, de);\n                de = next;\n            }\n\n            /* Increment the reverse cursor not covered by the smaller mask.*/\n            v |= ~m1;\n            v = rev(v);\n            v++;\n            v = rev(v);\n\n            /* Continue while bits covered by mask difference is non-zero */\n        } while (v & (m0 ^ m1));\n    }\n\n    dictResumeRehashing(d);\n\n    return v;\n}\n\n/* ------------------------- private functions ------------------------------ */\n\n/* Because we may need to allocate huge memory chunk at once when dict\n * resizes, we will check this allocation is allowed or not if the dict\n * type has resizeAllowed member function. */\nstatic int dictTypeResizeAllowed(dict *d, size_t size) {\n    if (d->type->resizeAllowed == NULL) return 1;\n    return d->type->resizeAllowed(\n                    DICTHT_SIZE(_dictNextExp(size)) * sizeof(dictEntry*),\n                    (double)d->ht_used[0] / DICTHT_SIZE(d->ht_size_exp[0]));\n}\n\n/* Returning DICT_OK indicates a successful expand or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that expand has not been triggered (may be try shrinking?)*/\nint dictExpandIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) == 0) {\n        dictExpand(d, DICT_HT_INITIAL_SIZE);\n        return DICT_OK;\n    }\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] >= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] >= dict_force_resize_ratio * DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0] + 1))\n            dictExpand(d, d->ht_used[0] + 1);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\n/* Expand the hash table if needed */\nstatic void _dictExpandIfNeeded(dict *d) {\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictExpandIfNeeded(d);\n}\n\n/* Returning DICT_OK indicates a successful shrinking or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that shrinking has not been triggered (may be try expanding?)*/\nint dictShrinkIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n    \n    /* If the size of hash table is DICT_HT_INITIAL_SIZE, don't shrink it. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) <= DICT_HT_INITIAL_SIZE) return DICT_OK;\n\n    /* If we reached below 1:8 elements/buckets ratio, and we are allowed to resize\n     * the hash table (global setting) or we should avoid it but the ratio is below 1:32,\n     * we'll trigger a resize of the hash table. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL <= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL * dict_force_resize_ratio <= DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0]))\n            dictShrink(d, d->ht_used[0]);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\nstatic void _dictShrinkIfNeeded(dict *d) \n{\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictShrinkIfNeeded(d);\n}\n\n/* Our hash table capability is a power of two */\nstatic signed char _dictNextExp(unsigned long size)\n{\n    if (size <= DICT_HT_INITIAL_SIZE) return DICT_HT_INITIAL_EXP;\n    if (size >= LONG_MAX) return (8*sizeof(long)-1);\n\n    return 8*sizeof(long) - __builtin_clzl(size-1);\n}\n\n/* Finds and returns the position within the dict where the provided key should\n * be inserted using dictInsertAtPosition if the key does not already exist in\n * the dict. If the key exists in the dict, NULL is returned and the optional\n * 'existing' entry pointer is populated, if provided. */\nvoid *dictFindPositionForInsert(dict *d, const void *key, dictEntry **existing) {\n    unsigned long idx, table;\n    dictEntry *he;\n    if (existing) *existing = NULL;\n    uint64_t hash = dictHashKey(d, key);\n    idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    /* Expand the hash table if needed */\n    _dictExpandIfNeeded(d);\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue; \n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        /* Search if this slot does not already contain the given key */\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                if (existing) *existing = he;\n                return NULL;\n            }\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n\n    /* If we are in the process of rehashing the hash table, the bucket is\n     * always returned in the context of the second (new) hash table. */\n    dictEntry **bucket = &d->ht_table[dictIsRehashing(d) ? 1 : 0][idx];\n    return bucket;\n}\n\nvoid dictEmpty(dict *d, void(callback)(dict*)) {\n    _dictClear(d,0,callback);\n    _dictClear(d,1,callback);\n    d->rehashidx = -1;\n    d->pauserehash = 0;\n    d->pauseAutoResize = 0;\n}\n\nvoid dictSetResizeEnabled(dictResizeEnable enable) {\n    dict_can_resize = enable;\n}\n\nuint64_t dictGetHash(dict *d, const void *key) {\n    return dictHashKey(d, key);\n}\n\n/* Finds the dictEntry using pointer and pre-calculated hash.\n * oldkey is a dead pointer and should not be accessed.\n * the hash value should be provided using dictGetHash.\n * no string / key comparison is performed.\n * return value is a pointer to the dictEntry if found, or NULL if not found. */\ndictEntry *dictFindEntryByPtrAndHash(dict *d, const void *oldptr, uint64_t hash) {\n    dictEntry *he;\n    unsigned long idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n    for (table = 0; table <= 1; table++) {\n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        he = d->ht_table[table][idx];\n        while(he) {\n            if (oldptr == dictGetKey(he))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\n/* Provides the old and new ht size for a given dictionary during rehashing. This method\n * should only be invoked during initialization/rehashing. */\nvoid dictRehashingInfo(dict *d, unsigned long long *from_size, unsigned long long *to_size) {\n    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n\n/* ------------------------------- Debugging ---------------------------------*/\n#define DICT_STATS_VECTLEN 50\nvoid dictFreeStats(dictStats *stats) {\n    zfree(stats->clvector);\n    zfree(stats);\n}\n\nvoid dictCombineStats(dictStats *from, dictStats *into) {\n    into->buckets += from->buckets;\n    into->maxChainLen = (from->maxChainLen > into->maxChainLen) ? from->maxChainLen : into->maxChainLen;\n    into->totalChainLen += from->totalChainLen;\n    into->htSize += from->htSize;\n    into->htUsed += from->htUsed;\n    for (int i = 0; i < DICT_STATS_VECTLEN; i++) {\n        into->clvector[i] += from->clvector[i];\n    }\n}\n\ndictStats *dictGetStatsHt(dict *d, int htidx, int full) {\n    unsigned long *clvector = zcalloc(sizeof(unsigned long) * DICT_STATS_VECTLEN);\n    dictStats *stats = zcalloc(sizeof(dictStats));\n    stats->htidx = htidx;\n    stats->clvector = clvector;\n    stats->htSize = DICTHT_SIZE(d->ht_size_exp[htidx]);\n    stats->htUsed = d->ht_used[htidx];\n    if (!full) return stats;\n    /* Compute stats. */\n    for (unsigned long i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]); i++) {\n        dictEntry *he;\n\n        if (d->ht_table[htidx][i] == NULL) {\n            clvector[0]++;\n            continue;\n        }\n        stats->buckets++;\n        /* For each hash entry on this slot... */\n        unsigned long chainlen = 0;\n        he = d->ht_table[htidx][i];\n        while(he) {\n            chainlen++;\n            he = dictGetNext(he);\n        }\n        clvector[(chainlen < DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++;\n        if (chainlen > stats->maxChainLen) stats->maxChainLen = chainlen;\n        stats->totalChainLen += chainlen;\n    }\n\n    return stats;\n}\n\n/* Generates human readable stats. */\nsize_t dictGetStatsMsg(char *buf, size_t bufsize, dictStats *stats, int full) {\n    if (stats->htUsed == 0) {\n        return snprintf(buf,bufsize,\n            \"Hash table %d stats (%s):\\n\"\n            \"No stats available for empty dictionaries\\n\",\n            stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\");\n    }\n    size_t l = 0;\n    l += snprintf(buf + l, bufsize - l,\n                  \"Hash table %d stats (%s):\\n\"\n                  \" table size: %lu\\n\"\n                  \" number of elements: %lu\\n\",\n                  stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\",\n                  stats->htSize, stats->htUsed);\n    if (full) {\n        l += snprintf(buf + l, bufsize - l,\n                      \" different slots: %lu\\n\"\n                      \" max chain length: %lu\\n\"\n                      \" avg chain length (counted): %.02f\\n\"\n                      \" avg chain length (computed): %.02f\\n\"\n                      \" Chain length distribution:\\n\",\n                      stats->buckets, stats->maxChainLen,\n                      (float) stats->totalChainLen / stats->buckets, (float) stats->htUsed / stats->buckets);\n\n        for (unsigned long i = 0; i < DICT_STATS_VECTLEN - 1; i++) {\n            if (stats->clvector[i] == 0) continue;\n            if (l >= bufsize) break;\n            l += snprintf(buf + l, bufsize - l,\n                          \"   %ld: %ld (%.02f%%)\\n\",\n                          i, stats->clvector[i], ((float) stats->clvector[i] / stats->htSize) * 100);\n        }\n    }\n\n    /* Make sure there is a NULL term at the end. */\n    buf[bufsize-1] = '\\0';\n    /* Unlike snprintf(), return the number of characters actually written. */\n    return strlen(buf);\n}\n\nvoid dictGetStats(char *buf, size_t bufsize, dict *d, int full) {\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n\n    dictStats *mainHtStats = dictGetStatsHt(d, 0, full);\n    l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n    dictFreeStats(mainHtStats);\n    buf += l;\n    bufsize -= l;\n    if (dictIsRehashing(d) && bufsize > 0) {\n        dictStats *rehashHtStats = dictGetStatsHt(d, 1, full);\n        dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n    }\n    /* Make sure there is a NULL term at the end. */\n    orig_buf[orig_bufsize-1] = '\\0';\n}\n\n/* ------------------------------- Benchmark ---------------------------------*/\n\n#ifdef REDIS_TEST\n#include \"testhelp.h\"\n\n#define UNUSED(V) ((void) V)\n#define TEST(name) printf(\"test \u2014 %s\\n\", name);\n\nuint64_t hashCallback(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\nint compareCallback(dict *d, const void *key1, const void *key2) {\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = strlen((char*)key1);\n    l2 = strlen((char*)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\nvoid freeCallback(dict *d, void *val) {\n    UNUSED(d);\n\n    zfree(val);\n}\n\nchar *stringFromLongLong(long long value) {\n    char buf[32];\n    int len;\n    char *s;\n\n    len = snprintf(buf,sizeof(buf),\"%lld\",value);\n    s = zmalloc(len+1);\n    memcpy(s, buf, len);\n    s[len] = '\\0';\n    return s;\n}\n\ndictType BenchmarkDictType = {\n    hashCallback,\n    NULL,\n    NULL,\n    compareCallback,\n    freeCallback,\n    NULL,\n    NULL\n};\n\n#define start_benchmark() start = timeInMilliseconds()\n#define end_benchmark(msg) do { \\\n    elapsed = timeInMilliseconds()-start; \\\n    printf(msg \": %ld items in %lld ms\\n\", count, elapsed); \\\n} while(0)\n\n/* ./redis-server test dict [<count> | --accurate] */\nint dictTest(int argc, char **argv, int flags) {\n    long j;\n    long long start, elapsed;\n    int retval;\n    dict *dict = dictCreate(&BenchmarkDictType);\n    long count = 0;\n    unsigned long new_dict_size, current_dict_used, remain_keys;\n    int accurate = (flags & REDIS_TEST_ACCURATE);\n\n    if (argc == 4) {\n        if (accurate) {\n            count = 5000000;\n        } else {\n            count = strtol(argv[3],NULL,10);\n        }\n    } else {\n        count = 5000;\n    }\n\n    TEST(\"Add 16 keys and verify dict resize is ok\") {\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        for (j = 0; j < 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 16);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and pad to (dict_force_resize_ratio * 16)\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict resize, and pad\n         * the number of keys to (dict_force_resize_ratio * 16), so we can satisfy\n         * dict_force_resize_ratio in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        for (j = 16; j < (long)dict_force_resize_ratio * 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = dict_force_resize_ratio * 16;\n        assert(dictSize(dict) == current_dict_used);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Add one more key, trigger the dict resize\") {\n        retval = dictAdd(dict,stringFromLongLong(current_dict_used),(void*)(current_dict_used));\n        assert(retval == DICT_OK);\n        current_dict_used++;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 16);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete keys until we can trigger shrink in next test\") {\n        /* Delete keys until we can satisfy (1 / HASHTABLE_MIN_FILL) in the next test. */\n        for (j = new_dict_size / HASHTABLE_MIN_FILL + 1; j < (long)current_dict_used; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = new_dict_size / HASHTABLE_MIN_FILL + 1;\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        unsigned long oldDictSize = new_dict_size;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == oldDictSize);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Empty the dictionary and add 128 keys\") {\n        dictEmpty(dict, NULL);\n        for (j = 0; j < 128; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 128);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and reduce to 3\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict reset, and reduce\n         * the number of keys until we can trigger shrinking in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        remain_keys = DICTHT_SIZE(dict->ht_size_exp[0]) / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) + 1;\n        for (j = remain_keys; j < 128; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = remain_keys;\n        assert(dictSize(dict) == remain_keys);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 128);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Restore to original state\") {\n        dictEmpty(dict, NULL);\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n        assert(retval == DICT_OK);\n    }\n    end_benchmark(\"Inserting\");\n    assert((long)dictSize(dict) == count);\n\n    /* Wait for rehashing. */\n    while (dictIsRehashing(dict)) {\n        dictRehashMicroseconds(dict,100*1000);\n    }\n\n    start_benchmark();\n"}, {"id": "0099D3133B207CDF", "name": "zfree", "path": "redis/src/zmalloc.c", "start": {"line": 364, "col": 1}, "end": {"line": 380, "col": 1}, "code": ""}], "code": "void kvstoreIteratorRelease(kvstoreIterator *kvs_it) {\n    dictIterator *iter = &kvs_it->di;\n    dictResetIterator(iter);\n\n    zfree(kvs_it);\n}\n"}, "B9770C032ED2D79F": {"calls": [{"id": "054A43FDE5CB0E46", "name": "dictGetSafeIterator", "path": "redis/src/dict.c", "start": {"line": 994, "col": 1}, "end": {"line": 999, "col": 1}, "code": "    dictIterator *i = dictGetIterator(d);\n\n    i->safe = 1;\n    return i;\n}\n\ndictEntry *dictNext(dictIterator *iter)\n{\n    while (1) {\n        if (iter->entry == NULL) {\n            if (iter->index == -1 && iter->table == 0) {\n                if (iter->safe)\n                    dictPauseRehashing(iter->d);\n                else\n                    iter->fingerprint = dictFingerprint(iter->d);\n\n                /* skip the rehashed slots in table[0] */\n                if (dictIsRehashing(iter->d)) {\n                    iter->index = iter->d->rehashidx - 1;\n                }\n            }\n            iter->index++;\n            if (iter->index >= (long) DICTHT_SIZE(iter->d->ht_size_exp[iter->table])) {\n                if (dictIsRehashing(iter->d) && iter->table == 0) {\n                    iter->table++;\n                    iter->index = 0;\n                } else {\n                    break;\n                }\n            }\n            iter->entry = iter->d->ht_table[iter->table][iter->index];\n        } else {\n            iter->entry = iter->nextEntry;\n        }\n        if (iter->entry) {\n            /* We need to save the 'next' here, the iterator user\n             * may delete the entry we are returning. */\n            iter->nextEntry = dictGetNext(iter->entry);\n            return iter->entry;\n        }\n    }\n    return NULL;\n}\n\nvoid dictReleaseIterator(dictIterator *iter)\n{\n    dictResetIterator(iter);\n    zfree(iter);\n}\n\n/* Return a random entry from the hash table. Useful to\n * implement randomized algorithms */\ndictEntry *dictGetRandomKey(dict *d)\n{\n    dictEntry *he, *orighe;\n    unsigned long h;\n    int listlen, listele;\n\n    if (dictSize(d) == 0) return NULL;\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    if (dictIsRehashing(d)) {\n        unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n        do {\n            /* We are sure there are no elements in indexes from 0\n             * to rehashidx-1 */\n            h = d->rehashidx + (randomULong() % (dictBuckets(d) - d->rehashidx));\n            he = (h >= s0) ? d->ht_table[1][h - s0] : d->ht_table[0][h];\n        } while(he == NULL);\n    } else {\n        unsigned long m = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n        do {\n            h = randomULong() & m;\n            he = d->ht_table[0][h];\n        } while(he == NULL);\n    }\n\n    /* Now we found a non empty bucket, but it is a linked\n     * list and we need to get a random element from the list.\n     * The only sane way to do so is counting the elements and\n     * select a random index. */\n    listlen = 0;\n    orighe = he;\n    while(he) {\n        he = dictGetNext(he);\n        listlen++;\n    }\n    listele = random() % listlen;\n    he = orighe;\n    while(listele--) he = dictGetNext(he);\n    return he;\n}\n\n/* This function samples the dictionary to return a few keys from random\n * locations.\n *\n * It does not guarantee to return all the keys specified in 'count', nor\n * it does guarantee to return non-duplicated elements, however it will make\n * some effort to do both things.\n *\n * Returned pointers to hash table entries are stored into 'des' that\n * points to an array of dictEntry pointers. The array must have room for\n * at least 'count' elements, that is the argument we pass to the function\n * to tell how many random elements we need.\n *\n * The function returns the number of items stored into 'des', that may\n * be less than 'count' if the hash table has less than 'count' elements\n * inside, or if not enough elements were found in a reasonable amount of\n * steps.\n *\n * Note that this function is not suitable when you need a good distribution\n * of the returned items, but only when you need to \"sample\" a given number\n * of continuous elements to run some kind of algorithm or to produce\n * statistics. However the function is much faster than dictGetRandomKey()\n * at producing N elements. */\nunsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) {\n    unsigned long j; /* internal hash table id, 0 or 1. */\n    unsigned long tables; /* 1 or 2 tables? */\n    unsigned long stored = 0, maxsizemask;\n    unsigned long maxsteps;\n\n    if (dictSize(d) < count) count = dictSize(d);\n    maxsteps = count*10;\n\n    /* Try to do a rehashing work proportional to 'count'. */\n    for (j = 0; j < count; j++) {\n        if (dictIsRehashing(d))\n            _dictRehashStep(d);\n        else\n            break;\n    }\n\n    tables = dictIsRehashing(d) ? 2 : 1;\n    maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n    if (tables > 1 && maxsizemask < DICTHT_SIZE_MASK(d->ht_size_exp[1]))\n        maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n\n    /* Pick a random point inside the larger table. */\n    unsigned long i = randomULong() & maxsizemask;\n    unsigned long emptylen = 0; /* Continuous empty entries so far. */\n    while(stored < count && maxsteps--) {\n        for (j = 0; j < tables; j++) {\n            /* Invariant of the dict.c rehashing: up to the indexes already\n             * visited in ht[0] during the rehashing, there are no populated\n             * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */\n            if (tables == 2 && j == 0 && i < (unsigned long) d->rehashidx) {\n                /* Moreover, if we are currently out of range in the second\n                 * table, there will be no elements in both tables up to\n                 * the current rehashing index, so we jump if possible.\n                 * (this happens when going from big to small table). */\n                if (i >= DICTHT_SIZE(d->ht_size_exp[1]))\n                    i = d->rehashidx;\n                else\n                    continue;\n            }\n            if (i >= DICTHT_SIZE(d->ht_size_exp[j])) continue; /* Out of range for this table. */\n            dictEntry *he = d->ht_table[j][i];\n\n            /* Count contiguous empty buckets, and jump to other\n             * locations if they reach 'count' (with a minimum of 5). */\n            if (he == NULL) {\n                emptylen++;\n                if (emptylen >= 5 && emptylen > count) {\n                    i = randomULong() & maxsizemask;\n                    emptylen = 0;\n                }\n            } else {\n                emptylen = 0;\n                while (he) {\n                    /* Collect all the elements of the buckets found non empty while iterating.\n                     * To avoid the issue of being unable to sample the end of a long chain,\n                     * we utilize the Reservoir Sampling algorithm to optimize the sampling process.\n                     * This means that even when the maximum number of samples has been reached,\n                     * we continue sampling until we reach the end of the chain.\n                     * See https://en.wikipedia.org/wiki/Reservoir_sampling. */\n                    if (stored < count) {\n                        des[stored] = he;\n                    } else {\n                        unsigned long r = randomULong() % (stored + 1);\n                        if (r < count) des[r] = he;\n                    }\n\n                    he = dictGetNext(he);\n                    stored++;\n                }\n                if (stored >= count) goto end;\n            }\n        }\n        i = (i+1) & maxsizemask;\n    }\n\nend:\n    return stored > count ? count : stored;\n}\n\n\n/* Reallocate the dictEntry, key and value allocations in a bucket using the\n * provided allocation functions in order to defrag them. */\nstatic void dictDefragBucket(dictEntry **bucketref, dictDefragFunctions *defragfns) {\n    dictDefragAllocFunction *defragalloc = defragfns->defragAlloc;\n    dictDefragAllocFunction *defragkey = defragfns->defragKey;\n    dictDefragAllocFunction *defragval = defragfns->defragVal;\n    while (bucketref && *bucketref) {\n        dictEntry *de = *bucketref, *newde = NULL;\n        void *newkey = defragkey ? defragkey(dictGetKey(de)) : NULL;\n        void *newval = defragval ? defragval(dictGetVal(de)) : NULL;\n        if (entryIsKey(de)) {\n            if (newkey) *bucketref = newkey;\n            assert(entryIsKey(*bucketref));\n        } else if (entryIsNoValue(de)) {\n            dictEntryNoValue *entry = decodeEntryNoValue(de), *newentry;\n            if ((newentry = defragalloc(entry))) {\n                newde = encodeMaskedPtr(newentry, ENTRY_PTR_NO_VALUE);\n                entry = newentry;\n            }\n            if (newkey) entry->key = newkey;\n        } else {\n            assert(entryIsNormal(de));\n            newde = defragalloc(de);\n            if (newde) de = newde;\n            if (newkey) de->key = newkey;\n            if (newval) de->v.val = newval;\n        }\n        if (newde) {\n            *bucketref = newde;\n        }\n        bucketref = dictGetNextRef(*bucketref);\n    }\n}\n\n/* This is like dictGetRandomKey() from the POV of the API, but will do more\n * work to ensure a better distribution of the returned element.\n *\n * This function improves the distribution because the dictGetRandomKey()\n * problem is that it selects a random bucket, then it selects a random\n * element from the chain in the bucket. However elements being in different\n * chain lengths will have different probabilities of being reported. With\n * this function instead what we do is to consider a \"linear\" range of the table\n * that may be constituted of N buckets with chains of different lengths\n * appearing one after the other. Then we report a random element in the range.\n * In this way we smooth away the problem of different chain lengths. */\n#define GETFAIR_NUM_ENTRIES 15\ndictEntry *dictGetFairRandomKey(dict *d) {\n    dictEntry *entries[GETFAIR_NUM_ENTRIES];\n    unsigned int count = dictGetSomeKeys(d,entries,GETFAIR_NUM_ENTRIES);\n    /* Note that dictGetSomeKeys() may return zero elements in an unlucky\n     * run() even if there are actually elements inside the hash table. So\n     * when we get zero, we call the true dictGetRandomKey() that will always\n     * yield the element if the hash table has at least one. */\n    if (count == 0) return dictGetRandomKey(d);\n    unsigned int idx = rand() % count;\n    return entries[idx];\n}\n\n/* Function to reverse bits. Algorithm from:\n * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */\nstatic unsigned long rev(unsigned long v) {\n    unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2\n    unsigned long mask = ~0UL;\n    while ((s >>= 1) > 0) {\n        mask ^= (mask << s);\n        v = ((v >> s) & mask) | ((v << s) & ~mask);\n    }\n    return v;\n}\n\n/* dictScan() is used to iterate over the elements of a dictionary.\n *\n * Iterating works the following way:\n *\n * 1) Initially you call the function using a cursor (v) value of 0.\n * 2) The function performs one step of the iteration, and returns the\n *    new cursor value you must use in the next call.\n * 3) When the returned cursor is 0, the iteration is complete.\n *\n * The function guarantees all elements present in the\n * dictionary get returned between the start and end of the iteration.\n * However it is possible some elements get returned multiple times.\n *\n * For every element returned, the callback argument 'fn' is\n * called with 'privdata' as first argument and the dictionary entry\n * 'de' as second argument.\n *\n * HOW IT WORKS.\n *\n * The iteration algorithm was designed by Pieter Noordhuis.\n * The main idea is to increment a cursor starting from the higher order\n * bits. That is, instead of incrementing the cursor normally, the bits\n * of the cursor are reversed, then the cursor is incremented, and finally\n * the bits are reversed again.\n *\n * This strategy is needed because the hash table may be resized between\n * iteration calls.\n *\n * dict.c hash tables are always power of two in size, and they\n * use chaining, so the position of an element in a given table is given\n * by computing the bitwise AND between Hash(key) and SIZE-1\n * (where SIZE-1 is always the mask that is equivalent to taking the rest\n *  of the division between the Hash of the key and SIZE).\n *\n * For example if the current hash table size is 16, the mask is\n * (in binary) 1111. The position of a key in the hash table will always be\n * the last four bits of the hash output, and so forth.\n *\n * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE?\n *\n * If the hash table grows, elements can go anywhere in one multiple of\n * the old bucket: for example let's say we already iterated with\n * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16).\n *\n * If the hash table will be resized to 64 elements, then the new mask will\n * be 111111. The new buckets you obtain by substituting in ??1100\n * with either 0 or 1 can be targeted only by keys we already visited\n * when scanning the bucket 1100 in the smaller hash table.\n *\n * By iterating the higher bits first, because of the inverted counter, the\n * cursor does not need to restart if the table size gets bigger. It will\n * continue iterating using cursors without '1100' at the end, and also\n * without any other combination of the final 4 bits already explored.\n *\n * Similarly when the table size shrinks over time, for example going from\n * 16 to 8, if a combination of the lower three bits (the mask for size 8\n * is 111) were already completely explored, it would not be visited again\n * because we are sure we tried, for example, both 0111 and 1111 (all the\n * variations of the higher bit) so we don't need to test it again.\n *\n * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING!\n *\n * Yes, this is true, but we always iterate the smaller table first, then\n * we test all the expansions of the current cursor into the larger\n * table. For example if the current cursor is 101 and we also have a\n * larger table of size 16, we also test (0)101 and (1)101 inside the larger\n * table. This reduces the problem back to having only one table, where\n * the larger one, if it exists, is just an expansion of the smaller one.\n *\n * LIMITATIONS\n *\n * This iterator is completely stateless, and this is a huge advantage,\n * including no additional memory used.\n *\n * The disadvantages resulting from this design are:\n *\n * 1) It is possible we return elements more than once. However this is usually\n *    easy to deal with in the application level.\n * 2) The iterator must return multiple elements per call, as it needs to always\n *    return all the keys chained in a given bucket, and all the expansions, so\n *    we are sure we don't miss keys moving during rehashing.\n * 3) The reverse cursor is somewhat hard to understand at first, but this\n *    comment is supposed to help.\n */\nunsigned long dictScan(dict *d,\n                       unsigned long v,\n                       dictScanFunction *fn,\n                       void *privdata)\n{\n    return dictScanDefrag(d, v, fn, NULL, privdata);\n}\n\n/* Like dictScan, but additionally reallocates the memory used by the dict\n * entries using the provided allocation function. This feature was added for\n * the active defrag feature.\n *\n * The 'defragfns' callbacks are called with a pointer to memory that callback\n * can reallocate. The callbacks should return a new memory address or NULL,\n * where NULL means that no reallocation happened and the old memory is still\n * valid. */\nunsigned long dictScanDefrag(dict *d,\n                             unsigned long v,\n                             dictScanFunction *fn,\n                             dictDefragFunctions *defragfns,\n                             void *privdata)\n{\n    int htidx0, htidx1;\n    const dictEntry *de, *next;\n    unsigned long m0, m1;\n\n    if (dictSize(d) == 0) return 0;\n\n    /* This is needed in case the scan callback tries to do dictFind or alike. */\n    dictPauseRehashing(d);\n\n    if (!dictIsRehashing(d)) {\n        htidx0 = 0;\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Set unmasked bits so incrementing the reversed cursor\n         * operates on the masked bits */\n        v |= ~m0;\n\n        /* Increment the reverse cursor */\n        v = rev(v);\n        v++;\n        v = rev(v);\n\n    } else {\n        htidx0 = 0;\n        htidx1 = 1;\n\n        /* Make sure t0 is the smaller and t1 is the bigger table */\n        if (DICTHT_SIZE(d->ht_size_exp[htidx0]) > DICTHT_SIZE(d->ht_size_exp[htidx1])) {\n            htidx0 = 1;\n            htidx1 = 0;\n        }\n\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n        m1 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx1]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Iterate over indices in larger table that are the expansion\n         * of the index pointed to by the cursor in the smaller table */\n        do {\n            /* Emit entries at cursor */\n            if (defragfns) {\n                dictDefragBucket(&d->ht_table[htidx1][v & m1], defragfns);\n            }\n            de = d->ht_table[htidx1][v & m1];\n            while (de) {\n                next = dictGetNext(de);\n                fn(privdata, de);\n                de = next;\n            }\n\n            /* Increment the reverse cursor not covered by the smaller mask.*/\n            v |= ~m1;\n            v = rev(v);\n            v++;\n            v = rev(v);\n\n            /* Continue while bits covered by mask difference is non-zero */\n        } while (v & (m0 ^ m1));\n    }\n\n    dictResumeRehashing(d);\n\n    return v;\n}\n\n/* ------------------------- private functions ------------------------------ */\n\n/* Because we may need to allocate huge memory chunk at once when dict\n * resizes, we will check this allocation is allowed or not if the dict\n * type has resizeAllowed member function. */\nstatic int dictTypeResizeAllowed(dict *d, size_t size) {\n    if (d->type->resizeAllowed == NULL) return 1;\n    return d->type->resizeAllowed(\n                    DICTHT_SIZE(_dictNextExp(size)) * sizeof(dictEntry*),\n                    (double)d->ht_used[0] / DICTHT_SIZE(d->ht_size_exp[0]));\n}\n\n/* Returning DICT_OK indicates a successful expand or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that expand has not been triggered (may be try shrinking?)*/\nint dictExpandIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) == 0) {\n        dictExpand(d, DICT_HT_INITIAL_SIZE);\n        return DICT_OK;\n    }\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] >= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] >= dict_force_resize_ratio * DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0] + 1))\n            dictExpand(d, d->ht_used[0] + 1);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\n/* Expand the hash table if needed */\nstatic void _dictExpandIfNeeded(dict *d) {\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictExpandIfNeeded(d);\n}\n\n/* Returning DICT_OK indicates a successful shrinking or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that shrinking has not been triggered (may be try expanding?)*/\nint dictShrinkIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n    \n    /* If the size of hash table is DICT_HT_INITIAL_SIZE, don't shrink it. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) <= DICT_HT_INITIAL_SIZE) return DICT_OK;\n\n    /* If we reached below 1:8 elements/buckets ratio, and we are allowed to resize\n     * the hash table (global setting) or we should avoid it but the ratio is below 1:32,\n     * we'll trigger a resize of the hash table. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL <= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL * dict_force_resize_ratio <= DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0]))\n            dictShrink(d, d->ht_used[0]);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\nstatic void _dictShrinkIfNeeded(dict *d) \n{\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictShrinkIfNeeded(d);\n}\n\n/* Our hash table capability is a power of two */\nstatic signed char _dictNextExp(unsigned long size)\n{\n    if (size <= DICT_HT_INITIAL_SIZE) return DICT_HT_INITIAL_EXP;\n    if (size >= LONG_MAX) return (8*sizeof(long)-1);\n\n    return 8*sizeof(long) - __builtin_clzl(size-1);\n}\n\n/* Finds and returns the position within the dict where the provided key should\n * be inserted using dictInsertAtPosition if the key does not already exist in\n * the dict. If the key exists in the dict, NULL is returned and the optional\n * 'existing' entry pointer is populated, if provided. */\nvoid *dictFindPositionForInsert(dict *d, const void *key, dictEntry **existing) {\n    unsigned long idx, table;\n    dictEntry *he;\n    if (existing) *existing = NULL;\n    uint64_t hash = dictHashKey(d, key);\n    idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    /* Expand the hash table if needed */\n    _dictExpandIfNeeded(d);\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue; \n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        /* Search if this slot does not already contain the given key */\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                if (existing) *existing = he;\n                return NULL;\n            }\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n\n    /* If we are in the process of rehashing the hash table, the bucket is\n     * always returned in the context of the second (new) hash table. */\n    dictEntry **bucket = &d->ht_table[dictIsRehashing(d) ? 1 : 0][idx];\n    return bucket;\n}\n\nvoid dictEmpty(dict *d, void(callback)(dict*)) {\n    _dictClear(d,0,callback);\n    _dictClear(d,1,callback);\n    d->rehashidx = -1;\n    d->pauserehash = 0;\n    d->pauseAutoResize = 0;\n}\n\nvoid dictSetResizeEnabled(dictResizeEnable enable) {\n    dict_can_resize = enable;\n}\n\nuint64_t dictGetHash(dict *d, const void *key) {\n    return dictHashKey(d, key);\n}\n\n/* Finds the dictEntry using pointer and pre-calculated hash.\n * oldkey is a dead pointer and should not be accessed.\n * the hash value should be provided using dictGetHash.\n * no string / key comparison is performed.\n * return value is a pointer to the dictEntry if found, or NULL if not found. */\ndictEntry *dictFindEntryByPtrAndHash(dict *d, const void *oldptr, uint64_t hash) {\n    dictEntry *he;\n    unsigned long idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n    for (table = 0; table <= 1; table++) {\n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        he = d->ht_table[table][idx];\n        while(he) {\n            if (oldptr == dictGetKey(he))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\n/* Provides the old and new ht size for a given dictionary during rehashing. This method\n * should only be invoked during initialization/rehashing. */\nvoid dictRehashingInfo(dict *d, unsigned long long *from_size, unsigned long long *to_size) {\n    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n\n/* ------------------------------- Debugging ---------------------------------*/\n#define DICT_STATS_VECTLEN 50\nvoid dictFreeStats(dictStats *stats) {\n    zfree(stats->clvector);\n    zfree(stats);\n}\n\nvoid dictCombineStats(dictStats *from, dictStats *into) {\n    into->buckets += from->buckets;\n    into->maxChainLen = (from->maxChainLen > into->maxChainLen) ? from->maxChainLen : into->maxChainLen;\n    into->totalChainLen += from->totalChainLen;\n    into->htSize += from->htSize;\n    into->htUsed += from->htUsed;\n    for (int i = 0; i < DICT_STATS_VECTLEN; i++) {\n        into->clvector[i] += from->clvector[i];\n    }\n}\n\ndictStats *dictGetStatsHt(dict *d, int htidx, int full) {\n    unsigned long *clvector = zcalloc(sizeof(unsigned long) * DICT_STATS_VECTLEN);\n    dictStats *stats = zcalloc(sizeof(dictStats));\n    stats->htidx = htidx;\n    stats->clvector = clvector;\n    stats->htSize = DICTHT_SIZE(d->ht_size_exp[htidx]);\n    stats->htUsed = d->ht_used[htidx];\n    if (!full) return stats;\n    /* Compute stats. */\n    for (unsigned long i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]); i++) {\n        dictEntry *he;\n\n        if (d->ht_table[htidx][i] == NULL) {\n            clvector[0]++;\n            continue;\n        }\n        stats->buckets++;\n        /* For each hash entry on this slot... */\n        unsigned long chainlen = 0;\n        he = d->ht_table[htidx][i];\n        while(he) {\n            chainlen++;\n            he = dictGetNext(he);\n        }\n        clvector[(chainlen < DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++;\n        if (chainlen > stats->maxChainLen) stats->maxChainLen = chainlen;\n        stats->totalChainLen += chainlen;\n    }\n\n    return stats;\n}\n\n/* Generates human readable stats. */\nsize_t dictGetStatsMsg(char *buf, size_t bufsize, dictStats *stats, int full) {\n    if (stats->htUsed == 0) {\n        return snprintf(buf,bufsize,\n            \"Hash table %d stats (%s):\\n\"\n            \"No stats available for empty dictionaries\\n\",\n            stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\");\n    }\n    size_t l = 0;\n    l += snprintf(buf + l, bufsize - l,\n                  \"Hash table %d stats (%s):\\n\"\n                  \" table size: %lu\\n\"\n                  \" number of elements: %lu\\n\",\n                  stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\",\n                  stats->htSize, stats->htUsed);\n    if (full) {\n        l += snprintf(buf + l, bufsize - l,\n                      \" different slots: %lu\\n\"\n                      \" max chain length: %lu\\n\"\n                      \" avg chain length (counted): %.02f\\n\"\n                      \" avg chain length (computed): %.02f\\n\"\n                      \" Chain length distribution:\\n\",\n                      stats->buckets, stats->maxChainLen,\n                      (float) stats->totalChainLen / stats->buckets, (float) stats->htUsed / stats->buckets);\n\n        for (unsigned long i = 0; i < DICT_STATS_VECTLEN - 1; i++) {\n            if (stats->clvector[i] == 0) continue;\n            if (l >= bufsize) break;\n            l += snprintf(buf + l, bufsize - l,\n                          \"   %ld: %ld (%.02f%%)\\n\",\n                          i, stats->clvector[i], ((float) stats->clvector[i] / stats->htSize) * 100);\n        }\n    }\n\n    /* Make sure there is a NULL term at the end. */\n    buf[bufsize-1] = '\\0';\n    /* Unlike snprintf(), return the number of characters actually written. */\n    return strlen(buf);\n}\n\nvoid dictGetStats(char *buf, size_t bufsize, dict *d, int full) {\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n\n    dictStats *mainHtStats = dictGetStatsHt(d, 0, full);\n    l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n    dictFreeStats(mainHtStats);\n    buf += l;\n    bufsize -= l;\n    if (dictIsRehashing(d) && bufsize > 0) {\n        dictStats *rehashHtStats = dictGetStatsHt(d, 1, full);\n        dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n    }\n    /* Make sure there is a NULL term at the end. */\n    orig_buf[orig_bufsize-1] = '\\0';\n}\n\n/* ------------------------------- Benchmark ---------------------------------*/\n\n#ifdef REDIS_TEST\n#include \"testhelp.h\"\n\n#define UNUSED(V) ((void) V)\n#define TEST(name) printf(\"test \u2014 %s\\n\", name);\n\nuint64_t hashCallback(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\nint compareCallback(dict *d, const void *key1, const void *key2) {\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = strlen((char*)key1);\n    l2 = strlen((char*)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\nvoid freeCallback(dict *d, void *val) {\n    UNUSED(d);\n\n    zfree(val);\n}\n\nchar *stringFromLongLong(long long value) {\n    char buf[32];\n    int len;\n    char *s;\n\n    len = snprintf(buf,sizeof(buf),\"%lld\",value);\n    s = zmalloc(len+1);\n    memcpy(s, buf, len);\n    s[len] = '\\0';\n    return s;\n}\n\ndictType BenchmarkDictType = {\n    hashCallback,\n    NULL,\n    NULL,\n    compareCallback,\n    freeCallback,\n    NULL,\n    NULL\n};\n\n#define start_benchmark() start = timeInMilliseconds()\n#define end_benchmark(msg) do { \\\n    elapsed = timeInMilliseconds()-start; \\\n    printf(msg \": %ld items in %lld ms\\n\", count, elapsed); \\\n} while(0)\n\n/* ./redis-server test dict [<count> | --accurate] */\nint dictTest(int argc, char **argv, int flags) {\n    long j;\n    long long start, elapsed;\n    int retval;\n    dict *dict = dictCreate(&BenchmarkDictType);\n    long count = 0;\n    unsigned long new_dict_size, current_dict_used, remain_keys;\n    int accurate = (flags & REDIS_TEST_ACCURATE);\n\n    if (argc == 4) {\n        if (accurate) {\n            count = 5000000;\n        } else {\n            count = strtol(argv[3],NULL,10);\n        }\n    } else {\n        count = 5000;\n    }\n\n    TEST(\"Add 16 keys and verify dict resize is ok\") {\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        for (j = 0; j < 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 16);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and pad to (dict_force_resize_ratio * 16)\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict resize, and pad\n         * the number of keys to (dict_force_resize_ratio * 16), so we can satisfy\n         * dict_force_resize_ratio in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        for (j = 16; j < (long)dict_force_resize_ratio * 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = dict_force_resize_ratio * 16;\n        assert(dictSize(dict) == current_dict_used);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Add one more key, trigger the dict resize\") {\n        retval = dictAdd(dict,stringFromLongLong(current_dict_used),(void*)(current_dict_used));\n        assert(retval == DICT_OK);\n        current_dict_used++;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 16);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete keys until we can trigger shrink in next test\") {\n        /* Delete keys until we can satisfy (1 / HASHTABLE_MIN_FILL) in the next test. */\n        for (j = new_dict_size / HASHTABLE_MIN_FILL + 1; j < (long)current_dict_used; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = new_dict_size / HASHTABLE_MIN_FILL + 1;\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        unsigned long oldDictSize = new_dict_size;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == oldDictSize);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Empty the dictionary and add 128 keys\") {\n        dictEmpty(dict, NULL);\n        for (j = 0; j < 128; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 128);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and reduce to 3\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict reset, and reduce\n         * the number of keys until we can trigger shrinking in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        remain_keys = DICTHT_SIZE(dict->ht_size_exp[0]) / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) + 1;\n        for (j = remain_keys; j < 128; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = remain_keys;\n        assert(dictSize(dict) == remain_keys);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 128);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Restore to original state\") {\n        dictEmpty(dict, NULL);\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n        assert(retval == DICT_OK);\n    }\n    end_benchmark(\"Inserting\");\n    assert((long)dictSize(dict) == count);\n\n    /* Wait for rehashing. */\n    while (dictIsRehashing(dict)) {\n        dictRehashMicroseconds(dict,100*1000);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Linear access of existing elements\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Linear access of existing elements (2nd round)\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(rand() % count);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Random access of existing elements\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        dictEntry *de = dictGetRandomKey(dict);\n        assert(de != NULL);\n    }\n"}, {"id": "6362D92098B9C9AB", "name": "dictGetKey", "path": "redis/src/dict.c", "start": {"line": 854, "col": 1}, "end": {"line": 858, "col": 1}, "code": "    if (entryIsKey(de)) return (void*)de;\n    if (entryIsNoValue(de)) return decodeEntryNoValue(de)->key;\n    return de->key;\n}\n\nvoid *dictGetVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.val;\n}\n\nint64_t dictGetSignedIntegerVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.s64;\n}\n\nuint64_t dictGetUnsignedIntegerVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.u64;\n}\n\ndouble dictGetDoubleVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.d;\n}\n\n/* Returns a mutable reference to the value as a double within the entry. */\ndouble *dictGetDoubleValPtr(dictEntry *de) {\n    assert(entryHasValue(de));\n    return &de->v.d;\n}\n\n/* Returns the 'next' field of the entry or NULL if the entry doesn't have a\n * 'next' field. */\nstatic dictEntry *dictGetNext(const dictEntry *de) {\n    if (entryIsKey(de)) return NULL; /* there's no next */\n    if (entryIsNoValue(de)) return decodeEntryNoValue(de)->next;\n    return de->next;\n}\n\n/* Returns a pointer to the 'next' field in the entry or NULL if the entry\n * doesn't have a next field. */\nstatic dictEntry **dictGetNextRef(dictEntry *de) {\n    if (entryIsKey(de)) return NULL;\n    if (entryIsNoValue(de)) return &decodeEntryNoValue(de)->next;\n    return &de->next;\n}\n\nstatic void dictSetNext(dictEntry *de, dictEntry *next) {\n    assert(!entryIsKey(de));\n    if (entryIsNoValue(de)) {\n        dictEntryNoValue *entry = decodeEntryNoValue(de);\n        entry->next = next;\n    } else {\n        de->next = next;\n    }\n}\n\n/* Returns the memory usage in bytes of the dict, excluding the size of the keys\n * and values. */\nsize_t dictMemUsage(const dict *d) {\n    return dictSize(d) * sizeof(dictEntry) +\n        dictBuckets(d) * sizeof(dictEntry*);\n}\n\nsize_t dictEntryMemUsage(void) {\n    return sizeof(dictEntry);\n}\n\n/* A fingerprint is a 64 bit number that represents the state of the dictionary\n * at a given time, it's just a few dict properties xored together.\n * When an unsafe iterator is initialized, we get the dict fingerprint, and check\n * the fingerprint again when the iterator is released.\n * If the two fingerprints are different it means that the user of the iterator\n * performed forbidden operations against the dictionary while iterating. */\nunsigned long long dictFingerprint(dict *d) {\n    unsigned long long integers[6], hash = 0;\n    int j;\n\n    integers[0] = (long) d->ht_table[0];\n    integers[1] = d->ht_size_exp[0];\n    integers[2] = d->ht_used[0];\n    integers[3] = (long) d->ht_table[1];\n    integers[4] = d->ht_size_exp[1];\n    integers[5] = d->ht_used[1];\n\n    /* We hash N integers by summing every successive integer with the integer\n     * hashing of the previous sum. Basically:\n     *\n     * Result = hash(hash(hash(int1)+int2)+int3) ...\n     *\n     * This way the same set of integers in a different order will (likely) hash\n     * to a different number. */\n    for (j = 0; j < 6; j++) {\n        hash += integers[j];\n        /* For the hashing step we use Tomas Wang's 64 bit integer hash. */\n        hash = (~hash) + (hash << 21); // hash = (hash << 21) - hash - 1;\n        hash = hash ^ (hash >> 24);\n        hash = (hash + (hash << 3)) + (hash << 8); // hash * 265\n        hash = hash ^ (hash >> 14);\n        hash = (hash + (hash << 2)) + (hash << 4); // hash * 21\n        hash = hash ^ (hash >> 28);\n        hash = hash + (hash << 31);\n    }\n    return hash;\n}\n\nvoid dictInitIterator(dictIterator *iter, dict *d)\n{\n    iter->d = d;\n    iter->table = 0;\n    iter->index = -1;\n    iter->safe = 0;\n    iter->entry = NULL;\n    iter->nextEntry = NULL;\n}\n\nvoid dictInitSafeIterator(dictIterator *iter, dict *d)\n{\n    dictInitIterator(iter, d);\n    iter->safe = 1;\n}\n\nvoid dictResetIterator(dictIterator *iter)\n{\n    if (!(iter->index == -1 && iter->table == 0)) {\n        if (iter->safe)\n            dictResumeRehashing(iter->d);\n        else\n            assert(iter->fingerprint == dictFingerprint(iter->d));\n    }\n}\n\ndictIterator *dictGetIterator(dict *d)\n{\n    dictIterator *iter = zmalloc(sizeof(*iter));\n    dictInitIterator(iter, d);\n    return iter;\n}\n\ndictIterator *dictGetSafeIterator(dict *d) {\n    dictIterator *i = dictGetIterator(d);\n\n    i->safe = 1;\n    return i;\n}\n\ndictEntry *dictNext(dictIterator *iter)\n{\n    while (1) {\n        if (iter->entry == NULL) {\n            if (iter->index == -1 && iter->table == 0) {\n                if (iter->safe)\n                    dictPauseRehashing(iter->d);\n                else\n                    iter->fingerprint = dictFingerprint(iter->d);\n\n                /* skip the rehashed slots in table[0] */\n                if (dictIsRehashing(iter->d)) {\n                    iter->index = iter->d->rehashidx - 1;\n                }\n            }\n            iter->index++;\n            if (iter->index >= (long) DICTHT_SIZE(iter->d->ht_size_exp[iter->table])) {\n                if (dictIsRehashing(iter->d) && iter->table == 0) {\n                    iter->table++;\n                    iter->index = 0;\n                } else {\n                    break;\n                }\n            }\n            iter->entry = iter->d->ht_table[iter->table][iter->index];\n        } else {\n            iter->entry = iter->nextEntry;\n        }\n        if (iter->entry) {\n            /* We need to save the 'next' here, the iterator user\n             * may delete the entry we are returning. */\n            iter->nextEntry = dictGetNext(iter->entry);\n            return iter->entry;\n        }\n    }\n    return NULL;\n}\n\nvoid dictReleaseIterator(dictIterator *iter)\n{\n    dictResetIterator(iter);\n    zfree(iter);\n}\n\n/* Return a random entry from the hash table. Useful to\n * implement randomized algorithms */\ndictEntry *dictGetRandomKey(dict *d)\n{\n    dictEntry *he, *orighe;\n    unsigned long h;\n    int listlen, listele;\n\n    if (dictSize(d) == 0) return NULL;\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    if (dictIsRehashing(d)) {\n        unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n        do {\n            /* We are sure there are no elements in indexes from 0\n             * to rehashidx-1 */\n            h = d->rehashidx + (randomULong() % (dictBuckets(d) - d->rehashidx));\n            he = (h >= s0) ? d->ht_table[1][h - s0] : d->ht_table[0][h];\n        } while(he == NULL);\n    } else {\n        unsigned long m = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n        do {\n            h = randomULong() & m;\n            he = d->ht_table[0][h];\n        } while(he == NULL);\n    }\n\n    /* Now we found a non empty bucket, but it is a linked\n     * list and we need to get a random element from the list.\n     * The only sane way to do so is counting the elements and\n     * select a random index. */\n    listlen = 0;\n    orighe = he;\n    while(he) {\n        he = dictGetNext(he);\n        listlen++;\n    }\n    listele = random() % listlen;\n    he = orighe;\n    while(listele--) he = dictGetNext(he);\n    return he;\n}\n\n/* This function samples the dictionary to return a few keys from random\n * locations.\n *\n * It does not guarantee to return all the keys specified in 'count', nor\n * it does guarantee to return non-duplicated elements, however it will make\n * some effort to do both things.\n *\n * Returned pointers to hash table entries are stored into 'des' that\n * points to an array of dictEntry pointers. The array must have room for\n * at least 'count' elements, that is the argument we pass to the function\n * to tell how many random elements we need.\n *\n * The function returns the number of items stored into 'des', that may\n * be less than 'count' if the hash table has less than 'count' elements\n * inside, or if not enough elements were found in a reasonable amount of\n * steps.\n *\n * Note that this function is not suitable when you need a good distribution\n * of the returned items, but only when you need to \"sample\" a given number\n * of continuous elements to run some kind of algorithm or to produce\n * statistics. However the function is much faster than dictGetRandomKey()\n * at producing N elements. */\nunsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) {\n    unsigned long j; /* internal hash table id, 0 or 1. */\n    unsigned long tables; /* 1 or 2 tables? */\n    unsigned long stored = 0, maxsizemask;\n    unsigned long maxsteps;\n\n    if (dictSize(d) < count) count = dictSize(d);\n    maxsteps = count*10;\n\n    /* Try to do a rehashing work proportional to 'count'. */\n    for (j = 0; j < count; j++) {\n        if (dictIsRehashing(d))\n            _dictRehashStep(d);\n        else\n            break;\n    }\n\n    tables = dictIsRehashing(d) ? 2 : 1;\n    maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n    if (tables > 1 && maxsizemask < DICTHT_SIZE_MASK(d->ht_size_exp[1]))\n        maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n\n    /* Pick a random point inside the larger table. */\n    unsigned long i = randomULong() & maxsizemask;\n    unsigned long emptylen = 0; /* Continuous empty entries so far. */\n    while(stored < count && maxsteps--) {\n        for (j = 0; j < tables; j++) {\n            /* Invariant of the dict.c rehashing: up to the indexes already\n             * visited in ht[0] during the rehashing, there are no populated\n             * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */\n            if (tables == 2 && j == 0 && i < (unsigned long) d->rehashidx) {\n                /* Moreover, if we are currently out of range in the second\n                 * table, there will be no elements in both tables up to\n                 * the current rehashing index, so we jump if possible.\n                 * (this happens when going from big to small table). */\n                if (i >= DICTHT_SIZE(d->ht_size_exp[1]))\n                    i = d->rehashidx;\n                else\n                    continue;\n            }\n            if (i >= DICTHT_SIZE(d->ht_size_exp[j])) continue; /* Out of range for this table. */\n            dictEntry *he = d->ht_table[j][i];\n\n            /* Count contiguous empty buckets, and jump to other\n             * locations if they reach 'count' (with a minimum of 5). */\n            if (he == NULL) {\n                emptylen++;\n                if (emptylen >= 5 && emptylen > count) {\n                    i = randomULong() & maxsizemask;\n                    emptylen = 0;\n                }\n            } else {\n                emptylen = 0;\n                while (he) {\n                    /* Collect all the elements of the buckets found non empty while iterating.\n                     * To avoid the issue of being unable to sample the end of a long chain,\n                     * we utilize the Reservoir Sampling algorithm to optimize the sampling process.\n                     * This means that even when the maximum number of samples has been reached,\n                     * we continue sampling until we reach the end of the chain.\n                     * See https://en.wikipedia.org/wiki/Reservoir_sampling. */\n                    if (stored < count) {\n                        des[stored] = he;\n                    } else {\n                        unsigned long r = randomULong() % (stored + 1);\n                        if (r < count) des[r] = he;\n                    }\n\n                    he = dictGetNext(he);\n                    stored++;\n                }\n                if (stored >= count) goto end;\n            }\n        }\n        i = (i+1) & maxsizemask;\n    }\n\nend:\n    return stored > count ? count : stored;\n}\n\n\n/* Reallocate the dictEntry, key and value allocations in a bucket using the\n * provided allocation functions in order to defrag them. */\nstatic void dictDefragBucket(dictEntry **bucketref, dictDefragFunctions *defragfns) {\n    dictDefragAllocFunction *defragalloc = defragfns->defragAlloc;\n    dictDefragAllocFunction *defragkey = defragfns->defragKey;\n    dictDefragAllocFunction *defragval = defragfns->defragVal;\n    while (bucketref && *bucketref) {\n        dictEntry *de = *bucketref, *newde = NULL;\n        void *newkey = defragkey ? defragkey(dictGetKey(de)) : NULL;\n        void *newval = defragval ? defragval(dictGetVal(de)) : NULL;\n        if (entryIsKey(de)) {\n            if (newkey) *bucketref = newkey;\n            assert(entryIsKey(*bucketref));\n        } else if (entryIsNoValue(de)) {\n            dictEntryNoValue *entry = decodeEntryNoValue(de), *newentry;\n            if ((newentry = defragalloc(entry))) {\n                newde = encodeMaskedPtr(newentry, ENTRY_PTR_NO_VALUE);\n                entry = newentry;\n            }\n            if (newkey) entry->key = newkey;\n        } else {\n            assert(entryIsNormal(de));\n            newde = defragalloc(de);\n            if (newde) de = newde;\n            if (newkey) de->key = newkey;\n            if (newval) de->v.val = newval;\n        }\n        if (newde) {\n            *bucketref = newde;\n        }\n        bucketref = dictGetNextRef(*bucketref);\n    }\n}\n\n/* This is like dictGetRandomKey() from the POV of the API, but will do more\n * work to ensure a better distribution of the returned element.\n *\n * This function improves the distribution because the dictGetRandomKey()\n * problem is that it selects a random bucket, then it selects a random\n * element from the chain in the bucket. However elements being in different\n * chain lengths will have different probabilities of being reported. With\n * this function instead what we do is to consider a \"linear\" range of the table\n * that may be constituted of N buckets with chains of different lengths\n * appearing one after the other. Then we report a random element in the range.\n * In this way we smooth away the problem of different chain lengths. */\n#define GETFAIR_NUM_ENTRIES 15\ndictEntry *dictGetFairRandomKey(dict *d) {\n    dictEntry *entries[GETFAIR_NUM_ENTRIES];\n    unsigned int count = dictGetSomeKeys(d,entries,GETFAIR_NUM_ENTRIES);\n    /* Note that dictGetSomeKeys() may return zero elements in an unlucky\n     * run() even if there are actually elements inside the hash table. So\n     * when we get zero, we call the true dictGetRandomKey() that will always\n     * yield the element if the hash table has at least one. */\n    if (count == 0) return dictGetRandomKey(d);\n    unsigned int idx = rand() % count;\n    return entries[idx];\n}\n\n/* Function to reverse bits. Algorithm from:\n * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */\nstatic unsigned long rev(unsigned long v) {\n    unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2\n    unsigned long mask = ~0UL;\n    while ((s >>= 1) > 0) {\n        mask ^= (mask << s);\n        v = ((v >> s) & mask) | ((v << s) & ~mask);\n    }\n    return v;\n}\n\n/* dictScan() is used to iterate over the elements of a dictionary.\n *\n * Iterating works the following way:\n *\n * 1) Initially you call the function using a cursor (v) value of 0.\n * 2) The function performs one step of the iteration, and returns the\n *    new cursor value you must use in the next call.\n * 3) When the returned cursor is 0, the iteration is complete.\n *\n * The function guarantees all elements present in the\n * dictionary get returned between the start and end of the iteration.\n * However it is possible some elements get returned multiple times.\n *\n * For every element returned, the callback argument 'fn' is\n * called with 'privdata' as first argument and the dictionary entry\n * 'de' as second argument.\n *\n * HOW IT WORKS.\n *\n * The iteration algorithm was designed by Pieter Noordhuis.\n * The main idea is to increment a cursor starting from the higher order\n * bits. That is, instead of incrementing the cursor normally, the bits\n * of the cursor are reversed, then the cursor is incremented, and finally\n * the bits are reversed again.\n *\n * This strategy is needed because the hash table may be resized between\n * iteration calls.\n *\n * dict.c hash tables are always power of two in size, and they\n * use chaining, so the position of an element in a given table is given\n * by computing the bitwise AND between Hash(key) and SIZE-1\n * (where SIZE-1 is always the mask that is equivalent to taking the rest\n *  of the division between the Hash of the key and SIZE).\n *\n * For example if the current hash table size is 16, the mask is\n * (in binary) 1111. The position of a key in the hash table will always be\n * the last four bits of the hash output, and so forth.\n *\n * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE?\n *\n * If the hash table grows, elements can go anywhere in one multiple of\n * the old bucket: for example let's say we already iterated with\n * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16).\n *\n * If the hash table will be resized to 64 elements, then the new mask will\n * be 111111. The new buckets you obtain by substituting in ??1100\n * with either 0 or 1 can be targeted only by keys we already visited\n * when scanning the bucket 1100 in the smaller hash table.\n *\n * By iterating the higher bits first, because of the inverted counter, the\n * cursor does not need to restart if the table size gets bigger. It will\n * continue iterating using cursors without '1100' at the end, and also\n * without any other combination of the final 4 bits already explored.\n *\n * Similarly when the table size shrinks over time, for example going from\n * 16 to 8, if a combination of the lower three bits (the mask for size 8\n * is 111) were already completely explored, it would not be visited again\n * because we are sure we tried, for example, both 0111 and 1111 (all the\n * variations of the higher bit) so we don't need to test it again.\n *\n * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING!\n *\n * Yes, this is true, but we always iterate the smaller table first, then\n * we test all the expansions of the current cursor into the larger\n * table. For example if the current cursor is 101 and we also have a\n * larger table of size 16, we also test (0)101 and (1)101 inside the larger\n * table. This reduces the problem back to having only one table, where\n * the larger one, if it exists, is just an expansion of the smaller one.\n *\n * LIMITATIONS\n *\n * This iterator is completely stateless, and this is a huge advantage,\n * including no additional memory used.\n *\n * The disadvantages resulting from this design are:\n *\n * 1) It is possible we return elements more than once. However this is usually\n *    easy to deal with in the application level.\n * 2) The iterator must return multiple elements per call, as it needs to always\n *    return all the keys chained in a given bucket, and all the expansions, so\n *    we are sure we don't miss keys moving during rehashing.\n * 3) The reverse cursor is somewhat hard to understand at first, but this\n *    comment is supposed to help.\n */\nunsigned long dictScan(dict *d,\n                       unsigned long v,\n                       dictScanFunction *fn,\n                       void *privdata)\n{\n    return dictScanDefrag(d, v, fn, NULL, privdata);\n}\n\n/* Like dictScan, but additionally reallocates the memory used by the dict\n * entries using the provided allocation function. This feature was added for\n * the active defrag feature.\n *\n * The 'defragfns' callbacks are called with a pointer to memory that callback\n * can reallocate. The callbacks should return a new memory address or NULL,\n * where NULL means that no reallocation happened and the old memory is still\n * valid. */\nunsigned long dictScanDefrag(dict *d,\n                             unsigned long v,\n                             dictScanFunction *fn,\n                             dictDefragFunctions *defragfns,\n                             void *privdata)\n{\n    int htidx0, htidx1;\n    const dictEntry *de, *next;\n    unsigned long m0, m1;\n\n    if (dictSize(d) == 0) return 0;\n\n    /* This is needed in case the scan callback tries to do dictFind or alike. */\n    dictPauseRehashing(d);\n\n    if (!dictIsRehashing(d)) {\n        htidx0 = 0;\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Set unmasked bits so incrementing the reversed cursor\n         * operates on the masked bits */\n        v |= ~m0;\n\n        /* Increment the reverse cursor */\n        v = rev(v);\n        v++;\n        v = rev(v);\n\n    } else {\n        htidx0 = 0;\n        htidx1 = 1;\n\n        /* Make sure t0 is the smaller and t1 is the bigger table */\n        if (DICTHT_SIZE(d->ht_size_exp[htidx0]) > DICTHT_SIZE(d->ht_size_exp[htidx1])) {\n            htidx0 = 1;\n            htidx1 = 0;\n        }\n\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n        m1 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx1]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Iterate over indices in larger table that are the expansion\n         * of the index pointed to by the cursor in the smaller table */\n        do {\n            /* Emit entries at cursor */\n            if (defragfns) {\n                dictDefragBucket(&d->ht_table[htidx1][v & m1], defragfns);\n            }\n            de = d->ht_table[htidx1][v & m1];\n            while (de) {\n                next = dictGetNext(de);\n                fn(privdata, de);\n                de = next;\n            }\n\n            /* Increment the reverse cursor not covered by the smaller mask.*/\n            v |= ~m1;\n            v = rev(v);\n            v++;\n            v = rev(v);\n\n            /* Continue while bits covered by mask difference is non-zero */\n        } while (v & (m0 ^ m1));\n    }\n\n    dictResumeRehashing(d);\n\n    return v;\n}\n\n/* ------------------------- private functions ------------------------------ */\n\n/* Because we may need to allocate huge memory chunk at once when dict\n * resizes, we will check this allocation is allowed or not if the dict\n * type has resizeAllowed member function. */\nstatic int dictTypeResizeAllowed(dict *d, size_t size) {\n    if (d->type->resizeAllowed == NULL) return 1;\n    return d->type->resizeAllowed(\n                    DICTHT_SIZE(_dictNextExp(size)) * sizeof(dictEntry*),\n                    (double)d->ht_used[0] / DICTHT_SIZE(d->ht_size_exp[0]));\n}\n\n/* Returning DICT_OK indicates a successful expand or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that expand has not been triggered (may be try shrinking?)*/\nint dictExpandIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) == 0) {\n        dictExpand(d, DICT_HT_INITIAL_SIZE);\n        return DICT_OK;\n    }\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] >= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] >= dict_force_resize_ratio * DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0] + 1))\n            dictExpand(d, d->ht_used[0] + 1);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\n/* Expand the hash table if needed */\nstatic void _dictExpandIfNeeded(dict *d) {\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictExpandIfNeeded(d);\n}\n\n/* Returning DICT_OK indicates a successful shrinking or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that shrinking has not been triggered (may be try expanding?)*/\nint dictShrinkIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n    \n    /* If the size of hash table is DICT_HT_INITIAL_SIZE, don't shrink it. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) <= DICT_HT_INITIAL_SIZE) return DICT_OK;\n\n    /* If we reached below 1:8 elements/buckets ratio, and we are allowed to resize\n     * the hash table (global setting) or we should avoid it but the ratio is below 1:32,\n     * we'll trigger a resize of the hash table. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL <= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL * dict_force_resize_ratio <= DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0]))\n            dictShrink(d, d->ht_used[0]);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\nstatic void _dictShrinkIfNeeded(dict *d) \n{\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictShrinkIfNeeded(d);\n}\n\n/* Our hash table capability is a power of two */\nstatic signed char _dictNextExp(unsigned long size)\n{\n    if (size <= DICT_HT_INITIAL_SIZE) return DICT_HT_INITIAL_EXP;\n    if (size >= LONG_MAX) return (8*sizeof(long)-1);\n\n    return 8*sizeof(long) - __builtin_clzl(size-1);\n}\n\n/* Finds and returns the position within the dict where the provided key should\n * be inserted using dictInsertAtPosition if the key does not already exist in\n * the dict. If the key exists in the dict, NULL is returned and the optional\n * 'existing' entry pointer is populated, if provided. */\nvoid *dictFindPositionForInsert(dict *d, const void *key, dictEntry **existing) {\n    unsigned long idx, table;\n    dictEntry *he;\n    if (existing) *existing = NULL;\n    uint64_t hash = dictHashKey(d, key);\n    idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    /* Expand the hash table if needed */\n    _dictExpandIfNeeded(d);\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue; \n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        /* Search if this slot does not already contain the given key */\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                if (existing) *existing = he;\n                return NULL;\n            }\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n\n    /* If we are in the process of rehashing the hash table, the bucket is\n     * always returned in the context of the second (new) hash table. */\n    dictEntry **bucket = &d->ht_table[dictIsRehashing(d) ? 1 : 0][idx];\n    return bucket;\n}\n\nvoid dictEmpty(dict *d, void(callback)(dict*)) {\n    _dictClear(d,0,callback);\n    _dictClear(d,1,callback);\n    d->rehashidx = -1;\n    d->pauserehash = 0;\n    d->pauseAutoResize = 0;\n}\n\nvoid dictSetResizeEnabled(dictResizeEnable enable) {\n    dict_can_resize = enable;\n}\n\nuint64_t dictGetHash(dict *d, const void *key) {\n    return dictHashKey(d, key);\n}\n\n/* Finds the dictEntry using pointer and pre-calculated hash.\n * oldkey is a dead pointer and should not be accessed.\n * the hash value should be provided using dictGetHash.\n * no string / key comparison is performed.\n * return value is a pointer to the dictEntry if found, or NULL if not found. */\ndictEntry *dictFindEntryByPtrAndHash(dict *d, const void *oldptr, uint64_t hash) {\n    dictEntry *he;\n    unsigned long idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n    for (table = 0; table <= 1; table++) {\n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        he = d->ht_table[table][idx];\n        while(he) {\n            if (oldptr == dictGetKey(he))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\n/* Provides the old and new ht size for a given dictionary during rehashing. This method\n * should only be invoked during initialization/rehashing. */\nvoid dictRehashingInfo(dict *d, unsigned long long *from_size, unsigned long long *to_size) {\n    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n\n/* ------------------------------- Debugging ---------------------------------*/\n#define DICT_STATS_VECTLEN 50\nvoid dictFreeStats(dictStats *stats) {\n    zfree(stats->clvector);\n    zfree(stats);\n}\n\nvoid dictCombineStats(dictStats *from, dictStats *into) {\n    into->buckets += from->buckets;\n    into->maxChainLen = (from->maxChainLen > into->maxChainLen) ? from->maxChainLen : into->maxChainLen;\n    into->totalChainLen += from->totalChainLen;\n    into->htSize += from->htSize;\n    into->htUsed += from->htUsed;\n    for (int i = 0; i < DICT_STATS_VECTLEN; i++) {\n        into->clvector[i] += from->clvector[i];\n    }\n}\n\ndictStats *dictGetStatsHt(dict *d, int htidx, int full) {\n    unsigned long *clvector = zcalloc(sizeof(unsigned long) * DICT_STATS_VECTLEN);\n    dictStats *stats = zcalloc(sizeof(dictStats));\n    stats->htidx = htidx;\n    stats->clvector = clvector;\n    stats->htSize = DICTHT_SIZE(d->ht_size_exp[htidx]);\n    stats->htUsed = d->ht_used[htidx];\n    if (!full) return stats;\n    /* Compute stats. */\n    for (unsigned long i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]); i++) {\n        dictEntry *he;\n\n        if (d->ht_table[htidx][i] == NULL) {\n            clvector[0]++;\n            continue;\n        }\n        stats->buckets++;\n        /* For each hash entry on this slot... */\n        unsigned long chainlen = 0;\n        he = d->ht_table[htidx][i];\n        while(he) {\n            chainlen++;\n            he = dictGetNext(he);\n        }\n        clvector[(chainlen < DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++;\n        if (chainlen > stats->maxChainLen) stats->maxChainLen = chainlen;\n        stats->totalChainLen += chainlen;\n    }\n\n    return stats;\n}\n\n/* Generates human readable stats. */\nsize_t dictGetStatsMsg(char *buf, size_t bufsize, dictStats *stats, int full) {\n    if (stats->htUsed == 0) {\n        return snprintf(buf,bufsize,\n            \"Hash table %d stats (%s):\\n\"\n            \"No stats available for empty dictionaries\\n\",\n            stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\");\n    }\n    size_t l = 0;\n    l += snprintf(buf + l, bufsize - l,\n                  \"Hash table %d stats (%s):\\n\"\n                  \" table size: %lu\\n\"\n                  \" number of elements: %lu\\n\",\n                  stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\",\n                  stats->htSize, stats->htUsed);\n    if (full) {\n        l += snprintf(buf + l, bufsize - l,\n                      \" different slots: %lu\\n\"\n                      \" max chain length: %lu\\n\"\n                      \" avg chain length (counted): %.02f\\n\"\n                      \" avg chain length (computed): %.02f\\n\"\n                      \" Chain length distribution:\\n\",\n                      stats->buckets, stats->maxChainLen,\n                      (float) stats->totalChainLen / stats->buckets, (float) stats->htUsed / stats->buckets);\n\n"}, {"id": "E5F611507C613731", "name": "dbFind", "path": "redis/src/db.c", "start": {"line": 1905, "col": 1}, "end": {"line": 1907, "col": 1}, "code": "    return dbFindGeneric(db->keys, key);\n}\n\ndictEntry *dbFindExpires(redisDb *db, void *key) {\n    return dbFindGeneric(db->expires, key);\n}\n\nunsigned long long dbSize(redisDb *db) {\n    return kvstoreSize(db->keys);\n}\n\nunsigned long long dbScan(redisDb *db, unsigned long long cursor, dictScanFunction *scan_cb, void *privdata) {\n    return kvstoreScan(db->keys, cursor, -1, scan_cb, NULL, privdata);\n}\n\n/* -----------------------------------------------------------------------------\n * API to get key arguments from commands\n * ---------------------------------------------------------------------------*/\n\n/* Prepare the getKeysResult struct to hold numkeys, either by using the\n * pre-allocated keysbuf or by allocating a new array on the heap.\n *\n * This function must be called at least once before starting to populate\n * the result, and can be called repeatedly to enlarge the result array.\n */\nkeyReference *getKeysPrepareResult(getKeysResult *result, int numkeys) {\n    /* GETKEYS_RESULT_INIT initializes keys to NULL, point it to the pre-allocated stack\n     * buffer here. */\n    if (!result->keys) {\n        serverAssert(!result->numkeys);\n        result->keys = result->keysbuf;\n    }\n\n    /* Resize if necessary */\n    if (numkeys > result->size) {\n        if (result->keys != result->keysbuf) {\n            /* We're not using a static buffer, just (re)alloc */\n            result->keys = zrealloc(result->keys, numkeys * sizeof(keyReference));\n        } else {\n            /* We are using a static buffer, copy its contents */\n            result->keys = zmalloc(numkeys * sizeof(keyReference));\n            if (result->numkeys)\n                memcpy(result->keys, result->keysbuf, result->numkeys * sizeof(keyReference));\n        }\n        result->size = numkeys;\n    }\n\n    return result->keys;\n}\n\n/* Returns a bitmask with all the flags found in any of the key specs of the command.\n * The 'inv' argument means we'll return a mask with all flags that are missing in at least one spec. */\nint64_t getAllKeySpecsFlags(struct redisCommand *cmd, int inv) {\n    int64_t flags = 0;\n    for (int j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        flags |= inv? ~spec->flags : spec->flags;\n    }\n    return flags;\n}\n\n/* Fetch the keys based of the provided key specs. Returns the number of keys found, or -1 on error.\n * There are several flags that can be used to modify how this function finds keys in a command.\n * \n * GET_KEYSPEC_INCLUDE_NOT_KEYS: Return 'fake' keys as if they were keys.\n * GET_KEYSPEC_RETURN_PARTIAL:   Skips invalid and incomplete keyspecs but returns the keys\n *                               found in other valid keyspecs. \n */\nint getKeysUsingKeySpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    int j, i, last, first, step;\n    keyReference *keys;\n    serverAssert(result->numkeys == 0); /* caller should initialize or reset it */\n\n    for (j = 0; j < cmd->key_specs_num; j++) {\n        keySpec *spec = cmd->key_specs + j;\n        serverAssert(spec->begin_search_type != KSPEC_BS_INVALID);\n        /* Skip specs that represent 'fake' keys */\n        if ((spec->flags & CMD_KEY_NOT_KEY) && !(search_flags & GET_KEYSPEC_INCLUDE_NOT_KEYS)) {\n            continue;\n        }\n\n        first = 0;\n        if (spec->begin_search_type == KSPEC_BS_INDEX) {\n            first = spec->bs.index.pos;\n        } else if (spec->begin_search_type == KSPEC_BS_KEYWORD) {\n            int start_index = spec->bs.keyword.startfrom > 0 ? spec->bs.keyword.startfrom : argc+spec->bs.keyword.startfrom;\n            int end_index = spec->bs.keyword.startfrom > 0 ? argc-1: 1;\n            for (i = start_index; i != end_index; i = start_index <= end_index ? i + 1 : i - 1) {\n                if (i >= argc || i < 1)\n                    break;\n                if (!strcasecmp((char*)argv[i]->ptr,spec->bs.keyword.keyword)) {\n                    first = i+1;\n                    break;\n                }\n            }\n            /* keyword not found */\n            if (!first) {\n                continue;\n            }\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        if (spec->find_keys_type == KSPEC_FK_RANGE) {\n            step = spec->fk.range.keystep;\n            if (spec->fk.range.lastkey >= 0) {\n                last = first + spec->fk.range.lastkey;\n            } else {\n                if (!spec->fk.range.limit) {\n                    last = argc + spec->fk.range.lastkey;\n                } else {\n                    serverAssert(spec->fk.range.lastkey == -1);\n                    last = first + ((argc-first)/spec->fk.range.limit + spec->fk.range.lastkey);\n                }\n            }\n        } else if (spec->find_keys_type == KSPEC_FK_KEYNUM) {\n            step = spec->fk.keynum.keystep;\n            long long numkeys;\n            if (spec->fk.keynum.keynumidx >= argc)\n                goto invalid_spec;\n\n            sds keynum_str = argv[first + spec->fk.keynum.keynumidx]->ptr;\n            if (!string2ll(keynum_str,sdslen(keynum_str),&numkeys) || numkeys < 0) {\n                /* Unable to parse the numkeys argument or it was invalid */\n                goto invalid_spec;\n            }\n\n            first += spec->fk.keynum.firstkey;\n            last = first + (int)numkeys-1;\n        } else {\n            /* unknown spec */\n            goto invalid_spec;\n        }\n\n        int count = ((last - first)+1);\n        keys = getKeysPrepareResult(result, result->numkeys + count);\n\n        /* First or last is out of bounds, which indicates a syntax error */\n        if (last >= argc || last < first || first >= argc) {\n            goto invalid_spec;\n        }\n\n        for (i = first; i <= last; i += step) {\n            if (i >= argc || i < first) {\n                /* Modules commands, and standard commands with a not fixed number\n                 * of arguments (negative arity parameter) do not have dispatch\n                 * time arity checks, so we need to handle the case where the user\n                 * passed an invalid number of arguments here. In this case we\n                 * return no keys and expect the command implementation to report\n                 * an arity or syntax error. */\n                if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                    continue;\n                } else {\n                    serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n                }\n            }\n            keys[result->numkeys].pos = i;\n            keys[result->numkeys].flags = spec->flags;\n            result->numkeys++;\n        }\n\n        /* Handle incomplete specs (only after we added the current spec\n         * to `keys`, just in case GET_KEYSPEC_RETURN_PARTIAL was given) */\n        if (spec->flags & CMD_KEY_INCOMPLETE) {\n            goto invalid_spec;\n        }\n\n        /* Done with this spec */\n        continue;\n\ninvalid_spec:\n        if (search_flags & GET_KEYSPEC_RETURN_PARTIAL) {\n            continue;\n        } else {\n            result->numkeys = 0;\n            return -1;\n        }\n    }\n\n    return result->numkeys;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv. \n * This function will eventually replace getKeysFromCommand.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the key.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getKeysFromCommandWithSpecs(struct redisCommand *cmd, robj **argv, int argc, int search_flags, getKeysResult *result) {\n    /* The command has at least one key-spec not marked as NOT_KEY */\n    int has_keyspec = (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);\n    /* The command has at least one key-spec marked as VARIABLE_FLAGS */\n    int has_varflags = (getAllKeySpecsFlags(cmd, 0) & CMD_KEY_VARIABLE_FLAGS);\n\n    /* We prefer key-specs if there are any, and their flags are reliable. */\n    if (has_keyspec && !has_varflags) {\n        int ret = getKeysUsingKeySpecs(cmd,argv,argc,search_flags,result);\n        if (ret >= 0)\n            return ret;\n        /* If the specs returned with an error (probably an INVALID or INCOMPLETE spec),\n         * fallback to the callback method. */\n    }\n\n    /* Resort to getkeys callback methods. */\n    if (cmd->flags & CMD_MODULE_GETKEYS)\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n\n    /* We use native getkeys as a last resort, since not all these native getkeys provide\n     * flags properly (only the ones that correspond to INVALID, INCOMPLETE or VARIABLE_FLAGS do.*/\n    if (cmd->getkeys_proc)\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    return 0;\n}\n\n/* This function returns a sanity check if the command may have keys. */\nint doesCommandHaveKeys(struct redisCommand *cmd) {\n    return cmd->getkeys_proc ||                                 /* has getkeys_proc (non modules) */\n        (cmd->flags & CMD_MODULE_GETKEYS) ||                    /* module with GETKEYS */\n        (getAllKeySpecsFlags(cmd, 1) & CMD_KEY_NOT_KEY);        /* has at least one key-spec not marked as NOT_KEY */\n}\n\n/* A simplified channel spec table that contains all of the redis commands\n * and which channels they have and how they are accessed. */\ntypedef struct ChannelSpecs {\n    redisCommandProc *proc; /* Command procedure to match against */\n    uint64_t flags;         /* CMD_CHANNEL_* flags for this command */\n    int start;              /* The initial position of the first channel */\n    int count;              /* The number of channels, or -1 if all remaining\n                             * arguments are channels. */\n} ChannelSpecs;\n\nChannelSpecs commands_with_channels[] = {\n    {subscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {ssubscribeCommand, CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {unsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {sunsubscribeCommand, CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {psubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_SUBSCRIBE, 1, -1},\n    {punsubscribeCommand, CMD_CHANNEL_PATTERN | CMD_CHANNEL_UNSUBSCRIBE, 1, -1},\n    {publishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {spublishCommand, CMD_CHANNEL_PUBLISH, 1, 1},\n    {NULL,0} /* Terminator. */\n};\n\n/* Returns 1 if the command may access any channels matched by the flags\n * argument. */\nint doesCommandHaveChannelsWithFlags(struct redisCommand *cmd, int flags) {\n    /* If a module declares get channels, we are just going to assume\n     * has channels. This API is allowed to return false positives. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return 1;\n    }\n    for (ChannelSpecs *spec = commands_with_channels; spec->proc != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            return !!(spec->flags & flags);\n        }\n    }\n    return 0;\n}\n\n/* Return all the arguments that are channels in the command passed via argc / argv. \n * This function behaves similar to getKeysFromCommandWithSpecs, but with channels \n * instead of keys.\n * \n * The command returns the positions of all the channel arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n * \n * Along with the position, this command also returns the flags that are\n * associated with how Redis will access the channel.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0]. */\nint getChannelsFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    /* If a module declares get channels, use that. */\n    if (cmd->flags & CMD_MODULE_GETCHANNELS) {\n        return moduleGetCommandChannelsViaAPI(cmd, argv, argc, result);\n    }\n    /* Otherwise check the channel spec table */\n    for (ChannelSpecs *spec = commands_with_channels; spec != NULL; spec += 1) {\n        if (cmd->proc == spec->proc) {\n            int start = spec->start;\n            int stop = (spec->count == -1) ? argc : start + spec->count;\n            if (stop > argc) stop = argc;\n            int count = 0;\n            keys = getKeysPrepareResult(result, stop - start);\n            for (int i = start; i < stop; i++ ) {\n                keys[count].pos = i;\n                keys[count++].flags = spec->flags;\n            }\n            result->numkeys = count;\n            return count;\n        }\n    }\n    return 0;\n}\n\n/* The base case is to use the keys position as given in the command table\n * (firstkey, lastkey, step).\n * This function works only on command with the legacy_range_key_spec,\n * all other commands should be handled by getkeys_proc. \n * \n * If the commands keyspec is incomplete, no keys will be returned, and the provided\n * keys function should be called instead.\n * \n * NOTE: This function does not guarantee populating the flags for \n * the keys, in order to get flags you should use getKeysUsingKeySpecs. */\nint getKeysUsingLegacyRangeSpec(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int j, i = 0, last, first, step;\n    keyReference *keys;\n    UNUSED(argv);\n\n    if (cmd->legacy_range_key_spec.begin_search_type == KSPEC_BS_INVALID) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    first = cmd->legacy_range_key_spec.bs.index.pos;\n    last = cmd->legacy_range_key_spec.fk.range.lastkey;\n    if (last >= 0)\n        last += first;\n    step = cmd->legacy_range_key_spec.fk.range.keystep;\n\n    if (last < 0) last = argc+last;\n\n    int count = ((last - first)+1);\n    keys = getKeysPrepareResult(result, count);\n\n    for (j = first; j <= last; j += step) {\n        if (j >= argc || j < first) {\n            /* Modules commands, and standard commands with a not fixed number\n             * of arguments (negative arity parameter) do not have dispatch\n             * time arity checks, so we need to handle the case where the user\n             * passed an invalid number of arguments here. In this case we\n             * return no keys and expect the command implementation to report\n             * an arity or syntax error. */\n            if (cmd->flags & CMD_MODULE || cmd->arity < 0) {\n                result->numkeys = 0;\n                return 0;\n            } else {\n                serverPanic(\"Redis built-in command declared keys positions not matching the arity requirements.\");\n            }\n        }\n        keys[i].pos = j;\n        /* Flags are omitted from legacy key specs */\n        keys[i++].flags = 0;\n    }\n    result->numkeys = i;\n    return i;\n}\n\n/* Return all the arguments that are keys in the command passed via argc / argv.\n *\n * The command returns the positions of all the key arguments inside the array,\n * so the actual return value is a heap allocated array of integers. The\n * length of the array is returned by reference into *numkeys.\n *\n * 'cmd' must be point to the corresponding entry into the redisCommand\n * table, according to the command name in argv[0].\n *\n * This function uses the command table if a command-specific helper function\n * is not required, otherwise it calls the command-specific function. */\nint getKeysFromCommand(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    if (cmd->flags & CMD_MODULE_GETKEYS) {\n        return moduleGetCommandKeysViaAPI(cmd,argv,argc,result);\n    } else if (cmd->getkeys_proc) {\n        return cmd->getkeys_proc(cmd,argv,argc,result);\n    } else {\n        return getKeysUsingLegacyRangeSpec(cmd,argv,argc,result);\n    }\n}\n\n/* Free the result of getKeysFromCommand. */\nvoid getKeysFreeResult(getKeysResult *result) {\n    if (result && result->keys != result->keysbuf)\n        zfree(result->keys);\n}\n\n/* Helper function to extract keys from following commands:\n * COMMAND [destkey] <num-keys> <key> [...] <key> [...] ... <options>\n *\n * eg:\n * ZUNION <num-keys> <key> <key> ... <key> <options>\n * ZUNIONSTORE <destkey> <num-keys> <key> <key> ... <key> <options>\n *\n * 'storeKeyOfs': destkey index, 0 means destkey not exists.\n * 'keyCountOfs': num-keys index.\n * 'firstKeyOfs': firstkey index.\n * 'keyStep': the interval of each key, usually this value is 1.\n * \n * The commands using this function have a fully defined keyspec, so returning flags isn't needed. */\nint genericGetKeys(int storeKeyOfs, int keyCountOfs, int firstKeyOfs, int keyStep,\n                    robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n\n    num = atoi(argv[keyCountOfs]->ptr);\n    /* Sanity check. Don't return any key if the command is going to\n     * reply with syntax error. (no input keys). */\n    if (num < 1 || num > (argc - firstKeyOfs)/keyStep) {\n        result->numkeys = 0;\n        return 0;\n    }\n\n    int numkeys = storeKeyOfs ? num + 1 : num;\n    keys = getKeysPrepareResult(result, numkeys);\n    result->numkeys = numkeys;\n\n    /* Add all key positions for argv[firstKeyOfs...n] to keys[] */\n    for (i = 0; i < num; i++) {\n        keys[i].pos = firstKeyOfs+(i*keyStep);\n        keys[i].flags = 0;\n    } \n\n    if (storeKeyOfs) {\n        keys[num].pos = storeKeyOfs;\n        keys[num].flags = 0;\n    } \n    return result->numkeys;\n}\n\nint sintercardGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint zunionInterDiffStoreGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(1, 2, 3, 1, argv, argc, result);\n}\n\nint zunionInterDiffGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint evalGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint functionGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint lmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint blmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\nint zmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 1, 2, 1, argv, argc, result);\n}\n\nint bzmpopGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    UNUSED(cmd);\n    return genericGetKeys(0, 2, 3, 1, argv, argc, result);\n}\n\n/* Helper function to extract keys from the SORT RO command.\n *\n * SORT <sort-key>\n *\n * The second argument of SORT is always a key, however an arbitrary number of\n * keys may be accessed while doing the sort (the BY and GET args), so the\n * key-spec declares incomplete keys which is why we have to provide a concrete\n * implementation to fetch the keys.\n *\n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    result->numkeys = 1;\n    return result->numkeys;\n}\n\n/* Helper function to extract keys from the SORT command.\n *\n * SORT <sort-key> ... STORE <store-key> ...\n *\n * The first argument of SORT is always a key, however a list of options\n * follow in SQL-alike style. Here we parse just the minimum in order to\n * correctly identify keys in the \"STORE\" option. \n * \n * This command declares incomplete keys, so the flags are correctly set for this function */\nint sortGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, found_store = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    num = 0;\n    keys = getKeysPrepareResult(result, 2); /* Alloc 2 places for the worst case. */\n    keys[num].pos = 1; /* <sort-key> is always present. */\n    keys[num++].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n\n    /* Search for STORE option. By default we consider options to don't\n     * have arguments, so if we find an unknown option name we scan the\n     * next. However there are options with 1 or 2 arguments, so we\n     * provide a list here in order to skip the right number of args. */\n    struct {\n        char *name;\n        int skip;\n    } skiplist[] = {\n        {\"limit\", 2},\n        {\"get\", 1},\n        {\"by\", 1},\n        {NULL, 0} /* End of elements. */\n    };\n\n    for (i = 2; i < argc; i++) {\n        for (j = 0; skiplist[j].name != NULL; j++) {\n            if (!strcasecmp(argv[i]->ptr,skiplist[j].name)) {\n                i += skiplist[j].skip;\n                break;\n            } else if (!strcasecmp(argv[i]->ptr,\"store\") && i+1 < argc) {\n                /* Note: we don't increment \"num\" here and continue the loop\n                 * to be sure to process the *last* \"STORE\" option if multiple\n                 * ones are provided. This is same behavior as SORT. */\n                found_store = 1;\n                keys[num].pos = i+1; /* <store-key> */\n                keys[num].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n                break;\n            }\n        }\n    }\n    result->numkeys = num + found_store;\n    return result->numkeys;\n}\n\n/* This command declares incomplete keys, so the flags are correctly set for this function */\nint migrateGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, j, num, first;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Assume the obvious form. */\n    first = 3;\n    num = 1;\n\n    /* But check for the extended one with the KEYS option. */\n    struct {\n        char* name;\n        int skip;\n    } skip_keywords[] = {       \n        {\"copy\", 0},\n        {\"replace\", 0},\n        {\"auth\", 1},\n        {\"auth2\", 2},\n        {NULL, 0}\n    };\n    if (argc > 6) {\n        for (i = 6; i < argc; i++) {\n            if (!strcasecmp(argv[i]->ptr, \"keys\")) {\n                if (sdslen(argv[3]->ptr) > 0) {\n                    /* This is a syntax error. So ignore the keys and leave\n                     * the syntax error to be handled by migrateCommand. */\n                    num = 0; \n                } else {\n                    first = i + 1;\n                    num = argc - first;\n                }\n                break;\n            }\n            for (j = 0; skip_keywords[j].name != NULL; j++) {\n                if (!strcasecmp(argv[i]->ptr, skip_keywords[j].name)) {\n                    i += skip_keywords[j].skip;\n                    break;\n                }\n            }\n        }\n    }\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = 0; i < num; i++) {\n        keys[i].pos = first+i;\n        keys[i].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_DELETE;\n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from following commands:\n * GEORADIUS key x y radius unit [WITHDIST] [WITHHASH] [WITHCOORD] [ASC|DESC]\n *                             [COUNT count] [STORE key|STOREDIST key]\n * GEORADIUSBYMEMBER key member radius unit ... options ...\n * \n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint georadiusGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* Check for the presence of the stored key in the command */\n    int stored_key = -1;\n    for (i = 5; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        /* For the case when user specifies both \"store\" and \"storedist\" options, the\n         * second key specified would override the first key. This behavior is kept\n         * the same as in georadiusCommand method.\n         */\n        if ((!strcasecmp(arg, \"store\") || !strcasecmp(arg, \"storedist\")) && ((i+1) < argc)) {\n            stored_key = i+1;\n            i++;\n        }\n    }\n    num = 1 + (stored_key == -1 ? 0 : 1);\n\n    /* Keys in the command come from two places:\n     * argv[1] = key,\n     * argv[5...n] = stored key if present\n     */\n    keys = getKeysPrepareResult(result, num);\n\n    /* Add all key positions to keys[] */\n    keys[0].pos = 1;\n    keys[0].flags = 0;\n    if(num > 1) {\n         keys[1].pos = stored_key;\n         keys[1].flags = 0;\n    }\n    result->numkeys = num;\n    return num;\n}\n\n/* XREAD [BLOCK <milliseconds>] [COUNT <count>] [GROUP <groupname> <ttl>]\n *       STREAMS key_1 key_2 ... key_N ID_1 ID_2 ... ID_N\n *\n * This command has a fully defined keyspec, so returning flags isn't needed. */\nint xreadGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    int i, num = 0;\n    keyReference *keys;\n    UNUSED(cmd);\n\n    /* We need to parse the options of the command in order to seek the first\n     * \"STREAMS\" string which is actually the option. This is needed because\n     * \"STREAMS\" could also be the name of the consumer group and even the\n     * name of the stream key. */\n    int streams_pos = -1;\n    for (i = 1; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"block\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"count\")) {\n            i++; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"group\")) {\n            i += 2; /* Skip option argument. */\n        } else if (!strcasecmp(arg, \"noack\")) {\n            /* Nothing to do. */\n        } else if (!strcasecmp(arg, \"streams\")) {\n            streams_pos = i;\n            break;\n        } else {\n            break; /* Syntax error. */\n        }\n    }\n    if (streams_pos != -1) num = argc - streams_pos - 1;\n\n    /* Syntax error. */\n    if (streams_pos == -1 || num == 0 || num % 2 != 0) {\n        result->numkeys = 0;\n        return 0;\n    }\n    num /= 2; /* We have half the keys as there are arguments because\n                 there are also the IDs, one per key. */\n\n    keys = getKeysPrepareResult(result, num);\n    for (i = streams_pos+1; i < argc-num; i++) {\n        keys[i-streams_pos-1].pos = i;\n        keys[i-streams_pos-1].flags = 0; \n    } \n    result->numkeys = num;\n    return num;\n}\n\n/* Helper function to extract keys from the SET command, which may have\n * a read flag if the GET argument is passed in. */\nint setGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 3; i < argc; i++) {\n        char *arg = argv[i]->ptr;\n        if ((arg[0] == 'g' || arg[0] == 'G') &&\n            (arg[1] == 'e' || arg[1] == 'E') &&\n            (arg[2] == 't' || arg[2] == 'T') && arg[3] == '\\0')\n        {\n            keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n            return 1;\n        }\n    }\n\n    keys[0].flags = CMD_KEY_OW | CMD_KEY_UPDATE;\n    return 1;\n}\n\n/* Helper function to extract keys from the BITFIELD command, which may be\n * read-only if the BITFIELD GET subcommand is used. */\nint bitfieldGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    int readonly = 1;\n    UNUSED(cmd);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* We always know the position */\n    result->numkeys = 1;\n\n    for (int i = 2; i < argc; i++) {\n        int remargs = argc - i - 1; /* Remaining args other than current. */\n        char *arg = argv[i]->ptr;\n        if (!strcasecmp(arg, \"get\") && remargs >= 2) {\n            i += 2;\n        } else if ((!strcasecmp(arg, \"set\") || !strcasecmp(arg, \"incrby\")) && remargs >= 3) {\n            readonly = 0;\n            i += 3;\n            break;\n        } else if (!strcasecmp(arg, \"overflow\") && remargs >= 1) {\n            i += 1;\n        } else {\n            readonly = 0; /* Syntax error. safer to assume non-RO. */\n            break;\n        }\n    }\n\n    if (readonly) {\n        keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    } else {\n        keys[0].flags = CMD_KEY_RW | CMD_KEY_ACCESS | CMD_KEY_UPDATE;\n    }\n    return 1;\n}\n"}, {"id": "BDCCE769EF147F28", "name": "dictGetVal", "path": "redis/src/dict.c", "start": {"line": 860, "col": 1}, "end": {"line": 863, "col": 1}, "code": "    assert(entryHasValue(de));\n    return de->v.val;\n}\n\nint64_t dictGetSignedIntegerVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.s64;\n}\n\nuint64_t dictGetUnsignedIntegerVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.u64;\n}\n\ndouble dictGetDoubleVal(const dictEntry *de) {\n    assert(entryHasValue(de));\n    return de->v.d;\n}\n\n/* Returns a mutable reference to the value as a double within the entry. */\ndouble *dictGetDoubleValPtr(dictEntry *de) {\n    assert(entryHasValue(de));\n    return &de->v.d;\n}\n\n/* Returns the 'next' field of the entry or NULL if the entry doesn't have a\n * 'next' field. */\nstatic dictEntry *dictGetNext(const dictEntry *de) {\n    if (entryIsKey(de)) return NULL; /* there's no next */\n    if (entryIsNoValue(de)) return decodeEntryNoValue(de)->next;\n    return de->next;\n}\n\n/* Returns a pointer to the 'next' field in the entry or NULL if the entry\n * doesn't have a next field. */\nstatic dictEntry **dictGetNextRef(dictEntry *de) {\n    if (entryIsKey(de)) return NULL;\n    if (entryIsNoValue(de)) return &decodeEntryNoValue(de)->next;\n    return &de->next;\n}\n\nstatic void dictSetNext(dictEntry *de, dictEntry *next) {\n    assert(!entryIsKey(de));\n    if (entryIsNoValue(de)) {\n        dictEntryNoValue *entry = decodeEntryNoValue(de);\n        entry->next = next;\n    } else {\n        de->next = next;\n    }\n}\n\n/* Returns the memory usage in bytes of the dict, excluding the size of the keys\n * and values. */\nsize_t dictMemUsage(const dict *d) {\n    return dictSize(d) * sizeof(dictEntry) +\n        dictBuckets(d) * sizeof(dictEntry*);\n}\n\nsize_t dictEntryMemUsage(void) {\n    return sizeof(dictEntry);\n}\n\n/* A fingerprint is a 64 bit number that represents the state of the dictionary\n * at a given time, it's just a few dict properties xored together.\n * When an unsafe iterator is initialized, we get the dict fingerprint, and check\n * the fingerprint again when the iterator is released.\n * If the two fingerprints are different it means that the user of the iterator\n * performed forbidden operations against the dictionary while iterating. */\nunsigned long long dictFingerprint(dict *d) {\n    unsigned long long integers[6], hash = 0;\n    int j;\n\n    integers[0] = (long) d->ht_table[0];\n    integers[1] = d->ht_size_exp[0];\n    integers[2] = d->ht_used[0];\n    integers[3] = (long) d->ht_table[1];\n    integers[4] = d->ht_size_exp[1];\n    integers[5] = d->ht_used[1];\n\n    /* We hash N integers by summing every successive integer with the integer\n     * hashing of the previous sum. Basically:\n     *\n     * Result = hash(hash(hash(int1)+int2)+int3) ...\n     *\n     * This way the same set of integers in a different order will (likely) hash\n     * to a different number. */\n    for (j = 0; j < 6; j++) {\n        hash += integers[j];\n        /* For the hashing step we use Tomas Wang's 64 bit integer hash. */\n        hash = (~hash) + (hash << 21); // hash = (hash << 21) - hash - 1;\n        hash = hash ^ (hash >> 24);\n        hash = (hash + (hash << 3)) + (hash << 8); // hash * 265\n        hash = hash ^ (hash >> 14);\n        hash = (hash + (hash << 2)) + (hash << 4); // hash * 21\n        hash = hash ^ (hash >> 28);\n        hash = hash + (hash << 31);\n    }\n    return hash;\n}\n\nvoid dictInitIterator(dictIterator *iter, dict *d)\n{\n    iter->d = d;\n    iter->table = 0;\n    iter->index = -1;\n    iter->safe = 0;\n    iter->entry = NULL;\n    iter->nextEntry = NULL;\n}\n\nvoid dictInitSafeIterator(dictIterator *iter, dict *d)\n{\n    dictInitIterator(iter, d);\n    iter->safe = 1;\n}\n\nvoid dictResetIterator(dictIterator *iter)\n{\n    if (!(iter->index == -1 && iter->table == 0)) {\n        if (iter->safe)\n            dictResumeRehashing(iter->d);\n        else\n            assert(iter->fingerprint == dictFingerprint(iter->d));\n    }\n}\n\ndictIterator *dictGetIterator(dict *d)\n{\n    dictIterator *iter = zmalloc(sizeof(*iter));\n    dictInitIterator(iter, d);\n    return iter;\n}\n\ndictIterator *dictGetSafeIterator(dict *d) {\n    dictIterator *i = dictGetIterator(d);\n\n    i->safe = 1;\n    return i;\n}\n\ndictEntry *dictNext(dictIterator *iter)\n{\n    while (1) {\n        if (iter->entry == NULL) {\n            if (iter->index == -1 && iter->table == 0) {\n                if (iter->safe)\n                    dictPauseRehashing(iter->d);\n                else\n                    iter->fingerprint = dictFingerprint(iter->d);\n\n                /* skip the rehashed slots in table[0] */\n                if (dictIsRehashing(iter->d)) {\n                    iter->index = iter->d->rehashidx - 1;\n                }\n            }\n            iter->index++;\n            if (iter->index >= (long) DICTHT_SIZE(iter->d->ht_size_exp[iter->table])) {\n                if (dictIsRehashing(iter->d) && iter->table == 0) {\n                    iter->table++;\n                    iter->index = 0;\n                } else {\n                    break;\n                }\n            }\n            iter->entry = iter->d->ht_table[iter->table][iter->index];\n        } else {\n            iter->entry = iter->nextEntry;\n        }\n        if (iter->entry) {\n            /* We need to save the 'next' here, the iterator user\n             * may delete the entry we are returning. */\n            iter->nextEntry = dictGetNext(iter->entry);\n            return iter->entry;\n        }\n    }\n    return NULL;\n}\n\nvoid dictReleaseIterator(dictIterator *iter)\n{\n    dictResetIterator(iter);\n    zfree(iter);\n}\n\n/* Return a random entry from the hash table. Useful to\n * implement randomized algorithms */\ndictEntry *dictGetRandomKey(dict *d)\n{\n    dictEntry *he, *orighe;\n    unsigned long h;\n    int listlen, listele;\n\n    if (dictSize(d) == 0) return NULL;\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    if (dictIsRehashing(d)) {\n        unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n        do {\n            /* We are sure there are no elements in indexes from 0\n             * to rehashidx-1 */\n            h = d->rehashidx + (randomULong() % (dictBuckets(d) - d->rehashidx));\n            he = (h >= s0) ? d->ht_table[1][h - s0] : d->ht_table[0][h];\n        } while(he == NULL);\n    } else {\n        unsigned long m = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n        do {\n            h = randomULong() & m;\n            he = d->ht_table[0][h];\n        } while(he == NULL);\n    }\n\n    /* Now we found a non empty bucket, but it is a linked\n     * list and we need to get a random element from the list.\n     * The only sane way to do so is counting the elements and\n     * select a random index. */\n    listlen = 0;\n    orighe = he;\n    while(he) {\n        he = dictGetNext(he);\n        listlen++;\n    }\n    listele = random() % listlen;\n    he = orighe;\n    while(listele--) he = dictGetNext(he);\n    return he;\n}\n\n/* This function samples the dictionary to return a few keys from random\n * locations.\n *\n * It does not guarantee to return all the keys specified in 'count', nor\n * it does guarantee to return non-duplicated elements, however it will make\n * some effort to do both things.\n *\n * Returned pointers to hash table entries are stored into 'des' that\n * points to an array of dictEntry pointers. The array must have room for\n * at least 'count' elements, that is the argument we pass to the function\n * to tell how many random elements we need.\n *\n * The function returns the number of items stored into 'des', that may\n * be less than 'count' if the hash table has less than 'count' elements\n * inside, or if not enough elements were found in a reasonable amount of\n * steps.\n *\n * Note that this function is not suitable when you need a good distribution\n * of the returned items, but only when you need to \"sample\" a given number\n * of continuous elements to run some kind of algorithm or to produce\n * statistics. However the function is much faster than dictGetRandomKey()\n * at producing N elements. */\nunsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) {\n    unsigned long j; /* internal hash table id, 0 or 1. */\n    unsigned long tables; /* 1 or 2 tables? */\n    unsigned long stored = 0, maxsizemask;\n    unsigned long maxsteps;\n\n    if (dictSize(d) < count) count = dictSize(d);\n    maxsteps = count*10;\n\n    /* Try to do a rehashing work proportional to 'count'. */\n    for (j = 0; j < count; j++) {\n        if (dictIsRehashing(d))\n            _dictRehashStep(d);\n        else\n            break;\n    }\n\n    tables = dictIsRehashing(d) ? 2 : 1;\n    maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n    if (tables > 1 && maxsizemask < DICTHT_SIZE_MASK(d->ht_size_exp[1]))\n        maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n\n    /* Pick a random point inside the larger table. */\n    unsigned long i = randomULong() & maxsizemask;\n    unsigned long emptylen = 0; /* Continuous empty entries so far. */\n    while(stored < count && maxsteps--) {\n        for (j = 0; j < tables; j++) {\n            /* Invariant of the dict.c rehashing: up to the indexes already\n             * visited in ht[0] during the rehashing, there are no populated\n             * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */\n            if (tables == 2 && j == 0 && i < (unsigned long) d->rehashidx) {\n                /* Moreover, if we are currently out of range in the second\n                 * table, there will be no elements in both tables up to\n                 * the current rehashing index, so we jump if possible.\n                 * (this happens when going from big to small table). */\n                if (i >= DICTHT_SIZE(d->ht_size_exp[1]))\n                    i = d->rehashidx;\n                else\n                    continue;\n            }\n            if (i >= DICTHT_SIZE(d->ht_size_exp[j])) continue; /* Out of range for this table. */\n            dictEntry *he = d->ht_table[j][i];\n\n            /* Count contiguous empty buckets, and jump to other\n             * locations if they reach 'count' (with a minimum of 5). */\n            if (he == NULL) {\n                emptylen++;\n                if (emptylen >= 5 && emptylen > count) {\n                    i = randomULong() & maxsizemask;\n                    emptylen = 0;\n                }\n            } else {\n                emptylen = 0;\n                while (he) {\n                    /* Collect all the elements of the buckets found non empty while iterating.\n                     * To avoid the issue of being unable to sample the end of a long chain,\n                     * we utilize the Reservoir Sampling algorithm to optimize the sampling process.\n                     * This means that even when the maximum number of samples has been reached,\n                     * we continue sampling until we reach the end of the chain.\n                     * See https://en.wikipedia.org/wiki/Reservoir_sampling. */\n                    if (stored < count) {\n                        des[stored] = he;\n                    } else {\n                        unsigned long r = randomULong() % (stored + 1);\n                        if (r < count) des[r] = he;\n                    }\n\n                    he = dictGetNext(he);\n                    stored++;\n                }\n                if (stored >= count) goto end;\n            }\n        }\n        i = (i+1) & maxsizemask;\n    }\n\nend:\n    return stored > count ? count : stored;\n}\n\n\n/* Reallocate the dictEntry, key and value allocations in a bucket using the\n * provided allocation functions in order to defrag them. */\nstatic void dictDefragBucket(dictEntry **bucketref, dictDefragFunctions *defragfns) {\n    dictDefragAllocFunction *defragalloc = defragfns->defragAlloc;\n    dictDefragAllocFunction *defragkey = defragfns->defragKey;\n    dictDefragAllocFunction *defragval = defragfns->defragVal;\n    while (bucketref && *bucketref) {\n        dictEntry *de = *bucketref, *newde = NULL;\n        void *newkey = defragkey ? defragkey(dictGetKey(de)) : NULL;\n        void *newval = defragval ? defragval(dictGetVal(de)) : NULL;\n        if (entryIsKey(de)) {\n            if (newkey) *bucketref = newkey;\n            assert(entryIsKey(*bucketref));\n        } else if (entryIsNoValue(de)) {\n            dictEntryNoValue *entry = decodeEntryNoValue(de), *newentry;\n            if ((newentry = defragalloc(entry))) {\n                newde = encodeMaskedPtr(newentry, ENTRY_PTR_NO_VALUE);\n                entry = newentry;\n            }\n            if (newkey) entry->key = newkey;\n        } else {\n            assert(entryIsNormal(de));\n            newde = defragalloc(de);\n            if (newde) de = newde;\n            if (newkey) de->key = newkey;\n            if (newval) de->v.val = newval;\n        }\n        if (newde) {\n            *bucketref = newde;\n        }\n        bucketref = dictGetNextRef(*bucketref);\n    }\n}\n\n/* This is like dictGetRandomKey() from the POV of the API, but will do more\n * work to ensure a better distribution of the returned element.\n *\n * This function improves the distribution because the dictGetRandomKey()\n * problem is that it selects a random bucket, then it selects a random\n * element from the chain in the bucket. However elements being in different\n * chain lengths will have different probabilities of being reported. With\n * this function instead what we do is to consider a \"linear\" range of the table\n * that may be constituted of N buckets with chains of different lengths\n * appearing one after the other. Then we report a random element in the range.\n * In this way we smooth away the problem of different chain lengths. */\n#define GETFAIR_NUM_ENTRIES 15\ndictEntry *dictGetFairRandomKey(dict *d) {\n    dictEntry *entries[GETFAIR_NUM_ENTRIES];\n    unsigned int count = dictGetSomeKeys(d,entries,GETFAIR_NUM_ENTRIES);\n    /* Note that dictGetSomeKeys() may return zero elements in an unlucky\n     * run() even if there are actually elements inside the hash table. So\n     * when we get zero, we call the true dictGetRandomKey() that will always\n     * yield the element if the hash table has at least one. */\n    if (count == 0) return dictGetRandomKey(d);\n    unsigned int idx = rand() % count;\n    return entries[idx];\n}\n\n/* Function to reverse bits. Algorithm from:\n * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */\nstatic unsigned long rev(unsigned long v) {\n    unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2\n    unsigned long mask = ~0UL;\n    while ((s >>= 1) > 0) {\n        mask ^= (mask << s);\n        v = ((v >> s) & mask) | ((v << s) & ~mask);\n    }\n    return v;\n}\n\n/* dictScan() is used to iterate over the elements of a dictionary.\n *\n * Iterating works the following way:\n *\n * 1) Initially you call the function using a cursor (v) value of 0.\n * 2) The function performs one step of the iteration, and returns the\n *    new cursor value you must use in the next call.\n * 3) When the returned cursor is 0, the iteration is complete.\n *\n * The function guarantees all elements present in the\n * dictionary get returned between the start and end of the iteration.\n * However it is possible some elements get returned multiple times.\n *\n * For every element returned, the callback argument 'fn' is\n * called with 'privdata' as first argument and the dictionary entry\n * 'de' as second argument.\n *\n * HOW IT WORKS.\n *\n * The iteration algorithm was designed by Pieter Noordhuis.\n * The main idea is to increment a cursor starting from the higher order\n * bits. That is, instead of incrementing the cursor normally, the bits\n * of the cursor are reversed, then the cursor is incremented, and finally\n * the bits are reversed again.\n *\n * This strategy is needed because the hash table may be resized between\n * iteration calls.\n *\n * dict.c hash tables are always power of two in size, and they\n * use chaining, so the position of an element in a given table is given\n * by computing the bitwise AND between Hash(key) and SIZE-1\n * (where SIZE-1 is always the mask that is equivalent to taking the rest\n *  of the division between the Hash of the key and SIZE).\n *\n * For example if the current hash table size is 16, the mask is\n * (in binary) 1111. The position of a key in the hash table will always be\n * the last four bits of the hash output, and so forth.\n *\n * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE?\n *\n * If the hash table grows, elements can go anywhere in one multiple of\n * the old bucket: for example let's say we already iterated with\n * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16).\n *\n * If the hash table will be resized to 64 elements, then the new mask will\n * be 111111. The new buckets you obtain by substituting in ??1100\n * with either 0 or 1 can be targeted only by keys we already visited\n * when scanning the bucket 1100 in the smaller hash table.\n *\n * By iterating the higher bits first, because of the inverted counter, the\n * cursor does not need to restart if the table size gets bigger. It will\n * continue iterating using cursors without '1100' at the end, and also\n * without any other combination of the final 4 bits already explored.\n *\n * Similarly when the table size shrinks over time, for example going from\n * 16 to 8, if a combination of the lower three bits (the mask for size 8\n * is 111) were already completely explored, it would not be visited again\n * because we are sure we tried, for example, both 0111 and 1111 (all the\n * variations of the higher bit) so we don't need to test it again.\n *\n * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING!\n *\n * Yes, this is true, but we always iterate the smaller table first, then\n * we test all the expansions of the current cursor into the larger\n * table. For example if the current cursor is 101 and we also have a\n * larger table of size 16, we also test (0)101 and (1)101 inside the larger\n * table. This reduces the problem back to having only one table, where\n * the larger one, if it exists, is just an expansion of the smaller one.\n *\n * LIMITATIONS\n *\n * This iterator is completely stateless, and this is a huge advantage,\n * including no additional memory used.\n *\n * The disadvantages resulting from this design are:\n *\n * 1) It is possible we return elements more than once. However this is usually\n *    easy to deal with in the application level.\n * 2) The iterator must return multiple elements per call, as it needs to always\n *    return all the keys chained in a given bucket, and all the expansions, so\n *    we are sure we don't miss keys moving during rehashing.\n * 3) The reverse cursor is somewhat hard to understand at first, but this\n *    comment is supposed to help.\n */\nunsigned long dictScan(dict *d,\n                       unsigned long v,\n                       dictScanFunction *fn,\n                       void *privdata)\n{\n    return dictScanDefrag(d, v, fn, NULL, privdata);\n}\n\n/* Like dictScan, but additionally reallocates the memory used by the dict\n * entries using the provided allocation function. This feature was added for\n * the active defrag feature.\n *\n * The 'defragfns' callbacks are called with a pointer to memory that callback\n * can reallocate. The callbacks should return a new memory address or NULL,\n * where NULL means that no reallocation happened and the old memory is still\n * valid. */\nunsigned long dictScanDefrag(dict *d,\n                             unsigned long v,\n                             dictScanFunction *fn,\n                             dictDefragFunctions *defragfns,\n                             void *privdata)\n{\n    int htidx0, htidx1;\n    const dictEntry *de, *next;\n    unsigned long m0, m1;\n\n    if (dictSize(d) == 0) return 0;\n\n    /* This is needed in case the scan callback tries to do dictFind or alike. */\n    dictPauseRehashing(d);\n\n    if (!dictIsRehashing(d)) {\n        htidx0 = 0;\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Set unmasked bits so incrementing the reversed cursor\n         * operates on the masked bits */\n        v |= ~m0;\n\n        /* Increment the reverse cursor */\n        v = rev(v);\n        v++;\n        v = rev(v);\n\n    } else {\n        htidx0 = 0;\n        htidx1 = 1;\n\n        /* Make sure t0 is the smaller and t1 is the bigger table */\n        if (DICTHT_SIZE(d->ht_size_exp[htidx0]) > DICTHT_SIZE(d->ht_size_exp[htidx1])) {\n            htidx0 = 1;\n            htidx1 = 0;\n        }\n\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n        m1 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx1]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Iterate over indices in larger table that are the expansion\n         * of the index pointed to by the cursor in the smaller table */\n        do {\n            /* Emit entries at cursor */\n            if (defragfns) {\n                dictDefragBucket(&d->ht_table[htidx1][v & m1], defragfns);\n            }\n            de = d->ht_table[htidx1][v & m1];\n            while (de) {\n                next = dictGetNext(de);\n                fn(privdata, de);\n                de = next;\n            }\n\n            /* Increment the reverse cursor not covered by the smaller mask.*/\n            v |= ~m1;\n            v = rev(v);\n            v++;\n            v = rev(v);\n\n            /* Continue while bits covered by mask difference is non-zero */\n        } while (v & (m0 ^ m1));\n    }\n\n    dictResumeRehashing(d);\n\n    return v;\n}\n\n/* ------------------------- private functions ------------------------------ */\n\n/* Because we may need to allocate huge memory chunk at once when dict\n * resizes, we will check this allocation is allowed or not if the dict\n * type has resizeAllowed member function. */\nstatic int dictTypeResizeAllowed(dict *d, size_t size) {\n    if (d->type->resizeAllowed == NULL) return 1;\n    return d->type->resizeAllowed(\n                    DICTHT_SIZE(_dictNextExp(size)) * sizeof(dictEntry*),\n                    (double)d->ht_used[0] / DICTHT_SIZE(d->ht_size_exp[0]));\n}\n\n/* Returning DICT_OK indicates a successful expand or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that expand has not been triggered (may be try shrinking?)*/\nint dictExpandIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) == 0) {\n        dictExpand(d, DICT_HT_INITIAL_SIZE);\n        return DICT_OK;\n    }\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] >= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] >= dict_force_resize_ratio * DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0] + 1))\n            dictExpand(d, d->ht_used[0] + 1);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\n/* Expand the hash table if needed */\nstatic void _dictExpandIfNeeded(dict *d) {\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictExpandIfNeeded(d);\n}\n\n/* Returning DICT_OK indicates a successful shrinking or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that shrinking has not been triggered (may be try expanding?)*/\nint dictShrinkIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n    \n    /* If the size of hash table is DICT_HT_INITIAL_SIZE, don't shrink it. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) <= DICT_HT_INITIAL_SIZE) return DICT_OK;\n\n    /* If we reached below 1:8 elements/buckets ratio, and we are allowed to resize\n     * the hash table (global setting) or we should avoid it but the ratio is below 1:32,\n     * we'll trigger a resize of the hash table. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL <= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL * dict_force_resize_ratio <= DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0]))\n            dictShrink(d, d->ht_used[0]);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\nstatic void _dictShrinkIfNeeded(dict *d) \n{\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictShrinkIfNeeded(d);\n}\n\n/* Our hash table capability is a power of two */\nstatic signed char _dictNextExp(unsigned long size)\n{\n    if (size <= DICT_HT_INITIAL_SIZE) return DICT_HT_INITIAL_EXP;\n    if (size >= LONG_MAX) return (8*sizeof(long)-1);\n\n    return 8*sizeof(long) - __builtin_clzl(size-1);\n}\n\n/* Finds and returns the position within the dict where the provided key should\n * be inserted using dictInsertAtPosition if the key does not already exist in\n * the dict. If the key exists in the dict, NULL is returned and the optional\n * 'existing' entry pointer is populated, if provided. */\nvoid *dictFindPositionForInsert(dict *d, const void *key, dictEntry **existing) {\n    unsigned long idx, table;\n    dictEntry *he;\n    if (existing) *existing = NULL;\n    uint64_t hash = dictHashKey(d, key);\n    idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    /* Expand the hash table if needed */\n    _dictExpandIfNeeded(d);\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue; \n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        /* Search if this slot does not already contain the given key */\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                if (existing) *existing = he;\n                return NULL;\n            }\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n\n    /* If we are in the process of rehashing the hash table, the bucket is\n     * always returned in the context of the second (new) hash table. */\n    dictEntry **bucket = &d->ht_table[dictIsRehashing(d) ? 1 : 0][idx];\n    return bucket;\n}\n\nvoid dictEmpty(dict *d, void(callback)(dict*)) {\n    _dictClear(d,0,callback);\n    _dictClear(d,1,callback);\n    d->rehashidx = -1;\n    d->pauserehash = 0;\n    d->pauseAutoResize = 0;\n}\n\nvoid dictSetResizeEnabled(dictResizeEnable enable) {\n    dict_can_resize = enable;\n}\n\nuint64_t dictGetHash(dict *d, const void *key) {\n    return dictHashKey(d, key);\n}\n\n/* Finds the dictEntry using pointer and pre-calculated hash.\n * oldkey is a dead pointer and should not be accessed.\n * the hash value should be provided using dictGetHash.\n * no string / key comparison is performed.\n * return value is a pointer to the dictEntry if found, or NULL if not found. */\ndictEntry *dictFindEntryByPtrAndHash(dict *d, const void *oldptr, uint64_t hash) {\n    dictEntry *he;\n    unsigned long idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n    for (table = 0; table <= 1; table++) {\n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        he = d->ht_table[table][idx];\n        while(he) {\n            if (oldptr == dictGetKey(he))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\n/* Provides the old and new ht size for a given dictionary during rehashing. This method\n * should only be invoked during initialization/rehashing. */\nvoid dictRehashingInfo(dict *d, unsigned long long *from_size, unsigned long long *to_size) {\n    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n\n/* ------------------------------- Debugging ---------------------------------*/\n#define DICT_STATS_VECTLEN 50\nvoid dictFreeStats(dictStats *stats) {\n    zfree(stats->clvector);\n    zfree(stats);\n}\n\nvoid dictCombineStats(dictStats *from, dictStats *into) {\n    into->buckets += from->buckets;\n    into->maxChainLen = (from->maxChainLen > into->maxChainLen) ? from->maxChainLen : into->maxChainLen;\n    into->totalChainLen += from->totalChainLen;\n    into->htSize += from->htSize;\n    into->htUsed += from->htUsed;\n    for (int i = 0; i < DICT_STATS_VECTLEN; i++) {\n        into->clvector[i] += from->clvector[i];\n    }\n}\n\ndictStats *dictGetStatsHt(dict *d, int htidx, int full) {\n    unsigned long *clvector = zcalloc(sizeof(unsigned long) * DICT_STATS_VECTLEN);\n    dictStats *stats = zcalloc(sizeof(dictStats));\n    stats->htidx = htidx;\n    stats->clvector = clvector;\n    stats->htSize = DICTHT_SIZE(d->ht_size_exp[htidx]);\n    stats->htUsed = d->ht_used[htidx];\n    if (!full) return stats;\n    /* Compute stats. */\n    for (unsigned long i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]); i++) {\n        dictEntry *he;\n\n        if (d->ht_table[htidx][i] == NULL) {\n            clvector[0]++;\n            continue;\n        }\n        stats->buckets++;\n        /* For each hash entry on this slot... */\n        unsigned long chainlen = 0;\n        he = d->ht_table[htidx][i];\n        while(he) {\n            chainlen++;\n            he = dictGetNext(he);\n        }\n        clvector[(chainlen < DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++;\n        if (chainlen > stats->maxChainLen) stats->maxChainLen = chainlen;\n        stats->totalChainLen += chainlen;\n    }\n\n    return stats;\n}\n\n/* Generates human readable stats. */\nsize_t dictGetStatsMsg(char *buf, size_t bufsize, dictStats *stats, int full) {\n    if (stats->htUsed == 0) {\n        return snprintf(buf,bufsize,\n            \"Hash table %d stats (%s):\\n\"\n            \"No stats available for empty dictionaries\\n\",\n            stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\");\n    }\n    size_t l = 0;\n    l += snprintf(buf + l, bufsize - l,\n                  \"Hash table %d stats (%s):\\n\"\n                  \" table size: %lu\\n\"\n                  \" number of elements: %lu\\n\",\n                  stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\",\n                  stats->htSize, stats->htUsed);\n    if (full) {\n        l += snprintf(buf + l, bufsize - l,\n                      \" different slots: %lu\\n\"\n                      \" max chain length: %lu\\n\"\n                      \" avg chain length (counted): %.02f\\n\"\n                      \" avg chain length (computed): %.02f\\n\"\n                      \" Chain length distribution:\\n\",\n                      stats->buckets, stats->maxChainLen,\n                      (float) stats->totalChainLen / stats->buckets, (float) stats->htUsed / stats->buckets);\n\n        for (unsigned long i = 0; i < DICT_STATS_VECTLEN - 1; i++) {\n            if (stats->clvector[i] == 0) continue;\n            if (l >= bufsize) break;\n            l += snprintf(buf + l, bufsize - l,\n                          \"   %ld: %ld (%.02f%%)\\n\",\n                          i, stats->clvector[i], ((float) stats->clvector[i] / stats->htSize) * 100);\n        }\n    }\n\n    /* Make sure there is a NULL term at the end. */\n    buf[bufsize-1] = '\\0';\n"}, {"id": "7D7D2697AAE4AE85", "name": "signalKeyAsReady", "path": "redis/src/blocked.c", "start": {"line": 551, "col": 1}, "end": {"line": 553, "col": 1}, "code": "    signalKeyAsReadyLogic(db, key, type, 0);\n}\n\nvoid signalDeletedKeyAsReady(redisDb *db, robj *key, int type) {\n    signalKeyAsReadyLogic(db, key, type, 1);\n}\n\n/* Helper function for handleClientsBlockedOnKeys(). This function is called\n * whenever a key is ready. we iterate over all the clients blocked on this key\n * and try to re-execute the command (in case the key is still available). */\nstatic void handleClientsBlockedOnKey(readyList *rl) {\n\n    /* We serve clients in the same order they blocked for\n     * this key, from the first blocked to the last. */\n    dictEntry *de = dictFind(rl->db->blocking_keys,rl->key);\n\n    if (de) {\n        list *clients = dictGetVal(de);\n        listNode *ln;\n        listIter li;\n        listRewind(clients,&li);\n\n        /* Avoid processing more than the initial count so that we're not stuck\n         * in an endless loop in case the reprocessing of the command blocks again. */\n        long count = listLength(clients);\n        while ((ln = listNext(&li)) && count--) {\n            client *receiver = listNodeValue(ln);\n            robj *o = lookupKeyReadWithFlags(rl->db, rl->key, LOOKUP_NOEFFECTS);\n            /* 1. In case new key was added/touched we need to verify it satisfy the\n             *    blocked type, since we might process the wrong key type.\n             * 2. We want to serve clients blocked on module keys\n             *    regardless of the object type: we don't know what the\n             *    module is trying to accomplish right now.\n             * 3. In case of XREADGROUP call we will want to unblock on any change in object type\n             *    or in case the key was deleted, since the group is no longer valid. */\n            if ((o != NULL && (receiver->bstate.btype == getBlockedTypeByType(o->type))) ||\n                (o != NULL && (receiver->bstate.btype == BLOCKED_MODULE)) ||\n                (receiver->bstate.unblock_on_nokey))\n            {\n                if (receiver->bstate.btype != BLOCKED_MODULE)\n                    unblockClientOnKey(receiver, rl->key);\n                else\n                    moduleUnblockClientOnKey(receiver, rl->key);\n            }\n        }\n    }\n}\n\n/* block a client due to wait command */\nvoid blockForReplication(client *c, mstime_t timeout, long long offset, long numreplicas) {\n    c->bstate.timeout = timeout;\n    c->bstate.reploffset = offset;\n    c->bstate.numreplicas = numreplicas;\n    listAddNodeHead(server.clients_waiting_acks,c);\n    blockClient(c,BLOCKED_WAIT);\n}\n\n/* block a client due to waitaof command */\nvoid blockForAofFsync(client *c, mstime_t timeout, long long offset, int numlocal, long numreplicas) {\n    c->bstate.timeout = timeout;\n    c->bstate.reploffset = offset;\n    c->bstate.numreplicas = numreplicas;\n    c->bstate.numlocal = numlocal;\n    listAddNodeHead(server.clients_waiting_acks,c);\n    blockClient(c,BLOCKED_WAITAOF);\n}\n\n/* Postpone client from executing a command. For example the server might be busy\n * requesting to avoid processing clients commands which will be processed later\n * when the it is ready to accept them. */\nvoid blockPostponeClient(client *c) {\n    c->bstate.timeout = 0;\n    blockClient(c,BLOCKED_POSTPONE);\n    listAddNodeTail(server.postponed_clients, c);\n    c->postponed_list_node = listLast(server.postponed_clients);\n    /* Mark this client to execute its command */\n    c->flags |= CLIENT_PENDING_COMMAND;\n}\n\n/* Block client due to shutdown command */\nvoid blockClientShutdown(client *c) {\n    blockClient(c, BLOCKED_SHUTDOWN);\n}\n\n/* Unblock a client once a specific key became available for it.\n * This function will remove the client from the list of clients blocked on this key\n * and also remove the key from the dictionary of keys this client is blocked on.\n * in case the client has a command pending it will process it immediately.  */\nstatic void unblockClientOnKey(client *c, robj *key) {\n    dictEntry *de;\n\n    de = dictFind(c->bstate.keys, key);\n    releaseBlockedEntry(c, de, 1);\n\n    /* Only in case of blocking API calls, we might be blocked on several keys.\n       however we should force unblock the entire blocking keys */\n    serverAssert(c->bstate.btype == BLOCKED_STREAM ||\n                c->bstate.btype == BLOCKED_LIST   ||\n                c->bstate.btype == BLOCKED_ZSET);\n\n    /* We need to unblock the client before calling processCommandAndResetClient\n     * because it checks the CLIENT_BLOCKED flag */\n    unblockClient(c, 0);\n    /* In case this client was blocked on keys during command\n     * we need to re process the command again */\n    if (c->flags & CLIENT_PENDING_COMMAND) {\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n        /* We want the command processing and the unblock handler (see RM_Call 'K' option)\n         * to run atomically, this is why we must enter the execution unit here before\n         * running the command, and exit the execution unit after calling the unblock handler (if exists).\n         * Notice that we also must set the current client so it will be available\n         * when we will try to send the client side caching notification (done on 'afterCommand'). */\n        client *old_client = server.current_client;\n        server.current_client = c;\n        enterExecutionUnit(1, 0);\n        processCommandAndResetClient(c);\n        if (!(c->flags & CLIENT_BLOCKED)) {\n            if (c->flags & CLIENT_MODULE) {\n                moduleCallCommandUnblockedHandler(c);\n            } else {\n                queueClientForReprocessing(c);\n            }\n        }\n        exitExecutionUnit();\n        afterCommand(c);\n        server.current_client = old_client;\n    }\n}\n\n/* Unblock a client blocked on the specific key from module context.\n * This function will try to serve the module call, and in case it succeeds,\n * it will add the client to the list of module unblocked clients which will\n * be processed in moduleHandleBlockedClients. */\nstatic void moduleUnblockClientOnKey(client *c, robj *key) {\n    long long prev_error_replies = server.stat_total_error_replies;\n    client *old_client = server.current_client;\n    server.current_client = c;\n    monotime replyTimer;\n    elapsedStart(&replyTimer);\n\n    if (moduleTryServeClientBlockedOnKey(c, key)) {\n        updateStatsOnUnblock(c, 0, elapsedUs(replyTimer), server.stat_total_error_replies != prev_error_replies);\n        moduleUnblockClient(c);\n    }\n    /* We need to call afterCommand even if the client was not unblocked\n     * in order to propagate any changes that could have been done inside\n     * moduleTryServeClientBlockedOnKey */\n    afterCommand(c);\n    server.current_client = old_client;\n}\n\n/* Unblock a client which is currently Blocked on and provided a timeout.\n * The implementation will first reply to the blocked client with null response\n * or, in case of module blocked client the timeout callback will be used.\n * In this case since we might have a command pending\n * we want to remove the pending flag to indicate we already responded to the\n * command with timeout reply. */\nvoid unblockClientOnTimeout(client *c) {\n    /* The client has been unlocked (in the moduleUnblocked list), return ASAP. */\n    if (c->bstate.btype == BLOCKED_MODULE && isModuleClientUnblocked(c)) return;\n\n    replyToBlockedClientTimedOut(c);\n    if (c->flags & CLIENT_PENDING_COMMAND)\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n    unblockClient(c, 1);\n}\n\n/* Unblock a client which is currently Blocked with error.\n * If err_str is provided it will be used to reply to the blocked client */\nvoid unblockClientOnError(client *c, const char *err_str) {\n    if (err_str)\n        addReplyError(c, err_str);\n    updateStatsOnUnblock(c, 0, 0, 1);\n    if (c->flags & CLIENT_PENDING_COMMAND)\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n    unblockClient(c, 1);\n}\n\n/* sets blocking_keys to the total number of keys which has at least one client blocked on them\n * sets blocking_keys_on_nokey to the total number of keys which has at least one client\n * blocked on them to be written or deleted */\nvoid totalNumberOfBlockingKeys(unsigned long *blocking_keys, unsigned long *bloking_keys_on_nokey) {\n    unsigned long bkeys=0, bkeys_on_nokey=0;\n    for (int j = 0; j < server.dbnum; j++) {\n        bkeys += dictSize(server.db[j].blocking_keys);\n        bkeys_on_nokey += dictSize(server.db[j].blocking_keys_unblock_on_nokey);\n    }\n    if (blocking_keys)\n        *blocking_keys = bkeys;\n    if (bloking_keys_on_nokey)\n        *bloking_keys_on_nokey = bkeys_on_nokey;\n}\n\nvoid blockedBeforeSleep(void) {\n    /* Handle precise timeouts of blocked clients. */\n    handleBlockedClientsTimeout();\n\n    /* Unblock all the clients blocked for synchronous replication\n     * in WAIT or WAITAOF. */\n    if (listLength(server.clients_waiting_acks))\n        processClientsWaitingReplicas();\n\n    /* Try to process blocked clients every once in while.\n     *\n     * Example: A module calls RM_SignalKeyAsReady from within a timer callback\n     * (So we don't visit processCommand() at all).\n     *\n     * This may unblock clients, so must be done before processUnblockedClients */\n    handleClientsBlockedOnKeys();\n\n    /* Check if there are clients unblocked by modules that implement\n     * blocking commands. */\n    if (moduleCount())\n        moduleHandleBlockedClients();\n\n    /* Try to process pending commands for clients that were just unblocked. */\n    if (listLength(server.unblocked_clients))\n        processUnblockedClients();\n}\n"}, {"id": "A4F5851C66817980", "name": "dictReleaseIterator", "path": "redis/src/dict.c", "start": {"line": 1039, "col": 1}, "end": {"line": 1043, "col": 1}, "code": "{\n    dictResetIterator(iter);\n    zfree(iter);\n}\n\n/* Return a random entry from the hash table. Useful to\n * implement randomized algorithms */\ndictEntry *dictGetRandomKey(dict *d)\n{\n    dictEntry *he, *orighe;\n    unsigned long h;\n    int listlen, listele;\n\n    if (dictSize(d) == 0) return NULL;\n    if (dictIsRehashing(d)) _dictRehashStep(d);\n    if (dictIsRehashing(d)) {\n        unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n        do {\n            /* We are sure there are no elements in indexes from 0\n             * to rehashidx-1 */\n            h = d->rehashidx + (randomULong() % (dictBuckets(d) - d->rehashidx));\n            he = (h >= s0) ? d->ht_table[1][h - s0] : d->ht_table[0][h];\n        } while(he == NULL);\n    } else {\n        unsigned long m = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n        do {\n            h = randomULong() & m;\n            he = d->ht_table[0][h];\n        } while(he == NULL);\n    }\n\n    /* Now we found a non empty bucket, but it is a linked\n     * list and we need to get a random element from the list.\n     * The only sane way to do so is counting the elements and\n     * select a random index. */\n    listlen = 0;\n    orighe = he;\n    while(he) {\n        he = dictGetNext(he);\n        listlen++;\n    }\n    listele = random() % listlen;\n    he = orighe;\n    while(listele--) he = dictGetNext(he);\n    return he;\n}\n\n/* This function samples the dictionary to return a few keys from random\n * locations.\n *\n * It does not guarantee to return all the keys specified in 'count', nor\n * it does guarantee to return non-duplicated elements, however it will make\n * some effort to do both things.\n *\n * Returned pointers to hash table entries are stored into 'des' that\n * points to an array of dictEntry pointers. The array must have room for\n * at least 'count' elements, that is the argument we pass to the function\n * to tell how many random elements we need.\n *\n * The function returns the number of items stored into 'des', that may\n * be less than 'count' if the hash table has less than 'count' elements\n * inside, or if not enough elements were found in a reasonable amount of\n * steps.\n *\n * Note that this function is not suitable when you need a good distribution\n * of the returned items, but only when you need to \"sample\" a given number\n * of continuous elements to run some kind of algorithm or to produce\n * statistics. However the function is much faster than dictGetRandomKey()\n * at producing N elements. */\nunsigned int dictGetSomeKeys(dict *d, dictEntry **des, unsigned int count) {\n    unsigned long j; /* internal hash table id, 0 or 1. */\n    unsigned long tables; /* 1 or 2 tables? */\n    unsigned long stored = 0, maxsizemask;\n    unsigned long maxsteps;\n\n    if (dictSize(d) < count) count = dictSize(d);\n    maxsteps = count*10;\n\n    /* Try to do a rehashing work proportional to 'count'. */\n    for (j = 0; j < count; j++) {\n        if (dictIsRehashing(d))\n            _dictRehashStep(d);\n        else\n            break;\n    }\n\n    tables = dictIsRehashing(d) ? 2 : 1;\n    maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n    if (tables > 1 && maxsizemask < DICTHT_SIZE_MASK(d->ht_size_exp[1]))\n        maxsizemask = DICTHT_SIZE_MASK(d->ht_size_exp[1]);\n\n    /* Pick a random point inside the larger table. */\n    unsigned long i = randomULong() & maxsizemask;\n    unsigned long emptylen = 0; /* Continuous empty entries so far. */\n    while(stored < count && maxsteps--) {\n        for (j = 0; j < tables; j++) {\n            /* Invariant of the dict.c rehashing: up to the indexes already\n             * visited in ht[0] during the rehashing, there are no populated\n             * buckets, so we can skip ht[0] for indexes between 0 and idx-1. */\n            if (tables == 2 && j == 0 && i < (unsigned long) d->rehashidx) {\n                /* Moreover, if we are currently out of range in the second\n                 * table, there will be no elements in both tables up to\n                 * the current rehashing index, so we jump if possible.\n                 * (this happens when going from big to small table). */\n                if (i >= DICTHT_SIZE(d->ht_size_exp[1]))\n                    i = d->rehashidx;\n                else\n                    continue;\n            }\n            if (i >= DICTHT_SIZE(d->ht_size_exp[j])) continue; /* Out of range for this table. */\n            dictEntry *he = d->ht_table[j][i];\n\n            /* Count contiguous empty buckets, and jump to other\n             * locations if they reach 'count' (with a minimum of 5). */\n            if (he == NULL) {\n                emptylen++;\n                if (emptylen >= 5 && emptylen > count) {\n                    i = randomULong() & maxsizemask;\n                    emptylen = 0;\n                }\n            } else {\n                emptylen = 0;\n                while (he) {\n                    /* Collect all the elements of the buckets found non empty while iterating.\n                     * To avoid the issue of being unable to sample the end of a long chain,\n                     * we utilize the Reservoir Sampling algorithm to optimize the sampling process.\n                     * This means that even when the maximum number of samples has been reached,\n                     * we continue sampling until we reach the end of the chain.\n                     * See https://en.wikipedia.org/wiki/Reservoir_sampling. */\n                    if (stored < count) {\n                        des[stored] = he;\n                    } else {\n                        unsigned long r = randomULong() % (stored + 1);\n                        if (r < count) des[r] = he;\n                    }\n\n                    he = dictGetNext(he);\n                    stored++;\n                }\n                if (stored >= count) goto end;\n            }\n        }\n        i = (i+1) & maxsizemask;\n    }\n\nend:\n    return stored > count ? count : stored;\n}\n\n\n/* Reallocate the dictEntry, key and value allocations in a bucket using the\n * provided allocation functions in order to defrag them. */\nstatic void dictDefragBucket(dictEntry **bucketref, dictDefragFunctions *defragfns) {\n    dictDefragAllocFunction *defragalloc = defragfns->defragAlloc;\n    dictDefragAllocFunction *defragkey = defragfns->defragKey;\n    dictDefragAllocFunction *defragval = defragfns->defragVal;\n    while (bucketref && *bucketref) {\n        dictEntry *de = *bucketref, *newde = NULL;\n        void *newkey = defragkey ? defragkey(dictGetKey(de)) : NULL;\n        void *newval = defragval ? defragval(dictGetVal(de)) : NULL;\n        if (entryIsKey(de)) {\n            if (newkey) *bucketref = newkey;\n            assert(entryIsKey(*bucketref));\n        } else if (entryIsNoValue(de)) {\n            dictEntryNoValue *entry = decodeEntryNoValue(de), *newentry;\n            if ((newentry = defragalloc(entry))) {\n                newde = encodeMaskedPtr(newentry, ENTRY_PTR_NO_VALUE);\n                entry = newentry;\n            }\n            if (newkey) entry->key = newkey;\n        } else {\n            assert(entryIsNormal(de));\n            newde = defragalloc(de);\n            if (newde) de = newde;\n            if (newkey) de->key = newkey;\n            if (newval) de->v.val = newval;\n        }\n        if (newde) {\n            *bucketref = newde;\n        }\n        bucketref = dictGetNextRef(*bucketref);\n    }\n}\n\n/* This is like dictGetRandomKey() from the POV of the API, but will do more\n * work to ensure a better distribution of the returned element.\n *\n * This function improves the distribution because the dictGetRandomKey()\n * problem is that it selects a random bucket, then it selects a random\n * element from the chain in the bucket. However elements being in different\n * chain lengths will have different probabilities of being reported. With\n * this function instead what we do is to consider a \"linear\" range of the table\n * that may be constituted of N buckets with chains of different lengths\n * appearing one after the other. Then we report a random element in the range.\n * In this way we smooth away the problem of different chain lengths. */\n#define GETFAIR_NUM_ENTRIES 15\ndictEntry *dictGetFairRandomKey(dict *d) {\n    dictEntry *entries[GETFAIR_NUM_ENTRIES];\n    unsigned int count = dictGetSomeKeys(d,entries,GETFAIR_NUM_ENTRIES);\n    /* Note that dictGetSomeKeys() may return zero elements in an unlucky\n     * run() even if there are actually elements inside the hash table. So\n     * when we get zero, we call the true dictGetRandomKey() that will always\n     * yield the element if the hash table has at least one. */\n    if (count == 0) return dictGetRandomKey(d);\n    unsigned int idx = rand() % count;\n    return entries[idx];\n}\n\n/* Function to reverse bits. Algorithm from:\n * http://graphics.stanford.edu/~seander/bithacks.html#ReverseParallel */\nstatic unsigned long rev(unsigned long v) {\n    unsigned long s = CHAR_BIT * sizeof(v); // bit size; must be power of 2\n    unsigned long mask = ~0UL;\n    while ((s >>= 1) > 0) {\n        mask ^= (mask << s);\n        v = ((v >> s) & mask) | ((v << s) & ~mask);\n    }\n    return v;\n}\n\n/* dictScan() is used to iterate over the elements of a dictionary.\n *\n * Iterating works the following way:\n *\n * 1) Initially you call the function using a cursor (v) value of 0.\n * 2) The function performs one step of the iteration, and returns the\n *    new cursor value you must use in the next call.\n * 3) When the returned cursor is 0, the iteration is complete.\n *\n * The function guarantees all elements present in the\n * dictionary get returned between the start and end of the iteration.\n * However it is possible some elements get returned multiple times.\n *\n * For every element returned, the callback argument 'fn' is\n * called with 'privdata' as first argument and the dictionary entry\n * 'de' as second argument.\n *\n * HOW IT WORKS.\n *\n * The iteration algorithm was designed by Pieter Noordhuis.\n * The main idea is to increment a cursor starting from the higher order\n * bits. That is, instead of incrementing the cursor normally, the bits\n * of the cursor are reversed, then the cursor is incremented, and finally\n * the bits are reversed again.\n *\n * This strategy is needed because the hash table may be resized between\n * iteration calls.\n *\n * dict.c hash tables are always power of two in size, and they\n * use chaining, so the position of an element in a given table is given\n * by computing the bitwise AND between Hash(key) and SIZE-1\n * (where SIZE-1 is always the mask that is equivalent to taking the rest\n *  of the division between the Hash of the key and SIZE).\n *\n * For example if the current hash table size is 16, the mask is\n * (in binary) 1111. The position of a key in the hash table will always be\n * the last four bits of the hash output, and so forth.\n *\n * WHAT HAPPENS IF THE TABLE CHANGES IN SIZE?\n *\n * If the hash table grows, elements can go anywhere in one multiple of\n * the old bucket: for example let's say we already iterated with\n * a 4 bit cursor 1100 (the mask is 1111 because hash table size = 16).\n *\n * If the hash table will be resized to 64 elements, then the new mask will\n * be 111111. The new buckets you obtain by substituting in ??1100\n * with either 0 or 1 can be targeted only by keys we already visited\n * when scanning the bucket 1100 in the smaller hash table.\n *\n * By iterating the higher bits first, because of the inverted counter, the\n * cursor does not need to restart if the table size gets bigger. It will\n * continue iterating using cursors without '1100' at the end, and also\n * without any other combination of the final 4 bits already explored.\n *\n * Similarly when the table size shrinks over time, for example going from\n * 16 to 8, if a combination of the lower three bits (the mask for size 8\n * is 111) were already completely explored, it would not be visited again\n * because we are sure we tried, for example, both 0111 and 1111 (all the\n * variations of the higher bit) so we don't need to test it again.\n *\n * WAIT... YOU HAVE *TWO* TABLES DURING REHASHING!\n *\n * Yes, this is true, but we always iterate the smaller table first, then\n * we test all the expansions of the current cursor into the larger\n * table. For example if the current cursor is 101 and we also have a\n * larger table of size 16, we also test (0)101 and (1)101 inside the larger\n * table. This reduces the problem back to having only one table, where\n * the larger one, if it exists, is just an expansion of the smaller one.\n *\n * LIMITATIONS\n *\n * This iterator is completely stateless, and this is a huge advantage,\n * including no additional memory used.\n *\n * The disadvantages resulting from this design are:\n *\n * 1) It is possible we return elements more than once. However this is usually\n *    easy to deal with in the application level.\n * 2) The iterator must return multiple elements per call, as it needs to always\n *    return all the keys chained in a given bucket, and all the expansions, so\n *    we are sure we don't miss keys moving during rehashing.\n * 3) The reverse cursor is somewhat hard to understand at first, but this\n *    comment is supposed to help.\n */\nunsigned long dictScan(dict *d,\n                       unsigned long v,\n                       dictScanFunction *fn,\n                       void *privdata)\n{\n    return dictScanDefrag(d, v, fn, NULL, privdata);\n}\n\n/* Like dictScan, but additionally reallocates the memory used by the dict\n * entries using the provided allocation function. This feature was added for\n * the active defrag feature.\n *\n * The 'defragfns' callbacks are called with a pointer to memory that callback\n * can reallocate. The callbacks should return a new memory address or NULL,\n * where NULL means that no reallocation happened and the old memory is still\n * valid. */\nunsigned long dictScanDefrag(dict *d,\n                             unsigned long v,\n                             dictScanFunction *fn,\n                             dictDefragFunctions *defragfns,\n                             void *privdata)\n{\n    int htidx0, htidx1;\n    const dictEntry *de, *next;\n    unsigned long m0, m1;\n\n    if (dictSize(d) == 0) return 0;\n\n    /* This is needed in case the scan callback tries to do dictFind or alike. */\n    dictPauseRehashing(d);\n\n    if (!dictIsRehashing(d)) {\n        htidx0 = 0;\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Set unmasked bits so incrementing the reversed cursor\n         * operates on the masked bits */\n        v |= ~m0;\n\n        /* Increment the reverse cursor */\n        v = rev(v);\n        v++;\n        v = rev(v);\n\n    } else {\n        htidx0 = 0;\n        htidx1 = 1;\n\n        /* Make sure t0 is the smaller and t1 is the bigger table */\n        if (DICTHT_SIZE(d->ht_size_exp[htidx0]) > DICTHT_SIZE(d->ht_size_exp[htidx1])) {\n            htidx0 = 1;\n            htidx1 = 0;\n        }\n\n        m0 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx0]);\n        m1 = DICTHT_SIZE_MASK(d->ht_size_exp[htidx1]);\n\n        /* Emit entries at cursor */\n        if (defragfns) {\n            dictDefragBucket(&d->ht_table[htidx0][v & m0], defragfns);\n        }\n        de = d->ht_table[htidx0][v & m0];\n        while (de) {\n            next = dictGetNext(de);\n            fn(privdata, de);\n            de = next;\n        }\n\n        /* Iterate over indices in larger table that are the expansion\n         * of the index pointed to by the cursor in the smaller table */\n        do {\n            /* Emit entries at cursor */\n            if (defragfns) {\n                dictDefragBucket(&d->ht_table[htidx1][v & m1], defragfns);\n            }\n            de = d->ht_table[htidx1][v & m1];\n            while (de) {\n                next = dictGetNext(de);\n                fn(privdata, de);\n                de = next;\n            }\n\n            /* Increment the reverse cursor not covered by the smaller mask.*/\n            v |= ~m1;\n            v = rev(v);\n            v++;\n            v = rev(v);\n\n            /* Continue while bits covered by mask difference is non-zero */\n        } while (v & (m0 ^ m1));\n    }\n\n    dictResumeRehashing(d);\n\n    return v;\n}\n\n/* ------------------------- private functions ------------------------------ */\n\n/* Because we may need to allocate huge memory chunk at once when dict\n * resizes, we will check this allocation is allowed or not if the dict\n * type has resizeAllowed member function. */\nstatic int dictTypeResizeAllowed(dict *d, size_t size) {\n    if (d->type->resizeAllowed == NULL) return 1;\n    return d->type->resizeAllowed(\n                    DICTHT_SIZE(_dictNextExp(size)) * sizeof(dictEntry*),\n                    (double)d->ht_used[0] / DICTHT_SIZE(d->ht_size_exp[0]));\n}\n\n/* Returning DICT_OK indicates a successful expand or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that expand has not been triggered (may be try shrinking?)*/\nint dictExpandIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n\n    /* If the hash table is empty expand it to the initial size. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) == 0) {\n        dictExpand(d, DICT_HT_INITIAL_SIZE);\n        return DICT_OK;\n    }\n\n    /* If we reached the 1:1 ratio, and we are allowed to resize the hash\n     * table (global setting) or we should avoid it but the ratio between\n     * elements/buckets is over the \"safe\" threshold, we resize doubling\n     * the number of buckets. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] >= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] >= dict_force_resize_ratio * DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0] + 1))\n            dictExpand(d, d->ht_used[0] + 1);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\n/* Expand the hash table if needed */\nstatic void _dictExpandIfNeeded(dict *d) {\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictExpandIfNeeded(d);\n}\n\n/* Returning DICT_OK indicates a successful shrinking or the dictionary is undergoing rehashing, \n * and there is nothing else we need to do about this dictionary currently. While DICT_ERR indicates\n * that shrinking has not been triggered (may be try expanding?)*/\nint dictShrinkIfNeeded(dict *d) {\n    /* Incremental rehashing already in progress. Return. */\n    if (dictIsRehashing(d)) return DICT_OK;\n    \n    /* If the size of hash table is DICT_HT_INITIAL_SIZE, don't shrink it. */\n    if (DICTHT_SIZE(d->ht_size_exp[0]) <= DICT_HT_INITIAL_SIZE) return DICT_OK;\n\n    /* If we reached below 1:8 elements/buckets ratio, and we are allowed to resize\n     * the hash table (global setting) or we should avoid it but the ratio is below 1:32,\n     * we'll trigger a resize of the hash table. */\n    if ((dict_can_resize == DICT_RESIZE_ENABLE &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL <= DICTHT_SIZE(d->ht_size_exp[0])) ||\n        (dict_can_resize != DICT_RESIZE_FORBID &&\n         d->ht_used[0] * HASHTABLE_MIN_FILL * dict_force_resize_ratio <= DICTHT_SIZE(d->ht_size_exp[0])))\n    {\n        if (dictTypeResizeAllowed(d, d->ht_used[0]))\n            dictShrink(d, d->ht_used[0]);\n        return DICT_OK;\n    }\n    return DICT_ERR;\n}\n\nstatic void _dictShrinkIfNeeded(dict *d) \n{\n    /* Automatic resizing is disallowed. Return */\n    if (d->pauseAutoResize > 0) return;\n\n    dictShrinkIfNeeded(d);\n}\n\n/* Our hash table capability is a power of two */\nstatic signed char _dictNextExp(unsigned long size)\n{\n    if (size <= DICT_HT_INITIAL_SIZE) return DICT_HT_INITIAL_EXP;\n    if (size >= LONG_MAX) return (8*sizeof(long)-1);\n\n    return 8*sizeof(long) - __builtin_clzl(size-1);\n}\n\n/* Finds and returns the position within the dict where the provided key should\n * be inserted using dictInsertAtPosition if the key does not already exist in\n * the dict. If the key exists in the dict, NULL is returned and the optional\n * 'existing' entry pointer is populated, if provided. */\nvoid *dictFindPositionForInsert(dict *d, const void *key, dictEntry **existing) {\n    unsigned long idx, table;\n    dictEntry *he;\n    if (existing) *existing = NULL;\n    uint64_t hash = dictHashKey(d, key);\n    idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    /* Expand the hash table if needed */\n    _dictExpandIfNeeded(d);\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue; \n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        /* Search if this slot does not already contain the given key */\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                if (existing) *existing = he;\n                return NULL;\n            }\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n\n    /* If we are in the process of rehashing the hash table, the bucket is\n     * always returned in the context of the second (new) hash table. */\n    dictEntry **bucket = &d->ht_table[dictIsRehashing(d) ? 1 : 0][idx];\n    return bucket;\n}\n\nvoid dictEmpty(dict *d, void(callback)(dict*)) {\n    _dictClear(d,0,callback);\n    _dictClear(d,1,callback);\n    d->rehashidx = -1;\n    d->pauserehash = 0;\n    d->pauseAutoResize = 0;\n}\n\nvoid dictSetResizeEnabled(dictResizeEnable enable) {\n    dict_can_resize = enable;\n}\n\nuint64_t dictGetHash(dict *d, const void *key) {\n    return dictHashKey(d, key);\n}\n\n/* Finds the dictEntry using pointer and pre-calculated hash.\n * oldkey is a dead pointer and should not be accessed.\n * the hash value should be provided using dictGetHash.\n * no string / key comparison is performed.\n * return value is a pointer to the dictEntry if found, or NULL if not found. */\ndictEntry *dictFindEntryByPtrAndHash(dict *d, const void *oldptr, uint64_t hash) {\n    dictEntry *he;\n    unsigned long idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n    for (table = 0; table <= 1; table++) {\n        idx = hash & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        he = d->ht_table[table][idx];\n        while(he) {\n            if (oldptr == dictGetKey(he))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\n/* Provides the old and new ht size for a given dictionary during rehashing. This method\n * should only be invoked during initialization/rehashing. */\nvoid dictRehashingInfo(dict *d, unsigned long long *from_size, unsigned long long *to_size) {\n    /* Invalid method usage if rehashing isn't ongoing. */\n    assert(dictIsRehashing(d));\n    *from_size = DICTHT_SIZE(d->ht_size_exp[0]);\n    *to_size = DICTHT_SIZE(d->ht_size_exp[1]);\n}\n\n/* ------------------------------- Debugging ---------------------------------*/\n#define DICT_STATS_VECTLEN 50\nvoid dictFreeStats(dictStats *stats) {\n    zfree(stats->clvector);\n    zfree(stats);\n}\n\nvoid dictCombineStats(dictStats *from, dictStats *into) {\n    into->buckets += from->buckets;\n    into->maxChainLen = (from->maxChainLen > into->maxChainLen) ? from->maxChainLen : into->maxChainLen;\n    into->totalChainLen += from->totalChainLen;\n    into->htSize += from->htSize;\n    into->htUsed += from->htUsed;\n    for (int i = 0; i < DICT_STATS_VECTLEN; i++) {\n        into->clvector[i] += from->clvector[i];\n    }\n}\n\ndictStats *dictGetStatsHt(dict *d, int htidx, int full) {\n    unsigned long *clvector = zcalloc(sizeof(unsigned long) * DICT_STATS_VECTLEN);\n    dictStats *stats = zcalloc(sizeof(dictStats));\n    stats->htidx = htidx;\n    stats->clvector = clvector;\n    stats->htSize = DICTHT_SIZE(d->ht_size_exp[htidx]);\n    stats->htUsed = d->ht_used[htidx];\n    if (!full) return stats;\n    /* Compute stats. */\n    for (unsigned long i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]); i++) {\n        dictEntry *he;\n\n        if (d->ht_table[htidx][i] == NULL) {\n            clvector[0]++;\n            continue;\n        }\n        stats->buckets++;\n        /* For each hash entry on this slot... */\n        unsigned long chainlen = 0;\n        he = d->ht_table[htidx][i];\n        while(he) {\n            chainlen++;\n            he = dictGetNext(he);\n        }\n        clvector[(chainlen < DICT_STATS_VECTLEN) ? chainlen : (DICT_STATS_VECTLEN-1)]++;\n        if (chainlen > stats->maxChainLen) stats->maxChainLen = chainlen;\n        stats->totalChainLen += chainlen;\n    }\n\n    return stats;\n}\n\n/* Generates human readable stats. */\nsize_t dictGetStatsMsg(char *buf, size_t bufsize, dictStats *stats, int full) {\n    if (stats->htUsed == 0) {\n        return snprintf(buf,bufsize,\n            \"Hash table %d stats (%s):\\n\"\n            \"No stats available for empty dictionaries\\n\",\n            stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\");\n    }\n    size_t l = 0;\n    l += snprintf(buf + l, bufsize - l,\n                  \"Hash table %d stats (%s):\\n\"\n                  \" table size: %lu\\n\"\n                  \" number of elements: %lu\\n\",\n                  stats->htidx, (stats->htidx == 0) ? \"main hash table\" : \"rehashing target\",\n                  stats->htSize, stats->htUsed);\n    if (full) {\n        l += snprintf(buf + l, bufsize - l,\n                      \" different slots: %lu\\n\"\n                      \" max chain length: %lu\\n\"\n                      \" avg chain length (counted): %.02f\\n\"\n                      \" avg chain length (computed): %.02f\\n\"\n                      \" Chain length distribution:\\n\",\n                      stats->buckets, stats->maxChainLen,\n                      (float) stats->totalChainLen / stats->buckets, (float) stats->htUsed / stats->buckets);\n\n        for (unsigned long i = 0; i < DICT_STATS_VECTLEN - 1; i++) {\n            if (stats->clvector[i] == 0) continue;\n            if (l >= bufsize) break;\n            l += snprintf(buf + l, bufsize - l,\n                          \"   %ld: %ld (%.02f%%)\\n\",\n                          i, stats->clvector[i], ((float) stats->clvector[i] / stats->htSize) * 100);\n        }\n    }\n\n    /* Make sure there is a NULL term at the end. */\n    buf[bufsize-1] = '\\0';\n    /* Unlike snprintf(), return the number of characters actually written. */\n    return strlen(buf);\n}\n\nvoid dictGetStats(char *buf, size_t bufsize, dict *d, int full) {\n    size_t l;\n    char *orig_buf = buf;\n    size_t orig_bufsize = bufsize;\n\n    dictStats *mainHtStats = dictGetStatsHt(d, 0, full);\n    l = dictGetStatsMsg(buf, bufsize, mainHtStats, full);\n    dictFreeStats(mainHtStats);\n    buf += l;\n    bufsize -= l;\n    if (dictIsRehashing(d) && bufsize > 0) {\n        dictStats *rehashHtStats = dictGetStatsHt(d, 1, full);\n        dictGetStatsMsg(buf, bufsize, rehashHtStats, full);\n        dictFreeStats(rehashHtStats);\n    }\n    /* Make sure there is a NULL term at the end. */\n    orig_buf[orig_bufsize-1] = '\\0';\n}\n\n/* ------------------------------- Benchmark ---------------------------------*/\n\n#ifdef REDIS_TEST\n#include \"testhelp.h\"\n\n#define UNUSED(V) ((void) V)\n#define TEST(name) printf(\"test \u2014 %s\\n\", name);\n\nuint64_t hashCallback(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\nint compareCallback(dict *d, const void *key1, const void *key2) {\n    int l1,l2;\n    UNUSED(d);\n\n    l1 = strlen((char*)key1);\n    l2 = strlen((char*)key2);\n    if (l1 != l2) return 0;\n    return memcmp(key1, key2, l1) == 0;\n}\n\nvoid freeCallback(dict *d, void *val) {\n    UNUSED(d);\n\n    zfree(val);\n}\n\nchar *stringFromLongLong(long long value) {\n    char buf[32];\n    int len;\n    char *s;\n\n    len = snprintf(buf,sizeof(buf),\"%lld\",value);\n    s = zmalloc(len+1);\n    memcpy(s, buf, len);\n    s[len] = '\\0';\n    return s;\n}\n\ndictType BenchmarkDictType = {\n    hashCallback,\n    NULL,\n    NULL,\n    compareCallback,\n    freeCallback,\n    NULL,\n    NULL\n};\n\n#define start_benchmark() start = timeInMilliseconds()\n#define end_benchmark(msg) do { \\\n    elapsed = timeInMilliseconds()-start; \\\n    printf(msg \": %ld items in %lld ms\\n\", count, elapsed); \\\n} while(0)\n\n/* ./redis-server test dict [<count> | --accurate] */\nint dictTest(int argc, char **argv, int flags) {\n    long j;\n    long long start, elapsed;\n    int retval;\n    dict *dict = dictCreate(&BenchmarkDictType);\n    long count = 0;\n    unsigned long new_dict_size, current_dict_used, remain_keys;\n    int accurate = (flags & REDIS_TEST_ACCURATE);\n\n    if (argc == 4) {\n        if (accurate) {\n            count = 5000000;\n        } else {\n            count = strtol(argv[3],NULL,10);\n        }\n    } else {\n        count = 5000;\n    }\n\n    TEST(\"Add 16 keys and verify dict resize is ok\") {\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        for (j = 0; j < 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 16);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and pad to (dict_force_resize_ratio * 16)\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict resize, and pad\n         * the number of keys to (dict_force_resize_ratio * 16), so we can satisfy\n         * dict_force_resize_ratio in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        for (j = 16; j < (long)dict_force_resize_ratio * 16; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = dict_force_resize_ratio * 16;\n        assert(dictSize(dict) == current_dict_used);\n        assert(dictBuckets(dict) == 16);\n    }\n\n    TEST(\"Add one more key, trigger the dict resize\") {\n        retval = dictAdd(dict,stringFromLongLong(current_dict_used),(void*)(current_dict_used));\n        assert(retval == DICT_OK);\n        current_dict_used++;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 16);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete keys until we can trigger shrink in next test\") {\n        /* Delete keys until we can satisfy (1 / HASHTABLE_MIN_FILL) in the next test. */\n        for (j = new_dict_size / HASHTABLE_MIN_FILL + 1; j < (long)current_dict_used; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = new_dict_size / HASHTABLE_MIN_FILL + 1;\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        unsigned long oldDictSize = new_dict_size;\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == oldDictSize);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Empty the dictionary and add 128 keys\") {\n        dictEmpty(dict, NULL);\n        for (j = 0; j < 128; j++) {\n            retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n            assert(retval == DICT_OK);\n        }\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == 128);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Use DICT_RESIZE_AVOID to disable the dict resize and reduce to 3\") {\n        /* Use DICT_RESIZE_AVOID to disable the dict reset, and reduce\n         * the number of keys until we can trigger shrinking in next test. */\n        dictSetResizeEnabled(DICT_RESIZE_AVOID);\n        remain_keys = DICTHT_SIZE(dict->ht_size_exp[0]) / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) + 1;\n        for (j = remain_keys; j < 128; j++) {\n            char *key = stringFromLongLong(j);\n            retval = dictDelete(dict, key);\n            zfree(key);\n            assert(retval == DICT_OK);\n        }\n        current_dict_used = remain_keys;\n        assert(dictSize(dict) == remain_keys);\n        assert(dictBuckets(dict) == 128);\n    }\n\n    TEST(\"Delete one more key, trigger the dict resize\") {\n        current_dict_used--;\n        char *key = stringFromLongLong(current_dict_used);\n        retval = dictDelete(dict, key);\n        zfree(key);\n        new_dict_size = 1UL << _dictNextExp(current_dict_used);\n        assert(retval == DICT_OK);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == 128);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == new_dict_size);\n\n        /* Wait for rehashing. */\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n        while (dictIsRehashing(dict)) dictRehashMicroseconds(dict,1000);\n        assert(dictSize(dict) == current_dict_used);\n        assert(DICTHT_SIZE(dict->ht_size_exp[0]) == new_dict_size);\n        assert(DICTHT_SIZE(dict->ht_size_exp[1]) == 0);\n    }\n\n    TEST(\"Restore to original state\") {\n        dictEmpty(dict, NULL);\n        dictSetResizeEnabled(DICT_RESIZE_ENABLE);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        retval = dictAdd(dict,stringFromLongLong(j),(void*)j);\n        assert(retval == DICT_OK);\n    }\n    end_benchmark(\"Inserting\");\n    assert((long)dictSize(dict) == count);\n\n    /* Wait for rehashing. */\n    while (dictIsRehashing(dict)) {\n        dictRehashMicroseconds(dict,100*1000);\n    }\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Linear access of existing elements\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Linear access of existing elements (2nd round)\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(rand() % count);\n        dictEntry *de = dictFind(dict,key);\n        assert(de != NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Random access of existing elements\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        dictEntry *de = dictGetRandomKey(dict);\n        assert(de != NULL);\n    }\n    end_benchmark(\"Accessing random keys\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(rand() % count);\n        key[0] = 'X';\n        dictEntry *de = dictFind(dict,key);\n        assert(de == NULL);\n        zfree(key);\n    }\n    end_benchmark(\"Accessing missing\");\n\n    start_benchmark();\n    for (j = 0; j < count; j++) {\n        char *key = stringFromLongLong(j);\n        retval = dictDelete(dict,key);\n        assert(retval == DICT_OK);\n        key[0] += 17; /* Change first number to letter. */\n        retval = dictAdd(dict,key,(void*)j);\n        assert(retval == DICT_OK);\n    }\n    end_benchmark(\"Removing and adding\");\n    dictRelease(dict);\n    return 0;\n}\n#endif\n"}], "code": "void scanDatabaseForReadyKeys(redisDb *db) {\n    dictEntry *de;\n    dictIterator *di = dictGetSafeIterator(db->blocking_keys);\n    while((de = dictNext(di)) != NULL) {\n        robj *key = dictGetKey(de);\n        dictEntry *kde = dbFind(db, key->ptr);\n        if (kde) {\n            robj *value = dictGetVal(kde);\n            signalKeyAsReady(db, key, value->type);\n        }\n    }\n    dictReleaseIterator(di);\n}\n"}, "D7B3A40224F9F596": {"calls": [{"id": "AD1EF9D76B227D07", "name": "isModuleClientUnblocked", "path": "redis/src/module.c", "start": {"line": 7702, "col": 1}, "end": {"line": 7706, "col": 1}, "code": "    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n\n    return bc->unblocked == 1;\n}\n\n/* This is called from blocked.c in order to unblock a client: may be called\n * for multiple reasons while the client is in the middle of being blocked\n * because the client is terminated, but is also called for cleanup when a\n * client is unblocked in a clean way after replaying.\n *\n * What we do here is just to set the client to NULL in the redis module\n * blocked client handle. This way if the client is terminated while there\n * is a pending threaded operation involving the blocked client, we'll know\n * that the client no longer exists and no reply callback should be called.\n *\n * The structure RedisModuleBlockedClient will be always deallocated when\n * running the list of clients blocked by a module that need to be unblocked. */\nvoid unblockClientFromModule(client *c) {\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n\n    /* Call the disconnection callback if any. Note that\n     * bc->disconnect_callback is set to NULL if the client gets disconnected\n     * by the module itself or because of a timeout, so the callback will NOT\n     * get called if this is not an actual disconnection event. */\n    if (bc->disconnect_callback) {\n        RedisModuleCtx ctx;\n        moduleCreateContext(&ctx, bc->module, REDISMODULE_CTX_NONE);\n        ctx.blocked_privdata = bc->privdata;\n        ctx.client = bc->client;\n        bc->disconnect_callback(&ctx,bc);\n        moduleFreeContext(&ctx);\n    }\n\n    /* If we made it here and client is still blocked it means that the command\n     * timed-out, client was killed or disconnected and disconnect_callback was\n     * not implemented (or it was, but RM_UnblockClient was not called from\n     * within it, as it should).\n     * We must call moduleUnblockClient in order to free privdata and\n     * RedisModuleBlockedClient.\n     *\n     * Note that we only do that for clients that are blocked on keys, for which\n     * the contract is that the module should not call RM_UnblockClient under\n     * normal circumstances.\n     * Clients implementing threads and working with private data should be\n     * aware that calling RM_UnblockClient for every blocked client is their\n     * responsibility, and if they fail to do so memory may leak. Ideally they\n     * should implement the disconnect and timeout callbacks and call\n     * RM_UnblockClient, but any other way is also acceptable. */\n    if (bc->blocked_on_keys && !bc->unblocked)\n        moduleUnblockClient(c);\n\n    bc->client = NULL;\n}\n\n/* Block a client in the context of a module: this function implements both\n * RM_BlockClient() and RM_BlockClientOnKeys() depending on the fact the\n * keys are passed or not.\n *\n * When not blocking for keys, the keys, numkeys, and privdata parameters are\n * not needed. The privdata in that case must be NULL, since later is\n * RM_UnblockClient() that will provide some private data that the reply\n * callback will receive.\n *\n * Instead when blocking for keys, normally RM_UnblockClient() will not be\n * called (because the client will unblock when the key is modified), so\n * 'privdata' should be provided in that case, so that once the client is\n * unlocked and the reply callback is called, it will receive its associated\n * private data.\n *\n * Even when blocking on keys, RM_UnblockClient() can be called however, but\n * in that case the privdata argument is disregarded, because we pass the\n * reply callback the privdata that is set here while blocking.\n *\n */\nRedisModuleBlockedClient *moduleBlockClient(RedisModuleCtx *ctx, RedisModuleCmdFunc reply_callback,\n                                            RedisModuleAuthCallback auth_reply_callback,\n                                            RedisModuleCmdFunc timeout_callback, void (*free_privdata)(RedisModuleCtx*,void*),\n                                            long long timeout_ms, RedisModuleString **keys, int numkeys, void *privdata,\n                                            int flags) {\n    client *c = ctx->client;\n    int islua = scriptIsRunning();\n    int ismulti = server.in_exec;\n\n    c->bstate.module_blocked_handle = zmalloc(sizeof(RedisModuleBlockedClient));\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n    ctx->module->blocked_clients++;\n\n    /* We need to handle the invalid operation of calling modules blocking\n     * commands from Lua or MULTI. We actually create an already aborted\n     * (client set to NULL) blocked client handle, and actually reply with\n     * an error. */\n    bc->client = (islua || ismulti) ? NULL : c;\n    bc->module = ctx->module;\n    bc->reply_callback = reply_callback;\n    bc->auth_reply_cb = auth_reply_callback;\n    bc->timeout_callback = timeout_callback;\n    bc->disconnect_callback = NULL; /* Set by RM_SetDisconnectCallback() */\n    bc->free_privdata = free_privdata;\n    bc->privdata = privdata;\n    bc->reply_client = moduleAllocTempClient();\n    bc->thread_safe_ctx_client = moduleAllocTempClient();\n    if (bc->client)\n        bc->reply_client->resp = bc->client->resp;\n    bc->dbid = c->db->id;\n    bc->blocked_on_keys = keys != NULL;\n    bc->unblocked = 0;\n    bc->background_timer = 0;\n    bc->background_duration = 0;\n\n    mstime_t timeout = 0;\n    if (timeout_ms) {\n        mstime_t now = mstime();\n        if (timeout_ms > LLONG_MAX - now) {\n            c->bstate.module_blocked_handle = NULL;\n            addReplyError(c, \"timeout is out of range\"); /* 'timeout_ms+now' would overflow */\n            return bc;\n        }\n        timeout = timeout_ms + now;\n    }\n\n    if (islua || ismulti) {\n        c->bstate.module_blocked_handle = NULL;\n        addReplyError(c, islua ?\n            \"Blocking module command called from Lua script\" :\n            \"Blocking module command called from transaction\");\n    } else if (ctx->flags & REDISMODULE_CTX_BLOCKED_REPLY) {\n        c->bstate.module_blocked_handle = NULL;\n        addReplyError(c, \"Blocking module command called from a Reply callback context\");\n    } else if (!auth_reply_callback && clientHasModuleAuthInProgress(c)) {\n        c->bstate.module_blocked_handle = NULL;\n        addReplyError(c, \"Clients undergoing module based authentication can only be blocked on auth\");\n    } else {\n        if (keys) {\n            blockForKeys(c,BLOCKED_MODULE,keys,numkeys,timeout,flags&REDISMODULE_BLOCK_UNBLOCK_DELETED);\n        } else {\n            c->bstate.timeout = timeout;\n            blockClient(c,BLOCKED_MODULE);\n        }\n    }\n    return bc;\n}\n\n/* This API registers a callback to execute in addition to normal password based authentication.\n * Multiple callbacks can be registered across different modules. When a Module is unloaded, all the\n * auth callbacks registered by it are unregistered.\n * The callbacks are attempted (in the order of most recently registered first) when the AUTH/HELLO\n * (with AUTH field provided) commands are called.\n * The callbacks will be called with a module context along with a username and a password, and are\n * expected to take one of the following actions:\n * (1) Authenticate - Use the RM_AuthenticateClient* API and return REDISMODULE_AUTH_HANDLED.\n * This will immediately end the auth chain as successful and add the OK reply.\n * (2) Deny Authentication - Return REDISMODULE_AUTH_HANDLED without authenticating or blocking the\n * client. Optionally, `err` can be set to a custom error message and `err` will be automatically\n * freed by the server.\n * This will immediately end the auth chain as unsuccessful and add the ERR reply.\n * (3) Block a client on authentication - Use the RM_BlockClientOnAuth API and return\n * REDISMODULE_AUTH_HANDLED. Here, the client will be blocked until the RM_UnblockClient API is used\n * which will trigger the auth reply callback (provided through the RM_BlockClientOnAuth).\n * In this reply callback, the Module should authenticate, deny or skip handling authentication.\n * (4) Skip handling Authentication - Return REDISMODULE_AUTH_NOT_HANDLED without blocking the\n * client. This will allow the engine to attempt the next module auth callback.\n * If none of the callbacks authenticate or deny auth, then password based auth is attempted and\n * will authenticate or add failure logs and reply to the clients accordingly.\n *\n * Note: If a client is disconnected while it was in the middle of blocking module auth, that\n * occurrence of the AUTH or HELLO command will not be tracked in the INFO command stats.\n *\n * The following is an example of how non-blocking module based authentication can be used:\n *\n *      int auth_cb(RedisModuleCtx *ctx, RedisModuleString *username, RedisModuleString *password, RedisModuleString **err) {\n *          const char *user = RedisModule_StringPtrLen(username, NULL);\n *          const char *pwd = RedisModule_StringPtrLen(password, NULL);\n *          if (!strcmp(user,\"foo\") && !strcmp(pwd,\"valid_password\")) {\n *              RedisModule_AuthenticateClientWithACLUser(ctx, \"foo\", 3, NULL, NULL, NULL);\n *              return REDISMODULE_AUTH_HANDLED;\n *          }\n *\n *          else if (!strcmp(user,\"foo\") && !strcmp(pwd,\"wrong_password\")) {\n *              RedisModuleString *log = RedisModule_CreateString(ctx, \"Module Auth\", 11);\n *              RedisModule_ACLAddLogEntryByUserName(ctx, username, log, REDISMODULE_ACL_LOG_AUTH);\n *              RedisModule_FreeString(ctx, log);\n *              const char *err_msg = \"Auth denied by Misc Module.\";\n *              *err = RedisModule_CreateString(ctx, err_msg, strlen(err_msg));\n *              return REDISMODULE_AUTH_HANDLED;\n *          }\n *          return REDISMODULE_AUTH_NOT_HANDLED;\n *       }\n *\n *      int RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n *          if (RedisModule_Init(ctx,\"authmodule\",1,REDISMODULE_APIVER_1)== REDISMODULE_ERR)\n *              return REDISMODULE_ERR;\n *          RedisModule_RegisterAuthCallback(ctx, auth_cb);\n *          return REDISMODULE_OK;\n *      }\n */\nvoid RM_RegisterAuthCallback(RedisModuleCtx *ctx, RedisModuleAuthCallback cb) {\n    RedisModuleAuthCtx *auth_ctx = zmalloc(sizeof(RedisModuleAuthCtx));\n    auth_ctx->module = ctx->module;\n    auth_ctx->auth_cb = cb;\n    listAddNodeHead(moduleAuthCallbacks, auth_ctx);\n}\n\n/* Helper function to invoke the free private data callback of a Module blocked client. */\nvoid moduleInvokeFreePrivDataCallback(client *c, RedisModuleBlockedClient *bc) {\n    if (bc->privdata && bc->free_privdata) {\n        RedisModuleCtx ctx;\n        int ctx_flags = c == NULL ? REDISMODULE_CTX_BLOCKED_DISCONNECTED : REDISMODULE_CTX_NONE;\n        moduleCreateContext(&ctx, bc->module, ctx_flags);\n        ctx.blocked_privdata = bc->privdata;\n        ctx.client = bc->client;\n        bc->free_privdata(&ctx,bc->privdata);\n        moduleFreeContext(&ctx);\n    }\n}\n\n/* Unregisters all the module auth callbacks that have been registered by this Module. */\nvoid moduleUnregisterAuthCBs(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    listRewind(moduleAuthCallbacks, &li);\n    while ((ln = listNext(&li))) {\n        RedisModuleAuthCtx *ctx = listNodeValue(ln);\n        if (ctx->module == module) {\n            listDelNode(moduleAuthCallbacks, ln);\n            zfree(ctx);\n        }\n    }\n}\n\n/* Search for & attempt next module auth callback after skipping the ones already attempted.\n * Returns the result of the module auth callback. */\nint attemptNextAuthCb(client *c, robj *username, robj *password, robj **err) {\n    int handle_next_callback = c->module_auth_ctx == NULL;\n    RedisModuleAuthCtx *cur_auth_ctx = NULL;\n    listNode *ln;\n    listIter li;\n    listRewind(moduleAuthCallbacks, &li);\n    int result = REDISMODULE_AUTH_NOT_HANDLED;\n    while((ln = listNext(&li))) {\n        cur_auth_ctx = listNodeValue(ln);\n        /* Skip over the previously attempted auth contexts. */\n        if (!handle_next_callback) {\n            handle_next_callback = cur_auth_ctx == c->module_auth_ctx;\n            continue;\n        }\n        /* Remove the module auth complete flag before we attempt the next cb. */\n        c->flags &= ~CLIENT_MODULE_AUTH_HAS_RESULT;\n        RedisModuleCtx ctx;\n        moduleCreateContext(&ctx, cur_auth_ctx->module, REDISMODULE_CTX_NONE);\n        ctx.client = c;\n        *err = NULL;\n        c->module_auth_ctx = cur_auth_ctx;\n        result = cur_auth_ctx->auth_cb(&ctx, username, password, err);\n        moduleFreeContext(&ctx);\n        if (result == REDISMODULE_AUTH_HANDLED) break;\n        /* If Auth was not handled (allowed/denied/blocked) by the Module, try the next auth cb. */\n    }\n    return result;\n}\n\n/* Helper function to handle a reprocessed unblocked auth client.\n * Returns REDISMODULE_AUTH_NOT_HANDLED if the client was not reprocessed after a blocking module\n * auth operation.\n * Otherwise, we attempt the auth reply callback & the free priv data callback, update fields and\n * return the result of the reply callback. */\nint attemptBlockedAuthReplyCallback(client *c, robj *username, robj *password, robj **err) {\n    int result = REDISMODULE_AUTH_NOT_HANDLED;\n    if (!c->module_blocked_client) return result;\n    RedisModuleBlockedClient *bc = (RedisModuleBlockedClient *) c->module_blocked_client;\n    bc->client = c;\n    if (bc->auth_reply_cb) {\n        RedisModuleCtx ctx;\n        moduleCreateContext(&ctx, bc->module, REDISMODULE_CTX_BLOCKED_REPLY);\n        ctx.blocked_privdata = bc->privdata;\n        ctx.blocked_ready_key = NULL;\n        ctx.client = bc->client;\n        ctx.blocked_client = bc;\n        result = bc->auth_reply_cb(&ctx, username, password, err);\n        moduleFreeContext(&ctx);\n    }\n    moduleInvokeFreePrivDataCallback(c, bc);\n    c->module_blocked_client = NULL;\n    c->lastcmd->microseconds += bc->background_duration;\n    bc->module->blocked_clients--;\n    zfree(bc);\n    return result;\n}\n\n/* Helper function to attempt Module based authentication through module auth callbacks.\n * Here, the Module is expected to authenticate the client using the RedisModule APIs and to add ACL\n * logs in case of errors.\n * Returns one of the following codes:\n * AUTH_OK - Indicates that a module handled and authenticated the client.\n * AUTH_ERR - Indicates that a module handled and denied authentication for this client.\n * AUTH_NOT_HANDLED - Indicates that authentication was not handled by any Module and that\n * normal password based authentication can be attempted next.\n * AUTH_BLOCKED - Indicates module authentication is in progress through a blocking implementation.\n * In this case, authentication is handled here again after the client is unblocked / reprocessed. */\nint checkModuleAuthentication(client *c, robj *username, robj *password, robj **err) {\n    if (!listLength(moduleAuthCallbacks)) return AUTH_NOT_HANDLED;\n    int result = attemptBlockedAuthReplyCallback(c, username, password, err);\n    if (result == REDISMODULE_AUTH_NOT_HANDLED) {\n        result = attemptNextAuthCb(c, username, password, err);\n    }\n    if (c->flags & CLIENT_BLOCKED) {\n        /* Modules are expected to return REDISMODULE_AUTH_HANDLED when blocking clients. */\n        serverAssert(result == REDISMODULE_AUTH_HANDLED);\n        return AUTH_BLOCKED;\n    }\n    c->module_auth_ctx = NULL;\n    if (result == REDISMODULE_AUTH_NOT_HANDLED) {\n        c->flags &= ~CLIENT_MODULE_AUTH_HAS_RESULT;\n        return AUTH_NOT_HANDLED;\n    }\n    if (c->flags & CLIENT_MODULE_AUTH_HAS_RESULT) {\n        c->flags &= ~CLIENT_MODULE_AUTH_HAS_RESULT;\n        if (c->authenticated) return AUTH_OK;\n    }\n    return AUTH_ERR;\n}\n\n/* This function is called from module.c in order to check if a module\n * blocked for BLOCKED_MODULE and subtype 'on keys' (bc->blocked_on_keys true)\n * can really be unblocked, since the module was able to serve the client.\n * If the callback returns REDISMODULE_OK, then the client can be unblocked,\n * otherwise the client remains blocked and we'll retry again when one of\n * the keys it blocked for becomes \"ready\" again.\n * This function returns 1 if client was served (and should be unblocked) */\nint moduleTryServeClientBlockedOnKey(client *c, robj *key) {\n    int served = 0;\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n\n    /* Protect against re-processing: don't serve clients that are already\n     * in the unblocking list for any reason (including RM_UnblockClient()\n     * explicit call). See #6798. */\n    if (bc->unblocked) return 0;\n\n    RedisModuleCtx ctx;\n    moduleCreateContext(&ctx, bc->module, REDISMODULE_CTX_BLOCKED_REPLY);\n    ctx.blocked_ready_key = key;\n    ctx.blocked_privdata = bc->privdata;\n    ctx.client = bc->client;\n    ctx.blocked_client = bc;\n    if (bc->reply_callback(&ctx,(void**)c->argv,c->argc) == REDISMODULE_OK)\n        served = 1;\n    moduleFreeContext(&ctx);\n    return served;\n}\n\n/* Block a client in the context of a blocking command, returning a handle\n * which will be used, later, in order to unblock the client with a call to\n * RedisModule_UnblockClient(). The arguments specify callback functions\n * and a timeout after which the client is unblocked.\n *\n * The callbacks are called in the following contexts:\n *\n *     reply_callback:   called after a successful RedisModule_UnblockClient()\n *                       call in order to reply to the client and unblock it.\n *\n *     timeout_callback: called when the timeout is reached or if `CLIENT UNBLOCK`\n *                       is invoked, in order to send an error to the client.\n *\n *     free_privdata:    called in order to free the private data that is passed\n *                       by RedisModule_UnblockClient() call.\n *\n * Note: RedisModule_UnblockClient should be called for every blocked client,\n *       even if client was killed, timed-out or disconnected. Failing to do so\n *       will result in memory leaks.\n *\n * There are some cases where RedisModule_BlockClient() cannot be used:\n *\n * 1. If the client is a Lua script.\n * 2. If the client is executing a MULTI block.\n *\n * In these cases, a call to RedisModule_BlockClient() will **not** block the\n * client, but instead produce a specific error reply.\n *\n * A module that registers a timeout_callback function can also be unblocked\n * using the `CLIENT UNBLOCK` command, which will trigger the timeout callback.\n * If a callback function is not registered, then the blocked client will be\n * treated as if it is not in a blocked state and `CLIENT UNBLOCK` will return\n * a zero value.\n *\n * Measuring background time: By default the time spent in the blocked command\n * is not account for the total command duration. To include such time you should\n * use RM_BlockedClientMeasureTimeStart() and RM_BlockedClientMeasureTimeEnd() one,\n * or multiple times within the blocking command background work.\n */\nRedisModuleBlockedClient *RM_BlockClient(RedisModuleCtx *ctx, RedisModuleCmdFunc reply_callback,\n                                         RedisModuleCmdFunc timeout_callback, void (*free_privdata)(RedisModuleCtx*,void*),\n                                         long long timeout_ms) {\n    return moduleBlockClient(ctx,reply_callback,NULL,timeout_callback,free_privdata,timeout_ms, NULL,0,NULL,0);\n}\n\n/* Block the current client for module authentication in the background. If module auth is not in\n * progress on the client, the API returns NULL. Otherwise, the client is blocked and the RM_BlockedClient\n * is returned similar to the RM_BlockClient API.\n * Note: Only use this API from the context of a module auth callback. */\nRedisModuleBlockedClient *RM_BlockClientOnAuth(RedisModuleCtx *ctx, RedisModuleAuthCallback reply_callback,\n                                               void (*free_privdata)(RedisModuleCtx*,void*)) {\n    if (!clientHasModuleAuthInProgress(ctx->client)) {\n        addReplyError(ctx->client, \"Module blocking client on auth when not currently undergoing module authentication\");\n        return NULL;\n    }\n    RedisModuleBlockedClient *bc = moduleBlockClient(ctx,NULL,reply_callback,NULL,free_privdata,0, NULL,0,NULL,0);\n    if (ctx->client->flags & CLIENT_BLOCKED) {\n        ctx->client->flags |= CLIENT_PENDING_COMMAND;\n    }\n    return bc;\n}\n\n/* Get the private data that was previusely set on a blocked client */\nvoid *RM_BlockClientGetPrivateData(RedisModuleBlockedClient *blocked_client) {\n    return blocked_client->privdata;\n}\n\n/* Set private data on a blocked client */\nvoid RM_BlockClientSetPrivateData(RedisModuleBlockedClient *blocked_client, void *private_data) {\n    blocked_client->privdata = private_data;\n}\n\n/* This call is similar to RedisModule_BlockClient(), however in this case we\n * don't just block the client, but also ask Redis to unblock it automatically\n * once certain keys become \"ready\", that is, contain more data.\n *\n * Basically this is similar to what a typical Redis command usually does,\n * like BLPOP or BZPOPMAX: the client blocks if it cannot be served ASAP,\n * and later when the key receives new data (a list push for instance), the\n * client is unblocked and served.\n *\n * However in the case of this module API, when the client is unblocked?\n *\n * 1. If you block on a key of a type that has blocking operations associated,\n *    like a list, a sorted set, a stream, and so forth, the client may be\n *    unblocked once the relevant key is targeted by an operation that normally\n *    unblocks the native blocking operations for that type. So if we block\n *    on a list key, an RPUSH command may unblock our client and so forth.\n * 2. If you are implementing your native data type, or if you want to add new\n *    unblocking conditions in addition to \"1\", you can call the modules API\n *    RedisModule_SignalKeyAsReady().\n *\n * Anyway we can't be sure if the client should be unblocked just because the\n * key is signaled as ready: for instance a successive operation may change the\n * key, or a client in queue before this one can be served, modifying the key\n * as well and making it empty again. So when a client is blocked with\n * RedisModule_BlockClientOnKeys() the reply callback is not called after\n * RM_UnblockClient() is called, but every time a key is signaled as ready:\n * if the reply callback can serve the client, it returns REDISMODULE_OK\n * and the client is unblocked, otherwise it will return REDISMODULE_ERR\n * and we'll try again later.\n *\n * The reply callback can access the key that was signaled as ready by\n * calling the API RedisModule_GetBlockedClientReadyKey(), that returns\n * just the string name of the key as a RedisModuleString object.\n *\n * Thanks to this system we can setup complex blocking scenarios, like\n * unblocking a client only if a list contains at least 5 items or other\n * more fancy logics.\n *\n * Note that another difference with RedisModule_BlockClient(), is that here\n * we pass the private data directly when blocking the client: it will\n * be accessible later in the reply callback. Normally when blocking with\n * RedisModule_BlockClient() the private data to reply to the client is\n * passed when calling RedisModule_UnblockClient() but here the unblocking\n * is performed by Redis itself, so we need to have some private data before\n * hand. The private data is used to store any information about the specific\n * unblocking operation that you are implementing. Such information will be\n * freed using the free_privdata callback provided by the user.\n *\n * However the reply callback will be able to access the argument vector of\n * the command, so the private data is often not needed.\n *\n * Note: Under normal circumstances RedisModule_UnblockClient should not be\n *       called for clients that are blocked on keys (Either the key will\n *       become ready or a timeout will occur). If for some reason you do want\n *       to call RedisModule_UnblockClient it is possible: Client will be\n *       handled as if it were timed-out (You must implement the timeout\n *       callback in that case).\n */\nRedisModuleBlockedClient *RM_BlockClientOnKeys(RedisModuleCtx *ctx, RedisModuleCmdFunc reply_callback,\n                                               RedisModuleCmdFunc timeout_callback, void (*free_privdata)(RedisModuleCtx*,void*),\n                                               long long timeout_ms, RedisModuleString **keys, int numkeys, void *privdata) {\n    return moduleBlockClient(ctx,reply_callback,NULL,timeout_callback,free_privdata,timeout_ms, keys,numkeys,privdata,0);\n}\n\n/* Same as RedisModule_BlockClientOnKeys, but can take REDISMODULE_BLOCK_* flags\n * Can be either REDISMODULE_BLOCK_UNBLOCK_DEFAULT, which means default behavior (same\n * as calling RedisModule_BlockClientOnKeys)\n *\n * The flags is a bit mask of these:\n *\n * - `REDISMODULE_BLOCK_UNBLOCK_DELETED`: The clients should to be awakened in case any of `keys` are deleted.\n *                                        Mostly useful for commands that require the key to exist (like XREADGROUP)\n */\nRedisModuleBlockedClient *RM_BlockClientOnKeysWithFlags(RedisModuleCtx *ctx, RedisModuleCmdFunc reply_callback,\n                                                        RedisModuleCmdFunc timeout_callback, void (*free_privdata)(RedisModuleCtx*,void*),\n                                                        long long timeout_ms, RedisModuleString **keys, int numkeys, void *privdata,\n                                                        int flags) {\n    return moduleBlockClient(ctx,reply_callback,NULL,timeout_callback,free_privdata,timeout_ms, keys,numkeys,privdata,flags);\n}\n\n/* This function is used in order to potentially unblock a client blocked\n * on keys with RedisModule_BlockClientOnKeys(). When this function is called,\n * all the clients blocked for this key will get their reply_callback called. */\nvoid RM_SignalKeyAsReady(RedisModuleCtx *ctx, RedisModuleString *key) {\n    signalKeyAsReady(ctx->client->db, key, OBJ_MODULE);\n}\n\n/* Implements RM_UnblockClient() and moduleUnblockClient(). */\nint moduleUnblockClientByHandle(RedisModuleBlockedClient *bc, void *privdata) {\n    pthread_mutex_lock(&moduleUnblockedClientsMutex);\n    if (!bc->blocked_on_keys) bc->privdata = privdata;\n    bc->unblocked = 1;\n    if (listLength(moduleUnblockedClients) == 0) {\n        if (write(server.module_pipe[1],\"A\",1) != 1) {\n            /* Ignore the error, this is best-effort. */\n        }\n    }\n    listAddNodeTail(moduleUnblockedClients,bc);\n    pthread_mutex_unlock(&moduleUnblockedClientsMutex);\n    return REDISMODULE_OK;\n}\n\n/* This API is used by the Redis core to unblock a client that was blocked\n * by a module. */\nvoid moduleUnblockClient(client *c) {\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n    moduleUnblockClientByHandle(bc,NULL);\n}\n\n/* Return true if the client 'c' was blocked by a module using\n * RM_BlockClientOnKeys(). */\nint moduleClientIsBlockedOnKeys(client *c) {\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n    return bc->blocked_on_keys;\n}\n\n/* Unblock a client blocked by `RedisModule_BlockedClient`. This will trigger\n * the reply callbacks to be called in order to reply to the client.\n * The 'privdata' argument will be accessible by the reply callback, so\n * the caller of this function can pass any value that is needed in order to\n * actually reply to the client.\n *\n * A common usage for 'privdata' is a thread that computes something that\n * needs to be passed to the client, included but not limited some slow\n * to compute reply or some reply obtained via networking.\n *\n * Note 1: this function can be called from threads spawned by the module.\n *\n * Note 2: when we unblock a client that is blocked for keys using the API\n * RedisModule_BlockClientOnKeys(), the privdata argument here is not used.\n * Unblocking a client that was blocked for keys using this API will still\n * require the client to get some reply, so the function will use the\n * \"timeout\" handler in order to do so (The privdata provided in\n * RedisModule_BlockClientOnKeys() is accessible from the timeout\n * callback via RM_GetBlockedClientPrivateData). */\nint RM_UnblockClient(RedisModuleBlockedClient *bc, void *privdata) {\n    if (bc->blocked_on_keys) {\n        /* In theory the user should always pass the timeout handler as an\n         * argument, but better to be safe than sorry. */\n        if (bc->timeout_callback == NULL) return REDISMODULE_ERR;\n        if (bc->unblocked) return REDISMODULE_OK;\n        if (bc->client) moduleBlockedClientTimedOut(bc->client, 1);\n    }\n    moduleUnblockClientByHandle(bc,privdata);\n    return REDISMODULE_OK;\n}\n\n/* Abort a blocked client blocking operation: the client will be unblocked\n * without firing any callback. */\nint RM_AbortBlock(RedisModuleBlockedClient *bc) {\n    bc->reply_callback = NULL;\n    bc->disconnect_callback = NULL;\n    bc->auth_reply_cb = NULL;\n    return RM_UnblockClient(bc,NULL);\n}\n\n/* Set a callback that will be called if a blocked client disconnects\n * before the module has a chance to call RedisModule_UnblockClient()\n *\n * Usually what you want to do there, is to cleanup your module state\n * so that you can call RedisModule_UnblockClient() safely, otherwise\n * the client will remain blocked forever if the timeout is large.\n *\n * Notes:\n *\n * 1. It is not safe to call Reply* family functions here, it is also\n *    useless since the client is gone.\n *\n * 2. This callback is not called if the client disconnects because of\n *    a timeout. In such a case, the client is unblocked automatically\n *    and the timeout callback is called.\n */\nvoid RM_SetDisconnectCallback(RedisModuleBlockedClient *bc, RedisModuleDisconnectFunc callback) {\n    bc->disconnect_callback = callback;\n}\n\n/* This function will check the moduleUnblockedClients queue in order to\n * call the reply callback and really unblock the client.\n *\n * Clients end into this list because of calls to RM_UnblockClient(),\n * however it is possible that while the module was doing work for the\n * blocked client, it was terminated by Redis (for timeout or other reasons).\n * When this happens the RedisModuleBlockedClient structure in the queue\n * will have the 'client' field set to NULL. */\nvoid moduleHandleBlockedClients(void) {\n    listNode *ln;\n    RedisModuleBlockedClient *bc;\n\n    pthread_mutex_lock(&moduleUnblockedClientsMutex);\n    while (listLength(moduleUnblockedClients)) {\n        ln = listFirst(moduleUnblockedClients);\n        bc = ln->value;\n        client *c = bc->client;\n        listDelNode(moduleUnblockedClients,ln);\n        pthread_mutex_unlock(&moduleUnblockedClientsMutex);\n\n        /* Release the lock during the loop, as long as we don't\n         * touch the shared list. */\n\n        /* Call the reply callback if the client is valid and we have\n         * any callback. However the callback is not called if the client\n         * was blocked on keys (RM_BlockClientOnKeys()), because we already\n         * called such callback in moduleTryServeClientBlockedOnKey() when\n         * the key was signaled as ready. */\n        long long prev_error_replies = server.stat_total_error_replies;\n        uint64_t reply_us = 0;\n        if (c && !bc->blocked_on_keys && bc->reply_callback) {\n            RedisModuleCtx ctx;\n            moduleCreateContext(&ctx, bc->module, REDISMODULE_CTX_BLOCKED_REPLY);\n            ctx.blocked_privdata = bc->privdata;\n            ctx.blocked_ready_key = NULL;\n            ctx.client = bc->client;\n            ctx.blocked_client = bc;\n            monotime replyTimer;\n            elapsedStart(&replyTimer);\n            bc->reply_callback(&ctx,(void**)c->argv,c->argc);\n            reply_us = elapsedUs(replyTimer);\n            moduleFreeContext(&ctx);\n        }\n        /* Hold onto the blocked client if module auth is in progress. The reply callback is invoked\n         * when the client is reprocessed. */\n        if (c && clientHasModuleAuthInProgress(c)) {\n            c->module_blocked_client = bc;\n        } else {\n            /* Free privdata if any. */\n            moduleInvokeFreePrivDataCallback(c, bc);\n        }\n\n        /* It is possible that this blocked client object accumulated\n         * replies to send to the client in a thread safe context.\n         * We need to glue such replies to the client output buffer and\n         * free the temporary client we just used for the replies. */\n        if (c) AddReplyFromClient(c, bc->reply_client);\n        moduleReleaseTempClient(bc->reply_client);\n        moduleReleaseTempClient(bc->thread_safe_ctx_client);\n\n        /* Update stats now that we've finished the blocking operation.\n         * This needs to be out of the reply callback above given that a\n         * module might not define any callback and still do blocking ops.\n         */\n        if (c && !clientHasModuleAuthInProgress(c)) {\n            int had_errors = c->deferred_reply_errors ? !!listLength(c->deferred_reply_errors) :\n                (server.stat_total_error_replies != prev_error_replies);\n            updateStatsOnUnblock(c, bc->background_duration, reply_us, had_errors);\n        }\n\n        if (c != NULL) {\n            /* Before unblocking the client, set the disconnect callback\n             * to NULL, because if we reached this point, the client was\n             * properly unblocked by the module. */\n            bc->disconnect_callback = NULL;\n            unblockClient(c, 1);\n\n            /* Update the wait offset, we don't know if this blocked client propagated anything,\n             * currently we rather not add any API for that, so we just assume it did. */\n            c->woff = server.master_repl_offset;\n\n            /* Put the client in the list of clients that need to write\n             * if there are pending replies here. This is needed since\n             * during a non blocking command the client may receive output. */\n            if (!clientHasModuleAuthInProgress(c) && clientHasPendingReplies(c) &&\n                !(c->flags & CLIENT_PENDING_WRITE) && c->conn)\n            {\n                c->flags |= CLIENT_PENDING_WRITE;\n                listLinkNodeHead(server.clients_pending_write, &c->clients_pending_write_node);\n            }\n        }\n\n        /* Free 'bc' only after unblocking the client, since it is\n         * referenced in the client blocking context, and must be valid\n         * when calling unblockClient(). */\n        if (!(c && clientHasModuleAuthInProgress(c))) {\n            bc->module->blocked_clients--;\n            zfree(bc);\n        }\n\n        /* Lock again before to iterate the loop. */\n        pthread_mutex_lock(&moduleUnblockedClientsMutex);\n    }\n    pthread_mutex_unlock(&moduleUnblockedClientsMutex);\n}\n\n/* Check if the specified client can be safely timed out using\n * moduleBlockedClientTimedOut().\n */\nint moduleBlockedClientMayTimeout(client *c) {\n    if (c->bstate.btype != BLOCKED_MODULE)\n        return 1;\n\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n    return (bc && bc->timeout_callback != NULL);\n}\n\n/* Called when our client timed out. After this function unblockClient()\n * is called, and it will invalidate the blocked client. So this function\n * does not need to do any cleanup. Eventually the module will call the\n * API to unblock the client and the memory will be released. \n *\n * If this function is called from a module, we handle the timeout callback\n * and the update of the unblock status in a thread-safe manner to avoid race\n * conditions with the main thread.\n * If this function is called from the main thread, we must handle the unblocking\n * of the client synchronously. This ensures that we can reply to the client before\n * resetClient() is called. */\nvoid moduleBlockedClientTimedOut(client *c, int from_module) {\n    RedisModuleBlockedClient *bc = c->bstate.module_blocked_handle;\n\n    /* Protect against re-processing: don't serve clients that are already\n     * in the unblocking list for any reason (including RM_UnblockClient()\n     * explicit call). See #6798. */\n    if (bc->unblocked) return;\n\n    RedisModuleCtx ctx;\n    int flags = REDISMODULE_CTX_BLOCKED_TIMEOUT;\n    if (from_module) flags |= REDISMODULE_CTX_THREAD_SAFE;\n    moduleCreateContext(&ctx, bc->module, flags);\n    ctx.client = bc->client;\n    ctx.blocked_client = bc;\n    ctx.blocked_privdata = bc->privdata;\n\n    long long prev_error_replies;\n    if (!from_module)\n        prev_error_replies = server.stat_total_error_replies;\n\n    if (bc->timeout_callback) {\n        /* In theory, the user should always pass the timeout handler as an\n         * argument, but better to be safe than sorry. */\n        bc->timeout_callback(&ctx,(void**)c->argv,c->argc);\n    }\n\n    moduleFreeContext(&ctx);\n\n    if (!from_module)\n        updateStatsOnUnblock(c, bc->background_duration, 0, server.stat_total_error_replies != prev_error_replies);\n\n    /* For timeout events, we do not want to call the disconnect callback,\n     * because the blocked client will be automatically disconnected in\n     * this case, and the user can still hook using the timeout callback. */\n    bc->disconnect_callback = NULL;\n}\n\n/* Return non-zero if a module command was called in order to fill the\n * reply for a blocked client. */\nint RM_IsBlockedReplyRequest(RedisModuleCtx *ctx) {\n    return (ctx->flags & REDISMODULE_CTX_BLOCKED_REPLY) != 0;\n}\n\n/* Return non-zero if a module command was called in order to fill the\n * reply for a blocked client that timed out. */\nint RM_IsBlockedTimeoutRequest(RedisModuleCtx *ctx) {\n    return (ctx->flags & REDISMODULE_CTX_BLOCKED_TIMEOUT) != 0;\n}\n\n/* Get the private data set by RedisModule_UnblockClient() */\nvoid *RM_GetBlockedClientPrivateData(RedisModuleCtx *ctx) {\n    return ctx->blocked_privdata;\n}\n\n/* Get the key that is ready when the reply callback is called in the context\n * of a client blocked by RedisModule_BlockClientOnKeys(). */\nRedisModuleString *RM_GetBlockedClientReadyKey(RedisModuleCtx *ctx) {\n    return ctx->blocked_ready_key;\n}\n\n/* Get the blocked client associated with a given context.\n * This is useful in the reply and timeout callbacks of blocked clients,\n * before sometimes the module has the blocked client handle references\n * around, and wants to cleanup it. */\nRedisModuleBlockedClient *RM_GetBlockedClientHandle(RedisModuleCtx *ctx) {\n    return ctx->blocked_client;\n}\n\n/* Return true if when the free callback of a blocked client is called,\n * the reason for the client to be unblocked is that it disconnected\n * while it was blocked. */\nint RM_BlockedClientDisconnected(RedisModuleCtx *ctx) {\n    return (ctx->flags & REDISMODULE_CTX_BLOCKED_DISCONNECTED) != 0;\n}\n\n/* --------------------------------------------------------------------------\n * ## Thread Safe Contexts\n * -------------------------------------------------------------------------- */\n\n/* Return a context which can be used inside threads to make Redis context\n * calls with certain modules APIs. If 'bc' is not NULL then the module will\n * be bound to a blocked client, and it will be possible to use the\n * `RedisModule_Reply*` family of functions to accumulate a reply for when the\n * client will be unblocked. Otherwise the thread safe context will be\n * detached by a specific client.\n *\n * To call non-reply APIs, the thread safe context must be prepared with:\n *\n *     RedisModule_ThreadSafeContextLock(ctx);\n *     ... make your call here ...\n *     RedisModule_ThreadSafeContextUnlock(ctx);\n *\n * This is not needed when using `RedisModule_Reply*` functions, assuming\n * that a blocked client was used when the context was created, otherwise\n * no RedisModule_Reply* call should be made at all.\n *\n * NOTE: If you're creating a detached thread safe context (bc is NULL),\n * consider using `RM_GetDetachedThreadSafeContext` which will also retain\n * the module ID and thus be more useful for logging. */\nRedisModuleCtx *RM_GetThreadSafeContext(RedisModuleBlockedClient *bc) {\n    RedisModuleCtx *ctx = zmalloc(sizeof(*ctx));\n    RedisModule *module = bc ? bc->module : NULL;\n    int flags = REDISMODULE_CTX_THREAD_SAFE;\n\n    /* Creating a new client object is costly. To avoid that, we have an\n     * internal pool of client objects. In blockClient(), a client object is\n     * assigned to bc->thread_safe_ctx_client to be used for the thread safe\n     * context.\n     * For detached thread safe contexts, we create a new client object.\n     * Otherwise, as this function can be called from different threads, we\n     * would need to synchronize access to internal pool of client objects.\n     * Assuming creating detached context is rare and not that performance\n     * critical, we avoid synchronizing access to the client pool by creating\n     * a new client */\n    if (!bc) flags |= REDISMODULE_CTX_NEW_CLIENT;\n    moduleCreateContext(ctx, module, flags);\n    /* Even when the context is associated with a blocked client, we can't\n     * access it safely from another thread, so we use a fake client here\n     * in order to keep things like the currently selected database and similar\n     * things. */\n    if (bc) {\n        ctx->blocked_client = bc;\n        ctx->client = bc->thread_safe_ctx_client;\n        selectDb(ctx->client,bc->dbid);\n        if (bc->client) {\n            ctx->client->id = bc->client->id;\n            ctx->client->resp = bc->client->resp;\n        }\n    }\n    return ctx;\n}\n\n/* Return a detached thread safe context that is not associated with any\n * specific blocked client, but is associated with the module's context.\n *\n * This is useful for modules that wish to hold a global context over\n * a long term, for purposes such as logging. */\nRedisModuleCtx *RM_GetDetachedThreadSafeContext(RedisModuleCtx *ctx) {\n    RedisModuleCtx *new_ctx = zmalloc(sizeof(*new_ctx));\n    /* We create a new client object for the detached context.\n     * See RM_GetThreadSafeContext() for more information */\n    moduleCreateContext(new_ctx, ctx->module,\n                        REDISMODULE_CTX_THREAD_SAFE|REDISMODULE_CTX_NEW_CLIENT);\n    return new_ctx;\n}\n\n/* Release a thread safe context. */\nvoid RM_FreeThreadSafeContext(RedisModuleCtx *ctx) {\n    moduleFreeContext(ctx);\n    zfree(ctx);\n}\n\nvoid moduleGILAfterLock(void) {\n    /* We should never get here if we already inside a module\n     * code block which already opened a context. */\n    serverAssert(server.execution_nesting == 0);\n    /* Bump up the nesting level to prevent immediate propagation\n     * of possible RM_Call from th thread */\n    enterExecutionUnit(1, 0);\n}\n\n/* Acquire the server lock before executing a thread safe API call.\n * This is not needed for `RedisModule_Reply*` calls when there is\n * a blocked client connected to the thread safe context. */\nvoid RM_ThreadSafeContextLock(RedisModuleCtx *ctx) {\n    UNUSED(ctx);\n    moduleAcquireGIL();\n    moduleGILAfterLock();\n}\n\n/* Similar to RM_ThreadSafeContextLock but this function\n * would not block if the server lock is already acquired.\n *\n * If successful (lock acquired) REDISMODULE_OK is returned,\n * otherwise REDISMODULE_ERR is returned and errno is set\n * accordingly. */\nint RM_ThreadSafeContextTryLock(RedisModuleCtx *ctx) {\n    UNUSED(ctx);\n\n    int res = moduleTryAcquireGIL();\n    if(res != 0) {\n        errno = res;\n        return REDISMODULE_ERR;\n    }\n    moduleGILAfterLock();\n    return REDISMODULE_OK;\n}\n\nvoid moduleGILBeforeUnlock(void) {\n    /* We should never get here if we already inside a module\n     * code block which already opened a context, except\n     * the bump-up from moduleGILAcquired. */\n    serverAssert(server.execution_nesting == 1);\n    /* Restore nesting level and propagate pending commands\n     * (because it's unclear when thread safe contexts are\n     * released we have to propagate here). */\n    exitExecutionUnit();\n    postExecutionUnitOperations();\n}\n\n/* Release the server lock after a thread safe API call was executed. */\nvoid RM_ThreadSafeContextUnlock(RedisModuleCtx *ctx) {\n    UNUSED(ctx);\n    moduleGILBeforeUnlock();\n    moduleReleaseGIL();\n}\n\nvoid moduleAcquireGIL(void) {\n    pthread_mutex_lock(&moduleGIL);\n}\n\nint moduleTryAcquireGIL(void) {\n    return pthread_mutex_trylock(&moduleGIL);\n}\n\nvoid moduleReleaseGIL(void) {\n    pthread_mutex_unlock(&moduleGIL);\n}\n\n\n/* --------------------------------------------------------------------------\n * ## Module Keyspace Notifications API\n * -------------------------------------------------------------------------- */\n\n/* Subscribe to keyspace notifications. This is a low-level version of the\n * keyspace-notifications API. A module can register callbacks to be notified\n * when keyspace events occur.\n *\n * Notification events are filtered by their type (string events, set events,\n * etc), and the subscriber callback receives only events that match a specific\n * mask of event types.\n *\n * When subscribing to notifications with RedisModule_SubscribeToKeyspaceEvents\n * the module must provide an event type-mask, denoting the events the subscriber\n * is interested in. This can be an ORed mask of any of the following flags:\n *\n *  - REDISMODULE_NOTIFY_GENERIC: Generic commands like DEL, EXPIRE, RENAME\n *  - REDISMODULE_NOTIFY_STRING: String events\n *  - REDISMODULE_NOTIFY_LIST: List events\n *  - REDISMODULE_NOTIFY_SET: Set events\n *  - REDISMODULE_NOTIFY_HASH: Hash events\n *  - REDISMODULE_NOTIFY_ZSET: Sorted Set events\n *  - REDISMODULE_NOTIFY_EXPIRED: Expiration events\n *  - REDISMODULE_NOTIFY_EVICTED: Eviction events\n *  - REDISMODULE_NOTIFY_STREAM: Stream events\n *  - REDISMODULE_NOTIFY_MODULE: Module types events\n *  - REDISMODULE_NOTIFY_KEYMISS: Key-miss events\n *                                Notice, key-miss event is the only type\n *                                of event that is fired from within a read command.\n *                                Performing RM_Call with a write command from within\n *                                this notification is wrong and discourage. It will\n *                                cause the read command that trigger the event to be\n *                                replicated to the AOF/Replica.\n *  - REDISMODULE_NOTIFY_ALL: All events (Excluding REDISMODULE_NOTIFY_KEYMISS)\n *  - REDISMODULE_NOTIFY_LOADED: A special notification available only for modules,\n *                               indicates that the key was loaded from persistence.\n *                               Notice, when this event fires, the given key\n *                               can not be retained, use RM_CreateStringFromString\n *                               instead.\n *\n * We do not distinguish between key events and keyspace events, and it is up\n * to the module to filter the actions taken based on the key.\n *\n * The subscriber signature is:\n *\n *     int (*RedisModuleNotificationFunc) (RedisModuleCtx *ctx, int type,\n *                                         const char *event,\n *                                         RedisModuleString *key);\n *\n * `type` is the event type bit, that must match the mask given at registration\n * time. The event string is the actual command being executed, and key is the\n * relevant Redis key.\n *\n * Notification callback gets executed with a redis context that can not be\n * used to send anything to the client, and has the db number where the event\n * occurred as its selected db number.\n *\n * Notice that it is not necessary to enable notifications in redis.conf for\n * module notifications to work.\n *\n * Warning: the notification callbacks are performed in a synchronous manner,\n * so notification callbacks must to be fast, or they would slow Redis down.\n * If you need to take long actions, use threads to offload them.\n *\n * Moreover, the fact that the notification is executed synchronously means\n * that the notification code will be executed in the middle on Redis logic\n * (commands logic, eviction, expire). Changing the key space while the logic\n * runs is dangerous and discouraged. In order to react to key space events with\n * write actions, please refer to `RM_AddPostNotificationJob`.\n *\n * See https://redis.io/topics/notifications for more information.\n */\nint RM_SubscribeToKeyspaceEvents(RedisModuleCtx *ctx, int types, RedisModuleNotificationFunc callback) {\n    RedisModuleKeyspaceSubscriber *sub = zmalloc(sizeof(*sub));\n    sub->module = ctx->module;\n    sub->event_mask = types;\n    sub->notify_callback = callback;\n    sub->active = 0;\n\n    listAddNodeTail(moduleKeyspaceSubscribers, sub);\n    return REDISMODULE_OK;\n}\n\nvoid firePostExecutionUnitJobs(void) {\n    /* Avoid propagation of commands.\n     * In that way, postExecutionUnitOperations will prevent\n     * recursive calls to firePostExecutionUnitJobs.\n     * This is a special case where we need to increase 'execution_nesting'\n     * but we do not want to update the cached time */\n    enterExecutionUnit(0, 0);\n    while (listLength(modulePostExecUnitJobs) > 0) {\n        listNode *ln = listFirst(modulePostExecUnitJobs);\n        RedisModulePostExecUnitJob *job = listNodeValue(ln);\n        listDelNode(modulePostExecUnitJobs, ln);\n\n        RedisModuleCtx ctx;\n        moduleCreateContext(&ctx, job->module, REDISMODULE_CTX_TEMP_CLIENT);\n        selectDb(ctx.client, job->dbid);\n\n        job->callback(&ctx, job->pd);\n        if (job->free_pd) job->free_pd(job->pd);\n\n        moduleFreeContext(&ctx);\n        zfree(job);\n    }\n    exitExecutionUnit();\n}\n\n/* When running inside a key space notification callback, it is dangerous and highly discouraged to perform any write\n * operation (See `RM_SubscribeToKeyspaceEvents`). In order to still perform write actions in this scenario,\n * Redis provides `RM_AddPostNotificationJob` API. The API allows to register a job callback which Redis will call\n * when the following condition are promised to be fulfilled:\n * 1. It is safe to perform any write operation.\n * 2. The job will be called atomically along side the key space notification.\n *\n * Notice, one job might trigger key space notifications that will trigger more jobs.\n * This raises a concerns of entering an infinite loops, we consider infinite loops\n * as a logical bug that need to be fixed in the module, an attempt to protect against\n * infinite loops by halting the execution could result in violation of the feature correctness\n * and so Redis will make no attempt to protect the module from infinite loops.\n *\n * 'free_pd' can be NULL and in such case will not be used.\n *\n * Return REDISMODULE_OK on success and REDISMODULE_ERR if was called while loading data from disk (AOF or RDB) or\n * if the instance is a readonly replica. */\nint RM_AddPostNotificationJob(RedisModuleCtx *ctx, RedisModulePostNotificationJobFunc callback, void *privdata, void (*free_privdata)(void*)) {\n    if (server.loading|| (server.masterhost && server.repl_slave_ro)) {\n        return REDISMODULE_ERR;\n    }\n    RedisModulePostExecUnitJob *job = zmalloc(sizeof(*job));\n    job->module = ctx->module;\n    job->callback = callback;\n    job->pd = privdata;\n    job->free_pd = free_privdata;\n    job->dbid = ctx->client->db->id;\n\n    listAddNodeTail(modulePostExecUnitJobs, job);\n    return REDISMODULE_OK;\n}\n\n/* Get the configured bitmap of notify-keyspace-events (Could be used\n * for additional filtering in RedisModuleNotificationFunc) */\nint RM_GetNotifyKeyspaceEvents(void) {\n    return server.notify_keyspace_events;\n}\n\n/* Expose notifyKeyspaceEvent to modules */\nint RM_NotifyKeyspaceEvent(RedisModuleCtx *ctx, int type, const char *event, RedisModuleString *key) {\n    if (!ctx || !ctx->client)\n        return REDISMODULE_ERR;\n    notifyKeyspaceEvent(type, (char *)event, key, ctx->client->db->id);\n    return REDISMODULE_OK;\n}\n\n/* Dispatcher for keyspace notifications to module subscriber functions.\n * This gets called  only if at least one module requested to be notified on\n * keyspace notifications */\nvoid moduleNotifyKeyspaceEvent(int type, const char *event, robj *key, int dbid) {\n    /* Don't do anything if there aren't any subscribers */\n    if (listLength(moduleKeyspaceSubscribers) == 0) return;\n\n    /* Ugly hack to handle modules which use write commands from within\n     * notify_callback, which they should NOT do!\n     * Modules should use RedisModules_AddPostNotificationJob instead.\n     *\n     * Anyway, we want any propagated commands from within notify_callback\n     * to be propagated inside a MULTI/EXEC together with the original\n     * command that caused the KSN.\n     * Note that it's only relevant for KSNs which are not generated from within\n     * call(), for example active-expiry and eviction (because anyway\n     * execution_nesting is incremented from within call())\n     *\n     * In order to do that we increment the execution_nesting counter, thus\n     * preventing postExecutionUnitOperations (from within moduleFreeContext)\n     * from propagating commands from CB.\n     *\n     * This is a special case where we need to increase 'execution_nesting'\n     * but we do not want to update the cached time */\n    enterExecutionUnit(0, 0);\n\n    listIter li;\n    listNode *ln;\n    listRewind(moduleKeyspaceSubscribers,&li);\n\n    /* Remove irrelevant flags from the type mask */\n    type &= ~(NOTIFY_KEYEVENT | NOTIFY_KEYSPACE);\n\n    while((ln = listNext(&li))) {\n        RedisModuleKeyspaceSubscriber *sub = ln->value;\n        /* Only notify subscribers on events matching the registration,\n         * and avoid subscribers triggering themselves */\n        if ((sub->event_mask & type) &&\n            (sub->active == 0 || (sub->module->options & REDISMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS))) {\n            RedisModuleCtx ctx;\n            moduleCreateContext(&ctx, sub->module, REDISMODULE_CTX_TEMP_CLIENT);\n            selectDb(ctx.client, dbid);\n\n            /* mark the handler as active to avoid reentrant loops.\n             * If the subscriber performs an action triggering itself,\n             * it will not be notified about it. */\n            int prev_active = sub->active;\n            sub->active = 1;\n            server.lazy_expire_disabled++;\n            sub->notify_callback(&ctx, type, event, key);\n            server.lazy_expire_disabled--;\n            sub->active = prev_active;\n            moduleFreeContext(&ctx);\n        }\n    }\n\n    exitExecutionUnit();\n}\n\n/* Unsubscribe any notification subscribers this module has upon unloading */\nvoid moduleUnsubscribeNotifications(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    listRewind(moduleKeyspaceSubscribers,&li);\n    while((ln = listNext(&li))) {\n        RedisModuleKeyspaceSubscriber *sub = ln->value;\n        if (sub->module == module) {\n            listDelNode(moduleKeyspaceSubscribers, ln);\n            zfree(sub);\n        }\n    }\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules Cluster API\n * -------------------------------------------------------------------------- */\n\n/* The Cluster message callback function pointer type. */\ntypedef void (*RedisModuleClusterMessageReceiver)(RedisModuleCtx *ctx, const char *sender_id, uint8_t type, const unsigned char *payload, uint32_t len);\n\n/* This structure identifies a registered caller: it must match a given module\n * ID, for a given message type. The callback function is just the function\n * that was registered as receiver. */\ntypedef struct moduleClusterReceiver {\n    uint64_t module_id;\n    RedisModuleClusterMessageReceiver callback;\n    struct RedisModule *module;\n    struct moduleClusterReceiver *next;\n} moduleClusterReceiver;\n\ntypedef struct moduleClusterNodeInfo {\n    int flags;\n    char ip[NET_IP_STR_LEN];\n    int port;\n    char master_id[40]; /* Only if flags & REDISMODULE_NODE_MASTER is true. */\n} mdouleClusterNodeInfo;\n\n/* We have an array of message types: each bucket is a linked list of\n * configured receivers. */\nstatic moduleClusterReceiver *clusterReceivers[UINT8_MAX];\n\n/* Dispatch the message to the right module receiver. */\nvoid moduleCallClusterReceivers(const char *sender_id, uint64_t module_id, uint8_t type, const unsigned char *payload, uint32_t len) {\n    moduleClusterReceiver *r = clusterReceivers[type];\n    while(r) {\n        if (r->module_id == module_id) {\n            RedisModuleCtx ctx;\n            moduleCreateContext(&ctx, r->module, REDISMODULE_CTX_TEMP_CLIENT);\n            r->callback(&ctx,sender_id,type,payload,len);\n            moduleFreeContext(&ctx);\n            return;\n        }\n        r = r->next;\n    }\n}\n\n/* Register a callback receiver for cluster messages of type 'type'. If there\n * was already a registered callback, this will replace the callback function\n * with the one provided, otherwise if the callback is set to NULL and there\n * is already a callback for this function, the callback is unregistered\n * (so this API call is also used in order to delete the receiver). */\nvoid RM_RegisterClusterMessageReceiver(RedisModuleCtx *ctx, uint8_t type, RedisModuleClusterMessageReceiver callback) {\n    if (!server.cluster_enabled) return;\n\n    uint64_t module_id = moduleTypeEncodeId(ctx->module->name,0);\n    moduleClusterReceiver *r = clusterReceivers[type], *prev = NULL;\n    while(r) {\n        if (r->module_id == module_id) {\n            /* Found! Set or delete. */\n            if (callback) {\n                r->callback = callback;\n            } else {\n                /* Delete the receiver entry if the user is setting\n                 * it to NULL. Just unlink the receiver node from the\n                 * linked list. */\n                if (prev)\n                    prev->next = r->next;\n                else\n                    clusterReceivers[type]->next = r->next;\n                zfree(r);\n            }\n            return;\n        }\n        prev = r;\n        r = r->next;\n    }\n\n    /* Not found, let's add it. */\n    if (callback) {\n        r = zmalloc(sizeof(*r));\n        r->module_id = module_id;\n        r->module = ctx->module;\n        r->callback = callback;\n        r->next = clusterReceivers[type];\n        clusterReceivers[type] = r;\n    }\n}\n\n/* Send a message to all the nodes in the cluster if `target` is NULL, otherwise\n * at the specified target, which is a REDISMODULE_NODE_ID_LEN bytes node ID, as\n * returned by the receiver callback or by the nodes iteration functions.\n *\n * The function returns REDISMODULE_OK if the message was successfully sent,\n * otherwise if the node is not connected or such node ID does not map to any\n * known cluster node, REDISMODULE_ERR is returned. */\nint RM_SendClusterMessage(RedisModuleCtx *ctx, const char *target_id, uint8_t type, const char *msg, uint32_t len) {\n    if (!server.cluster_enabled) return REDISMODULE_ERR;\n    uint64_t module_id = moduleTypeEncodeId(ctx->module->name,0);\n    if (clusterSendModuleMessageToTarget(target_id,module_id,type,msg,len) == C_OK)\n        return REDISMODULE_OK;\n    else\n        return REDISMODULE_ERR;\n}\n\n/* Return an array of string pointers, each string pointer points to a cluster\n * node ID of exactly REDISMODULE_NODE_ID_LEN bytes (without any null term).\n * The number of returned node IDs is stored into `*numnodes`.\n * However if this function is called by a module not running an a Redis\n * instance with Redis Cluster enabled, NULL is returned instead.\n *\n * The IDs returned can be used with RedisModule_GetClusterNodeInfo() in order\n * to get more information about single node.\n *\n * The array returned by this function must be freed using the function\n * RedisModule_FreeClusterNodesList().\n *\n * Example:\n *\n *     size_t count, j;\n *     char **ids = RedisModule_GetClusterNodesList(ctx,&count);\n *     for (j = 0; j < count; j++) {\n *         RedisModule_Log(ctx,\"notice\",\"Node %.*s\",\n *             REDISMODULE_NODE_ID_LEN,ids[j]);\n *     }\n *     RedisModule_FreeClusterNodesList(ids);\n */\nchar **RM_GetClusterNodesList(RedisModuleCtx *ctx, size_t *numnodes) {\n    UNUSED(ctx);\n\n    if (!server.cluster_enabled) return NULL;\n    return getClusterNodesList(numnodes);\n}\n\n/* Free the node list obtained with RedisModule_GetClusterNodesList. */\nvoid RM_FreeClusterNodesList(char **ids) {\n    if (ids == NULL) return;\n    for (int j = 0; ids[j]; j++) zfree(ids[j]);\n    zfree(ids);\n}\n\n/* Return this node ID (REDISMODULE_CLUSTER_ID_LEN bytes) or NULL if the cluster\n * is disabled. */\nconst char *RM_GetMyClusterID(void) {\n    if (!server.cluster_enabled) return NULL;\n    return getMyClusterId();\n}\n\n/* Return the number of nodes in the cluster, regardless of their state\n * (handshake, noaddress, ...) so that the number of active nodes may actually\n * be smaller, but not greater than this number. If the instance is not in\n * cluster mode, zero is returned. */\nsize_t RM_GetClusterSize(void) {\n    if (!server.cluster_enabled) return 0;\n    return getClusterSize();\n}\n\n/* Populate the specified info for the node having as ID the specified 'id',\n * then returns REDISMODULE_OK. Otherwise if the format of node ID is invalid\n * or the node ID does not exist from the POV of this local node, REDISMODULE_ERR\n * is returned.\n *\n * The arguments `ip`, `master_id`, `port` and `flags` can be NULL in case we don't\n * need to populate back certain info. If an `ip` and `master_id` (only populated\n * if the instance is a slave) are specified, they point to buffers holding\n * at least REDISMODULE_NODE_ID_LEN bytes. The strings written back as `ip`\n * and `master_id` are not null terminated.\n *\n * The list of flags reported is the following:\n *\n * * REDISMODULE_NODE_MYSELF:       This node\n * * REDISMODULE_NODE_MASTER:       The node is a master\n * * REDISMODULE_NODE_SLAVE:        The node is a replica\n * * REDISMODULE_NODE_PFAIL:        We see the node as failing\n * * REDISMODULE_NODE_FAIL:         The cluster agrees the node is failing\n * * REDISMODULE_NODE_NOFAILOVER:   The slave is configured to never failover\n */\nint RM_GetClusterNodeInfo(RedisModuleCtx *ctx, const char *id, char *ip, char *master_id, int *port, int *flags) {\n    UNUSED(ctx);\n\n    clusterNode *node = clusterLookupNode(id, strlen(id));\n    if (node == NULL || clusterNodePending(node))\n    {\n        return REDISMODULE_ERR;\n    }\n\n    if (ip) redis_strlcpy(ip, clusterNodeIp(node),NET_IP_STR_LEN);\n\n    if (master_id) {\n        /* If the information is not available, the function will set the\n         * field to zero bytes, so that when the field can't be populated the\n         * function kinda remains predictable. */\n        if (clusterNodeIsSlave(node) && clusterNodeGetSlaveof(node))\n            memcpy(master_id, clusterNodeGetName(clusterNodeGetSlaveof(node)) ,REDISMODULE_NODE_ID_LEN);\n        else\n            memset(master_id,0,REDISMODULE_NODE_ID_LEN);\n    }\n    if (port) *port = getNodeDefaultClientPort(node);\n\n    /* As usually we have to remap flags for modules, in order to ensure\n     * we can provide binary compatibility. */\n    if (flags) {\n        *flags = 0;\n        if (clusterNodeIsMyself(node)) *flags |= REDISMODULE_NODE_MYSELF;\n        if (clusterNodeIsMaster(node)) *flags |= REDISMODULE_NODE_MASTER;\n        if (clusterNodeIsSlave(node)) *flags |= REDISMODULE_NODE_SLAVE;\n        if (clusterNodeTimedOut(node)) *flags |= REDISMODULE_NODE_PFAIL;\n        if (clusterNodeIsFailing(node)) *flags |= REDISMODULE_NODE_FAIL;\n        if (clusterNodeIsNoFailover(node)) *flags |= REDISMODULE_NODE_NOFAILOVER;\n    }\n    return REDISMODULE_OK;\n}\n\n/* Set Redis Cluster flags in order to change the normal behavior of\n * Redis Cluster, especially with the goal of disabling certain functions.\n * This is useful for modules that use the Cluster API in order to create\n * a different distributed system, but still want to use the Redis Cluster\n * message bus. Flags that can be set:\n *\n * * CLUSTER_MODULE_FLAG_NO_FAILOVER\n * * CLUSTER_MODULE_FLAG_NO_REDIRECTION\n *\n * With the following effects:\n *\n * * NO_FAILOVER: prevent Redis Cluster slaves from failing over a dead master.\n *                Also disables the replica migration feature.\n *\n * * NO_REDIRECTION: Every node will accept any key, without trying to perform\n *                   partitioning according to the Redis Cluster algorithm.\n *                   Slots information will still be propagated across the\n *                   cluster, but without effect. */\nvoid RM_SetClusterFlags(RedisModuleCtx *ctx, uint64_t flags) {\n    UNUSED(ctx);\n    if (flags & REDISMODULE_CLUSTER_FLAG_NO_FAILOVER)\n        server.cluster_module_flags |= CLUSTER_MODULE_FLAG_NO_FAILOVER;\n    if (flags & REDISMODULE_CLUSTER_FLAG_NO_REDIRECTION)\n        server.cluster_module_flags |= CLUSTER_MODULE_FLAG_NO_REDIRECTION;\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules Timers API\n *\n * Module timers are a high precision \"green timers\" abstraction where\n * every module can register even millions of timers without problems, even if\n * the actual event loop will just have a single timer that is used to awake the\n * module timers subsystem in order to process the next event.\n *\n * All the timers are stored into a radix tree, ordered by expire time, when\n * the main Redis event loop timer callback is called, we try to process all\n * the timers already expired one after the other. Then we re-enter the event\n * loop registering a timer that will expire when the next to process module\n * timer will expire.\n *\n * Every time the list of active timers drops to zero, we unregister the\n * main event loop timer, so that there is no overhead when such feature is\n * not used.\n * -------------------------------------------------------------------------- */\n\nstatic rax *Timers;     /* The radix tree of all the timers sorted by expire. */\nlong long aeTimer = -1; /* Main event loop (ae.c) timer identifier. */\n\ntypedef void (*RedisModuleTimerProc)(RedisModuleCtx *ctx, void *data);\n\n/* The timer descriptor, stored as value in the radix tree. */\ntypedef struct RedisModuleTimer {\n    RedisModule *module;                /* Module reference. */\n    RedisModuleTimerProc callback;      /* The callback to invoke on expire. */\n    void *data;                         /* Private data for the callback. */\n    int dbid;                           /* Database number selected by the original client. */\n} RedisModuleTimer;\n\n/* This is the timer handler that is called by the main event loop. We schedule\n * this timer to be called when the nearest of our module timers will expire. */\nint moduleTimerHandler(struct aeEventLoop *eventLoop, long long id, void *clientData) {\n    UNUSED(eventLoop);\n    UNUSED(id);\n    UNUSED(clientData);\n\n    /* To start let's try to fire all the timers already expired. */\n    raxIterator ri;\n    raxStart(&ri,Timers);\n    uint64_t now = ustime();\n    long long next_period = 0;\n    while(1) {\n        raxSeek(&ri,\"^\",NULL,0);\n        if (!raxNext(&ri)) break;\n        uint64_t expiretime;\n        memcpy(&expiretime,ri.key,sizeof(expiretime));\n        expiretime = ntohu64(expiretime);\n        if (now >= expiretime) {\n            RedisModuleTimer *timer = ri.data;\n            RedisModuleCtx ctx;\n            moduleCreateContext(&ctx,timer->module,REDISMODULE_CTX_TEMP_CLIENT);\n            selectDb(ctx.client, timer->dbid);\n            timer->callback(&ctx,timer->data);\n            moduleFreeContext(&ctx);\n            raxRemove(Timers,(unsigned char*)ri.key,ri.key_len,NULL);\n            zfree(timer);\n        } else {\n            /* We call ustime() again instead of using the cached 'now' so that\n             * 'next_period' isn't affected by the time it took to execute\n             * previous calls to 'callback.\n             * We need to cast 'expiretime' so that the compiler will not treat\n             * the difference as unsigned (Causing next_period to be huge) in\n             * case expiretime < ustime() */\n            next_period = ((long long)expiretime-ustime())/1000; /* Scale to milliseconds. */\n            break;\n        }\n    }\n    raxStop(&ri);\n\n    /* Reschedule the next timer or cancel it. */\n    if (next_period <= 0) next_period = 1;\n    if (raxSize(Timers) > 0) {\n        return next_period;\n    } else {\n        aeTimer = -1;\n        return AE_NOMORE;\n    }\n}\n\n/* Create a new timer that will fire after `period` milliseconds, and will call\n * the specified function using `data` as argument. The returned timer ID can be\n * used to get information from the timer or to stop it before it fires.\n * Note that for the common use case of a repeating timer (Re-registration\n * of the timer inside the RedisModuleTimerProc callback) it matters when\n * this API is called:\n * If it is called at the beginning of 'callback' it means\n * the event will triggered every 'period'.\n * If it is called at the end of 'callback' it means\n * there will 'period' milliseconds gaps between events.\n * (If the time it takes to execute 'callback' is negligible the two\n * statements above mean the same) */\nRedisModuleTimerID RM_CreateTimer(RedisModuleCtx *ctx, mstime_t period, RedisModuleTimerProc callback, void *data) {\n    RedisModuleTimer *timer = zmalloc(sizeof(*timer));\n    timer->module = ctx->module;\n    timer->callback = callback;\n    timer->data = data;\n    timer->dbid = ctx->client ? ctx->client->db->id : 0;\n    uint64_t expiretime = ustime()+period*1000;\n    uint64_t key;\n\n    while(1) {\n        key = htonu64(expiretime);\n        if (!raxFind(Timers, (unsigned char*)&key,sizeof(key),NULL)) {\n            raxInsert(Timers,(unsigned char*)&key,sizeof(key),timer,NULL);\n            break;\n        } else {\n            expiretime++;\n        }\n    }\n\n    /* We need to install the main event loop timer if it's not already\n     * installed, or we may need to refresh its period if we just installed\n     * a timer that will expire sooner than any other else (i.e. the timer\n     * we just installed is the first timer in the Timers rax). */\n    if (aeTimer != -1) {\n        raxIterator ri;\n        raxStart(&ri,Timers);\n        raxSeek(&ri,\"^\",NULL,0);\n        raxNext(&ri);\n        if (memcmp(ri.key,&key,sizeof(key)) == 0) {\n            /* This is the first key, we need to re-install the timer according\n             * to the just added event. */\n            aeDeleteTimeEvent(server.el,aeTimer);\n            aeTimer = -1;\n        }\n        raxStop(&ri);\n    }\n\n    /* If we have no main timer (the old one was invalidated, or this is the\n     * first module timer we have), install one. */\n    if (aeTimer == -1)\n        aeTimer = aeCreateTimeEvent(server.el,period,moduleTimerHandler,NULL,NULL);\n\n    return key;\n}\n\n/* Stop a timer, returns REDISMODULE_OK if the timer was found, belonged to the\n * calling module, and was stopped, otherwise REDISMODULE_ERR is returned.\n * If not NULL, the data pointer is set to the value of the data argument when\n * the timer was created. */\nint RM_StopTimer(RedisModuleCtx *ctx, RedisModuleTimerID id, void **data) {\n    void *result;\n    if (!raxFind(Timers,(unsigned char*)&id,sizeof(id),&result))\n        return REDISMODULE_ERR;\n    RedisModuleTimer *timer = result;\n    if (timer->module != ctx->module)\n        return REDISMODULE_ERR;\n    if (data) *data = timer->data;\n    raxRemove(Timers,(unsigned char*)&id,sizeof(id),NULL);\n    zfree(timer);\n    return REDISMODULE_OK;\n}\n\n/* Obtain information about a timer: its remaining time before firing\n * (in milliseconds), and the private data pointer associated with the timer.\n * If the timer specified does not exist or belongs to a different module\n * no information is returned and the function returns REDISMODULE_ERR, otherwise\n * REDISMODULE_OK is returned. The arguments remaining or data can be NULL if\n * the caller does not need certain information. */\nint RM_GetTimerInfo(RedisModuleCtx *ctx, RedisModuleTimerID id, uint64_t *remaining, void **data) {\n    void *result;\n    if (!raxFind(Timers,(unsigned char*)&id,sizeof(id),&result))\n        return REDISMODULE_ERR;\n    RedisModuleTimer *timer = result;\n    if (timer->module != ctx->module)\n        return REDISMODULE_ERR;\n    if (remaining) {\n        int64_t rem = ntohu64(id)-ustime();\n        if (rem < 0) rem = 0;\n        *remaining = rem/1000; /* Scale to milliseconds. */\n    }\n    if (data) *data = timer->data;\n    return REDISMODULE_OK;\n}\n\n/* Query timers to see if any timer belongs to the module.\n * Return 1 if any timer was found, otherwise 0 would be returned. */\nint moduleHoldsTimer(struct RedisModule *module) {\n    raxIterator iter;\n    int found = 0;\n    raxStart(&iter,Timers);\n    raxSeek(&iter,\"^\",NULL,0);\n    while (raxNext(&iter)) {\n        RedisModuleTimer *timer = iter.data;\n        if (timer->module == module) {\n            found = 1;\n            break;\n        }\n    }\n    raxStop(&iter);\n    return found;\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules EventLoop API\n * --------------------------------------------------------------------------*/\n\ntypedef struct EventLoopData {\n    RedisModuleEventLoopFunc rFunc;\n    RedisModuleEventLoopFunc wFunc;\n    void *user_data;\n} EventLoopData;\n\ntypedef struct EventLoopOneShot {\n    RedisModuleEventLoopOneShotFunc func;\n    void *user_data;\n} EventLoopOneShot;\n\nlist *moduleEventLoopOneShots;\nstatic pthread_mutex_t moduleEventLoopMutex = PTHREAD_MUTEX_INITIALIZER;\n\nstatic int eventLoopToAeMask(int mask) {\n    int aeMask = 0;\n    if (mask & REDISMODULE_EVENTLOOP_READABLE)\n        aeMask |= AE_READABLE;\n    if (mask & REDISMODULE_EVENTLOOP_WRITABLE)\n        aeMask |= AE_WRITABLE;\n    return aeMask;\n}\n\nstatic int eventLoopFromAeMask(int ae_mask) {\n    int mask = 0;\n    if (ae_mask & AE_READABLE)\n        mask |= REDISMODULE_EVENTLOOP_READABLE;\n    if (ae_mask & AE_WRITABLE)\n        mask |= REDISMODULE_EVENTLOOP_WRITABLE;\n    return mask;\n}\n\nstatic void eventLoopCbReadable(struct aeEventLoop *ae, int fd, void *user_data, int ae_mask) {\n    UNUSED(ae);\n    EventLoopData *data = user_data;\n    data->rFunc(fd, data->user_data, eventLoopFromAeMask(ae_mask));\n}\n\nstatic void eventLoopCbWritable(struct aeEventLoop *ae, int fd, void *user_data, int ae_mask) {\n    UNUSED(ae);\n    EventLoopData *data = user_data;\n    data->wFunc(fd, data->user_data, eventLoopFromAeMask(ae_mask));\n}\n\n/* Add a pipe / socket event to the event loop.\n *\n * * `mask` must be one of the following values:\n *\n *     * `REDISMODULE_EVENTLOOP_READABLE`\n *     * `REDISMODULE_EVENTLOOP_WRITABLE`\n *     * `REDISMODULE_EVENTLOOP_READABLE | REDISMODULE_EVENTLOOP_WRITABLE`\n *\n * On success REDISMODULE_OK is returned, otherwise\n * REDISMODULE_ERR is returned and errno is set to the following values:\n *\n * * ERANGE: `fd` is negative or higher than `maxclients` Redis config.\n * * EINVAL: `callback` is NULL or `mask` value is invalid.\n *\n * `errno` might take other values in case of an internal error.\n *\n * Example:\n *\n *     void onReadable(int fd, void *user_data, int mask) {\n *         char buf[32];\n *         int bytes = read(fd,buf,sizeof(buf));\n *         printf(\"Read %d bytes \\n\", bytes);\n *     }\n *     RM_EventLoopAdd(fd, REDISMODULE_EVENTLOOP_READABLE, onReadable, NULL);\n */\nint RM_EventLoopAdd(int fd, int mask, RedisModuleEventLoopFunc func, void *user_data) {\n    if (fd < 0 || fd >= aeGetSetSize(server.el)) {\n        errno = ERANGE;\n        return REDISMODULE_ERR;\n    }\n\n    if (!func || mask & ~(REDISMODULE_EVENTLOOP_READABLE |\n                          REDISMODULE_EVENTLOOP_WRITABLE)) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    /* We are going to register stub callbacks to 'ae' for two reasons:\n     *\n     * - \"ae\" callback signature is different from RedisModuleEventLoopCallback,\n     *   that will be handled it in our stub callbacks.\n     * - We need to remap 'mask' value to provide binary compatibility.\n     *\n     * For the stub callbacks, saving user 'callback' and 'user_data' in an\n     * EventLoopData object and passing it to ae, later, we'll extract\n     * 'callback' and 'user_data' from that.\n     */\n    EventLoopData *data = aeGetFileClientData(server.el, fd);\n    if (!data)\n        data = zcalloc(sizeof(*data));\n\n    aeFileProc *aeProc;\n    if (mask & REDISMODULE_EVENTLOOP_READABLE)\n        aeProc = eventLoopCbReadable;\n    else\n        aeProc = eventLoopCbWritable;\n\n    int aeMask = eventLoopToAeMask(mask);\n\n    if (aeCreateFileEvent(server.el, fd, aeMask, aeProc, data) != AE_OK) {\n        if (aeGetFileEvents(server.el, fd) == AE_NONE)\n            zfree(data);\n        return REDISMODULE_ERR;\n    }\n\n    data->user_data = user_data;\n    if (mask & REDISMODULE_EVENTLOOP_READABLE)\n        data->rFunc = func;\n    if (mask & REDISMODULE_EVENTLOOP_WRITABLE)\n        data->wFunc = func;\n\n    errno = 0;\n    return REDISMODULE_OK;\n}\n\n/* Delete a pipe / socket event from the event loop.\n *\n * * `mask` must be one of the following values:\n *\n *     * `REDISMODULE_EVENTLOOP_READABLE`\n *     * `REDISMODULE_EVENTLOOP_WRITABLE`\n *     * `REDISMODULE_EVENTLOOP_READABLE | REDISMODULE_EVENTLOOP_WRITABLE`\n *\n * On success REDISMODULE_OK is returned, otherwise\n * REDISMODULE_ERR is returned and errno is set to the following values:\n *\n * * ERANGE: `fd` is negative or higher than `maxclients` Redis config.\n * * EINVAL: `mask` value is invalid.\n */\nint RM_EventLoopDel(int fd, int mask) {\n    if (fd < 0 || fd >= aeGetSetSize(server.el)) {\n        errno = ERANGE;\n        return REDISMODULE_ERR;\n    }\n\n    if (mask & ~(REDISMODULE_EVENTLOOP_READABLE |\n                 REDISMODULE_EVENTLOOP_WRITABLE)) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    /* After deleting the event, if fd does not have any registered event\n     * anymore, we can free the EventLoopData object. */\n    EventLoopData *data = aeGetFileClientData(server.el, fd);\n    aeDeleteFileEvent(server.el, fd, eventLoopToAeMask(mask));\n    if (aeGetFileEvents(server.el, fd) == AE_NONE)\n        zfree(data);\n\n    errno = 0;\n    return REDISMODULE_OK;\n}\n\n/* This function can be called from other threads to trigger callback on Redis\n * main thread. On success REDISMODULE_OK is returned. If `func` is NULL\n * REDISMODULE_ERR is returned and errno is set to EINVAL.\n */\nint RM_EventLoopAddOneShot(RedisModuleEventLoopOneShotFunc func, void *user_data) {\n    if (!func) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    EventLoopOneShot *oneshot = zmalloc(sizeof(*oneshot));\n    oneshot->func = func;\n    oneshot->user_data = user_data;\n\n    pthread_mutex_lock(&moduleEventLoopMutex);\n    if (!moduleEventLoopOneShots) moduleEventLoopOneShots = listCreate();\n    listAddNodeTail(moduleEventLoopOneShots, oneshot);\n    pthread_mutex_unlock(&moduleEventLoopMutex);\n\n    if (write(server.module_pipe[1],\"A\",1) != 1) {\n        /* Pipe is non-blocking, write() may fail if it's full. */\n    }\n\n    errno = 0;\n    return REDISMODULE_OK;\n}\n\n/* This function will check the moduleEventLoopOneShots queue in order to\n * call the callback for the registered oneshot events. */\nstatic void eventLoopHandleOneShotEvents(void) {\n    pthread_mutex_lock(&moduleEventLoopMutex);\n    if (moduleEventLoopOneShots) {\n        while (listLength(moduleEventLoopOneShots)) {\n            listNode *ln = listFirst(moduleEventLoopOneShots);\n            EventLoopOneShot *oneshot = ln->value;\n            listDelNode(moduleEventLoopOneShots, ln);\n            /* Unlock mutex before the callback. Another oneshot event can be\n             * added in the callback, it will need to lock the mutex. */\n            pthread_mutex_unlock(&moduleEventLoopMutex);\n            oneshot->func(oneshot->user_data);\n            zfree(oneshot);\n            /* Lock again for the next iteration */\n            pthread_mutex_lock(&moduleEventLoopMutex);\n        }\n    }\n    pthread_mutex_unlock(&moduleEventLoopMutex);\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules ACL API\n *\n * Implements a hook into the authentication and authorization within Redis.\n * --------------------------------------------------------------------------*/\n\n/* This function is called when a client's user has changed and invokes the\n * client's user changed callback if it was set. This callback should\n * cleanup any state the module was tracking about this client.\n *\n * A client's user can be changed through the AUTH command, module\n * authentication, and when a client is freed. */\nvoid moduleNotifyUserChanged(client *c) {\n    if (c->auth_callback) {\n        c->auth_callback(c->id, c->auth_callback_privdata);\n\n        /* The callback will fire exactly once, even if the user remains\n         * the same. It is expected to completely clean up the state\n         * so all references are cleared here. */\n        c->auth_callback = NULL;\n        c->auth_callback_privdata = NULL;\n        c->auth_module = NULL;\n    }\n}\n\nvoid revokeClientAuthentication(client *c) {\n    /* Freeing the client would result in moduleNotifyUserChanged() to be\n     * called later, however since we use revokeClientAuthentication() also\n     * in moduleFreeAuthenticatedClients() to implement module unloading, we\n     * do this action ASAP: this way if the module is unloaded, when the client\n     * is eventually freed we don't rely on the module to still exist. */\n    moduleNotifyUserChanged(c);\n\n    c->user = DefaultUser;\n    c->authenticated = 0;\n    /* We will write replies to this client later, so we can't close it\n     * directly even if async. */\n    if (c == server.current_client) {\n        c->flags |= CLIENT_CLOSE_AFTER_COMMAND;\n    } else {\n        freeClientAsync(c);\n    }\n}\n\n/* Cleanup all clients that have been authenticated with this module. This\n * is called from onUnload() to give the module a chance to cleanup any\n * resources associated with clients it has authenticated. */\nstatic void moduleFreeAuthenticatedClients(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    listRewind(server.clients,&li);\n    while ((ln = listNext(&li)) != NULL) {\n        client *c = listNodeValue(ln);\n        if (!c->auth_module) continue;\n\n        RedisModule *auth_module = (RedisModule *) c->auth_module;\n        if (auth_module == module) {\n            revokeClientAuthentication(c);\n        }\n    }\n}\n\n/* Creates a Redis ACL user that the module can use to authenticate a client.\n * After obtaining the user, the module should set what such user can do\n * using the RM_SetUserACL() function. Once configured, the user\n * can be used in order to authenticate a connection, with the specified\n * ACL rules, using the RedisModule_AuthClientWithUser() function.\n *\n * Note that:\n *\n * * Users created here are not listed by the ACL command.\n * * Users created here are not checked for duplicated name, so it's up to\n *   the module calling this function to take care of not creating users\n *   with the same name.\n * * The created user can be used to authenticate multiple Redis connections.\n *\n * The caller can later free the user using the function\n * RM_FreeModuleUser(). When this function is called, if there are\n * still clients authenticated with this user, they are disconnected.\n * The function to free the user should only be used when the caller really\n * wants to invalidate the user to define a new one with different\n * capabilities. */\nRedisModuleUser *RM_CreateModuleUser(const char *name) {\n    RedisModuleUser *new_user = zmalloc(sizeof(RedisModuleUser));\n    new_user->user = ACLCreateUnlinkedUser();\n    new_user->free_user = 1;\n\n    /* Free the previous temporarily assigned name to assign the new one */\n    sdsfree(new_user->user->name);\n    new_user->user->name = sdsnew(name);\n    return new_user;\n}\n\n/* Frees a given user and disconnects all of the clients that have been\n * authenticated with it. See RM_CreateModuleUser for detailed usage.*/\nint RM_FreeModuleUser(RedisModuleUser *user) {\n    if (user->free_user)\n        ACLFreeUserAndKillClients(user->user);\n    zfree(user);\n    return REDISMODULE_OK;\n}\n\n/* Sets the permissions of a user created through the redis module\n * interface. The syntax is the same as ACL SETUSER, so refer to the\n * documentation in acl.c for more information. See RM_CreateModuleUser\n * for detailed usage.\n *\n * Returns REDISMODULE_OK on success and REDISMODULE_ERR on failure\n * and will set an errno describing why the operation failed. */\nint RM_SetModuleUserACL(RedisModuleUser *user, const char* acl) {\n    return ACLSetUser(user->user, acl, -1);\n}\n\n/* Sets the permission of a user with a complete ACL string, such as one\n * would use on the redis ACL SETUSER command line API. This differs from\n * RM_SetModuleUserACL, which only takes single ACL operations at a time.\n *\n * Returns REDISMODULE_OK on success and REDISMODULE_ERR on failure\n * if a RedisModuleString is provided in error, a string describing the error\n * will be returned */\nint RM_SetModuleUserACLString(RedisModuleCtx *ctx, RedisModuleUser *user, const char *acl, RedisModuleString **error) {\n    serverAssert(user != NULL);\n\n    int argc;\n    sds *argv = sdssplitargs(acl, &argc);\n\n    sds err = ACLStringSetUser(user->user, NULL, argv, argc);\n\n    sdsfreesplitres(argv, argc);\n\n    if (err) {\n        if (error) {\n            *error = createObject(OBJ_STRING, err);\n            if (ctx != NULL) autoMemoryAdd(ctx, REDISMODULE_AM_STRING, *error);\n        } else {\n            sdsfree(err);\n        }\n\n        return REDISMODULE_ERR;\n    }\n\n    return REDISMODULE_OK;\n}\n\n/* Get the ACL string for a given user\n * Returns a RedisModuleString\n */\nRedisModuleString *RM_GetModuleUserACLString(RedisModuleUser *user) {\n    serverAssert(user != NULL);\n\n    return ACLDescribeUser(user->user);\n}\n\n/* Retrieve the user name of the client connection behind the current context.\n * The user name can be used later, in order to get a RedisModuleUser.\n * See more information in RM_GetModuleUserFromUserName.\n *\n * The returned string must be released with RedisModule_FreeString() or by\n * enabling automatic memory management. */\nRedisModuleString *RM_GetCurrentUserName(RedisModuleCtx *ctx) {\n    return RM_CreateString(ctx,ctx->client->user->name,sdslen(ctx->client->user->name));\n}\n\n/* A RedisModuleUser can be used to check if command, key or channel can be executed or\n * accessed according to the ACLs rules associated with that user.\n * When a Module wants to do ACL checks on a general ACL user (not created by RM_CreateModuleUser),\n * it can get the RedisModuleUser from this API, based on the user name retrieved by RM_GetCurrentUserName.\n *\n * Since a general ACL user can be deleted at any time, this RedisModuleUser should be used only in the context\n * where this function was called. In order to do ACL checks out of that context, the Module can store the user name,\n * and call this API at any other context.\n *\n * Returns NULL if the user is disabled or the user does not exist.\n * The caller should later free the user using the function RM_FreeModuleUser().*/\nRedisModuleUser *RM_GetModuleUserFromUserName(RedisModuleString *name) {\n    /* First, verify that the user exist */\n    user *acl_user = ACLGetUserByName(name->ptr, sdslen(name->ptr));\n    if (acl_user == NULL) {\n        return NULL;\n    }\n\n    RedisModuleUser *new_user = zmalloc(sizeof(RedisModuleUser));\n    new_user->user = acl_user;\n    new_user->free_user = 0;\n    return new_user;\n}\n\n/* Checks if the command can be executed by the user, according to the ACLs associated with it.\n *\n * On success a REDISMODULE_OK is returned, otherwise\n * REDISMODULE_ERR is returned and errno is set to the following values:\n *\n * * ENOENT: Specified command does not exist.\n * * EACCES: Command cannot be executed, according to ACL rules\n */\nint RM_ACLCheckCommandPermissions(RedisModuleUser *user, RedisModuleString **argv, int argc) {\n    int keyidxptr;\n    struct redisCommand *cmd;\n\n    /* Find command */\n    if ((cmd = lookupCommand(argv, argc)) == NULL) {\n        errno = ENOENT;\n        return REDISMODULE_ERR;\n    }\n\n    if (ACLCheckAllUserCommandPerm(user->user, cmd, argv, argc, &keyidxptr) != ACL_OK) {\n        errno = EACCES;\n        return REDISMODULE_ERR;\n    }\n\n    return REDISMODULE_OK;\n}\n\n/* Check if the key can be accessed by the user according to the ACLs attached to the user\n * and the flags representing the key access. The flags are the same that are used in the\n * keyspec for logical operations. These flags are documented in RedisModule_SetCommandInfo as\n * the REDISMODULE_CMD_KEY_ACCESS, REDISMODULE_CMD_KEY_UPDATE, REDISMODULE_CMD_KEY_INSERT,\n * and REDISMODULE_CMD_KEY_DELETE flags.\n * \n * If no flags are supplied, the user is still required to have some access to the key for\n * this command to return successfully.\n *\n * If the user is able to access the key then REDISMODULE_OK is returned, otherwise\n * REDISMODULE_ERR is returned and errno is set to one of the following values:\n * \n * * EINVAL: The provided flags are invalid.\n * * EACCESS: The user does not have permission to access the key.\n */\nint RM_ACLCheckKeyPermissions(RedisModuleUser *user, RedisModuleString *key, int flags) {\n    const int allow_mask = (REDISMODULE_CMD_KEY_ACCESS\n        | REDISMODULE_CMD_KEY_INSERT\n        | REDISMODULE_CMD_KEY_DELETE\n        | REDISMODULE_CMD_KEY_UPDATE);\n\n    if ((flags & allow_mask) != flags) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    int keyspec_flags = moduleConvertKeySpecsFlags(flags, 0);\n    if (ACLUserCheckKeyPerm(user->user, key->ptr, sdslen(key->ptr), keyspec_flags) != ACL_OK) {\n        errno = EACCES;\n        return REDISMODULE_ERR;\n    }\n\n    return REDISMODULE_OK;\n}\n\n/* Check if the pubsub channel can be accessed by the user based off of the given\n * access flags. See RM_ChannelAtPosWithFlags for more information about the\n * possible flags that can be passed in.\n *\n * If the user is able to access the pubsub channel then REDISMODULE_OK is returned, otherwise\n * REDISMODULE_ERR is returned and errno is set to one of the following values:\n * \n * * EINVAL: The provided flags are invalid.\n * * EACCESS: The user does not have permission to access the pubsub channel. \n */\nint RM_ACLCheckChannelPermissions(RedisModuleUser *user, RedisModuleString *ch, int flags) {\n    const int allow_mask = (REDISMODULE_CMD_CHANNEL_PUBLISH\n        | REDISMODULE_CMD_CHANNEL_SUBSCRIBE\n        | REDISMODULE_CMD_CHANNEL_UNSUBSCRIBE\n        | REDISMODULE_CMD_CHANNEL_PATTERN);\n\n    if ((flags & allow_mask) != flags) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    /* Unsubscribe permissions are currently always allowed. */\n    if (flags & REDISMODULE_CMD_CHANNEL_UNSUBSCRIBE){\n        return REDISMODULE_OK;\n    }\n\n    int is_pattern = flags & REDISMODULE_CMD_CHANNEL_PATTERN;\n    if (ACLUserCheckChannelPerm(user->user, ch->ptr, is_pattern) != ACL_OK)\n        return REDISMODULE_ERR;\n\n    return REDISMODULE_OK;\n}\n\n/* Helper function to map a RedisModuleACLLogEntryReason to ACL Log entry reason. */\nint moduleGetACLLogEntryReason(RedisModuleACLLogEntryReason reason) {\n    int acl_reason = 0;\n    switch (reason) {\n        case REDISMODULE_ACL_LOG_AUTH: acl_reason = ACL_DENIED_AUTH; break;\n        case REDISMODULE_ACL_LOG_KEY: acl_reason = ACL_DENIED_KEY; break;\n        case REDISMODULE_ACL_LOG_CHANNEL: acl_reason = ACL_DENIED_CHANNEL; break;\n        case REDISMODULE_ACL_LOG_CMD: acl_reason = ACL_DENIED_CMD; break;\n        default: break;\n    }\n    return acl_reason;\n}\n\n/* Adds a new entry in the ACL log.\n * Returns REDISMODULE_OK on success and REDISMODULE_ERR on error.\n *\n * For more information about ACL log, please refer to https://redis.io/commands/acl-log */\nint RM_ACLAddLogEntry(RedisModuleCtx *ctx, RedisModuleUser *user, RedisModuleString *object, RedisModuleACLLogEntryReason reason) {\n    int acl_reason = moduleGetACLLogEntryReason(reason);\n    if (!acl_reason) return REDISMODULE_ERR;\n    addACLLogEntry(ctx->client, acl_reason, ACL_LOG_CTX_MODULE, -1, user->user->name, sdsdup(object->ptr));\n    return REDISMODULE_OK;\n}\n\n/* Adds a new entry in the ACL log with the `username` RedisModuleString provided.\n * Returns REDISMODULE_OK on success and REDISMODULE_ERR on error.\n *\n * For more information about ACL log, please refer to https://redis.io/commands/acl-log */\nint RM_ACLAddLogEntryByUserName(RedisModuleCtx *ctx, RedisModuleString *username, RedisModuleString *object, RedisModuleACLLogEntryReason reason) {\n    int acl_reason = moduleGetACLLogEntryReason(reason);\n    if (!acl_reason) return REDISMODULE_ERR;\n    addACLLogEntry(ctx->client, acl_reason, ACL_LOG_CTX_MODULE, -1, username->ptr, sdsdup(object->ptr));\n    return REDISMODULE_OK;\n}\n\n/* Authenticate the client associated with the context with\n * the provided user. Returns REDISMODULE_OK on success and\n * REDISMODULE_ERR on error.\n *\n * This authentication can be tracked with the optional callback and private\n * data fields. The callback will be called whenever the user of the client\n * changes. This callback should be used to cleanup any state that is being\n * kept in the module related to the client authentication. It will only be\n * called once, even when the user hasn't changed, in order to allow for a\n * new callback to be specified. If this authentication does not need to be\n * tracked, pass in NULL for the callback and privdata.\n *\n * If client_id is not NULL, it will be filled with the id of the client\n * that was authenticated. This can be used with the\n * RM_DeauthenticateAndCloseClient() API in order to deauthenticate a\n * previously authenticated client if the authentication is no longer valid.\n *\n * For expensive authentication operations, it is recommended to block the\n * client and do the authentication in the background and then attach the user\n * to the client in a threadsafe context. */\nstatic int authenticateClientWithUser(RedisModuleCtx *ctx, user *user, RedisModuleUserChangedFunc callback, void *privdata, uint64_t *client_id) {\n    if (user->flags & USER_FLAG_DISABLED) {\n        return REDISMODULE_ERR;\n    }\n\n    /* Avoid settings which are meaningless and will be lost */\n    if (!ctx->client || (ctx->client->flags & CLIENT_MODULE)) {\n        return REDISMODULE_ERR;\n    }\n\n    moduleNotifyUserChanged(ctx->client);\n\n    ctx->client->user = user;\n    ctx->client->authenticated = 1;\n\n    if (clientHasModuleAuthInProgress(ctx->client)) {\n        ctx->client->flags |= CLIENT_MODULE_AUTH_HAS_RESULT;\n    }\n\n    if (callback) {\n        ctx->client->auth_callback = callback;\n        ctx->client->auth_callback_privdata = privdata;\n        ctx->client->auth_module = ctx->module;\n    }\n\n    if (client_id) {\n        *client_id = ctx->client->id;\n    }\n\n    return REDISMODULE_OK;\n}\n\n\n/* Authenticate the current context's user with the provided redis acl user.\n * Returns REDISMODULE_ERR if the user is disabled.\n *\n * See authenticateClientWithUser for information about callback, client_id,\n * and general usage for authentication. */\nint RM_AuthenticateClientWithUser(RedisModuleCtx *ctx, RedisModuleUser *module_user, RedisModuleUserChangedFunc callback, void *privdata, uint64_t *client_id) {\n    return authenticateClientWithUser(ctx, module_user->user, callback, privdata, client_id);\n}\n\n/* Authenticate the current context's user with the provided redis acl user.\n * Returns REDISMODULE_ERR if the user is disabled or the user does not exist.\n *\n * See authenticateClientWithUser for information about callback, client_id,\n * and general usage for authentication. */\nint RM_AuthenticateClientWithACLUser(RedisModuleCtx *ctx, const char *name, size_t len, RedisModuleUserChangedFunc callback, void *privdata, uint64_t *client_id) {\n    user *acl_user = ACLGetUserByName(name, len);\n\n    if (!acl_user) {\n        return REDISMODULE_ERR;\n    }\n    return authenticateClientWithUser(ctx, acl_user, callback, privdata, client_id);\n}\n\n/* Deauthenticate and close the client. The client resources will not be\n * immediately freed, but will be cleaned up in a background job. This is\n * the recommended way to deauthenticate a client since most clients can't\n * handle users becoming deauthenticated. Returns REDISMODULE_ERR when the\n * client doesn't exist and REDISMODULE_OK when the operation was successful.\n *\n * The client ID is returned from the RM_AuthenticateClientWithUser and\n * RM_AuthenticateClientWithACLUser APIs, but can be obtained through\n * the CLIENT api or through server events.\n *\n * This function is not thread safe, and must be executed within the context\n * of a command or thread safe context. */\nint RM_DeauthenticateAndCloseClient(RedisModuleCtx *ctx, uint64_t client_id) {\n    UNUSED(ctx);\n    client *c = lookupClientByID(client_id);\n    if (c == NULL) return REDISMODULE_ERR;\n\n    /* Revoke also marks client to be closed ASAP */\n    revokeClientAuthentication(c);\n    return REDISMODULE_OK;\n}\n\n/* Redact the client command argument specified at the given position. Redacted arguments \n * are obfuscated in user facing commands such as SLOWLOG or MONITOR, as well as\n * never being written to server logs. This command may be called multiple times on the\n * same position.\n * \n * Note that the command name, position 0, can not be redacted. \n * \n * Returns REDISMODULE_OK if the argument was redacted and REDISMODULE_ERR if there \n * was an invalid parameter passed in or the position is outside the client \n * argument range. */\nint RM_RedactClientCommandArgument(RedisModuleCtx *ctx, int pos) {\n    if (!ctx || !ctx->client || pos <= 0 || ctx->client->argc <= pos) {\n        return REDISMODULE_ERR;\n    }\n    redactClientCommandArgument(ctx->client, pos);\n    return REDISMODULE_OK;\n}\n\n/* Return the X.509 client-side certificate used by the client to authenticate\n * this connection.\n *\n * The return value is an allocated RedisModuleString that is a X.509 certificate\n * encoded in PEM (Base64) format. It should be freed (or auto-freed) by the caller.\n *\n * A NULL value is returned in the following conditions:\n *\n * - Connection ID does not exist\n * - Connection is not a TLS connection\n * - Connection is a TLS connection but no client certificate was used\n */\nRedisModuleString *RM_GetClientCertificate(RedisModuleCtx *ctx, uint64_t client_id) {\n    client *c = lookupClientByID(client_id);\n    if (c == NULL) return NULL;\n\n    sds cert = connGetPeerCert(c->conn);\n    if (!cert) return NULL;\n\n    RedisModuleString *s = createObject(OBJ_STRING, cert);\n    if (ctx != NULL) autoMemoryAdd(ctx, REDISMODULE_AM_STRING, s);\n\n    return s;\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules Dictionary API\n *\n * Implements a sorted dictionary (actually backed by a radix tree) with\n * the usual get / set / del / num-items API, together with an iterator\n * capable of going back and forth.\n * -------------------------------------------------------------------------- */\n\n/* Create a new dictionary. The 'ctx' pointer can be the current module context\n * or NULL, depending on what you want. Please follow the following rules:\n *\n * 1. Use a NULL context if you plan to retain a reference to this dictionary\n *    that will survive the time of the module callback where you created it.\n * 2. Use a NULL context if no context is available at the time you are creating\n *    the dictionary (of course...).\n * 3. However use the current callback context as 'ctx' argument if the\n *    dictionary time to live is just limited to the callback scope. In this\n *    case, if enabled, you can enjoy the automatic memory management that will\n *    reclaim the dictionary memory, as well as the strings returned by the\n *    Next / Prev dictionary iterator calls.\n */\nRedisModuleDict *RM_CreateDict(RedisModuleCtx *ctx) {\n    struct RedisModuleDict *d = zmalloc(sizeof(*d));\n    d->rax = raxNew();\n    if (ctx != NULL) autoMemoryAdd(ctx,REDISMODULE_AM_DICT,d);\n    return d;\n}\n\n/* Free a dictionary created with RM_CreateDict(). You need to pass the\n * context pointer 'ctx' only if the dictionary was created using the\n * context instead of passing NULL. */\nvoid RM_FreeDict(RedisModuleCtx *ctx, RedisModuleDict *d) {\n    if (ctx != NULL) autoMemoryFreed(ctx,REDISMODULE_AM_DICT,d);\n    raxFree(d->rax);\n    zfree(d);\n}\n\n/* Return the size of the dictionary (number of keys). */\nuint64_t RM_DictSize(RedisModuleDict *d) {\n    return raxSize(d->rax);\n}\n\n/* Store the specified key into the dictionary, setting its value to the\n * pointer 'ptr'. If the key was added with success, since it did not\n * already exist, REDISMODULE_OK is returned. Otherwise if the key already\n * exists the function returns REDISMODULE_ERR. */\nint RM_DictSetC(RedisModuleDict *d, void *key, size_t keylen, void *ptr) {\n    int retval = raxTryInsert(d->rax,key,keylen,ptr,NULL);\n    return (retval == 1) ? REDISMODULE_OK : REDISMODULE_ERR;\n}\n\n/* Like RedisModule_DictSetC() but will replace the key with the new\n * value if the key already exists. */\nint RM_DictReplaceC(RedisModuleDict *d, void *key, size_t keylen, void *ptr) {\n    int retval = raxInsert(d->rax,key,keylen,ptr,NULL);\n    return (retval == 1) ? REDISMODULE_OK : REDISMODULE_ERR;\n}\n\n/* Like RedisModule_DictSetC() but takes the key as a RedisModuleString. */\nint RM_DictSet(RedisModuleDict *d, RedisModuleString *key, void *ptr) {\n    return RM_DictSetC(d,key->ptr,sdslen(key->ptr),ptr);\n}\n\n/* Like RedisModule_DictReplaceC() but takes the key as a RedisModuleString. */\nint RM_DictReplace(RedisModuleDict *d, RedisModuleString *key, void *ptr) {\n    return RM_DictReplaceC(d,key->ptr,sdslen(key->ptr),ptr);\n}\n\n/* Return the value stored at the specified key. The function returns NULL\n * both in the case the key does not exist, or if you actually stored\n * NULL at key. So, optionally, if the 'nokey' pointer is not NULL, it will\n * be set by reference to 1 if the key does not exist, or to 0 if the key\n * exists. */\nvoid *RM_DictGetC(RedisModuleDict *d, void *key, size_t keylen, int *nokey) {\n    void *res = NULL;\n    int found = raxFind(d->rax,key,keylen,&res);\n    if (nokey) *nokey = !found;\n    return res;\n}\n\n/* Like RedisModule_DictGetC() but takes the key as a RedisModuleString. */\nvoid *RM_DictGet(RedisModuleDict *d, RedisModuleString *key, int *nokey) {\n    return RM_DictGetC(d,key->ptr,sdslen(key->ptr),nokey);\n}\n\n/* Remove the specified key from the dictionary, returning REDISMODULE_OK if\n * the key was found and deleted, or REDISMODULE_ERR if instead there was\n * no such key in the dictionary. When the operation is successful, if\n * 'oldval' is not NULL, then '*oldval' is set to the value stored at the\n * key before it was deleted. Using this feature it is possible to get\n * a pointer to the value (for instance in order to release it), without\n * having to call RedisModule_DictGet() before deleting the key. */\nint RM_DictDelC(RedisModuleDict *d, void *key, size_t keylen, void *oldval) {\n    int retval = raxRemove(d->rax,key,keylen,oldval);\n    return retval ? REDISMODULE_OK : REDISMODULE_ERR;\n}\n\n/* Like RedisModule_DictDelC() but gets the key as a RedisModuleString. */\nint RM_DictDel(RedisModuleDict *d, RedisModuleString *key, void *oldval) {\n    return RM_DictDelC(d,key->ptr,sdslen(key->ptr),oldval);\n}\n\n/* Return an iterator, setup in order to start iterating from the specified\n * key by applying the operator 'op', which is just a string specifying the\n * comparison operator to use in order to seek the first element. The\n * operators available are:\n *\n * * `^`   -- Seek the first (lexicographically smaller) key.\n * * `$`   -- Seek the last  (lexicographically bigger) key.\n * * `>`   -- Seek the first element greater than the specified key.\n * * `>=`  -- Seek the first element greater or equal than the specified key.\n * * `<`   -- Seek the first element smaller than the specified key.\n * * `<=`  -- Seek the first element smaller or equal than the specified key.\n * * `==`  -- Seek the first element matching exactly the specified key.\n *\n * Note that for `^` and `$` the passed key is not used, and the user may\n * just pass NULL with a length of 0.\n *\n * If the element to start the iteration cannot be seeked based on the\n * key and operator passed, RedisModule_DictNext() / Prev() will just return\n * REDISMODULE_ERR at the first call, otherwise they'll produce elements.\n */\nRedisModuleDictIter *RM_DictIteratorStartC(RedisModuleDict *d, const char *op, void *key, size_t keylen) {\n    RedisModuleDictIter *di = zmalloc(sizeof(*di));\n    di->dict = d;\n    raxStart(&di->ri,d->rax);\n    raxSeek(&di->ri,op,key,keylen);\n    return di;\n}\n\n/* Exactly like RedisModule_DictIteratorStartC, but the key is passed as a\n * RedisModuleString. */\nRedisModuleDictIter *RM_DictIteratorStart(RedisModuleDict *d, const char *op, RedisModuleString *key) {\n    return RM_DictIteratorStartC(d,op,key->ptr,sdslen(key->ptr));\n}\n\n/* Release the iterator created with RedisModule_DictIteratorStart(). This call\n * is mandatory otherwise a memory leak is introduced in the module. */\nvoid RM_DictIteratorStop(RedisModuleDictIter *di) {\n    raxStop(&di->ri);\n    zfree(di);\n}\n\n/* After its creation with RedisModule_DictIteratorStart(), it is possible to\n * change the currently selected element of the iterator by using this\n * API call. The result based on the operator and key is exactly like\n * the function RedisModule_DictIteratorStart(), however in this case the\n * return value is just REDISMODULE_OK in case the seeked element was found,\n * or REDISMODULE_ERR in case it was not possible to seek the specified\n * element. It is possible to reseek an iterator as many times as you want. */\nint RM_DictIteratorReseekC(RedisModuleDictIter *di, const char *op, void *key, size_t keylen) {\n    return raxSeek(&di->ri,op,key,keylen);\n}\n\n/* Like RedisModule_DictIteratorReseekC() but takes the key as a\n * RedisModuleString. */\nint RM_DictIteratorReseek(RedisModuleDictIter *di, const char *op, RedisModuleString *key) {\n    return RM_DictIteratorReseekC(di,op,key->ptr,sdslen(key->ptr));\n}\n\n/* Return the current item of the dictionary iterator `di` and steps to the\n * next element. If the iterator already yield the last element and there\n * are no other elements to return, NULL is returned, otherwise a pointer\n * to a string representing the key is provided, and the `*keylen` length\n * is set by reference (if keylen is not NULL). The `*dataptr`, if not NULL\n * is set to the value of the pointer stored at the returned key as auxiliary\n * data (as set by the RedisModule_DictSet API).\n *\n * Usage example:\n *\n *      ... create the iterator here ...\n *      char *key;\n *      void *data;\n *      while((key = RedisModule_DictNextC(iter,&keylen,&data)) != NULL) {\n *          printf(\"%.*s %p\\n\", (int)keylen, key, data);\n *      }\n *\n * The returned pointer is of type void because sometimes it makes sense\n * to cast it to a `char*` sometimes to an unsigned `char*` depending on the\n * fact it contains or not binary data, so this API ends being more\n * comfortable to use.\n *\n * The validity of the returned pointer is until the next call to the\n * next/prev iterator step. Also the pointer is no longer valid once the\n * iterator is released. */\nvoid *RM_DictNextC(RedisModuleDictIter *di, size_t *keylen, void **dataptr) {\n    if (!raxNext(&di->ri)) return NULL;\n    if (keylen) *keylen = di->ri.key_len;\n    if (dataptr) *dataptr = di->ri.data;\n    return di->ri.key;\n}\n\n/* This function is exactly like RedisModule_DictNext() but after returning\n * the currently selected element in the iterator, it selects the previous\n * element (lexicographically smaller) instead of the next one. */\nvoid *RM_DictPrevC(RedisModuleDictIter *di, size_t *keylen, void **dataptr) {\n    if (!raxPrev(&di->ri)) return NULL;\n    if (keylen) *keylen = di->ri.key_len;\n    if (dataptr) *dataptr = di->ri.data;\n    return di->ri.key;\n}\n\n/* Like RedisModuleNextC(), but instead of returning an internally allocated\n * buffer and key length, it returns directly a module string object allocated\n * in the specified context 'ctx' (that may be NULL exactly like for the main\n * API RedisModule_CreateString).\n *\n * The returned string object should be deallocated after use, either manually\n * or by using a context that has automatic memory management active. */\nRedisModuleString *RM_DictNext(RedisModuleCtx *ctx, RedisModuleDictIter *di, void **dataptr) {\n    size_t keylen;\n    void *key = RM_DictNextC(di,&keylen,dataptr);\n    if (key == NULL) return NULL;\n    return RM_CreateString(ctx,key,keylen);\n}\n\n/* Like RedisModule_DictNext() but after returning the currently selected\n * element in the iterator, it selects the previous element (lexicographically\n * smaller) instead of the next one. */\nRedisModuleString *RM_DictPrev(RedisModuleCtx *ctx, RedisModuleDictIter *di, void **dataptr) {\n    size_t keylen;\n    void *key = RM_DictPrevC(di,&keylen,dataptr);\n    if (key == NULL) return NULL;\n    return RM_CreateString(ctx,key,keylen);\n}\n\n/* Compare the element currently pointed by the iterator to the specified\n * element given by key/keylen, according to the operator 'op' (the set of\n * valid operators are the same valid for RedisModule_DictIteratorStart).\n * If the comparison is successful the command returns REDISMODULE_OK\n * otherwise REDISMODULE_ERR is returned.\n *\n * This is useful when we want to just emit a lexicographical range, so\n * in the loop, as we iterate elements, we can also check if we are still\n * on range.\n *\n * The function return REDISMODULE_ERR if the iterator reached the\n * end of elements condition as well. */\nint RM_DictCompareC(RedisModuleDictIter *di, const char *op, void *key, size_t keylen) {\n    if (raxEOF(&di->ri)) return REDISMODULE_ERR;\n    int res = raxCompare(&di->ri,op,key,keylen);\n    return res ? REDISMODULE_OK : REDISMODULE_ERR;\n}\n\n/* Like RedisModule_DictCompareC but gets the key to compare with the current\n * iterator key as a RedisModuleString. */\nint RM_DictCompare(RedisModuleDictIter *di, const char *op, RedisModuleString *key) {\n    if (raxEOF(&di->ri)) return REDISMODULE_ERR;\n    int res = raxCompare(&di->ri,op,key->ptr,sdslen(key->ptr));\n    return res ? REDISMODULE_OK : REDISMODULE_ERR;\n}\n\n\n\n\n/* --------------------------------------------------------------------------\n * ## Modules Info fields\n * -------------------------------------------------------------------------- */\n\nint RM_InfoEndDictField(RedisModuleInfoCtx *ctx);\n\n/* Used to start a new section, before adding any fields. the section name will\n * be prefixed by `<modulename>_` and must only include A-Z,a-z,0-9.\n * NULL or empty string indicates the default section (only `<modulename>`) is used.\n * When return value is REDISMODULE_ERR, the section should and will be skipped. */\nint RM_InfoAddSection(RedisModuleInfoCtx *ctx, const char *name) {\n    sds full_name = sdsdup(ctx->module->name);\n    if (name != NULL && strlen(name) > 0)\n        full_name = sdscatfmt(full_name, \"_%s\", name);\n\n    /* Implicitly end dicts, instead of returning an error which is likely un checked. */\n    if (ctx->in_dict_field)\n        RM_InfoEndDictField(ctx);\n\n    /* proceed only if:\n     * 1) no section was requested (emit all)\n     * 2) the module name was requested (emit all)\n     * 3) this specific section was requested. */\n    if (ctx->requested_sections) {\n        if ((!full_name || !dictFind(ctx->requested_sections, full_name)) &&\n            (!dictFind(ctx->requested_sections, ctx->module->name)))\n        {\n            sdsfree(full_name);\n            ctx->in_section = 0;\n            return REDISMODULE_ERR;\n        }\n    }\n    if (ctx->sections++) ctx->info = sdscat(ctx->info,\"\\r\\n\");\n    ctx->info = sdscatfmt(ctx->info, \"# %S\\r\\n\", full_name);\n    ctx->in_section = 1;\n    sdsfree(full_name);\n    return REDISMODULE_OK;\n}\n\n/* Starts a dict field, similar to the ones in INFO KEYSPACE. Use normal\n * RedisModule_InfoAddField* functions to add the items to this field, and\n * terminate with RedisModule_InfoEndDictField. */\nint RM_InfoBeginDictField(RedisModuleInfoCtx *ctx, const char *name) {\n    if (!ctx->in_section)\n        return REDISMODULE_ERR;\n    /* Implicitly end dicts, instead of returning an error which is likely un checked. */\n    if (ctx->in_dict_field)\n        RM_InfoEndDictField(ctx);\n    char *tmpmodname, *tmpname;\n    ctx->info = sdscatfmt(ctx->info,\n        \"%s_%s:\",\n        getSafeInfoString(ctx->module->name, strlen(ctx->module->name), &tmpmodname),\n        getSafeInfoString(name, strlen(name), &tmpname));\n    if (tmpmodname != NULL) zfree(tmpmodname);\n    if (tmpname != NULL) zfree(tmpname);\n    ctx->in_dict_field = 1;\n    return REDISMODULE_OK;\n}\n\n/* Ends a dict field, see RedisModule_InfoBeginDictField */\nint RM_InfoEndDictField(RedisModuleInfoCtx *ctx) {\n    if (!ctx->in_dict_field)\n        return REDISMODULE_ERR;\n    /* trim the last ',' if found. */\n    if (ctx->info[sdslen(ctx->info)-1]==',')\n        sdsIncrLen(ctx->info, -1);\n    ctx->info = sdscat(ctx->info, \"\\r\\n\");\n    ctx->in_dict_field = 0;\n    return REDISMODULE_OK;\n}\n\n/* Used by RedisModuleInfoFunc to add info fields.\n * Each field will be automatically prefixed by `<modulename>_`.\n * Field names or values must not include `\\r\\n` or `:`. */\nint RM_InfoAddFieldString(RedisModuleInfoCtx *ctx, const char *field, RedisModuleString *value) {\n    if (!ctx->in_section)\n        return REDISMODULE_ERR;\n    if (ctx->in_dict_field) {\n        ctx->info = sdscatfmt(ctx->info,\n            \"%s=%S,\",\n            field,\n            (sds)value->ptr);\n        return REDISMODULE_OK;\n    }\n    ctx->info = sdscatfmt(ctx->info,\n        \"%s_%s:%S\\r\\n\",\n        ctx->module->name,\n        field,\n        (sds)value->ptr);\n    return REDISMODULE_OK;\n}\n\n/* See RedisModule_InfoAddFieldString(). */\nint RM_InfoAddFieldCString(RedisModuleInfoCtx *ctx, const char *field, const char *value) {\n    if (!ctx->in_section)\n        return REDISMODULE_ERR;\n    if (ctx->in_dict_field) {\n        ctx->info = sdscatfmt(ctx->info,\n            \"%s=%s,\",\n            field,\n            value);\n        return REDISMODULE_OK;\n    }\n    ctx->info = sdscatfmt(ctx->info,\n        \"%s_%s:%s\\r\\n\",\n        ctx->module->name,\n        field,\n        value);\n    return REDISMODULE_OK;\n}\n\n/* See RedisModule_InfoAddFieldString(). */\nint RM_InfoAddFieldDouble(RedisModuleInfoCtx *ctx, const char *field, double value) {\n    if (!ctx->in_section)\n        return REDISMODULE_ERR;\n    if (ctx->in_dict_field) {\n        ctx->info = sdscatprintf(ctx->info,\n            \"%s=%.17g,\",\n            field,\n            value);\n        return REDISMODULE_OK;\n    }\n    ctx->info = sdscatprintf(ctx->info,\n        \"%s_%s:%.17g\\r\\n\",\n        ctx->module->name,\n        field,\n        value);\n    return REDISMODULE_OK;\n}\n\n/* See RedisModule_InfoAddFieldString(). */\nint RM_InfoAddFieldLongLong(RedisModuleInfoCtx *ctx, const char *field, long long value) {\n    if (!ctx->in_section)\n        return REDISMODULE_ERR;\n    if (ctx->in_dict_field) {\n        ctx->info = sdscatfmt(ctx->info,\n            \"%s=%I,\",\n            field,\n            value);\n        return REDISMODULE_OK;\n    }\n    ctx->info = sdscatfmt(ctx->info,\n        \"%s_%s:%I\\r\\n\",\n        ctx->module->name,\n        field,\n        value);\n    return REDISMODULE_OK;\n}\n\n/* See RedisModule_InfoAddFieldString(). */\nint RM_InfoAddFieldULongLong(RedisModuleInfoCtx *ctx, const char *field, unsigned long long value) {\n    if (!ctx->in_section)\n        return REDISMODULE_ERR;\n    if (ctx->in_dict_field) {\n        ctx->info = sdscatfmt(ctx->info,\n            \"%s=%U,\",\n            field,\n            value);\n        return REDISMODULE_OK;\n    }\n    ctx->info = sdscatfmt(ctx->info,\n        \"%s_%s:%U\\r\\n\",\n        ctx->module->name,\n        field,\n        value);\n    return REDISMODULE_OK;\n}\n\n/* Registers callback for the INFO command. The callback should add INFO fields\n * by calling the `RedisModule_InfoAddField*()` functions. */\nint RM_RegisterInfoFunc(RedisModuleCtx *ctx, RedisModuleInfoFunc cb) {\n    ctx->module->info_cb = cb;\n    return REDISMODULE_OK;\n}\n\nsds modulesCollectInfo(sds info, dict *sections_dict, int for_crash_report, int sections) {\n    dictIterator *di = dictGetIterator(modules);\n    dictEntry *de;\n\n    while ((de = dictNext(di)) != NULL) {\n        struct RedisModule *module = dictGetVal(de);\n        if (!module->info_cb)\n            continue;\n        RedisModuleInfoCtx info_ctx = {module, sections_dict, info, sections, 0, 0};\n        module->info_cb(&info_ctx, for_crash_report);\n        /* Implicitly end dicts (no way to handle errors, and we must add the newline). */\n        if (info_ctx.in_dict_field)\n            RM_InfoEndDictField(&info_ctx);\n        info = info_ctx.info;\n        sections = info_ctx.sections;\n    }\n    dictReleaseIterator(di);\n    return info;\n}\n\n/* Get information about the server similar to the one that returns from the\n * INFO command. This function takes an optional 'section' argument that may\n * be NULL. The return value holds the output and can be used with\n * RedisModule_ServerInfoGetField and alike to get the individual fields.\n * When done, it needs to be freed with RedisModule_FreeServerInfo or with the\n * automatic memory management mechanism if enabled. */\nRedisModuleServerInfoData *RM_GetServerInfo(RedisModuleCtx *ctx, const char *section) {\n    struct RedisModuleServerInfoData *d = zmalloc(sizeof(*d));\n    d->rax = raxNew();\n    if (ctx != NULL) autoMemoryAdd(ctx,REDISMODULE_AM_INFO,d);\n    int all = 0, everything = 0;\n    robj *argv[1];\n    argv[0] = section ? createStringObject(section, strlen(section)) : NULL;\n    dict *section_dict = genInfoSectionDict(argv, section ? 1 : 0, NULL, &all, &everything);\n    sds info = genRedisInfoString(section_dict, all, everything);\n    int totlines, i;\n    sds *lines = sdssplitlen(info, sdslen(info), \"\\r\\n\", 2, &totlines);\n    for(i=0; i<totlines; i++) {\n        sds line = lines[i];\n        if (line[0]=='#') continue;\n        char *sep = strchr(line, ':');\n        if (!sep) continue;\n        unsigned char *key = (unsigned char*)line;\n        size_t keylen = (intptr_t)sep-(intptr_t)line;\n        sds val = sdsnewlen(sep+1,sdslen(line)-((intptr_t)sep-(intptr_t)line)-1);\n        if (!raxTryInsert(d->rax,key,keylen,val,NULL))\n            sdsfree(val);\n    }\n    sdsfree(info);\n    sdsfreesplitres(lines,totlines);\n    releaseInfoSectionDict(section_dict);\n    if(argv[0]) decrRefCount(argv[0]);\n    return d;\n}\n\n/* Free data created with RM_GetServerInfo(). You need to pass the\n * context pointer 'ctx' only if the dictionary was created using the\n * context instead of passing NULL. */\nvoid RM_FreeServerInfo(RedisModuleCtx *ctx, RedisModuleServerInfoData *data) {\n    if (ctx != NULL) autoMemoryFreed(ctx,REDISMODULE_AM_INFO,data);\n    raxFreeWithCallback(data->rax, (void(*)(void*))sdsfree);\n    zfree(data);\n}\n\n/* Get the value of a field from data collected with RM_GetServerInfo(). You\n * need to pass the context pointer 'ctx' only if you want to use auto memory\n * mechanism to release the returned string. Return value will be NULL if the\n * field was not found. */\nRedisModuleString *RM_ServerInfoGetField(RedisModuleCtx *ctx, RedisModuleServerInfoData *data, const char* field) {\n    void *result;\n    if (!raxFind(data->rax, (unsigned char *)field, strlen(field), &result))\n        return NULL;\n    sds val = result;\n    RedisModuleString *o = createStringObject(val,sdslen(val));\n    if (ctx != NULL) autoMemoryAdd(ctx,REDISMODULE_AM_STRING,o);\n    return o;\n}\n\n/* Similar to RM_ServerInfoGetField, but returns a char* which should not be freed but the caller. */\nconst char *RM_ServerInfoGetFieldC(RedisModuleServerInfoData *data, const char* field) {\n    void *result = NULL;\n    raxFind(data->rax, (unsigned char *)field, strlen(field), &result);\n    return result;\n}\n\n/* Get the value of a field from data collected with RM_GetServerInfo(). If the\n * field is not found, or is not numerical or out of range, return value will be\n * 0, and the optional out_err argument will be set to REDISMODULE_ERR. */\nlong long RM_ServerInfoGetFieldSigned(RedisModuleServerInfoData *data, const char* field, int *out_err) {\n    long long ll;\n    void *result;\n    if (!raxFind(data->rax, (unsigned char *)field, strlen(field), &result)) {\n        if (out_err) *out_err = REDISMODULE_ERR;\n        return 0;\n    }\n    sds val = result;\n    if (!string2ll(val,sdslen(val),&ll)) {\n        if (out_err) *out_err = REDISMODULE_ERR;\n        return 0;\n    }\n    if (out_err) *out_err = REDISMODULE_OK;\n    return ll;\n}\n\n/* Get the value of a field from data collected with RM_GetServerInfo(). If the\n * field is not found, or is not numerical or out of range, return value will be\n * 0, and the optional out_err argument will be set to REDISMODULE_ERR. */\nunsigned long long RM_ServerInfoGetFieldUnsigned(RedisModuleServerInfoData *data, const char* field, int *out_err) {\n    unsigned long long ll;\n    void *result;\n    if (!raxFind(data->rax, (unsigned char *)field, strlen(field), &result)) {\n        if (out_err) *out_err = REDISMODULE_ERR;\n        return 0;\n    }\n    sds val = result;\n    if (!string2ull(val,&ll)) {\n        if (out_err) *out_err = REDISMODULE_ERR;\n        return 0;\n    }\n    if (out_err) *out_err = REDISMODULE_OK;\n    return ll;\n}\n\n/* Get the value of a field from data collected with RM_GetServerInfo(). If the\n * field is not found, or is not a double, return value will be 0, and the\n * optional out_err argument will be set to REDISMODULE_ERR. */\ndouble RM_ServerInfoGetFieldDouble(RedisModuleServerInfoData *data, const char* field, int *out_err) {\n    double dbl;\n    void *result;\n    if (!raxFind(data->rax, (unsigned char *)field, strlen(field), &result)) {\n        if (out_err) *out_err = REDISMODULE_ERR;\n        return 0;\n    }\n    sds val = result;\n    if (!string2d(val,sdslen(val),&dbl)) {\n        if (out_err) *out_err = REDISMODULE_ERR;\n        return 0;\n    }\n    if (out_err) *out_err = REDISMODULE_OK;\n    return dbl;\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules utility APIs\n * -------------------------------------------------------------------------- */\n\n/* Return random bytes using SHA1 in counter mode with a /dev/urandom\n * initialized seed. This function is fast so can be used to generate\n * many bytes without any effect on the operating system entropy pool.\n * Currently this function is not thread safe. */\nvoid RM_GetRandomBytes(unsigned char *dst, size_t len) {\n    getRandomBytes(dst,len);\n}\n\n/* Like RedisModule_GetRandomBytes() but instead of setting the string to\n * random bytes the string is set to random characters in the in the\n * hex charset [0-9a-f]. */\nvoid RM_GetRandomHexChars(char *dst, size_t len) {\n    getRandomHexChars(dst,len);\n}\n\n/* --------------------------------------------------------------------------\n * ## Modules API exporting / importing\n * -------------------------------------------------------------------------- */\n\n/* This function is called by a module in order to export some API with a\n * given name. Other modules will be able to use this API by calling the\n * symmetrical function RM_GetSharedAPI() and casting the return value to\n * the right function pointer.\n *\n * The function will return REDISMODULE_OK if the name is not already taken,\n * otherwise REDISMODULE_ERR will be returned and no operation will be\n * performed.\n *\n * IMPORTANT: the apiname argument should be a string literal with static\n * lifetime. The API relies on the fact that it will always be valid in\n * the future. */\nint RM_ExportSharedAPI(RedisModuleCtx *ctx, const char *apiname, void *func) {\n    RedisModuleSharedAPI *sapi = zmalloc(sizeof(*sapi));\n    sapi->module = ctx->module;\n    sapi->func = func;\n    if (dictAdd(server.sharedapi, (char*)apiname, sapi) != DICT_OK) {\n        zfree(sapi);\n        return REDISMODULE_ERR;\n    }\n    return REDISMODULE_OK;\n}\n\n/* Request an exported API pointer. The return value is just a void pointer\n * that the caller of this function will be required to cast to the right\n * function pointer, so this is a private contract between modules.\n *\n * If the requested API is not available then NULL is returned. Because\n * modules can be loaded at different times with different order, this\n * function calls should be put inside some module generic API registering\n * step, that is called every time a module attempts to execute a\n * command that requires external APIs: if some API cannot be resolved, the\n * command should return an error.\n *\n * Here is an example:\n *\n *     int ... myCommandImplementation(void) {\n *        if (getExternalAPIs() == 0) {\n *             reply with an error here if we cannot have the APIs\n *        }\n *        // Use the API:\n *        myFunctionPointer(foo);\n *     }\n *\n * And the function registerAPI() is:\n *\n *     int getExternalAPIs(void) {\n *         static int api_loaded = 0;\n *         if (api_loaded != 0) return 1; // APIs already resolved.\n *\n *         myFunctionPointer = RedisModule_GetSharedAPI(\"...\");\n *         if (myFunctionPointer == NULL) return 0;\n *\n *         return 1;\n *     }\n */\nvoid *RM_GetSharedAPI(RedisModuleCtx *ctx, const char *apiname) {\n    dictEntry *de = dictFind(server.sharedapi, apiname);\n    if (de == NULL) return NULL;\n    RedisModuleSharedAPI *sapi = dictGetVal(de);\n    if (listSearchKey(sapi->module->usedby,ctx->module) == NULL) {\n        listAddNodeTail(sapi->module->usedby,ctx->module);\n        listAddNodeTail(ctx->module->using,sapi->module);\n    }\n    return sapi->func;\n}\n\n/* Remove all the APIs registered by the specified module. Usually you\n * want this when the module is going to be unloaded. This function\n * assumes that's caller responsibility to make sure the APIs are not\n * used by other modules.\n *\n * The number of unregistered APIs is returned. */\nint moduleUnregisterSharedAPI(RedisModule *module) {\n    int count = 0;\n    dictIterator *di = dictGetSafeIterator(server.sharedapi);\n    dictEntry *de;\n    while ((de = dictNext(di)) != NULL) {\n        const char *apiname = dictGetKey(de);\n        RedisModuleSharedAPI *sapi = dictGetVal(de);\n        if (sapi->module == module) {\n            dictDelete(server.sharedapi,apiname);\n            zfree(sapi);\n            count++;\n        }\n    }\n    dictReleaseIterator(di);\n    return count;\n}\n\n/* Remove the specified module as an user of APIs of ever other module.\n * This is usually called when a module is unloaded.\n *\n * Returns the number of modules this module was using APIs from. */\nint moduleUnregisterUsedAPI(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    int count = 0;\n\n    listRewind(module->using,&li);\n    while((ln = listNext(&li))) {\n        RedisModule *used = ln->value;\n        listNode *ln = listSearchKey(used->usedby,module);\n        if (ln) {\n            listDelNode(used->usedby,ln);\n            count++;\n        }\n    }\n    return count;\n}\n\n/* Unregister all filters registered by a module.\n * This is called when a module is being unloaded.\n *\n * Returns the number of filters unregistered. */\nint moduleUnregisterFilters(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    int count = 0;\n\n    listRewind(module->filters,&li);\n    while((ln = listNext(&li))) {\n        RedisModuleCommandFilter *filter = ln->value;\n        listNode *ln = listSearchKey(moduleCommandFilters,filter);\n        if (ln) {\n            listDelNode(moduleCommandFilters,ln);\n            count++;\n        }\n        zfree(filter);\n    }\n    return count;\n}\n\n/* --------------------------------------------------------------------------\n * ## Module Command Filter API\n * -------------------------------------------------------------------------- */\n\n/* Register a new command filter function.\n *\n * Command filtering makes it possible for modules to extend Redis by plugging\n * into the execution flow of all commands.\n *\n * A registered filter gets called before Redis executes *any* command.  This\n * includes both core Redis commands and commands registered by any module.  The\n * filter applies in all execution paths including:\n *\n * 1. Invocation by a client.\n * 2. Invocation through `RedisModule_Call()` by any module.\n * 3. Invocation through Lua `redis.call()`.\n * 4. Replication of a command from a master.\n *\n * The filter executes in a special filter context, which is different and more\n * limited than a RedisModuleCtx.  Because the filter affects any command, it\n * must be implemented in a very efficient way to reduce the performance impact\n * on Redis.  All Redis Module API calls that require a valid context (such as\n * `RedisModule_Call()`, `RedisModule_OpenKey()`, etc.) are not supported in a\n * filter context.\n *\n * The `RedisModuleCommandFilterCtx` can be used to inspect or modify the\n * executed command and its arguments.  As the filter executes before Redis\n * begins processing the command, any change will affect the way the command is\n * processed.  For example, a module can override Redis commands this way:\n *\n * 1. Register a `MODULE.SET` command which implements an extended version of\n *    the Redis `SET` command.\n * 2. Register a command filter which detects invocation of `SET` on a specific\n *    pattern of keys.  Once detected, the filter will replace the first\n *    argument from `SET` to `MODULE.SET`.\n * 3. When filter execution is complete, Redis considers the new command name\n *    and therefore executes the module's own command.\n *\n * Note that in the above use case, if `MODULE.SET` itself uses\n * `RedisModule_Call()` the filter will be applied on that call as well.  If\n * that is not desired, the `REDISMODULE_CMDFILTER_NOSELF` flag can be set when\n * registering the filter.\n *\n * The `REDISMODULE_CMDFILTER_NOSELF` flag prevents execution flows that\n * originate from the module's own `RM_Call()` from reaching the filter.  This\n * flag is effective for all execution flows, including nested ones, as long as\n * the execution begins from the module's command context or a thread-safe\n * context that is associated with a blocking command.\n *\n * Detached thread-safe contexts are *not* associated with the module and cannot\n * be protected by this flag.\n *\n * If multiple filters are registered (by the same or different modules), they\n * are executed in the order of registration.\n */\nRedisModuleCommandFilter *RM_RegisterCommandFilter(RedisModuleCtx *ctx, RedisModuleCommandFilterFunc callback, int flags) {\n    RedisModuleCommandFilter *filter = zmalloc(sizeof(*filter));\n    filter->module = ctx->module;\n    filter->callback = callback;\n    filter->flags = flags;\n\n    listAddNodeTail(moduleCommandFilters, filter);\n    listAddNodeTail(ctx->module->filters, filter);\n    return filter;\n}\n\n/* Unregister a command filter.\n */\nint RM_UnregisterCommandFilter(RedisModuleCtx *ctx, RedisModuleCommandFilter *filter) {\n    listNode *ln;\n\n    /* A module can only remove its own filters */\n    if (filter->module != ctx->module) return REDISMODULE_ERR;\n\n    ln = listSearchKey(moduleCommandFilters,filter);\n    if (!ln) return REDISMODULE_ERR;\n    listDelNode(moduleCommandFilters,ln);\n\n    ln = listSearchKey(ctx->module->filters,filter);\n    if (!ln) return REDISMODULE_ERR;    /* Shouldn't happen */\n    listDelNode(ctx->module->filters,ln);\n\n    zfree(filter);\n\n    return REDISMODULE_OK;\n}\n\nvoid moduleCallCommandFilters(client *c) {\n    if (listLength(moduleCommandFilters) == 0) return;\n\n    listIter li;\n    listNode *ln;\n    listRewind(moduleCommandFilters,&li);\n\n    RedisModuleCommandFilterCtx filter = {\n        .argv = c->argv,\n        .argv_len = c->argv_len,\n        .argc = c->argc,\n        .c = c\n    };\n\n    while((ln = listNext(&li))) {\n        RedisModuleCommandFilter *f = ln->value;\n\n        /* Skip filter if REDISMODULE_CMDFILTER_NOSELF is set and module is\n         * currently processing a command.\n         */\n        if ((f->flags & REDISMODULE_CMDFILTER_NOSELF) && f->module->in_call) continue;\n\n        /* Call filter */\n        f->callback(&filter);\n    }\n\n    c->argv = filter.argv;\n    c->argv_len = filter.argv_len;\n    c->argc = filter.argc;\n}\n\n/* Return the number of arguments a filtered command has.  The number of\n * arguments include the command itself.\n */\nint RM_CommandFilterArgsCount(RedisModuleCommandFilterCtx *fctx)\n{\n    return fctx->argc;\n}\n\n/* Return the specified command argument.  The first argument (position 0) is\n * the command itself, and the rest are user-provided args.\n */\nRedisModuleString *RM_CommandFilterArgGet(RedisModuleCommandFilterCtx *fctx, int pos)\n{\n    if (pos < 0 || pos >= fctx->argc) return NULL;\n    return fctx->argv[pos];\n}\n\n/* Modify the filtered command by inserting a new argument at the specified\n * position.  The specified RedisModuleString argument may be used by Redis\n * after the filter context is destroyed, so it must not be auto-memory\n * allocated, freed or used elsewhere.\n */\nint RM_CommandFilterArgInsert(RedisModuleCommandFilterCtx *fctx, int pos, RedisModuleString *arg)\n{\n    int i;\n\n    if (pos < 0 || pos > fctx->argc) return REDISMODULE_ERR;\n\n    if (fctx->argv_len < fctx->argc+1) {\n        fctx->argv_len = fctx->argc+1;\n        fctx->argv = zrealloc(fctx->argv, fctx->argv_len*sizeof(RedisModuleString *));\n    }\n    for (i = fctx->argc; i > pos; i--) {\n        fctx->argv[i] = fctx->argv[i-1];\n    }\n    fctx->argv[pos] = arg;\n    fctx->argc++;\n\n    return REDISMODULE_OK;\n}\n\n/* Modify the filtered command by replacing an existing argument with a new one.\n * The specified RedisModuleString argument may be used by Redis after the\n * filter context is destroyed, so it must not be auto-memory allocated, freed\n * or used elsewhere.\n */\nint RM_CommandFilterArgReplace(RedisModuleCommandFilterCtx *fctx, int pos, RedisModuleString *arg)\n{\n    if (pos < 0 || pos >= fctx->argc) return REDISMODULE_ERR;\n\n    decrRefCount(fctx->argv[pos]);\n    fctx->argv[pos] = arg;\n\n    return REDISMODULE_OK;\n}\n\n/* Modify the filtered command by deleting an argument at the specified\n * position.\n */\nint RM_CommandFilterArgDelete(RedisModuleCommandFilterCtx *fctx, int pos)\n{\n    int i;\n    if (pos < 0 || pos >= fctx->argc) return REDISMODULE_ERR;\n\n    decrRefCount(fctx->argv[pos]);\n    for (i = pos; i < fctx->argc-1; i++) {\n        fctx->argv[i] = fctx->argv[i+1];\n    }\n    fctx->argc--;\n\n    return REDISMODULE_OK;\n}\n\n/* Get Client ID for client that issued the command we are filtering */\nunsigned long long RM_CommandFilterGetClientId(RedisModuleCommandFilterCtx *fctx) {\n    return fctx->c->id;\n}\n\n/* For a given pointer allocated via RedisModule_Alloc() or\n * RedisModule_Realloc(), return the amount of memory allocated for it.\n * Note that this may be different (larger) than the memory we allocated\n * with the allocation calls, since sometimes the underlying allocator\n * will allocate more memory.\n */\nsize_t RM_MallocSize(void* ptr) {\n    return zmalloc_size(ptr);\n}\n\n/* Similar to RM_MallocSize, the difference is that RM_MallocUsableSize\n * returns the usable size of memory by the module. */\nsize_t RM_MallocUsableSize(void *ptr) {\n    /* It is safe to use 'zmalloc_usable_size()' to manipulate additional\n     * memory space, as we guarantee that the compiler can recognize this\n     * after 'RM_Alloc', 'RM_TryAlloc', 'RM_Realloc', or 'RM_Calloc'. */\n    return zmalloc_usable_size(ptr);\n}\n\n/* Same as RM_MallocSize, except it works on RedisModuleString pointers.\n */\nsize_t RM_MallocSizeString(RedisModuleString* str) {\n    serverAssert(str->type == OBJ_STRING);\n    return sizeof(*str) + getStringObjectSdsUsedMemory(str);\n}\n\n/* Same as RM_MallocSize, except it works on RedisModuleDict pointers.\n * Note that the returned value is only the overhead of the underlying structures,\n * it does not include the allocation size of the keys and values.\n */\nsize_t RM_MallocSizeDict(RedisModuleDict* dict) {\n    size_t size = sizeof(RedisModuleDict) + sizeof(rax);\n    size += dict->rax->numnodes * sizeof(raxNode);\n    /* For more info about this weird line, see streamRadixTreeMemoryUsage */\n    size += dict->rax->numnodes * sizeof(long)*30;\n    return size;\n}\n\n/* Return the a number between 0 to 1 indicating the amount of memory\n * currently used, relative to the Redis \"maxmemory\" configuration.\n *\n * * 0 - No memory limit configured.\n * * Between 0 and 1 - The percentage of the memory used normalized in 0-1 range.\n * * Exactly 1 - Memory limit reached.\n * * Greater 1 - More memory used than the configured limit.\n */\nfloat RM_GetUsedMemoryRatio(void){\n    float level;\n    getMaxmemoryState(NULL, NULL, NULL, &level);\n    return level;\n}\n\n/* --------------------------------------------------------------------------\n * ## Scanning keyspace and hashes\n * -------------------------------------------------------------------------- */\n\ntypedef void (*RedisModuleScanCB)(RedisModuleCtx *ctx, RedisModuleString *keyname, RedisModuleKey *key, void *privdata);\ntypedef struct {\n    RedisModuleCtx *ctx;\n    void* user_data;\n    RedisModuleScanCB fn;\n} ScanCBData;\n\ntypedef struct RedisModuleScanCursor{\n    unsigned long long cursor;\n    int done;\n}RedisModuleScanCursor;\n\nstatic void moduleScanCallback(void *privdata, const dictEntry *de) {\n    ScanCBData *data = privdata;\n    sds key = dictGetKey(de);\n    robj* val = dictGetVal(de);\n    RedisModuleString *keyname = createObject(OBJ_STRING,sdsdup(key));\n\n    /* Setup the key handle. */\n    RedisModuleKey kp = {0};\n    moduleInitKey(&kp, data->ctx, keyname, val, REDISMODULE_READ);\n\n    data->fn(data->ctx, keyname, &kp, data->user_data);\n\n    moduleCloseKey(&kp);\n    decrRefCount(keyname);\n}\n\n/* Create a new cursor to be used with RedisModule_Scan */\nRedisModuleScanCursor *RM_ScanCursorCreate(void) {\n    RedisModuleScanCursor* cursor = zmalloc(sizeof(*cursor));\n    cursor->cursor = 0;\n    cursor->done = 0;\n    return cursor;\n}\n\n/* Restart an existing cursor. The keys will be rescanned. */\nvoid RM_ScanCursorRestart(RedisModuleScanCursor *cursor) {\n    cursor->cursor = 0;\n    cursor->done = 0;\n}\n\n/* Destroy the cursor struct. */\nvoid RM_ScanCursorDestroy(RedisModuleScanCursor *cursor) {\n    zfree(cursor);\n}\n\n/* Scan API that allows a module to scan all the keys and value in\n * the selected db.\n *\n * Callback for scan implementation.\n *\n *     void scan_callback(RedisModuleCtx *ctx, RedisModuleString *keyname,\n *                        RedisModuleKey *key, void *privdata);\n *\n * - `ctx`: the redis module context provided to for the scan.\n * - `keyname`: owned by the caller and need to be retained if used after this\n *   function.\n * - `key`: holds info on the key and value, it is provided as best effort, in\n *   some cases it might be NULL, in which case the user should (can) use\n *   RedisModule_OpenKey() (and CloseKey too).\n *   when it is provided, it is owned by the caller and will be free when the\n *   callback returns.\n * - `privdata`: the user data provided to RedisModule_Scan().\n *\n * The way it should be used:\n *\n *      RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n *      while(RedisModule_Scan(ctx, c, callback, privateData));\n *      RedisModule_ScanCursorDestroy(c);\n *\n * It is also possible to use this API from another thread while the lock\n * is acquired during the actual call to RM_Scan:\n *\n *      RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n *      RedisModule_ThreadSafeContextLock(ctx);\n *      while(RedisModule_Scan(ctx, c, callback, privateData)){\n *          RedisModule_ThreadSafeContextUnlock(ctx);\n *          // do some background job\n *          RedisModule_ThreadSafeContextLock(ctx);\n *      }\n *      RedisModule_ScanCursorDestroy(c);\n *\n * The function will return 1 if there are more elements to scan and\n * 0 otherwise, possibly setting errno if the call failed.\n *\n * It is also possible to restart an existing cursor using RM_ScanCursorRestart.\n *\n * IMPORTANT: This API is very similar to the Redis SCAN command from the\n * point of view of the guarantees it provides. This means that the API\n * may report duplicated keys, but guarantees to report at least one time\n * every key that was there from the start to the end of the scanning process.\n *\n * NOTE: If you do database changes within the callback, you should be aware\n * that the internal state of the database may change. For instance it is safe\n * to delete or modify the current key, but may not be safe to delete any\n * other key.\n * Moreover playing with the Redis keyspace while iterating may have the\n * effect of returning more duplicates. A safe pattern is to store the keys\n * names you want to modify elsewhere, and perform the actions on the keys\n * later when the iteration is complete. However this can cost a lot of\n * memory, so it may make sense to just operate on the current key when\n * possible during the iteration, given that this is safe. */\nint RM_Scan(RedisModuleCtx *ctx, RedisModuleScanCursor *cursor, RedisModuleScanCB fn, void *privdata) {\n    if (cursor->done) {\n        errno = ENOENT;\n        return 0;\n    }\n    int ret = 1;\n    ScanCBData data = { ctx, privdata, fn };\n    cursor->cursor = dbScan(ctx->client->db, cursor->cursor, moduleScanCallback, &data);\n    if (cursor->cursor == 0) {\n        cursor->done = 1;\n        ret = 0;\n    }\n    errno = 0;\n    return ret;\n}\n\ntypedef void (*RedisModuleScanKeyCB)(RedisModuleKey *key, RedisModuleString *field, RedisModuleString *value, void *privdata);\ntypedef struct {\n    RedisModuleKey *key;\n    void* user_data;\n    RedisModuleScanKeyCB fn;\n} ScanKeyCBData;\n\nstatic void moduleScanKeyCallback(void *privdata, const dictEntry *de) {\n    ScanKeyCBData *data = privdata;\n    sds key = dictGetKey(de);\n    robj *o = data->key->value;\n    robj *field = createStringObject(key, sdslen(key));\n    robj *value = NULL;\n    if (o->type == OBJ_SET) {\n        value = NULL;\n    } else if (o->type == OBJ_HASH) {\n        sds val = dictGetVal(de);\n        value = createStringObject(val, sdslen(val));\n    } else if (o->type == OBJ_ZSET) {\n        double *val = (double*)dictGetVal(de);\n        value = createStringObjectFromLongDouble(*val, 0);\n    }\n\n    data->fn(data->key, field, value, data->user_data);\n    decrRefCount(field);\n    if (value) decrRefCount(value);\n}\n\n/* Scan api that allows a module to scan the elements in a hash, set or sorted set key\n *\n * Callback for scan implementation.\n *\n *     void scan_callback(RedisModuleKey *key, RedisModuleString* field, RedisModuleString* value, void *privdata);\n *\n * - key - the redis key context provided to for the scan.\n * - field - field name, owned by the caller and need to be retained if used\n *   after this function.\n * - value - value string or NULL for set type, owned by the caller and need to\n *   be retained if used after this function.\n * - privdata - the user data provided to RedisModule_ScanKey.\n *\n * The way it should be used:\n *\n *      RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n *      RedisModuleKey *key = RedisModule_OpenKey(...)\n *      while(RedisModule_ScanKey(key, c, callback, privateData));\n *      RedisModule_CloseKey(key);\n *      RedisModule_ScanCursorDestroy(c);\n *\n * It is also possible to use this API from another thread while the lock is acquired during\n * the actual call to RM_ScanKey, and re-opening the key each time:\n *\n *      RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n *      RedisModule_ThreadSafeContextLock(ctx);\n *      RedisModuleKey *key = RedisModule_OpenKey(...)\n *      while(RedisModule_ScanKey(ctx, c, callback, privateData)){\n *          RedisModule_CloseKey(key);\n *          RedisModule_ThreadSafeContextUnlock(ctx);\n *          // do some background job\n *          RedisModule_ThreadSafeContextLock(ctx);\n *          RedisModuleKey *key = RedisModule_OpenKey(...)\n *      }\n *      RedisModule_CloseKey(key);\n *      RedisModule_ScanCursorDestroy(c);\n *\n * The function will return 1 if there are more elements to scan and 0 otherwise,\n * possibly setting errno if the call failed.\n * It is also possible to restart an existing cursor using RM_ScanCursorRestart.\n *\n * NOTE: Certain operations are unsafe while iterating the object. For instance\n * while the API guarantees to return at least one time all the elements that\n * are present in the data structure consistently from the start to the end\n * of the iteration (see HSCAN and similar commands documentation), the more\n * you play with the elements, the more duplicates you may get. In general\n * deleting the current element of the data structure is safe, while removing\n * the key you are iterating is not safe. */\nint RM_ScanKey(RedisModuleKey *key, RedisModuleScanCursor *cursor, RedisModuleScanKeyCB fn, void *privdata) {\n    if (key == NULL || key->value == NULL) {\n        errno = EINVAL;\n        return 0;\n    }\n    dict *ht = NULL;\n    robj *o = key->value;\n    if (o->type == OBJ_SET) {\n        if (o->encoding == OBJ_ENCODING_HT)\n            ht = o->ptr;\n    } else if (o->type == OBJ_HASH) {\n        if (o->encoding == OBJ_ENCODING_HT)\n            ht = o->ptr;\n    } else if (o->type == OBJ_ZSET) {\n        if (o->encoding == OBJ_ENCODING_SKIPLIST)\n            ht = ((zset *)o->ptr)->dict;\n    } else {\n        errno = EINVAL;\n        return 0;\n    }\n    if (cursor->done) {\n        errno = ENOENT;\n        return 0;\n    }\n    int ret = 1;\n    if (ht) {\n        ScanKeyCBData data = { key, privdata, fn };\n        cursor->cursor = dictScan(ht, cursor->cursor, moduleScanKeyCallback, &data);\n        if (cursor->cursor == 0) {\n            cursor->done = 1;\n            ret = 0;\n        }\n    } else if (o->type == OBJ_SET) {\n        setTypeIterator *si = setTypeInitIterator(o);\n        sds sdsele;\n        while ((sdsele = setTypeNextObject(si)) != NULL) {\n            robj *field = createObject(OBJ_STRING, sdsele);\n            fn(key, field, NULL, privdata);\n            decrRefCount(field);\n        }\n        setTypeReleaseIterator(si);\n        cursor->cursor = 1;\n        cursor->done = 1;\n        ret = 0;\n    } else if (o->type == OBJ_ZSET || o->type == OBJ_HASH) {\n        unsigned char *p = lpSeek(o->ptr,0);\n        unsigned char *vstr;\n        unsigned int vlen;\n        long long vll;\n        while(p) {\n            vstr = lpGetValue(p,&vlen,&vll);\n            robj *field = (vstr != NULL) ?\n                createStringObject((char*)vstr,vlen) :\n                createStringObjectFromLongLongWithSds(vll);\n            p = lpNext(o->ptr,p);\n            vstr = lpGetValue(p,&vlen,&vll);\n            robj *value = (vstr != NULL) ?\n                createStringObject((char*)vstr,vlen) :\n                createStringObjectFromLongLongWithSds(vll);\n            fn(key, field, value, privdata);\n            p = lpNext(o->ptr,p);\n            decrRefCount(field);\n            decrRefCount(value);\n        }\n        cursor->cursor = 1;\n        cursor->done = 1;\n        ret = 0;\n    }\n    errno = 0;\n    return ret;\n}\n\n\n/* --------------------------------------------------------------------------\n * ## Module fork API\n * -------------------------------------------------------------------------- */\n\n/* Create a background child process with the current frozen snapshot of the\n * main process where you can do some processing in the background without\n * affecting / freezing the traffic and no need for threads and GIL locking.\n * Note that Redis allows for only one concurrent fork.\n * When the child wants to exit, it should call RedisModule_ExitFromChild.\n * If the parent wants to kill the child it should call RedisModule_KillForkChild\n * The done handler callback will be executed on the parent process when the\n * child existed (but not when killed)\n * Return: -1 on failure, on success the parent process will get a positive PID\n * of the child, and the child process will get 0.\n */\nint RM_Fork(RedisModuleForkDoneHandler cb, void *user_data) {\n    pid_t childpid;\n\n    if ((childpid = redisFork(CHILD_TYPE_MODULE)) == 0) {\n        /* Child */\n        redisSetProcTitle(\"redis-module-fork\");\n    } else if (childpid == -1) {\n        serverLog(LL_WARNING,\"Can't fork for module: %s\", strerror(errno));\n    } else {\n        /* Parent */\n        moduleForkInfo.done_handler = cb;\n        moduleForkInfo.done_handler_user_data = user_data;\n        serverLog(LL_VERBOSE, \"Module fork started pid: %ld \", (long) childpid);\n    }\n    return childpid;\n}\n\n/* The module is advised to call this function from the fork child once in a while,\n * so that it can report progress and COW memory to the parent which will be\n * reported in INFO.\n * The `progress` argument should between 0 and 1, or -1 when not available. */\nvoid RM_SendChildHeartbeat(double progress) {\n    sendChildInfoGeneric(CHILD_INFO_TYPE_CURRENT_INFO, 0, progress, \"Module fork\");\n}\n\n/* Call from the child process when you want to terminate it.\n * retcode will be provided to the done handler executed on the parent process.\n */\nint RM_ExitFromChild(int retcode) {\n    sendChildCowInfo(CHILD_INFO_TYPE_MODULE_COW_SIZE, \"Module fork\");\n    exitFromChild(retcode);\n    return REDISMODULE_OK;\n}\n\n/* Kill the active module forked child, if there is one active and the\n * pid matches, and returns C_OK. Otherwise if there is no active module\n * child or the pid does not match, return C_ERR without doing anything. */\nint TerminateModuleForkChild(int child_pid, int wait) {\n    /* Module child should be active and pid should match. */\n    if (server.child_type != CHILD_TYPE_MODULE ||\n        server.child_pid != child_pid) return C_ERR;\n\n    int statloc;\n    serverLog(LL_VERBOSE,\"Killing running module fork child: %ld\",\n        (long) server.child_pid);\n    if (kill(server.child_pid,SIGUSR1) != -1 && wait) {\n        while(waitpid(server.child_pid, &statloc, 0) !=\n              server.child_pid);\n    }\n    /* Reset the buffer accumulating changes while the child saves. */\n    resetChildState();\n    moduleForkInfo.done_handler = NULL;\n    moduleForkInfo.done_handler_user_data = NULL;\n    return C_OK;\n}\n\n/* Can be used to kill the forked child process from the parent process.\n * child_pid would be the return value of RedisModule_Fork. */\nint RM_KillForkChild(int child_pid) {\n    /* Kill module child, wait for child exit. */\n    if (TerminateModuleForkChild(child_pid,1) == C_OK)\n        return REDISMODULE_OK;\n    else\n        return REDISMODULE_ERR;\n}\n\nvoid ModuleForkDoneHandler(int exitcode, int bysignal) {\n    serverLog(LL_NOTICE,\n        \"Module fork exited pid: %ld, retcode: %d, bysignal: %d\",\n        (long) server.child_pid, exitcode, bysignal);\n    if (moduleForkInfo.done_handler) {\n        moduleForkInfo.done_handler(exitcode, bysignal,\n            moduleForkInfo.done_handler_user_data);\n    }\n\n    moduleForkInfo.done_handler = NULL;\n    moduleForkInfo.done_handler_user_data = NULL;\n}\n\n/* --------------------------------------------------------------------------\n * ## Server hooks implementation\n * -------------------------------------------------------------------------- */\n\n/* This must be synced with REDISMODULE_EVENT_*\n * We use -1 (MAX_UINT64) to denote that this event doesn't have\n * a data structure associated with it. We use MAX_UINT64 on purpose,\n * in order to pass the check in RedisModule_SubscribeToServerEvent. */\nstatic uint64_t moduleEventVersions[] = {\n    REDISMODULE_REPLICATIONINFO_VERSION, /* REDISMODULE_EVENT_REPLICATION_ROLE_CHANGED */\n    -1, /* REDISMODULE_EVENT_PERSISTENCE */\n    REDISMODULE_FLUSHINFO_VERSION, /* REDISMODULE_EVENT_FLUSHDB */\n    -1, /* REDISMODULE_EVENT_LOADING */\n    REDISMODULE_CLIENTINFO_VERSION, /* REDISMODULE_EVENT_CLIENT_CHANGE */\n    -1, /* REDISMODULE_EVENT_SHUTDOWN */\n    -1, /* REDISMODULE_EVENT_REPLICA_CHANGE */\n    -1, /* REDISMODULE_EVENT_MASTER_LINK_CHANGE */\n    REDISMODULE_CRON_LOOP_VERSION, /* REDISMODULE_EVENT_CRON_LOOP */\n    REDISMODULE_MODULE_CHANGE_VERSION, /* REDISMODULE_EVENT_MODULE_CHANGE */\n    REDISMODULE_LOADING_PROGRESS_VERSION, /* REDISMODULE_EVENT_LOADING_PROGRESS */\n    REDISMODULE_SWAPDBINFO_VERSION, /* REDISMODULE_EVENT_SWAPDB */\n    -1, /* REDISMODULE_EVENT_REPL_BACKUP */\n    -1, /* REDISMODULE_EVENT_FORK_CHILD */\n    -1, /* REDISMODULE_EVENT_REPL_ASYNC_LOAD */\n    -1, /* REDISMODULE_EVENT_EVENTLOOP */\n    -1, /* REDISMODULE_EVENT_CONFIG */\n    REDISMODULE_KEYINFO_VERSION, /* REDISMODULE_EVENT_KEY */\n};\n\n/* Register to be notified, via a callback, when the specified server event\n * happens. The callback is called with the event as argument, and an additional\n * argument which is a void pointer and should be cased to a specific type\n * that is event-specific (but many events will just use NULL since they do not\n * have additional information to pass to the callback).\n *\n * If the callback is NULL and there was a previous subscription, the module\n * will be unsubscribed. If there was a previous subscription and the callback\n * is not null, the old callback will be replaced with the new one.\n *\n * The callback must be of this type:\n *\n *     int (*RedisModuleEventCallback)(RedisModuleCtx *ctx,\n *                                     RedisModuleEvent eid,\n *                                     uint64_t subevent,\n *                                     void *data);\n *\n * The 'ctx' is a normal Redis module context that the callback can use in\n * order to call other modules APIs. The 'eid' is the event itself, this\n * is only useful in the case the module subscribed to multiple events: using\n * the 'id' field of this structure it is possible to check if the event\n * is one of the events we registered with this callback. The 'subevent' field\n * depends on the event that fired.\n *\n * Finally the 'data' pointer may be populated, only for certain events, with\n * more relevant data.\n *\n * Here is a list of events you can use as 'eid' and related sub events:\n *\n * * RedisModuleEvent_ReplicationRoleChanged:\n *\n *     This event is called when the instance switches from master\n *     to replica or the other way around, however the event is\n *     also called when the replica remains a replica but starts to\n *     replicate with a different master.\n *\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_REPLROLECHANGED_NOW_MASTER`\n *     * `REDISMODULE_SUBEVENT_REPLROLECHANGED_NOW_REPLICA`\n *\n *     The 'data' field can be casted by the callback to a\n *     `RedisModuleReplicationInfo` structure with the following fields:\n *\n *         int master; // true if master, false if replica\n *         char *masterhost; // master instance hostname for NOW_REPLICA\n *         int masterport; // master instance port for NOW_REPLICA\n *         char *replid1; // Main replication ID\n *         char *replid2; // Secondary replication ID\n *         uint64_t repl1_offset; // Main replication offset\n *         uint64_t repl2_offset; // Offset of replid2 validity\n *\n * * RedisModuleEvent_Persistence\n *\n *     This event is called when RDB saving or AOF rewriting starts\n *     and ends. The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_PERSISTENCE_RDB_START`\n *     * `REDISMODULE_SUBEVENT_PERSISTENCE_AOF_START`\n *     * `REDISMODULE_SUBEVENT_PERSISTENCE_SYNC_RDB_START`\n *     * `REDISMODULE_SUBEVENT_PERSISTENCE_SYNC_AOF_START`\n *     * `REDISMODULE_SUBEVENT_PERSISTENCE_ENDED`\n *     * `REDISMODULE_SUBEVENT_PERSISTENCE_FAILED`\n *\n *     The above events are triggered not just when the user calls the\n *     relevant commands like BGSAVE, but also when a saving operation\n *     or AOF rewriting occurs because of internal server triggers.\n *     The SYNC_RDB_START sub events are happening in the foreground due to\n *     SAVE command, FLUSHALL, or server shutdown, and the other RDB and\n *     AOF sub events are executed in a background fork child, so any\n *     action the module takes can only affect the generated AOF or RDB,\n *     but will not be reflected in the parent process and affect connected\n *     clients and commands. Also note that the AOF_START sub event may end\n *     up saving RDB content in case of an AOF with rdb-preamble.\n *\n * * RedisModuleEvent_FlushDB\n *\n *     The FLUSHALL, FLUSHDB or an internal flush (for instance\n *     because of replication, after the replica synchronization)\n *     happened. The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_FLUSHDB_START`\n *     * `REDISMODULE_SUBEVENT_FLUSHDB_END`\n *\n *     The data pointer can be casted to a RedisModuleFlushInfo\n *     structure with the following fields:\n *\n *         int32_t async;  // True if the flush is done in a thread.\n *                         // See for instance FLUSHALL ASYNC.\n *                         // In this case the END callback is invoked\n *                         // immediately after the database is put\n *                         // in the free list of the thread.\n *         int32_t dbnum;  // Flushed database number, -1 for all the DBs\n *                         // in the case of the FLUSHALL operation.\n *\n *     The start event is called *before* the operation is initiated, thus\n *     allowing the callback to call DBSIZE or other operation on the\n *     yet-to-free keyspace.\n *\n * * RedisModuleEvent_Loading\n *\n *     Called on loading operations: at startup when the server is\n *     started, but also after a first synchronization when the\n *     replica is loading the RDB file from the master.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_LOADING_RDB_START`\n *     * `REDISMODULE_SUBEVENT_LOADING_AOF_START`\n *     * `REDISMODULE_SUBEVENT_LOADING_REPL_START`\n *     * `REDISMODULE_SUBEVENT_LOADING_ENDED`\n *     * `REDISMODULE_SUBEVENT_LOADING_FAILED`\n *\n *     Note that AOF loading may start with an RDB data in case of\n *     rdb-preamble, in which case you'll only receive an AOF_START event.\n *\n * * RedisModuleEvent_ClientChange\n *\n *     Called when a client connects or disconnects.\n *     The data pointer can be casted to a RedisModuleClientInfo\n *     structure, documented in RedisModule_GetClientInfoById().\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_CLIENT_CHANGE_CONNECTED`\n *     * `REDISMODULE_SUBEVENT_CLIENT_CHANGE_DISCONNECTED`\n *\n * * RedisModuleEvent_Shutdown\n *\n *     The server is shutting down. No subevents are available.\n *\n * * RedisModuleEvent_ReplicaChange\n *\n *     This event is called when the instance (that can be both a\n *     master or a replica) get a new online replica, or lose a\n *     replica since it gets disconnected.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_REPLICA_CHANGE_ONLINE`\n *     * `REDISMODULE_SUBEVENT_REPLICA_CHANGE_OFFLINE`\n *\n *     No additional information is available so far: future versions\n *     of Redis will have an API in order to enumerate the replicas\n *     connected and their state.\n *\n * * RedisModuleEvent_CronLoop\n *\n *     This event is called every time Redis calls the serverCron()\n *     function in order to do certain bookkeeping. Modules that are\n *     required to do operations from time to time may use this callback.\n *     Normally Redis calls this function 10 times per second, but\n *     this changes depending on the \"hz\" configuration.\n *     No sub events are available.\n *\n *     The data pointer can be casted to a RedisModuleCronLoop\n *     structure with the following fields:\n *\n *         int32_t hz;  // Approximate number of events per second.\n *\n * * RedisModuleEvent_MasterLinkChange\n *\n *     This is called for replicas in order to notify when the\n *     replication link becomes functional (up) with our master,\n *     or when it goes down. Note that the link is not considered\n *     up when we just connected to the master, but only if the\n *     replication is happening correctly.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_MASTER_LINK_UP`\n *     * `REDISMODULE_SUBEVENT_MASTER_LINK_DOWN`\n *\n * * RedisModuleEvent_ModuleChange\n *\n *     This event is called when a new module is loaded or one is unloaded.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_MODULE_LOADED`\n *     * `REDISMODULE_SUBEVENT_MODULE_UNLOADED`\n *\n *     The data pointer can be casted to a RedisModuleModuleChange\n *     structure with the following fields:\n *\n *         const char* module_name;  // Name of module loaded or unloaded.\n *         int32_t module_version;  // Module version.\n *\n * * RedisModuleEvent_LoadingProgress\n *\n *     This event is called repeatedly called while an RDB or AOF file\n *     is being loaded.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_LOADING_PROGRESS_RDB`\n *     * `REDISMODULE_SUBEVENT_LOADING_PROGRESS_AOF`\n *\n *     The data pointer can be casted to a RedisModuleLoadingProgress\n *     structure with the following fields:\n *\n *         int32_t hz;  // Approximate number of events per second.\n *         int32_t progress;  // Approximate progress between 0 and 1024,\n *                            // or -1 if unknown.\n *\n * * RedisModuleEvent_SwapDB\n *\n *     This event is called when a SWAPDB command has been successfully\n *     Executed.\n *     For this event call currently there is no subevents available.\n *\n *     The data pointer can be casted to a RedisModuleSwapDbInfo\n *     structure with the following fields:\n *\n *         int32_t dbnum_first;    // Swap Db first dbnum\n *         int32_t dbnum_second;   // Swap Db second dbnum\n *\n * * RedisModuleEvent_ReplBackup\n * \n *     WARNING: Replication Backup events are deprecated since Redis 7.0 and are never fired.\n *     See RedisModuleEvent_ReplAsyncLoad for understanding how Async Replication Loading events\n *     are now triggered when repl-diskless-load is set to swapdb.\n *\n *     Called when repl-diskless-load config is set to swapdb,\n *     And redis needs to backup the current database for the\n *     possibility to be restored later. A module with global data and\n *     maybe with aux_load and aux_save callbacks may need to use this\n *     notification to backup / restore / discard its globals.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_REPL_BACKUP_CREATE`\n *     * `REDISMODULE_SUBEVENT_REPL_BACKUP_RESTORE`\n *     * `REDISMODULE_SUBEVENT_REPL_BACKUP_DISCARD`\n * \n * * RedisModuleEvent_ReplAsyncLoad\n *\n *     Called when repl-diskless-load config is set to swapdb and a replication with a master of same\n *     data set history (matching replication ID) occurs.\n *     In which case redis serves current data set while loading new database in memory from socket.\n *     Modules must have declared they support this mechanism in order to activate it, through\n *     REDISMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD flag.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_STARTED`\n *     * `REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_ABORTED`\n *     * `REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_COMPLETED`\n *\n * * RedisModuleEvent_ForkChild\n *\n *     Called when a fork child (AOFRW, RDBSAVE, module fork...) is born/dies\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_FORK_CHILD_BORN`\n *     * `REDISMODULE_SUBEVENT_FORK_CHILD_DIED`\n *\n * * RedisModuleEvent_EventLoop\n *\n *     Called on each event loop iteration, once just before the event loop goes\n *     to sleep or just after it wakes up.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_EVENTLOOP_BEFORE_SLEEP`\n *     * `REDISMODULE_SUBEVENT_EVENTLOOP_AFTER_SLEEP`\n *\n * * RedisModule_Event_Config\n *\n *     Called when a configuration event happens\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_CONFIG_CHANGE`\n *\n *     The data pointer can be casted to a RedisModuleConfigChange\n *     structure with the following fields:\n *\n *         const char **config_names; // An array of C string pointers containing the\n *                                    // name of each modified configuration item \n *         uint32_t num_changes;      // The number of elements in the config_names array\n *\n * * RedisModule_Event_Key\n *\n *     Called when a key is removed from the keyspace. We can't modify any key in\n *     the event.\n *     The following sub events are available:\n *\n *     * `REDISMODULE_SUBEVENT_KEY_DELETED`\n *     * `REDISMODULE_SUBEVENT_KEY_EXPIRED`\n *     * `REDISMODULE_SUBEVENT_KEY_EVICTED`\n *     * `REDISMODULE_SUBEVENT_KEY_OVERWRITTEN`\n *\n *     The data pointer can be casted to a RedisModuleKeyInfo\n *     structure with the following fields:\n *\n *         RedisModuleKey *key;    // Key name\n *\n * The function returns REDISMODULE_OK if the module was successfully subscribed\n * for the specified event. If the API is called from a wrong context or unsupported event\n * is given then REDISMODULE_ERR is returned. */\nint RM_SubscribeToServerEvent(RedisModuleCtx *ctx, RedisModuleEvent event, RedisModuleEventCallback callback) {\n    RedisModuleEventListener *el;\n\n    /* Protect in case of calls from contexts without a module reference. */\n    if (ctx->module == NULL) return REDISMODULE_ERR;\n    if (event.id >= _REDISMODULE_EVENT_NEXT) return REDISMODULE_ERR;\n    if (event.dataver > moduleEventVersions[event.id]) return REDISMODULE_ERR; /* Module compiled with a newer redismodule.h than we support */\n\n    /* Search an event matching this module and event ID. */\n    listIter li;\n    listNode *ln;\n    listRewind(RedisModule_EventListeners,&li);\n    while((ln = listNext(&li))) {\n        el = ln->value;\n        if (el->module == ctx->module && el->event.id == event.id)\n            break; /* Matching event found. */\n    }\n\n    /* Modify or remove the event listener if we already had one. */\n    if (ln) {\n        if (callback == NULL) {\n            listDelNode(RedisModule_EventListeners,ln);\n            zfree(el);\n        } else {\n            el->callback = callback; /* Update the callback with the new one. */\n        }\n        return REDISMODULE_OK;\n    }\n\n    /* No event found, we need to add a new one. */\n    el = zmalloc(sizeof(*el));\n    el->module = ctx->module;\n    el->event = event;\n    el->callback = callback;\n    listAddNodeTail(RedisModule_EventListeners,el);\n    return REDISMODULE_OK;\n}\n\n/**\n * For a given server event and subevent, return zero if the\n * subevent is not supported and non-zero otherwise.\n */\nint RM_IsSubEventSupported(RedisModuleEvent event, int64_t subevent) {\n    switch (event.id) {\n    case REDISMODULE_EVENT_REPLICATION_ROLE_CHANGED:\n        return subevent < _REDISMODULE_EVENT_REPLROLECHANGED_NEXT;\n    case REDISMODULE_EVENT_PERSISTENCE:\n        return subevent < _REDISMODULE_SUBEVENT_PERSISTENCE_NEXT;\n    case REDISMODULE_EVENT_FLUSHDB:\n        return subevent < _REDISMODULE_SUBEVENT_FLUSHDB_NEXT;\n    case REDISMODULE_EVENT_LOADING:\n        return subevent < _REDISMODULE_SUBEVENT_LOADING_NEXT;\n    case REDISMODULE_EVENT_CLIENT_CHANGE:\n        return subevent < _REDISMODULE_SUBEVENT_CLIENT_CHANGE_NEXT;\n    case REDISMODULE_EVENT_SHUTDOWN:\n        return subevent < _REDISMODULE_SUBEVENT_SHUTDOWN_NEXT;\n    case REDISMODULE_EVENT_REPLICA_CHANGE:\n        return subevent < _REDISMODULE_EVENT_REPLROLECHANGED_NEXT;\n    case REDISMODULE_EVENT_MASTER_LINK_CHANGE:\n        return subevent < _REDISMODULE_SUBEVENT_MASTER_NEXT;\n    case REDISMODULE_EVENT_CRON_LOOP:\n        return subevent < _REDISMODULE_SUBEVENT_CRON_LOOP_NEXT;\n    case REDISMODULE_EVENT_MODULE_CHANGE:\n        return subevent < _REDISMODULE_SUBEVENT_MODULE_NEXT;\n    case REDISMODULE_EVENT_LOADING_PROGRESS:\n        return subevent < _REDISMODULE_SUBEVENT_LOADING_PROGRESS_NEXT;\n    case REDISMODULE_EVENT_SWAPDB:\n        return subevent < _REDISMODULE_SUBEVENT_SWAPDB_NEXT;\n    case REDISMODULE_EVENT_REPL_ASYNC_LOAD:\n        return subevent < _REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_NEXT;\n    case REDISMODULE_EVENT_FORK_CHILD:\n        return subevent < _REDISMODULE_SUBEVENT_FORK_CHILD_NEXT;\n    case REDISMODULE_EVENT_EVENTLOOP:\n        return subevent < _REDISMODULE_SUBEVENT_EVENTLOOP_NEXT;\n    case REDISMODULE_EVENT_CONFIG:\n        return subevent < _REDISMODULE_SUBEVENT_CONFIG_NEXT; \n    case REDISMODULE_EVENT_KEY:\n        return subevent < _REDISMODULE_SUBEVENT_KEY_NEXT;\n    default:\n        break;\n    }\n    return 0;\n}\n\ntypedef struct KeyInfo {\n    int32_t dbnum;\n    RedisModuleString *key;\n    robj *value;\n    int mode;\n} KeyInfo;\n\n/* This is called by the Redis internals every time we want to fire an\n * event that can be intercepted by some module. The pointer 'data' is useful\n * in order to populate the event-specific structure when needed, in order\n * to return the structure with more information to the callback.\n *\n * 'eid' and 'subid' are just the main event ID and the sub event associated\n * with the event, depending on what exactly happened. */\nvoid moduleFireServerEvent(uint64_t eid, int subid, void *data) {\n    /* Fast path to return ASAP if there is nothing to do, avoiding to\n     * setup the iterator and so forth: we want this call to be extremely\n     * cheap if there are no registered modules. */\n    if (listLength(RedisModule_EventListeners) == 0) return;\n\n    listIter li;\n    listNode *ln;\n    listRewind(RedisModule_EventListeners,&li);\n    while((ln = listNext(&li))) {\n        RedisModuleEventListener *el = ln->value;\n        if (el->event.id == eid) {\n            RedisModuleCtx ctx;\n            if (eid == REDISMODULE_EVENT_CLIENT_CHANGE) {\n                /* In the case of client changes, we're pushing the real client\n                 * so the event handler can mutate it if needed. For example,\n                 * to change its authentication state in a way that does not\n                 * depend on specific commands executed later.\n                 */\n                moduleCreateContext(&ctx,el->module,REDISMODULE_CTX_NONE);\n                ctx.client = (client *) data;\n            } else {\n                moduleCreateContext(&ctx,el->module,REDISMODULE_CTX_TEMP_CLIENT);\n            }\n\n            void *moduledata = NULL;\n            RedisModuleClientInfoV1 civ1;\n            RedisModuleReplicationInfoV1 riv1;\n            RedisModuleModuleChangeV1 mcv1;\n            RedisModuleKey key;\n            RedisModuleKeyInfoV1 ki = {REDISMODULE_KEYINFO_VERSION, &key};\n\n            /* Event specific context and data pointer setup. */\n            if (eid == REDISMODULE_EVENT_CLIENT_CHANGE) {\n                serverAssert(modulePopulateClientInfoStructure(&civ1,data, el->event.dataver) == REDISMODULE_OK);\n                moduledata = &civ1;\n            } else if (eid == REDISMODULE_EVENT_REPLICATION_ROLE_CHANGED) {\n                serverAssert(modulePopulateReplicationInfoStructure(&riv1,el->event.dataver) == REDISMODULE_OK);\n                moduledata = &riv1;\n            } else if (eid == REDISMODULE_EVENT_FLUSHDB) {\n                moduledata = data;\n                RedisModuleFlushInfoV1 *fi = data;\n                if (fi->dbnum != -1)\n                    selectDb(ctx.client, fi->dbnum);\n            } else if (eid == REDISMODULE_EVENT_MODULE_CHANGE) {\n                RedisModule *m = data;\n                if (m == el->module) {\n                    moduleFreeContext(&ctx);\n                    continue;\n                }\n                mcv1.version = REDISMODULE_MODULE_CHANGE_VERSION;\n                mcv1.module_name = m->name;\n                mcv1.module_version = m->ver;\n                moduledata = &mcv1;\n            } else if (eid == REDISMODULE_EVENT_LOADING_PROGRESS) {\n                moduledata = data;\n            } else if (eid == REDISMODULE_EVENT_CRON_LOOP) {\n                moduledata = data;\n            } else if (eid == REDISMODULE_EVENT_SWAPDB) {\n                moduledata = data;\n            } else if (eid == REDISMODULE_EVENT_CONFIG) {\n                moduledata = data;\n            } else if (eid == REDISMODULE_EVENT_KEY) {\n                KeyInfo *info = data;\n                selectDb(ctx.client, info->dbnum);\n                moduleInitKey(&key, &ctx, info->key, info->value, info->mode);\n                moduledata = &ki;\n            }\n\n            el->module->in_hook++;\n            el->callback(&ctx,el->event,subid,moduledata);\n            el->module->in_hook--;\n\n            if (eid == REDISMODULE_EVENT_KEY) {\n                moduleCloseKey(&key);\n            }\n\n            moduleFreeContext(&ctx);\n        }\n    }\n}\n\n/* Remove all the listeners for this module: this is used before unloading\n * a module. */\nvoid moduleUnsubscribeAllServerEvents(RedisModule *module) {\n    RedisModuleEventListener *el;\n    listIter li;\n    listNode *ln;\n    listRewind(RedisModule_EventListeners,&li);\n\n    while((ln = listNext(&li))) {\n        el = ln->value;\n        if (el->module == module) {\n            listDelNode(RedisModule_EventListeners,ln);\n            zfree(el);\n        }\n    }\n}\n\nvoid processModuleLoadingProgressEvent(int is_aof) {\n    long long now = server.ustime;\n    static long long next_event = 0;\n    if (now >= next_event) {\n        /* Fire the loading progress modules end event. */\n        int progress = -1;\n        if (server.loading_total_bytes)\n            progress = (server.loading_loaded_bytes<<10) / server.loading_total_bytes;\n        RedisModuleLoadingProgressV1 fi = {REDISMODULE_LOADING_PROGRESS_VERSION,\n                                     server.hz,\n                                     progress};\n        moduleFireServerEvent(REDISMODULE_EVENT_LOADING_PROGRESS,\n                              is_aof?\n                                REDISMODULE_SUBEVENT_LOADING_PROGRESS_AOF:\n                                REDISMODULE_SUBEVENT_LOADING_PROGRESS_RDB,\n                              &fi);\n        /* decide when the next event should fire. */\n        next_event = now + 1000000 / server.hz;\n    }\n}\n\n/* When a key is deleted (in dbAsyncDelete/dbSyncDelete/setKey), it\n*  will be called to tell the module which key is about to be released. */\nvoid moduleNotifyKeyUnlink(robj *key, robj *val, int dbid, int flags) {\n    server.lazy_expire_disabled++;\n    int subevent = REDISMODULE_SUBEVENT_KEY_DELETED;\n    if (flags & DB_FLAG_KEY_EXPIRED) {\n        subevent = REDISMODULE_SUBEVENT_KEY_EXPIRED;\n    } else if (flags & DB_FLAG_KEY_EVICTED) {\n        subevent = REDISMODULE_SUBEVENT_KEY_EVICTED;\n    } else if (flags & DB_FLAG_KEY_OVERWRITE) {\n        subevent = REDISMODULE_SUBEVENT_KEY_OVERWRITTEN;\n    }\n    KeyInfo info = {dbid, key, val, REDISMODULE_READ};\n    moduleFireServerEvent(REDISMODULE_EVENT_KEY, subevent, &info);\n\n    if (val->type == OBJ_MODULE) {\n        moduleValue *mv = val->ptr;\n        moduleType *mt = mv->type;\n        /* We prefer to use the enhanced version. */\n        if (mt->unlink2 != NULL) {\n            RedisModuleKeyOptCtx ctx = {key, NULL, dbid, -1};\n            mt->unlink2(&ctx,mv->value);\n        } else if (mt->unlink != NULL) {\n            mt->unlink(key,mv->value);\n        }\n    }\n    server.lazy_expire_disabled--;\n}\n\n/* Return the free_effort of the module, it will automatically choose to call \n * `free_effort` or `free_effort2`, and the default return value is 1.\n * value of 0 means very high effort (always asynchronous freeing). */\nsize_t moduleGetFreeEffort(robj *key, robj *val, int dbid) {\n    moduleValue *mv = val->ptr;\n    moduleType *mt = mv->type;\n    size_t effort = 1;\n    /* We prefer to use the enhanced version. */\n    if (mt->free_effort2 != NULL) {\n        RedisModuleKeyOptCtx ctx = {key, NULL, dbid, -1};\n        effort = mt->free_effort2(&ctx,mv->value);\n    } else if (mt->free_effort != NULL) {\n        effort = mt->free_effort(key,mv->value);\n    }  \n\n    return effort;\n}\n\n/* Return the memory usage of the module, it will automatically choose to call \n * `mem_usage` or `mem_usage2`, and the default return value is 0. */\nsize_t moduleGetMemUsage(robj *key, robj *val, size_t sample_size, int dbid) {\n    moduleValue *mv = val->ptr;\n    moduleType *mt = mv->type;\n    size_t size = 0;\n    /* We prefer to use the enhanced version. */\n    if (mt->mem_usage2 != NULL) {\n        RedisModuleKeyOptCtx ctx = {key, NULL, dbid, -1};\n        size = mt->mem_usage2(&ctx, mv->value, sample_size);\n    } else if (mt->mem_usage != NULL) {\n        size = mt->mem_usage(mv->value);\n    } \n\n    return size;\n}\n\n/* --------------------------------------------------------------------------\n * Modules API internals\n * -------------------------------------------------------------------------- */\n\n/* server.moduleapi dictionary type. Only uses plain C strings since\n * this gets queries from modules. */\n\nuint64_t dictCStringKeyHash(const void *key) {\n    return dictGenHashFunction((unsigned char*)key, strlen((char*)key));\n}\n\nint dictCStringKeyCompare(dict *d, const void *key1, const void *key2) {\n    UNUSED(d);\n    return strcmp(key1,key2) == 0;\n}\n\ndictType moduleAPIDictType = {\n    dictCStringKeyHash,        /* hash function */\n    NULL,                      /* key dup */\n    NULL,                      /* val dup */\n    dictCStringKeyCompare,     /* key compare */\n    NULL,                      /* key destructor */\n    NULL,                      /* val destructor */\n    NULL                       /* allow to expand */\n};\n\nint moduleRegisterApi(const char *funcname, void *funcptr) {\n    return dictAdd(server.moduleapi, (char*)funcname, funcptr);\n}\n\n#define REGISTER_API(name) \\\n    moduleRegisterApi(\"RedisModule_\" #name, (void *)(unsigned long)RM_ ## name)\n\n/* Global initialization at Redis startup. */\nvoid moduleRegisterCoreAPI(void);\n\n/* Currently, this function is just a placeholder for the module system\n * initialization steps that need to be run after server initialization.\n * A previous issue, selectDb() in createClient() requires that server.db has\n * been initialized, see #7323. */\nvoid moduleInitModulesSystemLast(void) {\n}\n\n\ndictType sdsKeyValueHashDictType = {\n    dictSdsCaseHash,            /* hash function */\n    NULL,                       /* key dup */\n    NULL,                       /* val dup */\n    dictSdsKeyCaseCompare,      /* key compare */\n    dictSdsDestructor,          /* key destructor */\n    dictSdsDestructor,          /* val destructor */\n    NULL                        /* allow to expand */\n};\n\nvoid moduleInitModulesSystem(void) {\n    moduleUnblockedClients = listCreate();\n    server.loadmodule_queue = listCreate();\n    server.module_configs_queue = dictCreate(&sdsKeyValueHashDictType);\n    server.module_gil_acquring = 0;\n    modules = dictCreate(&modulesDictType);\n    moduleAuthCallbacks = listCreate();\n\n    /* Set up the keyspace notification subscriber list and static client */\n    moduleKeyspaceSubscribers = listCreate();\n\n    modulePostExecUnitJobs = listCreate();\n\n    /* Set up filter list */\n    moduleCommandFilters = listCreate();\n\n    moduleRegisterCoreAPI();\n\n    /* Create a pipe for module threads to be able to wake up the redis main thread.\n     * Make the pipe non blocking. This is just a best effort aware mechanism\n     * and we do not want to block not in the read nor in the write half.\n     * Enable close-on-exec flag on pipes in case of the fork-exec system calls in\n     * sentinels or redis servers. */\n    if (anetPipe(server.module_pipe, O_CLOEXEC|O_NONBLOCK, O_CLOEXEC|O_NONBLOCK) == -1) {\n        serverLog(LL_WARNING,\n            \"Can't create the pipe for module threads: %s\", strerror(errno));\n        exit(1);\n    }\n\n    /* Create the timers radix tree. */\n    Timers = raxNew();\n\n    /* Setup the event listeners data structures. */\n    RedisModule_EventListeners = listCreate();\n\n    /* Making sure moduleEventVersions is synced with the number of events. */\n    serverAssert(sizeof(moduleEventVersions)/sizeof(moduleEventVersions[0]) == _REDISMODULE_EVENT_NEXT);\n\n    /* Our thread-safe contexts GIL must start with already locked:\n     * it is just unlocked when it's safe. */\n    pthread_mutex_lock(&moduleGIL);\n}\n\nvoid modulesCron(void) {\n    /* Check number of temporary clients in the pool and free the unused ones\n     * since the last cron. moduleTempClientMinCount tracks minimum count of\n     * clients in the pool since the last cron. This is the number of clients\n     * that we didn't use for the last cron period. */\n\n    /* Limit the max client count to be freed at once to avoid latency spikes.*/\n    int iteration = 50;\n    /* We are freeing clients if we have more than 8 unused clients. Keeping\n     * small amount of clients to avoid client allocation costs if temporary\n     * clients are required after some idle period. */\n    const unsigned int min_client = 8;\n    while (iteration > 0 && moduleTempClientCount > 0 && moduleTempClientMinCount > min_client) {\n        client *c = moduleTempClients[--moduleTempClientCount];\n        freeClient(c);\n        iteration--;\n        moduleTempClientMinCount--;\n    }\n    moduleTempClientMinCount = moduleTempClientCount;\n\n    /* Shrink moduleTempClients array itself if it is wasting some space */\n    if (moduleTempClientCap > 32 && moduleTempClientCap > moduleTempClientCount * 4) {\n        moduleTempClientCap /= 4;\n        moduleTempClients = zrealloc(moduleTempClients,sizeof(client*)*moduleTempClientCap);\n    }\n}\n\nvoid moduleLoadQueueEntryFree(struct moduleLoadQueueEntry *loadmod) {\n    if (!loadmod) return;\n    sdsfree(loadmod->path);\n    for (int i = 0; i < loadmod->argc; i++) {\n        decrRefCount(loadmod->argv[i]);\n    }\n    zfree(loadmod->argv);\n    zfree(loadmod);\n}\n\n/* Remove Module Configs from standardConfig array in config.c */\nvoid moduleRemoveConfigs(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    listRewind(module->module_configs, &li);\n    while ((ln = listNext(&li))) {\n        ModuleConfig *config = listNodeValue(ln);\n        sds module_name = sdsnew(module->name);\n        sds full_name = sdscat(sdscat(module_name, \".\"), config->name); /* ModuleName.ModuleConfig */\n        removeConfig(full_name);\n        sdsfree(full_name);\n    }\n}\n\n/* Remove ACL categories added by the module when it fails to load. */\nvoid moduleRemoveCateogires(RedisModule *module) {\n    if (module->num_acl_categories_added) {\n        ACLCleanupCategoriesOnFailure(module->num_acl_categories_added);\n    }\n}\n\n/* Load all the modules in the server.loadmodule_queue list, which is\n * populated by `loadmodule` directives in the configuration file.\n * We can't load modules directly when processing the configuration file\n * because the server must be fully initialized before loading modules.\n *\n * The function aborts the server on errors, since to start with missing\n * modules is not considered sane: clients may rely on the existence of\n * given commands, loading AOF also may need some modules to exist, and\n * if this instance is a slave, it must understand commands from master. */\nvoid moduleLoadFromQueue(void) {\n    listIter li;\n    listNode *ln;\n\n    listRewind(server.loadmodule_queue,&li);\n    while((ln = listNext(&li))) {\n        struct moduleLoadQueueEntry *loadmod = ln->value;\n        if (moduleLoad(loadmod->path,(void **)loadmod->argv,loadmod->argc, 0)\n            == C_ERR)\n        {\n            serverLog(LL_WARNING,\n                \"Can't load module from %s: server aborting\",\n                loadmod->path);\n            exit(1);\n        }\n        moduleLoadQueueEntryFree(loadmod);\n        listDelNode(server.loadmodule_queue, ln);\n    }\n    if (dictSize(server.module_configs_queue)) {\n        serverLog(LL_WARNING, \"Module Configuration detected without loadmodule directive or no ApplyConfig call: aborting\");\n        exit(1);\n    }\n}\n\nvoid moduleFreeModuleStructure(struct RedisModule *module) {\n    listRelease(module->types);\n    listRelease(module->filters);\n    listRelease(module->usedby);\n    listRelease(module->using);\n    listRelease(module->module_configs);\n    sdsfree(module->name);\n    moduleLoadQueueEntryFree(module->loadmod);\n    zfree(module);\n}\n\nvoid moduleFreeArgs(struct redisCommandArg *args, int num_args) {\n    for (int j = 0; j < num_args; j++) {\n        zfree((char *)args[j].name);\n        zfree((char *)args[j].token);\n        zfree((char *)args[j].summary);\n        zfree((char *)args[j].since);\n        zfree((char *)args[j].deprecated_since);\n        zfree((char *)args[j].display_text);\n\n        if (args[j].subargs) {\n            moduleFreeArgs(args[j].subargs, args[j].num_args);\n        }\n    }\n    zfree(args);\n}\n\n/* Free the command registered with the specified module.\n * On success C_OK is returned, otherwise C_ERR is returned.\n *\n * Note that caller needs to handle the deletion of the command table dict,\n * and after that needs to free the command->fullname and the command itself.\n */\nint moduleFreeCommand(struct RedisModule *module, struct redisCommand *cmd) {\n    if (cmd->proc != RedisModuleCommandDispatcher)\n        return C_ERR;\n\n    RedisModuleCommand *cp = cmd->module_cmd;\n    if (cp->module != module)\n        return C_ERR;\n\n    /* Free everything except cmd->fullname and cmd itself. */\n    for (int j = 0; j < cmd->key_specs_num; j++) {\n        if (cmd->key_specs[j].notes)\n            zfree((char *)cmd->key_specs[j].notes);\n        if (cmd->key_specs[j].begin_search_type == KSPEC_BS_KEYWORD)\n            zfree((char *)cmd->key_specs[j].bs.keyword.keyword);\n    }\n    zfree(cmd->key_specs);\n    for (int j = 0; cmd->tips && cmd->tips[j]; j++)\n        zfree((char *)cmd->tips[j]);\n    zfree(cmd->tips);\n    for (int j = 0; cmd->history && cmd->history[j].since; j++) {\n        zfree((char *)cmd->history[j].since);\n        zfree((char *)cmd->history[j].changes);\n    }\n    zfree(cmd->history);\n    zfree((char *)cmd->summary);\n    zfree((char *)cmd->since);\n    zfree((char *)cmd->deprecated_since);\n    zfree((char *)cmd->complexity);\n    if (cmd->latency_histogram) {\n        hdr_close(cmd->latency_histogram);\n        cmd->latency_histogram = NULL;\n    }\n    moduleFreeArgs(cmd->args, cmd->num_args);\n    zfree(cp);\n\n    if (cmd->subcommands_dict) {\n        dictEntry *de;\n        dictIterator *di = dictGetSafeIterator(cmd->subcommands_dict);\n        while ((de = dictNext(di)) != NULL) {\n            struct redisCommand *sub = dictGetVal(de);\n            if (moduleFreeCommand(module, sub) != C_OK) continue;\n\n            serverAssert(dictDelete(cmd->subcommands_dict, sub->declared_name) == DICT_OK);\n            sdsfree((sds)sub->declared_name);\n            sdsfree(sub->fullname);\n            zfree(sub);\n        }\n        dictReleaseIterator(di);\n        dictRelease(cmd->subcommands_dict);\n    }\n\n    return C_OK;\n}\n\nvoid moduleUnregisterCommands(struct RedisModule *module) {\n    /* Unregister all the commands registered by this module. */\n    dictIterator *di = dictGetSafeIterator(server.commands);\n    dictEntry *de;\n    while ((de = dictNext(di)) != NULL) {\n        struct redisCommand *cmd = dictGetVal(de);\n        if (moduleFreeCommand(module, cmd) != C_OK) continue;\n\n        serverAssert(dictDelete(server.commands, cmd->fullname) == DICT_OK);\n        serverAssert(dictDelete(server.orig_commands, cmd->fullname) == DICT_OK);\n        sdsfree((sds)cmd->declared_name);\n        sdsfree(cmd->fullname);\n        zfree(cmd);\n    }\n    dictReleaseIterator(di);\n}\n\n/* We parse argv to add sds \"NAME VALUE\" pairs to the server.module_configs_queue list of configs.\n * We also increment the module_argv pointer to just after ARGS if there are args, otherwise\n * we set it to NULL */\nint parseLoadexArguments(RedisModuleString ***module_argv, int *module_argc) {\n    int args_specified = 0;\n    RedisModuleString **argv = *module_argv;\n    int argc = *module_argc;\n    for (int i = 0; i < argc; i++) {\n        char *arg_val = argv[i]->ptr;\n        if (!strcasecmp(arg_val, \"CONFIG\")) {\n            if (i + 2 >= argc) {\n                serverLog(LL_NOTICE, \"CONFIG specified without name value pair\");\n                return REDISMODULE_ERR;\n            }\n            sds name = sdsdup(argv[i + 1]->ptr);\n            sds value = sdsdup(argv[i + 2]->ptr);\n            if (!dictReplace(server.module_configs_queue, name, value)) sdsfree(name);\n            i += 2;\n        } else if (!strcasecmp(arg_val, \"ARGS\")) {\n            args_specified = 1;\n            i++;\n            if (i >= argc) {\n                *module_argv = NULL;\n                *module_argc = 0;\n            } else {\n                *module_argv = argv + i;\n                *module_argc = argc - i;\n            }\n            break;\n        } else {\n            serverLog(LL_NOTICE, \"Syntax Error from arguments to loadex around %s.\", arg_val);\n            return REDISMODULE_ERR;\n        }\n    }\n    if (!args_specified) {\n        *module_argv = NULL;\n        *module_argc = 0;\n    }\n    return REDISMODULE_OK;\n}\n\n/* Unregister module-related things, called when moduleLoad fails or moduleUnload. */\nvoid moduleUnregisterCleanup(RedisModule *module) {\n    moduleFreeAuthenticatedClients(module);\n    moduleUnregisterCommands(module);\n    moduleUnsubscribeNotifications(module);\n    moduleUnregisterSharedAPI(module);\n    moduleUnregisterUsedAPI(module);\n    moduleUnregisterFilters(module);\n    moduleUnsubscribeAllServerEvents(module);\n    moduleRemoveConfigs(module);\n    moduleUnregisterAuthCBs(module);\n}\n\n/* Load a module and initialize it. On success C_OK is returned, otherwise\n * C_ERR is returned. */\nint moduleLoad(const char *path, void **module_argv, int module_argc, int is_loadex) {\n    int (*onload)(void *, void **, int);\n    void *handle;\n\n    struct stat st;\n    if (stat(path, &st) == 0) {\n        /* This check is best effort */\n        if (!(st.st_mode & (S_IXUSR  | S_IXGRP | S_IXOTH))) {\n            serverLog(LL_WARNING, \"Module %s failed to load: It does not have execute permissions.\", path);\n            return C_ERR;\n        }\n    }\n\n    handle = dlopen(path,RTLD_NOW|RTLD_LOCAL);\n    if (handle == NULL) {\n        serverLog(LL_WARNING, \"Module %s failed to load: %s\", path, dlerror());\n        return C_ERR;\n    }\n    onload = (int (*)(void *, void **, int))(unsigned long) dlsym(handle,\"RedisModule_OnLoad\");\n    if (onload == NULL) {\n        dlclose(handle);\n        serverLog(LL_WARNING,\n            \"Module %s does not export RedisModule_OnLoad() \"\n            \"symbol. Module not loaded.\",path);\n        return C_ERR;\n    }\n    RedisModuleCtx ctx;\n    moduleCreateContext(&ctx, NULL, REDISMODULE_CTX_TEMP_CLIENT); /* We pass NULL since we don't have a module yet. */\n    if (onload((void*)&ctx,module_argv,module_argc) == REDISMODULE_ERR) {\n        serverLog(LL_WARNING,\n            \"Module %s initialization failed. Module not loaded\",path);\n        if (ctx.module) {\n            moduleUnregisterCleanup(ctx.module);\n            moduleRemoveCateogires(ctx.module);\n            moduleFreeModuleStructure(ctx.module);\n        }\n        moduleFreeContext(&ctx);\n        dlclose(handle);\n        return C_ERR;\n    }\n\n    /* Redis module loaded! Register it. */\n    dictAdd(modules,ctx.module->name,ctx.module);\n    ctx.module->blocked_clients = 0;\n    ctx.module->handle = handle;\n    ctx.module->loadmod = zmalloc(sizeof(struct moduleLoadQueueEntry));\n    ctx.module->loadmod->path = sdsnew(path);\n    ctx.module->loadmod->argv = module_argc ? zmalloc(sizeof(robj*)*module_argc) : NULL;\n    ctx.module->loadmod->argc = module_argc;\n    for (int i = 0; i < module_argc; i++) {\n        ctx.module->loadmod->argv[i] = module_argv[i];\n        incrRefCount(ctx.module->loadmod->argv[i]);\n    }\n\n    /* If module commands have ACL categories, recompute command bits \n     * for all existing users once the modules has been registered. */\n    if (ctx.module->num_commands_with_acl_categories) {\n        ACLRecomputeCommandBitsFromCommandRulesAllUsers();\n    }\n    serverLog(LL_NOTICE,\"Module '%s' loaded from %s\",ctx.module->name,path);\n    ctx.module->onload = 0;\n\n    int post_load_err = 0;\n    if (listLength(ctx.module->module_configs) && !ctx.module->configs_initialized) {\n        serverLogRaw(LL_WARNING, \"Module Configurations were not set, likely a missing LoadConfigs call. Unloading the module.\");\n        post_load_err = 1;\n    }\n\n    if (is_loadex && dictSize(server.module_configs_queue)) {\n        serverLogRaw(LL_WARNING, \"Loadex configurations were not applied, likely due to invalid arguments. Unloading the module.\");\n        post_load_err = 1;\n    }\n\n    if (post_load_err) {\n        moduleUnload(ctx.module->name, NULL);\n        moduleFreeContext(&ctx);\n        return C_ERR;\n    }\n\n    /* Fire the loaded modules event. */\n    moduleFireServerEvent(REDISMODULE_EVENT_MODULE_CHANGE,\n                          REDISMODULE_SUBEVENT_MODULE_LOADED,\n                          ctx.module);\n\n    moduleFreeContext(&ctx);\n    return C_OK;\n}\n\n/* Unload the module registered with the specified name. On success\n * C_OK is returned, otherwise C_ERR is returned and errmsg is set\n * with an appropriate message. */\nint moduleUnload(sds name, const char **errmsg) {\n    struct RedisModule *module = dictFetchValue(modules,name);\n\n    if (module == NULL) {\n        *errmsg = \"no such module with that name\";\n        return C_ERR;\n    } else if (listLength(module->types)) {\n        *errmsg = \"the module exports one or more module-side data \"\n                  \"types, can't unload\";\n        return C_ERR;\n    } else if (listLength(module->usedby)) {\n        *errmsg = \"the module exports APIs used by other modules. \"\n                  \"Please unload them first and try again\";\n        return C_ERR;\n    } else if (module->blocked_clients) {\n        *errmsg = \"the module has blocked clients. \"\n                  \"Please wait for them to be unblocked and try again\";\n        return C_ERR;\n    } else if (moduleHoldsTimer(module)) {\n        *errmsg = \"the module holds timer that is not fired. \"\n                  \"Please stop the timer or wait until it fires.\";\n        return C_ERR;\n    }\n\n    /* Give module a chance to clean up. */\n    int (*onunload)(void *);\n    onunload = (int (*)(void *))(unsigned long) dlsym(module->handle, \"RedisModule_OnUnload\");\n    if (onunload) {\n        RedisModuleCtx ctx;\n        moduleCreateContext(&ctx, module, REDISMODULE_CTX_TEMP_CLIENT);\n        int unload_status = onunload((void*)&ctx);\n        moduleFreeContext(&ctx);\n\n        if (unload_status == REDISMODULE_ERR) {\n            serverLog(LL_WARNING, \"Module %s OnUnload failed.  Unload canceled.\", name);\n            errno = ECANCELED;\n            return C_ERR;\n        }\n    }\n\n    moduleUnregisterCleanup(module);\n\n    /* Unload the dynamic library. */\n    if (dlclose(module->handle) == -1) {\n        char *error = dlerror();\n        if (error == NULL) error = \"Unknown error\";\n        serverLog(LL_WARNING,\"Error when trying to close the %s module: %s\",\n            module->name, error);\n    }\n\n    /* Fire the unloaded modules event. */\n    moduleFireServerEvent(REDISMODULE_EVENT_MODULE_CHANGE,\n                          REDISMODULE_SUBEVENT_MODULE_UNLOADED,\n                          module);\n\n    /* Remove from list of modules. */\n    serverLog(LL_NOTICE,\"Module %s unloaded\",module->name);\n    dictDelete(modules,module->name);\n    module->name = NULL; /* The name was already freed by dictDelete(). */\n    moduleFreeModuleStructure(module);\n\n    /* Recompute command bits for all users once the modules has been completely unloaded. */\n    ACLRecomputeCommandBitsFromCommandRulesAllUsers();\n    return C_OK;\n}\n\nvoid modulePipeReadable(aeEventLoop *el, int fd, void *privdata, int mask) {\n    UNUSED(el);\n    UNUSED(fd);\n    UNUSED(mask);\n    UNUSED(privdata);\n\n    char buf[128];\n    while (read(fd, buf, sizeof(buf)) == sizeof(buf));\n\n    /* Handle event loop events if pipe was written from event loop API */\n    eventLoopHandleOneShotEvents();\n}\n\n/* Helper function for the MODULE and HELLO command: send the list of the\n * loaded modules to the client. */\nvoid addReplyLoadedModules(client *c) {\n    dictIterator *di = dictGetIterator(modules);\n    dictEntry *de;\n\n    addReplyArrayLen(c,dictSize(modules));\n    while ((de = dictNext(di)) != NULL) {\n        sds name = dictGetKey(de);\n        struct RedisModule *module = dictGetVal(de);\n        sds path = module->loadmod->path;\n        addReplyMapLen(c,4);\n        addReplyBulkCString(c,\"name\");\n        addReplyBulkCBuffer(c,name,sdslen(name));\n        addReplyBulkCString(c,\"ver\");\n        addReplyLongLong(c,module->ver);\n        addReplyBulkCString(c,\"path\");\n        addReplyBulkCBuffer(c,path,sdslen(path));\n        addReplyBulkCString(c,\"args\");\n        addReplyArrayLen(c,module->loadmod->argc);\n        for (int i = 0; i < module->loadmod->argc; i++) {\n            addReplyBulk(c,module->loadmod->argv[i]);\n        }\n    }\n    dictReleaseIterator(di);\n}\n\n/* Helper for genModulesInfoString(): given a list of modules, return\n * an SDS string in the form \"[modulename|modulename2|...]\" */\nsds genModulesInfoStringRenderModulesList(list *l) {\n    listIter li;\n    listNode *ln;\n    listRewind(l,&li);\n    sds output = sdsnew(\"[\");\n    while((ln = listNext(&li))) {\n        RedisModule *module = ln->value;\n        output = sdscat(output,module->name);\n        if (ln != listLast(l))\n            output = sdscat(output,\"|\");\n    }\n    output = sdscat(output,\"]\");\n    return output;\n}\n\n/* Helper for genModulesInfoString(): render module options as an SDS string. */\nsds genModulesInfoStringRenderModuleOptions(struct RedisModule *module) {\n    sds output = sdsnew(\"[\");\n    if (module->options & REDISMODULE_OPTIONS_HANDLE_IO_ERRORS)\n        output = sdscat(output,\"handle-io-errors|\");\n    if (module->options & REDISMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD)\n        output = sdscat(output,\"handle-repl-async-load|\");\n    if (module->options & REDISMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED)\n        output = sdscat(output,\"no-implicit-signal-modified|\");\n    output = sdstrim(output,\"|\");\n    output = sdscat(output,\"]\");\n    return output;\n}\n\n\n/* Helper function for the INFO command: adds loaded modules as to info's\n * output.\n *\n * After the call, the passed sds info string is no longer valid and all the\n * references must be substituted with the new pointer returned by the call. */\nsds genModulesInfoString(sds info) {\n    dictIterator *di = dictGetIterator(modules);\n    dictEntry *de;\n\n    while ((de = dictNext(di)) != NULL) {\n        sds name = dictGetKey(de);\n        struct RedisModule *module = dictGetVal(de);\n\n        sds usedby = genModulesInfoStringRenderModulesList(module->usedby);\n        sds using = genModulesInfoStringRenderModulesList(module->using);\n        sds options = genModulesInfoStringRenderModuleOptions(module);\n        info = sdscatfmt(info,\n            \"module:name=%S,ver=%i,api=%i,filters=%i,\"\n            \"usedby=%S,using=%S,options=%S\\r\\n\",\n                name, module->ver, module->apiver,\n                (int)listLength(module->filters), usedby, using, options);\n        sdsfree(usedby);\n        sdsfree(using);\n        sdsfree(options);\n    }\n    dictReleaseIterator(di);\n    return info;\n}\n\n/* --------------------------------------------------------------------------\n * Module Configurations API internals\n * -------------------------------------------------------------------------- */\n\t \n/* Check if the configuration name is already registered */\nint isModuleConfigNameRegistered(RedisModule *module, const char *name) {\n    listNode *match = listSearchKey(module->module_configs, (void *) name);\n    return match != NULL;\n}\n\n/* Assert that the flags passed into the RM_RegisterConfig Suite are valid */\nint moduleVerifyConfigFlags(unsigned int flags, configType type) {\n    if ((flags & ~(REDISMODULE_CONFIG_DEFAULT\n                    | REDISMODULE_CONFIG_IMMUTABLE\n                    | REDISMODULE_CONFIG_SENSITIVE\n                    | REDISMODULE_CONFIG_HIDDEN\n                    | REDISMODULE_CONFIG_PROTECTED\n                    | REDISMODULE_CONFIG_DENY_LOADING\n                    | REDISMODULE_CONFIG_BITFLAGS\n                    | REDISMODULE_CONFIG_MEMORY))) {\n        serverLogRaw(LL_WARNING, \"Invalid flag(s) for configuration\");\n        return REDISMODULE_ERR;\n    }\n    if (type != NUMERIC_CONFIG && flags & REDISMODULE_CONFIG_MEMORY) {\n        serverLogRaw(LL_WARNING, \"Numeric flag provided for non-numeric configuration.\");\n        return REDISMODULE_ERR;\n    }\n    if (type != ENUM_CONFIG && flags & REDISMODULE_CONFIG_BITFLAGS) {\n        serverLogRaw(LL_WARNING, \"Enum flag provided for non-enum configuration.\");\n        return REDISMODULE_ERR;\n    }\n    return REDISMODULE_OK;\n}\n\n/* Verify a module resource or name has only alphanumeric characters, underscores\n * or dashes. */\nint moduleVerifyResourceName(const char *name) {\n    if (name[0] == '\\0') {\n        return REDISMODULE_ERR;\n    }\n\n    for (size_t i = 0; name[i] != '\\0'; i++) {\n        char curr_char = name[i];\n        if ((curr_char >= 'a' && curr_char <= 'z') ||\n            (curr_char >= 'A' && curr_char <= 'Z') ||\n            (curr_char >= '0' && curr_char <= '9') ||\n            (curr_char == '_') || (curr_char == '-'))\n        {\n            continue;\n        }\n        serverLog(LL_WARNING, \"Invalid character %c in Module resource name %s.\", curr_char, name);\n        return REDISMODULE_ERR;\n    }\n    return REDISMODULE_OK;\n}\n\n/* This is a series of set functions for each type that act as dispatchers for \n * config.c to call module set callbacks. */\n#define CONFIG_ERR_SIZE 256\nstatic char configerr[CONFIG_ERR_SIZE];\nstatic void propagateErrorString(RedisModuleString *err_in, const char **err) {\n    if (err_in) {\n        redis_strlcpy(configerr, err_in->ptr, CONFIG_ERR_SIZE);\n        decrRefCount(err_in);\n        *err = configerr;\n    }\n}\n\nint setModuleBoolConfig(ModuleConfig *config, int val, const char **err) {\n    RedisModuleString *error = NULL;\n    int return_code = config->set_fn.set_bool(config->name, val, config->privdata, &error);\n    propagateErrorString(error, err);\n    return return_code == REDISMODULE_OK ? 1 : 0;\n}\n\nint setModuleStringConfig(ModuleConfig *config, sds strval, const char **err) {\n    RedisModuleString *error = NULL;\n    RedisModuleString *new = createStringObject(strval, sdslen(strval));\n    int return_code = config->set_fn.set_string(config->name, new, config->privdata, &error);\n    propagateErrorString(error, err);\n    decrRefCount(new);\n    return return_code == REDISMODULE_OK ? 1 : 0;\n}\n\nint setModuleEnumConfig(ModuleConfig *config, int val, const char **err) {\n    RedisModuleString *error = NULL;\n    int return_code = config->set_fn.set_enum(config->name, val, config->privdata, &error);\n    propagateErrorString(error, err);\n    return return_code == REDISMODULE_OK ? 1 : 0;\n}\n\nint setModuleNumericConfig(ModuleConfig *config, long long val, const char **err) {\n    RedisModuleString *error = NULL;\n    int return_code = config->set_fn.set_numeric(config->name, val, config->privdata, &error);\n    propagateErrorString(error, err);\n    return return_code == REDISMODULE_OK ? 1 : 0;\n}\n\n/* This is a series of get functions for each type that act as dispatchers for \n * config.c to call module set callbacks. */\nint getModuleBoolConfig(ModuleConfig *module_config) {\n    return module_config->get_fn.get_bool(module_config->name, module_config->privdata);\n}\n\nsds getModuleStringConfig(ModuleConfig *module_config) {\n    RedisModuleString *val = module_config->get_fn.get_string(module_config->name, module_config->privdata);\n    return val ? sdsdup(val->ptr) : NULL;\n}\n\nint getModuleEnumConfig(ModuleConfig *module_config) {\n    return module_config->get_fn.get_enum(module_config->name, module_config->privdata);\n}\n\nlong long getModuleNumericConfig(ModuleConfig *module_config) {\n    return module_config->get_fn.get_numeric(module_config->name, module_config->privdata);\n}\n\n/* This function takes a module and a list of configs stored as sds NAME VALUE pairs.\n * It attempts to call set on each of these configs. */\nint loadModuleConfigs(RedisModule *module) {\n    listIter li;\n    listNode *ln;\n    const char *err = NULL;\n    listRewind(module->module_configs, &li);\n    while ((ln = listNext(&li))) {\n        ModuleConfig *module_config = listNodeValue(ln);\n        sds config_name = sdscatfmt(sdsempty(), \"%s.%s\", module->name, module_config->name);\n        dictEntry *config_argument = dictFind(server.module_configs_queue, config_name);\n        if (config_argument) {\n            if (!performModuleConfigSetFromName(dictGetKey(config_argument), dictGetVal(config_argument), &err)) {\n                serverLog(LL_WARNING, \"Issue during loading of configuration %s : %s\", (sds) dictGetKey(config_argument), err);\n                sdsfree(config_name);\n                dictEmpty(server.module_configs_queue, NULL);\n                return REDISMODULE_ERR;\n            }\n        } else {\n            if (!performModuleConfigSetDefaultFromName(config_name, &err)) {\n                serverLog(LL_WARNING, \"Issue attempting to set default value of configuration %s : %s\", module_config->name, err);\n                sdsfree(config_name);\n                dictEmpty(server.module_configs_queue, NULL);\n                return REDISMODULE_ERR;\n            }\n        }\n        dictDelete(server.module_configs_queue, config_name);\n        sdsfree(config_name);\n    }\n    module->configs_initialized = 1;\n    return REDISMODULE_OK;\n}\n\n/* Add module_config to the list if the apply and privdata do not match one already in it. */\nvoid addModuleConfigApply(list *module_configs, ModuleConfig *module_config) {\n    if (!module_config->apply_fn) return;\n    listIter li;\n    listNode *ln;\n    ModuleConfig *pending_apply;\n    listRewind(module_configs, &li);\n    while ((ln = listNext(&li))) {\n        pending_apply = listNodeValue(ln);\n        if (pending_apply->apply_fn == module_config->apply_fn && pending_apply->privdata == module_config->privdata) {\n            return;\n        }\n    }\n    listAddNodeTail(module_configs, module_config);\n}\n\n/* Call apply on all module configs specified in set, if an apply function was specified at registration time. */\nint moduleConfigApplyConfig(list *module_configs, const char **err, const char **err_arg_name) {\n    if (!listLength(module_configs)) return 1;\n    listIter li;\n    listNode *ln;\n    ModuleConfig *module_config;\n    RedisModuleString *error = NULL;\n    RedisModuleCtx ctx;\n\n    listRewind(module_configs, &li);\n    while ((ln = listNext(&li))) {\n        module_config = listNodeValue(ln);\n        moduleCreateContext(&ctx, module_config->module, REDISMODULE_CTX_NONE);\n        if (module_config->apply_fn(&ctx, module_config->privdata, &error)) {\n            if (err_arg_name) *err_arg_name = module_config->name;\n            propagateErrorString(error, err);\n            moduleFreeContext(&ctx);\n            return 0;\n        }\n        moduleFreeContext(&ctx);\n    }\n    return 1;\n}\n\n/* --------------------------------------------------------------------------\n * ## Module Configurations API\n * -------------------------------------------------------------------------- */\n\n/* Create a module config object. */\nModuleConfig *createModuleConfig(const char *name, RedisModuleConfigApplyFunc apply_fn, void *privdata, RedisModule *module) {\n    ModuleConfig *new_config = zmalloc(sizeof(ModuleConfig));\n    new_config->name = sdsnew(name);\n    new_config->apply_fn = apply_fn;\n    new_config->privdata = privdata;\n    new_config->module = module;\n    return new_config;\n}\n\nint moduleConfigValidityCheck(RedisModule *module, const char *name, unsigned int flags, configType type) {\n    if (!module->onload) {\n        errno = EBUSY;\n        return REDISMODULE_ERR;\n    }\n    if (moduleVerifyConfigFlags(flags, type) || moduleVerifyResourceName(name)) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n    if (isModuleConfigNameRegistered(module, name)) {\n        serverLog(LL_WARNING, \"Configuration by the name: %s already registered\", name);\n        errno = EALREADY;\n        return REDISMODULE_ERR;\n    }\n    return REDISMODULE_OK;\n}\n\nunsigned int maskModuleConfigFlags(unsigned int flags) {\n    unsigned int new_flags = 0;\n    if (flags & REDISMODULE_CONFIG_DEFAULT) new_flags |= MODIFIABLE_CONFIG;\n    if (flags & REDISMODULE_CONFIG_IMMUTABLE) new_flags |= IMMUTABLE_CONFIG;\n    if (flags & REDISMODULE_CONFIG_HIDDEN) new_flags |= HIDDEN_CONFIG;\n    if (flags & REDISMODULE_CONFIG_PROTECTED) new_flags |= PROTECTED_CONFIG;\n    if (flags & REDISMODULE_CONFIG_DENY_LOADING) new_flags |= DENY_LOADING_CONFIG;\n    return new_flags;\n}\n\nunsigned int maskModuleNumericConfigFlags(unsigned int flags) {\n    unsigned int new_flags = 0;\n    if (flags & REDISMODULE_CONFIG_MEMORY) new_flags |= MEMORY_CONFIG;\n    return new_flags;\n}\n\nunsigned int maskModuleEnumConfigFlags(unsigned int flags) {\n    unsigned int new_flags = 0;\n    if (flags & REDISMODULE_CONFIG_BITFLAGS) new_flags |= MULTI_ARG_CONFIG;\n    return new_flags;\n}\n\n/* Create a string config that Redis users can interact with via the Redis config file,\n * `CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands.\n *\n * The actual config value is owned by the module, and the `getfn`, `setfn` and optional\n * `applyfn` callbacks that are provided to Redis in order to access or manipulate the\n * value. The `getfn` callback retrieves the value from the module, while the `setfn`\n * callback provides a value to be stored into the module config.\n * The optional `applyfn` callback is called after a `CONFIG SET` command modified one or\n * more configs using the `setfn` callback and can be used to atomically apply a config\n * after several configs were changed together.\n * If there are multiple configs with `applyfn` callbacks set by a single `CONFIG SET`\n * command, they will be deduplicated if their `applyfn` function and `privdata` pointers\n * are identical, and the callback will only be run once.\n * Both the `setfn` and `applyfn` can return an error if the provided value is invalid or\n * cannot be used.\n * The config also declares a type for the value that is validated by Redis and\n * provided to the module. The config system provides the following types:\n *\n * * Redis String: Binary safe string data.\n * * Enum: One of a finite number of string tokens, provided during registration.\n * * Numeric: 64 bit signed integer, which also supports min and max values.\n * * Bool: Yes or no value.\n *\n * The `setfn` callback is expected to return REDISMODULE_OK when the value is successfully\n * applied. It can also return REDISMODULE_ERR if the value can't be applied, and the\n * *err pointer can be set with a RedisModuleString error message to provide to the client.\n * This RedisModuleString will be freed by redis after returning from the set callback.\n *\n * All configs are registered with a name, a type, a default value, private data that is made\n * available in the callbacks, as well as several flags that modify the behavior of the config.\n * The name must only contain alphanumeric characters or dashes. The supported flags are:\n *\n * * REDISMODULE_CONFIG_DEFAULT: The default flags for a config. This creates a config that can be modified after startup.\n * * REDISMODULE_CONFIG_IMMUTABLE: This config can only be provided loading time.\n * * REDISMODULE_CONFIG_SENSITIVE: The value stored in this config is redacted from all logging.\n * * REDISMODULE_CONFIG_HIDDEN: The name is hidden from `CONFIG GET` with pattern matching.\n * * REDISMODULE_CONFIG_PROTECTED: This config will be only be modifiable based off the value of enable-protected-configs.\n * * REDISMODULE_CONFIG_DENY_LOADING: This config is not modifiable while the server is loading data.\n * * REDISMODULE_CONFIG_MEMORY: For numeric configs, this config will convert data unit notations into their byte equivalent.\n * * REDISMODULE_CONFIG_BITFLAGS: For enum configs, this config will allow multiple entries to be combined as bit flags.\n *\n * Default values are used on startup to set the value if it is not provided via the config file\n * or command line. Default values are also used to compare to on a config rewrite.\n *\n * Notes:\n *\n *  1. On string config sets that the string passed to the set callback will be freed after execution and the module must retain it.\n *  2. On string config gets the string will not be consumed and will be valid after execution.\n *\n * Example implementation:\n *\n *     RedisModuleString *strval;\n *     int adjustable = 1;\n *     RedisModuleString *getStringConfigCommand(const char *name, void *privdata) {\n *         return strval;\n *     }\n *\n *     int setStringConfigCommand(const char *name, RedisModuleString *new, void *privdata, RedisModuleString **err) {\n *        if (adjustable) {\n *            RedisModule_Free(strval);\n *            RedisModule_RetainString(NULL, new);\n *            strval = new;\n *            return REDISMODULE_OK;\n *        }\n *        *err = RedisModule_CreateString(NULL, \"Not adjustable.\", 15);\n *        return REDISMODULE_ERR;\n *     }\n *     ...\n *     RedisModule_RegisterStringConfig(ctx, \"string\", NULL, REDISMODULE_CONFIG_DEFAULT, getStringConfigCommand, setStringConfigCommand, NULL, NULL);\n *\n * If the registration fails, REDISMODULE_ERR is returned and one of the following\n * errno is set:\n * * EBUSY: Registering the Config outside of RedisModule_OnLoad.\n * * EINVAL: The provided flags are invalid for the registration or the name of the config contains invalid characters.\n * * EALREADY: The provided configuration name is already used. */\nint RM_RegisterStringConfig(RedisModuleCtx *ctx, const char *name, const char *default_val, unsigned int flags, RedisModuleConfigGetStringFunc getfn, RedisModuleConfigSetStringFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata) {\n    RedisModule *module = ctx->module;\n    if (moduleConfigValidityCheck(module, name, flags, NUMERIC_CONFIG)) {\n        return REDISMODULE_ERR;\n    }\n    ModuleConfig *new_config = createModuleConfig(name, applyfn, privdata, module);\n    new_config->get_fn.get_string = getfn;\n    new_config->set_fn.set_string = setfn;\n    listAddNodeTail(module->module_configs, new_config);\n    flags = maskModuleConfigFlags(flags);\n    addModuleStringConfig(module->name, name, flags, new_config, default_val ? sdsnew(default_val) : NULL);\n    return REDISMODULE_OK;\n}\n\n/* Create a bool config that server clients can interact with via the \n * `CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands. See \n * RedisModule_RegisterStringConfig for detailed information about configs. */\nint RM_RegisterBoolConfig(RedisModuleCtx *ctx, const char *name, int default_val, unsigned int flags, RedisModuleConfigGetBoolFunc getfn, RedisModuleConfigSetBoolFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata) {\n    RedisModule *module = ctx->module;\n    if (moduleConfigValidityCheck(module, name, flags, BOOL_CONFIG)) {\n        return REDISMODULE_ERR;\n    }\n    ModuleConfig *new_config = createModuleConfig(name, applyfn, privdata, module);\n    new_config->get_fn.get_bool = getfn;\n    new_config->set_fn.set_bool = setfn;\n    listAddNodeTail(module->module_configs, new_config);\n    flags = maskModuleConfigFlags(flags);\n    addModuleBoolConfig(module->name, name, flags, new_config, default_val);\n    return REDISMODULE_OK;\n}\n\n/* \n * Create an enum config that server clients can interact with via the \n * `CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands. \n * Enum configs are a set of string tokens to corresponding integer values, where \n * the string value is exposed to Redis clients but the value passed Redis and the\n * module is the integer value. These values are defined in enum_values, an array\n * of null-terminated c strings, and int_vals, an array of enum values who has an\n * index partner in enum_values.\n * Example Implementation:\n *      const char *enum_vals[3] = {\"first\", \"second\", \"third\"};\n *      const int int_vals[3] = {0, 2, 4};\n *      int enum_val = 0;\n *\n *      int getEnumConfigCommand(const char *name, void *privdata) {\n *          return enum_val;\n *      }\n *       \n *      int setEnumConfigCommand(const char *name, int val, void *privdata, const char **err) {\n *          enum_val = val;\n *          return REDISMODULE_OK;\n *      }\n *      ...\n *      RedisModule_RegisterEnumConfig(ctx, \"enum\", 0, REDISMODULE_CONFIG_DEFAULT, enum_vals, int_vals, 3, getEnumConfigCommand, setEnumConfigCommand, NULL, NULL);\n *\n * Note that you can use REDISMODULE_CONFIG_BITFLAGS so that multiple enum string\n * can be combined into one integer as bit flags, in which case you may want to\n * sort your enums so that the preferred combinations are present first.\n *\n * See RedisModule_RegisterStringConfig for detailed general information about configs. */\nint RM_RegisterEnumConfig(RedisModuleCtx *ctx, const char *name, int default_val, unsigned int flags, const char **enum_values, const int *int_values, int num_enum_vals, RedisModuleConfigGetEnumFunc getfn, RedisModuleConfigSetEnumFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata) {\n    RedisModule *module = ctx->module;\n    if (moduleConfigValidityCheck(module, name, flags, ENUM_CONFIG)) {\n        return REDISMODULE_ERR;\n    }\n    ModuleConfig *new_config = createModuleConfig(name, applyfn, privdata, module);\n    new_config->get_fn.get_enum = getfn;\n    new_config->set_fn.set_enum = setfn;\n    configEnum *enum_vals = zmalloc((num_enum_vals + 1) * sizeof(configEnum));\n    for (int i = 0; i < num_enum_vals; i++) {\n        enum_vals[i].name = zstrdup(enum_values[i]);\n        enum_vals[i].val = int_values[i];\n    }\n    enum_vals[num_enum_vals].name = NULL;\n    enum_vals[num_enum_vals].val = 0;\n    listAddNodeTail(module->module_configs, new_config);\n    flags = maskModuleConfigFlags(flags) | maskModuleEnumConfigFlags(flags);\n    addModuleEnumConfig(module->name, name, flags, new_config, default_val, enum_vals);\n    return REDISMODULE_OK;\n}\n\n/*\n * Create an integer config that server clients can interact with via the \n * `CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands. See \n * RedisModule_RegisterStringConfig for detailed information about configs. */\nint RM_RegisterNumericConfig(RedisModuleCtx *ctx, const char *name, long long default_val, unsigned int flags, long long min, long long max, RedisModuleConfigGetNumericFunc getfn, RedisModuleConfigSetNumericFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata) {\n    RedisModule *module = ctx->module;\n    if (moduleConfigValidityCheck(module, name, flags, NUMERIC_CONFIG)) {\n        return REDISMODULE_ERR;\n    }\n    ModuleConfig *new_config = createModuleConfig(name, applyfn, privdata, module);\n    new_config->get_fn.get_numeric = getfn;\n    new_config->set_fn.set_numeric = setfn;\n    listAddNodeTail(module->module_configs, new_config);\n    unsigned int numeric_flags = maskModuleNumericConfigFlags(flags);\n    flags = maskModuleConfigFlags(flags);\n    addModuleNumericConfig(module->name, name, flags, new_config, default_val, numeric_flags, min, max);\n    return REDISMODULE_OK;\n}\n\n/* Applies all pending configurations on the module load. This should be called\n * after all of the configurations have been registered for the module inside of RedisModule_OnLoad.\n * This will return REDISMODULE_ERR if it is called outside RedisModule_OnLoad.\n * This API needs to be called when configurations are provided in either `MODULE LOADEX`\n * or provided as startup arguments. */\nint RM_LoadConfigs(RedisModuleCtx *ctx) {\n    if (!ctx || !ctx->module || !ctx->module->onload) {\n        return REDISMODULE_ERR;\n    }\n    RedisModule *module = ctx->module;\n    /* Load configs from conf file or arguments from loadex */\n    if (loadModuleConfigs(module)) return REDISMODULE_ERR;\n    return REDISMODULE_OK;\n}\n\n/* --------------------------------------------------------------------------\n * ## RDB load/save API\n * -------------------------------------------------------------------------- */\n\n#define REDISMODULE_RDB_STREAM_FILE 1\n\ntypedef struct RedisModuleRdbStream {\n    int type;\n\n    union {\n        char *filename;\n    } data;\n} RedisModuleRdbStream;\n\n/* Create a stream object to save/load RDB to/from a file.\n *\n * This function returns a pointer to RedisModuleRdbStream which is owned\n * by the caller. It requires a call to RM_RdbStreamFree() to free\n * the object. */\nRedisModuleRdbStream *RM_RdbStreamCreateFromFile(const char *filename) {\n    RedisModuleRdbStream *stream = zmalloc(sizeof(*stream));\n    stream->type = REDISMODULE_RDB_STREAM_FILE;\n    stream->data.filename = zstrdup(filename);\n    return stream;\n}\n\n/* Release an RDB stream object. */\nvoid RM_RdbStreamFree(RedisModuleRdbStream *stream) {\n    switch (stream->type) {\n    case REDISMODULE_RDB_STREAM_FILE:\n        zfree(stream->data.filename);\n        break;\n    default:\n        serverAssert(0);\n        break;\n    }\n    zfree(stream);\n}\n\n/* Load RDB file from the `stream`. Dataset will be cleared first and then RDB\n * file will be loaded.\n *\n * `flags` must be zero. This parameter is for future use.\n *\n * On success REDISMODULE_OK is returned, otherwise REDISMODULE_ERR is returned\n * and errno is set accordingly.\n *\n * Example:\n *\n *     RedisModuleRdbStream *s = RedisModule_RdbStreamCreateFromFile(\"exp.rdb\");\n *     RedisModule_RdbLoad(ctx, s, 0);\n *     RedisModule_RdbStreamFree(s);\n */\nint RM_RdbLoad(RedisModuleCtx *ctx, RedisModuleRdbStream *stream, int flags) {\n    UNUSED(ctx);\n\n    if (!stream || flags != 0) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    /* Not allowed on replicas. */\n    if (server.masterhost != NULL) {\n        errno = ENOTSUP;\n        return REDISMODULE_ERR;\n    }\n\n    /* Drop replicas if exist. */\n    disconnectSlaves();\n    freeReplicationBacklog();\n\n    if (server.aof_state != AOF_OFF) stopAppendOnly();\n\n    /* Kill existing RDB fork as it is saving outdated data. Also killing it\n     * will prevent COW memory issue. */\n    if (server.child_type == CHILD_TYPE_RDB) killRDBChild();\n\n    emptyData(-1,EMPTYDB_NO_FLAGS,NULL);\n\n    /* rdbLoad() can go back to the networking and process network events. If\n     * RM_RdbLoad() is called inside a command callback, we don't want to\n     * process the current client. Otherwise, we may free the client or try to\n     * process next message while we are already in the command callback. */\n    if (server.current_client) protectClient(server.current_client);\n\n    serverAssert(stream->type == REDISMODULE_RDB_STREAM_FILE);\n    int ret = rdbLoad(stream->data.filename,NULL,RDBFLAGS_NONE);\n\n    if (server.current_client) unprotectClient(server.current_client);\n    if (server.aof_state != AOF_OFF) startAppendOnly();\n\n    if (ret != RDB_OK) {\n        errno = (ret == RDB_NOT_EXIST) ? ENOENT : EIO;\n        return REDISMODULE_ERR;\n    }\n\n    errno = 0;\n    return REDISMODULE_OK;\n}\n\n/* Save dataset to the RDB stream.\n *\n * `flags` must be zero. This parameter is for future use.\n *\n * On success REDISMODULE_OK is returned, otherwise REDISMODULE_ERR is returned\n * and errno is set accordingly.\n *\n * Example:\n *\n *     RedisModuleRdbStream *s = RedisModule_RdbStreamCreateFromFile(\"exp.rdb\");\n *     RedisModule_RdbSave(ctx, s, 0);\n *     RedisModule_RdbStreamFree(s);\n */\nint RM_RdbSave(RedisModuleCtx *ctx, RedisModuleRdbStream *stream, int flags) {\n    UNUSED(ctx);\n\n    if (!stream || flags != 0) {\n        errno = EINVAL;\n        return REDISMODULE_ERR;\n    }\n\n    serverAssert(stream->type == REDISMODULE_RDB_STREAM_FILE);\n\n    if (rdbSaveToFile(stream->data.filename) != C_OK) {\n        return REDISMODULE_ERR;\n    }\n\n    errno = 0;\n    return REDISMODULE_OK;\n}\n\n/* Redis MODULE command.\n *\n * MODULE LIST\n * MODULE LOAD <path> [args...]\n * MODULE LOADEX <path> [[CONFIG NAME VALUE] [CONFIG NAME VALUE]] [ARGS ...]\n * MODULE UNLOAD <name>\n */\nvoid moduleCommand(client *c) {\n    char *subcmd = c->argv[1]->ptr;\n\n    if (c->argc == 2 && !strcasecmp(subcmd,\"help\")) {\n        const char *help[] = {\n\"LIST\",\n\"    Return a list of loaded modules.\",\n\"LOAD <path> [<arg> ...]\",\n\"    Load a module library from <path>, passing to it any optional arguments.\",\n\"LOADEX <path> [[CONFIG NAME VALUE] [CONFIG NAME VALUE]] [ARGS ...]\",\n\"    Load a module library from <path>, while passing it module configurations and optional arguments.\",\n\"UNLOAD <name>\",\n\"    Unload a module.\",\nNULL\n        };\n        addReplyHelp(c, help);\n    } else if (!strcasecmp(subcmd,\"load\") && c->argc >= 3) {\n        robj **argv = NULL;\n        int argc = 0;\n\n        if (c->argc > 3) {\n            argc = c->argc - 3;\n            argv = &c->argv[3];\n        }\n\n        if (moduleLoad(c->argv[2]->ptr,(void **)argv,argc, 0) == C_OK)\n            addReply(c,shared.ok);\n        else\n            addReplyError(c,\n                \"Error loading the extension. Please check the server logs.\");\n    } else if (!strcasecmp(subcmd,\"loadex\") && c->argc >= 3) {\n        robj **argv = NULL;\n        int argc = 0;\n\n        if (c->argc > 3) {\n            argc = c->argc - 3;\n            argv = &c->argv[3];\n        }\n        /* If this is a loadex command we want to populate server.module_configs_queue with \n         * sds NAME VALUE pairs. We also want to increment argv to just after ARGS, if supplied. */\n        if (parseLoadexArguments((RedisModuleString ***) &argv, &argc) == REDISMODULE_OK &&\n            moduleLoad(c->argv[2]->ptr, (void **)argv, argc, 1) == C_OK)\n            addReply(c,shared.ok);\n        else {\n            dictEmpty(server.module_configs_queue, NULL);\n            addReplyError(c,\n                \"Error loading the extension. Please check the server logs.\");\n        }\n\n    } else if (!strcasecmp(subcmd,\"unload\") && c->argc == 3) {\n        const char *errmsg = NULL;\n        if (moduleUnload(c->argv[2]->ptr, &errmsg) == C_OK)\n            addReply(c,shared.ok);\n        else {\n            if (errmsg == NULL) errmsg = \"operation not possible.\";\n            addReplyErrorFormat(c, \"Error unloading module: %s\", errmsg);\n            serverLog(LL_WARNING, \"Error unloading module %s: %s\", (sds) c->argv[2]->ptr, errmsg);\n        }\n    } else if (!strcasecmp(subcmd,\"list\") && c->argc == 2) {\n        addReplyLoadedModules(c);\n    } else {\n        addReplySubcommandSyntaxError(c);\n        return;\n    }\n}\n\n/* Return the number of registered modules. */\nsize_t moduleCount(void) {\n    return dictSize(modules);\n}\n\n/* --------------------------------------------------------------------------\n * ## Key eviction API\n * -------------------------------------------------------------------------- */\n\n/* Set the key last access time for LRU based eviction. not relevant if the\n * servers's maxmemory policy is LFU based. Value is idle time in milliseconds.\n * returns REDISMODULE_OK if the LRU was updated, REDISMODULE_ERR otherwise. */\nint RM_SetLRU(RedisModuleKey *key, mstime_t lru_idle) {\n    if (!key->value)\n        return REDISMODULE_ERR;\n    if (objectSetLRUOrLFU(key->value, -1, lru_idle, lru_idle>=0 ? LRU_CLOCK() : 0, 1))\n        return REDISMODULE_OK;\n    return REDISMODULE_ERR;\n}\n\n/* Gets the key last access time.\n * Value is idletime in milliseconds or -1 if the server's eviction policy is\n * LFU based.\n * returns REDISMODULE_OK if when key is valid. */\nint RM_GetLRU(RedisModuleKey *key, mstime_t *lru_idle) {\n    *lru_idle = -1;\n    if (!key->value)\n        return REDISMODULE_ERR;\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU)\n        return REDISMODULE_OK;\n    *lru_idle = estimateObjectIdleTime(key->value);\n    return REDISMODULE_OK;\n}\n\n/* Set the key access frequency. only relevant if the server's maxmemory policy\n * is LFU based.\n * The frequency is a logarithmic counter that provides an indication of\n * the access frequencyonly (must be <= 255).\n * returns REDISMODULE_OK if the LFU was updated, REDISMODULE_ERR otherwise. */\nint RM_SetLFU(RedisModuleKey *key, long long lfu_freq) {\n    if (!key->value)\n        return REDISMODULE_ERR;\n    if (objectSetLRUOrLFU(key->value, lfu_freq, -1, 0, 1))\n        return REDISMODULE_OK;\n    return REDISMODULE_ERR;\n}\n\n/* Gets the key access frequency or -1 if the server's eviction policy is not\n * LFU based.\n * returns REDISMODULE_OK if when key is valid. */\nint RM_GetLFU(RedisModuleKey *key, long long *lfu_freq) {\n    *lfu_freq = -1;\n    if (!key->value)\n        return REDISMODULE_ERR;\n    if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU)\n        *lfu_freq = LFUDecrAndReturn(key->value);\n    return REDISMODULE_OK;\n}\n\n/* --------------------------------------------------------------------------\n * ## Miscellaneous APIs\n * -------------------------------------------------------------------------- */\n\n/**\n * Returns the full module options flags mask, using the return value\n * the module can check if a certain set of module options are supported\n * by the redis server version in use.\n * Example:\n *\n *        int supportedFlags = RM_GetModuleOptionsAll();\n *        if (supportedFlags & REDISMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS) {\n *              // REDISMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS is supported\n *        } else{\n *              // REDISMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS is not supported\n *        }\n */\nint RM_GetModuleOptionsAll(void) {\n    return _REDISMODULE_OPTIONS_FLAGS_NEXT - 1;\n}\n\n/**\n * Returns the full ContextFlags mask, using the return value\n * the module can check if a certain set of flags are supported\n * by the redis server version in use.\n * Example:\n *\n *        int supportedFlags = RM_GetContextFlagsAll();\n *        if (supportedFlags & REDISMODULE_CTX_FLAGS_MULTI) {\n *              // REDISMODULE_CTX_FLAGS_MULTI is supported\n *        } else{\n *              // REDISMODULE_CTX_FLAGS_MULTI is not supported\n *        }\n */\nint RM_GetContextFlagsAll(void) {\n    return _REDISMODULE_CTX_FLAGS_NEXT - 1;\n}\n\n/**\n * Returns the full KeyspaceNotification mask, using the return value\n * the module can check if a certain set of flags are supported\n * by the redis server version in use.\n * Example:\n *\n *        int supportedFlags = RM_GetKeyspaceNotificationFlagsAll();\n *        if (supportedFlags & REDISMODULE_NOTIFY_LOADED) {\n *              // REDISMODULE_NOTIFY_LOADED is supported\n *        } else{\n *              // REDISMODULE_NOTIFY_LOADED is not supported\n *        }\n */\nint RM_GetKeyspaceNotificationFlagsAll(void) {\n    return _REDISMODULE_NOTIFY_NEXT - 1;\n}\n\n/**\n * Return the redis version in format of 0x00MMmmpp.\n * Example for 6.0.7 the return value will be 0x00060007.\n */\nint RM_GetServerVersion(void) {\n    return REDIS_VERSION_NUM;\n}\n\n/**\n * Return the current redis-server runtime value of REDISMODULE_TYPE_METHOD_VERSION.\n * You can use that when calling RM_CreateDataType to know which fields of\n * RedisModuleTypeMethods are gonna be supported and which will be ignored.\n */\nint RM_GetTypeMethodVersion(void) {\n    return REDISMODULE_TYPE_METHOD_VERSION;\n}\n\n/* Replace the value assigned to a module type.\n *\n * The key must be open for writing, have an existing value, and have a moduleType\n * that matches the one specified by the caller.\n *\n * Unlike RM_ModuleTypeSetValue() which will free the old value, this function\n * simply swaps the old value with the new value.\n *\n * The function returns REDISMODULE_OK on success, REDISMODULE_ERR on errors\n * such as:\n *\n * 1. Key is not opened for writing.\n * 2. Key is not a module data type key.\n * 3. Key is a module datatype other than 'mt'.\n *\n * If old_value is non-NULL, the old value is returned by reference.\n */\nint RM_ModuleTypeReplaceValue(RedisModuleKey *key, moduleType *mt, void *new_value, void **old_value) {\n    if (!(key->mode & REDISMODULE_WRITE) || key->iter)\n        return REDISMODULE_ERR;\n    if (!key->value || key->value->type != OBJ_MODULE)\n        return REDISMODULE_ERR;\n\n    moduleValue *mv = key->value->ptr;\n    if (mv->type != mt)\n        return REDISMODULE_ERR;\n\n    if (old_value)\n        *old_value = mv->value;\n    mv->value = new_value;\n\n    return REDISMODULE_OK;\n}\n\n/* For a specified command, parse its arguments and return an array that\n * contains the indexes of all key name arguments. This function is\n * essentially a more efficient way to do `COMMAND GETKEYS`.\n *\n * The out_flags argument is optional, and can be set to NULL.\n * When provided it is filled with REDISMODULE_CMD_KEY_ flags in matching\n * indexes with the key indexes of the returned array.\n *\n * A NULL return value indicates the specified command has no keys, or\n * an error condition. Error conditions are indicated by setting errno\n * as follows:\n *\n * * ENOENT: Specified command does not exist.\n * * EINVAL: Invalid command arity specified.\n *\n * NOTE: The returned array is not a Redis Module object so it does not\n * get automatically freed even when auto-memory is used. The caller\n * must explicitly call RM_Free() to free it, same as the out_flags pointer if\n * used.\n */\nint *RM_GetCommandKeysWithFlags(RedisModuleCtx *ctx, RedisModuleString **argv, int argc, int *num_keys, int **out_flags) {\n    UNUSED(ctx);\n    struct redisCommand *cmd;\n    int *res = NULL;\n\n    /* Find command */\n    if ((cmd = lookupCommand(argv,argc)) == NULL) {\n        errno = ENOENT;\n        return NULL;\n    }\n\n    /* Bail out if command has no keys */\n    if (!doesCommandHaveKeys(cmd)) {\n        errno = 0;\n        return NULL;\n    }\n\n    if ((cmd->arity > 0 && cmd->arity != argc) || (argc < -cmd->arity)) {\n        errno = EINVAL;\n        return NULL;\n    }\n\n    getKeysResult result = GETKEYS_RESULT_INIT;\n    getKeysFromCommand(cmd, argv, argc, &result);\n\n    *num_keys = result.numkeys;\n    if (!result.numkeys) {\n        errno = 0;\n        getKeysFreeResult(&result);\n        return NULL;\n    }\n\n    /* The return value here expects an array of key positions */\n    unsigned long int size = sizeof(int) * result.numkeys;\n    res = zmalloc(size);\n    if (out_flags)\n        *out_flags = zmalloc(size);\n    for (int i = 0; i < result.numkeys; i++) {\n        res[i] = result.keys[i].pos;\n        if (out_flags)\n            (*out_flags)[i] = moduleConvertKeySpecsFlags(result.keys[i].flags, 0);\n    }\n\n    return res;\n}\n\n/* Identical to RM_GetCommandKeysWithFlags when flags are not needed. */\nint *RM_GetCommandKeys(RedisModuleCtx *ctx, RedisModuleString **argv, int argc, int *num_keys) {\n    return RM_GetCommandKeysWithFlags(ctx, argv, argc, num_keys, NULL);\n}\n\n/* Return the name of the command currently running */\nconst char *RM_GetCurrentCommandName(RedisModuleCtx *ctx) {\n    if (!ctx || !ctx->client || !ctx->client->cmd)\n        return NULL;\n\n    return (const char*)ctx->client->cmd->fullname;\n}\n\n/* --------------------------------------------------------------------------\n * ## Defrag API\n * -------------------------------------------------------------------------- */\n\n/* The defrag context, used to manage state during calls to the data type\n * defrag callback.\n */\nstruct RedisModuleDefragCtx {\n    long long int endtime;\n    unsigned long *cursor;\n    struct redisObject *key; /* Optional name of key processed, NULL when unknown. */\n    int dbid;                /* The dbid of the key being processed, -1 when unknown. */\n};\n\n/* Register a defrag callback for global data, i.e. anything that the module\n * may allocate that is not tied to a specific data type.\n */\nint RM_RegisterDefragFunc(RedisModuleCtx *ctx, RedisModuleDefragFunc cb) {\n    ctx->module->defrag_cb = cb;\n    return REDISMODULE_OK;\n}\n\n/* When the data type defrag callback iterates complex structures, this\n * function should be called periodically. A zero (false) return\n * indicates the callback may continue its work. A non-zero value (true)\n * indicates it should stop.\n *\n * When stopped, the callback may use RM_DefragCursorSet() to store its\n * position so it can later use RM_DefragCursorGet() to resume defragging.\n *\n * When stopped and more work is left to be done, the callback should\n * return 1. Otherwise, it should return 0.\n *\n * NOTE: Modules should consider the frequency in which this function is called,\n * so it generally makes sense to do small batches of work in between calls.\n */\nint RM_DefragShouldStop(RedisModuleDefragCtx *ctx) {\n    return (ctx->endtime != 0 && ctx->endtime < ustime());\n}\n\n/* Store an arbitrary cursor value for future re-use.\n *\n * This should only be called if RM_DefragShouldStop() has returned a non-zero\n * value and the defrag callback is about to exit without fully iterating its\n * data type.\n *\n * This behavior is reserved to cases where late defrag is performed. Late\n * defrag is selected for keys that implement the `free_effort` callback and\n * return a `free_effort` value that is larger than the defrag\n * 'active-defrag-max-scan-fields' configuration directive.\n *\n * Smaller keys, keys that do not implement `free_effort` or the global\n * defrag callback are not called in late-defrag mode. In those cases, a\n * call to this function will return REDISMODULE_ERR.\n *\n * The cursor may be used by the module to represent some progress into the\n * module's data type. Modules may also store additional cursor-related\n * information locally and use the cursor as a flag that indicates when\n * traversal of a new key begins. This is possible because the API makes\n * a guarantee that concurrent defragmentation of multiple keys will\n * not be performed.\n */\nint RM_DefragCursorSet(RedisModuleDefragCtx *ctx, unsigned long cursor) {\n    if (!ctx->cursor)\n        return REDISMODULE_ERR;\n\n    *ctx->cursor = cursor;\n    return REDISMODULE_OK;\n}\n\n/* Fetch a cursor value that has been previously stored using RM_DefragCursorSet().\n *\n * If not called for a late defrag operation, REDISMODULE_ERR will be returned and\n * the cursor should be ignored. See RM_DefragCursorSet() for more details on\n * defrag cursors.\n */\nint RM_DefragCursorGet(RedisModuleDefragCtx *ctx, unsigned long *cursor) {\n    if (!ctx->cursor)\n        return REDISMODULE_ERR;\n\n    *cursor = *ctx->cursor;\n    return REDISMODULE_OK;\n}\n\n/* Defrag a memory allocation previously allocated by RM_Alloc, RM_Calloc, etc.\n * The defragmentation process involves allocating a new memory block and copying\n * the contents to it, like realloc().\n *\n * If defragmentation was not necessary, NULL is returned and the operation has\n * no other effect.\n *\n * If a non-NULL value is returned, the caller should use the new pointer instead\n * of the old one and update any reference to the old pointer, which must not\n * be used again.\n */\nvoid *RM_DefragAlloc(RedisModuleDefragCtx *ctx, void *ptr) {\n    UNUSED(ctx);\n    return activeDefragAlloc(ptr);\n}\n\n/* Defrag a RedisModuleString previously allocated by RM_Alloc, RM_Calloc, etc.\n * See RM_DefragAlloc() for more information on how the defragmentation process\n * works.\n *\n * NOTE: It is only possible to defrag strings that have a single reference.\n * Typically this means strings retained with RM_RetainString or RM_HoldString\n * may not be defragmentable. One exception is command argvs which, if retained\n * by the module, will end up with a single reference (because the reference\n * on the Redis side is dropped as soon as the command callback returns).\n */\nRedisModuleString *RM_DefragRedisModuleString(RedisModuleDefragCtx *ctx, RedisModuleString *str) {\n    UNUSED(ctx);\n    return activeDefragStringOb(str);\n}\n\n\n/* Perform a late defrag of a module datatype key.\n *\n * Returns a zero value (and initializes the cursor) if no more needs to be done,\n * or a non-zero value otherwise.\n */\nint moduleLateDefrag(robj *key, robj *value, unsigned long *cursor, long long endtime, int dbid) {\n    moduleValue *mv = value->ptr;\n    moduleType *mt = mv->type;\n\n    RedisModuleDefragCtx defrag_ctx = { endtime, cursor, key, dbid};\n\n    /* Invoke callback. Note that the callback may be missing if the key has been\n     * replaced with a different type since our last visit.\n     */\n    int ret = 0;\n    if (mt->defrag)\n        ret = mt->defrag(&defrag_ctx, key, &mv->value);\n\n    if (!ret) {\n        *cursor = 0;    /* No more work to do */\n        return 0;\n    }\n\n    return 1;\n}\n\n/* Attempt to defrag a module data type value. Depending on complexity,\n * the operation may happen immediately or be scheduled for later.\n *\n * Returns 1 if the operation has been completed or 0 if it needs to\n * be scheduled for late defrag.\n */\nint moduleDefragValue(robj *key, robj *value, int dbid) {\n    moduleValue *mv = value->ptr;\n    moduleType *mt = mv->type;\n\n    /* Try to defrag moduleValue itself regardless of whether or not\n     * defrag callbacks are provided.\n     */\n    moduleValue *newmv = activeDefragAlloc(mv);\n    if (newmv) {\n        value->ptr = mv = newmv;\n    }\n\n    if (!mt->defrag)\n        return 1;\n\n    /* Use free_effort to determine complexity of module value, and if\n     * necessary schedule it for defragLater instead of quick immediate\n     * defrag.\n     */\n    size_t effort = moduleGetFreeEffort(key, value, dbid);\n    if (!effort)\n        effort = SIZE_MAX;\n    if (effort > server.active_defrag_max_scan_fields) {\n        return 0;  /* Defrag later */\n    }\n\n    RedisModuleDefragCtx defrag_ctx = { 0, NULL, key, dbid };\n    mt->defrag(&defrag_ctx, key, &mv->value);\n    return 1;\n}\n\n/* Call registered module API defrag functions */\nvoid moduleDefragGlobals(void) {\n    dictIterator *di = dictGetIterator(modules);\n    dictEntry *de;\n\n    while ((de = dictNext(di)) != NULL) {\n        struct RedisModule *module = dictGetVal(de);\n        if (!module->defrag_cb)\n            continue;\n        RedisModuleDefragCtx defrag_ctx = { 0, NULL, NULL, -1};\n        module->defrag_cb(&defrag_ctx);\n    }\n    dictReleaseIterator(di);\n}\n\n/* Returns the name of the key currently being processed.\n * There is no guarantee that the key name is always available, so this may return NULL.\n */\nconst RedisModuleString *RM_GetKeyNameFromDefragCtx(RedisModuleDefragCtx *ctx) {\n    return ctx->key;\n}\n\n/* Returns the database id of the key currently being processed.\n * There is no guarantee that this info is always available, so this may return -1.\n */\nint RM_GetDbIdFromDefragCtx(RedisModuleDefragCtx *ctx) {\n    return ctx->dbid;\n}\n\n/* Register all the APIs we export. Keep this function at the end of the\n * file so that's easy to seek it to add new entries. */\nvoid moduleRegisterCoreAPI(void) {\n    server.moduleapi = dictCreate(&moduleAPIDictType);\n    server.sharedapi = dictCreate(&moduleAPIDictType);\n    REGISTER_API(Alloc);\n    REGISTER_API(TryAlloc);\n    REGISTER_API(Calloc);\n    REGISTER_API(TryCalloc);\n    REGISTER_API(Realloc);\n    REGISTER_API(TryRealloc);\n    REGISTER_API(Free);\n    REGISTER_API(Strdup);\n    REGISTER_API(CreateCommand);\n    REGISTER_API(GetCommand);\n    REGISTER_API(CreateSubcommand);\n    REGISTER_API(SetCommandInfo);\n    REGISTER_API(SetCommandACLCategories);\n    REGISTER_API(AddACLCategory);\n    REGISTER_API(SetModuleAttribs);\n    REGISTER_API(IsModuleNameBusy);\n    REGISTER_API(WrongArity);\n    REGISTER_API(ReplyWithLongLong);\n    REGISTER_API(ReplyWithError);\n    REGISTER_API(ReplyWithErrorFormat);\n    REGISTER_API(ReplyWithSimpleString);\n    REGISTER_API(ReplyWithArray);\n    REGISTER_API(ReplyWithMap);\n    REGISTER_API(ReplyWithSet);\n    REGISTER_API(ReplyWithAttribute);\n    REGISTER_API(ReplyWithNullArray);\n    REGISTER_API(ReplyWithEmptyArray);\n    REGISTER_API(ReplySetArrayLength);\n    REGISTER_API(ReplySetMapLength);\n    REGISTER_API(ReplySetSetLength);\n    REGISTER_API(ReplySetAttributeLength);\n    REGISTER_API(ReplyWithString);\n    REGISTER_API(ReplyWithEmptyString);\n    REGISTER_API(ReplyWithVerbatimString);\n    REGISTER_API(ReplyWithVerbatimStringType);\n    REGISTER_API(ReplyWithStringBuffer);\n    REGISTER_API(ReplyWithCString);\n    REGISTER_API(ReplyWithNull);\n    REGISTER_API(ReplyWithBool);\n    REGISTER_API(ReplyWithCallReply);\n    REGISTER_API(ReplyWithDouble);\n    REGISTER_API(ReplyWithBigNumber);\n    REGISTER_API(ReplyWithLongDouble);\n    REGISTER_API(GetSelectedDb);\n    REGISTER_API(SelectDb);\n    REGISTER_API(KeyExists);\n    REGISTER_API(OpenKey);\n    REGISTER_API(GetOpenKeyModesAll);\n    REGISTER_API(CloseKey);\n    REGISTER_API(KeyType);\n    REGISTER_API(ValueLength);\n    REGISTER_API(ListPush);\n    REGISTER_API(ListPop);\n    REGISTER_API(ListGet);\n    REGISTER_API(ListSet);\n    REGISTER_API(ListInsert);\n    REGISTER_API(ListDelete);\n    REGISTER_API(StringToLongLong);\n    REGISTER_API(StringToULongLong);\n    REGISTER_API(StringToDouble);\n    REGISTER_API(StringToLongDouble);\n    REGISTER_API(StringToStreamID);\n    REGISTER_API(Call);\n    REGISTER_API(CallReplyProto);\n    REGISTER_API(FreeCallReply);\n    REGISTER_API(CallReplyInteger);\n    REGISTER_API(CallReplyDouble);\n    REGISTER_API(CallReplyBigNumber);\n    REGISTER_API(CallReplyVerbatim);\n    REGISTER_API(CallReplyBool);\n    REGISTER_API(CallReplySetElement);\n    REGISTER_API(CallReplyMapElement);\n    REGISTER_API(CallReplyAttributeElement);\n    REGISTER_API(CallReplyPromiseSetUnblockHandler);\n    REGISTER_API(CallReplyPromiseAbort);\n    REGISTER_API(CallReplyAttribute);\n    REGISTER_API(CallReplyType);\n    REGISTER_API(CallReplyLength);\n    REGISTER_API(CallReplyArrayElement);\n    REGISTER_API(CallReplyStringPtr);\n    REGISTER_API(CreateStringFromCallReply);\n    REGISTER_API(CreateString);\n    REGISTER_API(CreateStringFromLongLong);\n    REGISTER_API(CreateStringFromULongLong);\n    REGISTER_API(CreateStringFromDouble);\n    REGISTER_API(CreateStringFromLongDouble);\n    REGISTER_API(CreateStringFromString);\n    REGISTER_API(CreateStringFromStreamID);\n    REGISTER_API(CreateStringPrintf);\n    REGISTER_API(FreeString);\n    REGISTER_API(StringPtrLen);\n    REGISTER_API(AutoMemory);\n    REGISTER_API(Replicate);\n    REGISTER_API(ReplicateVerbatim);\n    REGISTER_API(DeleteKey);\n    REGISTER_API(UnlinkKey);\n    REGISTER_API(StringSet);\n    REGISTER_API(StringDMA);\n    REGISTER_API(StringTruncate);\n    REGISTER_API(SetExpire);\n    REGISTER_API(GetExpire);\n    REGISTER_API(SetAbsExpire);\n    REGISTER_API(GetAbsExpire);\n    REGISTER_API(ResetDataset);\n    REGISTER_API(DbSize);\n    REGISTER_API(RandomKey);\n    REGISTER_API(ZsetAdd);\n    REGISTER_API(ZsetIncrby);\n    REGISTER_API(ZsetScore);\n    REGISTER_API(ZsetRem);\n    REGISTER_API(ZsetRangeStop);\n    REGISTER_API(ZsetFirstInScoreRange);\n    REGISTER_API(ZsetLastInScoreRange);\n    REGISTER_API(ZsetFirstInLexRange);\n    REGISTER_API(ZsetLastInLexRange);\n    REGISTER_API(ZsetRangeCurrentElement);\n    REGISTER_API(ZsetRangeNext);\n    REGISTER_API(ZsetRangePrev);\n    REGISTER_API(ZsetRangeEndReached);\n    REGISTER_API(HashSet);\n    REGISTER_API(HashGet);\n    REGISTER_API(StreamAdd);\n    REGISTER_API(StreamDelete);\n    REGISTER_API(StreamIteratorStart);\n    REGISTER_API(StreamIteratorStop);\n    REGISTER_API(StreamIteratorNextID);\n    REGISTER_API(StreamIteratorNextField);\n    REGISTER_API(StreamIteratorDelete);\n    REGISTER_API(StreamTrimByLength);\n    REGISTER_API(StreamTrimByID);\n    REGISTER_API(IsKeysPositionRequest);\n    REGISTER_API(KeyAtPos);\n    REGISTER_API(KeyAtPosWithFlags);\n    REGISTER_API(IsChannelsPositionRequest);\n    REGISTER_API(ChannelAtPosWithFlags);\n    REGISTER_API(GetClientId);\n    REGISTER_API(GetClientUserNameById);\n    REGISTER_API(GetContextFlags);\n    REGISTER_API(AvoidReplicaTraffic);\n    REGISTER_API(PoolAlloc);\n    REGISTER_API(CreateDataType);\n    REGISTER_API(ModuleTypeSetValue);\n    REGISTER_API(ModuleTypeReplaceValue);\n    REGISTER_API(ModuleTypeGetType);\n    REGISTER_API(ModuleTypeGetValue);\n    REGISTER_API(IsIOError);\n    REGISTER_API(SetModuleOptions);\n    REGISTER_API(SignalModifiedKey);\n    REGISTER_API(SaveUnsigned);\n    REGISTER_API(LoadUnsigned);\n    REGISTER_API(SaveSigned);\n    REGISTER_API(LoadSigned);\n    REGISTER_API(SaveString);\n    REGISTER_API(SaveStringBuffer);\n    REGISTER_API(LoadString);\n    REGISTER_API(LoadStringBuffer);\n    REGISTER_API(SaveDouble);\n    REGISTER_API(LoadDouble);\n    REGISTER_API(SaveFloat);\n    REGISTER_API(LoadFloat);\n    REGISTER_API(SaveLongDouble);\n    REGISTER_API(LoadLongDouble);\n    REGISTER_API(SaveDataTypeToString);\n    REGISTER_API(LoadDataTypeFromString);\n    REGISTER_API(LoadDataTypeFromStringEncver);\n    REGISTER_API(EmitAOF);\n    REGISTER_API(Log);\n    REGISTER_API(LogIOError);\n    REGISTER_API(_Assert);\n    REGISTER_API(LatencyAddSample);\n    REGISTER_API(StringAppendBuffer);\n    REGISTER_API(TrimStringAllocation);\n    REGISTER_API(RetainString);\n    REGISTER_API(HoldString);\n    REGISTER_API(StringCompare);\n    REGISTER_API(GetContextFromIO);\n    REGISTER_API(GetKeyNameFromIO);\n    REGISTER_API(GetKeyNameFromModuleKey);\n    REGISTER_API(GetDbIdFromModuleKey);\n    REGISTER_API(GetDbIdFromIO);\n    REGISTER_API(GetKeyNameFromOptCtx);\n    REGISTER_API(GetToKeyNameFromOptCtx);\n    REGISTER_API(GetDbIdFromOptCtx);\n    REGISTER_API(GetToDbIdFromOptCtx);\n    REGISTER_API(GetKeyNameFromDefragCtx);\n    REGISTER_API(GetDbIdFromDefragCtx);\n    REGISTER_API(GetKeyNameFromDigest);\n    REGISTER_API(GetDbIdFromDigest);\n    REGISTER_API(BlockClient);\n    REGISTER_API(BlockClientGetPrivateData);\n    REGISTER_API(BlockClientSetPrivateData);\n    REGISTER_API(BlockClientOnAuth);\n    REGISTER_API(UnblockClient);\n    REGISTER_API(IsBlockedReplyRequest);\n    REGISTER_API(IsBlockedTimeoutRequest);\n    REGISTER_API(GetBlockedClientPrivateData);\n    REGISTER_API(AbortBlock);\n    REGISTER_API(Milliseconds);\n    REGISTER_API(MonotonicMicroseconds);\n    REGISTER_API(Microseconds);\n    REGISTER_API(CachedMicroseconds);\n    REGISTER_API(BlockedClientMeasureTimeStart);\n    REGISTER_API(BlockedClientMeasureTimeEnd);\n    REGISTER_API(GetThreadSafeContext);\n    REGISTER_API(GetDetachedThreadSafeContext);\n    REGISTER_API(FreeThreadSafeContext);\n    REGISTER_API(ThreadSafeContextLock);\n    REGISTER_API(ThreadSafeContextTryLock);\n    REGISTER_API(ThreadSafeContextUnlock);\n    REGISTER_API(DigestAddStringBuffer);\n    REGISTER_API(DigestAddLongLong);\n    REGISTER_API(DigestEndSequence);\n    REGISTER_API(NotifyKeyspaceEvent);\n    REGISTER_API(GetNotifyKeyspaceEvents);\n    REGISTER_API(SubscribeToKeyspaceEvents);\n    REGISTER_API(AddPostNotificationJob);\n    REGISTER_API(RegisterClusterMessageReceiver);\n    REGISTER_API(SendClusterMessage);\n    REGISTER_API(GetClusterNodeInfo);\n    REGISTER_API(GetClusterNodesList);\n    REGISTER_API(FreeClusterNodesList);\n    REGISTER_API(CreateTimer);\n    REGISTER_API(StopTimer);\n    REGISTER_API(GetTimerInfo);\n    REGISTER_API(GetMyClusterID);\n    REGISTER_API(GetClusterSize);\n    REGISTER_API(GetRandomBytes);\n    REGISTER_API(GetRandomHexChars);\n    REGISTER_API(BlockedClientDisconnected);\n    REGISTER_API(SetDisconnectCallback);\n    REGISTER_API(GetBlockedClientHandle);\n    REGISTER_API(SetClusterFlags);\n    REGISTER_API(CreateDict);\n    REGISTER_API(FreeDict);\n    REGISTER_API(DictSize);\n    REGISTER_API(DictSetC);\n    REGISTER_API(DictReplaceC);\n    REGISTER_API(DictSet);\n    REGISTER_API(DictReplace);\n    REGISTER_API(DictGetC);\n    REGISTER_API(DictGet);\n    REGISTER_API(DictDelC);\n    REGISTER_API(DictDel);\n    REGISTER_API(DictIteratorStartC);\n    REGISTER_API(DictIteratorStart);\n    REGISTER_API(DictIteratorStop);\n    REGISTER_API(DictIteratorReseekC);\n    REGISTER_API(DictIteratorReseek);\n    REGISTER_API(DictNextC);\n    REGISTER_API(DictPrevC);\n    REGISTER_API(DictNext);\n    REGISTER_API(DictPrev);\n    REGISTER_API(DictCompareC);\n    REGISTER_API(DictCompare);\n    REGISTER_API(ExportSharedAPI);\n    REGISTER_API(GetSharedAPI);\n    REGISTER_API(RegisterCommandFilter);\n    REGISTER_API(UnregisterCommandFilter);\n    REGISTER_API(CommandFilterArgsCount);\n    REGISTER_API(CommandFilterArgGet);\n    REGISTER_API(CommandFilterArgInsert);\n    REGISTER_API(CommandFilterArgReplace);\n    REGISTER_API(CommandFilterArgDelete);\n    REGISTER_API(CommandFilterGetClientId);\n    REGISTER_API(Fork);\n    REGISTER_API(SendChildHeartbeat);\n    REGISTER_API(ExitFromChild);\n    REGISTER_API(KillForkChild);\n    REGISTER_API(RegisterInfoFunc);\n    REGISTER_API(InfoAddSection);\n    REGISTER_API(InfoBeginDictField);\n    REGISTER_API(InfoEndDictField);\n    REGISTER_API(InfoAddFieldString);\n    REGISTER_API(InfoAddFieldCString);\n    REGISTER_API(InfoAddFieldDouble);\n    REGISTER_API(InfoAddFieldLongLong);\n    REGISTER_API(InfoAddFieldULongLong);\n    REGISTER_API(GetServerInfo);\n    REGISTER_API(FreeServerInfo);\n    REGISTER_API(ServerInfoGetField);\n    REGISTER_API(ServerInfoGetFieldC);\n    REGISTER_API(ServerInfoGetFieldSigned);\n    REGISTER_API(ServerInfoGetFieldUnsigned);\n    REGISTER_API(ServerInfoGetFieldDouble);\n    REGISTER_API(GetClientInfoById);\n    REGISTER_API(GetClientNameById);\n    REGISTER_API(SetClientNameById);\n    REGISTER_API(PublishMessage);\n    REGISTER_API(PublishMessageShard);\n    REGISTER_API(SubscribeToServerEvent);\n    REGISTER_API(SetLRU);\n    REGISTER_API(GetLRU);\n    REGISTER_API(SetLFU);\n    REGISTER_API(GetLFU);\n    REGISTER_API(BlockClientOnKeys);\n    REGISTER_API(BlockClientOnKeysWithFlags);\n    REGISTER_API(SignalKeyAsReady);\n    REGISTER_API(GetBlockedClientReadyKey);\n    REGISTER_API(GetUsedMemoryRatio);\n    REGISTER_API(MallocSize);\n    REGISTER_API(MallocUsableSize);\n    REGISTER_API(MallocSizeString);\n    REGISTER_API(MallocSizeDict);\n    REGISTER_API(ScanCursorCreate);\n    REGISTER_API(ScanCursorDestroy);\n    REGISTER_API(ScanCursorRestart);\n    REGISTER_API(Scan);\n    REGISTER_API(ScanKey);\n    REGISTER_API(CreateModuleUser);\n    REGISTER_API(SetContextUser);\n    REGISTER_API(SetModuleUserACL);\n    REGISTER_API(SetModuleUserACLString);\n    REGISTER_API(GetModuleUserACLString);\n    REGISTER_API(GetCurrentUserName);\n    REGISTER_API(GetModuleUserFromUserName);\n    REGISTER_API(ACLCheckCommandPermissions);\n    REGISTER_API(ACLCheckKeyPermissions);\n    REGISTER_API(ACLCheckChannelPermissions);\n    REGISTER_API(ACLAddLogEntry);\n    REGISTER_API(ACLAddLogEntryByUserName);\n    REGISTER_API(FreeModuleUser);\n    REGISTER_API(DeauthenticateAndCloseClient);\n    REGISTER_API(AuthenticateClientWithACLUser);\n    REGISTER_API(AuthenticateClientWithUser);\n    REGISTER_API(GetContextFlagsAll);\n    REGISTER_API(GetModuleOptionsAll);\n    REGISTER_API(GetKeyspaceNotificationFlagsAll);\n    REGISTER_API(IsSubEventSupported);\n    REGISTER_API(GetServerVersion);\n    REGISTER_API(GetClientCertificate);\n    REGISTER_API(RedactClientCommandArgument);\n    REGISTER_API(GetCommandKeys);\n    REGISTER_API(GetCommandKeysWithFlags);\n    REGISTER_API(GetCurrentCommandName);\n    REGISTER_API(GetTypeMethodVersion);\n    REGISTER_API(RegisterDefragFunc);\n    REGISTER_API(DefragAlloc);\n    REGISTER_API(DefragRedisModuleString);\n    REGISTER_API(DefragShouldStop);\n    REGISTER_API(DefragCursorSet);\n    REGISTER_API(DefragCursorGet);\n    REGISTER_API(EventLoopAdd);\n    REGISTER_API(EventLoopDel);\n    REGISTER_API(EventLoopAddOneShot);\n    REGISTER_API(Yield);\n    REGISTER_API(RegisterBoolConfig);\n    REGISTER_API(RegisterNumericConfig);\n    REGISTER_API(RegisterStringConfig);\n    REGISTER_API(RegisterEnumConfig);\n    REGISTER_API(LoadConfigs);\n    REGISTER_API(RegisterAuthCallback);\n    REGISTER_API(RdbStreamCreateFromFile);\n    REGISTER_API(RdbStreamFree);\n    REGISTER_API(RdbLoad);\n    REGISTER_API(RdbSave);\n}\n"}, {"id": "8D2242F56114BEED", "name": "replyToBlockedClientTimedOut", "path": "redis/src/blocked.c", "start": {"line": 229, "col": 1}, "end": {"line": 246, "col": 1}, "code": "    if (c->bstate.btype == BLOCKED_LIST ||\n        c->bstate.btype == BLOCKED_ZSET ||\n        c->bstate.btype == BLOCKED_STREAM) {\n        addReplyNullArray(c);\n        updateStatsOnUnblock(c, 0, 0, 0);\n    } else if (c->bstate.btype == BLOCKED_WAIT) {\n        addReplyLongLong(c,replicationCountAcksByOffset(c->bstate.reploffset));\n    } else if (c->bstate.btype == BLOCKED_WAITAOF) {\n        addReplyArrayLen(c,2);\n        addReplyLongLong(c,server.fsynced_reploff >= c->bstate.reploffset);\n        addReplyLongLong(c,replicationCountAOFAcksByOffset(c->bstate.reploffset));\n    } else if (c->bstate.btype == BLOCKED_MODULE) {\n        moduleBlockedClientTimedOut(c, 0);\n    } else {\n        serverPanic(\"Unknown btype in replyToBlockedClientTimedOut().\");\n    }\n}\n\n/* If one or more clients are blocked on the SHUTDOWN command, this function\n * sends them an error reply and unblocks them. */\nvoid replyToClientsBlockedOnShutdown(void) {\n    if (server.blocked_clients_by_type[BLOCKED_SHUTDOWN] == 0) return;\n    listNode *ln;\n    listIter li;\n    listRewind(server.clients, &li);\n    while((ln = listNext(&li))) {\n        client *c = listNodeValue(ln);\n        if (c->flags & CLIENT_BLOCKED && c->bstate.btype == BLOCKED_SHUTDOWN) {\n            addReplyError(c, \"Errors trying to SHUTDOWN. Check logs.\");\n            unblockClient(c, 1);\n        }\n    }\n}\n\n/* Mass-unblock clients because something changed in the instance that makes\n * blocking no longer safe. For example clients blocked in list operations\n * in an instance which turns from master to slave is unsafe, so this function\n * is called when a master turns into a slave.\n *\n * The semantics is to send an -UNBLOCKED error to the client, disconnecting\n * it at the same time. */\nvoid disconnectAllBlockedClients(void) {\n    listNode *ln;\n    listIter li;\n\n    listRewind(server.clients,&li);\n    while((ln = listNext(&li))) {\n        client *c = listNodeValue(ln);\n\n        if (c->flags & CLIENT_BLOCKED) {\n            /* POSTPONEd clients are an exception, when they'll be unblocked, the\n             * command processing will start from scratch, and the command will\n             * be either executed or rejected. (unlike LIST blocked clients for\n             * which the command is already in progress in a way. */\n            if (c->bstate.btype == BLOCKED_POSTPONE)\n                continue;\n\n            unblockClientOnError(c,\n                \"-UNBLOCKED force unblock from blocking operation, \"\n                \"instance state changed (master -> replica?)\");\n            c->flags |= CLIENT_CLOSE_AFTER_REPLY;\n        }\n    }\n}\n\n/* This function should be called by Redis every time a single command,\n * a MULTI/EXEC block, or a Lua script, terminated its execution after\n * being called by a client. It handles serving clients blocked in all scenarios\n * where a specific key access requires to block until that key is available.\n *\n * All the keys with at least one client blocked that are signaled as ready\n * are accumulated into the server.ready_keys list. This function will run\n * the list and will serve clients accordingly.\n * Note that the function will iterate again and again (for example as a result of serving BLMOVE\n * we can have new blocking clients to serve because of the PUSH side of BLMOVE.)\n *\n * This function is normally \"fair\", that is, it will serve clients\n * using a FIFO behavior. However this fairness is violated in certain\n * edge cases, that is, when we have clients blocked at the same time\n * in a sorted set and in a list, for the same key (a very odd thing to\n * do client side, indeed!). Because mismatching clients (blocking for\n * a different type compared to the current key type) are moved in the\n * other side of the linked list. However as long as the key starts to\n * be used only for a single type, like virtually any Redis application will\n * do, the function is already fair. */\nvoid handleClientsBlockedOnKeys(void) {\n\n    /* In case we are already in the process of unblocking clients we should\n     * not make a recursive call, in order to prevent breaking fairness. */\n    static int in_handling_blocked_clients = 0;\n    if (in_handling_blocked_clients)\n        return;\n    in_handling_blocked_clients = 1;\n\n    /* This function is called only when also_propagate is in its basic state\n     * (i.e. not from call(), module context, etc.) */\n    serverAssert(server.also_propagate.numops == 0);\n\n    /* If a command being unblocked causes another command to get unblocked,\n     * like a BLMOVE would do, then the new unblocked command will get processed\n     * right away rather than wait for later. */\n    while(listLength(server.ready_keys) != 0) {\n        list *l;\n\n        /* Point server.ready_keys to a fresh list and save the current one\n         * locally. This way as we run the old list we are free to call\n         * signalKeyAsReady() that may push new elements in server.ready_keys\n         * when handling clients blocked into BLMOVE. */\n        l = server.ready_keys;\n        server.ready_keys = listCreate();\n\n        while(listLength(l) != 0) {\n            listNode *ln = listFirst(l);\n            readyList *rl = ln->value;\n\n            /* First of all remove this key from db->ready_keys so that\n             * we can safely call signalKeyAsReady() against this key. */\n            dictDelete(rl->db->ready_keys,rl->key);\n\n            handleClientsBlockedOnKey(rl);\n\n            /* Free this item. */\n            decrRefCount(rl->key);\n            zfree(rl);\n            listDelNode(l,ln);\n        }\n        listRelease(l); /* We have the new list on place at this point. */\n    }\n    in_handling_blocked_clients = 0;\n}\n\n/* Set a client in blocking mode for the specified key, with the specified timeout.\n * The 'type' argument is BLOCKED_LIST,BLOCKED_ZSET or BLOCKED_STREAM depending on the kind of operation we are\n * waiting for an empty key in order to awake the client. The client is blocked\n * for all the 'numkeys' keys as in the 'keys' argument.\n * The client will unblocked as soon as one of the keys in 'keys' value was updated.\n * the parameter unblock_on_nokey can be used to force client to be unblocked even in the case the key\n * is updated to become unavailable, either by type change (override), deletion or swapdb */\nvoid blockForKeys(client *c, int btype, robj **keys, int numkeys, mstime_t timeout, int unblock_on_nokey) {\n    dictEntry *db_blocked_entry, *db_blocked_existing_entry, *client_blocked_entry;\n    list *l;\n    int j;\n\n    if (!(c->flags & CLIENT_REPROCESSING_COMMAND)) {\n        /* If the client is re-processing the command, we do not set the timeout\n         * because we need to retain the client's original timeout. */\n        c->bstate.timeout = timeout;\n    }\n\n    for (j = 0; j < numkeys; j++) {\n        /* If the key already exists in the dictionary ignore it. */\n        if (!(client_blocked_entry = dictAddRaw(c->bstate.keys,keys[j],NULL))) {\n            continue;\n        }\n        incrRefCount(keys[j]);\n\n        /* And in the other \"side\", to map keys -> clients */\n        db_blocked_entry = dictAddRaw(c->db->blocking_keys,keys[j], &db_blocked_existing_entry);\n\n        /* In case key[j] did not have blocking clients yet, we need to create a new list */\n        if (db_blocked_entry != NULL) {\n            l = listCreate();\n            dictSetVal(c->db->blocking_keys, db_blocked_entry, l);\n            incrRefCount(keys[j]);\n        } else {\n            l = dictGetVal(db_blocked_existing_entry);\n        }\n        listAddNodeTail(l,c);\n        dictSetVal(c->bstate.keys,client_blocked_entry,listLast(l));\n\n        /* We need to add the key to blocking_keys_unblock_on_nokey, if the client\n         * wants to be awakened if key is deleted (like XREADGROUP) */\n        if (unblock_on_nokey) {\n            db_blocked_entry = dictAddRaw(c->db->blocking_keys_unblock_on_nokey, keys[j], &db_blocked_existing_entry);\n            if (db_blocked_entry) {\n                incrRefCount(keys[j]);\n                dictSetUnsignedIntegerVal(db_blocked_entry, 1);\n            } else {\n                dictIncrUnsignedIntegerVal(db_blocked_existing_entry, 1);\n            }\n        }\n    }\n    c->bstate.unblock_on_nokey = unblock_on_nokey;\n    /* Currently we assume key blocking will require reprocessing the command.\n     * However in case of modules, they have a different way to handle the reprocessing\n     * which does not require setting the pending command flag */\n    if (btype != BLOCKED_MODULE)\n        c->flags |= CLIENT_PENDING_COMMAND;\n    blockClient(c,btype);\n}\n\n/* Helper function to unblock a client that's waiting in a blocking operation such as BLPOP.\n * Internal function for unblockClient() */\nstatic void unblockClientWaitingData(client *c) {\n    dictEntry *de;\n    dictIterator *di;\n\n    if (dictSize(c->bstate.keys) == 0)\n        return;\n\n    di = dictGetIterator(c->bstate.keys);\n    /* The client may wait for multiple keys, so unblock it for every key. */\n    while((de = dictNext(di)) != NULL) {\n        releaseBlockedEntry(c, de, 0);\n    }\n    dictReleaseIterator(di);\n    dictEmpty(c->bstate.keys, NULL);\n}\n\nstatic blocking_type getBlockedTypeByType(int type) {\n    switch (type) {\n        case OBJ_LIST: return BLOCKED_LIST;\n        case OBJ_ZSET: return BLOCKED_ZSET;\n        case OBJ_MODULE: return BLOCKED_MODULE;\n        case OBJ_STREAM: return BLOCKED_STREAM;\n        default: return BLOCKED_NONE;\n    }\n}\n\n/* If the specified key has clients blocked waiting for list pushes, this\n * function will put the key reference into the server.ready_keys list.\n * Note that db->ready_keys is a hash table that allows us to avoid putting\n * the same key again and again in the list in case of multiple pushes\n * made by a script or in the context of MULTI/EXEC.\n *\n * The list will be finally processed by handleClientsBlockedOnKeys() */\nstatic void signalKeyAsReadyLogic(redisDb *db, robj *key, int type, int deleted) {\n    readyList *rl;\n\n    /* Quick returns. */\n    int btype = getBlockedTypeByType(type);\n    if (btype == BLOCKED_NONE) {\n        /* The type can never block. */\n        return;\n    }\n    if (!server.blocked_clients_by_type[btype] &&\n        !server.blocked_clients_by_type[BLOCKED_MODULE]) {\n        /* No clients block on this type. Note: Blocked modules are represented\n         * by BLOCKED_MODULE, even if the intention is to wake up by normal\n         * types (list, zset, stream), so we need to check that there are no\n         * blocked modules before we do a quick return here. */\n        return;\n    }\n\n    if (deleted) {\n        /* Key deleted and no clients blocking for this key? No need to queue it. */\n        if (dictFind(db->blocking_keys_unblock_on_nokey,key) == NULL)\n"}, {"id": "6C27B2AABE9D7730", "name": "unblockClient", "path": "redis/src/blocked.c", "start": {"line": 184, "col": 1}, "end": {"line": 224, "col": 1}, "code": "    if (c->bstate.btype == BLOCKED_LIST ||\n        c->bstate.btype == BLOCKED_ZSET ||\n        c->bstate.btype == BLOCKED_STREAM) {\n        unblockClientWaitingData(c);\n    } else if (c->bstate.btype == BLOCKED_WAIT || c->bstate.btype == BLOCKED_WAITAOF) {\n        unblockClientWaitingReplicas(c);\n    } else if (c->bstate.btype == BLOCKED_MODULE) {\n        if (moduleClientIsBlockedOnKeys(c)) unblockClientWaitingData(c);\n        unblockClientFromModule(c);\n    } else if (c->bstate.btype == BLOCKED_POSTPONE) {\n        listDelNode(server.postponed_clients,c->postponed_list_node);\n        c->postponed_list_node = NULL;\n    } else if (c->bstate.btype == BLOCKED_SHUTDOWN) {\n        /* No special cleanup. */\n    } else {\n        serverPanic(\"Unknown btype in unblockClient().\");\n    }\n\n    /* Reset the client for a new query, unless the client has pending command to process\n     * or in case a shutdown operation was canceled and we are still in the processCommand sequence  */\n    if (!(c->flags & CLIENT_PENDING_COMMAND) && c->bstate.btype != BLOCKED_SHUTDOWN) {\n        freeClientOriginalArgv(c);\n        /* Clients that are not blocked on keys are not reprocessed so we must\n         * call reqresAppendResponse here (for clients blocked on key,\n         * unblockClientOnKey is called, which eventually calls processCommand,\n         * which calls reqresAppendResponse) */\n        reqresAppendResponse(c);\n        resetClient(c);\n    }\n\n    /* Clear the flags, and put the client in the unblocked list so that\n     * we'll process new commands in its query buffer ASAP. */\n    if (!(c->flags & CLIENT_MODULE)) server.blocked_clients--; /* We count blocked client stats on regular clients and not on module clients */\n    server.blocked_clients_by_type[c->bstate.btype]--;\n    c->flags &= ~CLIENT_BLOCKED;\n    c->bstate.btype = BLOCKED_NONE;\n    c->bstate.unblock_on_nokey = 0;\n    removeClientFromTimeoutTable(c);\n    if (queue_for_reprocessing) queueClientForReprocessing(c);\n}\n\n/* This function gets called when a blocked client timed out in order to\n * send it a reply of some kind. After this function is called,\n * unblockClient() will be called with the same client as argument. */\nvoid replyToBlockedClientTimedOut(client *c) {\n    if (c->bstate.btype == BLOCKED_LIST ||\n        c->bstate.btype == BLOCKED_ZSET ||\n        c->bstate.btype == BLOCKED_STREAM) {\n        addReplyNullArray(c);\n        updateStatsOnUnblock(c, 0, 0, 0);\n    } else if (c->bstate.btype == BLOCKED_WAIT) {\n        addReplyLongLong(c,replicationCountAcksByOffset(c->bstate.reploffset));\n    } else if (c->bstate.btype == BLOCKED_WAITAOF) {\n        addReplyArrayLen(c,2);\n        addReplyLongLong(c,server.fsynced_reploff >= c->bstate.reploffset);\n        addReplyLongLong(c,replicationCountAOFAcksByOffset(c->bstate.reploffset));\n    } else if (c->bstate.btype == BLOCKED_MODULE) {\n        moduleBlockedClientTimedOut(c, 0);\n    } else {\n        serverPanic(\"Unknown btype in replyToBlockedClientTimedOut().\");\n    }\n}\n\n/* If one or more clients are blocked on the SHUTDOWN command, this function\n * sends them an error reply and unblocks them. */\nvoid replyToClientsBlockedOnShutdown(void) {\n    if (server.blocked_clients_by_type[BLOCKED_SHUTDOWN] == 0) return;\n    listNode *ln;\n    listIter li;\n    listRewind(server.clients, &li);\n    while((ln = listNext(&li))) {\n        client *c = listNodeValue(ln);\n        if (c->flags & CLIENT_BLOCKED && c->bstate.btype == BLOCKED_SHUTDOWN) {\n            addReplyError(c, \"Errors trying to SHUTDOWN. Check logs.\");\n            unblockClient(c, 1);\n        }\n    }\n}\n\n/* Mass-unblock clients because something changed in the instance that makes\n * blocking no longer safe. For example clients blocked in list operations\n * in an instance which turns from master to slave is unsafe, so this function\n * is called when a master turns into a slave.\n *\n * The semantics is to send an -UNBLOCKED error to the client, disconnecting\n * it at the same time. */\nvoid disconnectAllBlockedClients(void) {\n    listNode *ln;\n    listIter li;\n\n    listRewind(server.clients,&li);\n    while((ln = listNext(&li))) {\n        client *c = listNodeValue(ln);\n\n        if (c->flags & CLIENT_BLOCKED) {\n            /* POSTPONEd clients are an exception, when they'll be unblocked, the\n             * command processing will start from scratch, and the command will\n             * be either executed or rejected. (unlike LIST blocked clients for\n             * which the command is already in progress in a way. */\n            if (c->bstate.btype == BLOCKED_POSTPONE)\n                continue;\n\n            unblockClientOnError(c,\n                \"-UNBLOCKED force unblock from blocking operation, \"\n                \"instance state changed (master -> replica?)\");\n            c->flags |= CLIENT_CLOSE_AFTER_REPLY;\n        }\n    }\n}\n\n/* This function should be called by Redis every time a single command,\n * a MULTI/EXEC block, or a Lua script, terminated its execution after\n * being called by a client. It handles serving clients blocked in all scenarios\n * where a specific key access requires to block until that key is available.\n *\n * All the keys with at least one client blocked that are signaled as ready\n * are accumulated into the server.ready_keys list. This function will run\n * the list and will serve clients accordingly.\n * Note that the function will iterate again and again (for example as a result of serving BLMOVE\n * we can have new blocking clients to serve because of the PUSH side of BLMOVE.)\n *\n * This function is normally \"fair\", that is, it will serve clients\n * using a FIFO behavior. However this fairness is violated in certain\n * edge cases, that is, when we have clients blocked at the same time\n * in a sorted set and in a list, for the same key (a very odd thing to\n * do client side, indeed!). Because mismatching clients (blocking for\n * a different type compared to the current key type) are moved in the\n * other side of the linked list. However as long as the key starts to\n * be used only for a single type, like virtually any Redis application will\n * do, the function is already fair. */\nvoid handleClientsBlockedOnKeys(void) {\n\n    /* In case we are already in the process of unblocking clients we should\n     * not make a recursive call, in order to prevent breaking fairness. */\n    static int in_handling_blocked_clients = 0;\n    if (in_handling_blocked_clients)\n        return;\n    in_handling_blocked_clients = 1;\n\n    /* This function is called only when also_propagate is in its basic state\n     * (i.e. not from call(), module context, etc.) */\n    serverAssert(server.also_propagate.numops == 0);\n\n    /* If a command being unblocked causes another command to get unblocked,\n     * like a BLMOVE would do, then the new unblocked command will get processed\n     * right away rather than wait for later. */\n    while(listLength(server.ready_keys) != 0) {\n        list *l;\n\n        /* Point server.ready_keys to a fresh list and save the current one\n         * locally. This way as we run the old list we are free to call\n         * signalKeyAsReady() that may push new elements in server.ready_keys\n         * when handling clients blocked into BLMOVE. */\n        l = server.ready_keys;\n        server.ready_keys = listCreate();\n\n        while(listLength(l) != 0) {\n            listNode *ln = listFirst(l);\n            readyList *rl = ln->value;\n\n            /* First of all remove this key from db->ready_keys so that\n             * we can safely call signalKeyAsReady() against this key. */\n            dictDelete(rl->db->ready_keys,rl->key);\n\n            handleClientsBlockedOnKey(rl);\n\n            /* Free this item. */\n            decrRefCount(rl->key);\n            zfree(rl);\n            listDelNode(l,ln);\n        }\n        listRelease(l); /* We have the new list on place at this point. */\n    }\n    in_handling_blocked_clients = 0;\n}\n\n/* Set a client in blocking mode for the specified key, with the specified timeout.\n * The 'type' argument is BLOCKED_LIST,BLOCKED_ZSET or BLOCKED_STREAM depending on the kind of operation we are\n * waiting for an empty key in order to awake the client. The client is blocked\n * for all the 'numkeys' keys as in the 'keys' argument.\n * The client will unblocked as soon as one of the keys in 'keys' value was updated.\n * the parameter unblock_on_nokey can be used to force client to be unblocked even in the case the key\n * is updated to become unavailable, either by type change (override), deletion or swapdb */\nvoid blockForKeys(client *c, int btype, robj **keys, int numkeys, mstime_t timeout, int unblock_on_nokey) {\n    dictEntry *db_blocked_entry, *db_blocked_existing_entry, *client_blocked_entry;\n    list *l;\n    int j;\n\n    if (!(c->flags & CLIENT_REPROCESSING_COMMAND)) {\n        /* If the client is re-processing the command, we do not set the timeout\n         * because we need to retain the client's original timeout. */\n        c->bstate.timeout = timeout;\n    }\n\n    for (j = 0; j < numkeys; j++) {\n        /* If the key already exists in the dictionary ignore it. */\n        if (!(client_blocked_entry = dictAddRaw(c->bstate.keys,keys[j],NULL))) {\n            continue;\n        }\n        incrRefCount(keys[j]);\n\n        /* And in the other \"side\", to map keys -> clients */\n        db_blocked_entry = dictAddRaw(c->db->blocking_keys,keys[j], &db_blocked_existing_entry);\n\n        /* In case key[j] did not have blocking clients yet, we need to create a new list */\n        if (db_blocked_entry != NULL) {\n            l = listCreate();\n            dictSetVal(c->db->blocking_keys, db_blocked_entry, l);\n            incrRefCount(keys[j]);\n        } else {\n            l = dictGetVal(db_blocked_existing_entry);\n        }\n        listAddNodeTail(l,c);\n        dictSetVal(c->bstate.keys,client_blocked_entry,listLast(l));\n\n        /* We need to add the key to blocking_keys_unblock_on_nokey, if the client\n         * wants to be awakened if key is deleted (like XREADGROUP) */\n        if (unblock_on_nokey) {\n            db_blocked_entry = dictAddRaw(c->db->blocking_keys_unblock_on_nokey, keys[j], &db_blocked_existing_entry);\n            if (db_blocked_entry) {\n                incrRefCount(keys[j]);\n                dictSetUnsignedIntegerVal(db_blocked_entry, 1);\n            } else {\n                dictIncrUnsignedIntegerVal(db_blocked_existing_entry, 1);\n            }\n"}], "code": "void unblockClientOnTimeout(client *c) {\n    /* The client has been unlocked (in the moduleUnblocked list), return ASAP. */\n    if (c->bstate.btype == BLOCKED_MODULE && isModuleClientUnblocked(c)) return;\n\n    replyToBlockedClientTimedOut(c);\n    if (c->flags & CLIENT_PENDING_COMMAND)\n        c->flags &= ~CLIENT_PENDING_COMMAND;\n    unblockClient(c, 1);\n}\n"}, "1D2EBFAEB02EB387": {"calls": [{"id": "E825123C21A944A9", "name": "listAddNodeHead", "path": "redis/src/adlist.c", "start": {"line": 91, "col": 1}, "end": {"line": 100, "col": 1}, "code": "{\n    listNode *node;\n\n    if ((node = zmalloc(sizeof(*node))) == NULL)\n        return NULL;\n    node->value = value;\n    listLinkNodeHead(list, node);\n    return list;\n}\n\n/*\n * Add a node that has already been allocated to the head of list\n */\nvoid listLinkNodeHead(list* list, listNode *node) {\n    if (list->len == 0) {\n        list->head = list->tail = node;\n        node->prev = node->next = NULL;\n    } else {\n        node->prev = NULL;\n        node->next = list->head;\n        list->head->prev = node;\n        list->head = node;\n    }\n    list->len++;\n}\n\n/* Add a new node to the list, to tail, containing the specified 'value'\n * pointer as value.\n *\n * On error, NULL is returned and no operation is performed (i.e. the\n * list remains unaltered).\n * On success the 'list' pointer you pass to the function is returned. */\nlist *listAddNodeTail(list *list, void *value)\n{\n    listNode *node;\n\n    if ((node = zmalloc(sizeof(*node))) == NULL)\n        return NULL;\n    node->value = value;\n    listLinkNodeTail(list, node);\n    return list;\n}\n\n/*\n * Add a node that has already been allocated to the tail of list\n */\nvoid listLinkNodeTail(list *list, listNode *node) {\n    if (list->len == 0) {\n        list->head = list->tail = node;\n        node->prev = node->next = NULL;\n    } else {\n        node->prev = list->tail;\n        node->next = NULL;\n        list->tail->next = node;\n        list->tail = node;\n    }\n    list->len++;\n}\n\nlist *listInsertNode(list *list, listNode *old_node, void *value, int after) {\n    listNode *node;\n\n    if ((node = zmalloc(sizeof(*node))) == NULL)\n        return NULL;\n    node->value = value;\n    if (after) {\n        node->prev = old_node;\n        node->next = old_node->next;\n        if (list->tail == old_node) {\n            list->tail = node;\n        }\n    } else {\n        node->next = old_node;\n        node->prev = old_node->prev;\n        if (list->head == old_node) {\n            list->head = node;\n        }\n    }\n    if (node->prev != NULL) {\n        node->prev->next = node;\n    }\n    if (node->next != NULL) {\n        node->next->prev = node;\n    }\n    list->len++;\n    return list;\n}\n\n/* Remove the specified node from the specified list.\n * The node is freed. If free callback is provided the value is freed as well.\n *\n * This function can't fail. */\nvoid listDelNode(list *list, listNode *node)\n{\n    listUnlinkNode(list, node);\n    if (list->free) list->free(node->value);\n    zfree(node);\n}\n\n/*\n * Remove the specified node from the list without freeing it.\n"}, {"id": "52FB033A1653FBBB", "name": "slowlogCreateEntry", "path": "redis/src/slowlog.c", "start": {"line": 48, "col": 1}, "end": {"line": 94, "col": 1}, "code": "    slowlogEntry *se = zmalloc(sizeof(*se));\n    int j, slargc = argc;\n\n    if (slargc > SLOWLOG_ENTRY_MAX_ARGC) slargc = SLOWLOG_ENTRY_MAX_ARGC;\n    se->argc = slargc;\n    se->argv = zmalloc(sizeof(robj*)*slargc);\n    for (j = 0; j < slargc; j++) {\n        /* Logging too many arguments is a useless memory waste, so we stop\n         * at SLOWLOG_ENTRY_MAX_ARGC, but use the last argument to specify\n         * how many remaining arguments there were in the original command. */\n        if (slargc != argc && j == slargc-1) {\n            se->argv[j] = createObject(OBJ_STRING,\n                sdscatprintf(sdsempty(),\"... (%d more arguments)\",\n                argc-slargc+1));\n        } else {\n            /* Trim too long strings as well... */\n            if (argv[j]->type == OBJ_STRING &&\n                sdsEncodedObject(argv[j]) &&\n                sdslen(argv[j]->ptr) > SLOWLOG_ENTRY_MAX_STRING)\n            {\n                sds s = sdsnewlen(argv[j]->ptr, SLOWLOG_ENTRY_MAX_STRING);\n\n                s = sdscatprintf(s,\"... (%lu more bytes)\",\n                    (unsigned long)\n                    sdslen(argv[j]->ptr) - SLOWLOG_ENTRY_MAX_STRING);\n                se->argv[j] = createObject(OBJ_STRING,s);\n            } else if (argv[j]->refcount == OBJ_SHARED_REFCOUNT) {\n                se->argv[j] = argv[j];\n            } else {\n                /* Here we need to duplicate the string objects composing the\n                 * argument vector of the command, because those may otherwise\n                 * end shared with string objects stored into keys. Having\n                 * shared objects between any part of Redis, and the data\n                 * structure holding the data, is a problem: FLUSHALL ASYNC\n                 * may release the shared string object and create a race. */\n                se->argv[j] = dupStringObject(argv[j]);\n            }\n        }\n    }\n    se->time = time(NULL);\n    se->duration = duration;\n    se->id = server.slowlog_entry_id++;\n    se->peerid = sdsnew(getClientPeerId(c));\n    se->cname = c->name ? sdsnew(c->name->ptr) : sdsempty();\n    return se;\n}\n\n/* Free a slow log entry. The argument is void so that the prototype of this\n * function matches the one of the 'free' method of adlist.c.\n *\n * This function will take care to release all the retained object. */\nvoid slowlogFreeEntry(void *septr) {\n    slowlogEntry *se = septr;\n    int j;\n\n    for (j = 0; j < se->argc; j++)\n        decrRefCount(se->argv[j]);\n    zfree(se->argv);\n    sdsfree(se->peerid);\n    sdsfree(se->cname);\n    zfree(se);\n}\n\n/* Initialize the slow log. This function should be called a single time\n * at server startup. */\nvoid slowlogInit(void) {\n    server.slowlog = listCreate();\n    server.slowlog_entry_id = 0;\n    listSetFreeMethod(server.slowlog,slowlogFreeEntry);\n}\n\n/* Push a new entry into the slow log.\n * This function will make sure to trim the slow log accordingly to the\n * configured max length. */\nvoid slowlogPushEntryIfNeeded(client *c, robj **argv, int argc, long long duration) {\n    if (server.slowlog_log_slower_than < 0 || server.slowlog_max_len == 0) return; /* Slowlog disabled */\n    if (duration >= server.slowlog_log_slower_than)\n        listAddNodeHead(server.slowlog,\n                        slowlogCreateEntry(c,argv,argc,duration));\n\n    /* Remove old entries if needed. */\n    while (listLength(server.slowlog) > server.slowlog_max_len)\n        listDelNode(server.slowlog,listLast(server.slowlog));\n}\n\n/* Remove all the entries from the current slow log. */\nvoid slowlogReset(void) {\n    while (listLength(server.slowlog) > 0)\n        listDelNode(server.slowlog,listLast(server.slowlog));\n}\n\n/* The SLOWLOG command. Implements all the subcommands needed to handle the\n * Redis slow log. */\nvoid slowlogCommand(client *c) {\n    if (c->argc == 2 && !strcasecmp(c->argv[1]->ptr,\"help\")) {\n"}, {"id": "09D79C066D48D03C", "name": "listDelNode", "path": "redis/src/adlist.c", "start": {"line": 184, "col": 1}, "end": {"line": 189, "col": 1}, "code": "{\n    listUnlinkNode(list, node);\n    if (list->free) list->free(node->value);\n    zfree(node);\n}\n\n/*\n * Remove the specified node from the list without freeing it.\n */\nvoid listUnlinkNode(list *list, listNode *node) {\n    if (node->prev)\n        node->prev->next = node->next;\n    else\n        list->head = node->next;\n    if (node->next)\n        node->next->prev = node->prev;\n    else\n        list->tail = node->prev;\n\n    node->next = NULL;\n    node->prev = NULL;\n\n    list->len--;\n}\n\n/* Returns a list iterator 'iter'. After the initialization every\n * call to listNext() will return the next element of the list.\n *\n * This function can't fail. */\nlistIter *listGetIterator(list *list, int direction)\n{\n    listIter *iter;\n\n    if ((iter = zmalloc(sizeof(*iter))) == NULL) return NULL;\n    if (direction == AL_START_HEAD)\n        iter->next = list->head;\n    else\n        iter->next = list->tail;\n    iter->direction = direction;\n    return iter;\n}\n\n/* Release the iterator memory */\nvoid listReleaseIterator(listIter *iter) {\n    zfree(iter);\n}\n\n/* Create an iterator in the list private iterator structure */\nvoid listRewind(list *list, listIter *li) {\n    li->next = list->head;\n    li->direction = AL_START_HEAD;\n}\n\nvoid listRewindTail(list *list, listIter *li) {\n    li->next = list->tail;\n    li->direction = AL_START_TAIL;\n}\n\n/* Return the next element of an iterator.\n * It's valid to remove the currently returned element using\n * listDelNode(), but not to remove other elements.\n *\n * The function returns a pointer to the next element of the list,\n * or NULL if there are no more elements, so the classical usage\n * pattern is:\n *\n * iter = listGetIterator(list,<direction>);\n * while ((node = listNext(iter)) != NULL) {\n *     doSomethingWith(listNodeValue(node));\n * }\n *\n * */\nlistNode *listNext(listIter *iter)\n{\n    listNode *current = iter->next;\n\n    if (current != NULL) {\n        if (iter->direction == AL_START_HEAD)\n            iter->next = current->next;\n        else\n            iter->next = current->prev;\n    }\n    return current;\n}\n\n/* Duplicate the whole list. On out of memory NULL is returned.\n * On success a copy of the original list is returned.\n *\n * The 'Dup' method set with listSetDupMethod() function is used\n * to copy the node value. Otherwise the same pointer value of\n * the original node is used as value of the copied node.\n *\n * The original list both on success or error is never modified. */\nlist *listDup(list *orig)\n{\n    list *copy;\n    listIter iter;\n    listNode *node;\n\n    if ((copy = listCreate()) == NULL)\n        return NULL;\n    copy->dup = orig->dup;\n    copy->free = orig->free;\n    copy->match = orig->match;\n    listRewind(orig, &iter);\n    while((node = listNext(&iter)) != NULL) {\n        void *value;\n\n        if (copy->dup) {\n            value = copy->dup(node->value);\n            if (value == NULL) {\n                listRelease(copy);\n                return NULL;\n            }\n        } else {\n            value = node->value;\n        }\n        \n        if (listAddNodeTail(copy, value) == NULL) {\n            /* Free value if dup succeed but listAddNodeTail failed. */\n            if (copy->free) copy->free(value);\n\n            listRelease(copy);\n            return NULL;\n        }\n    }\n    return copy;\n}\n\n/* Search the list for a node matching a given key.\n * The match is performed using the 'match' method\n * set with listSetMatchMethod(). If no 'match' method\n * is set, the 'value' pointer of every node is directly\n * compared with the 'key' pointer.\n *\n * On success the first matching node pointer is returned\n * (search starts from head). If no matching node exists\n * NULL is returned. */\nlistNode *listSearchKey(list *list, void *key)\n{\n    listIter iter;\n    listNode *node;\n\n    listRewind(list, &iter);\n    while((node = listNext(&iter)) != NULL) {\n        if (list->match) {\n            if (list->match(node->value, key)) {\n                return node;\n            }\n        } else {\n            if (key == node->value) {\n                return node;\n            }\n        }\n    }\n    return NULL;\n}\n\n/* Return the element at the specified zero-based index\n * where 0 is the head, 1 is the element next to head\n * and so on. Negative integers are used in order to count\n * from the tail, -1 is the last element, -2 the penultimate\n * and so on. If the index is out of range NULL is returned. */\nlistNode *listIndex(list *list, long index) {\n    listNode *n;\n\n    if (index < 0) {\n        index = (-index)-1;\n        n = list->tail;\n        while(index-- && n) n = n->prev;\n    } else {\n        n = list->head;\n        while(index-- && n) n = n->next;\n    }\n    return n;\n}\n\n/* Rotate the list removing the tail node and inserting it to the head. */\nvoid listRotateTailToHead(list *list) {\n    if (listLength(list) <= 1) return;\n\n    /* Detach current tail */\n    listNode *tail = list->tail;\n    list->tail = tail->prev;\n    list->tail->next = NULL;\n    /* Move it as head */\n    list->head->prev = tail;\n    tail->prev = NULL;\n    tail->next = list->head;\n    list->head = tail;\n"}], "code": "void slowlogPushEntryIfNeeded(client *c, robj **argv, int argc, long long duration) {\n    if (server.slowlog_log_slower_than < 0 || server.slowlog_max_len == 0) return; /* Slowlog disabled */\n    if (duration >= server.slowlog_log_slower_than)\n        listAddNodeHead(server.slowlog,\n                        slowlogCreateEntry(c,argv,argc,duration));\n\n    /* Remove old entries if needed. */\n    while (listLength(server.slowlog) > server.slowlog_max_len)\n        listDelNode(server.slowlog,listLast(server.slowlog));\n}\n"}, "34E0B83C2E59A0E6": {"calls": [{"id": "67AE58D70D0E2562", "name": "getClientType", "path": "redis/src/networking.c", "start": {"line": 3862, "col": 1}, "end": {"line": 3870, "col": 1}, "code": "    if (c->flags & CLIENT_MASTER) return CLIENT_TYPE_MASTER;\n    /* Even though MONITOR clients are marked as replicas, we\n     * want the expose them as normal clients. */\n    if ((c->flags & CLIENT_SLAVE) && !(c->flags & CLIENT_MONITOR))\n        return CLIENT_TYPE_SLAVE;\n    if (c->flags & CLIENT_PUBSUB) return CLIENT_TYPE_PUBSUB;\n    return CLIENT_TYPE_NORMAL;\n}\n\nint getClientTypeByName(char *name) {\n    if (!strcasecmp(name,\"normal\")) return CLIENT_TYPE_NORMAL;\n    else if (!strcasecmp(name,\"slave\")) return CLIENT_TYPE_SLAVE;\n    else if (!strcasecmp(name,\"replica\")) return CLIENT_TYPE_SLAVE;\n    else if (!strcasecmp(name,\"pubsub\")) return CLIENT_TYPE_PUBSUB;\n    else if (!strcasecmp(name,\"master\")) return CLIENT_TYPE_MASTER;\n    else return -1;\n}\n\nchar *getClientTypeName(int class) {\n    switch(class) {\n    case CLIENT_TYPE_NORMAL: return \"normal\";\n    case CLIENT_TYPE_SLAVE:  return \"slave\";\n    case CLIENT_TYPE_PUBSUB: return \"pubsub\";\n    case CLIENT_TYPE_MASTER: return \"master\";\n    default:                       return NULL;\n    }\n}\n\n/* The function checks if the client reached output buffer soft or hard\n * limit, and also update the state needed to check the soft limit as\n * a side effect.\n *\n * Return value: non-zero if the client reached the soft or the hard limit.\n *               Otherwise zero is returned. */\nint checkClientOutputBufferLimits(client *c) {\n    int soft = 0, hard = 0, class;\n    unsigned long used_mem = getClientOutputBufferMemoryUsage(c);\n\n    class = getClientType(c);\n    /* For the purpose of output buffer limiting, masters are handled\n     * like normal clients. */\n    if (class == CLIENT_TYPE_MASTER) class = CLIENT_TYPE_NORMAL;\n\n    /* Note that it doesn't make sense to set the replica clients output buffer\n     * limit lower than the repl-backlog-size config (partial sync will succeed\n     * and then replica will get disconnected).\n     * Such a configuration is ignored (the size of repl-backlog-size will be used).\n     * This doesn't have memory consumption implications since the replica client\n     * will share the backlog buffers memory. */\n    size_t hard_limit_bytes = server.client_obuf_limits[class].hard_limit_bytes;\n    if (class == CLIENT_TYPE_SLAVE && hard_limit_bytes &&\n        (long long)hard_limit_bytes < server.repl_backlog_size)\n        hard_limit_bytes = server.repl_backlog_size;\n    if (server.client_obuf_limits[class].hard_limit_bytes &&\n        used_mem >= hard_limit_bytes)\n        hard = 1;\n    if (server.client_obuf_limits[class].soft_limit_bytes &&\n        used_mem >= server.client_obuf_limits[class].soft_limit_bytes)\n        soft = 1;\n\n    /* We need to check if the soft limit is reached continuously for the\n     * specified amount of seconds. */\n    if (soft) {\n        if (c->obuf_soft_limit_reached_time == 0) {\n            c->obuf_soft_limit_reached_time = server.unixtime;\n            soft = 0; /* First time we see the soft limit reached */\n        } else {\n            time_t elapsed = server.unixtime - c->obuf_soft_limit_reached_time;\n\n            if (elapsed <=\n                server.client_obuf_limits[class].soft_limit_seconds) {\n                soft = 0; /* The client still did not reached the max number of\n                             seconds for the soft limit to be considered\n                             reached. */\n            }\n        }\n    } else {\n        c->obuf_soft_limit_reached_time = 0;\n    }\n    return soft || hard;\n}\n\n/* Asynchronously close a client if soft or hard limit is reached on the\n * output buffer size. The caller can check if the client will be closed\n * checking if the client CLIENT_CLOSE_ASAP flag is set.\n *\n * Note: we need to close the client asynchronously because this function is\n * called from contexts where the client can't be freed safely, i.e. from the\n * lower level functions pushing data inside the client output buffers.\n * When `async` is set to 0, we close the client immediately, this is\n * useful when called from cron.\n *\n * Returns 1 if client was (flagged) closed. */\nint closeClientOnOutputBufferLimitReached(client *c, int async) {\n    if (!c->conn) return 0; /* It is unsafe to free fake clients. */\n    serverAssert(c->reply_bytes < SIZE_MAX-(1024*64));\n    /* Note that c->reply_bytes is irrelevant for replica clients\n     * (they use the global repl buffers). */\n    if ((c->reply_bytes == 0 && getClientType(c) != CLIENT_TYPE_SLAVE) ||\n        c->flags & CLIENT_CLOSE_ASAP) return 0;\n    if (checkClientOutputBufferLimits(c)) {\n        sds client = catClientInfoString(sdsempty(),c);\n\n        if (async) {\n            freeClientAsync(c);\n            serverLog(LL_WARNING,\n                      \"Client %s scheduled to be closed ASAP for overcoming of output buffer limits.\",\n                      client);\n        } else {\n            freeClient(c);\n            serverLog(LL_WARNING,\n                      \"Client %s closed for overcoming of output buffer limits.\",\n                      client);\n        }\n        sdsfree(client);\n        server.stat_client_outbuf_limit_disconnections++;\n        return  1;\n    }\n    return 0;\n}\n\n/* Helper function used by performEvictions() in order to flush slaves\n * output buffers without returning control to the event loop.\n * This is also called by SHUTDOWN for a best-effort attempt to send\n * slaves the latest writes. */\nvoid flushSlavesOutputBuffers(void) {\n    listIter li;\n    listNode *ln;\n\n    listRewind(server.slaves,&li);\n    while((ln = listNext(&li))) {\n        client *slave = listNodeValue(ln);\n        int can_receive_writes = connHasWriteHandler(slave->conn) ||\n                                 (slave->flags & CLIENT_PENDING_WRITE);\n\n        /* We don't want to send the pending data to the replica in a few\n         * cases:\n         *\n         * 1. For some reason there is neither the write handler installed\n         *    nor the client is flagged as to have pending writes: for some\n         *    reason this replica may not be set to receive data. This is\n         *    just for the sake of defensive programming.\n         *\n         * 2. The put_online_on_ack flag is true. To know why we don't want\n         *    to send data to the replica in this case, please grep for the\n         *    flag for this flag.\n         *\n         * 3. Obviously if the slave is not ONLINE.\n         */\n        if (slave->replstate == SLAVE_STATE_ONLINE &&\n            !(slave->flags & CLIENT_CLOSE_ASAP) &&\n            can_receive_writes &&\n            !slave->repl_start_cmd_stream_on_ack &&\n            clientHasPendingReplies(slave))\n        {\n            writeToClient(slave,0);\n        }\n    }\n}\n\n/* Compute current paused actions and its end time, aggregated for\n * all pause purposes. */\nvoid updatePausedActions(void) {\n    uint32_t prev_paused_actions = server.paused_actions;\n    server.paused_actions = 0;\n\n    for (int i = 0; i < NUM_PAUSE_PURPOSES; i++) {\n        pause_event *p = &(server.client_pause_per_purpose[i]);\n        if (p->end > server.mstime)\n            server.paused_actions |= p->paused_actions;\n        else {\n            p->paused_actions = 0;\n            p->end = 0;\n        }\n    }\n\n    /* If the pause type is less restrictive than before, we unblock all clients\n     * so they are reprocessed (may get re-paused). */\n    uint32_t mask_cli = (PAUSE_ACTION_CLIENT_WRITE|PAUSE_ACTION_CLIENT_ALL);\n    if ((server.paused_actions & mask_cli) < (prev_paused_actions & mask_cli)) {\n        unblockPostponedClients();\n    }\n}\n\n/* Unblock all paused clients (ones that where blocked by BLOCKED_POSTPONE (possibly in processCommand).\n * This means they'll get re-processed in beforeSleep, and may get paused again if needed. */\nvoid unblockPostponedClients(void) {\n    listNode *ln;\n    listIter li;\n    listRewind(server.postponed_clients, &li);\n    while ((ln = listNext(&li)) != NULL) {\n        client *c = listNodeValue(ln);\n        unblockClient(c, 1);\n    }\n}\n\n/* Set pause-client end-time and restricted action. If already paused, then:\n * 1. Keep higher end-time value between configured and the new one\n * 2. Keep most restrictive action between configured and the new one */\nstatic void pauseClientsByClient(mstime_t endTime, int isPauseClientAll) {\n    uint32_t actions;\n    pause_event *p = &server.client_pause_per_purpose[PAUSE_BY_CLIENT_COMMAND];\n\n    if (isPauseClientAll)\n        actions = PAUSE_ACTIONS_CLIENT_ALL_SET;\n    else {\n        actions = PAUSE_ACTIONS_CLIENT_WRITE_SET;\n        /* If currently configured most restrictive client pause, then keep it */\n        if (p->paused_actions & PAUSE_ACTION_CLIENT_ALL)\n            actions = PAUSE_ACTIONS_CLIENT_ALL_SET;\n    }\n    \n    pauseActions(PAUSE_BY_CLIENT_COMMAND, endTime, actions);\n}\n\n/* Pause actions up to the specified unixtime (in ms) for a given type of\n * commands.\n *\n * A main use case of this function is to allow pausing replication traffic\n * so that a failover without data loss to occur. Replicas will continue to receive\n * traffic to facilitate this functionality.\n * \n * This function is also internally used by Redis Cluster for the manual\n * failover procedure implemented by CLUSTER FAILOVER.\n *\n * The function always succeed, even if there is already a pause in progress.\n * The new paused_actions of a given 'purpose' will override the old ones and\n * end time will be updated if new end time is bigger than currently configured */\nvoid pauseActions(pause_purpose purpose, mstime_t end, uint32_t actions) {\n    /* Manage pause type and end time per pause purpose. */\n    server.client_pause_per_purpose[purpose].paused_actions = actions;\n\n    /* If currently configured end time bigger than new one, then keep it */\n    if (server.client_pause_per_purpose[purpose].end < end)\n        server.client_pause_per_purpose[purpose].end = end;\n\n    updatePausedActions();\n\n    /* We allow write commands that were queued\n     * up before and after to execute. We need\n     * to track this state so that we don't assert\n     * in propagateNow(). */\n    if (server.in_exec) {\n        server.client_pause_in_transaction = 1;\n    }\n}\n\n/* Unpause actions and queue them for reprocessing. */\nvoid unpauseActions(pause_purpose purpose) {\n    server.client_pause_per_purpose[purpose].end = 0;\n    server.client_pause_per_purpose[purpose].paused_actions = 0;\n    updatePausedActions();\n}\n\n/* Returns bitmask of paused actions */\nuint32_t isPausedActions(uint32_t actions_bitmask) {\n    return (server.paused_actions & actions_bitmask);\n}\n\n/* Returns bitmask of paused actions */\nuint32_t isPausedActionsWithUpdate(uint32_t actions_bitmask) {\n    if (!(server.paused_actions & actions_bitmask)) return 0;\n    updatePausedActions();\n    return (server.paused_actions & actions_bitmask);\n}\n\n/* This function is called by Redis in order to process a few events from\n * time to time while blocked into some not interruptible operation.\n * This allows to reply to clients with the -LOADING error while loading the\n * data set at startup or after a full resynchronization with the master\n * and so forth.\n *\n * It calls the event loop in order to process a few events. Specifically we\n * try to call the event loop 4 times as long as we receive acknowledge that\n * some event was processed, in order to go forward with the accept, read,\n * write, close sequence needed to serve a client.\n *\n * The function returns the total number of events processed. */\nvoid processEventsWhileBlocked(void) {\n    int iterations = 4; /* See the function top-comment. */\n\n    /* Update our cached time since it is used to create and update the last\n     * interaction time with clients and for other important things. */\n    updateCachedTime(0);\n\n    /* For the few commands that are allowed during busy scripts, we rather\n     * provide a fresher time than the one from when the script started (they\n     * still won't get it from the call due to execution_nesting. For commands\n     * during loading this doesn't matter. */\n    mstime_t prev_cmd_time_snapshot = server.cmd_time_snapshot;\n    server.cmd_time_snapshot = server.mstime;\n\n    /* Note: when we are processing events while blocked (for instance during\n     * busy Lua scripts), we set a global flag. When such flag is set, we\n     * avoid handling the read part of clients using threaded I/O.\n     * See https://github.com/redis/redis/issues/6988 for more info.\n     * Note that there could be cases of nested calls to this function,\n     * specifically on a busy script during async_loading rdb, and scripts\n     * that came from AOF. */\n    ProcessingEventsWhileBlocked++;\n    while (iterations--) {\n        long long startval = server.events_processed_while_blocked;\n        long long ae_events = aeProcessEvents(server.el,\n            AE_FILE_EVENTS|AE_DONT_WAIT|\n            AE_CALL_BEFORE_SLEEP|AE_CALL_AFTER_SLEEP);\n        /* Note that server.events_processed_while_blocked will also get\n         * incremented by callbacks called by the event loop handlers. */\n        server.events_processed_while_blocked += ae_events;\n        long long events = server.events_processed_while_blocked - startval;\n        if (!events) break;\n    }\n\n    whileBlockedCron();\n\n    ProcessingEventsWhileBlocked--;\n    serverAssert(ProcessingEventsWhileBlocked >= 0);\n\n    server.cmd_time_snapshot = prev_cmd_time_snapshot;\n}\n\n/* ==========================================================================\n * Threaded I/O\n * ========================================================================== */\n\n#define IO_THREADS_MAX_NUM 128\n"}], "code": "void updateClientMemoryUsage(client *c) {\n    serverAssert(c->conn);\n    size_t mem = getClientMemoryUsage(c, NULL);\n    int type = getClientType(c);\n    /* Now that we have the memory used by the client, remove the old\n     * value from the old category, and add it back. */\n    server.stat_clients_type_memory[c->last_memory_type] -= c->last_memory_usage;\n    server.stat_clients_type_memory[type] += mem;\n    /* Remember what we added and where, to remove it next time. */\n    c->last_memory_type = type;\n    c->last_memory_usage = mem;\n}\n"}, "6F0C31DFFEC181FB": {"calls": [{"id": "0D52ADAC56D29522", "name": "sdslen", "path": "redis/src/sds.h", "start": {"line": 87, "col": 1}, "end": {"line": 102, "col": 1}, "code": "    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            return SDS_TYPE_5_LEN(flags);\n        case SDS_TYPE_8:\n            return SDS_HDR(8,s)->len;\n        case SDS_TYPE_16:\n            return SDS_HDR(16,s)->len;\n        case SDS_TYPE_32:\n            return SDS_HDR(32,s)->len;\n        case SDS_TYPE_64:\n            return SDS_HDR(64,s)->len;\n    }\n    return 0;\n}\n\nstatic inline size_t sdsavail(const sds s) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5: {\n            return 0;\n        }\n        case SDS_TYPE_8: {\n            SDS_HDR_VAR(8,s);\n            return sh->alloc - sh->len;\n        }\n        case SDS_TYPE_16: {\n            SDS_HDR_VAR(16,s);\n            return sh->alloc - sh->len;\n        }\n        case SDS_TYPE_32: {\n            SDS_HDR_VAR(32,s);\n            return sh->alloc - sh->len;\n        }\n        case SDS_TYPE_64: {\n            SDS_HDR_VAR(64,s);\n            return sh->alloc - sh->len;\n        }\n    }\n    return 0;\n}\n\nstatic inline void sdssetlen(sds s, size_t newlen) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            {\n                unsigned char *fp = ((unsigned char*)s)-1;\n                *fp = SDS_TYPE_5 | (newlen << SDS_TYPE_BITS);\n            }\n            break;\n        case SDS_TYPE_8:\n            SDS_HDR(8,s)->len = newlen;\n            break;\n        case SDS_TYPE_16:\n            SDS_HDR(16,s)->len = newlen;\n            break;\n        case SDS_TYPE_32:\n            SDS_HDR(32,s)->len = newlen;\n            break;\n        case SDS_TYPE_64:\n            SDS_HDR(64,s)->len = newlen;\n            break;\n    }\n}\n\nstatic inline void sdsinclen(sds s, size_t inc) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            {\n                unsigned char *fp = ((unsigned char*)s)-1;\n                unsigned char newlen = SDS_TYPE_5_LEN(flags)+inc;\n                *fp = SDS_TYPE_5 | (newlen << SDS_TYPE_BITS);\n            }\n            break;\n        case SDS_TYPE_8:\n            SDS_HDR(8,s)->len += inc;\n            break;\n        case SDS_TYPE_16:\n            SDS_HDR(16,s)->len += inc;\n            break;\n        case SDS_TYPE_32:\n            SDS_HDR(32,s)->len += inc;\n            break;\n        case SDS_TYPE_64:\n            SDS_HDR(64,s)->len += inc;\n            break;\n    }\n}\n\n/* sdsalloc() = sdsavail() + sdslen() */\nstatic inline size_t sdsalloc(const sds s) {\n    unsigned char flags = s[-1];\n    switch(flags&SDS_TYPE_MASK) {\n        case SDS_TYPE_5:\n            return SDS_TYPE_5_LEN(flags);\n        case SDS_TYPE_8:\n            return SDS_HDR(8,s)->alloc;\n        case SDS_TYPE_16:\n            return SDS_HDR(16,s)->alloc;\n        case SDS_TYPE_32:\n            return SDS_HDR(32,s)->alloc;\n"}], "code": "streamCG *streamLookupCG(stream *s, sds groupname) {\n    if (s->cgroups == NULL) return NULL;\n    void *cg = NULL;\n    raxFind(s->cgroups,(unsigned char*)groupname,sdslen(groupname),&cg);\n    return cg;\n}\n"}, "561120EE41B27B2E": {"calls": [{"id": "17EAEED34BD8D63D", "name": "elapsedStart", "path": "redis/src/monotonic.h", "start": {"line": 49, "col": 1}, "end": {"line": 51, "col": 1}, "code": "    *start_time = getMonotonicUs();\n}\n\nstatic inline uint64_t elapsedUs(monotime start_time) {\n    return getMonotonicUs() - start_time;\n}\n\nstatic inline uint64_t elapsedMs(monotime start_time) {\n    return elapsedUs(start_time) / 1000;\n}\n\n#endif\n"}, {"id": "8B9ED28546C6EDF9", "name": "dictRehash", "path": "redis/src/dict.c", "start": {"line": 373, "col": 1}, "end": {"line": 402, "col": 1}, "code": "    int empty_visits = n*10; /* Max number of empty buckets to visit. */\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n\n    while(n-- && d->ht_used[0] != 0) {\n        /* Note that rehashidx can't overflow as we are sure there are more\n         * elements because ht[0].used != 0 */\n        assert(DICTHT_SIZE(d->ht_size_exp[0]) > (unsigned long)d->rehashidx);\n        while(d->ht_table[0][d->rehashidx] == NULL) {\n            d->rehashidx++;\n            if (--empty_visits == 0) return 1;\n        }\n        /* Move all the keys in this bucket from the old to the new hash HT */\n        rehashEntriesInBucketAtIndex(d, d->rehashidx);\n        d->rehashidx++;\n    }\n\n    return !dictCheckRehashingCompleted(d);\n}\n\nlong long timeInMilliseconds(void) {\n    struct timeval tv;\n\n    gettimeofday(&tv,NULL);\n    return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);\n}\n\n/* Rehash in us+\"delta\" microseconds. The value of \"delta\" is larger\n * than 0, and is smaller than 1000 in most cases. The exact upper bound\n * depends on the running time of dictRehash(d,100).*/\nint dictRehashMicroseconds(dict *d, uint64_t us) {\n    if (d->pauserehash > 0) return 0;\n\n    monotime timer;\n    elapsedStart(&timer);\n    int rehashes = 0;\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (elapsedUs(timer) >= us) break;\n    }\n    return rehashes;\n}\n\n/* This function performs just a step of rehashing, and only if hashing has\n * not been paused for our hash table. When we have iterators in the\n * middle of a rehashing we can't mess with the two hash tables otherwise\n * some elements can be missed or duplicated.\n *\n * This function is called by common lookup or update operations in the\n * dictionary so that the hash table automatically migrates from H1 to H2\n * while it is actively used. */\nstatic void _dictRehashStep(dict *d) {\n    if (d->pauserehash == 0) dictRehash(d,1);\n}\n\n/* Performs rehashing on a single bucket. */\nint _dictBucketRehash(dict *d, uint64_t idx) {\n    if (d->pauserehash != 0) return 0;\n    unsigned long s0 = DICTHT_SIZE(d->ht_size_exp[0]);\n    unsigned long s1 = DICTHT_SIZE(d->ht_size_exp[1]);\n    if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;\n    /* If dict_can_resize is DICT_RESIZE_AVOID, we want to avoid rehashing. \n     * - If expanding, the threshold is dict_force_resize_ratio which is 4.\n     * - If shrinking, the threshold is 1 / (HASHTABLE_MIN_FILL * dict_force_resize_ratio) which is 1/32. */\n    if (dict_can_resize == DICT_RESIZE_AVOID && \n        ((s1 > s0 && s1 < dict_force_resize_ratio * s0) ||\n         (s1 < s0 && s0 < HASHTABLE_MIN_FILL * dict_force_resize_ratio * s1)))\n    {\n        return 0;\n    }\n    rehashEntriesInBucketAtIndex(d, idx);\n    dictCheckRehashingCompleted(d);\n    return 1;\n}\n\n/* Add an element to the target hash table */\nint dictAdd(dict *d, void *key, void *val)\n{\n    dictEntry *entry = dictAddRaw(d,key,NULL);\n\n    if (!entry) return DICT_ERR;\n    if (!d->type->no_value) dictSetVal(d, entry, val);\n    return DICT_OK;\n}\n\n/* Low level add or find:\n * This function adds the entry but instead of setting a value returns the\n * dictEntry structure to the user, that will make sure to fill the value\n * field as they wish.\n *\n * This function is also directly exposed to the user API to be called\n * mainly in order to store non-pointers inside the hash value, example:\n *\n * entry = dictAddRaw(dict,mykey,NULL);\n * if (entry != NULL) dictSetSignedIntegerVal(entry,1000);\n *\n * Return values:\n *\n * If key already exists NULL is returned, and \"*existing\" is populated\n * with the existing entry if existing is not NULL.\n *\n * If key was added, the hash entry is returned to be manipulated by the caller.\n */\ndictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)\n{\n    /* Get the position for the new key or NULL if the key already exists. */\n    void *position = dictFindPositionForInsert(d, key, existing);\n    if (!position) return NULL;\n\n    /* Dup the key if necessary. */\n    if (d->type->keyDup) key = d->type->keyDup(d, key);\n\n    return dictInsertAtPosition(d, key, position);\n}\n\n/* Adds a key in the dict's hashtable at the position returned by a preceding\n * call to dictFindPositionForInsert. This is a low level function which allows\n * splitting dictAddRaw in two parts. Normally, dictAddRaw or dictAdd should be\n * used instead. */\ndictEntry *dictInsertAtPosition(dict *d, void *key, void *position) {\n    dictEntry **bucket = position; /* It's a bucket, but the API hides that. */\n    dictEntry *entry;\n    /* If rehashing is ongoing, we insert in table 1, otherwise in table 0.\n     * Assert that the provided bucket is the right table. */\n    int htidx = dictIsRehashing(d) ? 1 : 0;\n    assert(bucket >= &d->ht_table[htidx][0] &&\n           bucket <= &d->ht_table[htidx][DICTHT_SIZE_MASK(d->ht_size_exp[htidx])]);\n    if (d->type->no_value) {\n        if (d->type->keys_are_odd && !*bucket) {\n            /* We can store the key directly in the destination bucket without the\n             * allocated entry.\n             *\n             * TODO: Add a flag 'keys_are_even' and if set, we can use this\n             * optimization for these dicts too. We can set the LSB bit when\n             * stored as a dict entry and clear it again when we need the key\n             * back. */\n            entry = key;\n            assert(entryIsKey(entry));\n        } else {\n            /* Allocate an entry without value. */\n            entry = createEntryNoValue(key, *bucket);\n        }\n    } else {\n        /* Allocate the memory and store the new entry.\n         * Insert the element in top, with the assumption that in a database\n         * system it is more likely that recently added entries are accessed\n         * more frequently. */\n        entry = zmalloc(sizeof(*entry));\n        assert(entryIsNormal(entry)); /* Check alignment of allocation */\n        entry->key = key;\n        entry->next = *bucket;\n    }\n    *bucket = entry;\n    d->ht_used[htidx]++;\n\n    return entry;\n}\n\n/* Add or Overwrite:\n * Add an element, discarding the old value if the key already exists.\n * Return 1 if the key was added from scratch, 0 if there was already an\n * element with such key and dictReplace() just performed a value update\n * operation. */\nint dictReplace(dict *d, void *key, void *val)\n{\n    dictEntry *entry, *existing;\n\n    /* Try to add the element. If the key\n     * does not exists dictAdd will succeed. */\n    entry = dictAddRaw(d,key,&existing);\n    if (entry) {\n        dictSetVal(d, entry, val);\n        return 1;\n    }\n\n    /* Set the new value and free the old one. Note that it is important\n     * to do that in this order, as the value may just be exactly the same\n     * as the previous one. In this context, think to reference counting,\n     * you want to increment (set), and then decrement (free), and not the\n     * reverse. */\n    void *oldval = dictGetVal(existing);\n    dictSetVal(d, existing, val);\n    if (d->type->valDestructor)\n        d->type->valDestructor(d, oldval);\n    return 0;\n}\n\n/* Add or Find:\n * dictAddOrFind() is simply a version of dictAddRaw() that always\n * returns the hash entry of the specified key, even if the key already\n * exists and can't be added (in that case the entry of the already\n * existing key is returned.)\n *\n * See dictAddRaw() for more information. */\ndictEntry *dictAddOrFind(dict *d, void *key) {\n    dictEntry *entry, *existing;\n    entry = dictAddRaw(d,key,&existing);\n    return entry ? entry : existing;\n}\n\n/* Search and remove an element. This is a helper function for\n * dictDelete() and dictUnlink(), please check the top comment\n * of those functions. */\nstatic dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) {\n    uint64_t h, idx;\n    dictEntry *he, *prevHe;\n    int table;\n\n    /* dict is empty */\n    if (dictSize(d) == 0) return NULL;\n\n    h = dictHashKey(d, key);\n    idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        he = d->ht_table[table][idx];\n        prevHe = NULL;\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key)) {\n                /* Unlink the element from the list */\n                if (prevHe)\n                    dictSetNext(prevHe, dictGetNext(he));\n                else\n                    d->ht_table[table][idx] = dictGetNext(he);\n                if (!nofree) {\n                    dictFreeUnlinkedEntry(d, he);\n                }\n                d->ht_used[table]--;\n                _dictShrinkIfNeeded(d);\n                return he;\n            }\n            prevHe = he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) break;\n    }\n    return NULL; /* not found */\n}\n\n/* Remove an element, returning DICT_OK on success or DICT_ERR if the\n * element was not found. */\nint dictDelete(dict *ht, const void *key) {\n    return dictGenericDelete(ht,key,0) ? DICT_OK : DICT_ERR;\n}\n\n/* Remove an element from the table, but without actually releasing\n * the key, value and dictionary entry. The dictionary entry is returned\n * if the element was found (and unlinked from the table), and the user\n * should later call `dictFreeUnlinkedEntry()` with it in order to release it.\n * Otherwise if the key is not found, NULL is returned.\n *\n * This function is useful when we want to remove something from the hash\n * table but want to use its value before actually deleting the entry.\n * Without this function the pattern would require two lookups:\n *\n *  entry = dictFind(...);\n *  // Do something with entry\n *  dictDelete(dictionary,entry);\n *\n * Thanks to this function it is possible to avoid this, and use\n * instead:\n *\n * entry = dictUnlink(dictionary,entry);\n * // Do something with entry\n * dictFreeUnlinkedEntry(entry); // <- This does not need to lookup again.\n */\ndictEntry *dictUnlink(dict *d, const void *key) {\n    return dictGenericDelete(d,key,1);\n}\n\n/* You need to call this function to really free the entry after a call\n * to dictUnlink(). It's safe to call this function with 'he' = NULL. */\nvoid dictFreeUnlinkedEntry(dict *d, dictEntry *he) {\n    if (he == NULL) return;\n    dictFreeKey(d, he);\n    dictFreeVal(d, he);\n    if (!entryIsKey(he)) zfree(decodeMaskedPtr(he));\n}\n\n/* Destroy an entire dictionary */\nint _dictClear(dict *d, int htidx, void(callback)(dict*)) {\n    unsigned long i;\n\n    /* Free all the elements */\n    for (i = 0; i < DICTHT_SIZE(d->ht_size_exp[htidx]) && d->ht_used[htidx] > 0; i++) {\n        dictEntry *he, *nextHe;\n\n        if (callback && (i & 65535) == 0) callback(d);\n\n        if ((he = d->ht_table[htidx][i]) == NULL) continue;\n        while(he) {\n            nextHe = dictGetNext(he);\n            dictFreeKey(d, he);\n            dictFreeVal(d, he);\n            if (!entryIsKey(he)) zfree(decodeMaskedPtr(he));\n            d->ht_used[htidx]--;\n            he = nextHe;\n        }\n    }\n    /* Free the table and the allocated cache structure */\n    zfree(d->ht_table[htidx]);\n    /* Re-initialize the table */\n    _dictReset(d, htidx);\n    return DICT_OK; /* never fails */\n}\n\n/* Clear & Release the hash table */\nvoid dictRelease(dict *d)\n{\n    _dictClear(d,0,NULL);\n    _dictClear(d,1,NULL);\n    zfree(d);\n}\n\ndictEntry *dictFind(dict *d, const void *key)\n{\n    dictEntry *he;\n    uint64_t h, idx, table;\n\n    if (dictSize(d) == 0) return NULL; /* dict is empty */\n\n    h = dictHashKey(d, key);\n    idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[0]);\n\n    if (dictIsRehashing(d)) {\n        if ((long)idx >= d->rehashidx && d->ht_table[0][idx]) {\n            /* If we have a valid hash entry at `idx` in ht0, we perform\n             * rehash on the bucket at `idx` (being more CPU cache friendly) */\n            _dictBucketRehash(d, idx);\n        } else {\n            /* If the hash entry is not in ht0, we rehash the buckets based\n             * on the rehashidx (not CPU cache friendly). */\n            _dictRehashStep(d);\n        }\n    }\n\n    for (table = 0; table <= 1; table++) {\n        if (table == 0 && (long)idx < d->rehashidx) continue;\n        idx = h & DICTHT_SIZE_MASK(d->ht_size_exp[table]);\n        he = d->ht_table[table][idx];\n        while(he) {\n            void *he_key = dictGetKey(he);\n            if (key == he_key || dictCompareKeys(d, key, he_key))\n                return he;\n            he = dictGetNext(he);\n        }\n        if (!dictIsRehashing(d)) return NULL;\n    }\n    return NULL;\n}\n\nvoid *dictFetchValue(dict *d, const void *key) {\n    dictEntry *he;\n\n    he = dictFind(d,key);\n    return he ? dictGetVal(he) : NULL;\n}\n\n/* Find an element from the table, also get the plink of the entry. The entry\n * is returned if the element is found, and the user should later call\n * `dictTwoPhaseUnlinkFree` with it in order to unlink and release it. Otherwise if\n * the key is not found, NULL is returned. These two functions should be used in pair.\n * `dictTwoPhaseUnlinkFind` pauses rehash and `dictTwoPhaseUnlinkFree` resumes rehash.\n *\n * We can use like this:\n *\n * dictEntry *de = dictTwoPhaseUnlinkFind(db->dict,key->ptr,&plink, &table);\n * // Do something, but we can't modify the dict\n * dictTwoPhaseUnlinkFree(db->dict,de,plink,table); // We don't need to lookup again\n *\n * If we want to find an entry before delete this entry, this an optimization to avoid\n * dictFind followed by dictDelete. i.e. the first API is a find, and it gives some info\n * to the second one to avoid repeating the lookup\n */\ndictEntry *dictTwoPhaseUnlinkFind(dict *d, const void *key, dictEntry ***plink, int *table_index) {\n    uint64_t h, idx, table;\n\n"}, {"id": "0CE2102A7D2E5909", "name": "elapsedUs", "path": "redis/src/monotonic.h", "start": {"line": 53, "col": 1}, "end": {"line": 55, "col": 1}, "code": "    return getMonotonicUs() - start_time;\n}\n\nstatic inline uint64_t elapsedMs(monotime start_time) {\n    return elapsedUs(start_time) / 1000;\n}\n\n#endif\n"}], "code": "int dictRehashMicroseconds(dict *d, uint64_t us) {\n    if (d->pauserehash > 0) return 0;\n\n    monotime timer;\n    elapsedStart(&timer);\n    int rehashes = 0;\n\n    while(dictRehash(d,100)) {\n        rehashes += 100;\n        if (elapsedUs(timer) >= us) break;\n    }\n    return rehashes;\n}\n"}, "1E86D002109F35F0": {"calls": [{"id": "1024095D36BA023F", "name": "raxNew", "path": "redis/src/rax.c", "start": {"line": 198, "col": 1}, "end": {"line": 210, "col": 1}, "code": "    rax *rax = rax_malloc(sizeof(*rax));\n    if (rax == NULL) return NULL;\n    rax->numele = 0;\n    rax->numnodes = 1;\n    rax->head = raxNewNode(0,0);\n    if (rax->head == NULL) {\n        rax_free(rax);\n        return NULL;\n    } else {\n        return rax;\n    }\n}\n\n/* realloc the node to make room for auxiliary data in order\n * to store an item in that node. On out of memory NULL is returned. */\nraxNode *raxReallocForData(raxNode *n, void *data) {\n    if (data == NULL) return n; /* No reallocation needed, setting isnull=1 */\n    size_t curlen = raxNodeCurrentLength(n);\n    return rax_realloc(n,curlen+sizeof(void*));\n}\n\n/* Set the node auxiliary data to the specified pointer. */\nvoid raxSetData(raxNode *n, void *data) {\n    n->iskey = 1;\n    if (data != NULL) {\n        n->isnull = 0;\n        void **ndata = (void**)\n            ((char*)n+raxNodeCurrentLength(n)-sizeof(void*));\n        memcpy(ndata,&data,sizeof(data));\n    } else {\n        n->isnull = 1;\n    }\n}\n\n/* Get the node auxiliary data. */\nvoid *raxGetData(raxNode *n) {\n    if (n->isnull) return NULL;\n    void **ndata =(void**)((char*)n+raxNodeCurrentLength(n)-sizeof(void*));\n    void *data;\n    memcpy(&data,ndata,sizeof(data));\n    return data;\n}\n\n/* Add a new child to the node 'n' representing the character 'c' and return\n * its new pointer, as well as the child pointer by reference. Additionally\n * '***parentlink' is populated with the raxNode pointer-to-pointer of where\n * the new child was stored, which is useful for the caller to replace the\n * child pointer if it gets reallocated.\n *\n * On success the new parent node pointer is returned (it may change because\n * of the realloc, so the caller should discard 'n' and use the new value).\n * On out of memory NULL is returned, and the old node is still valid. */\nraxNode *raxAddChild(raxNode *n, unsigned char c, raxNode **childptr, raxNode ***parentlink) {\n    assert(n->iscompr == 0);\n\n    size_t curlen = raxNodeCurrentLength(n);\n    n->size++;\n    size_t newlen = raxNodeCurrentLength(n);\n    n->size--; /* For now restore the original size. We'll update it only on\n                  success at the end. */\n\n    /* Alloc the new child we will link to 'n'. */\n    raxNode *child = raxNewNode(0,0);\n    if (child == NULL) return NULL;\n\n    /* Make space in the original node. */\n    raxNode *newn = rax_realloc(n,newlen);\n    if (newn == NULL) {\n        rax_free(child);\n        return NULL;\n    }\n    n = newn;\n\n    /* After the reallocation, we have up to 8/16 (depending on the system\n     * pointer size, and the required node padding) bytes at the end, that is,\n     * the additional char in the 'data' section, plus one pointer to the new\n     * child, plus the padding needed in order to store addresses into aligned\n     * locations.\n     *\n     * So if we start with the following node, having \"abde\" edges.\n     *\n     * Note:\n     * - We assume 4 bytes pointer for simplicity.\n     * - Each space below corresponds to one byte\n     *\n     * [HDR*][abde][Aptr][Bptr][Dptr][Eptr]|AUXP|\n     *\n     * After the reallocation we need: 1 byte for the new edge character\n     * plus 4 bytes for a new child pointer (assuming 32 bit machine).\n     * However after adding 1 byte to the edge char, the header + the edge\n     * characters are no longer aligned, so we also need 3 bytes of padding.\n     * In total the reallocation will add 1+4+3 bytes = 8 bytes:\n     *\n     * (Blank bytes are represented by \".\")\n     *\n     * [HDR*][abde][Aptr][Bptr][Dptr][Eptr]|AUXP|[....][....]\n     *\n     * Let's find where to insert the new child in order to make sure\n     * it is inserted in-place lexicographically. Assuming we are adding\n     * a child \"c\" in our case pos will be = 2 after the end of the following\n     * loop. */\n    int pos;\n    for (pos = 0; pos < n->size; pos++) {\n        if (n->data[pos] > c) break;\n    }\n\n    /* Now, if present, move auxiliary data pointer at the end\n     * so that we can mess with the other data without overwriting it.\n     * We will obtain something like that:\n     *\n     * [HDR*][abde][Aptr][Bptr][Dptr][Eptr][....][....]|AUXP|\n     */\n    unsigned char *src, *dst;\n    if (n->iskey && !n->isnull) {\n        src = ((unsigned char*)n+curlen-sizeof(void*));\n        dst = ((unsigned char*)n+newlen-sizeof(void*));\n        memmove(dst,src,sizeof(void*));\n    }\n\n    /* Compute the \"shift\", that is, how many bytes we need to move the\n     * pointers section forward because of the addition of the new child\n     * byte in the string section. Note that if we had no padding, that\n     * would be always \"1\", since we are adding a single byte in the string\n     * section of the node (where now there is \"abde\" basically).\n     *\n     * However we have padding, so it could be zero, or up to 8.\n     *\n     * Another way to think at the shift is, how many bytes we need to\n     * move child pointers forward *other than* the obvious sizeof(void*)\n     * needed for the additional pointer itself. */\n    size_t shift = newlen - curlen - sizeof(void*);\n\n    /* We said we are adding a node with edge 'c'. The insertion\n     * point is between 'b' and 'd', so the 'pos' variable value is\n     * the index of the first child pointer that we need to move forward\n     * to make space for our new pointer.\n     *\n     * To start, move all the child pointers after the insertion point\n     * of shift+sizeof(pointer) bytes on the right, to obtain:\n     *\n     * [HDR*][abde][Aptr][Bptr][....][....][Dptr][Eptr]|AUXP|\n     */\n    src = n->data+n->size+\n          raxPadding(n->size)+\n          sizeof(raxNode*)*pos;\n    memmove(src+shift+sizeof(raxNode*),src,sizeof(raxNode*)*(n->size-pos));\n\n    /* Move the pointers to the left of the insertion position as well. Often\n     * we don't need to do anything if there was already some padding to use. In\n     * that case the final destination of the pointers will be the same, however\n     * in our example there was no pre-existing padding, so we added one byte\n     * plus three bytes of padding. After the next memmove() things will look\n     * like that:\n     *\n     * [HDR*][abde][....][Aptr][Bptr][....][Dptr][Eptr]|AUXP|\n     */\n    if (shift) {\n        src = (unsigned char*) raxNodeFirstChildPtr(n);\n        memmove(src+shift,src,sizeof(raxNode*)*pos);\n    }\n\n    /* Now make the space for the additional char in the data section,\n     * but also move the pointers before the insertion point to the right\n     * by shift bytes, in order to obtain the following:\n     *\n     * [HDR*][ab.d][e...][Aptr][Bptr][....][Dptr][Eptr]|AUXP|\n     */\n    src = n->data+pos;\n    memmove(src+1,src,n->size-pos);\n\n    /* We can now set the character and its child node pointer to get:\n     *\n     * [HDR*][abcd][e...][Aptr][Bptr][....][Dptr][Eptr]|AUXP|\n     * [HDR*][abcd][e...][Aptr][Bptr][Cptr][Dptr][Eptr]|AUXP|\n     */\n    n->data[pos] = c;\n    n->size++;\n    src = (unsigned char*) raxNodeFirstChildPtr(n);\n    raxNode **childfield = (raxNode**)(src+sizeof(raxNode*)*pos);\n    memcpy(childfield,&child,sizeof(child));\n    *childptr = child;\n    *parentlink = childfield;\n    return n;\n}\n\n/* Turn the node 'n', that must be a node without any children, into a\n * compressed node representing a set of nodes linked one after the other\n * and having exactly one child each. The node can be a key or not: this\n * property and the associated value if any will be preserved.\n *\n * The function also returns a child node, since the last node of the\n * compressed chain cannot be part of the chain: it has zero children while\n * we can only compress inner nodes with exactly one child each. */\nraxNode *raxCompressNode(raxNode *n, unsigned char *s, size_t len, raxNode **child) {\n    assert(n->size == 0 && n->iscompr == 0);\n    void *data = NULL; /* Initialized only to avoid warnings. */\n    size_t newsize;\n\n    debugf(\"Compress node: %.*s\\n\", (int)len,s);\n\n    /* Allocate the child to link to this node. */\n    *child = raxNewNode(0,0);\n    if (*child == NULL) return NULL;\n\n    /* Make space in the parent node. */\n    newsize = sizeof(raxNode)+len+raxPadding(len)+sizeof(raxNode*);\n    if (n->iskey) {\n        data = raxGetData(n); /* To restore it later. */\n        if (!n->isnull) newsize += sizeof(void*);\n    }\n    raxNode *newn = rax_realloc(n,newsize);\n"}], "code": "streamCG *streamCreateCG(stream *s, char *name, size_t namelen, streamID *id, long long entries_read) {\n    if (s->cgroups == NULL) s->cgroups = raxNew();\n    if (raxFind(s->cgroups,(unsigned char*)name,namelen,NULL))\n        return NULL;\n\n    streamCG *cg = zmalloc(sizeof(*cg));\n    cg->pel = raxNew();\n    cg->consumers = raxNew();\n    cg->last_id = *id;\n    cg->entries_read = entries_read;\n    raxInsert(s->cgroups,(unsigned char*)name,namelen,cg,NULL);\n    return cg;\n}\n"}, "5D25DDD74AF87E40": {"calls": [{"id": "F0E27CBDF05E449D", "name": "addReplyError", "path": "redis/src/networking.c", "start": {"line": 614, "col": 1}, "end": {"line": 617, "col": 1}, "code": "    addReplyErrorLength(c,err,strlen(err));\n    afterErrorReply(c,err,strlen(err),0);\n}\n\n/* Add error reply to the given client.\n * Supported flags:\n * * ERR_REPLY_FLAG_NO_STATS_UPDATE - indicate not to perform any error stats updates */\nvoid addReplyErrorSdsEx(client *c, sds err, int flags) {\n    addReplyErrorLength(c,err,sdslen(err));\n    afterErrorReply(c,err,sdslen(err),flags);\n    sdsfree(err);\n}\n\n/* See addReplyErrorLength for expectations from the input string. */\n/* As a side effect the SDS string is freed. */\nvoid addReplyErrorSds(client *c, sds err) {\n    addReplyErrorSdsEx(c, err, 0);\n}\n\n/* See addReplyErrorLength for expectations from the input string. */\n/* As a side effect the SDS string is freed. */\nvoid addReplyErrorSdsSafe(client *c, sds err) {\n    err = sdsmapchars(err, \"\\r\\n\", \"  \",  2);\n    addReplyErrorSdsEx(c, err, 0);\n}\n\n/* Internal function used by addReplyErrorFormat, addReplyErrorFormatEx and RM_ReplyWithErrorFormat.\n * Refer to afterErrorReply for more information about the flags. */\nvoid addReplyErrorFormatInternal(client *c, int flags, const char *fmt, va_list ap) {\n    va_list cpy;\n    va_copy(cpy,ap);\n    sds s = sdscatvprintf(sdsempty(),fmt,cpy);\n    va_end(cpy);\n    /* Trim any newlines at the end (ones will be added by addReplyErrorLength) */\n    s = sdstrim(s, \"\\r\\n\");\n    /* Make sure there are no newlines in the middle of the string, otherwise\n     * invalid protocol is emitted. */\n    s = sdsmapchars(s, \"\\r\\n\", \"  \",  2);\n    addReplyErrorLength(c,s,sdslen(s));\n    afterErrorReply(c,s,sdslen(s),flags);\n    sdsfree(s);\n}\n\nvoid addReplyErrorFormatEx(client *c, int flags, const char *fmt, ...) {\n    va_list ap;\n    va_start(ap,fmt);\n    addReplyErrorFormatInternal(c, flags, fmt, ap);\n    va_end(ap);\n}\n\n/* See addReplyErrorLength for expectations from the formatted string.\n * The formatted string is safe to contain \\r and \\n anywhere. */\nvoid addReplyErrorFormat(client *c, const char *fmt, ...) {\n    va_list ap;\n    va_start(ap,fmt);\n    addReplyErrorFormatInternal(c, 0, fmt, ap);\n    va_end(ap);\n}\n\nvoid addReplyErrorArity(client *c) {\n    addReplyErrorFormat(c, \"wrong number of arguments for '%s' command\",\n                        c->cmd->fullname);\n}\n\nvoid addReplyErrorExpireTime(client *c) {\n    addReplyErrorFormat(c, \"invalid expire time in '%s' command\",\n                        c->cmd->fullname);\n}\n\nvoid addReplyStatusLength(client *c, const char *s, size_t len) {\n    addReplyProto(c,\"+\",1);\n    addReplyProto(c,s,len);\n    addReplyProto(c,\"\\r\\n\",2);\n}\n\nvoid addReplyStatus(client *c, const char *status) {\n    addReplyStatusLength(c,status,strlen(status));\n}\n\nvoid addReplyStatusFormat(client *c, const char *fmt, ...) {\n    va_list ap;\n    va_start(ap,fmt);\n    sds s = sdscatvprintf(sdsempty(),fmt,ap);\n    va_end(ap);\n    addReplyStatusLength(c,s,sdslen(s));\n    sdsfree(s);\n}\n\n/* Sometimes we are forced to create a new reply node, and we can't append to\n * the previous one, when that happens, we wanna try to trim the unused space\n * at the end of the last reply node which we won't use anymore. */\nvoid trimReplyUnusedTailSpace(client *c) {\n    listNode *ln = listLast(c->reply);\n    clientReplyBlock *tail = ln? listNodeValue(ln): NULL;\n\n    /* Note that 'tail' may be NULL even if we have a tail node, because when\n     * addReplyDeferredLen() is used */\n    if (!tail) return;\n\n    /* We only try to trim the space is relatively high (more than a 1/4 of the\n     * allocation), otherwise there's a high chance realloc will NOP.\n     * Also, to avoid large memmove which happens as part of realloc, we only do\n     * that if the used part is small.  */\n    if (tail->size - tail->used > tail->size / 4 &&\n        tail->used < PROTO_REPLY_CHUNK_BYTES)\n    {\n        size_t usable_size;\n        size_t old_size = tail->size;\n        tail = zrealloc_usable(tail, tail->used + sizeof(clientReplyBlock), &usable_size);\n        /* take over the allocation's internal fragmentation (at least for\n         * memory usage tracking) */\n        tail->size = usable_size - sizeof(clientReplyBlock);\n        c->reply_bytes = c->reply_bytes + tail->size - old_size;\n        listNodeValue(ln) = tail;\n    }\n}\n\n/* Adds an empty object to the reply list that will contain the multi bulk\n * length, which is not known when this function is called. */\nvoid *addReplyDeferredLen(client *c) {\n    /* Note that we install the write event here even if the object is not\n     * ready to be sent, since we are sure that before returning to the\n     * event loop setDeferredAggregateLen() will be called. */\n    if (prepareClientToWrite(c) != C_OK) return NULL;\n\n    /* Replicas should normally not cause any writes to the reply buffer. In case a rogue replica sent a command on the\n     * replication link that caused a reply to be generated we'll simply disconnect it.\n     * Note this is the simplest way to check a command added a response. Replication links are used to write data but\n     * not for responses, so we should normally never get here on a replica client. */\n    if (getClientType(c) == CLIENT_TYPE_SLAVE) {\n        sds cmdname = c->lastcmd ? c->lastcmd->fullname : NULL;\n        logInvalidUseAndFreeClientAsync(c, \"Replica generated a reply to command '%s'\",\n                                        cmdname ? cmdname : \"<unknown>\");\n        return NULL;\n    }\n\n    /* We call it here because this function conceptually affects the reply\n     * buffer offset (see function comment) */\n    reqresSaveClientReplyOffset(c);\n\n    trimReplyUnusedTailSpace(c);\n    listAddNodeTail(c->reply,NULL); /* NULL is our placeholder. */\n    return listLast(c->reply);\n}\n\nvoid setDeferredReply(client *c, void *node, const char *s, size_t length) {\n    listNode *ln = (listNode*)node;\n    clientReplyBlock *next, *prev;\n\n    /* Abort when *node is NULL: when the client should not accept writes\n     * we return NULL in addReplyDeferredLen() */\n    if (node == NULL) return;\n    serverAssert(!listNodeValue(ln));\n\n    /* Normally we fill this dummy NULL node, added by addReplyDeferredLen(),\n     * with a new buffer structure containing the protocol needed to specify\n     * the length of the array following. However sometimes there might be room\n     * in the previous/next node so we can instead remove this NULL node, and\n     * suffix/prefix our data in the node immediately before/after it, in order\n     * to save a write(2) syscall later. Conditions needed to do it:\n     *\n     * - The prev node is non-NULL and has space in it or\n     * - The next node is non-NULL,\n     * - It has enough room already allocated\n     * - And not too large (avoid large memmove) */\n    if (ln->prev != NULL && (prev = listNodeValue(ln->prev)) &&\n        prev->size - prev->used > 0)\n    {\n        size_t len_to_copy = prev->size - prev->used;\n        if (len_to_copy > length)\n            len_to_copy = length;\n        memcpy(prev->buf + prev->used, s, len_to_copy);\n        prev->used += len_to_copy;\n        length -= len_to_copy;\n        if (length == 0) {\n            listDelNode(c->reply, ln);\n            return;\n        }\n        s += len_to_copy;\n    }\n\n    if (ln->next != NULL && (next = listNodeValue(ln->next)) &&\n        next->size - next->used >= length &&\n        next->used < PROTO_REPLY_CHUNK_BYTES * 4)\n    {\n        memmove(next->buf + length, next->buf, next->used);\n        memcpy(next->buf, s, length);\n        next->used += length;\n        listDelNode(c->reply,ln);\n    } else {\n        /* Create a new node */\n        size_t usable_size;\n        clientReplyBlock *buf = zmalloc_usable(length + sizeof(clientReplyBlock), &usable_size);\n        /* Take over the allocation's internal fragmentation */\n        buf->size = usable_size - sizeof(clientReplyBlock);\n        buf->used = length;\n        memcpy(buf->buf, s, length);\n        listNodeValue(ln) = buf;\n        c->reply_bytes += buf->size;\n\n        closeClientOnOutputBufferLimitReached(c, 1);\n    }\n}\n\n/* Populate the length object and try gluing it to the next chunk. */\nvoid setDeferredAggregateLen(client *c, void *node, long length, char prefix) {\n    serverAssert(length >= 0);\n\n    /* Abort when *node is NULL: when the client should not accept writes\n     * we return NULL in addReplyDeferredLen() */\n    if (node == NULL) return;\n\n    /* Things like *2\\r\\n, %3\\r\\n or ~4\\r\\n are emitted very often by the protocol\n     * so we have a few shared objects to use if the integer is small\n     * like it is most of the times. */\n    const size_t hdr_len = OBJ_SHARED_HDR_STRLEN(length);\n    const int opt_hdr = length < OBJ_SHARED_BULKHDR_LEN;\n    if (prefix == '*' && opt_hdr) {\n        setDeferredReply(c, node, shared.mbulkhdr[length]->ptr, hdr_len);\n        return;\n    }\n    if (prefix == '%' && opt_hdr) {\n        setDeferredReply(c, node, shared.maphdr[length]->ptr, hdr_len);\n        return;\n    }\n    if (prefix == '~' && opt_hdr) {\n        setDeferredReply(c, node, shared.sethdr[length]->ptr, hdr_len);\n        return;\n    }\n\n    char lenstr[128];\n    size_t lenstr_len = snprintf(lenstr, sizeof(lenstr), \"%c%ld\\r\\n\", prefix, length);\n    setDeferredReply(c, node, lenstr, lenstr_len);\n}\n\nvoid setDeferredArrayLen(client *c, void *node, long length) {\n    setDeferredAggregateLen(c,node,length,'*');\n}\n\nvoid setDeferredMapLen(client *c, void *node, long length) {\n    int prefix = c->resp == 2 ? '*' : '%';\n    if (c->resp == 2) length *= 2;\n    setDeferredAggregateLen(c,node,length,prefix);\n}\n\nvoid setDeferredSetLen(client *c, void *node, long length) {\n    int prefix = c->resp == 2 ? '*' : '~';\n    setDeferredAggregateLen(c,node,length,prefix);\n}\n\nvoid setDeferredAttributeLen(client *c, void *node, long length) {\n    serverAssert(c->resp >= 3);\n    setDeferredAggregateLen(c,node,length,'|');\n}\n\nvoid setDeferredPushLen(client *c, void *node, long length) {\n    serverAssert(c->resp >= 3);\n    setDeferredAggregateLen(c,node,length,'>');\n}\n\n/* Add a double as a bulk reply */\nvoid addReplyDouble(client *c, double d) {\n    if (c->resp == 3) {\n        char dbuf[MAX_D2STRING_CHARS+3];\n        dbuf[0] = ',';\n        const int dlen = d2string(dbuf+1,sizeof(dbuf)-1,d);\n        dbuf[dlen+1] = '\\r';\n        dbuf[dlen+2] = '\\n';\n        dbuf[dlen+3] = '\\0';\n        addReplyProto(c,dbuf,dlen+3);\n    } else {\n        char dbuf[MAX_LONG_DOUBLE_CHARS+32];\n        /* In order to prepend the string length before the formatted number,\n         * but still avoid an extra memcpy of the whole number, we reserve space\n         * for maximum header `$0000\\r\\n`, print double, add the resp header in\n         * front of it, and then send the buffer with the right `start` offset. */\n        const int dlen = d2string(dbuf+7,sizeof(dbuf)-7,d);\n        int digits = digits10(dlen);\n        int start = 4 - digits;\n        serverAssert(start >= 0);\n        dbuf[start] = '$';\n\n        /* Convert `dlen` to string, putting it's digits after '$' and before the\n            * formatted double string. */\n        for(int i = digits, val = dlen; val && i > 0 ; --i, val /= 10) {\n            dbuf[start + i] = \"0123456789\"[val % 10];\n        }\n        dbuf[5] = '\\r';\n        dbuf[6] = '\\n';\n        dbuf[dlen+7] = '\\r';\n        dbuf[dlen+8] = '\\n';\n        dbuf[dlen+9] = '\\0';\n        addReplyProto(c,dbuf+start,dlen+9-start);\n    }\n}\n\nvoid addReplyBigNum(client *c, const char* num, size_t len) {\n    if (c->resp == 2) {\n        addReplyBulkCBuffer(c, num, len);\n    } else {\n        addReplyProto(c,\"(\",1);\n        addReplyProto(c,num,len);\n        addReplyProto(c,\"\\r\\n\",2);\n    }\n}\n\n/* Add a long double as a bulk reply, but uses a human readable formatting\n * of the double instead of exposing the crude behavior of doubles to the\n * dear user. */\nvoid addReplyHumanLongDouble(client *c, long double d) {\n    if (c->resp == 2) {\n        robj *o = createStringObjectFromLongDouble(d,1);\n        addReplyBulk(c,o);\n        decrRefCount(o);\n    } else {\n        char buf[MAX_LONG_DOUBLE_CHARS];\n        int len = ld2string(buf,sizeof(buf),d,LD_STR_HUMAN);\n        addReplyProto(c,\",\",1);\n        addReplyProto(c,buf,len);\n        addReplyProto(c,\"\\r\\n\",2);\n    }\n}\n\n/* Add a long long as integer reply or bulk len / multi bulk count.\n * Basically this is used to output <prefix><long long><crlf>. */\nvoid addReplyLongLongWithPrefix(client *c, long long ll, char prefix) {\n    char buf[128];\n    int len;\n\n    /* Things like $3\\r\\n or *2\\r\\n are emitted very often by the protocol\n     * so we have a few shared objects to use if the integer is small\n     * like it is most of the times. */\n    const int opt_hdr = ll < OBJ_SHARED_BULKHDR_LEN && ll >= 0;\n    const size_t hdr_len = OBJ_SHARED_HDR_STRLEN(ll);\n    if (prefix == '*' && opt_hdr) {\n        addReplyProto(c,shared.mbulkhdr[ll]->ptr,hdr_len);\n        return;\n    } else if (prefix == '$' && opt_hdr) {\n        addReplyProto(c,shared.bulkhdr[ll]->ptr,hdr_len);\n        return;\n    } else if (prefix == '%' && opt_hdr) {\n        addReplyProto(c,shared.maphdr[ll]->ptr,hdr_len);\n        return;\n    } else if (prefix == '~' && opt_hdr) {\n        addReplyProto(c,shared.sethdr[ll]->ptr,hdr_len);\n        return;\n    }\n\n    buf[0] = prefix;\n    len = ll2string(buf+1,sizeof(buf)-1,ll);\n    buf[len+1] = '\\r';\n    buf[len+2] = '\\n';\n    addReplyProto(c,buf,len+3);\n}\n\nvoid addReplyLongLong(client *c, long long ll) {\n    if (ll == 0)\n        addReply(c,shared.czero);\n    else if (ll == 1)\n        addReply(c,shared.cone);\n    else\n        addReplyLongLongWithPrefix(c,ll,':');\n}\n\nvoid addReplyAggregateLen(client *c, long length, int prefix) {\n    serverAssert(length >= 0);\n    addReplyLongLongWithPrefix(c,length,prefix);\n}\n\nvoid addReplyArrayLen(client *c, long length) {\n    addReplyAggregateLen(c,length,'*');\n}\n\nvoid addReplyMapLen(client *c, long length) {\n    int prefix = c->resp == 2 ? '*' : '%';\n    if (c->resp == 2) length *= 2;\n    addReplyAggregateLen(c,length,prefix);\n}\n\nvoid addReplySetLen(client *c, long length) {\n    int prefix = c->resp == 2 ? '*' : '~';\n    addReplyAggregateLen(c,length,prefix);\n}\n\nvoid addReplyAttributeLen(client *c, long length) {\n    serverAssert(c->resp >= 3);\n    addReplyAggregateLen(c,length,'|');\n}\n\nvoid addReplyPushLen(client *c, long length) {\n    serverAssert(c->resp >= 3);\n    serverAssertWithInfo(c, NULL, c->flags & CLIENT_PUSHING);\n    addReplyAggregateLen(c,length,'>');\n}\n\nvoid addReplyNull(client *c) {\n    if (c->resp == 2) {\n        addReplyProto(c,\"$-1\\r\\n\",5);\n    } else {\n        addReplyProto(c,\"_\\r\\n\",3);\n    }\n}\n\nvoid addReplyBool(client *c, int b) {\n    if (c->resp == 2) {\n        addReply(c, b ? shared.cone : shared.czero);\n    } else {\n        addReplyProto(c, b ? \"#t\\r\\n\" : \"#f\\r\\n\",4);\n    }\n}\n\n/* A null array is a concept that no longer exists in RESP3. However\n * RESP2 had it, so API-wise we have this call, that will emit the correct\n * RESP2 protocol, however for RESP3 the reply will always be just the\n * Null type \"_\\r\\n\". */\nvoid addReplyNullArray(client *c) {\n    if (c->resp == 2) {\n        addReplyProto(c,\"*-1\\r\\n\",5);\n    } else {\n        addReplyProto(c,\"_\\r\\n\",3);\n    }\n}\n\n/* Create the length prefix of a bulk reply, example: $2234 */\nvoid addReplyBulkLen(client *c, robj *obj) {\n    size_t len = stringObjectLen(obj);\n\n    addReplyLongLongWithPrefix(c,len,'$');\n}\n\n/* Add a Redis Object as a bulk reply */\nvoid addReplyBulk(client *c, robj *obj) {\n    addReplyBulkLen(c,obj);\n    addReply(c,obj);\n    addReplyProto(c,\"\\r\\n\",2);\n}\n\n/* Add a C buffer as bulk reply */\nvoid addReplyBulkCBuffer(client *c, const void *p, size_t len) {\n    addReplyLongLongWithPrefix(c,len,'$');\n    addReplyProto(c,p,len);\n    addReplyProto(c,\"\\r\\n\",2);\n}\n\n/* Add sds to reply (takes ownership of sds and frees it) */\nvoid addReplyBulkSds(client *c, sds s)  {\n    addReplyLongLongWithPrefix(c,sdslen(s),'$');\n    addReplySds(c,s);\n    addReplyProto(c,\"\\r\\n\",2);\n}\n\n/* Set sds to a deferred reply (for symmetry with addReplyBulkSds it also frees the sds) */\nvoid setDeferredReplyBulkSds(client *c, void *node, sds s) {\n    sds reply = sdscatprintf(sdsempty(), \"$%d\\r\\n%s\\r\\n\", (unsigned)sdslen(s), s);\n    setDeferredReply(c, node, reply, sdslen(reply));\n    sdsfree(reply);\n    sdsfree(s);\n}\n\n/* Add a C null term string as bulk reply */\nvoid addReplyBulkCString(client *c, const char *s) {\n    if (s == NULL) {\n        addReplyNull(c);\n    } else {\n        addReplyBulkCBuffer(c,s,strlen(s));\n    }\n}\n\n/* Add a long long as a bulk reply */\nvoid addReplyBulkLongLong(client *c, long long ll) {\n    char buf[64];\n    int len;\n\n    len = ll2string(buf,64,ll);\n    addReplyBulkCBuffer(c,buf,len);\n}\n\n/* Reply with a verbatim type having the specified extension.\n *\n * The 'ext' is the \"extension\" of the file, actually just a three\n * character type that describes the format of the verbatim string.\n * For instance \"txt\" means it should be interpreted as a text only\n * file by the receiver, \"md \" as markdown, and so forth. Only the\n * three first characters of the extension are used, and if the\n * provided one is shorter than that, the remaining is filled with\n * spaces. */\nvoid addReplyVerbatim(client *c, const char *s, size_t len, const char *ext) {\n    if (c->resp == 2) {\n        addReplyBulkCBuffer(c,s,len);\n    } else {\n        char buf[32];\n        size_t preflen = snprintf(buf,sizeof(buf),\"=%zu\\r\\nxxx:\",len+4);\n        char *p = buf+preflen-4;\n        for (int i = 0; i < 3; i++) {\n            if (*ext == '\\0') {\n                p[i] = ' ';\n            } else {\n                p[i] = *ext++;\n            }\n        }\n        addReplyProto(c,buf,preflen);\n        addReplyProto(c,s,len);\n        addReplyProto(c,\"\\r\\n\",2);\n    }\n}\n\n/* This function is similar to the addReplyHelp function but adds the\n * ability to pass in two arrays of strings. Some commands have\n * some additional subcommands based on the specific feature implementation\n * Redis is compiled with (currently just clustering). This function allows\n * to pass is the common subcommands in `help` and any implementation\n * specific subcommands in `extended_help`.\n */\nvoid addExtendedReplyHelp(client *c, const char **help, const char **extended_help) {\n    sds cmd = sdsnew((char*) c->argv[0]->ptr);\n    void *blenp = addReplyDeferredLen(c);\n    int blen = 0;\n    int idx = 0;\n\n    sdstoupper(cmd);\n    addReplyStatusFormat(c,\n        \"%s <subcommand> [<arg> [value] [opt] ...]. Subcommands are:\",cmd);\n    sdsfree(cmd);\n\n    while (help[blen]) addReplyStatus(c,help[blen++]);\n    if (extended_help) {\n        while (extended_help[idx]) addReplyStatus(c,extended_help[idx++]);\n    }\n    blen += idx;\n\n    addReplyStatus(c,\"HELP\");\n    addReplyStatus(c,\"    Print this help.\");\n\n    blen += 1;  /* Account for the header. */\n    blen += 2;  /* Account for the footer. */\n    setDeferredArrayLen(c,blenp,blen);\n}\n\n/* Add an array of C strings as status replies with a heading.\n * This function is typically invoked by commands that support\n * subcommands in response to the 'help' subcommand. The help array\n * is terminated by NULL sentinel. */\nvoid addReplyHelp(client *c, const char **help) {\n    addExtendedReplyHelp(c, help, NULL);\n}\n\n/* Add a suggestive error reply.\n * This function is typically invoked by from commands that support\n * subcommands in response to an unknown subcommand or argument error. */\nvoid addReplySubcommandSyntaxError(client *c) {\n    sds cmd = sdsnew((char*) c->argv[0]->ptr);\n    sdstoupper(cmd);\n    addReplyErrorFormat(c,\n        \"unknown subcommand or wrong number of arguments for '%.128s'. Try %s HELP.\",\n        (char*)c->argv[1]->ptr,cmd);\n    sdsfree(cmd);\n}\n\n/* Append 'src' client output buffers into 'dst' client output buffers.\n * This function clears the output buffers of 'src' */\nvoid AddReplyFromClient(client *dst, client *src) {\n    /* If the source client contains a partial response due to client output\n     * buffer limits, propagate that to the dest rather than copy a partial\n     * reply. We don't wanna run the risk of copying partial response in case\n     * for some reason the output limits don't reach the same decision (maybe\n     * they changed) */\n    if (src->flags & CLIENT_CLOSE_ASAP) {\n        sds client = catClientInfoString(sdsempty(),dst);\n        freeClientAsync(dst);\n        serverLog(LL_WARNING,\"Client %s scheduled to be closed ASAP for overcoming of output buffer limits.\", client);\n        sdsfree(client);\n        return;\n    }\n\n    /* First add the static buffer (either into the static buffer or reply list) */\n    addReplyProto(dst,src->buf, src->bufpos);\n\n    /* We need to check with prepareClientToWrite again (after addReplyProto)\n     * since addReplyProto may have changed something (like CLIENT_CLOSE_ASAP) */\n    if (prepareClientToWrite(dst) != C_OK)\n        return;\n\n    /* We're bypassing _addReplyProtoToList, so we need to add the pre/post\n     * checks in it. */\n    if (dst->flags & CLIENT_CLOSE_AFTER_REPLY) return;\n\n    /* Concatenate the reply list into the dest */\n    if (listLength(src->reply))\n        listJoin(dst->reply,src->reply);\n    dst->reply_bytes += src->reply_bytes;\n    src->reply_bytes = 0;\n    src->bufpos = 0;\n\n    if (src->deferred_reply_errors) {\n        deferredAfterErrorReply(dst, src->deferred_reply_errors);\n        listRelease(src->deferred_reply_errors);\n        src->deferred_reply_errors = NULL;\n    }\n\n    /* Check output buffer limits */\n    closeClientOnOutputBufferLimitReached(dst, 1);\n}\n\n/* Append the listed errors to the server error statistics. the input\n * list is not modified and remains the responsibility of the caller. */\nvoid deferredAfterErrorReply(client *c, list *errors) {\n    listIter li;\n    listNode *ln;\n    listRewind(errors,&li);\n    while((ln = listNext(&li))) {\n        sds err = ln->value;\n        afterErrorReply(c, err, sdslen(err), 0);\n    }\n}\n\n/* Logically copy 'src' replica client buffers info to 'dst' replica.\n * Basically increase referenced buffer block node reference count. */\nvoid copyReplicaOutputBuffer(client *dst, client *src) {\n"}, {"id": "B82A437F15072F1C", "name": "pubsubSubscribeChannel", "path": "redis/src/pubsub.c", "start": {"line": 259, "col": 1}, "end": {"line": 289, "col": 1}, "code": "    dictEntry *de, *existing;\n    dict *clients = NULL;\n    int retval = 0;\n    unsigned int slot = 0;\n\n    /* Add the channel to the client -> channels hash table */\n    if (dictAdd(type.clientPubSubChannels(c),channel,NULL) == DICT_OK) {\n        retval = 1;\n        incrRefCount(channel);\n        /* Add the client to the channel -> list of clients hash table */\n        if (server.cluster_enabled && type.shard) {\n            slot = getKeySlot(channel->ptr);\n        }\n\n        de = kvstoreDictAddRaw(*type.serverPubSubChannels, slot, channel, &existing);\n\n        if (existing) {\n            clients = dictGetVal(existing);\n        } else {\n            clients = dictCreate(&clientDictType);\n            kvstoreDictSetVal(*type.serverPubSubChannels, slot, de, clients);\n            incrRefCount(channel);\n        }\n\n        serverAssert(dictAdd(clients, c, NULL) != DICT_ERR);\n    }\n    /* Notify the client */\n    addReplyPubsubSubscribed(c,channel,type);\n    return retval;\n}\n\n/* Unsubscribe a client from a channel. Returns 1 if the operation succeeded, or\n * 0 if the client was not subscribed to the specified channel. */\nint pubsubUnsubscribeChannel(client *c, robj *channel, int notify, pubsubtype type) {\n    dictEntry *de;\n    dict *clients;\n    int retval = 0;\n    int slot = 0;\n\n    /* Remove the channel from the client -> channels hash table */\n    incrRefCount(channel); /* channel may be just a pointer to the same object\n                            we have in the hash tables. Protect it... */\n    if (dictDelete(type.clientPubSubChannels(c),channel) == DICT_OK) {\n        retval = 1;\n        /* Remove the client from the channel -> clients list hash table */\n        if (server.cluster_enabled && type.shard) {\n            slot = getKeySlot(channel->ptr);\n        }\n        de = kvstoreDictFind(*type.serverPubSubChannels, slot, channel);\n        serverAssertWithInfo(c,NULL,de != NULL);\n        clients = dictGetVal(de);\n        serverAssertWithInfo(c, NULL, dictDelete(clients, c) == DICT_OK);\n        if (dictSize(clients) == 0) {\n            /* Free the dict and associated hash entry at all if this was\n             * the latest client, so that it will be possible to abuse\n             * Redis PUBSUB creating millions of channels. */\n            kvstoreDictDelete(*type.serverPubSubChannels, slot, channel);\n        }\n    }\n    /* Notify the client */\n    if (notify) {\n        addReplyPubsubUnsubscribed(c,channel,type);\n    }\n    decrRefCount(channel); /* it is finally safe to release it */\n    return retval;\n}\n\n/* Unsubscribe all shard channels in a slot. */\nvoid pubsubShardUnsubscribeAllChannelsInSlot(unsigned int slot) {\n    if (!kvstoreDictSize(server.pubsubshard_channels, slot))\n        return;\n\n    kvstoreDictIterator *kvs_di = kvstoreGetDictSafeIterator(server.pubsubshard_channels, slot);\n    dictEntry *de;\n    while ((de = kvstoreDictIteratorNext(kvs_di)) != NULL) {\n        robj *channel = dictGetKey(de);\n        dict *clients = dictGetVal(de);\n        /* For each client subscribed to the channel, unsubscribe it. */\n        dictIterator *iter = dictGetIterator(clients);\n        dictEntry *entry;\n        while ((entry = dictNext(iter)) != NULL) {\n            client *c = dictGetKey(entry);\n            int retval = dictDelete(c->pubsubshard_channels, channel);\n            serverAssertWithInfo(c,channel,retval == DICT_OK);\n            addReplyPubsubUnsubscribed(c, channel, pubSubShardType);\n            /* If the client has no other pubsub subscription,\n             * move out of pubsub mode. */\n            if (clientTotalPubSubSubscriptionCount(c) == 0) {\n                unmarkClientAsPubSub(c);\n            }\n        }\n        dictReleaseIterator(iter);\n        kvstoreDictDelete(server.pubsubshard_channels, slot, channel);\n    }\n    kvstoreReleaseDictIterator(kvs_di);\n}\n\n/* Subscribe a client to a pattern. Returns 1 if the operation succeeded, or 0 if the client was already subscribed to that pattern. */\nint pubsubSubscribePattern(client *c, robj *pattern) {\n    dictEntry *de;\n    dict *clients;\n    int retval = 0;\n\n    if (dictAdd(c->pubsub_patterns, pattern, NULL) == DICT_OK) {\n        retval = 1;\n        incrRefCount(pattern);\n        /* Add the client to the pattern -> list of clients hash table */\n        de = dictFind(server.pubsub_patterns,pattern);\n        if (de == NULL) {\n            clients = dictCreate(&clientDictType);\n            dictAdd(server.pubsub_patterns,pattern,clients);\n            incrRefCount(pattern);\n        } else {\n            clients = dictGetVal(de);\n        }\n        serverAssert(dictAdd(clients, c, NULL) != DICT_ERR);\n    }\n    /* Notify the client */\n    addReplyPubsubPatSubscribed(c,pattern);\n    return retval;\n}\n\n/* Unsubscribe a client from a channel. Returns 1 if the operation succeeded, or\n * 0 if the client was not subscribed to the specified channel. */\nint pubsubUnsubscribePattern(client *c, robj *pattern, int notify) {\n    dictEntry *de;\n    dict *clients;\n    int retval = 0;\n\n    incrRefCount(pattern); /* Protect the object. May be the same we remove */\n    if (dictDelete(c->pubsub_patterns, pattern) == DICT_OK) {\n        retval = 1;\n        /* Remove the client from the pattern -> clients list hash table */\n        de = dictFind(server.pubsub_patterns,pattern);\n        serverAssertWithInfo(c,NULL,de != NULL);\n        clients = dictGetVal(de);\n        serverAssertWithInfo(c, NULL, dictDelete(clients, c) == DICT_OK);\n        if (dictSize(clients) == 0) {\n            /* Free the dict and associated hash entry at all if this was\n             * the latest client. */\n            dictDelete(server.pubsub_patterns,pattern);\n        }\n    }\n    /* Notify the client */\n    if (notify) addReplyPubsubPatUnsubscribed(c,pattern);\n    decrRefCount(pattern);\n    return retval;\n}\n\n/* Unsubscribe from all the channels. Return the number of channels the\n * client was subscribed to. */\nint pubsubUnsubscribeAllChannelsInternal(client *c, int notify, pubsubtype type) {\n    int count = 0;\n    if (dictSize(type.clientPubSubChannels(c)) > 0) {\n        dictIterator *di = dictGetSafeIterator(type.clientPubSubChannels(c));\n        dictEntry *de;\n\n        while((de = dictNext(di)) != NULL) {\n            robj *channel = dictGetKey(de);\n\n            count += pubsubUnsubscribeChannel(c,channel,notify,type);\n        }\n        dictReleaseIterator(di);\n    }\n    /* We were subscribed to nothing? Still reply to the client. */\n    if (notify && count == 0) {\n        addReplyPubsubUnsubscribed(c,NULL,type);\n    }\n    return count;\n}\n\n/*\n * Unsubscribe a client from all global channels.\n */\nint pubsubUnsubscribeAllChannels(client *c, int notify) {\n    int count = pubsubUnsubscribeAllChannelsInternal(c,notify,pubSubType);\n    return count;\n}\n\n/*\n * Unsubscribe a client from all shard subscribed channels.\n */\nint pubsubUnsubscribeShardAllChannels(client *c, int notify) {\n    int count = pubsubUnsubscribeAllChannelsInternal(c, notify, pubSubShardType);\n    return count;\n}\n\n/* Unsubscribe from all the patterns. Return the number of patterns the\n * client was subscribed from. */\nint pubsubUnsubscribeAllPatterns(client *c, int notify) {\n    int count = 0;\n\n    if (dictSize(c->pubsub_patterns) > 0) {\n        dictIterator *di = dictGetSafeIterator(c->pubsub_patterns);\n        dictEntry *de;\n\n        while ((de = dictNext(di)) != NULL) {\n            robj *pattern = dictGetKey(de);\n            count += pubsubUnsubscribePattern(c, pattern, notify);\n        }\n        dictReleaseIterator(di);\n    }\n\n    /* We were subscribed to nothing? Still reply to the client. */\n    if (notify && count == 0) addReplyPubsubPatUnsubscribed(c,NULL);\n    return count;\n}\n\n/*\n * Publish a message to all the subscribers.\n */\nint pubsubPublishMessageInternal(robj *channel, robj *message, pubsubtype type) {\n    int receivers = 0;\n    dictEntry *de;\n    dictIterator *di;\n    unsigned int slot = 0;\n\n    /* Send to clients listening for that channel */\n    if (server.cluster_enabled && type.shard) {\n        slot = keyHashSlot(channel->ptr, sdslen(channel->ptr));\n    }\n    de = kvstoreDictFind(*type.serverPubSubChannels, slot, channel);\n    if (de) {\n        dict *clients = dictGetVal(de);\n        dictEntry *entry;\n        dictIterator *iter = dictGetIterator(clients);\n        while ((entry = dictNext(iter)) != NULL) {\n            client *c = dictGetKey(entry);\n            addReplyPubsubMessage(c,channel,message,*type.messageBulk);\n            updateClientMemUsageAndBucket(c);\n            receivers++;\n        }\n        dictReleaseIterator(iter);\n    }\n\n    if (type.shard) {\n        /* Shard pubsub ignores patterns. */\n        return receivers;\n    }\n\n    /* Send to clients listening to matching channels */\n    di = dictGetIterator(server.pubsub_patterns);\n    if (di) {\n        channel = getDecodedObject(channel);\n        while((de = dictNext(di)) != NULL) {\n            robj *pattern = dictGetKey(de);\n            dict *clients = dictGetVal(de);\n            if (!stringmatchlen((char*)pattern->ptr,\n                                sdslen(pattern->ptr),\n                                (char*)channel->ptr,\n                                sdslen(channel->ptr),0)) continue;\n\n            dictEntry *entry;\n            dictIterator *iter = dictGetIterator(clients);\n            while ((entry = dictNext(iter)) != NULL) {\n                client *c = dictGetKey(entry);\n                addReplyPubsubPatMessage(c,pattern,channel,message);\n                updateClientMemUsageAndBucket(c);\n                receivers++;\n            }\n            dictReleaseIterator(iter);\n        }\n        decrRefCount(channel);\n        dictReleaseIterator(di);\n    }\n    return receivers;\n}\n\n/* Publish a message to all the subscribers. */\nint pubsubPublishMessage(robj *channel, robj *message, int sharded) {\n    return pubsubPublishMessageInternal(channel, message, sharded? pubSubShardType : pubSubType);\n}\n\n/*-----------------------------------------------------------------------------\n * Pubsub commands implementation\n *----------------------------------------------------------------------------*/\n\n/* SUBSCRIBE channel [channel ...] */\nvoid subscribeCommand(client *c) {\n    int j;\n    if ((c->flags & CLIENT_DENY_BLOCKING) && !(c->flags & CLIENT_MULTI)) {\n        /**\n         * A client that has CLIENT_DENY_BLOCKING flag on\n         * expect a reply per command and so can not execute subscribe.\n         *\n         * Notice that we have a special treatment for multi because of\n         * backward compatibility\n         */\n        addReplyError(c, \"SUBSCRIBE isn't allowed for a DENY BLOCKING client\");\n        return;\n"}, {"id": "DD93D5F1D417DC23", "name": "markClientAsPubSub", "path": "redis/src/pubsub.c", "start": {"line": 243, "col": 1}, "end": {"line": 248, "col": 1}, "code": "    if (!(c->flags & CLIENT_PUBSUB)) {\n        c->flags |= CLIENT_PUBSUB;\n        server.pubsub_clients++;\n    }\n}\n\nvoid unmarkClientAsPubSub(client *c) {\n    if (c->flags & CLIENT_PUBSUB) {\n        c->flags &= ~CLIENT_PUBSUB;\n        server.pubsub_clients--;\n    }\n}\n\n/* Subscribe a client to a channel. Returns 1 if the operation succeeded, or\n * 0 if the client was already subscribed to that channel. */\nint pubsubSubscribeChannel(client *c, robj *channel, pubsubtype type) {\n    dictEntry *de, *existing;\n    dict *clients = NULL;\n    int retval = 0;\n    unsigned int slot = 0;\n\n    /* Add the channel to the client -> channels hash table */\n    if (dictAdd(type.clientPubSubChannels(c),channel,NULL) == DICT_OK) {\n        retval = 1;\n        incrRefCount(channel);\n        /* Add the client to the channel -> list of clients hash table */\n        if (server.cluster_enabled && type.shard) {\n            slot = getKeySlot(channel->ptr);\n        }\n\n        de = kvstoreDictAddRaw(*type.serverPubSubChannels, slot, channel, &existing);\n\n        if (existing) {\n            clients = dictGetVal(existing);\n        } else {\n            clients = dictCreate(&clientDictType);\n            kvstoreDictSetVal(*type.serverPubSubChannels, slot, de, clients);\n            incrRefCount(channel);\n        }\n\n        serverAssert(dictAdd(clients, c, NULL) != DICT_ERR);\n    }\n    /* Notify the client */\n    addReplyPubsubSubscribed(c,channel,type);\n    return retval;\n}\n\n/* Unsubscribe a client from a channel. Returns 1 if the operation succeeded, or\n * 0 if the client was not subscribed to the specified channel. */\nint pubsubUnsubscribeChannel(client *c, robj *channel, int notify, pubsubtype type) {\n    dictEntry *de;\n    dict *clients;\n    int retval = 0;\n    int slot = 0;\n\n    /* Remove the channel from the client -> channels hash table */\n    incrRefCount(channel); /* channel may be just a pointer to the same object\n                            we have in the hash tables. Protect it... */\n    if (dictDelete(type.clientPubSubChannels(c),channel) == DICT_OK) {\n        retval = 1;\n        /* Remove the client from the channel -> clients list hash table */\n        if (server.cluster_enabled && type.shard) {\n            slot = getKeySlot(channel->ptr);\n        }\n        de = kvstoreDictFind(*type.serverPubSubChannels, slot, channel);\n        serverAssertWithInfo(c,NULL,de != NULL);\n        clients = dictGetVal(de);\n        serverAssertWithInfo(c, NULL, dictDelete(clients, c) == DICT_OK);\n        if (dictSize(clients) == 0) {\n            /* Free the dict and associated hash entry at all if this was\n             * the latest client, so that it will be possible to abuse\n             * Redis PUBSUB creating millions of channels. */\n            kvstoreDictDelete(*type.serverPubSubChannels, slot, channel);\n        }\n    }\n    /* Notify the client */\n    if (notify) {\n        addReplyPubsubUnsubscribed(c,channel,type);\n    }\n    decrRefCount(channel); /* it is finally safe to release it */\n    return retval;\n}\n\n/* Unsubscribe all shard channels in a slot. */\nvoid pubsubShardUnsubscribeAllChannelsInSlot(unsigned int slot) {\n    if (!kvstoreDictSize(server.pubsubshard_channels, slot))\n        return;\n\n    kvstoreDictIterator *kvs_di = kvstoreGetDictSafeIterator(server.pubsubshard_channels, slot);\n    dictEntry *de;\n    while ((de = kvstoreDictIteratorNext(kvs_di)) != NULL) {\n        robj *channel = dictGetKey(de);\n        dict *clients = dictGetVal(de);\n        /* For each client subscribed to the channel, unsubscribe it. */\n        dictIterator *iter = dictGetIterator(clients);\n        dictEntry *entry;\n        while ((entry = dictNext(iter)) != NULL) {\n            client *c = dictGetKey(entry);\n            int retval = dictDelete(c->pubsubshard_channels, channel);\n            serverAssertWithInfo(c,channel,retval == DICT_OK);\n            addReplyPubsubUnsubscribed(c, channel, pubSubShardType);\n            /* If the client has no other pubsub subscription,\n             * move out of pubsub mode. */\n            if (clientTotalPubSubSubscriptionCount(c) == 0) {\n                unmarkClientAsPubSub(c);\n            }\n        }\n        dictReleaseIterator(iter);\n        kvstoreDictDelete(server.pubsubshard_channels, slot, channel);\n    }\n    kvstoreReleaseDictIterator(kvs_di);\n}\n\n/* Subscribe a client to a pattern. Returns 1 if the operation succeeded, or 0 if the client was already subscribed to that pattern. */\nint pubsubSubscribePattern(client *c, robj *pattern) {\n    dictEntry *de;\n    dict *clients;\n    int retval = 0;\n\n    if (dictAdd(c->pubsub_patterns, pattern, NULL) == DICT_OK) {\n        retval = 1;\n        incrRefCount(pattern);\n        /* Add the client to the pattern -> list of clients hash table */\n        de = dictFind(server.pubsub_patterns,pattern);\n        if (de == NULL) {\n            clients = dictCreate(&clientDictType);\n            dictAdd(server.pubsub_patterns,pattern,clients);\n            incrRefCount(pattern);\n        } else {\n            clients = dictGetVal(de);\n        }\n        serverAssert(dictAdd(clients, c, NULL) != DICT_ERR);\n    }\n    /* Notify the client */\n    addReplyPubsubPatSubscribed(c,pattern);\n    return retval;\n}\n\n/* Unsubscribe a client from a channel. Returns 1 if the operation succeeded, or\n * 0 if the client was not subscribed to the specified channel. */\nint pubsubUnsubscribePattern(client *c, robj *pattern, int notify) {\n    dictEntry *de;\n    dict *clients;\n    int retval = 0;\n\n    incrRefCount(pattern); /* Protect the object. May be the same we remove */\n    if (dictDelete(c->pubsub_patterns, pattern) == DICT_OK) {\n        retval = 1;\n        /* Remove the client from the pattern -> clients list hash table */\n        de = dictFind(server.pubsub_patterns,pattern);\n        serverAssertWithInfo(c,NULL,de != NULL);\n        clients = dictGetVal(de);\n        serverAssertWithInfo(c, NULL, dictDelete(clients, c) == DICT_OK);\n        if (dictSize(clients) == 0) {\n            /* Free the dict and associated hash entry at all if this was\n             * the latest client. */\n            dictDelete(server.pubsub_patterns,pattern);\n        }\n    }\n    /* Notify the client */\n    if (notify) addReplyPubsubPatUnsubscribed(c,pattern);\n    decrRefCount(pattern);\n    return retval;\n}\n\n/* Unsubscribe from all the channels. Return the number of channels the\n * client was subscribed to. */\nint pubsubUnsubscribeAllChannelsInternal(client *c, int notify, pubsubtype type) {\n    int count = 0;\n    if (dictSize(type.clientPubSubChannels(c)) > 0) {\n        dictIterator *di = dictGetSafeIterator(type.clientPubSubChannels(c));\n        dictEntry *de;\n\n        while((de = dictNext(di)) != NULL) {\n            robj *channel = dictGetKey(de);\n\n            count += pubsubUnsubscribeChannel(c,channel,notify,type);\n        }\n        dictReleaseIterator(di);\n    }\n    /* We were subscribed to nothing? Still reply to the client. */\n    if (notify && count == 0) {\n        addReplyPubsubUnsubscribed(c,NULL,type);\n    }\n    return count;\n}\n\n/*\n * Unsubscribe a client from all global channels.\n */\nint pubsubUnsubscribeAllChannels(client *c, int notify) {\n    int count = pubsubUnsubscribeAllChannelsInternal(c,notify,pubSubType);\n    return count;\n}\n\n/*\n * Unsubscribe a client from all shard subscribed channels.\n */\nint pubsubUnsubscribeShardAllChannels(client *c, int notify) {\n    int count = pubsubUnsubscribeAllChannelsInternal(c, notify, pubSubShardType);\n    return count;\n}\n\n/* Unsubscribe from all the patterns. Return the number of patterns the\n * client was subscribed from. */\nint pubsubUnsubscribeAllPatterns(client *c, int notify) {\n    int count = 0;\n\n    if (dictSize(c->pubsub_patterns) > 0) {\n        dictIterator *di = dictGetSafeIterator(c->pubsub_patterns);\n        dictEntry *de;\n\n        while ((de = dictNext(di)) != NULL) {\n            robj *pattern = dictGetKey(de);\n            count += pubsubUnsubscribePattern(c, pattern, notify);\n        }\n        dictReleaseIterator(di);\n    }\n\n    /* We were subscribed to nothing? Still reply to the client. */\n    if (notify && count == 0) addReplyPubsubPatUnsubscribed(c,NULL);\n    return count;\n}\n\n/*\n * Publish a message to all the subscribers.\n */\nint pubsubPublishMessageInternal(robj *channel, robj *message, pubsubtype type) {\n    int receivers = 0;\n    dictEntry *de;\n    dictIterator *di;\n    unsigned int slot = 0;\n\n    /* Send to clients listening for that channel */\n    if (server.cluster_enabled && type.shard) {\n        slot = keyHashSlot(channel->ptr, sdslen(channel->ptr));\n    }\n    de = kvstoreDictFind(*type.serverPubSubChannels, slot, channel);\n    if (de) {\n        dict *clients = dictGetVal(de);\n        dictEntry *entry;\n        dictIterator *iter = dictGetIterator(clients);\n        while ((entry = dictNext(iter)) != NULL) {\n            client *c = dictGetKey(entry);\n            addReplyPubsubMessage(c,channel,message,*type.messageBulk);\n            updateClientMemUsageAndBucket(c);\n            receivers++;\n        }\n        dictReleaseIterator(iter);\n"}], "code": "void subscribeCommand(client *c) {\n    int j;\n    if ((c->flags & CLIENT_DENY_BLOCKING) && !(c->flags & CLIENT_MULTI)) {\n        /**\n         * A client that has CLIENT_DENY_BLOCKING flag on\n         * expect a reply per command and so can not execute subscribe.\n         *\n         * Notice that we have a special treatment for multi because of\n         * backward compatibility\n         */\n        addReplyError(c, \"SUBSCRIBE isn't allowed for a DENY BLOCKING client\");\n        return;\n    }\n    for (j = 1; j < c->argc; j++)\n        pubsubSubscribeChannel(c,c->argv[j],pubSubType);\n    markClientAsPubSub(c);\n}\n"}, "C1BC3BEC28C03F06": {"calls": [{"id": "41983AB5291BB54C", "name": "std::error_code::message", "path": "/usr/include/c++/11/system_error", "start": {"line": 237, "col": 5}, "end": {"line": 240, "col": 43}}], "code": "ErrorOr<StringRef> SampleProfileReaderBinary::readString() {\n  StringRef Str(reinterpret_cast<const char *>(Data));\n  if (Data + Str.size() + 1 > End) {\n    std::error_code EC = sampleprof_error::truncated;\n    reportError(0, EC.message());\n    return EC;\n  }\n\n  Data += Str.size() + 1;\n  return Str;\n}\n"}, "A7AB81C8E4DCDC67": {"calls": [{"id": "3F2294775E32A7FE", "name": "abort", "path": "/usr/include/stdlib.h", "start": {"line": 598, "col": 1}, "end": {"line": 598, "col": 63}}], "code": "  void grow(size_t N) {\n    size_t Need = N + CurrentPosition;\n    if (Need > BufferCapacity) {\n      // Reduce the number of reallocations, with a bit of hysteresis. The\n      // number here is chosen so the first allocation will more-than-likely not\n      // allocate more than 1K.\n      Need += 1024 - 32;\n      BufferCapacity *= 2;\n      if (BufferCapacity < Need)\n        BufferCapacity = Need;\n      Buffer = static_cast<char *>(std::realloc(Buffer, BufferCapacity));\n      if (Buffer == nullptr)\n        std::abort();\n    }\n  }\n"}, "BD2DC0F2F8DD4DEC": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}], "code": "void OrcX86_64_Base::writeTrampolines(char *TrampolineBlockWorkingMem,\n                                      ExecutorAddr TrampolineBlockTargetAddress,\n                                      ExecutorAddr ResolverAddr,\n                                      unsigned NumTrampolines) {\n\n  unsigned OffsetToPtr = NumTrampolines * TrampolineSize;\n\n  memcpy(TrampolineBlockWorkingMem + OffsetToPtr, &ResolverAddr,\n         sizeof(uint64_t));\n\n  uint64_t *Trampolines =\n      reinterpret_cast<uint64_t *>(TrampolineBlockWorkingMem);\n  uint64_t CallIndirPCRel = 0xf1c40000000015ff;\n\n  for (unsigned I = 0; I < NumTrampolines; ++I, OffsetToPtr -= TrampolineSize)\n    Trampolines[I] = CallIndirPCRel | ((OffsetToPtr - 6) << 16);\n}\n"}, "04C8813A1EE4450F": {"calls": [{"id": "218565AF4CADA005", "name": "std::error_code::operator bool", "path": "/usr/include/c++/11/system_error", "start": {"line": 242, "col": 5}, "end": {"line": 243, "col": 29}}], "code": "ErrorOr<std::unique_ptr<SampleProfileReader>>\nSampleProfileReader::create(const std::string Filename, LLVMContext &C,\n                            vfs::FileSystem &FS, FSDiscriminatorPass P,\n                            const std::string RemapFilename) {\n  auto BufferOrError = setupMemoryBuffer(Filename, FS);\n  if (std::error_code EC = BufferOrError.getError())\n    return EC;\n  return create(BufferOrError.get(), C, FS, P, RemapFilename);\n}\n"}, "A19320F747B60D76": {"calls": [{"id": "218565AF4CADA005", "name": "std::error_code::operator bool", "path": "/usr/include/c++/11/system_error", "start": {"line": 242, "col": 5}, "end": {"line": 243, "col": 29}}], "code": "std::error_code llvm::EmitImportsFiles(\n    StringRef ModulePath, StringRef OutputFilename,\n    const std::map<std::string, GVSummaryMapTy> &ModuleToSummariesForIndex) {\n  std::error_code EC;\n  raw_fd_ostream ImportsOS(OutputFilename, EC, sys::fs::OpenFlags::OF_None);\n  if (EC)\n    return EC;\n  for (const auto &ILI : ModuleToSummariesForIndex)\n    // The ModuleToSummariesForIndex map includes an entry for the current\n    // Module (needed for writing out the index files). We don't want to\n    // include it in the imports file, however, so filter it out.\n    if (ILI.first != ModulePath)\n      ImportsOS << ILI.first << \"\\n\";\n  return std::error_code();\n}\n"}, "10B1B6E197369BB6": {"calls": [{"id": "79A75B37732ED7D6", "name": "std::condition_variable::notify_all", "path": "/usr/include/c++/11/condition_variable", "start": {"line": 92, "col": 5}, "end": {"line": 93, "col": 18}}], "code": "ThreadPool::~ThreadPool() {\n  {\n    std::unique_lock<std::mutex> LockGuard(QueueLock);\n    EnableFlag = false;\n  }\n  QueueCondition.notify_all();\n  llvm::sys::ScopedReader LockGuard(ThreadsLock);\n  for (auto &Worker : Threads)\n    Worker.join();\n}\n"}, "455EF5EE60B536EC": {"calls": [{"id": "9F48B16FB25170B0", "name": "getenv", "path": "/usr/include/stdlib.h", "start": {"line": 641, "col": 1}, "end": {"line": 641, "col": 50}}], "code": "std::chrono::milliseconds getDefaultDebuginfodTimeout() {\n  long Timeout;\n  const char *DebuginfodTimeoutEnv = std::getenv(\"DEBUGINFOD_TIMEOUT\");\n  if (DebuginfodTimeoutEnv &&\n      to_integer(StringRef(DebuginfodTimeoutEnv).trim(), Timeout, 10))\n    return std::chrono::milliseconds(Timeout * 1000);\n\n  return std::chrono::milliseconds(90 * 1000);\n}\n"}, "9F07BA675598F8EA": {"calls": [{"id": "99EEC24AE0821E03", "name": "std::numeric_limits<unsigned int>::max", "path": "/usr/include/c++/11/limits", "start": {"line": 1134, "col": 7}, "end": {"line": 1135, "col": 66}}], "code": "  void initializePackExpansion(OutputBuffer &OB) const {\n    if (OB.CurrentPackMax == std::numeric_limits<unsigned>::max()) {\n      OB.CurrentPackMax = static_cast<unsigned>(Data.size());\n      OB.CurrentPackIndex = 0;\n    }\n  }\n"}, "5F93B753CE8A58FE": {"calls": [{"id": "218565AF4CADA005", "name": "std::error_code::operator bool", "path": "/usr/include/c++/11/system_error", "start": {"line": 242, "col": 5}, "end": {"line": 243, "col": 29}}], "code": "std::unique_ptr<MIRParser> llvm::createMIRParserFromFile(\n    StringRef Filename, SMDiagnostic &Error, LLVMContext &Context,\n    std::function<void(Function &)> ProcessIRFunction) {\n  auto FileOrErr = MemoryBuffer::getFileOrSTDIN(Filename, /*IsText=*/true);\n  if (std::error_code EC = FileOrErr.getError()) {\n    Error = SMDiagnostic(Filename, SourceMgr::DK_Error,\n                         \"Could not open input file: \" + EC.message());\n    return nullptr;\n  }\n  return createMIRParser(std::move(FileOrErr.get()), Context,\n                         ProcessIRFunction);\n}\n"}, "6A6BE28E5DA17399": {"calls": [{"id": "5B907C42BEDCBD08", "name": "std::set_new_handler", "path": "/usr/include/c++/11/new", "start": {"line": 107, "col": 3}, "end": {"line": 107, "col": 50}}], "code": "void llvm::install_out_of_memory_new_handler() {\n  std::new_handler old = std::set_new_handler(out_of_memory_new_handler);\n  (void)old;\n  assert((old == nullptr || old == out_of_memory_new_handler) &&\n         \"new-handler already installed\");\n}\n"}, "E9A0485F1DBF0175": {"calls": [{"id": "554AD0080D90E364", "name": "std::numeric_limits<unsigned char>::max", "path": "/usr/include/c++/11/limits", "start": {"line": 597, "col": 7}, "end": {"line": 598, "col": 68}}], "code": "unsigned SourceMgr::SrcBuffer::getLineNumber(const char *Ptr) const {\n  size_t Sz = Buffer->getBufferSize();\n  if (Sz <= std::numeric_limits<uint8_t>::max())\n    return getLineNumberSpecialized<uint8_t>(Ptr);\n  else if (Sz <= std::numeric_limits<uint16_t>::max())\n    return getLineNumberSpecialized<uint16_t>(Ptr);\n  else if (Sz <= std::numeric_limits<uint32_t>::max())\n    return getLineNumberSpecialized<uint32_t>(Ptr);\n  else\n    return getLineNumberSpecialized<uint64_t>(Ptr);\n}\n"}, "1635888CFAE50587": {"calls": [{"id": "F02A2DCA89E528AB", "name": "operator new", "path": "/usr/include/c++/11/new", "start": {"line": 149, "col": 20}, "end": {"line": 150, "col": 73}}], "code": "LLVM_ATTRIBUTE_RETURNS_NONNULL LLVM_ATTRIBUTE_RETURNS_NOALIAS void *\nllvm::allocate_buffer(size_t Size, size_t Alignment) {\n  return ::operator new(Size\n#ifdef __cpp_aligned_new\n                        ,\n                        std::align_val_t(Alignment)\n#endif\n  );\n}\n"}, "1BB1EAA93F31CA22": {"calls": [{"id": "19B3308B1AB6348D", "name": "std::atomic<bool>::load", "path": "/usr/include/c++/11/atomic", "start": {"line": 110, "col": 5}, "end": {"line": 112, "col": 33}}], "code": "static const NEONLdStTableEntry *LookupNEONLdSt(unsigned Opcode) {\n#ifndef NDEBUG\n  // Make sure the table is sorted.\n  static std::atomic<bool> TableChecked(false);\n  if (!TableChecked.load(std::memory_order_relaxed)) {\n    assert(llvm::is_sorted(NEONLdStTable) && \"NEONLdStTable is not sorted!\");\n    TableChecked.store(true, std::memory_order_relaxed);\n  }\n#endif\n\n  auto I = llvm::lower_bound(NEONLdStTable, Opcode);\n  if (I != std::end(NEONLdStTable) && I->PseudoOpc == Opcode)\n    return I;\n  return nullptr;\n}\n"}, "DCC42EFE21BAC90C": {"calls": [{"id": "9FB50521EE51F448", "name": "memcpy", "path": "/usr/include/string.h", "start": {"line": 43, "col": 1}, "end": {"line": 44, "col": 28}}], "code": "  BasicBlockBits getBasicBlockBits() const {\n    static_assert(sizeof(BasicBlockBits) == sizeof(unsigned short),\n                  \"too many bits for Value::SubclassData\");\n    unsigned short ValueData = getSubclassDataFromValue();\n    BasicBlockBits AsBits;\n    memcpy(&AsBits, &ValueData, sizeof(AsBits));\n    return AsBits;\n  }\n"}, "65864C55741B0B7A": {"calls": [{"id": "76570F39EEB577F3", "name": "llvm::CodeGenSubRegIndex::getComposites", "path": "llvm-project/llvm/utils/TableGen/CodeGenRegisters.h", "start": {"line": 132, "col": 3}, "end": {"line": 132, "col": 59}, "code": "\n  // Compute LaneMask from Composed. Return LaneMask.\n  LaneBitmask computeLaneMask() const;\n\n  void setConcatenationOf(ArrayRef<CodeGenSubRegIndex *> Parts);\n\n  /// Replaces subregister indexes in the `ConcatenationOf` list with\n  /// list of subregisters they are composed of (if any). Do this recursively.\n  void computeConcatTransitiveClosure();\n\n  bool operator<(const CodeGenSubRegIndex &RHS) const {\n    return this->EnumValue < RHS.EnumValue;\n  }\n\nprivate:\n  CompMap Composed;\n};\n\n/// CodeGenRegister - Represents a register definition.\nclass CodeGenRegister {\npublic:\n  Record *TheDef;\n  unsigned EnumValue;\n  std::vector<int64_t> CostPerUse;\n  bool CoveredBySubRegs = true;\n  bool HasDisjunctSubRegs = false;\n  bool Artificial = true;\n  bool Constant = false;\n\n  // Map SubRegIndex -> Register.\n  typedef std::map<CodeGenSubRegIndex *, CodeGenRegister *, deref<std::less<>>>\n      SubRegMap;\n\n  CodeGenRegister(Record *R, unsigned Enum);\n\n  StringRef getName() const;\n\n  // Extract more information from TheDef. This is used to build an object\n  // graph after all CodeGenRegister objects have been created.\n  void buildObjectGraph(CodeGenRegBank &);\n\n  // Lazily compute a map of all sub-registers.\n  // This includes unique entries for all sub-sub-registers.\n  const SubRegMap &computeSubRegs(CodeGenRegBank &);\n\n  // Compute extra sub-registers by combining the existing sub-registers.\n  void computeSecondarySubRegs(CodeGenRegBank &);\n\n  // Add this as a super-register to all sub-registers after the sub-register\n  // graph has been built.\n  void computeSuperRegs(CodeGenRegBank &);\n\n  const SubRegMap &getSubRegs() const {\n    assert(SubRegsComplete && \"Must precompute sub-registers\");\n    return SubRegs;\n  }\n\n  // Add sub-registers to OSet following a pre-order defined by the .td file.\n  void addSubRegsPreOrder(SetVector<const CodeGenRegister *> &OSet,\n                          CodeGenRegBank &) const;\n\n  // Return the sub-register index naming Reg as a sub-register of this\n  // register. Returns NULL if Reg is not a sub-register.\n  CodeGenSubRegIndex *getSubRegIndex(const CodeGenRegister *Reg) const {\n    return SubReg2Idx.lookup(Reg);\n  }\n\n  typedef std::vector<const CodeGenRegister *> SuperRegList;\n\n  // Get the list of super-registers in topological order, small to large.\n  // This is valid after computeSubRegs visits all registers during RegBank\n  // construction.\n  const SuperRegList &getSuperRegs() const {\n    assert(SubRegsComplete && \"Must precompute sub-registers\");\n    return SuperRegs;\n  }\n\n  // Get the list of ad hoc aliases. The graph is symmetric, so the list\n  // contains all registers in 'Aliases', and all registers that mention this\n  // register in 'Aliases'.\n  ArrayRef<CodeGenRegister *> getExplicitAliases() const {\n    return ExplicitAliases;\n  }\n\n  // Get the topological signature of this register. This is a small integer\n  // less than RegBank.getNumTopoSigs(). Registers with the same TopoSig have\n  // identical sub-register structure. That is, they support the same set of\n  // sub-register indices mapping to the same kind of sub-registers\n  // (TopoSig-wise).\n  unsigned getTopoSig() const {\n    assert(SuperRegsComplete && \"TopoSigs haven't been computed yet.\");\n    return TopoSig;\n  }\n\n  // List of register units in ascending order.\n  typedef SparseBitVector<> RegUnitList;\n  typedef SmallVector<LaneBitmask, 16> RegUnitLaneMaskList;\n\n  // How many entries in RegUnitList are native?\n  RegUnitList NativeRegUnits;\n\n  // Get the list of register units.\n  // This is only valid after computeSubRegs() completes.\n  const RegUnitList &getRegUnits() const { return RegUnits; }\n\n  ArrayRef<LaneBitmask> getRegUnitLaneMasks() const {\n    return ArrayRef(RegUnitLaneMasks).slice(0, NativeRegUnits.count());\n  }\n\n  // Get the native register units. This is a prefix of getRegUnits().\n  RegUnitList getNativeRegUnits() const { return NativeRegUnits; }\n\n  void setRegUnitLaneMasks(const RegUnitLaneMaskList &LaneMasks) {\n    RegUnitLaneMasks = LaneMasks;\n  }\n\n  // Inherit register units from subregisters.\n  // Return true if the RegUnits changed.\n  bool inheritRegUnits(CodeGenRegBank &RegBank);\n\n  // Adopt a register unit for pressure tracking.\n  // A unit is adopted iff its unit number is >= NativeRegUnits.count().\n  void adoptRegUnit(unsigned RUID) { RegUnits.set(RUID); }\n\n  // Get the sum of this register's register unit weights.\n  unsigned getWeight(const CodeGenRegBank &RegBank) const;\n\n  // Canonically ordered set.\n  typedef std::vector<const CodeGenRegister *> Vec;\n\nprivate:\n  bool SubRegsComplete;\n  bool SuperRegsComplete;\n"}], "code": "static bool combine(const CodeGenSubRegIndex *Idx,\n                    SmallVectorImpl<CodeGenSubRegIndex *> &Vec) {\n  const CodeGenSubRegIndex::CompMap &Map = Idx->getComposites();\n  for (const auto &I : Map) {\n    CodeGenSubRegIndex *&Entry = Vec[I.first->EnumValue - 1];\n    if (Entry && Entry != I.second)\n      return false;\n  }\n\n  // All entries are compatible. Make it so.\n  for (const auto &I : Map) {\n    auto *&Entry = Vec[I.first->EnumValue - 1];\n    assert((!Entry || Entry == I.second) && \"Expected EnumValue to be unique\");\n    Entry = I.second;\n  }\n  return true;\n}\n"}, "2203A9ADE06F7F30": {"calls": [{"id": "297A68B3DBD6C97C", "name": "llvm::TreePatternNode::getTransformFn", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 768, "col": 3}, "end": {"line": 768, "col": 56}, "code": "  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "7C857B410BB6A85B", "name": "llvm::TreePatternNode::setTransformFn", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 769, "col": 3}, "end": {"line": 769, "col": 55}, "code": "\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "2203A9ADE06F7F30", "name": "PromoteXForms", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp", "start": {"line": 4220, "col": 1}, "end": {"line": 4235, "col": 1}, "code": "  if (Record *Xform = N->getTransformFn()) {\n    N->setTransformFn(nullptr);\n    std::vector<TreePatternNodePtr> Children;\n    Children.push_back(PromoteXForms(N));\n    return makeIntrusiveRefCnt<TreePatternNode>(Xform, std::move(Children),\n                                                N->getNumTypes());\n  }\n\n  if (!N->isLeaf())\n    for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i) {\n      TreePatternNodePtr Child = N->getChildShared(i);\n      N->setChild(i, PromoteXForms(Child));\n    }\n  return N;\n}\n\nvoid CodeGenDAGPatterns::ParseOnePattern(\n    Record *TheDef, TreePattern &Pattern, TreePattern &Result,\n    const std::vector<Record *> &InstImpResults) {\n\n  // Inline pattern fragments and expand multiple alternatives.\n  Pattern.InlinePatternFragments();\n  Result.InlinePatternFragments();\n\n  if (Result.getNumTrees() != 1)\n    Result.error(\"Cannot use multi-alternative fragments in result pattern!\");\n\n  // Infer types.\n  bool IterateInference;\n  bool InferredAllPatternTypes, InferredAllResultTypes;\n  do {\n    // Infer as many types as possible.  If we cannot infer all of them, we\n    // can never do anything with this pattern: report it to the user.\n    InferredAllPatternTypes =\n        Pattern.InferAllTypes(&Pattern.getNamedNodesMap());\n\n    // Infer as many types as possible.  If we cannot infer all of them, we\n    // can never do anything with this pattern: report it to the user.\n    InferredAllResultTypes = Result.InferAllTypes(&Pattern.getNamedNodesMap());\n\n    IterateInference = false;\n\n    // Apply the type of the result to the source pattern.  This helps us\n    // resolve cases where the input type is known to be a pointer type (which\n    // is considered resolved), but the result knows it needs to be 32- or\n    // 64-bits.  Infer the other way for good measure.\n    for (const auto &T : Pattern.getTrees())\n      for (unsigned i = 0, e = std::min(Result.getOnlyTree()->getNumTypes(),\n                                        T->getNumTypes());\n           i != e; ++i) {\n        IterateInference |=\n            T->UpdateNodeType(i, Result.getOnlyTree()->getExtType(i), Result);\n        IterateInference |=\n            Result.getOnlyTree()->UpdateNodeType(i, T->getExtType(i), Result);\n      }\n\n    // If our iteration has converged and the input pattern's types are fully\n    // resolved but the result pattern is not fully resolved, we may have a\n    // situation where we have two instructions in the result pattern and\n    // the instructions require a common register class, but don't care about\n    // what actual MVT is used.  This is actually a bug in our modelling:\n    // output patterns should have register classes, not MVTs.\n    //\n    // In any case, to handle this, we just go through and disambiguate some\n    // arbitrary types to the result pattern's nodes.\n    if (!IterateInference && InferredAllPatternTypes && !InferredAllResultTypes)\n      IterateInference =\n          ForceArbitraryInstResultType(*Result.getTree(0), Result);\n  } while (IterateInference);\n\n  // Verify that we inferred enough types that we can do something with the\n  // pattern and result.  If these fire the user has to add type casts.\n  if (!InferredAllPatternTypes)\n    Pattern.error(\"Could not infer all types in pattern!\");\n  if (!InferredAllResultTypes) {\n    Pattern.dump();\n    Result.error(\"Could not infer all types in pattern result!\");\n  }\n\n  // Promote xform function to be an explicit node wherever set.\n  TreePatternNodePtr DstShared = PromoteXForms(Result.getOnlyTree());\n\n  TreePattern Temp(Result.getRecord(), DstShared, false, *this);\n  Temp.InferAllTypes();\n\n  ListInit *Preds = TheDef->getValueAsListInit(\"Predicates\");\n  int Complexity = TheDef->getValueAsInt(\"AddedComplexity\");\n\n  if (PatternRewriter)\n    PatternRewriter(&Pattern);\n\n  // A pattern may end up with an \"impossible\" type, i.e. a situation\n  // where all types have been eliminated for some node in this pattern.\n  // This could occur for intrinsics that only make sense for a specific\n  // value type, and use a specific register class. If, for some mode,\n  // that register class does not accept that type, the type inference\n  // will lead to a contradiction, which is not an error however, but\n  // a sign that this pattern will simply never match.\n  if (Temp.getOnlyTree()->hasPossibleType()) {\n    for (const auto &T : Pattern.getTrees()) {\n      if (T->hasPossibleType())\n        AddPatternToMatch(&Pattern,\n                          PatternToMatch(TheDef, Preds, T, Temp.getOnlyTree(),\n                                         InstImpResults, Complexity,\n                                         TheDef->getID()));\n    }\n  } else {\n    // Show a message about a dropped pattern with some info to make it\n    // easier to identify it in the .td files.\n    LLVM_DEBUG({\n      dbgs() << \"Dropping: \";\n      Pattern.dump();\n      Temp.getOnlyTree()->dump();\n      dbgs() << \"\\n\";\n    });\n  }\n}\n\nvoid CodeGenDAGPatterns::ParsePatterns() {\n  std::vector<Record *> Patterns = Records.getAllDerivedDefinitions(\"Pattern\");\n\n  for (Record *CurPattern : Patterns) {\n    DagInit *Tree = CurPattern->getValueAsDag(\"PatternToMatch\");\n\n    // If the pattern references the null_frag, there's nothing to do.\n    if (hasNullFragReference(Tree))\n      continue;\n\n    TreePattern Pattern(CurPattern, Tree, true, *this);\n\n    ListInit *LI = CurPattern->getValueAsListInit(\"ResultInstrs\");\n    if (LI->empty())\n      continue; // no pattern.\n\n    // Parse the instruction.\n    TreePattern Result(CurPattern, LI, false, *this);\n\n    if (Result.getNumTrees() != 1)\n      Result.error(\"Cannot handle instructions producing instructions \"\n                   \"with temporaries yet!\");\n\n    // Validate that the input pattern is correct.\n    std::map<std::string, TreePatternNodePtr> InstInputs;\n    MapVector<std::string, TreePatternNodePtr, std::map<std::string, unsigned>>\n        InstResults;\n    std::vector<Record *> InstImpResults;\n    for (unsigned j = 0, ee = Pattern.getNumTrees(); j != ee; ++j)\n      FindPatternInputsAndOutputs(Pattern, Pattern.getTree(j), InstInputs,\n                                  InstResults, InstImpResults);\n\n    ParseOnePattern(CurPattern, Pattern, Result, InstImpResults);\n  }\n}\n\nstatic void collectModes(std::set<unsigned> &Modes, const TreePatternNode &N) {\n  for (const TypeSetByHwMode &VTS : N.getExtTypes())\n    for (const auto &I : VTS)\n      Modes.insert(I.first);\n\n  for (unsigned i = 0, e = N.getNumChildren(); i != e; ++i)\n    collectModes(Modes, N.getChild(i));\n}\n\nvoid CodeGenDAGPatterns::ExpandHwModeBasedTypes() {\n  const CodeGenHwModes &CGH = getTargetInfo().getHwModes();\n  if (CGH.getNumModeIds() == 1)\n    return;\n\n  std::vector<PatternToMatch> Copy;\n  PatternsToMatch.swap(Copy);\n\n  auto AppendPattern = [this](PatternToMatch &P, unsigned Mode,\n                              StringRef Check) {\n    TreePatternNodePtr NewSrc = P.getSrcPattern().clone();\n    TreePatternNodePtr NewDst = P.getDstPattern().clone();\n    if (!NewSrc->setDefaultMode(Mode) || !NewDst->setDefaultMode(Mode)) {\n      return;\n    }\n\n    PatternsToMatch.emplace_back(P.getSrcRecord(), P.getPredicates(),\n                                 std::move(NewSrc), std::move(NewDst),\n                                 P.getDstRegs(), P.getAddedComplexity(),\n                                 Record::getNewUID(Records), Check);\n  };\n\n  for (PatternToMatch &P : Copy) {\n    const TreePatternNode *SrcP = nullptr, *DstP = nullptr;\n    if (P.getSrcPattern().hasProperTypeByHwMode())\n      SrcP = &P.getSrcPattern();\n    if (P.getDstPattern().hasProperTypeByHwMode())\n      DstP = &P.getDstPattern();\n    if (!SrcP && !DstP) {\n      PatternsToMatch.push_back(P);\n      continue;\n    }\n\n    std::set<unsigned> Modes;\n    if (SrcP)\n      collectModes(Modes, *SrcP);\n    if (DstP)\n      collectModes(Modes, *DstP);\n\n    // The predicate for the default mode needs to be constructed for each\n    // pattern separately.\n    // Since not all modes must be present in each pattern, if a mode m is\n    // absent, then there is no point in constructing a check for m. If such\n    // a check was created, it would be equivalent to checking the default\n    // mode, except not all modes' predicates would be a part of the checking\n    // code. The subsequently generated check for the default mode would then\n    // have the exact same patterns, but a different predicate code. To avoid\n    // duplicated patterns with different predicate checks, construct the\n    // default check as a negation of all predicates that are actually present\n    // in the source/destination patterns.\n    SmallString<128> DefaultCheck;\n\n    for (unsigned M : Modes) {\n      if (M == DefaultMode)\n        continue;\n\n      // Fill the map entry for this mode.\n      const HwMode &HM = CGH.getMode(M);\n      AppendPattern(P, M, HM.Predicates);\n\n      // Add negations of the HM's predicates to the default predicate.\n      if (!DefaultCheck.empty())\n        DefaultCheck += \" && \";\n      DefaultCheck += \"!(\";\n      DefaultCheck += HM.Predicates;\n      DefaultCheck += \")\";\n    }\n\n    bool HasDefault = Modes.count(DefaultMode);\n    if (HasDefault)\n      AppendPattern(P, DefaultMode, DefaultCheck);\n  }\n}\n\n/// Dependent variable map for CodeGenDAGPattern variant generation\ntypedef StringMap<int> DepVarMap;\n\nstatic void FindDepVarsOf(TreePatternNode &N, DepVarMap &DepMap) {\n  if (N.isLeaf()) {\n    if (N.hasName() && isa<DefInit>(N.getLeafValue()))\n      DepMap[N.getName()]++;\n  } else {\n    for (size_t i = 0, e = N.getNumChildren(); i != e; ++i)\n      FindDepVarsOf(N.getChild(i), DepMap);\n  }\n}\n\n/// Find dependent variables within child patterns\nstatic void FindDepVars(TreePatternNode &N, MultipleUseVarSet &DepVars) {\n  DepVarMap depcounts;\n  FindDepVarsOf(N, depcounts);\n  for (const auto &Pair : depcounts) {\n    if (Pair.getValue() > 1)\n      DepVars.insert(Pair.getKey());\n  }\n}\n\n#ifndef NDEBUG\n/// Dump the dependent variable set:\nstatic void DumpDepVars(MultipleUseVarSet &DepVars) {\n  if (DepVars.empty()) {\n    LLVM_DEBUG(errs() << \"<empty set>\");\n  } else {\n    LLVM_DEBUG(errs() << \"[ \");\n    for (const auto &DepVar : DepVars) {\n      LLVM_DEBUG(errs() << DepVar.getKey() << \" \");\n    }\n    LLVM_DEBUG(errs() << \"]\");\n  }\n}\n#endif\n\n/// CombineChildVariants - Given a bunch of permutations of each child of the\n/// 'operator' node, put them together in all possible ways.\nstatic void CombineChildVariants(\n    TreePatternNodePtr Orig,\n    const std::vector<std::vector<TreePatternNodePtr>> &ChildVariants,\n    std::vector<TreePatternNodePtr> &OutVariants, CodeGenDAGPatterns &CDP,\n    const MultipleUseVarSet &DepVars) {\n  // Make sure that each operand has at least one variant to choose from.\n  for (const auto &Variants : ChildVariants)\n    if (Variants.empty())\n      return;\n\n  // The end result is an all-pairs construction of the resultant pattern.\n  std::vector<unsigned> Idxs(ChildVariants.size());\n  bool NotDone;\n  do {\n#ifndef NDEBUG\n    LLVM_DEBUG(if (!Idxs.empty()) {\n      errs() << Orig->getOperator()->getName() << \": Idxs = [ \";\n      for (unsigned Idx : Idxs) {\n        errs() << Idx << \" \";\n      }\n      errs() << \"]\\n\";\n    });\n#endif\n    // Create the variant and add it to the output list.\n    std::vector<TreePatternNodePtr> NewChildren;\n    NewChildren.reserve(ChildVariants.size());\n    for (unsigned i = 0, e = ChildVariants.size(); i != e; ++i)\n      NewChildren.push_back(ChildVariants[i][Idxs[i]]);\n    TreePatternNodePtr R = makeIntrusiveRefCnt<TreePatternNode>(\n        Orig->getOperator(), std::move(NewChildren), Orig->getNumTypes());\n\n    // Copy over properties.\n    R->setName(Orig->getName());\n    R->setNamesAsPredicateArg(Orig->getNamesAsPredicateArg());\n    R->setPredicateCalls(Orig->getPredicateCalls());\n    R->setGISelFlagsRecord(Orig->getGISelFlagsRecord());\n    R->setTransformFn(Orig->getTransformFn());\n    for (unsigned i = 0, e = Orig->getNumTypes(); i != e; ++i)\n      R->setType(i, Orig->getExtType(i));\n\n    // If this pattern cannot match, do not include it as a variant.\n    std::string ErrString;\n    // Scan to see if this pattern has already been emitted.  We can get\n    // duplication due to things like commuting:\n    //   (and GPRC:$a, GPRC:$b) -> (and GPRC:$b, GPRC:$a)\n    // which are the same pattern.  Ignore the dups.\n    if (R->canPatternMatch(ErrString, CDP) &&\n        none_of(OutVariants, [&](TreePatternNodePtr Variant) {\n          return R->isIsomorphicTo(*Variant, DepVars);\n        }))\n      OutVariants.push_back(R);\n\n    // Increment indices to the next permutation by incrementing the\n    // indices from last index backward, e.g., generate the sequence\n    // [0, 0], [0, 1], [1, 0], [1, 1].\n    int IdxsIdx;\n    for (IdxsIdx = Idxs.size() - 1; IdxsIdx >= 0; --IdxsIdx) {\n      if (++Idxs[IdxsIdx] == ChildVariants[IdxsIdx].size())\n        Idxs[IdxsIdx] = 0;\n      else\n        break;\n    }\n    NotDone = (IdxsIdx >= 0);\n  } while (NotDone);\n}\n\n/// CombineChildVariants - A helper function for binary operators.\n///\nstatic void CombineChildVariants(TreePatternNodePtr Orig,\n                                 const std::vector<TreePatternNodePtr> &LHS,\n                                 const std::vector<TreePatternNodePtr> &RHS,\n                                 std::vector<TreePatternNodePtr> &OutVariants,\n                                 CodeGenDAGPatterns &CDP,\n                                 const MultipleUseVarSet &DepVars) {\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants;\n  ChildVariants.push_back(LHS);\n  ChildVariants.push_back(RHS);\n  CombineChildVariants(Orig, ChildVariants, OutVariants, CDP, DepVars);\n}\n\nstatic void\nGatherChildrenOfAssociativeOpcode(TreePatternNodePtr N,\n                                  std::vector<TreePatternNodePtr> &Children) {\n  assert(N->getNumChildren() == 2 &&\n         \"Associative but doesn't have 2 children!\");\n  Record *Operator = N->getOperator();\n\n  // Only permit raw nodes.\n  if (!N->getName().empty() || !N->getPredicateCalls().empty() ||\n      N->getTransformFn()) {\n    Children.push_back(N);\n    return;\n  }\n\n  if (N->getChild(0).isLeaf() || N->getChild(0).getOperator() != Operator)\n    Children.push_back(N->getChildShared(0));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(0), Children);\n\n  if (N->getChild(1).isLeaf() || N->getChild(1).getOperator() != Operator)\n    Children.push_back(N->getChildShared(1));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(1), Children);\n}\n\n/// GenerateVariantsOf - Given a pattern N, generate all permutations we can of\n/// the (potentially recursive) pattern by using algebraic laws.\n///\nstatic void GenerateVariantsOf(TreePatternNodePtr N,\n                               std::vector<TreePatternNodePtr> &OutVariants,\n                               CodeGenDAGPatterns &CDP,\n                               const MultipleUseVarSet &DepVars) {\n  // We cannot permute leaves or ComplexPattern uses.\n  if (N->isLeaf() || N->getOperator()->isSubClassOf(\"ComplexPattern\")) {\n    OutVariants.push_back(N);\n    return;\n  }\n\n  // Look up interesting info about the node.\n  const SDNodeInfo &NodeInfo = CDP.getSDNodeInfo(N->getOperator());\n\n  // If this node is associative, re-associate.\n  if (NodeInfo.hasProperty(SDNPAssociative)) {\n    // Re-associate by pulling together all of the linked operators\n    std::vector<TreePatternNodePtr> MaximalChildren;\n    GatherChildrenOfAssociativeOpcode(N, MaximalChildren);\n\n    // Only handle child sizes of 3.  Otherwise we'll end up trying too many\n    // permutations.\n    if (MaximalChildren.size() == 3) {\n      // Find the variants of all of our maximal children.\n      std::vector<TreePatternNodePtr> AVariants, BVariants, CVariants;\n      GenerateVariantsOf(MaximalChildren[0], AVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[1], BVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[2], CVariants, CDP, DepVars);\n\n      // There are only two ways we can permute the tree:\n      //   (A op B) op C    and    A op (B op C)\n      // Within these forms, we can also permute A/B/C.\n\n      // Generate legal pair permutations of A/B/C.\n      std::vector<TreePatternNodePtr> ABVariants;\n      std::vector<TreePatternNodePtr> BAVariants;\n      std::vector<TreePatternNodePtr> ACVariants;\n      std::vector<TreePatternNodePtr> CAVariants;\n      std::vector<TreePatternNodePtr> BCVariants;\n      std::vector<TreePatternNodePtr> CBVariants;\n      CombineChildVariants(N, AVariants, BVariants, ABVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, AVariants, BAVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CVariants, ACVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, AVariants, CAVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CVariants, BCVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BVariants, CBVariants, CDP, DepVars);\n\n      // Combine those into the result: (x op x) op x\n      CombineChildVariants(N, ABVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BAVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, ACVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CAVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BCVariants, AVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CBVariants, AVariants, OutVariants, CDP, DepVars);\n\n      // Combine those into the result: x op (x op x)\n      CombineChildVariants(N, CVariants, ABVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, ACVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, BCVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CBVariants, OutVariants, CDP, DepVars);\n      return;\n    }\n  }\n\n  // Compute permutations of all children.\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants(\n      N->getNumChildren());\n  for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i)\n    GenerateVariantsOf(N->getChildShared(i), ChildVariants[i], CDP, DepVars);\n\n  // Build all permutations based on how the children were formed.\n  CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n\n  // If this node is commutative, consider the commuted order.\n  bool isCommIntrinsic = N->isCommutativeIntrinsic(CDP);\n  if (NodeInfo.hasProperty(SDNPCommutative) || isCommIntrinsic) {\n    unsigned Skip = isCommIntrinsic ? 1 : 0; // First operand is intrinsic id.\n    assert(N->getNumChildren() >= (2 + Skip) &&\n           \"Commutative but doesn't have 2 children!\");\n    // Don't allow commuting children which are actually register references.\n    bool NoRegisters = true;\n    unsigned i = 0 + Skip;\n    unsigned e = 2 + Skip;\n    for (; i != e; ++i) {\n      TreePatternNode &Child = N->getChild(i);\n      if (Child.isLeaf())\n        if (DefInit *DI = dyn_cast<DefInit>(Child.getLeafValue())) {\n          Record *RR = DI->getDef();\n          if (RR->isSubClassOf(\"Register\"))\n            NoRegisters = false;\n        }\n    }\n    // Consider the commuted order.\n    if (NoRegisters) {\n      // Swap the first two operands after the intrinsic id, if present.\n      unsigned i = isCommIntrinsic ? 1 : 0;\n      std::swap(ChildVariants[i], ChildVariants[i + 1]);\n      CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n    }\n  }\n}\n\n// GenerateVariants - Generate variants.  For example, commutative patterns can\n// match multiple ways.  Add them to PatternsToMatch as well.\nvoid CodeGenDAGPatterns::GenerateVariants() {\n  LLVM_DEBUG(errs() << \"Generating instruction variants.\\n\");\n\n  // Loop over all of the patterns we've collected, checking to see if we can\n  // generate variants of the instruction, through the exploitation of\n  // identities.  This permits the target to provide aggressive matching without\n  // the .td file having to contain tons of variants of instructions.\n  //\n  // Note that this loop adds new patterns to the PatternsToMatch list, but we\n  // intentionally do not reconsider these.  Any variants of added patterns have\n  // already been added.\n  //\n  for (unsigned i = 0, e = PatternsToMatch.size(); i != e; ++i) {\n    MultipleUseVarSet DepVars;\n    std::vector<TreePatternNodePtr> Variants;\n    FindDepVars(PatternsToMatch[i].getSrcPattern(), DepVars);\n    LLVM_DEBUG(errs() << \"Dependent/multiply used variables: \");\n    LLVM_DEBUG(DumpDepVars(DepVars));\n    LLVM_DEBUG(errs() << \"\\n\");\n    GenerateVariantsOf(PatternsToMatch[i].getSrcPatternShared(), Variants,\n                       *this, DepVars);\n\n    assert(PatternsToMatch[i].getHwModeFeatures().empty() &&\n           \"HwModes should not have been expanded yet!\");\n\n    assert(!Variants.empty() && \"Must create at least original variant!\");\n    if (Variants.size() == 1) // No additional variants for this pattern.\n      continue;\n\n    LLVM_DEBUG(errs() << \"FOUND VARIANTS OF: \";\n               PatternsToMatch[i].getSrcPattern().dump(); errs() << \"\\n\");\n\n    for (unsigned v = 0, e = Variants.size(); v != e; ++v) {\n      TreePatternNodePtr Variant = Variants[v];\n\n      LLVM_DEBUG(errs() << \"  VAR#\" << v << \": \"; Variant->dump();\n                 errs() << \"\\n\");\n\n      // Scan to see if an instruction or explicit pattern already matches this.\n      bool AlreadyExists = false;\n      for (unsigned p = 0, e = PatternsToMatch.size(); p != e; ++p) {\n        // Skip if the top level predicates do not match.\n        if ((i != p) && (PatternsToMatch[i].getPredicates() !=\n                         PatternsToMatch[p].getPredicates()))\n          continue;\n        // Check to see if this variant already exists.\n        if (Variant->isIsomorphicTo(PatternsToMatch[p].getSrcPattern(),\n                                    DepVars)) {\n          LLVM_DEBUG(errs() << \"  *** ALREADY EXISTS, ignoring variant.\\n\");\n          AlreadyExists = true;\n          break;\n        }\n      }\n      // If we already have it, ignore the variant.\n      if (AlreadyExists)\n        continue;\n\n      // Otherwise, add it to the list of patterns we have.\n      PatternsToMatch.emplace_back(\n          PatternsToMatch[i].getSrcRecord(), PatternsToMatch[i].getPredicates(),\n          Variant, PatternsToMatch[i].getDstPatternShared(),\n          PatternsToMatch[i].getDstRegs(),\n          PatternsToMatch[i].getAddedComplexity(), Record::getNewUID(Records),\n          PatternsToMatch[i].getHwModeFeatures());\n    }\n\n    LLVM_DEBUG(errs() << \"\\n\");\n  }\n}\n"}], "code": "static TreePatternNodePtr PromoteXForms(TreePatternNodePtr N) {\n  if (Record *Xform = N->getTransformFn()) {\n    N->setTransformFn(nullptr);\n    std::vector<TreePatternNodePtr> Children;\n    Children.push_back(PromoteXForms(N));\n    return makeIntrusiveRefCnt<TreePatternNode>(Xform, std::move(Children),\n                                                N->getNumTypes());\n  }\n\n  if (!N->isLeaf())\n    for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i) {\n      TreePatternNodePtr Child = N->getChildShared(i);\n      N->setChild(i, PromoteXForms(Child));\n    }\n  return N;\n}\n"}, "5EE96E0B69B072FF": {"calls": [{"id": "07D39C7BBCE328A7", "name": "llvm::CodeGenRegBank::getReg", "path": "llvm-project/llvm/utils/TableGen/CodeGenRegisters.cpp", "start": {"line": 1333, "col": 1}, "end": {"line": 1340, "col": 1}, "code": "  CodeGenRegister *&Reg = Def2Reg[Def];\n  if (Reg)\n    return Reg;\n  Registers.emplace_back(Def, Registers.size() + 1);\n  Reg = &Registers.back();\n  return Reg;\n}\n\nvoid CodeGenRegBank::addToMaps(CodeGenRegisterClass *RC) {\n  if (Record *Def = RC->getDef())\n    Def2RC.insert(std::make_pair(Def, RC));\n\n  // Duplicate classes are rejected by insert().\n  // That's OK, we only care about the properties handled by CGRC::Key.\n  CodeGenRegisterClass::Key K(*RC);\n  Key2RC.insert(std::make_pair(K, RC));\n}\n\n// Create a synthetic sub-class if it is missing.\nCodeGenRegisterClass *\nCodeGenRegBank::getOrCreateSubClass(const CodeGenRegisterClass *RC,\n                                    const CodeGenRegister::Vec *Members,\n                                    StringRef Name) {\n  // Synthetic sub-class has the same size and alignment as RC.\n  CodeGenRegisterClass::Key K(Members, RC->RSI);\n  RCKeyMap::const_iterator FoundI = Key2RC.find(K);\n  if (FoundI != Key2RC.end())\n    return FoundI->second;\n\n  // Sub-class doesn't exist, create a new one.\n  RegClasses.emplace_back(*this, Name, K);\n  addToMaps(&RegClasses.back());\n  return &RegClasses.back();\n}\n\nCodeGenRegisterClass *CodeGenRegBank::getRegClass(const Record *Def) const {\n  if (CodeGenRegisterClass *RC = Def2RC.lookup(Def))\n    return RC;\n\n  PrintFatalError(Def->getLoc(), \"Not a known RegisterClass!\");\n}\n\nCodeGenSubRegIndex *\nCodeGenRegBank::getCompositeSubRegIndex(CodeGenSubRegIndex *A,\n                                        CodeGenSubRegIndex *B) {\n  // Look for an existing entry.\n  CodeGenSubRegIndex *Comp = A->compose(B);\n  if (Comp)\n    return Comp;\n\n  // None exists, synthesize one.\n  std::string Name = A->getName() + \"_then_\" + B->getName();\n  Comp = createSubRegIndex(Name, A->getNamespace());\n  A->addComposite(B, Comp);\n  return Comp;\n}\n\nCodeGenSubRegIndex *CodeGenRegBank::getConcatSubRegIndex(\n    const SmallVector<CodeGenSubRegIndex *, 8> &Parts) {\n  assert(Parts.size() > 1 && \"Need two parts to concatenate\");\n#ifndef NDEBUG\n  for (CodeGenSubRegIndex *Idx : Parts) {\n    assert(Idx->ConcatenationOf.empty() && \"No transitive closure?\");\n  }\n#endif\n\n  // Look for an existing entry.\n  CodeGenSubRegIndex *&Idx = ConcatIdx[Parts];\n  if (Idx)\n    return Idx;\n\n  // None exists, synthesize one.\n  std::string Name = Parts.front()->getName();\n  // Determine whether all parts are contiguous.\n  bool isContinuous = true;\n  unsigned Size = Parts.front()->Size;\n  unsigned LastOffset = Parts.front()->Offset;\n  unsigned LastSize = Parts.front()->Size;\n  unsigned UnknownSize = (uint16_t)-1;\n  for (unsigned i = 1, e = Parts.size(); i != e; ++i) {\n    Name += '_';\n    Name += Parts[i]->getName();\n    if (Size == UnknownSize || Parts[i]->Size == UnknownSize)\n      Size = UnknownSize;\n    else\n      Size += Parts[i]->Size;\n    if (LastSize == UnknownSize || Parts[i]->Offset != (LastOffset + LastSize))\n      isContinuous = false;\n    LastOffset = Parts[i]->Offset;\n    LastSize = Parts[i]->Size;\n  }\n  Idx = createSubRegIndex(Name, Parts.front()->getNamespace());\n  Idx->Size = Size;\n  Idx->Offset = isContinuous ? Parts.front()->Offset : -1;\n  Idx->ConcatenationOf.assign(Parts.begin(), Parts.end());\n  return Idx;\n}\n\nvoid CodeGenRegBank::computeComposites() {\n  using RegMap = std::map<const CodeGenRegister *, const CodeGenRegister *>;\n\n  // Subreg -> { Reg->Reg }, where the right-hand side is the mapping from\n  // register to (sub)register associated with the action of the left-hand\n  // side subregister.\n  std::map<const CodeGenSubRegIndex *, RegMap> SubRegAction;\n  for (const CodeGenRegister &R : Registers) {\n    const CodeGenRegister::SubRegMap &SM = R.getSubRegs();\n    for (std::pair<const CodeGenSubRegIndex *, const CodeGenRegister *> P : SM)\n      SubRegAction[P.first].insert({&R, P.second});\n  }\n\n  // Calculate the composition of two subregisters as compositions of their\n  // associated actions.\n  auto compose = [&SubRegAction](const CodeGenSubRegIndex *Sub1,\n                                 const CodeGenSubRegIndex *Sub2) {\n    RegMap C;\n    const RegMap &Img1 = SubRegAction.at(Sub1);\n    const RegMap &Img2 = SubRegAction.at(Sub2);\n    for (std::pair<const CodeGenRegister *, const CodeGenRegister *> P : Img1) {\n      auto F = Img2.find(P.second);\n      if (F != Img2.end())\n        C.insert({P.first, F->second});\n    }\n    return C;\n  };\n\n  // Check if the two maps agree on the intersection of their domains.\n  auto agree = [](const RegMap &Map1, const RegMap &Map2) {\n    // Technically speaking, an empty map agrees with any other map, but\n    // this could flag false positives. We're interested in non-vacuous\n    // agreements.\n    if (Map1.empty() || Map2.empty())\n      return false;\n    for (std::pair<const CodeGenRegister *, const CodeGenRegister *> P : Map1) {\n      auto F = Map2.find(P.first);\n      if (F == Map2.end() || P.second != F->second)\n        return false;\n    }\n    return true;\n  };\n\n  using CompositePair =\n      std::pair<const CodeGenSubRegIndex *, const CodeGenSubRegIndex *>;\n  SmallSet<CompositePair, 4> UserDefined;\n  for (const CodeGenSubRegIndex &Idx : SubRegIndices)\n    for (auto P : Idx.getComposites())\n      UserDefined.insert(std::make_pair(&Idx, P.first));\n\n  // Keep track of TopoSigs visited. We only need to visit each TopoSig once,\n  // and many registers will share TopoSigs on regular architectures.\n  BitVector TopoSigs(getNumTopoSigs());\n\n  for (const auto &Reg1 : Registers) {\n    // Skip identical subreg structures already processed.\n    if (TopoSigs.test(Reg1.getTopoSig()))\n      continue;\n    TopoSigs.set(Reg1.getTopoSig());\n\n    const CodeGenRegister::SubRegMap &SRM1 = Reg1.getSubRegs();\n    for (auto I1 : SRM1) {\n      CodeGenSubRegIndex *Idx1 = I1.first;\n      CodeGenRegister *Reg2 = I1.second;\n      // Ignore identity compositions.\n      if (&Reg1 == Reg2)\n        continue;\n      const CodeGenRegister::SubRegMap &SRM2 = Reg2->getSubRegs();\n      // Try composing Idx1 with another SubRegIndex.\n      for (auto I2 : SRM2) {\n        CodeGenSubRegIndex *Idx2 = I2.first;\n        CodeGenRegister *Reg3 = I2.second;\n        // Ignore identity compositions.\n        if (Reg2 == Reg3)\n          continue;\n        // OK Reg1:IdxPair == Reg3. Find the index with Reg:Idx == Reg3.\n        CodeGenSubRegIndex *Idx3 = Reg1.getSubRegIndex(Reg3);\n        assert(Idx3 && \"Sub-register doesn't have an index\");\n\n        // Conflicting composition? Emit a warning but allow it.\n        if (CodeGenSubRegIndex *Prev = Idx1->addComposite(Idx2, Idx3)) {\n          // If the composition was not user-defined, always emit a warning.\n          if (!UserDefined.count({Idx1, Idx2}) ||\n              agree(compose(Idx1, Idx2), SubRegAction.at(Idx3)))\n            PrintWarning(Twine(\"SubRegIndex \") + Idx1->getQualifiedName() +\n                         \" and \" + Idx2->getQualifiedName() +\n                         \" compose ambiguously as \" + Prev->getQualifiedName() +\n                         \" or \" + Idx3->getQualifiedName());\n        }\n      }\n    }\n  }\n}\n\n// Compute lane masks. This is similar to register units, but at the\n// sub-register index level. Each bit in the lane mask is like a register unit\n// class, and two lane masks will have a bit in common if two sub-register\n// indices overlap in some register.\n//\n// Conservatively share a lane mask bit if two sub-register indices overlap in\n// some registers, but not in others. That shouldn't happen a lot.\nvoid CodeGenRegBank::computeSubRegLaneMasks() {\n  // First assign individual bits to all the leaf indices.\n  unsigned Bit = 0;\n  // Determine mask of lanes that cover their registers.\n  CoveringLanes = LaneBitmask::getAll();\n  for (auto &Idx : SubRegIndices) {\n    if (Idx.getComposites().empty()) {\n      if (Bit > LaneBitmask::BitWidth) {\n        PrintFatalError(\n            Twine(\"Ran out of lanemask bits to represent subregister \") +\n            Idx.getName());\n      }\n      Idx.LaneMask = LaneBitmask::getLane(Bit);\n      ++Bit;\n    } else {\n      Idx.LaneMask = LaneBitmask::getNone();\n    }\n  }\n\n  // Compute transformation sequences for composeSubRegIndexLaneMask. The idea\n  // here is that for each possible target subregister we look at the leafs\n  // in the subregister graph that compose for this target and create\n  // transformation sequences for the lanemasks. Each step in the sequence\n  // consists of a bitmask and a bitrotate operation. As the rotation amounts\n  // are usually the same for many subregisters we can easily combine the steps\n  // by combining the masks.\n  for (const auto &Idx : SubRegIndices) {\n    const auto &Composites = Idx.getComposites();\n    auto &LaneTransforms = Idx.CompositionLaneMaskTransform;\n\n    if (Composites.empty()) {\n      // Moving from a class with no subregisters we just had a single lane:\n      // The subregister must be a leaf subregister and only occupies 1 bit.\n      // Move the bit from the class without subregisters into that position.\n      unsigned DstBit = Idx.LaneMask.getHighestLane();\n      assert(Idx.LaneMask == LaneBitmask::getLane(DstBit) &&\n             \"Must be a leaf subregister\");\n      MaskRolPair MaskRol = {LaneBitmask::getLane(0), (uint8_t)DstBit};\n      LaneTransforms.push_back(MaskRol);\n    } else {\n      // Go through all leaf subregisters and find the ones that compose with\n      // Idx. These make out all possible valid bits in the lane mask we want to\n      // transform. Looking only at the leafs ensure that only a single bit in\n      // the mask is set.\n      unsigned NextBit = 0;\n      for (auto &Idx2 : SubRegIndices) {\n        // Skip non-leaf subregisters.\n        if (!Idx2.getComposites().empty())\n          continue;\n        // Replicate the behaviour from the lane mask generation loop above.\n        unsigned SrcBit = NextBit;\n        LaneBitmask SrcMask = LaneBitmask::getLane(SrcBit);\n        if (NextBit < LaneBitmask::BitWidth - 1)\n          ++NextBit;\n        assert(Idx2.LaneMask == SrcMask);\n\n        // Get the composed subregister if there is any.\n        auto C = Composites.find(&Idx2);\n        if (C == Composites.end())\n          continue;\n        const CodeGenSubRegIndex *Composite = C->second;\n        // The Composed subreg should be a leaf subreg too\n        assert(Composite->getComposites().empty());\n\n        // Create Mask+Rotate operation and merge with existing ops if possible.\n        unsigned DstBit = Composite->LaneMask.getHighestLane();\n        int Shift = DstBit - SrcBit;\n        uint8_t RotateLeft =\n            Shift >= 0 ? (uint8_t)Shift : LaneBitmask::BitWidth + Shift;\n        for (auto &I : LaneTransforms) {\n          if (I.RotateLeft == RotateLeft) {\n            I.Mask |= SrcMask;\n            SrcMask = LaneBitmask::getNone();\n          }\n        }\n        if (SrcMask.any()) {\n          MaskRolPair MaskRol = {SrcMask, RotateLeft};\n          LaneTransforms.push_back(MaskRol);\n        }\n      }\n    }\n\n    // Optimize if the transformation consists of one step only: Set mask to\n    // 0xffffffff (including some irrelevant invalid bits) so that it should\n    // merge with more entries later while compressing the table.\n    if (LaneTransforms.size() == 1)\n      LaneTransforms[0].Mask = LaneBitmask::getAll();\n\n    // Further compression optimization: For invalid compositions resulting\n    // in a sequence with 0 entries we can just pick any other. Choose\n    // Mask 0xffffffff with Rotation 0.\n    if (LaneTransforms.size() == 0) {\n      MaskRolPair P = {LaneBitmask::getAll(), 0};\n      LaneTransforms.push_back(P);\n    }\n  }\n\n  // FIXME: What if ad-hoc aliasing introduces overlaps that aren't represented\n  // by the sub-register graph? This doesn't occur in any known targets.\n\n  // Inherit lanes from composites.\n  for (const auto &Idx : SubRegIndices) {\n    LaneBitmask Mask = Idx.computeLaneMask();\n    // If some super-registers without CoveredBySubRegs use this index, we can\n    // no longer assume that the lanes are covering their registers.\n    if (!Idx.AllSuperRegsCovered)\n      CoveringLanes &= ~Mask;\n  }\n\n  // Compute lane mask combinations for register classes.\n  for (auto &RegClass : RegClasses) {\n    LaneBitmask LaneMask;\n    for (const auto &SubRegIndex : SubRegIndices) {\n      if (RegClass.getSubClassWithSubReg(&SubRegIndex) == nullptr)\n        continue;\n      LaneMask |= SubRegIndex.LaneMask;\n    }\n\n    // For classes without any subregisters set LaneMask to 1 instead of 0.\n    // This makes it easier for client code to handle classes uniformly.\n    if (LaneMask.none())\n      LaneMask = LaneBitmask::getLane(0);\n\n    RegClass.LaneMask = LaneMask;\n  }\n}\n\nnamespace {\n\n// UberRegSet is a helper class for computeRegUnitWeights. Each UberRegSet is\n// the transitive closure of the union of overlapping register\n// classes. Together, the UberRegSets form a partition of the registers. If we\n// consider overlapping register classes to be connected, then each UberRegSet\n// is a set of connected components.\n//\n// An UberRegSet will likely be a horizontal slice of register names of\n// the same width. Nontrivial subregisters should then be in a separate\n// UberRegSet. But this property isn't required for valid computation of\n// register unit weights.\n//\n// A Weight field caches the max per-register unit weight in each UberRegSet.\n//\n// A set of SingularDeterminants flags single units of some register in this set\n// for which the unit weight equals the set weight. These units should not have\n// their weight increased.\nstruct UberRegSet {\n  CodeGenRegister::Vec Regs;\n  unsigned Weight = 0;\n  CodeGenRegister::RegUnitList SingularDeterminants;\n\n  UberRegSet() = default;\n};\n\n} // end anonymous namespace\n\n// Partition registers into UberRegSets, where each set is the transitive\n// closure of the union of overlapping register classes.\n//\n// UberRegSets[0] is a special non-allocatable set.\nstatic void computeUberSets(std::vector<UberRegSet> &UberSets,\n                            std::vector<UberRegSet *> &RegSets,\n                            CodeGenRegBank &RegBank) {\n  const auto &Registers = RegBank.getRegisters();\n\n  // The Register EnumValue is one greater than its index into Registers.\n  assert(Registers.size() == Registers.back().EnumValue &&\n         \"register enum value mismatch\");\n\n  // For simplicitly make the SetID the same as EnumValue.\n  IntEqClasses UberSetIDs(Registers.size() + 1);\n  BitVector AllocatableRegs(Registers.size() + 1);\n  for (auto &RegClass : RegBank.getRegClasses()) {\n    if (!RegClass.Allocatable)\n      continue;\n\n    const CodeGenRegister::Vec &Regs = RegClass.getMembers();\n    if (Regs.empty())\n      continue;\n\n    unsigned USetID = UberSetIDs.findLeader((*Regs.begin())->EnumValue);\n    assert(USetID && \"register number 0 is invalid\");\n\n    AllocatableRegs.set((*Regs.begin())->EnumValue);\n    for (const CodeGenRegister *CGR : llvm::drop_begin(Regs)) {\n      AllocatableRegs.set(CGR->EnumValue);\n      UberSetIDs.join(USetID, CGR->EnumValue);\n    }\n  }\n  // Combine non-allocatable regs.\n  for (const auto &Reg : Registers) {\n    unsigned RegNum = Reg.EnumValue;\n    if (AllocatableRegs.test(RegNum))\n      continue;\n\n    UberSetIDs.join(0, RegNum);\n  }\n  UberSetIDs.compress();\n\n  // Make the first UberSet a special unallocatable set.\n  unsigned ZeroID = UberSetIDs[0];\n\n  // Insert Registers into the UberSets formed by union-find.\n  // Do not resize after this.\n  UberSets.resize(UberSetIDs.getNumClasses());\n  unsigned i = 0;\n  for (const CodeGenRegister &Reg : Registers) {\n    unsigned USetID = UberSetIDs[Reg.EnumValue];\n    if (!USetID)\n      USetID = ZeroID;\n    else if (USetID == ZeroID)\n      USetID = 0;\n\n    UberRegSet *USet = &UberSets[USetID];\n    USet->Regs.push_back(&Reg);\n    RegSets[i++] = USet;\n  }\n}\n\n// Recompute each UberSet weight after changing unit weights.\nstatic void computeUberWeights(std::vector<UberRegSet> &UberSets,\n                               CodeGenRegBank &RegBank) {\n  // Skip the first unallocatable set.\n  for (std::vector<UberRegSet>::iterator I = std::next(UberSets.begin()),\n                                         E = UberSets.end();\n       I != E; ++I) {\n\n    // Initialize all unit weights in this set, and remember the max units/reg.\n    const CodeGenRegister *Reg = nullptr;\n    unsigned MaxWeight = 0, Weight = 0;\n    for (RegUnitIterator UnitI(I->Regs); UnitI.isValid(); ++UnitI) {\n      if (Reg != UnitI.getReg()) {\n        if (Weight > MaxWeight)\n          MaxWeight = Weight;\n        Reg = UnitI.getReg();\n        Weight = 0;\n      }\n      if (!RegBank.getRegUnit(*UnitI).Artificial) {\n        unsigned UWeight = RegBank.getRegUnit(*UnitI).Weight;\n        if (!UWeight) {\n          UWeight = 1;\n          RegBank.increaseRegUnitWeight(*UnitI, UWeight);\n        }\n        Weight += UWeight;\n      }\n    }\n    if (Weight > MaxWeight)\n      MaxWeight = Weight;\n    if (I->Weight != MaxWeight) {\n      LLVM_DEBUG(dbgs() << \"UberSet \" << I - UberSets.begin() << \" Weight \"\n                        << MaxWeight;\n                 for (auto &Unit\n                      : I->Regs) dbgs()\n                 << \" \" << Unit->getName();\n                 dbgs() << \"\\n\");\n      // Update the set weight.\n      I->Weight = MaxWeight;\n    }\n\n    // Find singular determinants.\n    for (const auto R : I->Regs) {\n      if (R->getRegUnits().count() == 1 && R->getWeight(RegBank) == I->Weight) {\n        I->SingularDeterminants |= R->getRegUnits();\n      }\n    }\n  }\n}\n\n// normalizeWeight is a computeRegUnitWeights helper that adjusts the weight of\n// a register and its subregisters so that they have the same weight as their\n// UberSet. Self-recursion processes the subregister tree in postorder so\n// subregisters are normalized first.\n//\n// Side effects:\n// - creates new adopted register units\n// - causes superregisters to inherit adopted units\n// - increases the weight of \"singular\" units\n// - induces recomputation of UberWeights.\nstatic bool normalizeWeight(CodeGenRegister *Reg,\n                            std::vector<UberRegSet> &UberSets,\n                            std::vector<UberRegSet *> &RegSets,\n                            BitVector &NormalRegs,\n                            CodeGenRegister::RegUnitList &NormalUnits,\n                            CodeGenRegBank &RegBank) {\n  NormalRegs.resize(std::max(Reg->EnumValue + 1, NormalRegs.size()));\n  if (NormalRegs.test(Reg->EnumValue))\n    return false;\n  NormalRegs.set(Reg->EnumValue);\n\n  bool Changed = false;\n  const CodeGenRegister::SubRegMap &SRM = Reg->getSubRegs();\n  for (auto SRI : SRM) {\n    if (SRI.second == Reg)\n      continue; // self-cycles happen\n\n    Changed |= normalizeWeight(SRI.second, UberSets, RegSets, NormalRegs,\n                               NormalUnits, RegBank);\n  }\n  // Postorder register normalization.\n\n  // Inherit register units newly adopted by subregisters.\n  if (Reg->inheritRegUnits(RegBank))\n    computeUberWeights(UberSets, RegBank);\n\n  // Check if this register is too skinny for its UberRegSet.\n  UberRegSet *UberSet = RegSets[RegBank.getRegIndex(Reg)];\n\n  unsigned RegWeight = Reg->getWeight(RegBank);\n  if (UberSet->Weight > RegWeight) {\n    // A register unit's weight can be adjusted only if it is the singular unit\n    // for this register, has not been used to normalize a subregister's set,\n    // and has not already been used to singularly determine this UberRegSet.\n    unsigned AdjustUnit = *Reg->getRegUnits().begin();\n    if (Reg->getRegUnits().count() != 1 ||\n        hasRegUnit(NormalUnits, AdjustUnit) ||\n        hasRegUnit(UberSet->SingularDeterminants, AdjustUnit)) {\n      // We don't have an adjustable unit, so adopt a new one.\n      AdjustUnit = RegBank.newRegUnit(UberSet->Weight - RegWeight);\n      Reg->adoptRegUnit(AdjustUnit);\n      // Adopting a unit does not immediately require recomputing set weights.\n    } else {\n      // Adjust the existing single unit.\n      if (!RegBank.getRegUnit(AdjustUnit).Artificial)\n        RegBank.increaseRegUnitWeight(AdjustUnit, UberSet->Weight - RegWeight);\n      // The unit may be shared among sets and registers within this set.\n      computeUberWeights(UberSets, RegBank);\n    }\n    Changed = true;\n  }\n\n  // Mark these units normalized so superregisters can't change their weights.\n  NormalUnits |= Reg->getRegUnits();\n\n  return Changed;\n}\n\n// Compute a weight for each register unit created during getSubRegs.\n//\n// The goal is that two registers in the same class will have the same weight,\n// where each register's weight is defined as sum of its units' weights.\nvoid CodeGenRegBank::computeRegUnitWeights() {\n  std::vector<UberRegSet> UberSets;\n  std::vector<UberRegSet *> RegSets(Registers.size());\n  computeUberSets(UberSets, RegSets, *this);\n  // UberSets and RegSets are now immutable.\n\n  computeUberWeights(UberSets, *this);\n\n  // Iterate over each Register, normalizing the unit weights until reaching\n  // a fix point.\n  unsigned NumIters = 0;\n  for (bool Changed = true; Changed; ++NumIters) {\n    assert(NumIters <= NumNativeRegUnits && \"Runaway register unit weights\");\n    (void)NumIters;\n    Changed = false;\n    for (auto &Reg : Registers) {\n      CodeGenRegister::RegUnitList NormalUnits;\n      BitVector NormalRegs;\n      Changed |= normalizeWeight(&Reg, UberSets, RegSets, NormalRegs,\n                                 NormalUnits, *this);\n    }\n  }\n}\n\n// Find a set in UniqueSets with the same elements as Set.\n// Return an iterator into UniqueSets.\nstatic std::vector<RegUnitSet>::const_iterator\nfindRegUnitSet(const std::vector<RegUnitSet> &UniqueSets,\n               const RegUnitSet &Set) {\n  return find_if(UniqueSets,\n                 [&Set](const RegUnitSet &I) { return I.Units == Set.Units; });\n}\n\n// Return true if the RUSubSet is a subset of RUSuperSet.\nstatic bool isRegUnitSubSet(const std::vector<unsigned> &RUSubSet,\n                            const std::vector<unsigned> &RUSuperSet) {\n  return std::includes(RUSuperSet.begin(), RUSuperSet.end(), RUSubSet.begin(),\n                       RUSubSet.end());\n}\n\n/// Iteratively prune unit sets. Prune subsets that are close to the superset,\n/// but with one or two registers removed. We occasionally have registers like\n/// APSR and PC thrown in with the general registers. We also see many\n/// special-purpose register subsets, such as tail-call and Thumb\n/// encodings. Generating all possible overlapping sets is combinatorial and\n/// overkill for modeling pressure. Ideally we could fix this statically in\n/// tablegen by (1) having the target define register classes that only include\n/// the allocatable registers and marking other classes as non-allocatable and\n/// (2) having a way to mark special purpose classes as \"don't-care\" classes for\n/// the purpose of pressure.  However, we make an attempt to handle targets that\n/// are not nicely defined by merging nearly identical register unit sets\n/// statically. This generates smaller tables. Then, dynamically, we adjust the\n/// set limit by filtering the reserved registers.\n///\n/// Merge sets only if the units have the same weight. For example, on ARM,\n/// Q-tuples with ssub index 0 include all S regs but also include D16+. We\n/// should not expand the S set to include D regs.\nvoid CodeGenRegBank::pruneUnitSets() {\n  assert(RegClassUnitSets.empty() && \"this invalidates RegClassUnitSets\");\n\n  // Form an equivalence class of UnitSets with no significant difference.\n  std::vector<unsigned> SuperSetIDs;\n  for (unsigned SubIdx = 0, EndIdx = RegUnitSets.size(); SubIdx != EndIdx;\n       ++SubIdx) {\n    const RegUnitSet &SubSet = RegUnitSets[SubIdx];\n    unsigned SuperIdx = 0;\n    for (; SuperIdx != EndIdx; ++SuperIdx) {\n      if (SuperIdx == SubIdx)\n        continue;\n\n      unsigned UnitWeight = RegUnits[SubSet.Units[0]].Weight;\n      const RegUnitSet &SuperSet = RegUnitSets[SuperIdx];\n      if (isRegUnitSubSet(SubSet.Units, SuperSet.Units) &&\n          (SubSet.Units.size() + 3 > SuperSet.Units.size()) &&\n          UnitWeight == RegUnits[SuperSet.Units[0]].Weight &&\n          UnitWeight == RegUnits[SuperSet.Units.back()].Weight) {\n        LLVM_DEBUG(dbgs() << \"UnitSet \" << SubIdx << \" subsumed by \" << SuperIdx\n                          << \"\\n\");\n        // We can pick any of the set names for the merged set. Go for the\n        // shortest one to avoid picking the name of one of the classes that are\n        // artificially created by tablegen. So \"FPR128_lo\" instead of\n        // \"QQQQ_with_qsub3_in_FPR128_lo\".\n        if (RegUnitSets[SubIdx].Name.size() < RegUnitSets[SuperIdx].Name.size())\n          RegUnitSets[SuperIdx].Name = RegUnitSets[SubIdx].Name;\n        break;\n      }\n    }\n    if (SuperIdx == EndIdx)\n      SuperSetIDs.push_back(SubIdx);\n  }\n  // Populate PrunedUnitSets with each equivalence class's superset.\n  std::vector<RegUnitSet> PrunedUnitSets(SuperSetIDs.size());\n  for (unsigned i = 0, e = SuperSetIDs.size(); i != e; ++i) {\n    unsigned SuperIdx = SuperSetIDs[i];\n    PrunedUnitSets[i].Name = RegUnitSets[SuperIdx].Name;\n    PrunedUnitSets[i].Units.swap(RegUnitSets[SuperIdx].Units);\n  }\n  RegUnitSets.swap(PrunedUnitSets);\n}\n\n// Create a RegUnitSet for each RegClass that contains all units in the class\n// including adopted units that are necessary to model register pressure. Then\n// iteratively compute RegUnitSets such that the union of any two overlapping\n// RegUnitSets is repreresented.\n//\n// RegisterInfoEmitter will map each RegClass to its RegUnitClass and any\n// RegUnitSet that is a superset of that RegUnitClass.\nvoid CodeGenRegBank::computeRegUnitSets() {\n  assert(RegUnitSets.empty() && \"dirty RegUnitSets\");\n\n  // Compute a unique RegUnitSet for each RegClass.\n  auto &RegClasses = getRegClasses();\n  for (auto &RC : RegClasses) {\n    if (!RC.Allocatable || RC.Artificial || !RC.GeneratePressureSet)\n      continue;\n\n    // Speculatively grow the RegUnitSets to hold the new set.\n    RegUnitSets.resize(RegUnitSets.size() + 1);\n    RegUnitSets.back().Name = RC.getName();\n\n    // Compute a sorted list of units in this class.\n    RC.buildRegUnitSet(*this, RegUnitSets.back().Units);\n\n    // Find an existing RegUnitSet.\n    std::vector<RegUnitSet>::const_iterator SetI =\n        findRegUnitSet(RegUnitSets, RegUnitSets.back());\n    if (SetI != std::prev(RegUnitSets.end()))\n      RegUnitSets.pop_back();\n  }\n\n  if (RegUnitSets.empty())\n    PrintFatalError(\"RegUnitSets cannot be empty!\");\n\n  LLVM_DEBUG(dbgs() << \"\\nBefore pruning:\\n\"; for (unsigned USIdx = 0,\n                                                   USEnd = RegUnitSets.size();\n                                                   USIdx < USEnd; ++USIdx) {\n    dbgs() << \"UnitSet \" << USIdx << \" \" << RegUnitSets[USIdx].Name << \":\";\n    for (auto &U : RegUnitSets[USIdx].Units)\n      printRegUnitName(U);\n    dbgs() << \"\\n\";\n  });\n\n  // Iteratively prune unit sets.\n  pruneUnitSets();\n\n  LLVM_DEBUG(dbgs() << \"\\nBefore union:\\n\"; for (unsigned USIdx = 0,\n                                                 USEnd = RegUnitSets.size();\n                                                 USIdx < USEnd; ++USIdx) {\n    dbgs() << \"UnitSet \" << USIdx << \" \" << RegUnitSets[USIdx].Name << \":\";\n    for (auto &U : RegUnitSets[USIdx].Units)\n      printRegUnitName(U);\n    dbgs() << \"\\n\";\n  } dbgs() << \"\\nUnion sets:\\n\");\n\n  // Iterate over all unit sets, including new ones added by this loop.\n  unsigned NumRegUnitSubSets = RegUnitSets.size();\n  for (unsigned Idx = 0, EndIdx = RegUnitSets.size(); Idx != EndIdx; ++Idx) {\n    // In theory, this is combinatorial. In practice, it needs to be bounded\n    // by a small number of sets for regpressure to be efficient.\n    // If the assert is hit, we need to implement pruning.\n    assert(Idx < (2 * NumRegUnitSubSets) && \"runaway unit set inference\");\n\n    // Compare new sets with all original classes.\n    for (unsigned SearchIdx = (Idx >= NumRegUnitSubSets) ? 0 : Idx + 1;\n         SearchIdx != EndIdx; ++SearchIdx) {\n      std::set<unsigned> Intersection;\n      std::set_intersection(RegUnitSets[Idx].Units.begin(),\n                            RegUnitSets[Idx].Units.end(),\n                            RegUnitSets[SearchIdx].Units.begin(),\n                            RegUnitSets[SearchIdx].Units.end(),\n                            std::inserter(Intersection, Intersection.begin()));\n      if (Intersection.empty())\n        continue;\n\n      // Speculatively grow the RegUnitSets to hold the new set.\n      RegUnitSets.resize(RegUnitSets.size() + 1);\n      RegUnitSets.back().Name =\n          RegUnitSets[Idx].Name + \"_with_\" + RegUnitSets[SearchIdx].Name;\n\n      std::set_union(RegUnitSets[Idx].Units.begin(),\n                     RegUnitSets[Idx].Units.end(),\n                     RegUnitSets[SearchIdx].Units.begin(),\n                     RegUnitSets[SearchIdx].Units.end(),\n                     std::inserter(RegUnitSets.back().Units,\n                                   RegUnitSets.back().Units.begin()));\n\n      // Find an existing RegUnitSet, or add the union to the unique sets.\n      std::vector<RegUnitSet>::const_iterator SetI =\n          findRegUnitSet(RegUnitSets, RegUnitSets.back());\n      if (SetI != std::prev(RegUnitSets.end()))\n        RegUnitSets.pop_back();\n      else {\n        LLVM_DEBUG(dbgs() << \"UnitSet \" << RegUnitSets.size() - 1 << \" \"\n                          << RegUnitSets.back().Name << \":\";\n                   for (auto &U\n                        : RegUnitSets.back().Units) printRegUnitName(U);\n                   dbgs() << \"\\n\";);\n      }\n    }\n  }\n\n  // Iteratively prune unit sets after inferring supersets.\n  pruneUnitSets();\n\n  LLVM_DEBUG(\n      dbgs() << \"\\n\"; for (unsigned USIdx = 0, USEnd = RegUnitSets.size();\n                           USIdx < USEnd; ++USIdx) {\n        dbgs() << \"UnitSet \" << USIdx << \" \" << RegUnitSets[USIdx].Name << \":\";\n        for (auto &U : RegUnitSets[USIdx].Units)\n          printRegUnitName(U);\n        dbgs() << \"\\n\";\n      });\n\n  // For each register class, list the UnitSets that are supersets.\n  RegClassUnitSets.resize(RegClasses.size());\n  int RCIdx = -1;\n  for (auto &RC : RegClasses) {\n    ++RCIdx;\n    if (!RC.Allocatable)\n      continue;\n\n    // Recompute the sorted list of units in this class.\n    std::vector<unsigned> RCRegUnits;\n    RC.buildRegUnitSet(*this, RCRegUnits);\n\n    // Don't increase pressure for unallocatable regclasses.\n    if (RCRegUnits.empty())\n      continue;\n\n    LLVM_DEBUG(dbgs() << \"RC \" << RC.getName() << \" Units:\\n\";\n               for (auto U\n                    : RCRegUnits) printRegUnitName(U);\n               dbgs() << \"\\n  UnitSetIDs:\");\n\n    // Find all supersets.\n    for (unsigned USIdx = 0, USEnd = RegUnitSets.size(); USIdx != USEnd;\n         ++USIdx) {\n      if (isRegUnitSubSet(RCRegUnits, RegUnitSets[USIdx].Units)) {\n        LLVM_DEBUG(dbgs() << \" \" << USIdx);\n        RegClassUnitSets[RCIdx].push_back(USIdx);\n      }\n    }\n    LLVM_DEBUG(dbgs() << \"\\n\");\n    assert((!RegClassUnitSets[RCIdx].empty() || !RC.GeneratePressureSet) &&\n           \"missing unit set for regclass\");\n  }\n\n  // For each register unit, ensure that we have the list of UnitSets that\n  // contain the unit. Normally, this matches an existing list of UnitSets for a\n  // register class. If not, we create a new entry in RegClassUnitSets as a\n  // \"fake\" register class.\n  for (unsigned UnitIdx = 0, UnitEnd = NumNativeRegUnits; UnitIdx < UnitEnd;\n       ++UnitIdx) {\n    std::vector<unsigned> RUSets;\n    for (unsigned i = 0, e = RegUnitSets.size(); i != e; ++i) {\n      RegUnitSet &RUSet = RegUnitSets[i];\n      if (!is_contained(RUSet.Units, UnitIdx))\n        continue;\n      RUSets.push_back(i);\n    }\n    unsigned RCUnitSetsIdx = 0;\n    for (unsigned e = RegClassUnitSets.size(); RCUnitSetsIdx != e;\n         ++RCUnitSetsIdx) {\n      if (RegClassUnitSets[RCUnitSetsIdx] == RUSets) {\n        break;\n      }\n    }\n    RegUnits[UnitIdx].RegClassUnitSetsIdx = RCUnitSetsIdx;\n    if (RCUnitSetsIdx == RegClassUnitSets.size()) {\n      // Create a new list of UnitSets as a \"fake\" register class.\n      RegClassUnitSets.resize(RCUnitSetsIdx + 1);\n      RegClassUnitSets[RCUnitSetsIdx].swap(RUSets);\n    }\n  }\n}\n\nvoid CodeGenRegBank::computeRegUnitLaneMasks() {\n  for (auto &Register : Registers) {\n    // Create an initial lane mask for all register units.\n    const auto &RegUnits = Register.getRegUnits();\n    CodeGenRegister::RegUnitLaneMaskList RegUnitLaneMasks(\n        RegUnits.count(), LaneBitmask::getAll());\n    // Iterate through SubRegisters.\n    typedef CodeGenRegister::SubRegMap SubRegMap;\n    const SubRegMap &SubRegs = Register.getSubRegs();\n    for (auto S : SubRegs) {\n      CodeGenRegister *SubReg = S.second;\n      // Ignore non-leaf subregisters, their lane masks are fully covered by\n      // the leaf subregisters anyway.\n      if (!SubReg->getSubRegs().empty())\n        continue;\n      CodeGenSubRegIndex *SubRegIndex = S.first;\n      const CodeGenRegister *SubRegister = S.second;\n      LaneBitmask LaneMask = SubRegIndex->LaneMask;\n      // Distribute LaneMask to Register Units touched.\n      for (unsigned SUI : SubRegister->getRegUnits()) {\n        bool Found = false;\n        unsigned u = 0;\n        for (unsigned RU : RegUnits) {\n          if (SUI == RU) {\n            RegUnitLaneMasks[u] &= LaneMask;\n            assert(!Found);\n            Found = true;\n          }\n          ++u;\n        }\n        (void)Found;\n        assert(Found);\n      }\n    }\n    Register.setRegUnitLaneMasks(RegUnitLaneMasks);\n  }\n}\n\nvoid CodeGenRegBank::computeDerivedInfo() {\n  computeComposites();\n  computeSubRegLaneMasks();\n\n  // Compute a weight for each register unit created during getSubRegs.\n  // This may create adopted register units (with unit # >= NumNativeRegUnits).\n  computeRegUnitWeights();\n\n  // Compute a unique set of RegUnitSets. One for each RegClass and inferred\n  // supersets for the union of overlapping sets.\n  computeRegUnitSets();\n\n  computeRegUnitLaneMasks();\n\n  // Compute register class HasDisjunctSubRegs/CoveredBySubRegs flag.\n  for (CodeGenRegisterClass &RC : RegClasses) {\n    RC.HasDisjunctSubRegs = false;\n    RC.CoveredBySubRegs = true;\n    for (const CodeGenRegister *Reg : RC.getMembers()) {\n      RC.HasDisjunctSubRegs |= Reg->HasDisjunctSubRegs;\n      RC.CoveredBySubRegs &= Reg->CoveredBySubRegs;\n    }\n  }\n\n  // Get the weight of each set.\n  for (unsigned Idx = 0, EndIdx = RegUnitSets.size(); Idx != EndIdx; ++Idx)\n    RegUnitSets[Idx].Weight = getRegUnitSetWeight(RegUnitSets[Idx].Units);\n\n  // Find the order of each set.\n  RegUnitSetOrder.reserve(RegUnitSets.size());\n  for (unsigned Idx = 0, EndIdx = RegUnitSets.size(); Idx != EndIdx; ++Idx)\n    RegUnitSetOrder.push_back(Idx);\n\n  llvm::stable_sort(RegUnitSetOrder, [this](unsigned ID1, unsigned ID2) {\n    return getRegPressureSet(ID1).Units.size() <\n           getRegPressureSet(ID2).Units.size();\n  });\n  for (unsigned Idx = 0, EndIdx = RegUnitSets.size(); Idx != EndIdx; ++Idx) {\n    RegUnitSets[RegUnitSetOrder[Idx]].Order = Idx;\n  }\n}\n\n//\n// Synthesize missing register class intersections.\n//\n// Make sure that sub-classes of RC exists such that getCommonSubClass(RC, X)\n// returns a maximal register class for all X.\n//\nvoid CodeGenRegBank::inferCommonSubClass(CodeGenRegisterClass *RC) {\n  assert(!RegClasses.empty());\n  // Stash the iterator to the last element so that this loop doesn't visit\n  // elements added by the getOrCreateSubClass call within it.\n  for (auto I = RegClasses.begin(), E = std::prev(RegClasses.end());\n       I != std::next(E); ++I) {\n    CodeGenRegisterClass *RC1 = RC;\n    CodeGenRegisterClass *RC2 = &*I;\n    if (RC1 == RC2)\n      continue;\n\n    // Compute the set intersection of RC1 and RC2.\n    const CodeGenRegister::Vec &Memb1 = RC1->getMembers();\n    const CodeGenRegister::Vec &Memb2 = RC2->getMembers();\n    CodeGenRegister::Vec Intersection;\n    std::set_intersection(Memb1.begin(), Memb1.end(), Memb2.begin(),\n                          Memb2.end(),\n                          std::inserter(Intersection, Intersection.begin()),\n                          deref<std::less<>>());\n\n    // Skip disjoint class pairs.\n    if (Intersection.empty())\n      continue;\n\n    // If RC1 and RC2 have different spill sizes or alignments, use the\n    // stricter one for sub-classing.  If they are equal, prefer RC1.\n    if (RC2->RSI.hasStricterSpillThan(RC1->RSI))\n      std::swap(RC1, RC2);\n\n    getOrCreateSubClass(RC1, &Intersection,\n                        RC1->getName() + \"_and_\" + RC2->getName());\n  }\n}\n\n//\n// Synthesize missing sub-classes for getSubClassWithSubReg().\n//\n// Make sure that the set of registers in RC with a given SubIdx sub-register\n// form a register class.  Update RC->SubClassWithSubReg.\n//\nvoid CodeGenRegBank::inferSubClassWithSubReg(CodeGenRegisterClass *RC) {\n  // Map SubRegIndex to set of registers in RC supporting that SubRegIndex.\n  typedef std::map<const CodeGenSubRegIndex *, CodeGenRegister::Vec,\n                   deref<std::less<>>>\n      SubReg2SetMap;\n\n  // Compute the set of registers supporting each SubRegIndex.\n  SubReg2SetMap SRSets;\n  for (const auto R : RC->getMembers()) {\n    if (R->Artificial)\n      continue;\n    const CodeGenRegister::SubRegMap &SRM = R->getSubRegs();\n    for (auto I : SRM) {\n      if (!I.first->Artificial)\n        SRSets[I.first].push_back(R);\n    }\n  }\n\n  for (auto I : SRSets)\n    sortAndUniqueRegisters(I.second);\n\n  // Find matching classes for all SRSets entries.  Iterate in SubRegIndex\n  // numerical order to visit synthetic indices last.\n  for (const auto &SubIdx : SubRegIndices) {\n    if (SubIdx.Artificial)\n      continue;\n    SubReg2SetMap::const_iterator I = SRSets.find(&SubIdx);\n    // Unsupported SubRegIndex. Skip it.\n    if (I == SRSets.end())\n      continue;\n    // In most cases, all RC registers support the SubRegIndex.\n    if (I->second.size() == RC->getMembers().size()) {\n      RC->setSubClassWithSubReg(&SubIdx, RC);\n      continue;\n    }\n    // This is a real subset.  See if we have a matching class.\n    CodeGenRegisterClass *SubRC = getOrCreateSubClass(\n        RC, &I->second, RC->getName() + \"_with_\" + I->first->getName());\n    RC->setSubClassWithSubReg(&SubIdx, SubRC);\n  }\n}\n\n//\n// Synthesize missing sub-classes of RC for getMatchingSuperRegClass().\n//\n// Create sub-classes of RC such that getMatchingSuperRegClass(RC, SubIdx, X)\n// has a maximal result for any SubIdx and any X >= FirstSubRegRC.\n//\n\nvoid CodeGenRegBank::inferMatchingSuperRegClass(\n    CodeGenRegisterClass *RC,\n    std::list<CodeGenRegisterClass>::iterator FirstSubRegRC) {\n  DenseMap<const CodeGenRegister *, std::vector<const CodeGenRegister *>>\n      SubToSuperRegs;\n  BitVector TopoSigs(getNumTopoSigs());\n\n  // Iterate in SubRegIndex numerical order to visit synthetic indices last.\n  for (auto &SubIdx : SubRegIndices) {\n    // Skip indexes that aren't fully supported by RC's registers. This was\n    // computed by inferSubClassWithSubReg() above which should have been\n    // called first.\n    if (RC->getSubClassWithSubReg(&SubIdx) != RC)\n      continue;\n\n    // Build list of (Super, Sub) pairs for this SubIdx.\n    SubToSuperRegs.clear();\n    TopoSigs.reset();\n    for (const auto Super : RC->getMembers()) {\n      const CodeGenRegister *Sub = Super->getSubRegs().find(&SubIdx)->second;\n      assert(Sub && \"Missing sub-register\");\n      SubToSuperRegs[Sub].push_back(Super);\n      TopoSigs.set(Sub->getTopoSig());\n    }\n\n    // Iterate over sub-register class candidates.  Ignore classes created by\n    // this loop. They will never be useful.\n    // Store an iterator to the last element (not end) so that this loop doesn't\n    // visit newly inserted elements.\n    assert(!RegClasses.empty());\n    for (auto I = FirstSubRegRC, E = std::prev(RegClasses.end());\n         I != std::next(E); ++I) {\n      CodeGenRegisterClass &SubRC = *I;\n      if (SubRC.Artificial)\n        continue;\n      // Topological shortcut: SubRC members have the wrong shape.\n      if (!TopoSigs.anyCommon(SubRC.getTopoSigs()))\n        continue;\n      // Compute the subset of RC that maps into SubRC.\n      CodeGenRegister::Vec SubSetVec;\n      for (const CodeGenRegister *R : SubRC.getMembers()) {\n        auto It = SubToSuperRegs.find(R);\n        if (It != SubToSuperRegs.end()) {\n          const std::vector<const CodeGenRegister *> &SuperRegs = It->second;\n          SubSetVec.insert(SubSetVec.end(), SuperRegs.begin(), SuperRegs.end());\n        }\n      }\n\n      if (SubSetVec.empty())\n        continue;\n\n      // RC injects completely into SubRC.\n      sortAndUniqueRegisters(SubSetVec);\n      if (SubSetVec.size() == RC->getMembers().size()) {\n        SubRC.addSuperRegClass(&SubIdx, RC);\n        continue;\n      }\n\n      // Only a subset of RC maps into SubRC. Make sure it is represented by a\n      // class.\n      getOrCreateSubClass(RC, &SubSetVec,\n                          RC->getName() + \"_with_\" + SubIdx.getName() + \"_in_\" +\n                              SubRC.getName());\n    }\n  }\n}\n\n//\n// Infer missing register classes.\n//\nvoid CodeGenRegBank::computeInferredRegisterClasses() {\n  assert(!RegClasses.empty());\n  // When this function is called, the register classes have not been sorted\n  // and assigned EnumValues yet.  That means getSubClasses(),\n  // getSuperClasses(), and hasSubClass() functions are defunct.\n\n  // Use one-before-the-end so it doesn't move forward when new elements are\n  // added.\n  auto FirstNewRC = std::prev(RegClasses.end());\n\n  // Visit all register classes, including the ones being added by the loop.\n  // Watch out for iterator invalidation here.\n  for (auto I = RegClasses.begin(), E = RegClasses.end(); I != E; ++I) {\n    CodeGenRegisterClass *RC = &*I;\n    if (RC->Artificial)\n      continue;\n\n    // Synthesize answers for getSubClassWithSubReg().\n    inferSubClassWithSubReg(RC);\n\n    // Synthesize answers for getCommonSubClass().\n    inferCommonSubClass(RC);\n\n    // Synthesize answers for getMatchingSuperRegClass().\n    inferMatchingSuperRegClass(RC);\n\n    // New register classes are created while this loop is running, and we need\n    // to visit all of them.  I  particular, inferMatchingSuperRegClass needs\n    // to match old super-register classes with sub-register classes created\n    // after inferMatchingSuperRegClass was called.  At this point,\n    // inferMatchingSuperRegClass has checked SuperRC = [0..rci] with SubRC =\n    // [0..FirstNewRC).  We need to cover SubRC = [FirstNewRC..rci].\n    if (I == FirstNewRC) {\n      auto NextNewRC = std::prev(RegClasses.end());\n      for (auto I2 = RegClasses.begin(), E2 = std::next(FirstNewRC); I2 != E2;\n           ++I2)\n        inferMatchingSuperRegClass(&*I2, E2);\n      FirstNewRC = NextNewRC;\n    }\n  }\n}\n\n/// getRegisterClassForRegister - Find the register class that contains the\n/// specified physical register.  If the register is not in a register class,\n/// return null. If the register is in multiple classes, and the classes have a\n/// superset-subset relationship and the same set of types, return the\n/// superclass.  Otherwise return null.\nconst CodeGenRegisterClass *CodeGenRegBank::getRegClassForRegister(Record *R) {\n  const CodeGenRegister *Reg = getReg(R);\n  const CodeGenRegisterClass *FoundRC = nullptr;\n  for (const auto &RC : getRegClasses()) {\n    if (!RC.contains(Reg))\n      continue;\n\n    // If this is the first class that contains the register,\n    // make a note of it and go on to the next class.\n    if (!FoundRC) {\n      FoundRC = &RC;\n      continue;\n    }\n\n    // If a register's classes have different types, return null.\n    if (RC.getValueTypes() != FoundRC->getValueTypes())\n      return nullptr;\n\n    // Check to see if the previously found class that contains\n    // the register is a subclass of the current class. If so,\n    // prefer the superclass.\n    if (RC.hasSubClass(FoundRC)) {\n      FoundRC = &RC;\n      continue;\n    }\n\n    // Check to see if the previously found class that contains\n    // the register is a superclass of the current class. If so,\n    // prefer the superclass.\n    if (FoundRC->hasSubClass(&RC))\n      continue;\n\n    // Multiple classes, and neither is a superclass of the other.\n    // Return null.\n    return nullptr;\n  }\n  return FoundRC;\n}\n\nconst CodeGenRegisterClass *\nCodeGenRegBank::getMinimalPhysRegClass(Record *RegRecord,\n                                       ValueTypeByHwMode *VT) {\n  const CodeGenRegister *Reg = getReg(RegRecord);\n  const CodeGenRegisterClass *BestRC = nullptr;\n  for (const auto &RC : getRegClasses()) {\n    if ((!VT || RC.hasType(*VT)) && RC.contains(Reg) &&\n        (!BestRC || BestRC->hasSubClass(&RC)))\n      BestRC = &RC;\n  }\n\n  assert(BestRC && \"Couldn't find the register class\");\n  return BestRC;\n}\n\nBitVector CodeGenRegBank::computeCoveredRegisters(ArrayRef<Record *> Regs) {\n  SetVector<const CodeGenRegister *> Set;\n\n  // First add Regs with all sub-registers.\n  for (unsigned i = 0, e = Regs.size(); i != e; ++i) {\n    CodeGenRegister *Reg = getReg(Regs[i]);\n    if (Set.insert(Reg))\n      // Reg is new, add all sub-registers.\n      // The pre-ordering is not important here.\n      Reg->addSubRegsPreOrder(Set, *this);\n  }\n\n  // Second, find all super-registers that are completely covered by the set.\n  for (unsigned i = 0; i != Set.size(); ++i) {\n    const CodeGenRegister::SuperRegList &SR = Set[i]->getSuperRegs();\n    for (unsigned j = 0, e = SR.size(); j != e; ++j) {\n      const CodeGenRegister *Super = SR[j];\n      if (!Super->CoveredBySubRegs || Set.count(Super))\n        continue;\n      // This new super-register is covered by its sub-registers.\n      bool AllSubsInSet = true;\n      const CodeGenRegister::SubRegMap &SRM = Super->getSubRegs();\n      for (auto I : SRM)\n        if (!Set.count(I.second)) {\n          AllSubsInSet = false;\n          break;\n        }\n      // All sub-registers in Set, add Super as well.\n      // We will visit Super later to recheck its super-registers.\n      if (AllSubsInSet)\n        Set.insert(Super);\n    }\n  }\n\n  // Convert to BitVector.\n  BitVector BV(Registers.size() + 1);\n  for (unsigned i = 0, e = Set.size(); i != e; ++i)\n    BV.set(Set[i]->EnumValue);\n  return BV;\n}\n\nvoid CodeGenRegBank::printRegUnitName(unsigned Unit) const {\n  if (Unit < NumNativeRegUnits)\n    dbgs() << ' ' << RegUnits[Unit].Roots[0]->getName();\n  else\n    dbgs() << \" #\" << Unit;\n}\n"}], "code": "std::vector<ValueTypeByHwMode> CodeGenTarget::getRegisterVTs(Record *R) const {\n  const CodeGenRegister *Reg = getRegBank().getReg(R);\n  std::vector<ValueTypeByHwMode> Result;\n  for (const auto &RC : getRegBank().getRegClasses()) {\n    if (RC.contains(Reg)) {\n      ArrayRef<ValueTypeByHwMode> InVTs = RC.getValueTypes();\n      llvm::append_range(Result, InVTs);\n    }\n  }\n\n  // Remove duplicates.\n  llvm::sort(Result);\n  Result.erase(std::unique(Result.begin(), Result.end()), Result.end());\n  return Result;\n}\n"}, "D291EF0201C0B2FA": {"calls": [{"id": "8466D35135FCE1A7", "name": "llvm::Matcher::takeNext", "path": "llvm-project/llvm/utils/TableGen/DAGISelMatcher.h", "start": {"line": 117, "col": 3}, "end": {"line": 117, "col": 48}, "code": "\n  std::unique_ptr<Matcher> &getNextPtr() { return Next; }\n\n  bool isEqual(const Matcher *M) const {\n    if (getKind() != M->getKind())\n      return false;\n    return isEqualImpl(M);\n  }\n\n  /// isSimplePredicateNode - Return true if this is a simple predicate that\n  /// operates on the node or its children without potential side effects or a\n  /// change of the current node.\n  bool isSimplePredicateNode() const {\n    switch (getKind()) {\n    default:\n      return false;\n    case CheckSame:\n    case CheckChildSame:\n    case CheckPatternPredicate:\n    case CheckPredicate:\n    case CheckOpcode:\n    case CheckType:\n    case CheckChildType:\n    case CheckInteger:\n    case CheckChildInteger:\n    case CheckCondCode:\n    case CheckChild2CondCode:\n    case CheckValueType:\n    case CheckAndImm:\n    case CheckOrImm:\n    case CheckImmAllOnesV:\n    case CheckImmAllZerosV:\n    case CheckFoldableChainNode:\n      return true;\n    }\n  }\n\n  /// isSimplePredicateOrRecordNode - Return true if this is a record node or\n  /// a simple predicate.\n  bool isSimplePredicateOrRecordNode() const {\n    return isSimplePredicateNode() || getKind() == RecordNode ||\n           getKind() == RecordChild;\n  }\n\n  /// unlinkNode - Unlink the specified node from this chain.  If Other ==\n  /// this, we unlink the next pointer and return it.  Otherwise we unlink\n  /// Other from the list and return this.\n  Matcher *unlinkNode(Matcher *Other);\n\n  /// canMoveBefore - Return true if this matcher is the same as Other, or if\n  /// we can move this matcher past all of the nodes in-between Other and this\n  /// node.  Other must be equal to or before this.\n  bool canMoveBefore(const Matcher *Other) const;\n\n  /// canMoveBeforeNode - Return true if it is safe to move the current\n  /// matcher across the specified one.\n  bool canMoveBeforeNode(const Matcher *Other) const;\n\n  /// isContradictory - Return true of these two matchers could never match on\n  /// the same node.\n  bool isContradictory(const Matcher *Other) const {\n    // Since this predicate is reflexive, we canonicalize the ordering so that\n    // we always match a node against nodes with kinds that are greater or\n    // equal to them.  For example, we'll pass in a CheckType node as an\n    // argument to the CheckOpcode method, not the other way around.\n    if (getKind() < Other->getKind())\n      return isContradictoryImpl(Other);\n    return Other->isContradictoryImpl(this);\n  }\n\n  void print(raw_ostream &OS, unsigned indent = 0) const;\n  void printOne(raw_ostream &OS) const;\n  void dump() const;\n\nprotected:\n  virtual void printImpl(raw_ostream &OS, unsigned indent) const = 0;\n  virtual bool isEqualImpl(const Matcher *M) const = 0;\n  virtual bool isContradictoryImpl(const Matcher *M) const { return false; }\n};\n\n/// ScopeMatcher - This attempts to match each of its children to find the first\n/// one that successfully matches.  If one child fails, it tries the next child.\n/// If none of the children match then this check fails.  It never has a 'next'.\nclass ScopeMatcher : public Matcher {\n  SmallVector<Matcher *, 4> Children;\n\npublic:\n  ScopeMatcher(SmallVectorImpl<Matcher *> &&children)\n      : Matcher(Scope), Children(std::move(children)) {}\n  ~ScopeMatcher() override;\n\n  unsigned getNumChildren() const { return Children.size(); }\n\n  Matcher *getChild(unsigned i) { return Children[i]; }\n  const Matcher *getChild(unsigned i) const { return Children[i]; }\n\n  void resetChild(unsigned i, Matcher *N) {\n    delete Children[i];\n    Children[i] = N;\n  }\n\n  Matcher *takeChild(unsigned i) {\n    Matcher *Res = Children[i];\n    Children[i] = nullptr;\n    return Res;\n  }\n\n  void setNumChildren(unsigned NC) {\n    if (NC < Children.size()) {\n      // delete any children we're about to lose pointers to.\n      for (unsigned i = NC, e = Children.size(); i != e; ++i)\n        delete Children[i];\n    }\n    Children.resize(NC);\n  }\n\n  static bool classof(const Matcher *N) { return N->getKind() == Scope; }\n\n"}, {"id": "0CAC23B6EAC64A1F", "name": "llvm::Matcher::getNext", "path": "llvm-project/llvm/utils/TableGen/DAGISelMatcher.h", "start": {"line": 114, "col": 3}, "end": {"line": 114, "col": 43}, "code": "  const Matcher *getNext() const { return Next.get(); }\n  void setNext(Matcher *C) { Next.reset(C); }\n  Matcher *takeNext() { return Next.release(); }\n\n  std::unique_ptr<Matcher> &getNextPtr() { return Next; }\n\n  bool isEqual(const Matcher *M) const {\n    if (getKind() != M->getKind())\n      return false;\n    return isEqualImpl(M);\n  }\n\n  /// isSimplePredicateNode - Return true if this is a simple predicate that\n  /// operates on the node or its children without potential side effects or a\n  /// change of the current node.\n  bool isSimplePredicateNode() const {\n    switch (getKind()) {\n    default:\n      return false;\n    case CheckSame:\n    case CheckChildSame:\n    case CheckPatternPredicate:\n    case CheckPredicate:\n    case CheckOpcode:\n    case CheckType:\n    case CheckChildType:\n    case CheckInteger:\n    case CheckChildInteger:\n    case CheckCondCode:\n    case CheckChild2CondCode:\n    case CheckValueType:\n    case CheckAndImm:\n    case CheckOrImm:\n    case CheckImmAllOnesV:\n    case CheckImmAllZerosV:\n    case CheckFoldableChainNode:\n      return true;\n    }\n  }\n\n  /// isSimplePredicateOrRecordNode - Return true if this is a record node or\n  /// a simple predicate.\n  bool isSimplePredicateOrRecordNode() const {\n    return isSimplePredicateNode() || getKind() == RecordNode ||\n           getKind() == RecordChild;\n  }\n\n  /// unlinkNode - Unlink the specified node from this chain.  If Other ==\n  /// this, we unlink the next pointer and return it.  Otherwise we unlink\n  /// Other from the list and return this.\n  Matcher *unlinkNode(Matcher *Other);\n\n  /// canMoveBefore - Return true if this matcher is the same as Other, or if\n  /// we can move this matcher past all of the nodes in-between Other and this\n  /// node.  Other must be equal to or before this.\n  bool canMoveBefore(const Matcher *Other) const;\n\n  /// canMoveBeforeNode - Return true if it is safe to move the current\n  /// matcher across the specified one.\n  bool canMoveBeforeNode(const Matcher *Other) const;\n\n  /// isContradictory - Return true of these two matchers could never match on\n  /// the same node.\n  bool isContradictory(const Matcher *Other) const {\n    // Since this predicate is reflexive, we canonicalize the ordering so that\n    // we always match a node against nodes with kinds that are greater or\n    // equal to them.  For example, we'll pass in a CheckType node as an\n    // argument to the CheckOpcode method, not the other way around.\n    if (getKind() < Other->getKind())\n      return isContradictoryImpl(Other);\n    return Other->isContradictoryImpl(this);\n  }\n\n  void print(raw_ostream &OS, unsigned indent = 0) const;\n  void printOne(raw_ostream &OS) const;\n  void dump() const;\n\nprotected:\n  virtual void printImpl(raw_ostream &OS, unsigned indent) const = 0;\n  virtual bool isEqualImpl(const Matcher *M) const = 0;\n  virtual bool isContradictoryImpl(const Matcher *M) const { return false; }\n};\n\n/// ScopeMatcher - This attempts to match each of its children to find the first\n/// one that successfully matches.  If one child fails, it tries the next child.\n/// If none of the children match then this check fails.  It never has a 'next'.\nclass ScopeMatcher : public Matcher {\n  SmallVector<Matcher *, 4> Children;\n\npublic:\n  ScopeMatcher(SmallVectorImpl<Matcher *> &&children)\n      : Matcher(Scope), Children(std::move(children)) {}\n  ~ScopeMatcher() override;\n\n  unsigned getNumChildren() const { return Children.size(); }\n\n  Matcher *getChild(unsigned i) { return Children[i]; }\n  const Matcher *getChild(unsigned i) const { return Children[i]; }\n\n  void resetChild(unsigned i, Matcher *N) {\n    delete Children[i];\n    Children[i] = N;\n  }\n\n  Matcher *takeChild(unsigned i) {\n    Matcher *Res = Children[i];\n    Children[i] = nullptr;\n    return Res;\n  }\n\n  void setNumChildren(unsigned NC) {\n    if (NC < Children.size()) {\n      // delete any children we're about to lose pointers to.\n      for (unsigned i = NC, e = Children.size(); i != e; ++i)\n        delete Children[i];\n"}, {"id": "5BDF172251D3F6BD", "name": "llvm::Matcher::setNext", "path": "llvm-project/llvm/utils/TableGen/DAGISelMatcher.h", "start": {"line": 116, "col": 3}, "end": {"line": 116, "col": 45}, "code": "  Matcher *takeNext() { return Next.release(); }\n\n  std::unique_ptr<Matcher> &getNextPtr() { return Next; }\n\n  bool isEqual(const Matcher *M) const {\n    if (getKind() != M->getKind())\n      return false;\n    return isEqualImpl(M);\n  }\n\n  /// isSimplePredicateNode - Return true if this is a simple predicate that\n  /// operates on the node or its children without potential side effects or a\n  /// change of the current node.\n  bool isSimplePredicateNode() const {\n    switch (getKind()) {\n    default:\n      return false;\n    case CheckSame:\n    case CheckChildSame:\n    case CheckPatternPredicate:\n    case CheckPredicate:\n    case CheckOpcode:\n    case CheckType:\n    case CheckChildType:\n    case CheckInteger:\n    case CheckChildInteger:\n    case CheckCondCode:\n    case CheckChild2CondCode:\n    case CheckValueType:\n    case CheckAndImm:\n    case CheckOrImm:\n    case CheckImmAllOnesV:\n    case CheckImmAllZerosV:\n    case CheckFoldableChainNode:\n      return true;\n    }\n  }\n\n  /// isSimplePredicateOrRecordNode - Return true if this is a record node or\n  /// a simple predicate.\n  bool isSimplePredicateOrRecordNode() const {\n    return isSimplePredicateNode() || getKind() == RecordNode ||\n           getKind() == RecordChild;\n  }\n\n  /// unlinkNode - Unlink the specified node from this chain.  If Other ==\n  /// this, we unlink the next pointer and return it.  Otherwise we unlink\n  /// Other from the list and return this.\n  Matcher *unlinkNode(Matcher *Other);\n\n  /// canMoveBefore - Return true if this matcher is the same as Other, or if\n  /// we can move this matcher past all of the nodes in-between Other and this\n  /// node.  Other must be equal to or before this.\n  bool canMoveBefore(const Matcher *Other) const;\n\n  /// canMoveBeforeNode - Return true if it is safe to move the current\n  /// matcher across the specified one.\n  bool canMoveBeforeNode(const Matcher *Other) const;\n\n  /// isContradictory - Return true of these two matchers could never match on\n  /// the same node.\n  bool isContradictory(const Matcher *Other) const {\n    // Since this predicate is reflexive, we canonicalize the ordering so that\n    // we always match a node against nodes with kinds that are greater or\n    // equal to them.  For example, we'll pass in a CheckType node as an\n    // argument to the CheckOpcode method, not the other way around.\n    if (getKind() < Other->getKind())\n      return isContradictoryImpl(Other);\n    return Other->isContradictoryImpl(this);\n  }\n\n  void print(raw_ostream &OS, unsigned indent = 0) const;\n  void printOne(raw_ostream &OS) const;\n  void dump() const;\n\nprotected:\n  virtual void printImpl(raw_ostream &OS, unsigned indent) const = 0;\n  virtual bool isEqualImpl(const Matcher *M) const = 0;\n  virtual bool isContradictoryImpl(const Matcher *M) const { return false; }\n};\n\n/// ScopeMatcher - This attempts to match each of its children to find the first\n/// one that successfully matches.  If one child fails, it tries the next child.\n/// If none of the children match then this check fails.  It never has a 'next'.\nclass ScopeMatcher : public Matcher {\n  SmallVector<Matcher *, 4> Children;\n\npublic:\n  ScopeMatcher(SmallVectorImpl<Matcher *> &&children)\n      : Matcher(Scope), Children(std::move(children)) {}\n  ~ScopeMatcher() override;\n\n  unsigned getNumChildren() const { return Children.size(); }\n\n  Matcher *getChild(unsigned i) { return Children[i]; }\n  const Matcher *getChild(unsigned i) const { return Children[i]; }\n\n  void resetChild(unsigned i, Matcher *N) {\n    delete Children[i];\n    Children[i] = N;\n  }\n\n  Matcher *takeChild(unsigned i) {\n    Matcher *Res = Children[i];\n    Children[i] = nullptr;\n    return Res;\n  }\n\n  void setNumChildren(unsigned NC) {\n    if (NC < Children.size()) {\n      // delete any children we're about to lose pointers to.\n      for (unsigned i = NC, e = Children.size(); i != e; ++i)\n        delete Children[i];\n    }\n    Children.resize(NC);\n  }\n\n"}], "code": "Matcher *Matcher::unlinkNode(Matcher *Other) {\n  if (this == Other)\n    return takeNext();\n\n  // Scan until we find the predecessor of Other.\n  Matcher *Cur = this;\n  for (; Cur && Cur->getNext() != Other; Cur = Cur->getNext())\n    /*empty*/;\n\n  if (!Cur)\n    return nullptr;\n  Cur->takeNext();\n  Cur->setNext(Other->takeNext());\n  return this;\n}\n"}, "135AB6DB6E67CB5A": {"calls": [{"id": "94E2B5420044B621", "name": "llvm::VPValue::getDefiningRecipe", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlan.cpp", "start": {"line": 116, "col": 1}, "end": {"line": 118, "col": 1}, "code": "  return cast_or_null<VPRecipeBase>(Def);\n}\n\nconst VPRecipeBase *VPValue::getDefiningRecipe() const {\n  return cast_or_null<VPRecipeBase>(Def);\n}\n\n// Get the top-most entry block of \\p Start. This is the entry block of the\n// containing VPlan. This function is templated to support both const and non-const blocks\ntemplate <typename T> static T *getPlanEntry(T *Start) {\n  T *Next = Start;\n  T *Current = Start;\n  while ((Next = Next->getParent()))\n    Current = Next;\n\n  SmallSetVector<T *, 8> WorkList;\n  WorkList.insert(Current);\n\n  for (unsigned i = 0; i < WorkList.size(); i++) {\n    T *Current = WorkList[i];\n    if (Current->getNumPredecessors() == 0)\n      return Current;\n    auto &Predecessors = Current->getPredecessors();\n    WorkList.insert(Predecessors.begin(), Predecessors.end());\n  }\n\n  llvm_unreachable(\"VPlan without any entry node without predecessors\");\n}\n\nVPlan *VPBlockBase::getPlan() { return getPlanEntry(this)->Plan; }\n\nconst VPlan *VPBlockBase::getPlan() const { return getPlanEntry(this)->Plan; }\n\n/// \\return the VPBasicBlock that is the entry of Block, possibly indirectly.\nconst VPBasicBlock *VPBlockBase::getEntryBasicBlock() const {\n  const VPBlockBase *Block = this;\n  while (const VPRegionBlock *Region = dyn_cast<VPRegionBlock>(Block))\n    Block = Region->getEntry();\n  return cast<VPBasicBlock>(Block);\n}\n\nVPBasicBlock *VPBlockBase::getEntryBasicBlock() {\n  VPBlockBase *Block = this;\n  while (VPRegionBlock *Region = dyn_cast<VPRegionBlock>(Block))\n    Block = Region->getEntry();\n  return cast<VPBasicBlock>(Block);\n}\n\nvoid VPBlockBase::setPlan(VPlan *ParentPlan) {\n  assert(\n      (ParentPlan->getEntry() == this || ParentPlan->getPreheader() == this) &&\n      \"Can only set plan on its entry or preheader block.\");\n  Plan = ParentPlan;\n}\n\n/// \\return the VPBasicBlock that is the exit of Block, possibly indirectly.\nconst VPBasicBlock *VPBlockBase::getExitingBasicBlock() const {\n  const VPBlockBase *Block = this;\n  while (const VPRegionBlock *Region = dyn_cast<VPRegionBlock>(Block))\n    Block = Region->getExiting();\n  return cast<VPBasicBlock>(Block);\n}\n\nVPBasicBlock *VPBlockBase::getExitingBasicBlock() {\n  VPBlockBase *Block = this;\n  while (VPRegionBlock *Region = dyn_cast<VPRegionBlock>(Block))\n    Block = Region->getExiting();\n  return cast<VPBasicBlock>(Block);\n}\n\nVPBlockBase *VPBlockBase::getEnclosingBlockWithSuccessors() {\n  if (!Successors.empty() || !Parent)\n    return this;\n  assert(Parent->getExiting() == this &&\n         \"Block w/o successors not the exiting block of its parent.\");\n  return Parent->getEnclosingBlockWithSuccessors();\n}\n\nVPBlockBase *VPBlockBase::getEnclosingBlockWithPredecessors() {\n  if (!Predecessors.empty() || !Parent)\n    return this;\n  assert(Parent->getEntry() == this &&\n         \"Block w/o predecessors not the entry of its parent.\");\n  return Parent->getEnclosingBlockWithPredecessors();\n}\n\nvoid VPBlockBase::deleteCFG(VPBlockBase *Entry) {\n  for (VPBlockBase *Block : to_vector(vp_depth_first_shallow(Entry)))\n    delete Block;\n}\n\nVPBasicBlock::iterator VPBasicBlock::getFirstNonPhi() {\n  iterator It = begin();\n  while (It != end() && It->isPhi())\n    It++;\n  return It;\n}\n\nValue *VPTransformState::get(VPValue *Def, const VPIteration &Instance) {\n  if (Def->isLiveIn())\n    return Def->getLiveInIRValue();\n\n  if (hasScalarValue(Def, Instance)) {\n    return Data\n        .PerPartScalars[Def][Instance.Part][Instance.Lane.mapToCacheIndex(VF)];\n  }\n\n  assert(hasVectorValue(Def, Instance.Part));\n  auto *VecPart = Data.PerPartOutput[Def][Instance.Part];\n  if (!VecPart->getType()->isVectorTy()) {\n    assert(Instance.Lane.isFirstLane() && \"cannot get lane > 0 for scalar\");\n    return VecPart;\n  }\n  // TODO: Cache created scalar values.\n  Value *Lane = Instance.Lane.getAsRuntimeExpr(Builder, VF);\n  auto *Extract = Builder.CreateExtractElement(VecPart, Lane);\n  // set(Def, Extract, Instance);\n  return Extract;\n}\n"}], "code": "bool VPCanonicalIVPHIRecipe::isCanonical(\n    InductionDescriptor::InductionKind Kind, VPValue *Start,\n    VPValue *Step) const {\n  // Must be an integer induction.\n  if (Kind != InductionDescriptor::IK_IntInduction)\n    return false;\n  // Start must match the start value of this canonical induction.\n  if (Start != getStartValue())\n    return false;\n\n  // If the step is defined by a recipe, it is not a ConstantInt.\n  if (Step->getDefiningRecipe())\n    return false;\n\n  ConstantInt *StepC = dyn_cast<ConstantInt>(Step->getLiveInIRValue());\n  return StepC && StepC->isOne();\n}\n"}, "9D32EA254C7044EC": {"calls": [{"id": "3FBB61DB2320ED9E", "name": "llvm::AArch64Subtarget::isWindowsArm64EC", "path": "llvm-project/llvm/lib/Target/AArch64/AArch64Subtarget.h", "start": {"line": 303, "col": 3}, "end": {"line": 303, "col": 75}, "code": "\n  bool isTargetCOFF() const { return TargetTriple.isOSBinFormatCOFF(); }\n  bool isTargetELF() const { return TargetTriple.isOSBinFormatELF(); }\n  bool isTargetMachO() const { return TargetTriple.isOSBinFormatMachO(); }\n\n  bool isTargetILP32() const {\n    return TargetTriple.isArch32Bit() ||\n           TargetTriple.getEnvironment() == Triple::GNUILP32;\n  }\n\n  bool useAA() const override;\n\n  bool addrSinkUsingGEPs() const override {\n    // Keeping GEPs inbounds is important for exploiting AArch64\n    // addressing-modes in ILP32 mode.\n    return useAA() || isTargetILP32();\n  }\n\n  bool useSmallAddressing() const {\n    switch (TLInfo.getTargetMachine().getCodeModel()) {\n      case CodeModel::Kernel:\n        // Kernel is currently allowed only for Fuchsia targets,\n        // where it is the same as Small for almost all purposes.\n      case CodeModel::Small:\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  /// ParseSubtargetFeatures - Parses features string setting specified\n  /// subtarget options.  Definition of function is auto generated by tblgen.\n  void ParseSubtargetFeatures(StringRef CPU, StringRef TuneCPU, StringRef FS);\n\n  /// ClassifyGlobalReference - Find the target operand flags that describe\n  /// how a global value should be referenced for the current subtarget.\n  unsigned ClassifyGlobalReference(const GlobalValue *GV,\n                                   const TargetMachine &TM) const;\n\n  unsigned classifyGlobalFunctionReference(const GlobalValue *GV,\n                                           const TargetMachine &TM) const;\n\n  /// This function is design to compatible with the function def in other\n  /// targets and escape build error about the virtual function def in base\n  /// class TargetSubtargetInfo. Updeate me if AArch64 target need to use it.\n  unsigned char\n  classifyGlobalFunctionReference(const GlobalValue *GV) const override {\n    return 0;\n  }\n\n  void overrideSchedPolicy(MachineSchedPolicy &Policy,\n                           unsigned NumRegionInstrs) const override;\n\n  bool enableEarlyIfConversion() const override;\n\n  std::unique_ptr<PBQPRAConstraint> getCustomPBQPConstraints() const override;\n\n  bool isCallingConvWin64(CallingConv::ID CC) const {\n    switch (CC) {\n    case CallingConv::C:\n    case CallingConv::Fast:\n    case CallingConv::Swift:\n      return isTargetWindows();\n    case CallingConv::Win64:\n      return true;\n    default:\n      return false;\n    }\n  }\n\n  /// Return whether FrameLowering should always set the \"extended frame\n  /// present\" bit in FP, or set it based on a symbol in the runtime.\n  bool swiftAsyncContextIsDynamicallySet() const {\n    // Older OS versions (particularly system unwinders) are confused by the\n    // Swift extended frame, so when building code that might be run on them we\n    // must dynamically query the concurrency library to determine whether\n    // extended frames should be flagged as present.\n    const Triple &TT = getTargetTriple();\n\n    unsigned Major = TT.getOSVersion().getMajor();\n    switch(TT.getOS()) {\n    default:\n      return false;\n    case Triple::IOS:\n    case Triple::TvOS:\n      return Major < 15;\n    case Triple::WatchOS:\n      return Major < 8;\n    case Triple::MacOSX:\n    case Triple::Darwin:\n      return Major < 12;\n    }\n  }\n\n  void mirFileLoaded(MachineFunction &MF) const override;\n\n  bool hasSVEorSME() const { return hasSVE() || hasSME(); }\n  bool hasSVE2orSME() const { return hasSVE2() || hasSME(); }\n\n  // Return the known range for the bit length of SVE data registers. A value\n  // of 0 means nothing is known about that particular limit beyong what's\n  // implied by the architecture.\n  unsigned getMaxSVEVectorSizeInBits() const {\n    assert(hasSVEorSME() &&\n           \"Tried to get SVE vector length without SVE support!\");\n    return MaxSVEVectorSizeInBits;\n  }\n\n  unsigned getMinSVEVectorSizeInBits() const {\n    assert(hasSVEorSME() &&\n           \"Tried to get SVE vector length without SVE support!\");\n    return MinSVEVectorSizeInBits;\n  }\n\n  bool useSVEForFixedLengthVectors() const {\n    if (!isNeonAvailable())\n      return hasSVEorSME();\n\n    // Prefer NEON unless larger SVE registers are available.\n    return hasSVEorSME() && getMinSVEVectorSizeInBits() >= 256;\n  }\n\n  bool useSVEForFixedLengthVectors(EVT VT) const {\n    if (!useSVEForFixedLengthVectors() || !VT.isFixedLengthVector())\n      return false;\n    return VT.getFixedSizeInBits() > AArch64::SVEBitsPerBlock ||\n           !isNeonAvailable();\n  }\n\n  unsigned getVScaleForTuning() const { return VScaleForTuning; }\n\n  TailFoldingOpts getSVETailFoldingDefaultOpts() const {\n    return DefaultSVETFOpts;\n  }\n\n  const char* getChkStkName() const {\n    if (isWindowsArm64EC())\n      return \"#__chkstk_arm64ec\";\n    return \"__chkstk\";\n  }\n\n  const char* getSecurityCheckCookieName() const {\n    if (isWindowsArm64EC())\n      return \"#__security_check_cookie_arm64ec\";\n    return \"__security_check_cookie\";\n  }\n\n  /// Choose a method of checking LR before performing a tail call.\n  AArch64PAuth::AuthCheckMethod getAuthenticatedLRCheckMethod() const;\n\n  const PseudoSourceValue *getAddressCheckPSV() const {\n    return AddressCheckPSV.get();\n  }\n\nprivate:\n  /// Pseudo value representing memory load performed to check an address.\n  ///\n  /// This load operation is solely used for its side-effects: if the address\n  /// is not mapped (or not readable), it triggers CPU exception, otherwise\n  /// execution proceeds and the value is not used.\n  class AddressCheckPseudoSourceValue : public PseudoSourceValue {\n  public:\n    AddressCheckPseudoSourceValue(const TargetMachine &TM)\n        : PseudoSourceValue(TargetCustom, TM) {}\n\n    bool isConstant(const MachineFrameInfo *) const override { return false; }\n    bool isAliased(const MachineFrameInfo *) const override { return true; }\n    bool mayAlias(const MachineFrameInfo *) const override { return true; }\n    void printCustom(raw_ostream &OS) const override { OS << \"AddressCheck\"; }\n  };\n\n  std::unique_ptr<AddressCheckPseudoSourceValue> AddressCheckPSV;\n};\n} // End llvm namespace\n\n#endif\n"}], "code": "CCAssignFn *\nAArch64TargetLowering::CCAssignFnForReturn(CallingConv::ID CC) const {\n  switch (CC) {\n  default:\n    return RetCC_AArch64_AAPCS;\n  case CallingConv::ARM64EC_Thunk_X64:\n    return RetCC_AArch64_Arm64EC_Thunk;\n  case CallingConv::CFGuard_Check:\n    if (Subtarget->isWindowsArm64EC())\n      return RetCC_AArch64_Arm64EC_CFGuard_Check;\n    return RetCC_AArch64_AAPCS;\n  }\n}\n"}, "4735CDFEDB70C30E": {"calls": [{"id": "58A14B5646B121DC", "name": "llvm::MachineRegisterInfo::tracksLiveness", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineRegisterInfo.h", "start": {"line": 210, "col": 3}, "end": {"line": 213, "col": 3}, "code": "    return MF->getProperties().hasProperty(\n        MachineFunctionProperties::Property::TracksLiveness);\n  }\n\n  /// invalidateLiveness - Indicates that register liveness is no longer being\n  /// tracked accurately.\n  ///\n  /// This should be called by late passes that invalidate the liveness\n  /// information.\n  void invalidateLiveness() {\n    MF->getProperties().reset(\n        MachineFunctionProperties::Property::TracksLiveness);\n  }\n\n  /// Returns true if liveness for register class @p RC should be tracked at\n  /// the subregister level.\n  bool shouldTrackSubRegLiveness(const TargetRegisterClass &RC) const {\n    return subRegLivenessEnabled() && RC.HasDisjunctSubRegs;\n  }\n  bool shouldTrackSubRegLiveness(Register VReg) const {\n    assert(VReg.isVirtual() && \"Must pass a VReg\");\n    const TargetRegisterClass *RC = getRegClassOrNull(VReg);\n    return LLVM_LIKELY(RC) ? shouldTrackSubRegLiveness(*RC) : false;\n  }\n  bool subRegLivenessEnabled() const {\n    return TracksSubRegLiveness;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Register Info\n  //===--------------------------------------------------------------------===//\n\n  /// Returns true if the updated CSR list was initialized and false otherwise.\n  bool isUpdatedCSRsInitialized() const { return IsUpdatedCSRsInitialized; }\n\n  /// Returns true if a register can be used as an argument to a function.\n  bool isArgumentRegister(const MachineFunction &MF, MCRegister Reg) const;\n\n  /// Returns true if a register is a fixed register.\n  bool isFixedRegister(const MachineFunction &MF, MCRegister Reg) const;\n\n  /// Returns true if a register is a general purpose register.\n  bool isGeneralPurposeRegister(const MachineFunction &MF,\n                                MCRegister Reg) const;\n\n  /// Disables the register from the list of CSRs.\n  /// I.e. the register will not appear as part of the CSR mask.\n  /// \\see UpdatedCalleeSavedRegs.\n  void disableCalleeSavedRegister(MCRegister Reg);\n\n  /// Returns list of callee saved registers.\n  /// The function returns the updated CSR list (after taking into account\n  /// registers that are disabled from the CSR list).\n  const MCPhysReg *getCalleeSavedRegs() const;\n\n  /// Sets the updated Callee Saved Registers list.\n  /// Notice that it will override ant previously disabled/saved CSRs.\n  void setCalleeSavedRegs(ArrayRef<MCPhysReg> CSRs);\n\n  // Strictly for use by MachineInstr.cpp.\n  void addRegOperandToUseList(MachineOperand *MO);\n\n  // Strictly for use by MachineInstr.cpp.\n  void removeRegOperandFromUseList(MachineOperand *MO);\n\n  // Strictly for use by MachineInstr.cpp.\n  void moveOperands(MachineOperand *Dst, MachineOperand *Src, unsigned NumOps);\n\n  /// Verify the sanity of the use list for Reg.\n  void verifyUseList(Register Reg) const;\n\n  /// Verify the use list of all registers.\n  void verifyUseLists() const;\n\n  /// reg_begin/reg_end - Provide iteration support to walk over all definitions\n  /// and uses of a register within the MachineFunction that corresponds to this\n  /// MachineRegisterInfo object.\n  template<bool Uses, bool Defs, bool SkipDebug,\n           bool ByOperand, bool ByInstr, bool ByBundle>\n  class defusechain_iterator;\n  template<bool Uses, bool Defs, bool SkipDebug,\n           bool ByOperand, bool ByInstr, bool ByBundle>\n  class defusechain_instr_iterator;\n\n  // Make it a friend so it can access getNextOperandForReg().\n  template<bool, bool, bool, bool, bool, bool>\n    friend class defusechain_iterator;\n  template<bool, bool, bool, bool, bool, bool>\n    friend class defusechain_instr_iterator;\n\n  /// reg_iterator/reg_begin/reg_end - Walk all defs and uses of the specified\n  /// register.\n  using reg_iterator =\n      defusechain_iterator<true, true, false, true, false, false>;\n  reg_iterator reg_begin(Register RegNo) const {\n    return reg_iterator(getRegUseDefListHead(RegNo));\n  }\n  static reg_iterator reg_end() { return reg_iterator(nullptr); }\n\n  inline iterator_range<reg_iterator> reg_operands(Register Reg) const {\n    return make_range(reg_begin(Reg), reg_end());\n  }\n\n  /// reg_instr_iterator/reg_instr_begin/reg_instr_end - Walk all defs and uses\n  /// of the specified register, stepping by MachineInstr.\n  using reg_instr_iterator =\n      defusechain_instr_iterator<true, true, false, false, true, false>;\n  reg_instr_iterator reg_instr_begin(Register RegNo) const {\n    return reg_instr_iterator(getRegUseDefListHead(RegNo));\n  }\n  static reg_instr_iterator reg_instr_end() {\n    return reg_instr_iterator(nullptr);\n  }\n\n  inline iterator_range<reg_instr_iterator>\n  reg_instructions(Register Reg) const {\n    return make_range(reg_instr_begin(Reg), reg_instr_end());\n  }\n\n  /// reg_bundle_iterator/reg_bundle_begin/reg_bundle_end - Walk all defs and uses\n  /// of the specified register, stepping by bundle.\n  using reg_bundle_iterator =\n      defusechain_instr_iterator<true, true, false, false, false, true>;\n  reg_bundle_iterator reg_bundle_begin(Register RegNo) const {\n    return reg_bundle_iterator(getRegUseDefListHead(RegNo));\n  }\n  static reg_bundle_iterator reg_bundle_end() {\n    return reg_bundle_iterator(nullptr);\n  }\n\n  inline iterator_range<reg_bundle_iterator> reg_bundles(Register Reg) const {\n    return make_range(reg_bundle_begin(Reg), reg_bundle_end());\n  }\n\n  /// reg_empty - Return true if there are no instructions using or defining the\n  /// specified register (it may be live-in).\n  bool reg_empty(Register RegNo) const { return reg_begin(RegNo) == reg_end(); }\n\n  /// reg_nodbg_iterator/reg_nodbg_begin/reg_nodbg_end - Walk all defs and uses\n  /// of the specified register, skipping those marked as Debug.\n  using reg_nodbg_iterator =\n      defusechain_iterator<true, true, true, true, false, false>;\n  reg_nodbg_iterator reg_nodbg_begin(Register RegNo) const {\n    return reg_nodbg_iterator(getRegUseDefListHead(RegNo));\n  }\n  static reg_nodbg_iterator reg_nodbg_end() {\n    return reg_nodbg_iterator(nullptr);\n  }\n\n  inline iterator_range<reg_nodbg_iterator>\n  reg_nodbg_operands(Register Reg) const {\n    return make_range(reg_nodbg_begin(Reg), reg_nodbg_end());\n  }\n\n  /// reg_instr_nodbg_iterator/reg_instr_nodbg_begin/reg_instr_nodbg_end - Walk\n  /// all defs and uses of the specified register, stepping by MachineInstr,\n  /// skipping those marked as Debug.\n  using reg_instr_nodbg_iterator =\n      defusechain_instr_iterator<true, true, true, false, true, false>;\n  reg_instr_nodbg_iterator reg_instr_nodbg_begin(Register RegNo) const {\n    return reg_instr_nodbg_iterator(getRegUseDefListHead(RegNo));\n  }\n  static reg_instr_nodbg_iterator reg_instr_nodbg_end() {\n    return reg_instr_nodbg_iterator(nullptr);\n  }\n\n  inline iterator_range<reg_instr_nodbg_iterator>\n  reg_nodbg_instructions(Register Reg) const {\n    return make_range(reg_instr_nodbg_begin(Reg), reg_instr_nodbg_end());\n  }\n\n  /// reg_bundle_nodbg_iterator/reg_bundle_nodbg_begin/reg_bundle_nodbg_end - Walk\n  /// all defs and uses of the specified register, stepping by bundle,\n  /// skipping those marked as Debug.\n  using reg_bundle_nodbg_iterator =\n      defusechain_instr_iterator<true, true, true, false, false, true>;\n  reg_bundle_nodbg_iterator reg_bundle_nodbg_begin(Register RegNo) const {\n    return reg_bundle_nodbg_iterator(getRegUseDefListHead(RegNo));\n  }\n  static reg_bundle_nodbg_iterator reg_bundle_nodbg_end() {\n    return reg_bundle_nodbg_iterator(nullptr);\n  }\n\n  inline iterator_range<reg_bundle_nodbg_iterator>\n  reg_nodbg_bundles(Register Reg) const {\n    return make_range(reg_bundle_nodbg_begin(Reg), reg_bundle_nodbg_end());\n  }\n\n  /// reg_nodbg_empty - Return true if the only instructions using or defining\n  /// Reg are Debug instructions.\n  bool reg_nodbg_empty(Register RegNo) const {\n    return reg_nodbg_begin(RegNo) == reg_nodbg_end();\n  }\n\n  /// def_iterator/def_begin/def_end - Walk all defs of the specified register.\n  using def_iterator =\n      defusechain_iterator<false, true, false, true, false, false>;\n  def_iterator def_begin(Register RegNo) const {\n    return def_iterator(getRegUseDefListHead(RegNo));\n  }\n  static def_iterator def_end() { return def_iterator(nullptr); }\n\n  inline iterator_range<def_iterator> def_operands(Register Reg) const {\n    return make_range(def_begin(Reg), def_end());\n  }\n\n  /// def_instr_iterator/def_instr_begin/def_instr_end - Walk all defs of the\n  /// specified register, stepping by MachineInst.\n  using def_instr_iterator =\n      defusechain_instr_iterator<false, true, false, false, true, false>;\n  def_instr_iterator def_instr_begin(Register RegNo) const {\n    return def_instr_iterator(getRegUseDefListHead(RegNo));\n  }\n  static def_instr_iterator def_instr_end() {\n"}], "code": "  void initInSeq(const TargetRegisterInfo &TRI) {\n    assert(MBB->getParent()->getRegInfo().tracksLiveness() &&\n           \"Candidate's Machine Function must track liveness\");\n    // Only initialize once.\n    if (InSeqWasSet)\n      return;\n    InSeqWasSet = true;\n    InSeq.init(TRI);\n    for (auto &MI : *this)\n      InSeq.accumulate(MI);\n  }\n"}, "47249762535B6FF1": {"calls": [{"id": "C1AF811D5E8A6E20", "name": "llvm::RegionBase::getEntry", "path": "llvm-project/llvm/include/llvm/Analysis/RegionInfo.h", "start": {"line": 322, "col": 3}, "end": {"line": 324, "col": 3}, "code": "    return RegionNodeBase<Tr>::getEntry();\n  }\n\n  /// Replace the entry basic block of the region with the new basic\n  ///        block.\n  ///\n  /// @param BB  The new entry basic block of the region.\n  void replaceEntry(BlockT *BB);\n\n  /// Replace the exit basic block of the region with the new basic\n  ///        block.\n  ///\n  /// @param BB  The new exit basic block of the region.\n  void replaceExit(BlockT *BB);\n\n  /// Recursively replace the entry basic block of the region.\n  ///\n  /// This function replaces the entry basic block with a new basic block. It\n  /// also updates all child regions that have the same entry basic block as\n  /// this region.\n  ///\n  /// @param NewEntry The new entry basic block.\n  void replaceEntryRecursive(BlockT *NewEntry);\n\n  /// Recursively replace the exit basic block of the region.\n  ///\n  /// This function replaces the exit basic block with a new basic block. It\n  /// also updates all child regions that have the same exit basic block as\n  /// this region.\n  ///\n  /// @param NewExit The new exit basic block.\n  void replaceExitRecursive(BlockT *NewExit);\n\n  /// Get the exit BasicBlock of the Region.\n  /// @return The exit BasicBlock of the Region, NULL if this is the TopLevel\n  ///         Region.\n  BlockT *getExit() const { return exit; }\n\n  /// Get the parent of the Region.\n  /// @return The parent of the Region or NULL if this is a top level\n  ///         Region.\n  RegionT *getParent() const {\n    return RegionNodeBase<Tr>::getParent();\n  }\n\n  /// Get the RegionNode representing the current Region.\n  /// @return The RegionNode representing the current Region.\n  RegionNodeT *getNode() const {\n    return const_cast<RegionNodeT *>(\n        reinterpret_cast<const RegionNodeT *>(this));\n  }\n\n  /// Get the nesting level of this Region.\n  ///\n  /// An toplevel Region has depth 0.\n  ///\n  /// @return The depth of the region.\n  unsigned getDepth() const;\n\n  /// Check if a Region is the TopLevel region.\n  ///\n  /// The toplevel region represents the whole function.\n  bool isTopLevelRegion() const { return exit == nullptr; }\n\n  /// Return a new (non-canonical) region, that is obtained by joining\n  ///        this region with its predecessors.\n  ///\n  /// @return A region also starting at getEntry(), but reaching to the next\n  ///         basic block that forms with getEntry() a (non-canonical) region.\n  ///         NULL if such a basic block does not exist.\n  RegionT *getExpandedRegion() const;\n\n  /// Return the first block of this region's single entry edge,\n  ///        if existing.\n  ///\n  /// @return The BasicBlock starting this region's single entry edge,\n  ///         else NULL.\n  BlockT *getEnteringBlock() const;\n\n  /// Return the first block of this region's single exit edge,\n  ///        if existing.\n  ///\n  /// @return The BasicBlock starting this region's single exit edge,\n  ///         else NULL.\n  BlockT *getExitingBlock() const;\n\n  /// Collect all blocks of this region's single exit edge, if existing.\n  ///\n  /// @return True if this region contains all the predecessors of the exit.\n  bool getExitingBlocks(SmallVectorImpl<BlockT *> &Exitings) const;\n\n  /// Is this a simple region?\n  ///\n  /// A region is simple if it has exactly one exit and one entry edge.\n  ///\n  /// @return True if the Region is simple.\n  bool isSimple() const;\n\n  /// Returns the name of the Region.\n  /// @return The Name of the Region.\n  std::string getNameStr() const;\n\n  /// Return the RegionInfo object, that belongs to this Region.\n  RegionInfoT *getRegionInfo() const { return RI; }\n\n  /// PrintStyle - Print region in difference ways.\n  enum PrintStyle { PrintNone, PrintBB, PrintRN };\n\n  /// Print the region.\n  ///\n  /// @param OS The output stream the Region is printed to.\n  /// @param printTree Print also the tree of subregions.\n  /// @param level The indentation level used for printing.\n  void print(raw_ostream &OS, bool printTree = true, unsigned level = 0,\n             PrintStyle Style = PrintNone) const;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print the region to stderr.\n  void dump() const;\n#endif\n\n  /// Check if the region contains a BasicBlock.\n  ///\n  /// @param BB The BasicBlock that might be contained in this Region.\n  /// @return True if the block is contained in the region otherwise false.\n  bool contains(const BlockT *BB) const;\n\n  /// Check if the region contains another region.\n  ///\n  /// @param SubRegion The region that might be contained in this Region.\n  /// @return True if SubRegion is contained in the region otherwise false.\n  bool contains(const RegionT *SubRegion) const {\n    // Toplevel Region.\n    if (!getExit())\n      return true;\n\n    return contains(SubRegion->getEntry()) &&\n           (contains(SubRegion->getExit()) ||\n            SubRegion->getExit() == getExit());\n  }\n\n  /// Check if the region contains an Instruction.\n  ///\n  /// @param Inst The Instruction that might be contained in this region.\n  /// @return True if the Instruction is contained in the region otherwise\n  /// false.\n  bool contains(const InstT *Inst) const { return contains(Inst->getParent()); }\n\n  /// Check if the region contains a loop.\n  ///\n  /// @param L The loop that might be contained in this region.\n  /// @return True if the loop is contained in the region otherwise false.\n  ///         In case a NULL pointer is passed to this function the result\n  ///         is false, except for the region that describes the whole function.\n  ///         In that case true is returned.\n  bool contains(const LoopT *L) const;\n\n  /// Get the outermost loop in the region that contains a loop.\n  ///\n  /// Find for a Loop L the outermost loop OuterL that is a parent loop of L\n  /// and is itself contained in the region.\n  ///\n  /// @param L The loop the lookup is started.\n  /// @return The outermost loop in the region, NULL if such a loop does not\n  ///         exist or if the region describes the whole function.\n  LoopT *outermostLoopInRegion(LoopT *L) const;\n\n  /// Get the outermost loop in the region that contains a basic block.\n  ///\n  /// Find for a basic block BB the outermost loop L that contains BB and is\n  /// itself contained in the region.\n  ///\n  /// @param LI A pointer to a LoopInfo analysis.\n  /// @param BB The basic block surrounded by the loop.\n  /// @return The outermost loop in the region, NULL if such a loop does not\n  ///         exist or if the region describes the whole function.\n  LoopT *outermostLoopInRegion(LoopInfoT *LI, BlockT *BB) const;\n\n  /// Get the subregion that starts at a BasicBlock\n  ///\n  /// @param BB The BasicBlock the subregion should start.\n  /// @return The Subregion if available, otherwise NULL.\n  RegionT *getSubRegionNode(BlockT *BB) const;\n\n  /// Get the RegionNode for a BasicBlock\n  ///\n  /// @param BB The BasicBlock at which the RegionNode should start.\n  /// @return If available, the RegionNode that represents the subregion\n  ///         starting at BB. If no subregion starts at BB, the RegionNode\n  ///         representing BB.\n  RegionNodeT *getNode(BlockT *BB) const;\n\n  /// Get the BasicBlock RegionNode for a BasicBlock\n  ///\n  /// @param BB The BasicBlock for which the RegionNode is requested.\n  /// @return The RegionNode representing the BB.\n  RegionNodeT *getBBNode(BlockT *BB) const;\n\n  /// Add a new subregion to this Region.\n  ///\n  /// @param SubRegion The new subregion that will be added.\n  /// @param moveChildren Move the children of this region, that are also\n  ///                     contained in SubRegion into SubRegion.\n  void addSubRegion(RegionT *SubRegion, bool moveChildren = false);\n\n  /// Remove a subregion from this Region.\n  ///\n  /// The subregion is not deleted, as it will probably be inserted into another\n  /// region.\n  /// @param SubRegion The SubRegion that will be removed.\n  RegionT *removeSubRegion(RegionT *SubRegion);\n\n  /// Move all direct child nodes of this Region to another Region.\n  ///\n  /// @param To The Region the child nodes will be transferred to.\n  void transferChildrenTo(RegionT *To);\n\n  /// Verify if the region is a correct region.\n  ///\n  /// Check if this is a correctly build Region. This is an expensive check, as\n  /// the complete CFG of the Region will be walked.\n  void verifyRegion() const;\n\n  /// Clear the cache for BB RegionNodes.\n  ///\n  /// After calling this function the BasicBlock RegionNodes will be stored at\n  /// different memory locations. RegionNodes obtained before this function is\n  /// called are therefore not comparable to RegionNodes abtained afterwords.\n  void clearNodeCache();\n\n  /// @name Subregion Iterators\n  ///\n  /// These iterators iterator over all subregions of this Region.\n  //@{\n  using iterator = typename RegionSet::iterator;\n  using const_iterator = typename RegionSet::const_iterator;\n\n  iterator begin() { return children.begin(); }\n  iterator end() { return children.end(); }\n\n  const_iterator begin() const { return children.begin(); }\n  const_iterator end() const { return children.end(); }\n  //@}\n\n  /// @name BasicBlock Iterators\n  ///\n  /// These iterators iterate over all BasicBlocks that are contained in this\n  /// Region. The iterator also iterates over BasicBlocks that are elements of\n  /// a subregion of this Region. It is therefore called a flat iterator.\n  //@{\n  template <bool IsConst>\n  class block_iterator_wrapper\n      : public df_iterator<\n            std::conditional_t<IsConst, const BlockT, BlockT> *> {\n    using super =\n        df_iterator<std::conditional_t<IsConst, const BlockT, BlockT> *>;\n\n  public:\n    using Self = block_iterator_wrapper<IsConst>;\n    using value_type = typename super::value_type;\n\n    // Construct the begin iterator.\n    block_iterator_wrapper(value_type Entry, value_type Exit)\n        : super(df_begin(Entry)) {\n      // Mark the exit of the region as visited, so that the children of the\n      // exit and the exit itself, i.e. the block outside the region will never\n      // be visited.\n      super::Visited.insert(Exit);\n    }\n\n    // Construct the end iterator.\n    block_iterator_wrapper() : super(df_end<value_type>((BlockT *)nullptr)) {}\n\n    /*implicit*/ block_iterator_wrapper(super I) : super(I) {}\n\n    // FIXME: Even a const_iterator returns a non-const BasicBlock pointer.\n    //        This was introduced for backwards compatibility, but should\n    //        be removed as soon as all users are fixed.\n    BlockT *operator*() const {\n      return const_cast<BlockT *>(super::operator*());\n    }\n  };\n\n  using block_iterator = block_iterator_wrapper<false>;\n  using const_block_iterator = block_iterator_wrapper<true>;\n\n  block_iterator block_begin() { return block_iterator(getEntry(), getExit()); }\n\n  block_iterator block_end() { return block_iterator(); }\n\n  const_block_iterator block_begin() const {\n    return const_block_iterator(getEntry(), getExit());\n  }\n  const_block_iterator block_end() const { return const_block_iterator(); }\n\n  using block_range = iterator_range<block_iterator>;\n  using const_block_range = iterator_range<const_block_iterator>;\n\n  /// Returns a range view of the basic blocks in the region.\n  inline block_range blocks() {\n    return block_range(block_begin(), block_end());\n  }\n\n  /// Returns a range view of the basic blocks in the region.\n  ///\n  /// This is the 'const' version of the range view.\n  inline const_block_range blocks() const {\n    return const_block_range(block_begin(), block_end());\n  }\n  //@}\n\n  /// @name Element Iterators\n  ///\n  /// These iterators iterate over all BasicBlock and subregion RegionNodes that\n  /// are direct children of this Region. It does not iterate over any\n  /// RegionNodes that are also element of a subregion of this Region.\n  //@{\n  using element_iterator =\n      df_iterator<RegionNodeT *, df_iterator_default_set<RegionNodeT *>, false,\n                  GraphTraits<RegionNodeT *>>;\n\n  using const_element_iterator =\n      df_iterator<const RegionNodeT *,\n                  df_iterator_default_set<const RegionNodeT *>, false,\n                  GraphTraits<const RegionNodeT *>>;\n"}], "code": "template <class Tr>\ntypename RegionBase<Tr>::BlockT *RegionBase<Tr>::getEnteringBlock() const {\n  auto isEnteringBlock = [&](BlockT *Pred, bool AllowRepeats) -> BlockT * {\n    assert(!AllowRepeats && \"Unexpected parameter value.\");\n    return DT->getNode(Pred) && !contains(Pred) ? Pred : nullptr;\n  };\n  return find_singleton<BlockT>(llvm::inverse_children<BlockT *>(getEntry()),\n                                isEnteringBlock);\n}\n"}, "57A29FD53DCA2606": {"calls": [{"id": "20E2E09173F8338D", "name": "llvm::SMEAttrs::hasStreamingCompatibleInterface", "path": "llvm-project/llvm/lib/Target/AArch64/Utils/AArch64SMEAttributes.h", "start": {"line": 65, "col": 3}, "end": {"line": 67, "col": 3}, "code": "    return Bitmask & SM_Compatible;\n  }\n  bool hasNonStreamingInterface() const {\n    return !hasStreamingInterface() && !hasStreamingCompatibleInterface();\n  }\n  bool hasNonStreamingInterfaceAndBody() const {\n    return hasNonStreamingInterface() && !hasStreamingBody();\n  }\n\n  /// \\return true if a call from Caller -> Callee requires a change in\n  /// streaming mode.\n  bool requiresSMChange(const SMEAttrs &Callee) const;\n\n  // Interfaces to query ZA\n  static StateValue decodeZAState(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZA_Mask) >> ZA_Shift);\n  }\n  static unsigned encodeZAState(StateValue S) {\n    return static_cast<unsigned>(S) << ZA_Shift;\n  }\n\n  bool isNewZA() const { return decodeZAState(Bitmask) == StateValue::New; }\n  bool isInZA() const { return decodeZAState(Bitmask) == StateValue::In; }\n  bool isOutZA() const { return decodeZAState(Bitmask) == StateValue::Out; }\n  bool isInOutZA() const { return decodeZAState(Bitmask) == StateValue::InOut; }\n  bool isPreservesZA() const {\n    return decodeZAState(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZA() const {\n    StateValue State = decodeZAState(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasSharedZAInterface() const { return sharesZA() || sharesZT0(); }\n  bool hasPrivateZAInterface() const { return !hasSharedZAInterface(); }\n  bool hasZAState() const { return isNewZA() || sharesZA(); }\n  bool requiresLazySave(const SMEAttrs &Callee) const {\n    return hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n\n  // Interfaces to query ZT0 State\n  static StateValue decodeZT0State(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZT0_Mask) >> ZT0_Shift);\n  }\n  static unsigned encodeZT0State(StateValue S) {\n    return static_cast<unsigned>(S) << ZT0_Shift;\n  }\n\n  bool isNewZT0() const { return decodeZT0State(Bitmask) == StateValue::New; }\n  bool isInZT0() const { return decodeZT0State(Bitmask) == StateValue::In; }\n  bool isOutZT0() const { return decodeZT0State(Bitmask) == StateValue::Out; }\n  bool isInOutZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::InOut;\n  }\n  bool isPreservesZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZT0() const {\n    StateValue State = decodeZT0State(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasZT0State() const { return isNewZT0() || sharesZT0(); }\n  bool requiresPreservingZT0(const SMEAttrs &Callee) const {\n    return hasZT0State() && !Callee.sharesZT0();\n  }\n  bool requiresDisablingZABeforeCall(const SMEAttrs &Callee) const {\n"}, {"id": "0E37DCF751156CC2", "name": "llvm::SMEAttrs::hasNonStreamingInterfaceAndBody", "path": "llvm-project/llvm/lib/Target/AArch64/Utils/AArch64SMEAttributes.h", "start": {"line": 71, "col": 3}, "end": {"line": 73, "col": 3}, "code": "    return hasNonStreamingInterface() && !hasStreamingBody();\n  }\n\n  /// \\return true if a call from Caller -> Callee requires a change in\n  /// streaming mode.\n  bool requiresSMChange(const SMEAttrs &Callee) const;\n\n  // Interfaces to query ZA\n  static StateValue decodeZAState(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZA_Mask) >> ZA_Shift);\n  }\n  static unsigned encodeZAState(StateValue S) {\n    return static_cast<unsigned>(S) << ZA_Shift;\n  }\n\n  bool isNewZA() const { return decodeZAState(Bitmask) == StateValue::New; }\n  bool isInZA() const { return decodeZAState(Bitmask) == StateValue::In; }\n  bool isOutZA() const { return decodeZAState(Bitmask) == StateValue::Out; }\n  bool isInOutZA() const { return decodeZAState(Bitmask) == StateValue::InOut; }\n  bool isPreservesZA() const {\n    return decodeZAState(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZA() const {\n    StateValue State = decodeZAState(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasSharedZAInterface() const { return sharesZA() || sharesZT0(); }\n  bool hasPrivateZAInterface() const { return !hasSharedZAInterface(); }\n  bool hasZAState() const { return isNewZA() || sharesZA(); }\n  bool requiresLazySave(const SMEAttrs &Callee) const {\n    return hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n\n  // Interfaces to query ZT0 State\n  static StateValue decodeZT0State(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZT0_Mask) >> ZT0_Shift);\n  }\n  static unsigned encodeZT0State(StateValue S) {\n    return static_cast<unsigned>(S) << ZT0_Shift;\n  }\n\n  bool isNewZT0() const { return decodeZT0State(Bitmask) == StateValue::New; }\n  bool isInZT0() const { return decodeZT0State(Bitmask) == StateValue::In; }\n  bool isOutZT0() const { return decodeZT0State(Bitmask) == StateValue::Out; }\n  bool isInOutZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::InOut;\n  }\n  bool isPreservesZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZT0() const {\n    StateValue State = decodeZT0State(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasZT0State() const { return isNewZT0() || sharesZT0(); }\n  bool requiresPreservingZT0(const SMEAttrs &Callee) const {\n    return hasZT0State() && !Callee.sharesZT0();\n  }\n  bool requiresDisablingZABeforeCall(const SMEAttrs &Callee) const {\n    return hasZT0State() && !hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n  bool requiresEnablingZAAfterCall(const SMEAttrs &Callee) const {\n    return requiresLazySave(Callee) || requiresDisablingZABeforeCall(Callee);\n  }\n};\n\n} // namespace llvm\n\n#endif // LLVM_LIB_TARGET_AARCH64_UTILS_AARCH64SMEATTRIBUTES_H\n"}, {"id": "08CB8A9D3A1D041A", "name": "llvm::SMEAttrs::hasNonStreamingInterface", "path": "llvm-project/llvm/lib/Target/AArch64/Utils/AArch64SMEAttributes.h", "start": {"line": 68, "col": 3}, "end": {"line": 70, "col": 3}, "code": "    return !hasStreamingInterface() && !hasStreamingCompatibleInterface();\n  }\n  bool hasNonStreamingInterfaceAndBody() const {\n    return hasNonStreamingInterface() && !hasStreamingBody();\n  }\n\n  /// \\return true if a call from Caller -> Callee requires a change in\n  /// streaming mode.\n  bool requiresSMChange(const SMEAttrs &Callee) const;\n\n  // Interfaces to query ZA\n  static StateValue decodeZAState(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZA_Mask) >> ZA_Shift);\n  }\n  static unsigned encodeZAState(StateValue S) {\n    return static_cast<unsigned>(S) << ZA_Shift;\n  }\n\n  bool isNewZA() const { return decodeZAState(Bitmask) == StateValue::New; }\n  bool isInZA() const { return decodeZAState(Bitmask) == StateValue::In; }\n  bool isOutZA() const { return decodeZAState(Bitmask) == StateValue::Out; }\n  bool isInOutZA() const { return decodeZAState(Bitmask) == StateValue::InOut; }\n  bool isPreservesZA() const {\n    return decodeZAState(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZA() const {\n    StateValue State = decodeZAState(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasSharedZAInterface() const { return sharesZA() || sharesZT0(); }\n  bool hasPrivateZAInterface() const { return !hasSharedZAInterface(); }\n  bool hasZAState() const { return isNewZA() || sharesZA(); }\n  bool requiresLazySave(const SMEAttrs &Callee) const {\n    return hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n\n  // Interfaces to query ZT0 State\n  static StateValue decodeZT0State(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZT0_Mask) >> ZT0_Shift);\n  }\n  static unsigned encodeZT0State(StateValue S) {\n    return static_cast<unsigned>(S) << ZT0_Shift;\n  }\n\n  bool isNewZT0() const { return decodeZT0State(Bitmask) == StateValue::New; }\n  bool isInZT0() const { return decodeZT0State(Bitmask) == StateValue::In; }\n  bool isOutZT0() const { return decodeZT0State(Bitmask) == StateValue::Out; }\n  bool isInOutZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::InOut;\n  }\n  bool isPreservesZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZT0() const {\n    StateValue State = decodeZT0State(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasZT0State() const { return isNewZT0() || sharesZT0(); }\n  bool requiresPreservingZT0(const SMEAttrs &Callee) const {\n    return hasZT0State() && !Callee.sharesZT0();\n  }\n  bool requiresDisablingZABeforeCall(const SMEAttrs &Callee) const {\n    return hasZT0State() && !hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n  bool requiresEnablingZAAfterCall(const SMEAttrs &Callee) const {\n    return requiresLazySave(Callee) || requiresDisablingZABeforeCall(Callee);\n  }\n"}, {"id": "50558008AFB1DE2D", "name": "llvm::SMEAttrs::hasStreamingInterfaceOrBody", "path": "llvm-project/llvm/lib/Target/AArch64/Utils/AArch64SMEAttributes.h", "start": {"line": 62, "col": 3}, "end": {"line": 64, "col": 3}, "code": "    return hasStreamingBody() || hasStreamingInterface();\n  }\n  bool hasStreamingCompatibleInterface() const {\n    return Bitmask & SM_Compatible;\n  }\n  bool hasNonStreamingInterface() const {\n    return !hasStreamingInterface() && !hasStreamingCompatibleInterface();\n  }\n  bool hasNonStreamingInterfaceAndBody() const {\n    return hasNonStreamingInterface() && !hasStreamingBody();\n  }\n\n  /// \\return true if a call from Caller -> Callee requires a change in\n  /// streaming mode.\n  bool requiresSMChange(const SMEAttrs &Callee) const;\n\n  // Interfaces to query ZA\n  static StateValue decodeZAState(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZA_Mask) >> ZA_Shift);\n  }\n  static unsigned encodeZAState(StateValue S) {\n    return static_cast<unsigned>(S) << ZA_Shift;\n  }\n\n  bool isNewZA() const { return decodeZAState(Bitmask) == StateValue::New; }\n  bool isInZA() const { return decodeZAState(Bitmask) == StateValue::In; }\n  bool isOutZA() const { return decodeZAState(Bitmask) == StateValue::Out; }\n  bool isInOutZA() const { return decodeZAState(Bitmask) == StateValue::InOut; }\n  bool isPreservesZA() const {\n    return decodeZAState(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZA() const {\n    StateValue State = decodeZAState(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasSharedZAInterface() const { return sharesZA() || sharesZT0(); }\n  bool hasPrivateZAInterface() const { return !hasSharedZAInterface(); }\n  bool hasZAState() const { return isNewZA() || sharesZA(); }\n  bool requiresLazySave(const SMEAttrs &Callee) const {\n    return hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n\n  // Interfaces to query ZT0 State\n  static StateValue decodeZT0State(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZT0_Mask) >> ZT0_Shift);\n  }\n  static unsigned encodeZT0State(StateValue S) {\n    return static_cast<unsigned>(S) << ZT0_Shift;\n  }\n\n  bool isNewZT0() const { return decodeZT0State(Bitmask) == StateValue::New; }\n  bool isInZT0() const { return decodeZT0State(Bitmask) == StateValue::In; }\n  bool isOutZT0() const { return decodeZT0State(Bitmask) == StateValue::Out; }\n  bool isInOutZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::InOut;\n  }\n  bool isPreservesZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZT0() const {\n    StateValue State = decodeZT0State(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n"}, {"id": "B801AA7C709C316D", "name": "llvm::SMEAttrs::hasStreamingInterface", "path": "llvm-project/llvm/lib/Target/AArch64/Utils/AArch64SMEAttributes.h", "start": {"line": 61, "col": 3}, "end": {"line": 61, "col": 69}, "code": "  bool hasStreamingInterfaceOrBody() const {\n    return hasStreamingBody() || hasStreamingInterface();\n  }\n  bool hasStreamingCompatibleInterface() const {\n    return Bitmask & SM_Compatible;\n  }\n  bool hasNonStreamingInterface() const {\n    return !hasStreamingInterface() && !hasStreamingCompatibleInterface();\n  }\n  bool hasNonStreamingInterfaceAndBody() const {\n    return hasNonStreamingInterface() && !hasStreamingBody();\n  }\n\n  /// \\return true if a call from Caller -> Callee requires a change in\n  /// streaming mode.\n  bool requiresSMChange(const SMEAttrs &Callee) const;\n\n  // Interfaces to query ZA\n  static StateValue decodeZAState(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZA_Mask) >> ZA_Shift);\n  }\n  static unsigned encodeZAState(StateValue S) {\n    return static_cast<unsigned>(S) << ZA_Shift;\n  }\n\n  bool isNewZA() const { return decodeZAState(Bitmask) == StateValue::New; }\n  bool isInZA() const { return decodeZAState(Bitmask) == StateValue::In; }\n  bool isOutZA() const { return decodeZAState(Bitmask) == StateValue::Out; }\n  bool isInOutZA() const { return decodeZAState(Bitmask) == StateValue::InOut; }\n  bool isPreservesZA() const {\n    return decodeZAState(Bitmask) == StateValue::Preserved;\n  }\n  bool sharesZA() const {\n    StateValue State = decodeZAState(Bitmask);\n    return State == StateValue::In || State == StateValue::Out ||\n           State == StateValue::InOut || State == StateValue::Preserved;\n  }\n  bool hasSharedZAInterface() const { return sharesZA() || sharesZT0(); }\n  bool hasPrivateZAInterface() const { return !hasSharedZAInterface(); }\n  bool hasZAState() const { return isNewZA() || sharesZA(); }\n  bool requiresLazySave(const SMEAttrs &Callee) const {\n    return hasZAState() && Callee.hasPrivateZAInterface() &&\n           !(Callee.Bitmask & SME_ABI_Routine);\n  }\n\n  // Interfaces to query ZT0 State\n  static StateValue decodeZT0State(unsigned Bitmask) {\n    return static_cast<StateValue>((Bitmask & ZT0_Mask) >> ZT0_Shift);\n  }\n  static unsigned encodeZT0State(StateValue S) {\n    return static_cast<unsigned>(S) << ZT0_Shift;\n  }\n\n  bool isNewZT0() const { return decodeZT0State(Bitmask) == StateValue::New; }\n  bool isInZT0() const { return decodeZT0State(Bitmask) == StateValue::In; }\n  bool isOutZT0() const { return decodeZT0State(Bitmask) == StateValue::Out; }\n  bool isInOutZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::InOut;\n  }\n  bool isPreservesZT0() const {\n    return decodeZT0State(Bitmask) == StateValue::Preserved;\n  }\n"}], "code": "bool SMEAttrs::requiresSMChange(const SMEAttrs &Callee) const {\n  if (Callee.hasStreamingCompatibleInterface())\n    return false;\n\n  // Both non-streaming\n  if (hasNonStreamingInterfaceAndBody() && Callee.hasNonStreamingInterface())\n    return false;\n\n  // Both streaming\n  if (hasStreamingInterfaceOrBody() && Callee.hasStreamingInterface())\n    return false;\n\n  return true;\n}\n"}, "081EA200BE41D4AA": {"calls": [{"id": "241D9514E43F3BC9", "name": "llvm::TargetPassConfig::getOptLevel", "path": "llvm-project/llvm/lib/CodeGen/TargetPassConfig.cpp", "start": {"line": 599, "col": 1}, "end": {"line": 601, "col": 1}, "code": "  return TM->getOptLevel();\n}\n\n/// Insert InsertedPassID pass after TargetPassID.\nvoid TargetPassConfig::insertPass(AnalysisID TargetPassID,\n                                  IdentifyingPassPtr InsertedPassID) {\n  assert(((!InsertedPassID.isInstance() &&\n           TargetPassID != InsertedPassID.getID()) ||\n          (InsertedPassID.isInstance() &&\n           TargetPassID != InsertedPassID.getInstance()->getPassID())) &&\n         \"Insert a pass after itself!\");\n  Impl->InsertedPasses.emplace_back(TargetPassID, InsertedPassID);\n}\n\n/// createPassConfig - Create a pass configuration object to be used by\n/// addPassToEmitX methods for generating a pipeline of CodeGen passes.\n///\n/// Targets may override this to extend TargetPassConfig.\nTargetPassConfig *LLVMTargetMachine::createPassConfig(PassManagerBase &PM) {\n  return new TargetPassConfig(*this, PM);\n}\n\nTargetPassConfig::TargetPassConfig()\n  : ImmutablePass(ID) {\n  report_fatal_error(\"Trying to construct TargetPassConfig without a target \"\n                     \"machine. Scheduling a CodeGen pass without a target \"\n                     \"triple set?\");\n}\n\nbool TargetPassConfig::willCompleteCodeGenPipeline() {\n  return StopBeforeOpt.empty() && StopAfterOpt.empty();\n}\n\nbool TargetPassConfig::hasLimitedCodeGenPipeline() {\n  return !StartBeforeOpt.empty() || !StartAfterOpt.empty() ||\n         !willCompleteCodeGenPipeline();\n}\n\nstd::string TargetPassConfig::getLimitedCodeGenPipelineReason() {\n  if (!hasLimitedCodeGenPipeline())\n    return std::string();\n  std::string Res;\n  static cl::opt<std::string> *PassNames[] = {&StartAfterOpt, &StartBeforeOpt,\n                                              &StopAfterOpt, &StopBeforeOpt};\n  static const char *OptNames[] = {StartAfterOptName, StartBeforeOptName,\n                                   StopAfterOptName, StopBeforeOptName};\n  bool IsFirst = true;\n  for (int Idx = 0; Idx < 4; ++Idx)\n    if (!PassNames[Idx]->empty()) {\n      if (!IsFirst)\n        Res += \" and \";\n      IsFirst = false;\n      Res += OptNames[Idx];\n    }\n  return Res;\n}\n\n// Helper to verify the analysis is really immutable.\nvoid TargetPassConfig::setOpt(bool &Opt, bool Val) {\n  assert(!Initialized && \"PassConfig is immutable\");\n  Opt = Val;\n}\n\nvoid TargetPassConfig::substitutePass(AnalysisID StandardID,\n                                      IdentifyingPassPtr TargetID) {\n  Impl->TargetPasses[StandardID] = TargetID;\n}\n\nIdentifyingPassPtr TargetPassConfig::getPassSubstitution(AnalysisID ID) const {\n  DenseMap<AnalysisID, IdentifyingPassPtr>::const_iterator\n    I = Impl->TargetPasses.find(ID);\n  if (I == Impl->TargetPasses.end())\n    return ID;\n  return I->second;\n}\n\nbool TargetPassConfig::isPassSubstitutedOrOverridden(AnalysisID ID) const {\n  IdentifyingPassPtr TargetID = getPassSubstitution(ID);\n  IdentifyingPassPtr FinalPtr = overridePass(ID, TargetID);\n  return !FinalPtr.isValid() || FinalPtr.isInstance() ||\n      FinalPtr.getID() != ID;\n}\n\n/// Add a pass to the PassManager if that pass is supposed to be run.  If the\n/// Started/Stopped flags indicate either that the compilation should start at\n/// a later pass or that it should stop after an earlier pass, then do not add\n/// the pass.  Finally, compare the current pass against the StartAfter\n/// and StopAfter options and change the Started/Stopped flags accordingly.\nvoid TargetPassConfig::addPass(Pass *P) {\n  assert(!Initialized && \"PassConfig is immutable\");\n\n  // Cache the Pass ID here in case the pass manager finds this pass is\n  // redundant with ones already scheduled / available, and deletes it.\n  // Fundamentally, once we add the pass to the manager, we no longer own it\n  // and shouldn't reference it.\n  AnalysisID PassID = P->getPassID();\n\n  if (StartBefore == PassID && StartBeforeCount++ == StartBeforeInstanceNum)\n    Started = true;\n  if (StopBefore == PassID && StopBeforeCount++ == StopBeforeInstanceNum)\n    Stopped = true;\n  if (Started && !Stopped) {\n    if (AddingMachinePasses) {\n      // Construct banner message before PM->add() as that may delete the pass.\n      std::string Banner =\n          std::string(\"After \") + std::string(P->getPassName());\n      addMachinePrePasses();\n      PM->add(P);\n      addMachinePostPasses(Banner);\n    } else {\n      PM->add(P);\n    }\n\n    // Add the passes after the pass P if there is any.\n    for (const auto &IP : Impl->InsertedPasses)\n      if (IP.TargetPassID == PassID)\n        addPass(IP.getInsertedPass());\n  } else {\n    delete P;\n  }\n\n  if (StopAfter == PassID && StopAfterCount++ == StopAfterInstanceNum)\n    Stopped = true;\n\n  if (StartAfter == PassID && StartAfterCount++ == StartAfterInstanceNum)\n    Started = true;\n  if (Stopped && !Started)\n    report_fatal_error(\"Cannot stop compilation after pass that is not run\");\n}\n\n/// Add a CodeGen pass at this point in the pipeline after checking for target\n/// and command line overrides.\n///\n/// addPass cannot return a pointer to the pass instance because is internal the\n/// PassManager and the instance we create here may already be freed.\nAnalysisID TargetPassConfig::addPass(AnalysisID PassID) {\n  IdentifyingPassPtr TargetID = getPassSubstitution(PassID);\n  IdentifyingPassPtr FinalPtr = overridePass(PassID, TargetID);\n  if (!FinalPtr.isValid())\n    return nullptr;\n\n  Pass *P;\n  if (FinalPtr.isInstance())\n    P = FinalPtr.getInstance();\n  else {\n    P = Pass::createPass(FinalPtr.getID());\n    if (!P)\n      llvm_unreachable(\"Pass ID not registered\");\n  }\n  AnalysisID FinalID = P->getPassID();\n  addPass(P); // Ends the lifetime of P.\n\n  return FinalID;\n}\n\nvoid TargetPassConfig::printAndVerify(const std::string &Banner) {\n  addPrintPass(Banner);\n  addVerifyPass(Banner);\n}\n\nvoid TargetPassConfig::addPrintPass(const std::string &Banner) {\n  if (PrintAfterISel)\n    PM->add(createMachineFunctionPrinterPass(dbgs(), Banner));\n}\n\nvoid TargetPassConfig::addVerifyPass(const std::string &Banner) {\n  bool Verify = VerifyMachineCode == cl::BOU_TRUE;\n#ifdef EXPENSIVE_CHECKS\n  if (VerifyMachineCode == cl::BOU_UNSET)\n    Verify = TM->isMachineVerifierClean();\n#endif\n  if (Verify)\n    PM->add(createMachineVerifierPass(Banner));\n}\n\nvoid TargetPassConfig::addDebugifyPass() {\n  PM->add(createDebugifyMachineModulePass());\n}\n\nvoid TargetPassConfig::addStripDebugPass() {\n  PM->add(createStripDebugMachineModulePass(/*OnlyDebugified=*/true));\n}\n\nvoid TargetPassConfig::addCheckDebugPass() {\n  PM->add(createCheckDebugMachineModulePass());\n}\n\nvoid TargetPassConfig::addMachinePrePasses(bool AllowDebugify) {\n  if (AllowDebugify && DebugifyIsSafe &&\n      (DebugifyAndStripAll == cl::BOU_TRUE ||\n       DebugifyCheckAndStripAll == cl::BOU_TRUE))\n    addDebugifyPass();\n}\n\nvoid TargetPassConfig::addMachinePostPasses(const std::string &Banner) {\n  if (DebugifyIsSafe) {\n    if (DebugifyCheckAndStripAll == cl::BOU_TRUE) {\n      addCheckDebugPass();\n      addStripDebugPass();\n    } else if (DebugifyAndStripAll == cl::BOU_TRUE)\n      addStripDebugPass();\n  }\n  addVerifyPass(Banner);\n}\n\n/// Add common target configurable passes that perform LLVM IR to IR transforms\n/// following machine independent optimization.\nvoid TargetPassConfig::addIRPasses() {\n  // Before running any passes, run the verifier to determine if the input\n  // coming from the front-end and/or optimizer is valid.\n  if (!DisableVerify)\n    addPass(createVerifierPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None) {\n    // Basic AliasAnalysis support.\n    // Add TypeBasedAliasAnalysis before BasicAliasAnalysis so that\n    // BasicAliasAnalysis wins if they disagree. This is intended to help\n    // support \"obvious\" type-punning idioms.\n    addPass(createTypeBasedAAWrapperPass());\n    addPass(createScopedNoAliasAAWrapperPass());\n    addPass(createBasicAAWrapperPass());\n\n    // Run loop strength reduction before anything else.\n    if (!DisableLSR) {\n      addPass(createCanonicalizeFreezeInLoopsPass());\n      addPass(createLoopStrengthReducePass());\n      if (PrintLSR)\n        addPass(createPrintFunctionPass(dbgs(),\n                                        \"\\n\\n*** Code after LSR ***\\n\"));\n    }\n\n    // The MergeICmpsPass tries to create memcmp calls by grouping sequences of\n    // loads and compares. ExpandMemCmpPass then tries to expand those calls\n    // into optimally-sized loads and compares. The transforms are enabled by a\n    // target lowering hook.\n    if (!DisableMergeICmps)\n      addPass(createMergeICmpsLegacyPass());\n    addPass(createExpandMemCmpLegacyPass());\n  }\n\n  // Run GC lowering passes for builtin collectors\n  // TODO: add a pass insertion point here\n  addPass(&GCLoweringID);\n  addPass(&ShadowStackGCLoweringID);\n  addPass(createLowerConstantIntrinsicsPass());\n\n  // For MachO, lower @llvm.global_dtors into @llvm.global_ctors with\n  // __cxa_atexit() calls to avoid emitting the deprecated __mod_term_func.\n  if (TM->getTargetTriple().isOSBinFormatMachO() &&\n      !DisableAtExitBasedGlobalDtorLowering)\n    addPass(createLowerGlobalDtorsLegacyPass());\n\n  // Make sure that no unreachable blocks are instruction selected.\n  addPass(createUnreachableBlockEliminationPass());\n\n  // Prepare expensive constants for SelectionDAG.\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableConstantHoisting)\n    addPass(createConstantHoistingPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None)\n    addPass(createReplaceWithVeclibLegacyPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None && !DisablePartialLibcallInlining)\n    addPass(createPartiallyInlineLibCallsPass());\n\n  // Expand vector predication intrinsics into standard IR instructions.\n  // This pass has to run before ScalarizeMaskedMemIntrin and ExpandReduction\n  // passes since it emits those kinds of intrinsics.\n  addPass(createExpandVectorPredicationPass());\n\n  // Add scalarization of target's unsupported masked memory intrinsics pass.\n  // the unsupported intrinsic will be replaced with a chain of basic blocks,\n  // that stores/loads element one-by-one if the appropriate mask bit is set.\n  addPass(createScalarizeMaskedMemIntrinLegacyPass());\n\n  // Expand reduction intrinsics into shuffle sequences if the target wants to.\n  // Allow disabling it for testing purposes.\n  if (!DisableExpandReductions)\n    addPass(createExpandReductionsPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None)\n    addPass(createTLSVariableHoistPass());\n\n  // Convert conditional moves to conditional jumps when profitable.\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableSelectOptimize)\n    addPass(createSelectOptimizePass());\n}\n\n/// Turn exception handling constructs into something the code generators can\n/// handle.\nvoid TargetPassConfig::addPassesToHandleExceptions() {\n  const MCAsmInfo *MCAI = TM->getMCAsmInfo();\n  assert(MCAI && \"No MCAsmInfo\");\n  switch (MCAI->getExceptionHandlingType()) {\n  case ExceptionHandling::SjLj:\n    // SjLj piggy-backs on dwarf for this bit. The cleanups done apply to both\n    // Dwarf EH prepare needs to be run after SjLj prepare. Otherwise,\n    // catch info can get misplaced when a selector ends up more than one block\n    // removed from the parent invoke(s). This could happen when a landing\n    // pad is shared by multiple invokes and is also a target of a normal\n    // edge from elsewhere.\n    addPass(createSjLjEHPreparePass(TM));\n    [[fallthrough]];\n  case ExceptionHandling::DwarfCFI:\n  case ExceptionHandling::ARM:\n  case ExceptionHandling::AIX:\n  case ExceptionHandling::ZOS:\n    addPass(createDwarfEHPass(getOptLevel()));\n    break;\n  case ExceptionHandling::WinEH:\n    // We support using both GCC-style and MSVC-style exceptions on Windows, so\n    // add both preparation passes. Each pass will only actually run if it\n    // recognizes the personality function.\n    addPass(createWinEHPass());\n    addPass(createDwarfEHPass(getOptLevel()));\n    break;\n  case ExceptionHandling::Wasm:\n    // Wasm EH uses Windows EH instructions, but it does not need to demote PHIs\n    // on catchpads and cleanuppads because it does not outline them into\n    // funclets. Catchswitch blocks are not lowered in SelectionDAG, so we\n    // should remove PHIs there.\n    addPass(createWinEHPass(/*DemoteCatchSwitchPHIOnly=*/false));\n    addPass(createWasmEHPass());\n    break;\n  case ExceptionHandling::None:\n    addPass(createLowerInvokePass());\n\n    // The lower invoke pass may create unreachable code. Remove it.\n    addPass(createUnreachableBlockEliminationPass());\n    break;\n  }\n}\n\n/// Add pass to prepare the LLVM IR for code generation. This should be done\n/// before exception handling preparation passes.\nvoid TargetPassConfig::addCodeGenPrepare() {\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableCGP)\n    addPass(createCodeGenPrepareLegacyPass());\n}\n\n/// Add common passes that perform LLVM IR to IR transforms in preparation for\n/// instruction selection.\nvoid TargetPassConfig::addISelPrepare() {\n  addPreISel();\n\n  // Force codegen to run according to the callgraph.\n  if (requiresCodeGenSCCOrder())\n    addPass(new DummyCGSCCPass);\n\n  addPass(createCallBrPass());\n\n  // Add both the safe stack and the stack protection passes: each of them will\n  // only protect functions that have corresponding attributes.\n  addPass(createSafeStackPass());\n  addPass(createStackProtectorPass());\n\n  if (PrintISelInput)\n    addPass(createPrintFunctionPass(\n        dbgs(), \"\\n\\n*** Final LLVM Code input to ISel ***\\n\"));\n\n  // All passes which modify the LLVM IR are now complete; run the verifier\n  // to ensure that the IR is valid.\n  if (!DisableVerify)\n    addPass(createVerifierPass());\n}\n\nbool TargetPassConfig::addCoreISelPasses() {\n  // Enable FastISel with -fast-isel, but allow that to be overridden.\n  TM->setO0WantsFastISel(EnableFastISelOption != cl::BOU_FALSE);\n\n  // Determine an instruction selector.\n  enum class SelectorType { SelectionDAG, FastISel, GlobalISel };\n  SelectorType Selector;\n\n  if (EnableFastISelOption == cl::BOU_TRUE)\n    Selector = SelectorType::FastISel;\n  else if (EnableGlobalISelOption == cl::BOU_TRUE ||\n           (TM->Options.EnableGlobalISel &&\n            EnableGlobalISelOption != cl::BOU_FALSE))\n    Selector = SelectorType::GlobalISel;\n  else if (TM->getOptLevel() == CodeGenOptLevel::None &&\n           TM->getO0WantsFastISel())\n    Selector = SelectorType::FastISel;\n  else\n    Selector = SelectorType::SelectionDAG;\n\n  // Set consistently TM->Options.EnableFastISel and EnableGlobalISel.\n  if (Selector == SelectorType::FastISel) {\n    TM->setFastISel(true);\n    TM->setGlobalISel(false);\n  } else if (Selector == SelectorType::GlobalISel) {\n    TM->setFastISel(false);\n    TM->setGlobalISel(true);\n  }\n\n  // FIXME: Injecting into the DAGISel pipeline seems to cause issues with\n  //        analyses needing to be re-run. This can result in being unable to\n  //        schedule passes (particularly with 'Function Alias Analysis\n  //        Results'). It's not entirely clear why but AFAICT this seems to be\n  //        due to one FunctionPassManager not being able to use analyses from a\n  //        previous one. As we're injecting a ModulePass we break the usual\n  //        pass manager into two. GlobalISel with the fallback path disabled\n  //        and -run-pass seem to be unaffected. The majority of GlobalISel\n  //        testing uses -run-pass so this probably isn't too bad.\n  SaveAndRestore SavedDebugifyIsSafe(DebugifyIsSafe);\n  if (Selector != SelectorType::GlobalISel || !isGlobalISelAbortEnabled())\n    DebugifyIsSafe = false;\n\n  // Add instruction selector passes.\n  if (Selector == SelectorType::GlobalISel) {\n    SaveAndRestore SavedAddingMachinePasses(AddingMachinePasses, true);\n    if (addIRTranslator())\n      return true;\n\n    addPreLegalizeMachineIR();\n\n    if (addLegalizeMachineIR())\n      return true;\n\n    // Before running the register bank selector, ask the target if it\n    // wants to run some passes.\n    addPreRegBankSelect();\n\n    if (addRegBankSelect())\n      return true;\n\n    addPreGlobalInstructionSelect();\n\n    if (addGlobalInstructionSelect())\n      return true;\n\n    // Pass to reset the MachineFunction if the ISel failed.\n    addPass(createResetMachineFunctionPass(\n        reportDiagnosticWhenGlobalISelFallback(), isGlobalISelAbortEnabled()));\n\n    // Provide a fallback path when we do not want to abort on\n    // not-yet-supported input.\n    if (!isGlobalISelAbortEnabled() && addInstSelector())\n      return true;\n\n  } else if (addInstSelector())\n    return true;\n\n  // Expand pseudo-instructions emitted by ISel. Don't run the verifier before\n  // FinalizeISel.\n  addPass(&FinalizeISelID);\n\n  // Print the instruction selected machine code...\n  printAndVerify(\"After Instruction Selection\");\n\n  return false;\n}\n\nbool TargetPassConfig::addISelPasses() {\n  if (TM->useEmulatedTLS())\n    addPass(createLowerEmuTLSPass());\n\n  PM->add(createTargetTransformInfoWrapperPass(TM->getTargetIRAnalysis()));\n  addPass(createPreISelIntrinsicLoweringPass());\n  addPass(createExpandLargeDivRemPass());\n  addPass(createExpandLargeFpConvertPass());\n  addIRPasses();\n  addCodeGenPrepare();\n  addPassesToHandleExceptions();\n  addISelPrepare();\n\n  return addCoreISelPasses();\n}\n\n/// -regalloc=... command line option.\nstatic FunctionPass *useDefaultRegisterAllocator() { return nullptr; }\nstatic cl::opt<RegisterRegAlloc::FunctionPassCtor, false,\n               RegisterPassParser<RegisterRegAlloc>>\n    RegAlloc(\"regalloc\", cl::Hidden, cl::init(&useDefaultRegisterAllocator),\n             cl::desc(\"Register allocator to use\"));\n\n/// Add the complete set of target-independent postISel code generator passes.\n///\n/// This can be read as the standard order of major LLVM CodeGen stages. Stages\n/// with nontrivial configuration or multiple passes are broken out below in\n/// add%Stage routines.\n///\n/// Any TargetPassConfig::addXX routine may be overriden by the Target. The\n/// addPre/Post methods with empty header implementations allow injecting\n/// target-specific fixups just before or after major stages. Additionally,\n/// targets have the flexibility to change pass order within a stage by\n/// overriding default implementation of add%Stage routines below. Each\n/// technique has maintainability tradeoffs because alternate pass orders are\n/// not well supported. addPre/Post works better if the target pass is easily\n/// tied to a common pass. But if it has subtle dependencies on multiple passes,\n/// the target should override the stage instead.\n///\n/// TODO: We could use a single addPre/Post(ID) hook to allow pass injection\n/// before/after any target-independent pass. But it's currently overkill.\nvoid TargetPassConfig::addMachinePasses() {\n  AddingMachinePasses = true;\n\n  // Add passes that optimize machine instructions in SSA form.\n  if (getOptLevel() != CodeGenOptLevel::None) {\n    addMachineSSAOptimization();\n  } else {\n    // If the target requests it, assign local variables to stack slots relative\n    // to one another and simplify frame index references where possible.\n    addPass(&LocalStackSlotAllocationID);\n  }\n\n  if (TM->Options.EnableIPRA)\n    addPass(createRegUsageInfoPropPass());\n\n  // Run pre-ra passes.\n  addPreRegAlloc();\n\n  // Debugifying the register allocator passes seems to provoke some\n  // non-determinism that affects CodeGen and there doesn't seem to be a point\n  // where it becomes safe again so stop debugifying here.\n  DebugifyIsSafe = false;\n\n  // Add a FSDiscriminator pass right before RA, so that we could get\n  // more precise SampleFDO profile for RA.\n  if (EnableFSDiscriminator) {\n    addPass(createMIRAddFSDiscriminatorsPass(\n        sampleprof::FSDiscriminatorPass::Pass1));\n    const std::string ProfileFile = getFSProfileFile(TM);\n    if (!ProfileFile.empty() && !DisableRAFSProfileLoader)\n      addPass(createMIRProfileLoaderPass(ProfileFile, getFSRemappingFile(TM),\n                                         sampleprof::FSDiscriminatorPass::Pass1,\n                                         nullptr));\n  }\n\n  // Run register allocation and passes that are tightly coupled with it,\n  // including phi elimination and scheduling.\n  if (getOptimizeRegAlloc())\n    addOptimizedRegAlloc();\n  else\n    addFastRegAlloc();\n\n  // Run post-ra passes.\n  addPostRegAlloc();\n\n  addPass(&RemoveRedundantDebugValuesID);\n\n  addPass(&FixupStatepointCallerSavedID);\n\n  // Insert prolog/epilog code.  Eliminate abstract frame index references...\n  if (getOptLevel() != CodeGenOptLevel::None) {\n    addPass(&PostRAMachineSinkingID);\n    addPass(&ShrinkWrapID);\n  }\n\n  // Prolog/Epilog inserter needs a TargetMachine to instantiate. But only\n  // do so if it hasn't been disabled, substituted, or overridden.\n  if (!isPassSubstitutedOrOverridden(&PrologEpilogCodeInserterID))\n      addPass(createPrologEpilogInserterPass());\n\n  /// Add passes that optimize machine instructions after register allocation.\n  if (getOptLevel() != CodeGenOptLevel::None)\n      addMachineLateOptimization();\n\n  // Expand pseudo instructions before second scheduling pass.\n  addPass(&ExpandPostRAPseudosID);\n\n  // Run pre-sched2 passes.\n  addPreSched2();\n\n  if (EnableImplicitNullChecks)\n    addPass(&ImplicitNullChecksID);\n\n  // Second pass scheduler.\n  // Let Target optionally insert this pass by itself at some other\n  // point.\n  if (getOptLevel() != CodeGenOptLevel::None &&\n      !TM->targetSchedulesPostRAScheduling()) {\n    if (MISchedPostRA)\n      addPass(&PostMachineSchedulerID);\n    else\n      addPass(&PostRASchedulerID);\n  }\n\n  // GC\n  addGCPasses();\n\n  // Basic block placement.\n  if (getOptLevel() != CodeGenOptLevel::None)\n    addBlockPlacement();\n\n  // Insert before XRay Instrumentation.\n  addPass(&FEntryInserterID);\n\n  addPass(&XRayInstrumentationID);\n  addPass(&PatchableFunctionID);\n\n  addPreEmitPass();\n\n  if (TM->Options.EnableIPRA)\n    // Collect register usage information and produce a register mask of\n    // clobbered registers, to be used to optimize call sites.\n    addPass(createRegUsageInfoCollector());\n\n  // FIXME: Some backends are incompatible with running the verifier after\n  // addPreEmitPass.  Maybe only pass \"false\" here for those targets?\n  addPass(&FuncletLayoutID);\n\n"}, {"id": "15C6D93A9413CC3A", "name": "llvm::TargetPassConfig::addPass", "path": "llvm-project/llvm/lib/CodeGen/TargetPassConfig.cpp", "start": {"line": 688, "col": 1}, "end": {"line": 728, "col": 1}, "code": "  assert(!Initialized && \"PassConfig is immutable\");\n\n  // Cache the Pass ID here in case the pass manager finds this pass is\n  // redundant with ones already scheduled / available, and deletes it.\n  // Fundamentally, once we add the pass to the manager, we no longer own it\n  // and shouldn't reference it.\n  AnalysisID PassID = P->getPassID();\n\n  if (StartBefore == PassID && StartBeforeCount++ == StartBeforeInstanceNum)\n    Started = true;\n  if (StopBefore == PassID && StopBeforeCount++ == StopBeforeInstanceNum)\n    Stopped = true;\n  if (Started && !Stopped) {\n    if (AddingMachinePasses) {\n      // Construct banner message before PM->add() as that may delete the pass.\n      std::string Banner =\n          std::string(\"After \") + std::string(P->getPassName());\n      addMachinePrePasses();\n      PM->add(P);\n      addMachinePostPasses(Banner);\n    } else {\n      PM->add(P);\n    }\n\n    // Add the passes after the pass P if there is any.\n    for (const auto &IP : Impl->InsertedPasses)\n      if (IP.TargetPassID == PassID)\n        addPass(IP.getInsertedPass());\n  } else {\n    delete P;\n  }\n\n  if (StopAfter == PassID && StopAfterCount++ == StopAfterInstanceNum)\n    Stopped = true;\n\n  if (StartAfter == PassID && StartAfterCount++ == StartAfterInstanceNum)\n    Started = true;\n  if (Stopped && !Started)\n    report_fatal_error(\"Cannot stop compilation after pass that is not run\");\n}\n\n/// Add a CodeGen pass at this point in the pipeline after checking for target\n/// and command line overrides.\n///\n/// addPass cannot return a pointer to the pass instance because is internal the\n/// PassManager and the instance we create here may already be freed.\nAnalysisID TargetPassConfig::addPass(AnalysisID PassID) {\n  IdentifyingPassPtr TargetID = getPassSubstitution(PassID);\n  IdentifyingPassPtr FinalPtr = overridePass(PassID, TargetID);\n  if (!FinalPtr.isValid())\n    return nullptr;\n\n  Pass *P;\n  if (FinalPtr.isInstance())\n    P = FinalPtr.getInstance();\n  else {\n    P = Pass::createPass(FinalPtr.getID());\n    if (!P)\n      llvm_unreachable(\"Pass ID not registered\");\n  }\n  AnalysisID FinalID = P->getPassID();\n  addPass(P); // Ends the lifetime of P.\n\n  return FinalID;\n}\n\nvoid TargetPassConfig::printAndVerify(const std::string &Banner) {\n  addPrintPass(Banner);\n  addVerifyPass(Banner);\n}\n\nvoid TargetPassConfig::addPrintPass(const std::string &Banner) {\n  if (PrintAfterISel)\n    PM->add(createMachineFunctionPrinterPass(dbgs(), Banner));\n}\n\nvoid TargetPassConfig::addVerifyPass(const std::string &Banner) {\n  bool Verify = VerifyMachineCode == cl::BOU_TRUE;\n#ifdef EXPENSIVE_CHECKS\n  if (VerifyMachineCode == cl::BOU_UNSET)\n    Verify = TM->isMachineVerifierClean();\n#endif\n  if (Verify)\n    PM->add(createMachineVerifierPass(Banner));\n}\n\nvoid TargetPassConfig::addDebugifyPass() {\n  PM->add(createDebugifyMachineModulePass());\n}\n\nvoid TargetPassConfig::addStripDebugPass() {\n  PM->add(createStripDebugMachineModulePass(/*OnlyDebugified=*/true));\n}\n\nvoid TargetPassConfig::addCheckDebugPass() {\n  PM->add(createCheckDebugMachineModulePass());\n}\n\nvoid TargetPassConfig::addMachinePrePasses(bool AllowDebugify) {\n  if (AllowDebugify && DebugifyIsSafe &&\n      (DebugifyAndStripAll == cl::BOU_TRUE ||\n       DebugifyCheckAndStripAll == cl::BOU_TRUE))\n    addDebugifyPass();\n}\n\nvoid TargetPassConfig::addMachinePostPasses(const std::string &Banner) {\n  if (DebugifyIsSafe) {\n    if (DebugifyCheckAndStripAll == cl::BOU_TRUE) {\n      addCheckDebugPass();\n      addStripDebugPass();\n    } else if (DebugifyAndStripAll == cl::BOU_TRUE)\n      addStripDebugPass();\n  }\n  addVerifyPass(Banner);\n}\n\n/// Add common target configurable passes that perform LLVM IR to IR transforms\n/// following machine independent optimization.\nvoid TargetPassConfig::addIRPasses() {\n  // Before running any passes, run the verifier to determine if the input\n  // coming from the front-end and/or optimizer is valid.\n  if (!DisableVerify)\n    addPass(createVerifierPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None) {\n    // Basic AliasAnalysis support.\n    // Add TypeBasedAliasAnalysis before BasicAliasAnalysis so that\n    // BasicAliasAnalysis wins if they disagree. This is intended to help\n    // support \"obvious\" type-punning idioms.\n    addPass(createTypeBasedAAWrapperPass());\n    addPass(createScopedNoAliasAAWrapperPass());\n    addPass(createBasicAAWrapperPass());\n\n    // Run loop strength reduction before anything else.\n    if (!DisableLSR) {\n      addPass(createCanonicalizeFreezeInLoopsPass());\n      addPass(createLoopStrengthReducePass());\n      if (PrintLSR)\n        addPass(createPrintFunctionPass(dbgs(),\n                                        \"\\n\\n*** Code after LSR ***\\n\"));\n    }\n\n    // The MergeICmpsPass tries to create memcmp calls by grouping sequences of\n    // loads and compares. ExpandMemCmpPass then tries to expand those calls\n    // into optimally-sized loads and compares. The transforms are enabled by a\n    // target lowering hook.\n    if (!DisableMergeICmps)\n      addPass(createMergeICmpsLegacyPass());\n    addPass(createExpandMemCmpLegacyPass());\n  }\n\n  // Run GC lowering passes for builtin collectors\n  // TODO: add a pass insertion point here\n  addPass(&GCLoweringID);\n  addPass(&ShadowStackGCLoweringID);\n  addPass(createLowerConstantIntrinsicsPass());\n\n  // For MachO, lower @llvm.global_dtors into @llvm.global_ctors with\n  // __cxa_atexit() calls to avoid emitting the deprecated __mod_term_func.\n  if (TM->getTargetTriple().isOSBinFormatMachO() &&\n      !DisableAtExitBasedGlobalDtorLowering)\n    addPass(createLowerGlobalDtorsLegacyPass());\n\n  // Make sure that no unreachable blocks are instruction selected.\n  addPass(createUnreachableBlockEliminationPass());\n\n  // Prepare expensive constants for SelectionDAG.\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableConstantHoisting)\n    addPass(createConstantHoistingPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None)\n    addPass(createReplaceWithVeclibLegacyPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None && !DisablePartialLibcallInlining)\n    addPass(createPartiallyInlineLibCallsPass());\n\n  // Expand vector predication intrinsics into standard IR instructions.\n  // This pass has to run before ScalarizeMaskedMemIntrin and ExpandReduction\n  // passes since it emits those kinds of intrinsics.\n  addPass(createExpandVectorPredicationPass());\n\n  // Add scalarization of target's unsupported masked memory intrinsics pass.\n  // the unsupported intrinsic will be replaced with a chain of basic blocks,\n  // that stores/loads element one-by-one if the appropriate mask bit is set.\n  addPass(createScalarizeMaskedMemIntrinLegacyPass());\n\n  // Expand reduction intrinsics into shuffle sequences if the target wants to.\n  // Allow disabling it for testing purposes.\n  if (!DisableExpandReductions)\n    addPass(createExpandReductionsPass());\n\n  if (getOptLevel() != CodeGenOptLevel::None)\n    addPass(createTLSVariableHoistPass());\n\n  // Convert conditional moves to conditional jumps when profitable.\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableSelectOptimize)\n    addPass(createSelectOptimizePass());\n}\n\n/// Turn exception handling constructs into something the code generators can\n/// handle.\nvoid TargetPassConfig::addPassesToHandleExceptions() {\n  const MCAsmInfo *MCAI = TM->getMCAsmInfo();\n  assert(MCAI && \"No MCAsmInfo\");\n  switch (MCAI->getExceptionHandlingType()) {\n  case ExceptionHandling::SjLj:\n    // SjLj piggy-backs on dwarf for this bit. The cleanups done apply to both\n    // Dwarf EH prepare needs to be run after SjLj prepare. Otherwise,\n    // catch info can get misplaced when a selector ends up more than one block\n    // removed from the parent invoke(s). This could happen when a landing\n    // pad is shared by multiple invokes and is also a target of a normal\n    // edge from elsewhere.\n    addPass(createSjLjEHPreparePass(TM));\n    [[fallthrough]];\n  case ExceptionHandling::DwarfCFI:\n  case ExceptionHandling::ARM:\n  case ExceptionHandling::AIX:\n  case ExceptionHandling::ZOS:\n    addPass(createDwarfEHPass(getOptLevel()));\n    break;\n  case ExceptionHandling::WinEH:\n    // We support using both GCC-style and MSVC-style exceptions on Windows, so\n    // add both preparation passes. Each pass will only actually run if it\n    // recognizes the personality function.\n    addPass(createWinEHPass());\n    addPass(createDwarfEHPass(getOptLevel()));\n    break;\n  case ExceptionHandling::Wasm:\n    // Wasm EH uses Windows EH instructions, but it does not need to demote PHIs\n    // on catchpads and cleanuppads because it does not outline them into\n    // funclets. Catchswitch blocks are not lowered in SelectionDAG, so we\n    // should remove PHIs there.\n    addPass(createWinEHPass(/*DemoteCatchSwitchPHIOnly=*/false));\n    addPass(createWasmEHPass());\n    break;\n  case ExceptionHandling::None:\n    addPass(createLowerInvokePass());\n\n    // The lower invoke pass may create unreachable code. Remove it.\n    addPass(createUnreachableBlockEliminationPass());\n    break;\n  }\n}\n\n/// Add pass to prepare the LLVM IR for code generation. This should be done\n/// before exception handling preparation passes.\nvoid TargetPassConfig::addCodeGenPrepare() {\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableCGP)\n    addPass(createCodeGenPrepareLegacyPass());\n}\n\n/// Add common passes that perform LLVM IR to IR transforms in preparation for\n/// instruction selection.\nvoid TargetPassConfig::addISelPrepare() {\n  addPreISel();\n\n  // Force codegen to run according to the callgraph.\n  if (requiresCodeGenSCCOrder())\n    addPass(new DummyCGSCCPass);\n\n  addPass(createCallBrPass());\n\n  // Add both the safe stack and the stack protection passes: each of them will\n  // only protect functions that have corresponding attributes.\n  addPass(createSafeStackPass());\n  addPass(createStackProtectorPass());\n\n  if (PrintISelInput)\n    addPass(createPrintFunctionPass(\n        dbgs(), \"\\n\\n*** Final LLVM Code input to ISel ***\\n\"));\n\n  // All passes which modify the LLVM IR are now complete; run the verifier\n  // to ensure that the IR is valid.\n  if (!DisableVerify)\n    addPass(createVerifierPass());\n}\n\nbool TargetPassConfig::addCoreISelPasses() {\n  // Enable FastISel with -fast-isel, but allow that to be overridden.\n  TM->setO0WantsFastISel(EnableFastISelOption != cl::BOU_FALSE);\n\n  // Determine an instruction selector.\n  enum class SelectorType { SelectionDAG, FastISel, GlobalISel };\n  SelectorType Selector;\n\n  if (EnableFastISelOption == cl::BOU_TRUE)\n    Selector = SelectorType::FastISel;\n  else if (EnableGlobalISelOption == cl::BOU_TRUE ||\n           (TM->Options.EnableGlobalISel &&\n            EnableGlobalISelOption != cl::BOU_FALSE))\n    Selector = SelectorType::GlobalISel;\n  else if (TM->getOptLevel() == CodeGenOptLevel::None &&\n           TM->getO0WantsFastISel())\n    Selector = SelectorType::FastISel;\n  else\n    Selector = SelectorType::SelectionDAG;\n\n  // Set consistently TM->Options.EnableFastISel and EnableGlobalISel.\n  if (Selector == SelectorType::FastISel) {\n    TM->setFastISel(true);\n    TM->setGlobalISel(false);\n  } else if (Selector == SelectorType::GlobalISel) {\n    TM->setFastISel(false);\n    TM->setGlobalISel(true);\n  }\n\n  // FIXME: Injecting into the DAGISel pipeline seems to cause issues with\n  //        analyses needing to be re-run. This can result in being unable to\n  //        schedule passes (particularly with 'Function Alias Analysis\n  //        Results'). It's not entirely clear why but AFAICT this seems to be\n  //        due to one FunctionPassManager not being able to use analyses from a\n  //        previous one. As we're injecting a ModulePass we break the usual\n  //        pass manager into two. GlobalISel with the fallback path disabled\n  //        and -run-pass seem to be unaffected. The majority of GlobalISel\n  //        testing uses -run-pass so this probably isn't too bad.\n  SaveAndRestore SavedDebugifyIsSafe(DebugifyIsSafe);\n  if (Selector != SelectorType::GlobalISel || !isGlobalISelAbortEnabled())\n    DebugifyIsSafe = false;\n\n  // Add instruction selector passes.\n  if (Selector == SelectorType::GlobalISel) {\n    SaveAndRestore SavedAddingMachinePasses(AddingMachinePasses, true);\n    if (addIRTranslator())\n      return true;\n\n    addPreLegalizeMachineIR();\n\n    if (addLegalizeMachineIR())\n      return true;\n\n    // Before running the register bank selector, ask the target if it\n    // wants to run some passes.\n    addPreRegBankSelect();\n\n    if (addRegBankSelect())\n      return true;\n\n    addPreGlobalInstructionSelect();\n\n    if (addGlobalInstructionSelect())\n      return true;\n\n    // Pass to reset the MachineFunction if the ISel failed.\n    addPass(createResetMachineFunctionPass(\n        reportDiagnosticWhenGlobalISelFallback(), isGlobalISelAbortEnabled()));\n\n    // Provide a fallback path when we do not want to abort on\n    // not-yet-supported input.\n    if (!isGlobalISelAbortEnabled() && addInstSelector())\n      return true;\n\n  } else if (addInstSelector())\n    return true;\n\n  // Expand pseudo-instructions emitted by ISel. Don't run the verifier before\n  // FinalizeISel.\n  addPass(&FinalizeISelID);\n\n  // Print the instruction selected machine code...\n  printAndVerify(\"After Instruction Selection\");\n\n  return false;\n}\n\nbool TargetPassConfig::addISelPasses() {\n  if (TM->useEmulatedTLS())\n    addPass(createLowerEmuTLSPass());\n\n  PM->add(createTargetTransformInfoWrapperPass(TM->getTargetIRAnalysis()));\n  addPass(createPreISelIntrinsicLoweringPass());\n  addPass(createExpandLargeDivRemPass());\n  addPass(createExpandLargeFpConvertPass());\n  addIRPasses();\n  addCodeGenPrepare();\n  addPassesToHandleExceptions();\n  addISelPrepare();\n\n  return addCoreISelPasses();\n}\n\n/// -regalloc=... command line option.\nstatic FunctionPass *useDefaultRegisterAllocator() { return nullptr; }\nstatic cl::opt<RegisterRegAlloc::FunctionPassCtor, false,\n               RegisterPassParser<RegisterRegAlloc>>\n    RegAlloc(\"regalloc\", cl::Hidden, cl::init(&useDefaultRegisterAllocator),\n             cl::desc(\"Register allocator to use\"));\n\n/// Add the complete set of target-independent postISel code generator passes.\n///\n/// This can be read as the standard order of major LLVM CodeGen stages. Stages\n/// with nontrivial configuration or multiple passes are broken out below in\n/// add%Stage routines.\n///\n/// Any TargetPassConfig::addXX routine may be overriden by the Target. The\n/// addPre/Post methods with empty header implementations allow injecting\n/// target-specific fixups just before or after major stages. Additionally,\n/// targets have the flexibility to change pass order within a stage by\n/// overriding default implementation of add%Stage routines below. Each\n/// technique has maintainability tradeoffs because alternate pass orders are\n/// not well supported. addPre/Post works better if the target pass is easily\n/// tied to a common pass. But if it has subtle dependencies on multiple passes,\n/// the target should override the stage instead.\n///\n/// TODO: We could use a single addPre/Post(ID) hook to allow pass injection\n/// before/after any target-independent pass. But it's currently overkill.\nvoid TargetPassConfig::addMachinePasses() {\n  AddingMachinePasses = true;\n\n  // Add passes that optimize machine instructions in SSA form.\n  if (getOptLevel() != CodeGenOptLevel::None) {\n    addMachineSSAOptimization();\n  } else {\n    // If the target requests it, assign local variables to stack slots relative\n    // to one another and simplify frame index references where possible.\n    addPass(&LocalStackSlotAllocationID);\n  }\n\n  if (TM->Options.EnableIPRA)\n    addPass(createRegUsageInfoPropPass());\n\n  // Run pre-ra passes.\n  addPreRegAlloc();\n\n  // Debugifying the register allocator passes seems to provoke some\n  // non-determinism that affects CodeGen and there doesn't seem to be a point\n  // where it becomes safe again so stop debugifying here.\n  DebugifyIsSafe = false;\n\n  // Add a FSDiscriminator pass right before RA, so that we could get\n  // more precise SampleFDO profile for RA.\n  if (EnableFSDiscriminator) {\n    addPass(createMIRAddFSDiscriminatorsPass(\n        sampleprof::FSDiscriminatorPass::Pass1));\n    const std::string ProfileFile = getFSProfileFile(TM);\n    if (!ProfileFile.empty() && !DisableRAFSProfileLoader)\n      addPass(createMIRProfileLoaderPass(ProfileFile, getFSRemappingFile(TM),\n                                         sampleprof::FSDiscriminatorPass::Pass1,\n                                         nullptr));\n  }\n\n  // Run register allocation and passes that are tightly coupled with it,\n  // including phi elimination and scheduling.\n  if (getOptimizeRegAlloc())\n    addOptimizedRegAlloc();\n  else\n    addFastRegAlloc();\n\n  // Run post-ra passes.\n  addPostRegAlloc();\n\n  addPass(&RemoveRedundantDebugValuesID);\n\n  addPass(&FixupStatepointCallerSavedID);\n\n  // Insert prolog/epilog code.  Eliminate abstract frame index references...\n  if (getOptLevel() != CodeGenOptLevel::None) {\n    addPass(&PostRAMachineSinkingID);\n    addPass(&ShrinkWrapID);\n  }\n\n  // Prolog/Epilog inserter needs a TargetMachine to instantiate. But only\n  // do so if it hasn't been disabled, substituted, or overridden.\n  if (!isPassSubstitutedOrOverridden(&PrologEpilogCodeInserterID))\n      addPass(createPrologEpilogInserterPass());\n\n  /// Add passes that optimize machine instructions after register allocation.\n  if (getOptLevel() != CodeGenOptLevel::None)\n      addMachineLateOptimization();\n\n  // Expand pseudo instructions before second scheduling pass.\n  addPass(&ExpandPostRAPseudosID);\n\n  // Run pre-sched2 passes.\n  addPreSched2();\n\n  if (EnableImplicitNullChecks)\n    addPass(&ImplicitNullChecksID);\n\n  // Second pass scheduler.\n  // Let Target optionally insert this pass by itself at some other\n  // point.\n  if (getOptLevel() != CodeGenOptLevel::None &&\n      !TM->targetSchedulesPostRAScheduling()) {\n    if (MISchedPostRA)\n      addPass(&PostMachineSchedulerID);\n    else\n      addPass(&PostRASchedulerID);\n  }\n\n  // GC\n  addGCPasses();\n\n  // Basic block placement.\n  if (getOptLevel() != CodeGenOptLevel::None)\n    addBlockPlacement();\n\n  // Insert before XRay Instrumentation.\n  addPass(&FEntryInserterID);\n\n  addPass(&XRayInstrumentationID);\n  addPass(&PatchableFunctionID);\n\n  addPreEmitPass();\n\n  if (TM->Options.EnableIPRA)\n    // Collect register usage information and produce a register mask of\n    // clobbered registers, to be used to optimize call sites.\n    addPass(createRegUsageInfoCollector());\n\n  // FIXME: Some backends are incompatible with running the verifier after\n  // addPreEmitPass.  Maybe only pass \"false\" here for those targets?\n  addPass(&FuncletLayoutID);\n\n  addPass(&StackMapLivenessID);\n  addPass(&LiveDebugValuesID);\n  addPass(&MachineSanitizerBinaryMetadataID);\n\n  if (TM->Options.EnableMachineOutliner &&\n      getOptLevel() != CodeGenOptLevel::None &&\n      EnableMachineOutliner != RunOutliner::NeverOutline) {\n    bool RunOnAllFunctions =\n        (EnableMachineOutliner == RunOutliner::AlwaysOutline);\n    bool AddOutliner =\n        RunOnAllFunctions || TM->Options.SupportsDefaultOutlining;\n    if (AddOutliner)\n      addPass(createMachineOutlinerPass(RunOnAllFunctions));\n  }\n\n  if (GCEmptyBlocks)\n    addPass(llvm::createGCEmptyBasicBlocksPass());\n\n  if (EnableFSDiscriminator)\n    addPass(createMIRAddFSDiscriminatorsPass(\n        sampleprof::FSDiscriminatorPass::PassLast));\n\n  bool NeedsBBSections =\n      TM->getBBSectionsType() != llvm::BasicBlockSection::None;\n  // Machine function splitter uses the basic block sections feature. Both\n  // cannot be enabled at the same time. We do not apply machine function\n  // splitter if -basic-block-sections is requested.\n  if (!NeedsBBSections && (TM->Options.EnableMachineFunctionSplitter ||\n                           EnableMachineFunctionSplitter)) {\n    const std::string ProfileFile = getFSProfileFile(TM);\n    if (!ProfileFile.empty()) {\n      if (EnableFSDiscriminator) {\n        addPass(createMIRProfileLoaderPass(\n            ProfileFile, getFSRemappingFile(TM),\n            sampleprof::FSDiscriminatorPass::PassLast, nullptr));\n      } else {\n        // Sample profile is given, but FSDiscriminator is not\n        // enabled, this may result in performance regression.\n        WithColor::warning()\n            << \"Using AutoFDO without FSDiscriminator for MFS may regress \"\n               \"performance.\\n\";\n      }\n    }\n    addPass(createMachineFunctionSplitterPass());\n  }\n  // We run the BasicBlockSections pass if either we need BB sections or BB\n  // address map (or both).\n  if (NeedsBBSections || TM->Options.BBAddrMap) {\n    if (TM->getBBSectionsType() == llvm::BasicBlockSection::List) {\n      addPass(llvm::createBasicBlockSectionsProfileReaderWrapperPass(\n          TM->getBBSectionsFuncListBuf()));\n      addPass(llvm::createBasicBlockPathCloningPass());\n    }\n    addPass(llvm::createBasicBlockSectionsPass());\n  }\n\n  addPostBBSections();\n\n  if (!DisableCFIFixup && TM->Options.EnableCFIFixup)\n    addPass(createCFIFixup());\n\n  PM->add(createStackFrameLayoutAnalysisPass());\n\n  // Add passes that directly emit MI after all other MI passes.\n  addPreEmitPass2();\n\n  AddingMachinePasses = false;\n}\n\n/// Add passes that optimize machine instructions in SSA form.\nvoid TargetPassConfig::addMachineSSAOptimization() {\n  // Pre-ra tail duplication.\n  addPass(&EarlyTailDuplicateID);\n\n  // Optimize PHIs before DCE: removing dead PHI cycles may make more\n  // instructions dead.\n  addPass(&OptimizePHIsID);\n\n  // This pass merges large allocas. StackSlotColoring is a different pass\n  // which merges spill slots.\n  addPass(&StackColoringID);\n\n  // If the target requests it, assign local variables to stack slots relative\n  // to one another and simplify frame index references where possible.\n  addPass(&LocalStackSlotAllocationID);\n\n  // With optimization, dead code should already be eliminated. However\n  // there is one known exception: lowered code for arguments that are only\n  // used by tail calls, where the tail calls reuse the incoming stack\n  // arguments directly (see t11 in test/CodeGen/X86/sibcall.ll).\n  addPass(&DeadMachineInstructionElimID);\n\n  // Allow targets to insert passes that improve instruction level parallelism,\n  // like if-conversion. Such passes will typically need dominator trees and\n  // loop info, just like LICM and CSE below.\n  addILPOpts();\n\n  addPass(&EarlyMachineLICMID);\n  addPass(&MachineCSEID);\n\n  addPass(&MachineSinkingID);\n\n  addPass(&PeepholeOptimizerID);\n  // Clean-up the dead code that may have been generated by peephole\n  // rewriting.\n  addPass(&DeadMachineInstructionElimID);\n}\n\n//===---------------------------------------------------------------------===//\n/// Register Allocation Pass Configuration\n//===---------------------------------------------------------------------===//\n\nbool TargetPassConfig::getOptimizeRegAlloc() const {\n  switch (OptimizeRegAlloc) {\n  case cl::BOU_UNSET:\n    return getOptLevel() != CodeGenOptLevel::None;\n  case cl::BOU_TRUE:  return true;\n  case cl::BOU_FALSE: return false;\n  }\n  llvm_unreachable(\"Invalid optimize-regalloc state\");\n}\n\n/// A dummy default pass factory indicates whether the register allocator is\n/// overridden on the command line.\nstatic llvm::once_flag InitializeDefaultRegisterAllocatorFlag;\n\nstatic RegisterRegAlloc\ndefaultRegAlloc(\"default\",\n                \"pick register allocator based on -O option\",\n                useDefaultRegisterAllocator);\n\nstatic void initializeDefaultRegisterAllocatorOnce() {\n  if (!RegisterRegAlloc::getDefault())\n    RegisterRegAlloc::setDefault(RegAlloc);\n}\n\n/// Instantiate the default register allocator pass for this target for either\n/// the optimized or unoptimized allocation path. This will be added to the pass\n/// manager by addFastRegAlloc in the unoptimized case or addOptimizedRegAlloc\n/// in the optimized case.\n///\n/// A target that uses the standard regalloc pass order for fast or optimized\n/// allocation may still override this for per-target regalloc\n/// selection. But -regalloc=... always takes precedence.\nFunctionPass *TargetPassConfig::createTargetRegisterAllocator(bool Optimized) {\n  if (Optimized)\n    return createGreedyRegisterAllocator();\n  else\n    return createFastRegisterAllocator();\n}\n\n/// Find and instantiate the register allocation pass requested by this target\n/// at the current optimization level.  Different register allocators are\n/// defined as separate passes because they may require different analysis.\n///\n/// This helper ensures that the regalloc= option is always available,\n/// even for targets that override the default allocator.\n///\n/// FIXME: When MachinePassRegistry register pass IDs instead of function ptrs,\n/// this can be folded into addPass.\nFunctionPass *TargetPassConfig::createRegAllocPass(bool Optimized) {\n  // Initialize the global default.\n  llvm::call_once(InitializeDefaultRegisterAllocatorFlag,\n                  initializeDefaultRegisterAllocatorOnce);\n\n  RegisterRegAlloc::FunctionPassCtor Ctor = RegisterRegAlloc::getDefault();\n  if (Ctor != useDefaultRegisterAllocator)\n    return Ctor();\n\n  // With no -regalloc= override, ask the target for a regalloc pass.\n  return createTargetRegisterAllocator(Optimized);\n}\n\nbool TargetPassConfig::isCustomizedRegAlloc() {\n  return RegAlloc !=\n         (RegisterRegAlloc::FunctionPassCtor)&useDefaultRegisterAllocator;\n}\n\nbool TargetPassConfig::addRegAssignAndRewriteFast() {\n  if (RegAlloc != (RegisterRegAlloc::FunctionPassCtor)&useDefaultRegisterAllocator &&\n      RegAlloc != (RegisterRegAlloc::FunctionPassCtor)&createFastRegisterAllocator)\n    report_fatal_error(\"Must use fast (default) register allocator for unoptimized regalloc.\");\n\n  addPass(createRegAllocPass(false));\n\n  // Allow targets to change the register assignments after\n  // fast register allocation.\n  addPostFastRegAllocRewrite();\n  return true;\n}\n\nbool TargetPassConfig::addRegAssignAndRewriteOptimized() {\n  // Add the selected register allocation pass.\n  addPass(createRegAllocPass(true));\n\n  // Allow targets to change the register assignments before rewriting.\n  addPreRewrite();\n\n  // Finally rewrite virtual registers.\n  addPass(&VirtRegRewriterID);\n\n  // Regalloc scoring for ML-driven eviction - noop except when learning a new\n  // eviction policy.\n  addPass(createRegAllocScoringPass());\n  return true;\n}\n\n/// Return true if the default global register allocator is in use and\n/// has not be overriden on the command line with '-regalloc=...'\nbool TargetPassConfig::usingDefaultRegAlloc() const {\n  return RegAlloc.getNumOccurrences() == 0;\n}\n\n/// Add the minimum set of target-independent passes that are required for\n/// register allocation. No coalescing or scheduling.\nvoid TargetPassConfig::addFastRegAlloc() {\n"}, {"id": "1923C229AC264E0B", "name": "llvm::createCodeGenPrepareLegacyPass", "path": "llvm-project/llvm/lib/CodeGen/CodeGenPrepare.cpp", "start": {"line": 540, "col": 1}, "end": {"line": 542, "col": 1}, "code": "  return new CodeGenPrepareLegacyPass();\n}\n\nPreservedAnalyses CodeGenPreparePass::run(Function &F,\n                                          FunctionAnalysisManager &AM) {\n  CodeGenPrepare CGP(TM);\n\n  bool Changed = CGP.run(F, AM);\n  if (!Changed)\n    return PreservedAnalyses::all();\n\n  PreservedAnalyses PA;\n  PA.preserve<TargetLibraryAnalysis>();\n  PA.preserve<TargetIRAnalysis>();\n  PA.preserve<LoopAnalysis>();\n  return PA;\n}\n\nbool CodeGenPrepare::run(Function &F, FunctionAnalysisManager &AM) {\n  DL = &F.getParent()->getDataLayout();\n  SubtargetInfo = TM->getSubtargetImpl(F);\n  TLI = SubtargetInfo->getTargetLowering();\n  TRI = SubtargetInfo->getRegisterInfo();\n  TLInfo = &AM.getResult<TargetLibraryAnalysis>(F);\n  TTI = &AM.getResult<TargetIRAnalysis>(F);\n  LI = &AM.getResult<LoopAnalysis>(F);\n  BPI.reset(new BranchProbabilityInfo(F, *LI));\n  BFI.reset(new BlockFrequencyInfo(F, *BPI, *LI));\n  auto &MAMProxy = AM.getResult<ModuleAnalysisManagerFunctionProxy>(F);\n  PSI = MAMProxy.getCachedResult<ProfileSummaryAnalysis>(*F.getParent());\n  BBSectionsProfileReader =\n      AM.getCachedResult<BasicBlockSectionsProfileReaderAnalysis>(F);\n  return _run(F);\n}\n\nbool CodeGenPrepare::_run(Function &F) {\n  bool EverMadeChange = false;\n\n  OptSize = F.hasOptSize();\n  // Use the basic-block-sections profile to promote hot functions to .text.hot\n  // if requested.\n  if (BBSectionsGuidedSectionPrefix && BBSectionsProfileReader &&\n      BBSectionsProfileReader->isFunctionHot(F.getName())) {\n    F.setSectionPrefix(\"hot\");\n  } else if (ProfileGuidedSectionPrefix) {\n    // The hot attribute overwrites profile count based hotness while profile\n    // counts based hotness overwrite the cold attribute.\n    // This is a conservative behabvior.\n    if (F.hasFnAttribute(Attribute::Hot) ||\n        PSI->isFunctionHotInCallGraph(&F, *BFI))\n      F.setSectionPrefix(\"hot\");\n    // If PSI shows this function is not hot, we will placed the function\n    // into unlikely section if (1) PSI shows this is a cold function, or\n    // (2) the function has a attribute of cold.\n    else if (PSI->isFunctionColdInCallGraph(&F, *BFI) ||\n             F.hasFnAttribute(Attribute::Cold))\n      F.setSectionPrefix(\"unlikely\");\n    else if (ProfileUnknownInSpecialSection && PSI->hasPartialSampleProfile() &&\n             PSI->isFunctionHotnessUnknown(F))\n      F.setSectionPrefix(\"unknown\");\n  }\n\n  /// This optimization identifies DIV instructions that can be\n  /// profitably bypassed and carried out with a shorter, faster divide.\n  if (!OptSize && !PSI->hasHugeWorkingSetSize() && TLI->isSlowDivBypassed()) {\n    const DenseMap<unsigned int, unsigned int> &BypassWidths =\n        TLI->getBypassSlowDivWidths();\n    BasicBlock *BB = &*F.begin();\n    while (BB != nullptr) {\n      // bypassSlowDivision may create new BBs, but we don't want to reapply the\n      // optimization to those blocks.\n      BasicBlock *Next = BB->getNextNode();\n      // F.hasOptSize is already checked in the outer if statement.\n      if (!llvm::shouldOptimizeForSize(BB, PSI, BFI.get()))\n        EverMadeChange |= bypassSlowDivision(BB, BypassWidths);\n      BB = Next;\n    }\n  }\n\n  // Get rid of @llvm.assume builtins before attempting to eliminate empty\n  // blocks, since there might be blocks that only contain @llvm.assume calls\n  // (plus arguments that we can get rid of).\n  EverMadeChange |= eliminateAssumptions(F);\n\n  // Eliminate blocks that contain only PHI nodes and an\n  // unconditional branch.\n  EverMadeChange |= eliminateMostlyEmptyBlocks(F);\n\n  ModifyDT ModifiedDT = ModifyDT::NotModifyDT;\n  if (!DisableBranchOpts)\n    EverMadeChange |= splitBranchCondition(F, ModifiedDT);\n\n  // Split some critical edges where one of the sources is an indirect branch,\n  // to help generate sane code for PHIs involving such edges.\n  EverMadeChange |=\n      SplitIndirectBrCriticalEdges(F, /*IgnoreBlocksWithoutPHI=*/true);\n\n  // If we are optimzing huge function, we need to consider the build time.\n  // Because the basic algorithm's complex is near O(N!).\n  IsHugeFunc = F.size() > HugeFuncThresholdInCGPP;\n\n  // Transformations above may invalidate dominator tree and/or loop info.\n  DT.reset();\n  LI->releaseMemory();\n  LI->analyze(getDT(F));\n\n  bool MadeChange = true;\n  bool FuncIterated = false;\n  while (MadeChange) {\n    MadeChange = false;\n\n    for (BasicBlock &BB : llvm::make_early_inc_range(F)) {\n      if (FuncIterated && !FreshBBs.contains(&BB))\n        continue;\n\n      ModifyDT ModifiedDTOnIteration = ModifyDT::NotModifyDT;\n      bool Changed = optimizeBlock(BB, ModifiedDTOnIteration);\n\n      if (ModifiedDTOnIteration == ModifyDT::ModifyBBDT)\n        DT.reset();\n\n      MadeChange |= Changed;\n      if (IsHugeFunc) {\n        // If the BB is updated, it may still has chance to be optimized.\n        // This usually happen at sink optimization.\n        // For example:\n        //\n        // bb0\uff1a\n        // %and = and i32 %a, 4\n        // %cmp = icmp eq i32 %and, 0\n        //\n        // If the %cmp sink to other BB, the %and will has chance to sink.\n        if (Changed)\n          FreshBBs.insert(&BB);\n        else if (FuncIterated)\n          FreshBBs.erase(&BB);\n      } else {\n        // For small/normal functions, we restart BB iteration if the dominator\n        // tree of the Function was changed.\n        if (ModifiedDTOnIteration != ModifyDT::NotModifyDT)\n          break;\n      }\n    }\n    // We have iterated all the BB in the (only work for huge) function.\n    FuncIterated = IsHugeFunc;\n\n    if (EnableTypePromotionMerge && !ValToSExtendedUses.empty())\n      MadeChange |= mergeSExts(F);\n    if (!LargeOffsetGEPMap.empty())\n      MadeChange |= splitLargeGEPOffsets();\n    MadeChange |= optimizePhiTypes(F);\n\n    if (MadeChange)\n      eliminateFallThrough(F, DT.get());\n\n#ifndef NDEBUG\n    if (MadeChange && VerifyLoopInfo)\n      LI->verify(getDT(F));\n#endif\n\n    // Really free removed instructions during promotion.\n    for (Instruction *I : RemovedInsts)\n      I->deleteValue();\n\n    EverMadeChange |= MadeChange;\n    SeenChainsForSExt.clear();\n    ValToSExtendedUses.clear();\n    RemovedInsts.clear();\n    LargeOffsetGEPMap.clear();\n    LargeOffsetGEPID.clear();\n  }\n\n  NewGEPBases.clear();\n  SunkAddrs.clear();\n\n  if (!DisableBranchOpts) {\n    MadeChange = false;\n    // Use a set vector to get deterministic iteration order. The order the\n    // blocks are removed may affect whether or not PHI nodes in successors\n    // are removed.\n    SmallSetVector<BasicBlock *, 8> WorkList;\n    for (BasicBlock &BB : F) {\n      SmallVector<BasicBlock *, 2> Successors(successors(&BB));\n      MadeChange |= ConstantFoldTerminator(&BB, true);\n      if (!MadeChange)\n        continue;\n\n      for (BasicBlock *Succ : Successors)\n        if (pred_empty(Succ))\n          WorkList.insert(Succ);\n    }\n\n    // Delete the dead blocks and any of their dead successors.\n    MadeChange |= !WorkList.empty();\n    while (!WorkList.empty()) {\n      BasicBlock *BB = WorkList.pop_back_val();\n      SmallVector<BasicBlock *, 2> Successors(successors(BB));\n\n      DeleteDeadBlock(BB);\n\n      for (BasicBlock *Succ : Successors)\n        if (pred_empty(Succ))\n          WorkList.insert(Succ);\n    }\n\n    // Merge pairs of basic blocks with unconditional branches, connected by\n    // a single edge.\n    if (EverMadeChange || MadeChange)\n      MadeChange |= eliminateFallThrough(F);\n\n    EverMadeChange |= MadeChange;\n  }\n\n  if (!DisableGCOpts) {\n    SmallVector<GCStatepointInst *, 2> Statepoints;\n    for (BasicBlock &BB : F)\n      for (Instruction &I : BB)\n        if (auto *SP = dyn_cast<GCStatepointInst>(&I))\n          Statepoints.push_back(SP);\n    for (auto &I : Statepoints)\n      EverMadeChange |= simplifyOffsetableRelocate(*I);\n  }\n\n  // Do this last to clean up use-before-def scenarios introduced by other\n  // preparatory transforms.\n  EverMadeChange |= placeDbgValues(F);\n  EverMadeChange |= placePseudoProbes(F);\n\n#ifndef NDEBUG\n  if (VerifyBFIUpdates)\n    verifyBFIUpdates(F);\n#endif\n\n  return EverMadeChange;\n}\n\nbool CodeGenPrepare::eliminateAssumptions(Function &F) {\n  bool MadeChange = false;\n  for (BasicBlock &BB : F) {\n    CurInstIterator = BB.begin();\n    while (CurInstIterator != BB.end()) {\n      Instruction *I = &*(CurInstIterator++);\n      if (auto *Assume = dyn_cast<AssumeInst>(I)) {\n        MadeChange = true;\n        Value *Operand = Assume->getOperand(0);\n        Assume->eraseFromParent();\n\n        resetIteratorIfInvalidatedWhileCalling(&BB, [&]() {\n          RecursivelyDeleteTriviallyDeadInstructions(Operand, TLInfo, nullptr);\n        });\n      }\n    }\n  }\n  return MadeChange;\n}\n\n/// An instruction is about to be deleted, so remove all references to it in our\n/// GEP-tracking data strcutures.\nvoid CodeGenPrepare::removeAllAssertingVHReferences(Value *V) {\n  LargeOffsetGEPMap.erase(V);\n  NewGEPBases.erase(V);\n\n  auto GEP = dyn_cast<GetElementPtrInst>(V);\n  if (!GEP)\n    return;\n\n  LargeOffsetGEPID.erase(GEP);\n\n  auto VecI = LargeOffsetGEPMap.find(GEP->getPointerOperand());\n  if (VecI == LargeOffsetGEPMap.end())\n    return;\n\n  auto &GEPVector = VecI->second;\n  llvm::erase_if(GEPVector, [=](auto &Elt) { return Elt.first == GEP; });\n\n  if (GEPVector.empty())\n    LargeOffsetGEPMap.erase(VecI);\n}\n\n// Verify BFI has been updated correctly by recomputing BFI and comparing them.\nvoid LLVM_ATTRIBUTE_UNUSED CodeGenPrepare::verifyBFIUpdates(Function &F) {\n  DominatorTree NewDT(F);\n  LoopInfo NewLI(NewDT);\n  BranchProbabilityInfo NewBPI(F, NewLI, TLInfo);\n  BlockFrequencyInfo NewBFI(F, NewBPI, NewLI);\n  NewBFI.verifyMatch(*BFI);\n}\n\n/// Merge basic blocks which are connected by a single edge, where one of the\n/// basic blocks has a single successor pointing to the other basic block,\n/// which has a single predecessor.\nbool CodeGenPrepare::eliminateFallThrough(Function &F, DominatorTree *DT) {\n  bool Changed = false;\n  // Scan all of the blocks in the function, except for the entry block.\n  // Use a temporary array to avoid iterator being invalidated when\n  // deleting blocks.\n  SmallVector<WeakTrackingVH, 16> Blocks;\n  for (auto &Block : llvm::drop_begin(F))\n    Blocks.push_back(&Block);\n\n  SmallSet<WeakTrackingVH, 16> Preds;\n  for (auto &Block : Blocks) {\n    auto *BB = cast_or_null<BasicBlock>(Block);\n    if (!BB)\n      continue;\n    // If the destination block has a single pred, then this is a trivial\n    // edge, just collapse it.\n    BasicBlock *SinglePred = BB->getSinglePredecessor();\n\n    // Don't merge if BB's address is taken.\n    if (!SinglePred || SinglePred == BB || BB->hasAddressTaken())\n      continue;\n\n    // Make an effort to skip unreachable blocks.\n    if (DT && !DT->isReachableFromEntry(BB))\n      continue;\n\n    BranchInst *Term = dyn_cast<BranchInst>(SinglePred->getTerminator());\n    if (Term && !Term->isConditional()) {\n      Changed = true;\n      LLVM_DEBUG(dbgs() << \"To merge:\\n\" << *BB << \"\\n\\n\\n\");\n\n      // Merge BB into SinglePred and delete it.\n      MergeBlockIntoPredecessor(BB, /* DTU */ nullptr, LI, /* MSSAU */ nullptr,\n                                /* MemDep */ nullptr,\n                                /* PredecessorWithTwoSuccessors */ false, DT);\n      Preds.insert(SinglePred);\n\n      if (IsHugeFunc) {\n        // Update FreshBBs to optimize the merged BB.\n        FreshBBs.insert(SinglePred);\n        FreshBBs.erase(BB);\n      }\n    }\n  }\n\n  // (Repeatedly) merging blocks into their predecessors can create redundant\n  // debug intrinsics.\n  for (const auto &Pred : Preds)\n    if (auto *BB = cast_or_null<BasicBlock>(Pred))\n      RemoveRedundantDbgInstrs(BB);\n\n  return Changed;\n}\n\n/// Find a destination block from BB if BB is mergeable empty block.\nBasicBlock *CodeGenPrepare::findDestBlockOfMergeableEmptyBlock(BasicBlock *BB) {\n  // If this block doesn't end with an uncond branch, ignore it.\n  BranchInst *BI = dyn_cast<BranchInst>(BB->getTerminator());\n  if (!BI || !BI->isUnconditional())\n    return nullptr;\n\n  // If the instruction before the branch (skipping debug info) isn't a phi\n  // node, then other stuff is happening here.\n  BasicBlock::iterator BBI = BI->getIterator();\n  if (BBI != BB->begin()) {\n    --BBI;\n    while (isa<DbgInfoIntrinsic>(BBI)) {\n      if (BBI == BB->begin())\n        break;\n      --BBI;\n    }\n    if (!isa<DbgInfoIntrinsic>(BBI) && !isa<PHINode>(BBI))\n      return nullptr;\n  }\n\n  // Do not break infinite loops.\n  BasicBlock *DestBB = BI->getSuccessor(0);\n  if (DestBB == BB)\n    return nullptr;\n\n  if (!canMergeBlocks(BB, DestBB))\n    DestBB = nullptr;\n\n  return DestBB;\n}\n\n/// Eliminate blocks that contain only PHI nodes, debug info directives, and an\n/// unconditional branch. Passes before isel (e.g. LSR/loopsimplify) often split\n/// edges in ways that are non-optimal for isel. Start by eliminating these\n/// blocks so we can split them the way we want them.\nbool CodeGenPrepare::eliminateMostlyEmptyBlocks(Function &F) {\n  SmallPtrSet<BasicBlock *, 16> Preheaders;\n  SmallVector<Loop *, 16> LoopList(LI->begin(), LI->end());\n  while (!LoopList.empty()) {\n    Loop *L = LoopList.pop_back_val();\n    llvm::append_range(LoopList, *L);\n    if (BasicBlock *Preheader = L->getLoopPreheader())\n      Preheaders.insert(Preheader);\n  }\n\n  bool MadeChange = false;\n  // Copy blocks into a temporary array to avoid iterator invalidation issues\n  // as we remove them.\n  // Note that this intentionally skips the entry block.\n  SmallVector<WeakTrackingVH, 16> Blocks;\n  for (auto &Block : llvm::drop_begin(F)) {\n    // Delete phi nodes that could block deleting other empty blocks.\n    if (!DisableDeletePHIs)\n      MadeChange |= DeleteDeadPHIs(&Block, TLInfo);\n    Blocks.push_back(&Block);\n  }\n\n  for (auto &Block : Blocks) {\n    BasicBlock *BB = cast_or_null<BasicBlock>(Block);\n    if (!BB)\n      continue;\n    BasicBlock *DestBB = findDestBlockOfMergeableEmptyBlock(BB);\n    if (!DestBB ||\n        !isMergingEmptyBlockProfitable(BB, DestBB, Preheaders.count(BB)))\n      continue;\n\n    eliminateMostlyEmptyBlock(BB);\n    MadeChange = true;\n  }\n  return MadeChange;\n}\n\nbool CodeGenPrepare::isMergingEmptyBlockProfitable(BasicBlock *BB,\n                                                   BasicBlock *DestBB,\n                                                   bool isPreheader) {\n  // Do not delete loop preheaders if doing so would create a critical edge.\n  // Loop preheaders can be good locations to spill registers. If the\n  // preheader is deleted and we create a critical edge, registers may be\n  // spilled in the loop body instead.\n  if (!DisablePreheaderProtect && isPreheader &&\n      !(BB->getSinglePredecessor() &&\n        BB->getSinglePredecessor()->getSingleSuccessor()))\n    return false;\n\n  // Skip merging if the block's successor is also a successor to any callbr\n  // that leads to this block.\n  // FIXME: Is this really needed? Is this a correctness issue?\n  for (BasicBlock *Pred : predecessors(BB)) {\n    if (isa<CallBrInst>(Pred->getTerminator()) &&\n        llvm::is_contained(successors(Pred), DestBB))\n      return false;\n  }\n\n  // Try to skip merging if the unique predecessor of BB is terminated by a\n  // switch or indirect branch instruction, and BB is used as an incoming block\n  // of PHIs in DestBB. In such case, merging BB and DestBB would cause ISel to\n  // add COPY instructions in the predecessor of BB instead of BB (if it is not\n  // merged). Note that the critical edge created by merging such blocks wont be\n  // split in MachineSink because the jump table is not analyzable. By keeping\n  // such empty block (BB), ISel will place COPY instructions in BB, not in the\n  // predecessor of BB.\n  BasicBlock *Pred = BB->getUniquePredecessor();\n  if (!Pred || !(isa<SwitchInst>(Pred->getTerminator()) ||\n                 isa<IndirectBrInst>(Pred->getTerminator())))\n    return true;\n\n  if (BB->getTerminator() != BB->getFirstNonPHIOrDbg())\n    return true;\n\n  // We use a simple cost heuristic which determine skipping merging is\n  // profitable if the cost of skipping merging is less than the cost of\n  // merging : Cost(skipping merging) < Cost(merging BB), where the\n  // Cost(skipping merging) is Freq(BB) * (Cost(Copy) + Cost(Branch)), and\n  // the Cost(merging BB) is Freq(Pred) * Cost(Copy).\n  // Assuming Cost(Copy) == Cost(Branch), we could simplify it to :\n  //   Freq(Pred) / Freq(BB) > 2.\n  // Note that if there are multiple empty blocks sharing the same incoming\n  // value for the PHIs in the DestBB, we consider them together. In such\n  // case, Cost(merging BB) will be the sum of their frequencies.\n\n  if (!isa<PHINode>(DestBB->begin()))\n    return true;\n\n  SmallPtrSet<BasicBlock *, 16> SameIncomingValueBBs;\n\n  // Find all other incoming blocks from which incoming values of all PHIs in\n  // DestBB are the same as the ones from BB.\n  for (BasicBlock *DestBBPred : predecessors(DestBB)) {\n    if (DestBBPred == BB)\n      continue;\n\n    if (llvm::all_of(DestBB->phis(), [&](const PHINode &DestPN) {\n          return DestPN.getIncomingValueForBlock(BB) ==\n                 DestPN.getIncomingValueForBlock(DestBBPred);\n        }))\n      SameIncomingValueBBs.insert(DestBBPred);\n  }\n\n  // See if all BB's incoming values are same as the value from Pred. In this\n  // case, no reason to skip merging because COPYs are expected to be place in\n  // Pred already.\n  if (SameIncomingValueBBs.count(Pred))\n    return true;\n\n  BlockFrequency PredFreq = BFI->getBlockFreq(Pred);\n  BlockFrequency BBFreq = BFI->getBlockFreq(BB);\n\n  for (auto *SameValueBB : SameIncomingValueBBs)\n    if (SameValueBB->getUniquePredecessor() == Pred &&\n        DestBB == findDestBlockOfMergeableEmptyBlock(SameValueBB))\n      BBFreq += BFI->getBlockFreq(SameValueBB);\n\n  std::optional<BlockFrequency> Limit = BBFreq.mul(FreqRatioToSkipMerge);\n  return !Limit || PredFreq <= *Limit;\n}\n\n/// Return true if we can merge BB into DestBB if there is a single\n/// unconditional branch between them, and BB contains no other non-phi\n/// instructions.\nbool CodeGenPrepare::canMergeBlocks(const BasicBlock *BB,\n                                    const BasicBlock *DestBB) const {\n  // We only want to eliminate blocks whose phi nodes are used by phi nodes in\n  // the successor.  If there are more complex condition (e.g. preheaders),\n  // don't mess around with them.\n  for (const PHINode &PN : BB->phis()) {\n    for (const User *U : PN.users()) {\n      const Instruction *UI = cast<Instruction>(U);\n      if (UI->getParent() != DestBB || !isa<PHINode>(UI))\n        return false;\n      // If User is inside DestBB block and it is a PHINode then check\n      // incoming value. If incoming value is not from BB then this is\n      // a complex condition (e.g. preheaders) we want to avoid here.\n      if (UI->getParent() == DestBB) {\n        if (const PHINode *UPN = dyn_cast<PHINode>(UI))\n          for (unsigned I = 0, E = UPN->getNumIncomingValues(); I != E; ++I) {\n            Instruction *Insn = dyn_cast<Instruction>(UPN->getIncomingValue(I));\n            if (Insn && Insn->getParent() == BB &&\n                Insn->getParent() != UPN->getIncomingBlock(I))\n              return false;\n          }\n      }\n    }\n  }\n\n  // If BB and DestBB contain any common predecessors, then the phi nodes in BB\n  // and DestBB may have conflicting incoming values for the block.  If so, we\n  // can't merge the block.\n  const PHINode *DestBBPN = dyn_cast<PHINode>(DestBB->begin());\n  if (!DestBBPN)\n    return true; // no conflict.\n\n  // Collect the preds of BB.\n  SmallPtrSet<const BasicBlock *, 16> BBPreds;\n  if (const PHINode *BBPN = dyn_cast<PHINode>(BB->begin())) {\n    // It is faster to get preds from a PHI than with pred_iterator.\n    for (unsigned i = 0, e = BBPN->getNumIncomingValues(); i != e; ++i)\n      BBPreds.insert(BBPN->getIncomingBlock(i));\n"}], "code": "void TargetPassConfig::addCodeGenPrepare() {\n  if (getOptLevel() != CodeGenOptLevel::None && !DisableCGP)\n    addPass(createCodeGenPrepareLegacyPass());\n}\n"}, "41446EA1547D3DBE": {"calls": [{"id": "46A3E760C965F26A", "name": "llvm::TargetLoweringBase::isTruncateFree", "path": "llvm-project/llvm/include/llvm/CodeGen/TargetLowering.h", "start": {"line": 2857, "col": 3}, "end": {"line": 2857, "col": 75}, "code": "  virtual bool isTruncateFree(LLT FromTy, LLT ToTy, const DataLayout &DL,\n                              LLVMContext &Ctx) const {\n    return isTruncateFree(getApproximateEVTForLLT(FromTy, DL, Ctx),\n                          getApproximateEVTForLLT(ToTy, DL, Ctx));\n  }\n\n  /// Return true if truncating the specific node Val to type VT2 is free.\n  virtual bool isTruncateFree(SDValue Val, EVT VT2) const {\n    // Fallback to type matching.\n    return isTruncateFree(Val.getValueType(), VT2);\n  }\n\n  virtual bool isProfitableToHoist(Instruction *I) const { return true; }\n\n  /// Return true if the extension represented by \\p I is free.\n  /// Unlikely the is[Z|FP]ExtFree family which is based on types,\n  /// this method can use the context provided by \\p I to decide\n  /// whether or not \\p I is free.\n  /// This method extends the behavior of the is[Z|FP]ExtFree family.\n  /// In other words, if is[Z|FP]Free returns true, then this method\n  /// returns true as well. The converse is not true.\n  /// The target can perform the adequate checks by overriding isExtFreeImpl.\n  /// \\pre \\p I must be a sign, zero, or fp extension.\n  bool isExtFree(const Instruction *I) const {\n    switch (I->getOpcode()) {\n    case Instruction::FPExt:\n      if (isFPExtFree(EVT::getEVT(I->getType()),\n                      EVT::getEVT(I->getOperand(0)->getType())))\n        return true;\n      break;\n    case Instruction::ZExt:\n      if (isZExtFree(I->getOperand(0)->getType(), I->getType()))\n        return true;\n      break;\n    case Instruction::SExt:\n      break;\n    default:\n      llvm_unreachable(\"Instruction is not an extension\");\n    }\n    return isExtFreeImpl(I);\n  }\n\n  /// Return true if \\p Load and \\p Ext can form an ExtLoad.\n  /// For example, in AArch64\n  ///   %L = load i8, i8* %ptr\n  ///   %E = zext i8 %L to i32\n  /// can be lowered into one load instruction\n  ///   ldrb w0, [x0]\n  bool isExtLoad(const LoadInst *Load, const Instruction *Ext,\n                 const DataLayout &DL) const {\n    EVT VT = getValueType(DL, Ext->getType());\n    EVT LoadVT = getValueType(DL, Load->getType());\n\n    // If the load has other users and the truncate is not free, the ext\n    // probably isn't free.\n    if (!Load->hasOneUse() && (isTypeLegal(LoadVT) || !isTypeLegal(VT)) &&\n        !isTruncateFree(Ext->getType(), Load->getType()))\n      return false;\n\n    // Check whether the target supports casts folded into loads.\n    unsigned LType;\n    if (isa<ZExtInst>(Ext))\n      LType = ISD::ZEXTLOAD;\n    else {\n      assert(isa<SExtInst>(Ext) && \"Unexpected ext type!\");\n      LType = ISD::SEXTLOAD;\n    }\n\n    return isLoadExtLegal(LType, VT, LoadVT);\n  }\n\n  /// Return true if any actual instruction that defines a value of type FromTy\n  /// implicitly zero-extends the value to ToTy in the result register.\n  ///\n  /// The function should return true when it is likely that the truncate can\n  /// be freely folded with an instruction defining a value of FromTy. If\n  /// the defining instruction is unknown (because you're looking at a\n  /// function argument, PHI, etc.) then the target may require an\n  /// explicit truncate, which is not necessarily free, but this function\n  /// does not deal with those cases.\n  /// Targets must return false when FromTy >= ToTy.\n  virtual bool isZExtFree(Type *FromTy, Type *ToTy) const {\n    return false;\n  }\n\n  virtual bool isZExtFree(EVT FromTy, EVT ToTy) const { return false; }\n  virtual bool isZExtFree(LLT FromTy, LLT ToTy, const DataLayout &DL,\n                          LLVMContext &Ctx) const {\n    return isZExtFree(getApproximateEVTForLLT(FromTy, DL, Ctx),\n                      getApproximateEVTForLLT(ToTy, DL, Ctx));\n  }\n\n  /// Return true if zero-extending the specific node Val to type VT2 is free\n  /// (either because it's implicitly zero-extended such as ARM ldrb / ldrh or\n  /// because it's folded such as X86 zero-extending loads).\n  virtual bool isZExtFree(SDValue Val, EVT VT2) const {\n    return isZExtFree(Val.getValueType(), VT2);\n  }\n\n  /// Return true if sign-extension from FromTy to ToTy is cheaper than\n  /// zero-extension.\n  virtual bool isSExtCheaperThanZExt(EVT FromTy, EVT ToTy) const {\n    return false;\n  }\n\n  /// Return true if this constant should be sign extended when promoting to\n  /// a larger type.\n  virtual bool signExtendConstant(const ConstantInt *C) const { return false; }\n\n  /// Return true if sinking I's operands to the same basic block as I is\n  /// profitable, e.g. because the operands can be folded into a target\n  /// instruction during instruction selection. After calling the function\n  /// \\p Ops contains the Uses to sink ordered by dominance (dominating users\n  /// come first).\n  virtual bool shouldSinkOperands(Instruction *I,\n                                  SmallVectorImpl<Use *> &Ops) const {\n    return false;\n  }\n\n  /// Try to optimize extending or truncating conversion instructions (like\n  /// zext, trunc, fptoui, uitofp) for the target.\n  virtual bool\n  optimizeExtendOrTruncateConversion(Instruction *I, Loop *L,\n                                     const TargetTransformInfo &TTI) const {\n    return false;\n  }\n\n  /// Return true if the target supplies and combines to a paired load\n  /// two loaded values of type LoadedType next to each other in memory.\n  /// RequiredAlignment gives the minimal alignment constraints that must be met\n  /// to be able to select this paired load.\n  ///\n  /// This information is *not* used to generate actual paired loads, but it is\n  /// used to generate a sequence of loads that is easier to combine into a\n  /// paired load.\n  /// For instance, something like this:\n  /// a = load i64* addr\n  /// b = trunc i64 a to i32\n  /// c = lshr i64 a, 32\n  /// d = trunc i64 c to i32\n  /// will be optimized into:\n  /// b = load i32* addr1\n  /// d = load i32* addr2\n  /// Where addr1 = addr2 +/- sizeof(i32).\n  ///\n  /// In other words, unless the target performs a post-isel load combining,\n  /// this information should not be provided because it will generate more\n  /// loads.\n  virtual bool hasPairedLoad(EVT /*LoadedType*/,\n                             Align & /*RequiredAlignment*/) const {\n    return false;\n  }\n\n  /// Return true if the target has a vector blend instruction.\n  virtual bool hasVectorBlend() const { return false; }\n\n  /// Get the maximum supported factor for interleaved memory accesses.\n  /// Default to be the minimum interleave factor: 2.\n  virtual unsigned getMaxSupportedInterleaveFactor() const { return 2; }\n\n  /// Lower an interleaved load to target specific intrinsics. Return\n  /// true on success.\n  ///\n  /// \\p LI is the vector load instruction.\n  /// \\p Shuffles is the shufflevector list to DE-interleave the loaded vector.\n  /// \\p Indices is the corresponding indices for each shufflevector.\n  /// \\p Factor is the interleave factor.\n  virtual bool lowerInterleavedLoad(LoadInst *LI,\n                                    ArrayRef<ShuffleVectorInst *> Shuffles,\n                                    ArrayRef<unsigned> Indices,\n                                    unsigned Factor) const {\n    return false;\n  }\n\n  /// Lower an interleaved store to target specific intrinsics. Return\n  /// true on success.\n  ///\n  /// \\p SI is the vector store instruction.\n  /// \\p SVI is the shufflevector to RE-interleave the stored vector.\n  /// \\p Factor is the interleave factor.\n  virtual bool lowerInterleavedStore(StoreInst *SI, ShuffleVectorInst *SVI,\n                                     unsigned Factor) const {\n    return false;\n  }\n\n  /// Lower a deinterleave intrinsic to a target specific load intrinsic.\n  /// Return true on success. Currently only supports\n  /// llvm.experimental.vector.deinterleave2\n  ///\n  /// \\p DI is the deinterleave intrinsic.\n  /// \\p LI is the accompanying load instruction\n  virtual bool lowerDeinterleaveIntrinsicToLoad(IntrinsicInst *DI,\n                                                LoadInst *LI) const {\n    return false;\n  }\n\n  /// Lower an interleave intrinsic to a target specific store intrinsic.\n  /// Return true on success. Currently only supports\n  /// llvm.experimental.vector.interleave2\n  ///\n  /// \\p II is the interleave intrinsic.\n  /// \\p SI is the accompanying store instruction\n  virtual bool lowerInterleaveIntrinsicToStore(IntrinsicInst *II,\n                                               StoreInst *SI) const {\n    return false;\n  }\n\n  /// Return true if an fpext operation is free (for instance, because\n  /// single-precision floating-point numbers are implicitly extended to\n  /// double-precision).\n  virtual bool isFPExtFree(EVT DestVT, EVT SrcVT) const {\n    assert(SrcVT.isFloatingPoint() && DestVT.isFloatingPoint() &&\n           \"invalid fpext types\");\n    return false;\n  }\n\n  /// Return true if an fpext operation input to an \\p Opcode operation is free\n  /// (for instance, because half-precision floating-point numbers are\n  /// implicitly extended to float-precision) for an FMA instruction.\n  virtual bool isFPExtFoldable(const MachineInstr &MI, unsigned Opcode,\n                               LLT DestTy, LLT SrcTy) const {\n    return false;\n  }\n\n  /// Return true if an fpext operation input to an \\p Opcode operation is free\n  /// (for instance, because half-precision floating-point numbers are\n  /// implicitly extended to float-precision) for an FMA instruction.\n  virtual bool isFPExtFoldable(const SelectionDAG &DAG, unsigned Opcode,\n                               EVT DestVT, EVT SrcVT) const {\n    assert(DestVT.isFloatingPoint() && SrcVT.isFloatingPoint() &&\n           \"invalid fpext types\");\n    return isFPExtFree(DestVT, SrcVT);\n  }\n\n  /// Return true if folding a vector load into ExtVal (a sign, zero, or any\n  /// extend node) is profitable.\n  virtual bool isVectorLoadExtDesirable(SDValue ExtVal) const { return false; }\n\n  /// Return true if an fneg operation is free to the point where it is never\n  /// worthwhile to replace it with a bitwise operation.\n  virtual bool isFNegFree(EVT VT) const {\n    assert(VT.isFloatingPoint());\n    return false;\n  }\n\n  /// Return true if an fabs operation is free to the point where it is never\n  /// worthwhile to replace it with a bitwise operation.\n  virtual bool isFAbsFree(EVT VT) const {\n    assert(VT.isFloatingPoint());\n    return false;\n  }\n\n  /// Return true if an FMA operation is faster than a pair of fmul and fadd\n  /// instructions. fmuladd intrinsics will be expanded to FMAs when this method\n  /// returns true, otherwise fmuladd is expanded to fmul + fadd.\n  ///\n  /// NOTE: This may be called before legalization on types for which FMAs are\n  /// not legal, but should return true if those types will eventually legalize\n  /// to types that support FMAs. After legalization, it will only be called on\n  /// types that support FMAs (via Legal or Custom actions)\n  virtual bool isFMAFasterThanFMulAndFAdd(const MachineFunction &MF,\n                                          EVT) const {\n    return false;\n  }\n\n  /// Return true if an FMA operation is faster than a pair of fmul and fadd\n  /// instructions. fmuladd intrinsics will be expanded to FMAs when this method\n  /// returns true, otherwise fmuladd is expanded to fmul + fadd.\n  ///\n  /// NOTE: This may be called before legalization on types for which FMAs are\n  /// not legal, but should return true if those types will eventually legalize\n  /// to types that support FMAs. After legalization, it will only be called on\n  /// types that support FMAs (via Legal or Custom actions)\n  virtual bool isFMAFasterThanFMulAndFAdd(const MachineFunction &MF,\n                                          LLT) const {\n    return false;\n  }\n\n  /// IR version\n  virtual bool isFMAFasterThanFMulAndFAdd(const Function &F, Type *) const {\n    return false;\n  }\n\n  /// Returns true if \\p MI can be combined with another instruction to\n  /// form TargetOpcode::G_FMAD. \\p N may be an TargetOpcode::G_FADD,\n  /// TargetOpcode::G_FSUB, or an TargetOpcode::G_FMUL which will be\n  /// distributed into an fadd/fsub.\n  virtual bool isFMADLegal(const MachineInstr &MI, LLT Ty) const {\n    assert((MI.getOpcode() == TargetOpcode::G_FADD ||\n            MI.getOpcode() == TargetOpcode::G_FSUB ||\n            MI.getOpcode() == TargetOpcode::G_FMUL) &&\n           \"unexpected node in FMAD forming combine\");\n    switch (Ty.getScalarSizeInBits()) {\n    case 16:\n      return isOperationLegal(TargetOpcode::G_FMAD, MVT::f16);\n    case 32:\n      return isOperationLegal(TargetOpcode::G_FMAD, MVT::f32);\n    case 64:\n      return isOperationLegal(TargetOpcode::G_FMAD, MVT::f64);\n    default:\n      break;\n    }\n\n    return false;\n  }\n\n  /// Returns true if be combined with to form an ISD::FMAD. \\p N may be an\n  /// ISD::FADD, ISD::FSUB, or an ISD::FMUL which will be distributed into an\n  /// fadd/fsub.\n  virtual bool isFMADLegal(const SelectionDAG &DAG, const SDNode *N) const {\n    assert((N->getOpcode() == ISD::FADD || N->getOpcode() == ISD::FSUB ||\n            N->getOpcode() == ISD::FMUL) &&\n           \"unexpected node in FMAD forming combine\");\n    return isOperationLegal(ISD::FMAD, N->getValueType(0));\n  }\n\n  // Return true when the decision to generate FMA's (or FMS, FMLA etc) rather\n  // than FMUL and ADD is delegated to the machine combiner.\n  virtual bool generateFMAsInMachineCombiner(EVT VT,\n                                             CodeGenOptLevel OptLevel) const {\n    return false;\n  }\n\n  /// Return true if it's profitable to narrow operations of type SrcVT to\n  /// DestVT. e.g. on x86, it's profitable to narrow from i32 to i8 but not from\n  /// i32 to i16.\n  virtual bool isNarrowingProfitable(EVT SrcVT, EVT DestVT) const {\n    return false;\n  }\n\n  /// Return true if pulling a binary operation into a select with an identity\n  /// constant is profitable. This is the inverse of an IR transform.\n  /// Example: X + (Cond ? Y : 0) --> Cond ? (X + Y) : X\n  virtual bool shouldFoldSelectWithIdentityConstant(unsigned BinOpcode,\n                                                    EVT VT) const {\n    return false;\n  }\n\n  /// Return true if it is beneficial to convert a load of a constant to\n  /// just the constant itself.\n  /// On some targets it might be more efficient to use a combination of\n  /// arithmetic instructions to materialize the constant instead of loading it\n  /// from a constant pool.\n  virtual bool shouldConvertConstantLoadToIntImm(const APInt &Imm,\n                                                 Type *Ty) const {\n    return false;\n  }\n\n  /// Return true if EXTRACT_SUBVECTOR is cheap for extracting this result type\n  /// from this source type with this index. This is needed because\n  /// EXTRACT_SUBVECTOR usually has custom lowering that depends on the index of\n  /// the first element, and only the target knows which lowering is cheap.\n  virtual bool isExtractSubvectorCheap(EVT ResVT, EVT SrcVT,\n                                       unsigned Index) const {\n    return false;\n  }\n\n  /// Try to convert an extract element of a vector binary operation into an\n  /// extract element followed by a scalar operation.\n  virtual bool shouldScalarizeBinop(SDValue VecOp) const {\n    return false;\n  }\n\n  /// Return true if extraction of a scalar element from the given vector type\n  /// at the given index is cheap. For example, if scalar operations occur on\n  /// the same register file as vector operations, then an extract element may\n  /// be a sub-register rename rather than an actual instruction.\n  virtual bool isExtractVecEltCheap(EVT VT, unsigned Index) const {\n    return false;\n  }\n\n  /// Try to convert math with an overflow comparison into the corresponding DAG\n  /// node operation. Targets may want to override this independently of whether\n  /// the operation is legal/custom for the given type because it may obscure\n  /// matching of other patterns.\n  virtual bool shouldFormOverflowOp(unsigned Opcode, EVT VT,\n                                    bool MathUsed) const {\n    // TODO: The default logic is inherited from code in CodeGenPrepare.\n    // The opcode should not make a difference by default?\n    if (Opcode != ISD::UADDO)\n      return false;\n\n    // Allow the transform as long as we have an integer type that is not\n    // obviously illegal and unsupported and if the math result is used\n    // besides the overflow check. On some targets (e.g. SPARC), it is\n    // not profitable to form on overflow op if the math result has no\n    // concrete users.\n    if (VT.isVector())\n      return false;\n    return MathUsed && (VT.isSimple() || !isOperationExpand(Opcode, VT));\n  }\n\n  // Return true if it is profitable to use a scalar input to a BUILD_VECTOR\n  // even if the vector itself has multiple uses.\n  virtual bool aggressivelyPreferBuildVectorSources(EVT VecVT) const {\n    return false;\n  }\n\n  // Return true if CodeGenPrepare should consider splitting large offset of a\n  // GEP to make the GEP fit into the addressing mode and can be sunk into the\n  // same blocks of its users.\n  virtual bool shouldConsiderGEPOffsetSplit() const { return false; }\n\n  /// Return true if creating a shift of the type by the given\n  /// amount is not profitable.\n  virtual bool shouldAvoidTransformToShift(EVT VT, unsigned Amount) const {\n    return false;\n  }\n\n  // Should we fold (select_cc seteq (and x, y), 0, 0, A) -> (and (sra (shl x))\n  // A) where y has a single bit set?\n  virtual bool shouldFoldSelectWithSingleBitTest(EVT VT,\n                                                 const APInt &AndMask) const {\n    unsigned ShCt = AndMask.getBitWidth() - 1;\n    return !shouldAvoidTransformToShift(VT, ShCt);\n  }\n\n  /// Does this target require the clearing of high-order bits in a register\n  /// passed to the fp16 to fp conversion library function.\n  virtual bool shouldKeepZExtForFP16Conv() const { return false; }\n\n  /// Should we generate fp_to_si_sat and fp_to_ui_sat from type FPVT to type VT\n  /// from min(max(fptoi)) saturation patterns.\n  virtual bool shouldConvertFpToSat(unsigned Op, EVT FPVT, EVT VT) const {\n    return isOperationLegalOrCustom(Op, VT);\n  }\n\n  /// Does this target support complex deinterleaving\n  virtual bool isComplexDeinterleavingSupported() const { return false; }\n\n  /// Does this target support complex deinterleaving with the given operation\n  /// and type\n  virtual bool isComplexDeinterleavingOperationSupported(\n      ComplexDeinterleavingOperation Operation, Type *Ty) const {\n    return false;\n  }\n\n  /// Create the IR node for the given complex deinterleaving operation.\n  /// If one cannot be created using all the given inputs, nullptr should be\n  /// returned.\n  virtual Value *createComplexDeinterleavingIR(\n      IRBuilderBase &B, ComplexDeinterleavingOperation OperationType,\n      ComplexDeinterleavingRotation Rotation, Value *InputA, Value *InputB,\n      Value *Accumulator = nullptr) const {\n    return nullptr;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Runtime Library hooks\n  //\n\n  /// Rename the default libcall routine name for the specified libcall.\n  void setLibcallName(RTLIB::Libcall Call, const char *Name) {\n    LibcallRoutineNames[Call] = Name;\n  }\n  void setLibcallName(ArrayRef<RTLIB::Libcall> Calls, const char *Name) {\n    for (auto Call : Calls)\n      setLibcallName(Call, Name);\n  }\n\n  /// Get the libcall routine name for the specified libcall.\n  const char *getLibcallName(RTLIB::Libcall Call) const {\n    return LibcallRoutineNames[Call];\n  }\n\n  /// Override the default CondCode to be used to test the result of the\n  /// comparison libcall against zero.\n  void setCmpLibcallCC(RTLIB::Libcall Call, ISD::CondCode CC) {\n    CmpLibcallCCs[Call] = CC;\n  }\n\n  /// Get the CondCode that's to be used to test the result of the comparison\n  /// libcall against zero.\n  ISD::CondCode getCmpLibcallCC(RTLIB::Libcall Call) const {\n    return CmpLibcallCCs[Call];\n  }\n\n  /// Set the CallingConv that should be used for the specified libcall.\n  void setLibcallCallingConv(RTLIB::Libcall Call, CallingConv::ID CC) {\n    LibcallCallingConvs[Call] = CC;\n  }\n\n  /// Get the CallingConv that should be used for the specified libcall.\n  CallingConv::ID getLibcallCallingConv(RTLIB::Libcall Call) const {\n    return LibcallCallingConvs[Call];\n  }\n\n  /// Execute target specific actions to finalize target lowering.\n  /// This is used to set extra flags in MachineFrameInformation and freezing\n  /// the set of reserved registers.\n  /// The default implementation just freezes the set of reserved registers.\n  virtual void finalizeLowering(MachineFunction &MF) const;\n\n  //===----------------------------------------------------------------------===//\n  //  GlobalISel Hooks\n  //===----------------------------------------------------------------------===//\n  /// Check whether or not \\p MI needs to be moved close to its uses.\n  virtual bool shouldLocalize(const MachineInstr &MI, const TargetTransformInfo *TTI) const;\n\n\nprivate:\n  const TargetMachine &TM;\n\n  /// Tells the code generator that the target has multiple (allocatable)\n  /// condition registers that can be used to store the results of comparisons\n  /// for use by selects and conditional branches. With multiple condition\n  /// registers, the code generator will not aggressively sink comparisons into\n  /// the blocks of their users.\n  bool HasMultipleConditionRegisters;\n\n  /// Tells the code generator that the target has BitExtract instructions.\n  /// The code generator will aggressively sink \"shift\"s into the blocks of\n  /// their users if the users will generate \"and\" instructions which can be\n  /// combined with \"shift\" to BitExtract instructions.\n  bool HasExtractBitsInsn;\n\n  /// Tells the code generator to bypass slow divide or remainder\n  /// instructions. For example, BypassSlowDivWidths[32,8] tells the code\n  /// generator to bypass 32-bit integer div/rem with an 8-bit unsigned integer\n  /// div/rem when the operands are positive and less than 256.\n  DenseMap <unsigned int, unsigned int> BypassSlowDivWidths;\n\n  /// Tells the code generator that it shouldn't generate extra flow control\n  /// instructions and should attempt to combine flow control instructions via\n  /// predication.\n  bool JumpIsExpensive;\n\n  /// Information about the contents of the high-bits in boolean values held in\n  /// a type wider than i1. See getBooleanContents.\n  BooleanContent BooleanContents;\n\n  /// Information about the contents of the high-bits in boolean values held in\n  /// a type wider than i1. See getBooleanContents.\n  BooleanContent BooleanFloatContents;\n\n  /// Information about the contents of the high-bits in boolean vector values\n  /// when the element type is wider than i1. See getBooleanContents.\n  BooleanContent BooleanVectorContents;\n\n  /// The target scheduling preference: shortest possible total cycles or lowest\n  /// register usage.\n  Sched::Preference SchedPreferenceInfo;\n\n  /// The minimum alignment that any argument on the stack needs to have.\n  Align MinStackArgumentAlignment;\n\n  /// The minimum function alignment (used when optimizing for size, and to\n  /// prevent explicitly provided alignment from leading to incorrect code).\n  Align MinFunctionAlignment;\n\n  /// The preferred function alignment (used when alignment unspecified and\n  /// optimizing for speed).\n  Align PrefFunctionAlignment;\n\n  /// The preferred loop alignment (in log2 bot in bytes).\n  Align PrefLoopAlignment;\n  /// The maximum amount of bytes permitted to be emitted for alignment.\n  unsigned MaxBytesForAlignment;\n\n  /// Size in bits of the maximum atomics size the backend supports.\n  /// Accesses larger than this will be expanded by AtomicExpandPass.\n  unsigned MaxAtomicSizeInBitsSupported;\n\n  /// Size in bits of the maximum div/rem size the backend supports.\n  /// Larger operations will be expanded by ExpandLargeDivRem.\n  unsigned MaxDivRemBitWidthSupported;\n\n  /// Size in bits of the maximum larget fp convert size the backend\n  /// supports. Larger operations will be expanded by ExpandLargeFPConvert.\n  unsigned MaxLargeFPConvertBitWidthSupported;\n\n  /// Size in bits of the minimum cmpxchg or ll/sc operation the\n  /// backend supports.\n  unsigned MinCmpXchgSizeInBits;\n\n  /// This indicates if the target supports unaligned atomic operations.\n  bool SupportsUnalignedAtomics;\n\n  /// If set to a physical register, this specifies the register that\n  /// llvm.savestack/llvm.restorestack should save and restore.\n  Register StackPointerRegisterToSaveRestore;\n\n  /// This indicates the default register class to use for each ValueType the\n  /// target supports natively.\n  const TargetRegisterClass *RegClassForVT[MVT::VALUETYPE_SIZE];\n  uint16_t NumRegistersForVT[MVT::VALUETYPE_SIZE];\n  MVT RegisterTypeForVT[MVT::VALUETYPE_SIZE];\n\n  /// This indicates the \"representative\" register class to use for each\n  /// ValueType the target supports natively. This information is used by the\n  /// scheduler to track register pressure. By default, the representative\n  /// register class is the largest legal super-reg register class of the\n  /// register class of the specified type. e.g. On x86, i8, i16, and i32's\n  /// representative class would be GR32.\n  const TargetRegisterClass *RepRegClassForVT[MVT::VALUETYPE_SIZE] = {0};\n\n  /// This indicates the \"cost\" of the \"representative\" register class for each\n  /// ValueType. The cost is used by the scheduler to approximate register\n  /// pressure.\n  uint8_t RepRegClassCostForVT[MVT::VALUETYPE_SIZE];\n\n  /// For any value types we are promoting or expanding, this contains the value\n  /// type that we are changing to.  For Expanded types, this contains one step\n  /// of the expand (e.g. i64 -> i32), even if there are multiple steps required\n  /// (e.g. i64 -> i16).  For types natively supported by the system, this holds\n  /// the same type (e.g. i32 -> i32).\n  MVT TransformToType[MVT::VALUETYPE_SIZE];\n\n  /// For each operation and each value type, keep a LegalizeAction that\n  /// indicates how instruction selection should deal with the operation.  Most\n  /// operations are Legal (aka, supported natively by the target), but\n  /// operations that are not should be described.  Note that operations on\n  /// non-legal value types are not described here.\n  LegalizeAction OpActions[MVT::VALUETYPE_SIZE][ISD::BUILTIN_OP_END];\n\n  /// For each load extension type and each value type, keep a LegalizeAction\n  /// that indicates how instruction selection should deal with a load of a\n  /// specific value type and extension type. Uses 4-bits to store the action\n  /// for each of the 4 load ext types.\n  uint16_t LoadExtActions[MVT::VALUETYPE_SIZE][MVT::VALUETYPE_SIZE];\n\n  /// For each value type pair keep a LegalizeAction that indicates whether a\n  /// truncating store of a specific value type and truncating type is legal.\n  LegalizeAction TruncStoreActions[MVT::VALUETYPE_SIZE][MVT::VALUETYPE_SIZE];\n\n  /// For each indexed mode and each value type, keep a quad of LegalizeAction\n  /// that indicates how instruction selection should deal with the load /\n  /// store / maskedload / maskedstore.\n  ///\n  /// The first dimension is the value_type for the reference. The second\n  /// dimension represents the various modes for load store.\n  uint16_t IndexedModeActions[MVT::VALUETYPE_SIZE][ISD::LAST_INDEXED_MODE];\n\n  /// For each condition code (ISD::CondCode) keep a LegalizeAction that\n  /// indicates how instruction selection should deal with the condition code.\n  ///\n  /// Because each CC action takes up 4 bits, we need to have the array size be\n  /// large enough to fit all of the value types. This can be done by rounding\n  /// up the MVT::VALUETYPE_SIZE value to the next multiple of 8.\n  uint32_t CondCodeActions[ISD::SETCC_INVALID][(MVT::VALUETYPE_SIZE + 7) / 8];\n\n  ValueTypeActionImpl ValueTypeActions;\n\nprivate:\n  /// Targets can specify ISD nodes that they would like PerformDAGCombine\n  /// callbacks for by calling setTargetDAGCombine(), which sets a bit in this\n  /// array.\n  unsigned char\n  TargetDAGCombineArray[(ISD::BUILTIN_OP_END+CHAR_BIT-1)/CHAR_BIT];\n\n  /// For operations that must be promoted to a specific type, this holds the\n  /// destination type.  This map should be sparse, so don't hold it as an\n  /// array.\n  ///\n  /// Targets add entries to this map with AddPromotedToType(..), clients access\n  /// this with getTypeToPromoteTo(..).\n  std::map<std::pair<unsigned, MVT::SimpleValueType>, MVT::SimpleValueType>\n    PromoteToType;\n\n  /// Stores the name each libcall.\n  const char *LibcallRoutineNames[RTLIB::UNKNOWN_LIBCALL + 1];\n\n  /// The ISD::CondCode that should be used to test the result of each of the\n  /// comparison libcall against zero.\n  ISD::CondCode CmpLibcallCCs[RTLIB::UNKNOWN_LIBCALL];\n\n  /// Stores the CallingConv that should be used for each libcall.\n  CallingConv::ID LibcallCallingConvs[RTLIB::UNKNOWN_LIBCALL];\n\n  /// Set default libcall names and calling conventions.\n  void InitLibcalls(const Triple &TT);\n\n  /// The bits of IndexedModeActions used to store the legalisation actions\n  /// We store the data as   | ML | MS |  L |  S | each taking 4 bits.\n  enum IndexedModeActionsBits {\n    IMAB_Store = 0,\n    IMAB_Load = 4,\n    IMAB_MaskedStore = 8,\n    IMAB_MaskedLoad = 12\n  };\n\n  void setIndexedModeAction(unsigned IdxMode, MVT VT, unsigned Shift,\n                            LegalizeAction Action) {\n    assert(VT.isValid() && IdxMode < ISD::LAST_INDEXED_MODE &&\n           (unsigned)Action < 0xf && \"Table isn't big enough!\");\n    unsigned Ty = (unsigned)VT.SimpleTy;\n    IndexedModeActions[Ty][IdxMode] &= ~(0xf << Shift);\n    IndexedModeActions[Ty][IdxMode] |= ((uint16_t)Action) << Shift;\n  }\n\n  LegalizeAction getIndexedModeAction(unsigned IdxMode, MVT VT,\n                                      unsigned Shift) const {\n    assert(IdxMode < ISD::LAST_INDEXED_MODE && VT.isValid() &&\n           \"Table isn't big enough!\");\n    unsigned Ty = (unsigned)VT.SimpleTy;\n    return (LegalizeAction)((IndexedModeActions[Ty][IdxMode] >> Shift) & 0xf);\n  }\n\nprotected:\n  /// Return true if the extension represented by \\p I is free.\n  /// \\pre \\p I is a sign, zero, or fp extension and\n  ///      is[Z|FP]ExtFree of the related types is not true.\n  virtual bool isExtFreeImpl(const Instruction *I) const { return false; }\n\n  /// Depth that GatherAllAliases should continue looking for chain\n  /// dependencies when trying to find a more preferable chain. As an\n  /// approximation, this should be more than the number of consecutive stores\n  /// expected to be merged.\n  unsigned GatherAllAliasesMaxDepth;\n\n  /// \\brief Specify maximum number of store instructions per memset call.\n  ///\n  /// When lowering \\@llvm.memset this field specifies the maximum number of\n  /// store operations that may be substituted for the call to memset. Targets\n  /// must set this value based on the cost threshold for that target. Targets\n  /// should assume that the memset will be done using as many of the largest\n  /// store operations first, followed by smaller ones, if necessary, per\n  /// alignment restrictions. For example, storing 9 bytes on a 32-bit machine\n  /// with 16-bit alignment would result in four 2-byte stores and one 1-byte\n  /// store.  This only applies to setting a constant array of a constant size.\n  unsigned MaxStoresPerMemset;\n  /// Likewise for functions with the OptSize attribute.\n  unsigned MaxStoresPerMemsetOptSize;\n\n  /// \\brief Specify maximum number of store instructions per memcpy call.\n  ///\n  /// When lowering \\@llvm.memcpy this field specifies the maximum number of\n  /// store operations that may be substituted for a call to memcpy. Targets\n  /// must set this value based on the cost threshold for that target. Targets\n  /// should assume that the memcpy will be done using as many of the largest\n  /// store operations first, followed by smaller ones, if necessary, per\n  /// alignment restrictions. For example, storing 7 bytes on a 32-bit machine\n  /// with 32-bit alignment would result in one 4-byte store, a one 2-byte store\n  /// and one 1-byte store. This only applies to copying a constant array of\n  /// constant size.\n  unsigned MaxStoresPerMemcpy;\n  /// Likewise for functions with the OptSize attribute.\n  unsigned MaxStoresPerMemcpyOptSize;\n  /// \\brief Specify max number of store instructions to glue in inlined memcpy.\n  ///\n  /// When memcpy is inlined based on MaxStoresPerMemcpy, specify maximum number\n  /// of store instructions to keep together. This helps in pairing and\n  //  vectorization later on.\n  unsigned MaxGluedStoresPerMemcpy = 0;\n\n  /// \\brief Specify maximum number of load instructions per memcmp call.\n  ///\n  /// When lowering \\@llvm.memcmp this field specifies the maximum number of\n  /// pairs of load operations that may be substituted for a call to memcmp.\n  /// Targets must set this value based on the cost threshold for that target.\n  /// Targets should assume that the memcmp will be done using as many of the\n  /// largest load operations first, followed by smaller ones, if necessary, per\n  /// alignment restrictions. For example, loading 7 bytes on a 32-bit machine\n  /// with 32-bit alignment would result in one 4-byte load, a one 2-byte load\n  /// and one 1-byte load. This only applies to copying a constant array of\n  /// constant size.\n  unsigned MaxLoadsPerMemcmp;\n  /// Likewise for functions with the OptSize attribute.\n  unsigned MaxLoadsPerMemcmpOptSize;\n\n  /// \\brief Specify maximum number of store instructions per memmove call.\n  ///\n  /// When lowering \\@llvm.memmove this field specifies the maximum number of\n  /// store instructions that may be substituted for a call to memmove. Targets\n  /// must set this value based on the cost threshold for that target. Targets\n  /// should assume that the memmove will be done using as many of the largest\n  /// store operations first, followed by smaller ones, if necessary, per\n  /// alignment restrictions. For example, moving 9 bytes on a 32-bit machine\n  /// with 8-bit alignment would result in nine 1-byte stores.  This only\n  /// applies to copying a constant array of constant size.\n  unsigned MaxStoresPerMemmove;\n  /// Likewise for functions with the OptSize attribute.\n  unsigned MaxStoresPerMemmoveOptSize;\n\n  /// Tells the code generator that select is more expensive than a branch if\n  /// the branch is usually predicted right.\n  bool PredictableSelectIsExpensive;\n\n  /// \\see enableExtLdPromotion.\n  bool EnableExtLdPromotion;\n\n  /// Return true if the value types that can be represented by the specified\n  /// register class are all legal.\n  bool isLegalRC(const TargetRegisterInfo &TRI,\n                 const TargetRegisterClass &RC) const;\n\n  /// Replace/modify any TargetFrameIndex operands with a targte-dependent\n  /// sequence of memory operands that is recognized by PrologEpilogInserter.\n  MachineBasicBlock *emitPatchPoint(MachineInstr &MI,\n                                    MachineBasicBlock *MBB) const;\n\n  bool IsStrictFPEnabled;\n};\n\n/// This class defines information used to lower LLVM code to legal SelectionDAG\n/// operators that the target instruction selector can accept natively.\n///\n/// This class also defines callbacks that targets must implement to lower\n/// target-specific constructs to SelectionDAG operators.\nclass TargetLowering : public TargetLoweringBase {\npublic:\n  struct DAGCombinerInfo;\n  struct MakeLibCallOptions;\n\n  TargetLowering(const TargetLowering &) = delete;\n  TargetLowering &operator=(const TargetLowering &) = delete;\n\n  explicit TargetLowering(const TargetMachine &TM);\n\n  bool isPositionIndependent() const;\n\n  virtual bool isSDNodeSourceOfDivergence(const SDNode *N,\n                                          FunctionLoweringInfo *FLI,\n                                          UniformityInfo *UA) const {\n    return false;\n  }\n\n  // Lets target to control the following reassociation of operands: (op (op x,\n  // c1), y) -> (op (op x, y), c1) where N0 is (op x, c1) and N1 is y. By\n  // default consider profitable any case where N0 has single use.  This\n  // behavior reflects the condition replaced by this target hook call in the\n  // DAGCombiner.  Any particular target can implement its own heuristic to\n  // restrict common combiner.\n  virtual bool isReassocProfitable(SelectionDAG &DAG, SDValue N0,\n                                   SDValue N1) const {\n    return N0.hasOneUse();\n  }\n\n  // Lets target to control the following reassociation of operands: (op (op x,\n  // c1), y) -> (op (op x, y), c1) where N0 is (op x, c1) and N1 is y. By\n  // default consider profitable any case where N0 has single use.  This\n  // behavior reflects the condition replaced by this target hook call in the\n  // combiner.  Any particular target can implement its own heuristic to\n  // restrict common combiner.\n  virtual bool isReassocProfitable(MachineRegisterInfo &MRI, Register N0,\n                                   Register N1) const {\n    return MRI.hasOneNonDBGUse(N0);\n  }\n\n  virtual bool isSDNodeAlwaysUniform(const SDNode * N) const {\n    return false;\n  }\n\n  /// Returns true by value, base pointer and offset pointer and addressing mode\n  /// by reference if the node's address can be legally represented as\n  /// pre-indexed load / store address.\n  virtual bool getPreIndexedAddressParts(SDNode * /*N*/, SDValue &/*Base*/,\n                                         SDValue &/*Offset*/,\n                                         ISD::MemIndexedMode &/*AM*/,\n                                         SelectionDAG &/*DAG*/) const {\n    return false;\n  }\n\n  /// Returns true by value, base pointer and offset pointer and addressing mode\n  /// by reference if this node can be combined with a load / store to form a\n  /// post-indexed load / store.\n  virtual bool getPostIndexedAddressParts(SDNode * /*N*/, SDNode * /*Op*/,\n                                          SDValue &/*Base*/,\n                                          SDValue &/*Offset*/,\n                                          ISD::MemIndexedMode &/*AM*/,\n                                          SelectionDAG &/*DAG*/) const {\n    return false;\n  }\n\n  /// Returns true if the specified base+offset is a legal indexed addressing\n  /// mode for this target. \\p MI is the load or store instruction that is being\n  /// considered for transformation.\n  virtual bool isIndexingLegal(MachineInstr &MI, Register Base, Register Offset,\n                               bool IsPre, MachineRegisterInfo &MRI) const {\n    return false;\n  }\n\n  /// Return the entry encoding for a jump table in the current function.  The\n  /// returned value is a member of the MachineJumpTableInfo::JTEntryKind enum.\n  virtual unsigned getJumpTableEncoding() const;\n\n  virtual const MCExpr *\n  LowerCustomJumpTableEntry(const MachineJumpTableInfo * /*MJTI*/,\n                            const MachineBasicBlock * /*MBB*/, unsigned /*uid*/,\n                            MCContext &/*Ctx*/) const {\n    llvm_unreachable(\"Need to implement this hook if target has custom JTIs\");\n  }\n\n  /// Returns relocation base for the given PIC jumptable.\n  virtual SDValue getPICJumpTableRelocBase(SDValue Table,\n                                           SelectionDAG &DAG) const;\n\n  /// This returns the relocation base for the given PIC jumptable, the same as\n  /// getPICJumpTableRelocBase, but as an MCExpr.\n  virtual const MCExpr *\n  getPICJumpTableRelocBaseExpr(const MachineFunction *MF,\n                               unsigned JTI, MCContext &Ctx) const;\n\n  /// Return true if folding a constant offset with the given GlobalAddress is\n  /// legal.  It is frequently not legal in PIC relocation models.\n  virtual bool isOffsetFoldingLegal(const GlobalAddressSDNode *GA) const;\n\n  /// On x86, return true if the operand with index OpNo is a CALL or JUMP\n  /// instruction, which can use either a memory constraint or an address\n  /// constraint. -fasm-blocks \"__asm call foo\" lowers to\n  /// call void asm sideeffect inteldialect \"call ${0:P}\", \"*m...\"\n  ///\n  /// This function is used by a hack to choose the address constraint,\n  /// lowering to a direct call.\n  virtual bool\n  isInlineAsmTargetBranch(const SmallVectorImpl<StringRef> &AsmStrs,\n                          unsigned OpNo) const {\n    return false;\n  }\n\n  bool isInTailCallPosition(SelectionDAG &DAG, SDNode *Node,\n                            SDValue &Chain) const;\n\n  void softenSetCCOperands(SelectionDAG &DAG, EVT VT, SDValue &NewLHS,\n                           SDValue &NewRHS, ISD::CondCode &CCCode,\n                           const SDLoc &DL, const SDValue OldLHS,\n                           const SDValue OldRHS) const;\n\n  void softenSetCCOperands(SelectionDAG &DAG, EVT VT, SDValue &NewLHS,\n                           SDValue &NewRHS, ISD::CondCode &CCCode,\n                           const SDLoc &DL, const SDValue OldLHS,\n                           const SDValue OldRHS, SDValue &Chain,\n                           bool IsSignaling = false) const;\n\n  /// Returns a pair of (return value, chain).\n  /// It is an error to pass RTLIB::UNKNOWN_LIBCALL as \\p LC.\n  std::pair<SDValue, SDValue> makeLibCall(SelectionDAG &DAG, RTLIB::Libcall LC,\n                                          EVT RetVT, ArrayRef<SDValue> Ops,\n                                          MakeLibCallOptions CallOptions,\n                                          const SDLoc &dl,\n                                          SDValue Chain = SDValue()) const;\n\n  /// Check whether parameters to a call that are passed in callee saved\n  /// registers are the same as from the calling function.  This needs to be\n  /// checked for tail call eligibility.\n  bool parametersInCSRMatch(const MachineRegisterInfo &MRI,\n      const uint32_t *CallerPreservedMask,\n      const SmallVectorImpl<CCValAssign> &ArgLocs,\n      const SmallVectorImpl<SDValue> &OutVals) const;\n\n  //===--------------------------------------------------------------------===//\n  // TargetLowering Optimization Methods\n  //\n\n  /// A convenience struct that encapsulates a DAG, and two SDValues for\n  /// returning information from TargetLowering to its clients that want to\n  /// combine.\n  struct TargetLoweringOpt {\n    SelectionDAG &DAG;\n    bool LegalTys;\n    bool LegalOps;\n    SDValue Old;\n    SDValue New;\n\n    explicit TargetLoweringOpt(SelectionDAG &InDAG,\n                               bool LT, bool LO) :\n      DAG(InDAG), LegalTys(LT), LegalOps(LO) {}\n\n    bool LegalTypes() const { return LegalTys; }\n    bool LegalOperations() const { return LegalOps; }\n\n    bool CombineTo(SDValue O, SDValue N) {\n      Old = O;\n      New = N;\n      return true;\n    }\n  };\n\n  /// Determines the optimal series of memory ops to replace the memset / memcpy.\n  /// Return true if the number of memory ops is below the threshold (Limit).\n  /// Note that this is always the case when Limit is ~0.\n  /// It returns the types of the sequence of memory ops to perform\n  /// memset / memcpy by reference.\n  virtual bool\n  findOptimalMemOpLowering(std::vector<EVT> &MemOps, unsigned Limit,\n                           const MemOp &Op, unsigned DstAS, unsigned SrcAS,\n                           const AttributeList &FuncAttributes) const;\n\n  /// Check to see if the specified operand of the specified instruction is a\n  /// constant integer.  If so, check to see if there are any bits set in the\n  /// constant that are not demanded.  If so, shrink the constant and return\n  /// true.\n  bool ShrinkDemandedConstant(SDValue Op, const APInt &DemandedBits,\n                              const APInt &DemandedElts,\n                              TargetLoweringOpt &TLO) const;\n\n  /// Helper wrapper around ShrinkDemandedConstant, demanding all elements.\n  bool ShrinkDemandedConstant(SDValue Op, const APInt &DemandedBits,\n                              TargetLoweringOpt &TLO) const;\n\n  // Target hook to do target-specific const optimization, which is called by\n  // ShrinkDemandedConstant. This function should return true if the target\n  // doesn't want ShrinkDemandedConstant to further optimize the constant.\n  virtual bool targetShrinkDemandedConstant(SDValue Op,\n                                            const APInt &DemandedBits,\n                                            const APInt &DemandedElts,\n                                            TargetLoweringOpt &TLO) const {\n    return false;\n  }\n\n  /// Convert x+y to (VT)((SmallVT)x+(SmallVT)y) if the casts are free.\n  /// This uses isTruncateFree/isZExtFree and ANY_EXTEND for the widening cast,\n  /// but it could be generalized for targets with other types of implicit\n  /// widening casts.\n  bool ShrinkDemandedOp(SDValue Op, unsigned BitWidth,\n                        const APInt &DemandedBits,\n                        TargetLoweringOpt &TLO) const;\n\n  /// Look at Op.  At this point, we know that only the DemandedBits bits of the\n  /// result of Op are ever used downstream.  If we can use this information to\n  /// simplify Op, create a new simplified DAG node and return true, returning\n  /// the original and new nodes in Old and New.  Otherwise, analyze the\n  /// expression and return a mask of KnownOne and KnownZero bits for the\n  /// expression (used to simplify the caller).  The KnownZero/One bits may only\n  /// be accurate for those bits in the Demanded masks.\n  /// \\p AssumeSingleUse When this parameter is true, this function will\n  ///    attempt to simplify \\p Op even if there are multiple uses.\n  ///    Callers are responsible for correctly updating the DAG based on the\n  ///    results of this function, because simply replacing TLO.Old\n  ///    with TLO.New will be incorrect when this parameter is true and TLO.Old\n  ///    has multiple uses.\n  bool SimplifyDemandedBits(SDValue Op, const APInt &DemandedBits,\n                            const APInt &DemandedElts, KnownBits &Known,\n                            TargetLoweringOpt &TLO, unsigned Depth = 0,\n                            bool AssumeSingleUse = false) const;\n\n  /// Helper wrapper around SimplifyDemandedBits, demanding all elements.\n  /// Adds Op back to the worklist upon success.\n  bool SimplifyDemandedBits(SDValue Op, const APInt &DemandedBits,\n                            KnownBits &Known, TargetLoweringOpt &TLO,\n                            unsigned Depth = 0,\n                            bool AssumeSingleUse = false) const;\n\n  /// Helper wrapper around SimplifyDemandedBits.\n  /// Adds Op back to the worklist upon success.\n  bool SimplifyDemandedBits(SDValue Op, const APInt &DemandedBits,\n                            DAGCombinerInfo &DCI) const;\n\n  /// Helper wrapper around SimplifyDemandedBits.\n  /// Adds Op back to the worklist upon success.\n  bool SimplifyDemandedBits(SDValue Op, const APInt &DemandedBits,\n                            const APInt &DemandedElts,\n                            DAGCombinerInfo &DCI) const;\n\n  /// More limited version of SimplifyDemandedBits that can be used to \"look\n  /// through\" ops that don't contribute to the DemandedBits/DemandedElts -\n  /// bitwise ops etc.\n  SDValue SimplifyMultipleUseDemandedBits(SDValue Op, const APInt &DemandedBits,\n                                          const APInt &DemandedElts,\n                                          SelectionDAG &DAG,\n                                          unsigned Depth = 0) const;\n\n  /// Helper wrapper around SimplifyMultipleUseDemandedBits, demanding all\n  /// elements.\n  SDValue SimplifyMultipleUseDemandedBits(SDValue Op, const APInt &DemandedBits,\n                                          SelectionDAG &DAG,\n                                          unsigned Depth = 0) const;\n\n  /// Helper wrapper around SimplifyMultipleUseDemandedBits, demanding all\n  /// bits from only some vector elements.\n  SDValue SimplifyMultipleUseDemandedVectorElts(SDValue Op,\n                                                const APInt &DemandedElts,\n                                                SelectionDAG &DAG,\n                                                unsigned Depth = 0) const;\n\n  /// Look at Vector Op. At this point, we know that only the DemandedElts\n  /// elements of the result of Op are ever used downstream.  If we can use\n  /// this information to simplify Op, create a new simplified DAG node and\n  /// return true, storing the original and new nodes in TLO.\n  /// Otherwise, analyze the expression and return a mask of KnownUndef and\n  /// KnownZero elements for the expression (used to simplify the caller).\n  /// The KnownUndef/Zero elements may only be accurate for those bits\n  /// in the DemandedMask.\n  /// \\p AssumeSingleUse When this parameter is true, this function will\n  ///    attempt to simplify \\p Op even if there are multiple uses.\n  ///    Callers are responsible for correctly updating the DAG based on the\n  ///    results of this function, because simply replacing TLO.Old\n  ///    with TLO.New will be incorrect when this parameter is true and TLO.Old\n  ///    has multiple uses.\n  bool SimplifyDemandedVectorElts(SDValue Op, const APInt &DemandedEltMask,\n                                  APInt &KnownUndef, APInt &KnownZero,\n                                  TargetLoweringOpt &TLO, unsigned Depth = 0,\n                                  bool AssumeSingleUse = false) const;\n\n  /// Helper wrapper around SimplifyDemandedVectorElts.\n  /// Adds Op back to the worklist upon success.\n  bool SimplifyDemandedVectorElts(SDValue Op, const APInt &DemandedElts,\n                                  DAGCombinerInfo &DCI) const;\n\n  /// Return true if the target supports simplifying demanded vector elements by\n  /// converting them to undefs.\n  virtual bool\n  shouldSimplifyDemandedVectorElts(SDValue Op,\n                                   const TargetLoweringOpt &TLO) const {\n    return true;\n  }\n\n  /// Determine which of the bits specified in Mask are known to be either zero\n  /// or one and return them in the KnownZero/KnownOne bitsets. The DemandedElts\n  /// argument allows us to only collect the known bits that are shared by the\n  /// requested vector elements.\n  virtual void computeKnownBitsForTargetNode(const SDValue Op,\n                                             KnownBits &Known,\n                                             const APInt &DemandedElts,\n                                             const SelectionDAG &DAG,\n                                             unsigned Depth = 0) const;\n\n  /// Determine which of the bits specified in Mask are known to be either zero\n  /// or one and return them in the KnownZero/KnownOne bitsets. The DemandedElts\n  /// argument allows us to only collect the known bits that are shared by the\n  /// requested vector elements. This is for GISel.\n  virtual void computeKnownBitsForTargetInstr(GISelKnownBits &Analysis,\n                                              Register R, KnownBits &Known,\n                                              const APInt &DemandedElts,\n                                              const MachineRegisterInfo &MRI,\n                                              unsigned Depth = 0) const;\n\n  /// Determine the known alignment for the pointer value \\p R. This is can\n  /// typically be inferred from the number of low known 0 bits. However, for a\n  /// pointer with a non-integral address space, the alignment value may be\n  /// independent from the known low bits.\n  virtual Align computeKnownAlignForTargetInstr(GISelKnownBits &Analysis,\n                                                Register R,\n                                                const MachineRegisterInfo &MRI,\n                                                unsigned Depth = 0) const;\n\n  /// Determine which of the bits of FrameIndex \\p FIOp are known to be 0.\n  /// Default implementation computes low bits based on alignment\n  /// information. This should preserve known bits passed into it.\n  virtual void computeKnownBitsForFrameIndex(int FIOp,\n                                             KnownBits &Known,\n                                             const MachineFunction &MF) const;\n\n  /// This method can be implemented by targets that want to expose additional\n  /// information about sign bits to the DAG Combiner. The DemandedElts\n  /// argument allows us to only collect the minimum sign bits that are shared\n  /// by the requested vector elements.\n  virtual unsigned ComputeNumSignBitsForTargetNode(SDValue Op,\n                                                   const APInt &DemandedElts,\n                                                   const SelectionDAG &DAG,\n                                                   unsigned Depth = 0) const;\n\n  /// This method can be implemented by targets that want to expose additional\n  /// information about sign bits to GlobalISel combiners. The DemandedElts\n  /// argument allows us to only collect the minimum sign bits that are shared\n  /// by the requested vector elements.\n  virtual unsigned computeNumSignBitsForTargetInstr(GISelKnownBits &Analysis,\n                                                    Register R,\n                                                    const APInt &DemandedElts,\n                                                    const MachineRegisterInfo &MRI,\n                                                    unsigned Depth = 0) const;\n\n  /// Attempt to simplify any target nodes based on the demanded vector\n  /// elements, returning true on success. Otherwise, analyze the expression and\n  /// return a mask of KnownUndef and KnownZero elements for the expression\n  /// (used to simplify the caller). The KnownUndef/Zero elements may only be\n  /// accurate for those bits in the DemandedMask.\n  virtual bool SimplifyDemandedVectorEltsForTargetNode(\n      SDValue Op, const APInt &DemandedElts, APInt &KnownUndef,\n      APInt &KnownZero, TargetLoweringOpt &TLO, unsigned Depth = 0) const;\n\n  /// Attempt to simplify any target nodes based on the demanded bits/elts,\n  /// returning true on success. Otherwise, analyze the\n  /// expression and return a mask of KnownOne and KnownZero bits for the\n  /// expression (used to simplify the caller).  The KnownZero/One bits may only\n  /// be accurate for those bits in the Demanded masks.\n  virtual bool SimplifyDemandedBitsForTargetNode(SDValue Op,\n                                                 const APInt &DemandedBits,\n                                                 const APInt &DemandedElts,\n                                                 KnownBits &Known,\n                                                 TargetLoweringOpt &TLO,\n                                                 unsigned Depth = 0) const;\n\n  /// More limited version of SimplifyDemandedBits that can be used to \"look\n  /// through\" ops that don't contribute to the DemandedBits/DemandedElts -\n  /// bitwise ops etc.\n  virtual SDValue SimplifyMultipleUseDemandedBitsForTargetNode(\n      SDValue Op, const APInt &DemandedBits, const APInt &DemandedElts,\n      SelectionDAG &DAG, unsigned Depth) const;\n\n  /// Return true if this function can prove that \\p Op is never poison\n  /// and, if \\p PoisonOnly is false, does not have undef bits. The DemandedElts\n  /// argument limits the check to the requested vector elements.\n  virtual bool isGuaranteedNotToBeUndefOrPoisonForTargetNode(\n      SDValue Op, const APInt &DemandedElts, const SelectionDAG &DAG,\n      bool PoisonOnly, unsigned Depth) const;\n\n  /// Return true if Op can create undef or poison from non-undef & non-poison\n  /// operands. The DemandedElts argument limits the check to the requested\n  /// vector elements.\n  virtual bool\n  canCreateUndefOrPoisonForTargetNode(SDValue Op, const APInt &DemandedElts,\n                                      const SelectionDAG &DAG, bool PoisonOnly,\n                                      bool ConsiderFlags, unsigned Depth) const;\n\n  /// Tries to build a legal vector shuffle using the provided parameters\n  /// or equivalent variations. The Mask argument maybe be modified as the\n  /// function tries different variations.\n  /// Returns an empty SDValue if the operation fails.\n  SDValue buildLegalVectorShuffle(EVT VT, const SDLoc &DL, SDValue N0,\n                                  SDValue N1, MutableArrayRef<int> Mask,\n                                  SelectionDAG &DAG) const;\n\n  /// This method returns the constant pool value that will be loaded by LD.\n  /// NOTE: You must check for implicit extensions of the constant by LD.\n  virtual const Constant *getTargetConstantFromLoad(LoadSDNode *LD) const;\n\n  /// If \\p SNaN is false, \\returns true if \\p Op is known to never be any\n  /// NaN. If \\p sNaN is true, returns if \\p Op is known to never be a signaling\n  /// NaN.\n  virtual bool isKnownNeverNaNForTargetNode(SDValue Op,\n                                            const SelectionDAG &DAG,\n                                            bool SNaN = false,\n                                            unsigned Depth = 0) const;\n\n  /// Return true if vector \\p Op has the same value across all \\p DemandedElts,\n  /// indicating any elements which may be undef in the output \\p UndefElts.\n  virtual bool isSplatValueForTargetNode(SDValue Op, const APInt &DemandedElts,\n                                         APInt &UndefElts,\n                                         const SelectionDAG &DAG,\n                                         unsigned Depth = 0) const;\n\n  /// Returns true if the given Opc is considered a canonical constant for the\n  /// target, which should not be transformed back into a BUILD_VECTOR.\n  virtual bool isTargetCanonicalConstantNode(SDValue Op) const {\n    return Op.getOpcode() == ISD::SPLAT_VECTOR ||\n           Op.getOpcode() == ISD::SPLAT_VECTOR_PARTS;\n  }\n\n  struct DAGCombinerInfo {\n    void *DC;  // The DAG Combiner object.\n    CombineLevel Level;\n    bool CalledByLegalizer;\n\n  public:\n    SelectionDAG &DAG;\n\n    DAGCombinerInfo(SelectionDAG &dag, CombineLevel level,  bool cl, void *dc)\n      : DC(dc), Level(level), CalledByLegalizer(cl), DAG(dag) {}\n\n    bool isBeforeLegalize() const { return Level == BeforeLegalizeTypes; }\n    bool isBeforeLegalizeOps() const { return Level < AfterLegalizeVectorOps; }\n    bool isAfterLegalizeDAG() const { return Level >= AfterLegalizeDAG; }\n    CombineLevel getDAGCombineLevel() { return Level; }\n    bool isCalledByLegalizer() const { return CalledByLegalizer; }\n\n    void AddToWorklist(SDNode *N);\n    SDValue CombineTo(SDNode *N, ArrayRef<SDValue> To, bool AddTo = true);\n    SDValue CombineTo(SDNode *N, SDValue Res, bool AddTo = true);\n    SDValue CombineTo(SDNode *N, SDValue Res0, SDValue Res1, bool AddTo = true);\n\n    bool recursivelyDeleteUnusedNodes(SDNode *N);\n\n    void CommitTargetLoweringOpt(const TargetLoweringOpt &TLO);\n  };\n\n  /// Return if the N is a constant or constant vector equal to the true value\n  /// from getBooleanContents().\n  bool isConstTrueVal(SDValue N) const;\n\n  /// Return if the N is a constant or constant vector equal to the false value\n  /// from getBooleanContents().\n  bool isConstFalseVal(SDValue N) const;\n\n  /// Return if \\p N is a True value when extended to \\p VT.\n  bool isExtendedTrueVal(const ConstantSDNode *N, EVT VT, bool SExt) const;\n\n  /// Try to simplify a setcc built with the specified operands and cc. If it is\n  /// unable to simplify it, return a null SDValue.\n  SDValue SimplifySetCC(EVT VT, SDValue N0, SDValue N1, ISD::CondCode Cond,\n                        bool foldBooleans, DAGCombinerInfo &DCI,\n                        const SDLoc &dl) const;\n\n  // For targets which wrap address, unwrap for analysis.\n  virtual SDValue unwrapAddress(SDValue N) const { return N; }\n\n  /// Returns true (and the GlobalValue and the offset) if the node is a\n  /// GlobalAddress + offset.\n  virtual bool\n  isGAPlusOffset(SDNode *N, const GlobalValue* &GA, int64_t &Offset) const;\n\n  /// This method will be invoked for all target nodes and for any\n  /// target-independent nodes that the target has registered with invoke it\n  /// for.\n  ///\n  /// The semantics are as follows:\n  /// Return Value:\n  ///   SDValue.Val == 0   - No change was made\n  ///   SDValue.Val == N   - N was replaced, is dead, and is already handled.\n  ///   otherwise          - N should be replaced by the returned Operand.\n  ///\n  /// In addition, methods provided by DAGCombinerInfo may be used to perform\n  /// more complex transformations.\n  ///\n  virtual SDValue PerformDAGCombine(SDNode *N, DAGCombinerInfo &DCI) const;\n\n  /// Return true if it is profitable to move this shift by a constant amount\n  /// through its operand, adjusting any immediate operands as necessary to\n  /// preserve semantics. This transformation may not be desirable if it\n  /// disrupts a particularly auspicious target-specific tree (e.g. bitfield\n  /// extraction in AArch64). By default, it returns true.\n  ///\n  /// @param N the shift node\n  /// @param Level the current DAGCombine legalization level.\n  virtual bool isDesirableToCommuteWithShift(const SDNode *N,\n                                             CombineLevel Level) const {\n    return true;\n  }\n\n  /// GlobalISel - return true if it is profitable to move this shift by a\n  /// constant amount through its operand, adjusting any immediate operands as\n  /// necessary to preserve semantics. This transformation may not be desirable\n  /// if it disrupts a particularly auspicious target-specific tree (e.g.\n  /// bitfield extraction in AArch64). By default, it returns true.\n  ///\n  /// @param MI the shift instruction\n  /// @param IsAfterLegal true if running after legalization.\n  virtual bool isDesirableToCommuteWithShift(const MachineInstr &MI,\n                                             bool IsAfterLegal) const {\n    return true;\n  }\n\n  /// GlobalISel - return true if it's profitable to perform the combine:\n  /// shl ([sza]ext x), y => zext (shl x, y)\n  virtual bool isDesirableToPullExtFromShl(const MachineInstr &MI) const {\n    return true;\n  }\n\n  // Return AndOrSETCCFoldKind::{AddAnd, ABS} if its desirable to try and\n  // optimize LogicOp(SETCC0, SETCC1). An example (what is implemented as of\n  // writing this) is:\n  //    With C as a power of 2 and C != 0 and C != INT_MIN:\n  //    AddAnd:\n  //     (icmp eq A, C) | (icmp eq A, -C)\n  //            -> (icmp eq and(add(A, C), ~(C + C)), 0)\n  //     (icmp ne A, C) & (icmp ne A, -C)w\n  //            -> (icmp ne and(add(A, C), ~(C + C)), 0)\n  //    ABS:\n  //     (icmp eq A, C) | (icmp eq A, -C)\n  //            -> (icmp eq Abs(A), C)\n  //     (icmp ne A, C) & (icmp ne A, -C)w\n  //            -> (icmp ne Abs(A), C)\n  //\n  // @param LogicOp the logic op\n  // @param SETCC0 the first of the SETCC nodes\n  // @param SETCC0 the second of the SETCC nodes\n  virtual AndOrSETCCFoldKind isDesirableToCombineLogicOpOfSETCC(\n      const SDNode *LogicOp, const SDNode *SETCC0, const SDNode *SETCC1) const {\n    return AndOrSETCCFoldKind::None;\n  }\n\n  /// Return true if it is profitable to combine an XOR of a logical shift\n  /// to create a logical shift of NOT. This transformation may not be desirable\n  /// if it disrupts a particularly auspicious target-specific tree (e.g.\n  /// BIC on ARM/AArch64). By default, it returns true.\n  virtual bool isDesirableToCommuteXorWithShift(const SDNode *N) const {\n    return true;\n  }\n\n  /// Return true if the target has native support for the specified value type\n  /// and it is 'desirable' to use the type for the given node type. e.g. On x86\n  /// i16 is legal, but undesirable since i16 instruction encodings are longer\n  /// and some i16 instructions are slow.\n  virtual bool isTypeDesirableForOp(unsigned /*Opc*/, EVT VT) const {\n    // By default, assume all legal types are desirable.\n    return isTypeLegal(VT);\n  }\n\n  /// Return true if it is profitable for dag combiner to transform a floating\n  /// point op of specified opcode to a equivalent op of an integer\n  /// type. e.g. f32 load -> i32 load can be profitable on ARM.\n  virtual bool isDesirableToTransformToIntegerOp(unsigned /*Opc*/,\n                                                 EVT /*VT*/) const {\n    return false;\n  }\n\n  /// This method query the target whether it is beneficial for dag combiner to\n  /// promote the specified node. If true, it should return the desired\n  /// promotion type by reference.\n  virtual bool IsDesirableToPromoteOp(SDValue /*Op*/, EVT &/*PVT*/) const {\n    return false;\n  }\n\n  /// Return true if the target supports swifterror attribute. It optimizes\n  /// loads and stores to reading and writing a specific register.\n  virtual bool supportSwiftError() const {\n    return false;\n  }\n\n  /// Return true if the target supports that a subset of CSRs for the given\n  /// machine function is handled explicitly via copies.\n  virtual bool supportSplitCSR(MachineFunction *MF) const {\n    return false;\n  }\n\n  /// Return true if the target supports kcfi operand bundles.\n  virtual bool supportKCFIBundles() const { return false; }\n\n  /// Perform necessary initialization to handle a subset of CSRs explicitly\n  /// via copies. This function is called at the beginning of instruction\n  /// selection.\n  virtual void initializeSplitCSR(MachineBasicBlock *Entry) const {\n    llvm_unreachable(\"Not Implemented\");\n  }\n\n  /// Insert explicit copies in entry and exit blocks. We copy a subset of\n  /// CSRs to virtual registers in the entry block, and copy them back to\n  /// physical registers in the exit blocks. This function is called at the end\n  /// of instruction selection.\n  virtual void insertCopiesSplitCSR(\n      MachineBasicBlock *Entry,\n      const SmallVectorImpl<MachineBasicBlock *> &Exits) const {\n    llvm_unreachable(\"Not Implemented\");\n  }\n\n  /// Return the newly negated expression if the cost is not expensive and\n  /// set the cost in \\p Cost to indicate that if it is cheaper or neutral to\n  /// do the negation.\n  virtual SDValue getNegatedExpression(SDValue Op, SelectionDAG &DAG,\n                                       bool LegalOps, bool OptForSize,\n                                       NegatibleCost &Cost,\n                                       unsigned Depth = 0) const;\n\n  SDValue getCheaperOrNeutralNegatedExpression(\n      SDValue Op, SelectionDAG &DAG, bool LegalOps, bool OptForSize,\n      const NegatibleCost CostThreshold = NegatibleCost::Neutral,\n      unsigned Depth = 0) const {\n    NegatibleCost Cost = NegatibleCost::Expensive;\n    SDValue Neg =\n        getNegatedExpression(Op, DAG, LegalOps, OptForSize, Cost, Depth);\n    if (!Neg)\n      return SDValue();\n\n    if (Cost <= CostThreshold)\n      return Neg;\n\n    // Remove the new created node to avoid the side effect to the DAG.\n    if (Neg->use_empty())\n      DAG.RemoveDeadNode(Neg.getNode());\n    return SDValue();\n  }\n\n  /// This is the helper function to return the newly negated expression only\n  /// when the cost is cheaper.\n  SDValue getCheaperNegatedExpression(SDValue Op, SelectionDAG &DAG,\n                                      bool LegalOps, bool OptForSize,\n                                      unsigned Depth = 0) const {\n    return getCheaperOrNeutralNegatedExpression(Op, DAG, LegalOps, OptForSize,\n                                                NegatibleCost::Cheaper, Depth);\n  }\n\n  /// This is the helper function to return the newly negated expression if\n  /// the cost is not expensive.\n  SDValue getNegatedExpression(SDValue Op, SelectionDAG &DAG, bool LegalOps,\n                               bool OptForSize, unsigned Depth = 0) const {\n    NegatibleCost Cost = NegatibleCost::Expensive;\n    return getNegatedExpression(Op, DAG, LegalOps, OptForSize, Cost, Depth);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Lowering methods - These methods must be implemented by targets so that\n  // the SelectionDAGBuilder code knows how to lower these.\n  //\n\n  /// Target-specific splitting of values into parts that fit a register\n  /// storing a legal type\n  virtual bool splitValueIntoRegisterParts(\n      SelectionDAG & DAG, const SDLoc &DL, SDValue Val, SDValue *Parts,\n      unsigned NumParts, MVT PartVT, std::optional<CallingConv::ID> CC) const {\n    return false;\n  }\n\n  /// Allows the target to handle physreg-carried dependency\n  /// in target-specific way. Used from the ScheduleDAGSDNodes to decide whether\n  /// to add the edge to the dependency graph.\n  /// Def - input: Selection DAG node defininfg physical register\n  /// User - input: Selection DAG node using physical register\n  /// Op - input: Number of User operand\n  /// PhysReg - inout: set to the physical register if the edge is\n  /// necessary, unchanged otherwise\n  /// Cost - inout: physical register copy cost.\n  /// Returns 'true' is the edge is necessary, 'false' otherwise\n  virtual bool checkForPhysRegDependency(SDNode *Def, SDNode *User, unsigned Op,\n                                         const TargetRegisterInfo *TRI,\n                                         const TargetInstrInfo *TII,\n                                         unsigned &PhysReg, int &Cost) const {\n    return false;\n  }\n\n  /// Target-specific combining of register parts into its original value\n  virtual SDValue\n  joinRegisterPartsIntoValue(SelectionDAG &DAG, const SDLoc &DL,\n                             const SDValue *Parts, unsigned NumParts,\n                             MVT PartVT, EVT ValueVT,\n                             std::optional<CallingConv::ID> CC) const {\n    return SDValue();\n  }\n\n  /// This hook must be implemented to lower the incoming (formal) arguments,\n  /// described by the Ins array, into the specified DAG. The implementation\n  /// should fill in the InVals array with legal-type argument values, and\n  /// return the resulting token chain value.\n  virtual SDValue LowerFormalArguments(\n      SDValue /*Chain*/, CallingConv::ID /*CallConv*/, bool /*isVarArg*/,\n      const SmallVectorImpl<ISD::InputArg> & /*Ins*/, const SDLoc & /*dl*/,\n      SelectionDAG & /*DAG*/, SmallVectorImpl<SDValue> & /*InVals*/) const {\n    llvm_unreachable(\"Not Implemented\");\n  }\n\n  /// This structure contains all information that is necessary for lowering\n  /// calls. It is passed to TLI::LowerCallTo when the SelectionDAG builder\n  /// needs to lower a call, and targets will see this struct in their LowerCall\n  /// implementation.\n  struct CallLoweringInfo {\n    SDValue Chain;\n    Type *RetTy = nullptr;\n    bool RetSExt           : 1;\n    bool RetZExt           : 1;\n    bool IsVarArg          : 1;\n    bool IsInReg           : 1;\n    bool DoesNotReturn     : 1;\n    bool IsReturnValueUsed : 1;\n    bool IsConvergent      : 1;\n    bool IsPatchPoint      : 1;\n    bool IsPreallocated : 1;\n    bool NoMerge           : 1;\n\n    // IsTailCall should be modified by implementations of\n    // TargetLowering::LowerCall that perform tail call conversions.\n    bool IsTailCall = false;\n\n    // Is Call lowering done post SelectionDAG type legalization.\n    bool IsPostTypeLegalization = false;\n\n    unsigned NumFixedArgs = -1;\n    CallingConv::ID CallConv = CallingConv::C;\n    SDValue Callee;\n    ArgListTy Args;\n    SelectionDAG &DAG;\n    SDLoc DL;\n    const CallBase *CB = nullptr;\n    SmallVector<ISD::OutputArg, 32> Outs;\n    SmallVector<SDValue, 32> OutVals;\n    SmallVector<ISD::InputArg, 32> Ins;\n    SmallVector<SDValue, 4> InVals;\n    const ConstantInt *CFIType = nullptr;\n\n    CallLoweringInfo(SelectionDAG &DAG)\n        : RetSExt(false), RetZExt(false), IsVarArg(false), IsInReg(false),\n          DoesNotReturn(false), IsReturnValueUsed(true), IsConvergent(false),\n          IsPatchPoint(false), IsPreallocated(false), NoMerge(false),\n          DAG(DAG) {}\n\n    CallLoweringInfo &setDebugLoc(const SDLoc &dl) {\n      DL = dl;\n      return *this;\n    }\n\n    CallLoweringInfo &setChain(SDValue InChain) {\n      Chain = InChain;\n      return *this;\n    }\n\n    // setCallee with target/module-specific attributes\n    CallLoweringInfo &setLibCallee(CallingConv::ID CC, Type *ResultType,\n                                   SDValue Target, ArgListTy &&ArgsList) {\n      RetTy = ResultType;\n      Callee = Target;\n      CallConv = CC;\n      NumFixedArgs = ArgsList.size();\n      Args = std::move(ArgsList);\n\n      DAG.getTargetLoweringInfo().markLibCallAttributes(\n          &(DAG.getMachineFunction()), CC, Args);\n      return *this;\n    }\n\n    CallLoweringInfo &setCallee(CallingConv::ID CC, Type *ResultType,\n                                SDValue Target, ArgListTy &&ArgsList,\n                                AttributeSet ResultAttrs = {}) {\n      RetTy = ResultType;\n      IsInReg = ResultAttrs.hasAttribute(Attribute::InReg);\n      RetSExt = ResultAttrs.hasAttribute(Attribute::SExt);\n      RetZExt = ResultAttrs.hasAttribute(Attribute::ZExt);\n      NoMerge = ResultAttrs.hasAttribute(Attribute::NoMerge);\n\n      Callee = Target;\n      CallConv = CC;\n      NumFixedArgs = ArgsList.size();\n      Args = std::move(ArgsList);\n      return *this;\n    }\n\n    CallLoweringInfo &setCallee(Type *ResultType, FunctionType *FTy,\n                                SDValue Target, ArgListTy &&ArgsList,\n                                const CallBase &Call) {\n      RetTy = ResultType;\n\n      IsInReg = Call.hasRetAttr(Attribute::InReg);\n      DoesNotReturn =\n          Call.doesNotReturn() ||\n          (!isa<InvokeInst>(Call) && isa<UnreachableInst>(Call.getNextNode()));\n      IsVarArg = FTy->isVarArg();\n      IsReturnValueUsed = !Call.use_empty();\n      RetSExt = Call.hasRetAttr(Attribute::SExt);\n      RetZExt = Call.hasRetAttr(Attribute::ZExt);\n      NoMerge = Call.hasFnAttr(Attribute::NoMerge);\n\n      Callee = Target;\n\n      CallConv = Call.getCallingConv();\n      NumFixedArgs = FTy->getNumParams();\n      Args = std::move(ArgsList);\n\n      CB = &Call;\n\n      return *this;\n    }\n\n    CallLoweringInfo &setInRegister(bool Value = true) {\n      IsInReg = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setNoReturn(bool Value = true) {\n      DoesNotReturn = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setVarArg(bool Value = true) {\n      IsVarArg = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setTailCall(bool Value = true) {\n      IsTailCall = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setDiscardResult(bool Value = true) {\n      IsReturnValueUsed = !Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setConvergent(bool Value = true) {\n      IsConvergent = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setSExtResult(bool Value = true) {\n      RetSExt = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setZExtResult(bool Value = true) {\n      RetZExt = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setIsPatchPoint(bool Value = true) {\n      IsPatchPoint = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setIsPreallocated(bool Value = true) {\n      IsPreallocated = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setIsPostTypeLegalization(bool Value=true) {\n      IsPostTypeLegalization = Value;\n      return *this;\n    }\n\n    CallLoweringInfo &setCFIType(const ConstantInt *Type) {\n      CFIType = Type;\n      return *this;\n    }\n\n    ArgListTy &getArgs() {\n      return Args;\n    }\n  };\n\n  /// This structure is used to pass arguments to makeLibCall function.\n  struct MakeLibCallOptions {\n    // By passing type list before soften to makeLibCall, the target hook\n    // shouldExtendTypeInLibCall can get the original type before soften.\n    ArrayRef<EVT> OpsVTBeforeSoften;\n    EVT RetVTBeforeSoften;\n    bool IsSExt : 1;\n    bool DoesNotReturn : 1;\n    bool IsReturnValueUsed : 1;\n    bool IsPostTypeLegalization : 1;\n    bool IsSoften : 1;\n\n    MakeLibCallOptions()\n        : IsSExt(false), DoesNotReturn(false), IsReturnValueUsed(true),\n          IsPostTypeLegalization(false), IsSoften(false) {}\n\n    MakeLibCallOptions &setSExt(bool Value = true) {\n      IsSExt = Value;\n      return *this;\n    }\n\n    MakeLibCallOptions &setNoReturn(bool Value = true) {\n      DoesNotReturn = Value;\n      return *this;\n    }\n\n    MakeLibCallOptions &setDiscardResult(bool Value = true) {\n      IsReturnValueUsed = !Value;\n      return *this;\n    }\n\n    MakeLibCallOptions &setIsPostTypeLegalization(bool Value = true) {\n      IsPostTypeLegalization = Value;\n      return *this;\n    }\n\n    MakeLibCallOptions &setTypeListBeforeSoften(ArrayRef<EVT> OpsVT, EVT RetVT,\n                                                bool Value = true) {\n      OpsVTBeforeSoften = OpsVT;\n      RetVTBeforeSoften = RetVT;\n      IsSoften = Value;\n      return *this;\n    }\n  };\n\n  /// This function lowers an abstract call to a function into an actual call.\n  /// This returns a pair of operands.  The first element is the return value\n  /// for the function (if RetTy is not VoidTy).  The second element is the\n  /// outgoing token chain. It calls LowerCall to do the actual lowering.\n  std::pair<SDValue, SDValue> LowerCallTo(CallLoweringInfo &CLI) const;\n\n  /// This hook must be implemented to lower calls into the specified\n  /// DAG. The outgoing arguments to the call are described by the Outs array,\n  /// and the values to be returned by the call are described by the Ins\n  /// array. The implementation should fill in the InVals array with legal-type\n  /// return values from the call, and return the resulting token chain value.\n  virtual SDValue\n    LowerCall(CallLoweringInfo &/*CLI*/,\n              SmallVectorImpl<SDValue> &/*InVals*/) const {\n    llvm_unreachable(\"Not Implemented\");\n  }\n\n  /// Target-specific cleanup for formal ByVal parameters.\n  virtual void HandleByVal(CCState *, unsigned &, Align) const {}\n\n  /// This hook should be implemented to check whether the return values\n  /// described by the Outs array can fit into the return registers.  If false\n  /// is returned, an sret-demotion is performed.\n  virtual bool CanLowerReturn(CallingConv::ID /*CallConv*/,\n                              MachineFunction &/*MF*/, bool /*isVarArg*/,\n               const SmallVectorImpl<ISD::OutputArg> &/*Outs*/,\n               LLVMContext &/*Context*/) const\n  {\n    // Return true by default to get preexisting behavior.\n    return true;\n  }\n\n  /// This hook must be implemented to lower outgoing return values, described\n  /// by the Outs array, into the specified DAG. The implementation should\n  /// return the resulting token chain value.\n  virtual SDValue LowerReturn(SDValue /*Chain*/, CallingConv::ID /*CallConv*/,\n                              bool /*isVarArg*/,\n                              const SmallVectorImpl<ISD::OutputArg> & /*Outs*/,\n                              const SmallVectorImpl<SDValue> & /*OutVals*/,\n                              const SDLoc & /*dl*/,\n                              SelectionDAG & /*DAG*/) const {\n    llvm_unreachable(\"Not Implemented\");\n  }\n\n  /// Return true if result of the specified node is used by a return node\n  /// only. It also compute and return the input chain for the tail call.\n  ///\n  /// This is used to determine whether it is possible to codegen a libcall as\n  /// tail call at legalization time.\n  virtual bool isUsedByReturnOnly(SDNode *, SDValue &/*Chain*/) const {\n    return false;\n  }\n\n  /// Return true if the target may be able emit the call instruction as a tail\n  /// call. This is used by optimization passes to determine if it's profitable\n  /// to duplicate return instructions to enable tailcall optimization.\n  virtual bool mayBeEmittedAsTailCall(const CallInst *) const {\n    return false;\n  }\n\n  /// Return the builtin name for the __builtin___clear_cache intrinsic\n  /// Default is to invoke the clear cache library call\n  virtual const char * getClearCacheBuiltinName() const {\n    return \"__clear_cache\";\n  }\n\n  /// Return the register ID of the name passed in. Used by named register\n  /// global variables extension. There is no target-independent behaviour\n  /// so the default action is to bail.\n  virtual Register getRegisterByName(const char* RegName, LLT Ty,\n                                     const MachineFunction &MF) const {\n    report_fatal_error(\"Named registers not implemented for this target\");\n  }\n\n  /// Return the type that should be used to zero or sign extend a\n  /// zeroext/signext integer return value.  FIXME: Some C calling conventions\n  /// require the return type to be promoted, but this is not true all the time,\n  /// e.g. i1/i8/i16 on x86/x86_64. It is also not necessary for non-C calling\n  /// conventions. The frontend should handle this and include all of the\n  /// necessary information.\n  virtual EVT getTypeForExtReturn(LLVMContext &Context, EVT VT,\n                                       ISD::NodeType /*ExtendKind*/) const {\n    EVT MinVT = getRegisterType(MVT::i32);\n    return VT.bitsLT(MinVT) ? MinVT : VT;\n  }\n\n  /// For some targets, an LLVM struct type must be broken down into multiple\n  /// simple types, but the calling convention specifies that the entire struct\n  /// must be passed in a block of consecutive registers.\n  virtual bool\n  functionArgumentNeedsConsecutiveRegisters(Type *Ty, CallingConv::ID CallConv,\n                                            bool isVarArg,\n                                            const DataLayout &DL) const {\n    return false;\n  }\n\n  /// For most targets, an LLVM type must be broken down into multiple\n  /// smaller types. Usually the halves are ordered according to the endianness\n  /// but for some platform that would break. So this method will default to\n  /// matching the endianness but can be overridden.\n  virtual bool\n  shouldSplitFunctionArgumentsAsLittleEndian(const DataLayout &DL) const {\n    return DL.isLittleEndian();\n  }\n\n  /// Returns a 0 terminated array of registers that can be safely used as\n  /// scratch registers.\n  virtual const MCPhysReg *getScratchRegisters(CallingConv::ID CC) const {\n    return nullptr;\n  }\n\n  /// Returns a 0 terminated array of rounding control registers that can be\n  /// attached into strict FP call.\n  virtual ArrayRef<MCPhysReg> getRoundingControlRegisters() const {\n    return ArrayRef<MCPhysReg>();\n  }\n\n  /// This callback is used to prepare for a volatile or atomic load.\n  /// It takes a chain node as input and returns the chain for the load itself.\n  ///\n  /// Having a callback like this is necessary for targets like SystemZ,\n  /// which allows a CPU to reuse the result of a previous load indefinitely,\n  /// even if a cache-coherent store is performed by another CPU.  The default\n  /// implementation does nothing.\n  virtual SDValue prepareVolatileOrAtomicLoad(SDValue Chain, const SDLoc &DL,\n                                              SelectionDAG &DAG) const {\n    return Chain;\n  }\n\n  /// This callback is invoked by the type legalizer to legalize nodes with an\n  /// illegal operand type but legal result types.  It replaces the\n  /// LowerOperation callback in the type Legalizer.  The reason we can not do\n  /// away with LowerOperation entirely is that LegalizeDAG isn't yet ready to\n  /// use this callback.\n  ///\n  /// TODO: Consider merging with ReplaceNodeResults.\n  ///\n  /// The target places new result values for the node in Results (their number\n  /// and types must exactly match those of the original return values of\n  /// the node), or leaves Results empty, which indicates that the node is not\n  /// to be custom lowered after all.\n  /// The default implementation calls LowerOperation.\n  virtual void LowerOperationWrapper(SDNode *N,\n                                     SmallVectorImpl<SDValue> &Results,\n                                     SelectionDAG &DAG) const;\n\n  /// This callback is invoked for operations that are unsupported by the\n  /// target, which are registered to use 'custom' lowering, and whose defined\n  /// values are all legal.  If the target has no operations that require custom\n  /// lowering, it need not implement this.  The default implementation of this\n  /// aborts.\n  virtual SDValue LowerOperation(SDValue Op, SelectionDAG &DAG) const;\n\n  /// This callback is invoked when a node result type is illegal for the\n  /// target, and the operation was registered to use 'custom' lowering for that\n  /// result type.  The target places new result values for the node in Results\n  /// (their number and types must exactly match those of the original return\n  /// values of the node), or leaves Results empty, which indicates that the\n  /// node is not to be custom lowered after all.\n  ///\n  /// If the target has no operations that require custom lowering, it need not\n  /// implement this.  The default implementation aborts.\n  virtual void ReplaceNodeResults(SDNode * /*N*/,\n                                  SmallVectorImpl<SDValue> &/*Results*/,\n                                  SelectionDAG &/*DAG*/) const {\n    llvm_unreachable(\"ReplaceNodeResults not implemented for this target!\");\n  }\n\n  /// This method returns the name of a target specific DAG node.\n  virtual const char *getTargetNodeName(unsigned Opcode) const;\n\n  /// This method returns a target specific FastISel object, or null if the\n  /// target does not support \"fast\" ISel.\n  virtual FastISel *createFastISel(FunctionLoweringInfo &,\n                                   const TargetLibraryInfo *) const {\n    return nullptr;\n  }\n\n  bool verifyReturnAddressArgumentIsConstant(SDValue Op,\n                                             SelectionDAG &DAG) const;\n\n  //===--------------------------------------------------------------------===//\n  // Inline Asm Support hooks\n  //\n\n  /// This hook allows the target to expand an inline asm call to be explicit\n  /// llvm code if it wants to.  This is useful for turning simple inline asms\n  /// into LLVM intrinsics, which gives the compiler more information about the\n  /// behavior of the code.\n  virtual bool ExpandInlineAsm(CallInst *) const {\n    return false;\n  }\n\n  enum ConstraintType {\n    C_Register,            // Constraint represents specific register(s).\n    C_RegisterClass,       // Constraint represents any of register(s) in class.\n    C_Memory,              // Memory constraint.\n    C_Address,             // Address constraint.\n    C_Immediate,           // Requires an immediate.\n    C_Other,               // Something else.\n    C_Unknown              // Unsupported constraint.\n  };\n\n  enum ConstraintWeight {\n    // Generic weights.\n    CW_Invalid  = -1,     // No match.\n    CW_Okay     = 0,      // Acceptable.\n    CW_Good     = 1,      // Good weight.\n    CW_Better   = 2,      // Better weight.\n    CW_Best     = 3,      // Best weight.\n\n    // Well-known weights.\n    CW_SpecificReg  = CW_Okay,    // Specific register operands.\n    CW_Register     = CW_Good,    // Register operands.\n    CW_Memory       = CW_Better,  // Memory operands.\n    CW_Constant     = CW_Best,    // Constant operand.\n    CW_Default      = CW_Okay     // Default or don't know type.\n  };\n\n  /// This contains information for each constraint that we are lowering.\n  struct AsmOperandInfo : public InlineAsm::ConstraintInfo {\n    /// This contains the actual string for the code, like \"m\".  TargetLowering\n    /// picks the 'best' code from ConstraintInfo::Codes that most closely\n    /// matches the operand.\n    std::string ConstraintCode;\n\n    /// Information about the constraint code, e.g. Register, RegisterClass,\n    /// Memory, Other, Unknown.\n    TargetLowering::ConstraintType ConstraintType = TargetLowering::C_Unknown;\n\n    /// If this is the result output operand or a clobber, this is null,\n    /// otherwise it is the incoming operand to the CallInst.  This gets\n    /// modified as the asm is processed.\n    Value *CallOperandVal = nullptr;\n\n    /// The ValueType for the operand value.\n    MVT ConstraintVT = MVT::Other;\n\n    /// Copy constructor for copying from a ConstraintInfo.\n    AsmOperandInfo(InlineAsm::ConstraintInfo Info)\n        : InlineAsm::ConstraintInfo(std::move(Info)) {}\n\n    /// Return true of this is an input operand that is a matching constraint\n    /// like \"4\".\n    bool isMatchingInputConstraint() const;\n\n    /// If this is an input matching constraint, this method returns the output\n    /// operand it matches.\n    unsigned getMatchedOperand() const;\n  };\n\n  using AsmOperandInfoVector = std::vector<AsmOperandInfo>;\n\n  /// Split up the constraint string from the inline assembly value into the\n  /// specific constraints and their prefixes, and also tie in the associated\n  /// operand values.  If this returns an empty vector, and if the constraint\n  /// string itself isn't empty, there was an error parsing.\n  virtual AsmOperandInfoVector ParseConstraints(const DataLayout &DL,\n                                                const TargetRegisterInfo *TRI,\n                                                const CallBase &Call) const;\n\n  /// Examine constraint type and operand type and determine a weight value.\n  /// The operand object must already have been set up with the operand type.\n  virtual ConstraintWeight getMultipleConstraintMatchWeight(\n      AsmOperandInfo &info, int maIndex) const;\n\n  /// Examine constraint string and operand type and determine a weight value.\n  /// The operand object must already have been set up with the operand type.\n  virtual ConstraintWeight getSingleConstraintMatchWeight(\n      AsmOperandInfo &info, const char *constraint) const;\n\n  /// Determines the constraint code and constraint type to use for the specific\n  /// AsmOperandInfo, setting OpInfo.ConstraintCode and OpInfo.ConstraintType.\n  /// If the actual operand being passed in is available, it can be passed in as\n  /// Op, otherwise an empty SDValue can be passed.\n  virtual void ComputeConstraintToUse(AsmOperandInfo &OpInfo,\n                                      SDValue Op,\n                                      SelectionDAG *DAG = nullptr) const;\n\n  /// Given a constraint, return the type of constraint it is for this target.\n  virtual ConstraintType getConstraintType(StringRef Constraint) const;\n\n  using ConstraintPair = std::pair<StringRef, TargetLowering::ConstraintType>;\n  using ConstraintGroup = SmallVector<ConstraintPair>;\n  /// Given an OpInfo with list of constraints codes as strings, return a\n  /// sorted Vector of pairs of constraint codes and their types in priority of\n  /// what we'd prefer to lower them as. This may contain immediates that\n  /// cannot be lowered, but it is meant to be a machine agnostic order of\n  /// preferences.\n  ConstraintGroup getConstraintPreferences(AsmOperandInfo &OpInfo) const;\n\n  /// Given a physical register constraint (e.g.  {edx}), return the register\n  /// number and the register class for the register.\n  ///\n  /// Given a register class constraint, like 'r', if this corresponds directly\n  /// to an LLVM register class, return a register of 0 and the register class\n  /// pointer.\n  ///\n  /// This should only be used for C_Register constraints.  On error, this\n  /// returns a register number of 0 and a null register class pointer.\n  virtual std::pair<unsigned, const TargetRegisterClass *>\n  getRegForInlineAsmConstraint(const TargetRegisterInfo *TRI,\n                               StringRef Constraint, MVT VT) const;\n\n  virtual InlineAsm::ConstraintCode\n  getInlineAsmMemConstraint(StringRef ConstraintCode) const {\n    if (ConstraintCode == \"m\")\n      return InlineAsm::ConstraintCode::m;\n    if (ConstraintCode == \"o\")\n      return InlineAsm::ConstraintCode::o;\n    if (ConstraintCode == \"X\")\n      return InlineAsm::ConstraintCode::X;\n    if (ConstraintCode == \"p\")\n      return InlineAsm::ConstraintCode::p;\n    return InlineAsm::ConstraintCode::Unknown;\n  }\n\n  /// Try to replace an X constraint, which matches anything, with another that\n  /// has more specific requirements based on the type of the corresponding\n  /// operand.  This returns null if there is no replacement to make.\n  virtual const char *LowerXConstraint(EVT ConstraintVT) const;\n\n  /// Lower the specified operand into the Ops vector.  If it is invalid, don't\n  /// add anything to Ops.\n  virtual void LowerAsmOperandForConstraint(SDValue Op, StringRef Constraint,\n                                            std::vector<SDValue> &Ops,\n                                            SelectionDAG &DAG) const;\n\n  // Lower custom output constraints. If invalid, return SDValue().\n  virtual SDValue LowerAsmOutputForConstraint(SDValue &Chain, SDValue &Glue,\n                                              const SDLoc &DL,\n                                              const AsmOperandInfo &OpInfo,\n                                              SelectionDAG &DAG) const;\n\n  // Targets may override this function to collect operands from the CallInst\n  // and for example, lower them into the SelectionDAG operands.\n  virtual void CollectTargetIntrinsicOperands(const CallInst &I,\n                                              SmallVectorImpl<SDValue> &Ops,\n                                              SelectionDAG &DAG) const;\n\n  //===--------------------------------------------------------------------===//\n  // Div utility functions\n  //\n\n  SDValue BuildSDIV(SDNode *N, SelectionDAG &DAG, bool IsAfterLegalization,\n                    SmallVectorImpl<SDNode *> &Created) const;\n  SDValue BuildUDIV(SDNode *N, SelectionDAG &DAG, bool IsAfterLegalization,\n                    SmallVectorImpl<SDNode *> &Created) const;\n  // Build sdiv by power-of-2 with conditional move instructions\n  SDValue buildSDIVPow2WithCMov(SDNode *N, const APInt &Divisor,\n                                SelectionDAG &DAG,\n                                SmallVectorImpl<SDNode *> &Created) const;\n\n  /// Targets may override this function to provide custom SDIV lowering for\n  /// power-of-2 denominators.  If the target returns an empty SDValue, LLVM\n  /// assumes SDIV is expensive and replaces it with a series of other integer\n  /// operations.\n  virtual SDValue BuildSDIVPow2(SDNode *N, const APInt &Divisor,\n                                SelectionDAG &DAG,\n                                SmallVectorImpl<SDNode *> &Created) const;\n\n  /// Targets may override this function to provide custom SREM lowering for\n  /// power-of-2 denominators.  If the target returns an empty SDValue, LLVM\n  /// assumes SREM is expensive and replaces it with a series of other integer\n  /// operations.\n  virtual SDValue BuildSREMPow2(SDNode *N, const APInt &Divisor,\n                                SelectionDAG &DAG,\n                                SmallVectorImpl<SDNode *> &Created) const;\n\n  /// Indicate whether this target prefers to combine FDIVs with the same\n  /// divisor. If the transform should never be done, return zero. If the\n  /// transform should be done, return the minimum number of divisor uses\n  /// that must exist.\n  virtual unsigned combineRepeatedFPDivisors() const {\n    return 0;\n  }\n\n  /// Hooks for building estimates in place of slower divisions and square\n  /// roots.\n\n  /// Return either a square root or its reciprocal estimate value for the input\n  /// operand.\n  /// \\p Enabled is a ReciprocalEstimate enum with value either 'Unspecified' or\n  /// 'Enabled' as set by a potential default override attribute.\n  /// If \\p RefinementSteps is 'Unspecified', the number of Newton-Raphson\n  /// refinement iterations required to generate a sufficient (though not\n  /// necessarily IEEE-754 compliant) estimate is returned in that parameter.\n  /// The boolean UseOneConstNR output is used to select a Newton-Raphson\n  /// algorithm implementation that uses either one or two constants.\n  /// The boolean Reciprocal is used to select whether the estimate is for the\n  /// square root of the input operand or the reciprocal of its square root.\n  /// A target may choose to implement its own refinement within this function.\n  /// If that's true, then return '0' as the number of RefinementSteps to avoid\n  /// any further refinement of the estimate.\n  /// An empty SDValue return means no estimate sequence can be created.\n  virtual SDValue getSqrtEstimate(SDValue Operand, SelectionDAG &DAG,\n                                  int Enabled, int &RefinementSteps,\n                                  bool &UseOneConstNR, bool Reciprocal) const {\n    return SDValue();\n  }\n\n  /// Try to convert the fminnum/fmaxnum to a compare/select sequence. This is\n  /// required for correctness since InstCombine might have canonicalized a\n  /// fcmp+select sequence to a FMINNUM/FMAXNUM intrinsic.  If we were to fall\n  /// through to the default expansion/soften to libcall, we might introduce a\n  /// link-time dependency on libm into a file that originally did not have one.\n  SDValue createSelectForFMINNUM_FMAXNUM(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Return a reciprocal estimate value for the input operand.\n  /// \\p Enabled is a ReciprocalEstimate enum with value either 'Unspecified' or\n  /// 'Enabled' as set by a potential default override attribute.\n  /// If \\p RefinementSteps is 'Unspecified', the number of Newton-Raphson\n  /// refinement iterations required to generate a sufficient (though not\n  /// necessarily IEEE-754 compliant) estimate is returned in that parameter.\n  /// A target may choose to implement its own refinement within this function.\n  /// If that's true, then return '0' as the number of RefinementSteps to avoid\n  /// any further refinement of the estimate.\n  /// An empty SDValue return means no estimate sequence can be created.\n  virtual SDValue getRecipEstimate(SDValue Operand, SelectionDAG &DAG,\n                                   int Enabled, int &RefinementSteps) const {\n    return SDValue();\n  }\n\n  /// Return a target-dependent comparison result if the input operand is\n  /// suitable for use with a square root estimate calculation. For example, the\n  /// comparison may check if the operand is NAN, INF, zero, normal, etc. The\n  /// result should be used as the condition operand for a select or branch.\n  virtual SDValue getSqrtInputTest(SDValue Operand, SelectionDAG &DAG,\n                                   const DenormalMode &Mode) const;\n\n  /// Return a target-dependent result if the input operand is not suitable for\n  /// use with a square root estimate calculation.\n  virtual SDValue getSqrtResultForDenormInput(SDValue Operand,\n                                              SelectionDAG &DAG) const {\n    return DAG.getConstantFP(0.0, SDLoc(Operand), Operand.getValueType());\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Legalization utility functions\n  //\n\n  /// Expand a MUL or [US]MUL_LOHI of n-bit values into two or four nodes,\n  /// respectively, each computing an n/2-bit part of the result.\n  /// \\param Result A vector that will be filled with the parts of the result\n  ///        in little-endian order.\n  /// \\param LL Low bits of the LHS of the MUL.  You can use this parameter\n  ///        if you want to control how low bits are extracted from the LHS.\n  /// \\param LH High bits of the LHS of the MUL.  See LL for meaning.\n  /// \\param RL Low bits of the RHS of the MUL.  See LL for meaning\n  /// \\param RH High bits of the RHS of the MUL.  See LL for meaning.\n  /// \\returns true if the node has been expanded, false if it has not\n  bool expandMUL_LOHI(unsigned Opcode, EVT VT, const SDLoc &dl, SDValue LHS,\n                      SDValue RHS, SmallVectorImpl<SDValue> &Result, EVT HiLoVT,\n                      SelectionDAG &DAG, MulExpansionKind Kind,\n                      SDValue LL = SDValue(), SDValue LH = SDValue(),\n                      SDValue RL = SDValue(), SDValue RH = SDValue()) const;\n\n  /// Expand a MUL into two nodes.  One that computes the high bits of\n  /// the result and one that computes the low bits.\n  /// \\param HiLoVT The value type to use for the Lo and Hi nodes.\n  /// \\param LL Low bits of the LHS of the MUL.  You can use this parameter\n  ///        if you want to control how low bits are extracted from the LHS.\n  /// \\param LH High bits of the LHS of the MUL.  See LL for meaning.\n  /// \\param RL Low bits of the RHS of the MUL.  See LL for meaning\n  /// \\param RH High bits of the RHS of the MUL.  See LL for meaning.\n  /// \\returns true if the node has been expanded. false if it has not\n  bool expandMUL(SDNode *N, SDValue &Lo, SDValue &Hi, EVT HiLoVT,\n                 SelectionDAG &DAG, MulExpansionKind Kind,\n                 SDValue LL = SDValue(), SDValue LH = SDValue(),\n                 SDValue RL = SDValue(), SDValue RH = SDValue()) const;\n\n  /// Attempt to expand an n-bit div/rem/divrem by constant using a n/2-bit\n  /// urem by constant and other arithmetic ops. The n/2-bit urem by constant\n  /// will be expanded by DAGCombiner. This is not possible for all constant\n  /// divisors.\n  /// \\param N Node to expand\n  /// \\param Result A vector that will be filled with the lo and high parts of\n  ///        the results. For *DIVREM, this will be the quotient parts followed\n  ///        by the remainder parts.\n  /// \\param HiLoVT The value type to use for the Lo and Hi parts. Should be\n  ///        half of VT.\n  /// \\param LL Low bits of the LHS of the operation. You can use this\n  ///        parameter if you want to control how low bits are extracted from\n  ///        the LHS.\n  /// \\param LH High bits of the LHS of the operation. See LL for meaning.\n  /// \\returns true if the node has been expanded, false if it has not.\n  bool expandDIVREMByConstant(SDNode *N, SmallVectorImpl<SDValue> &Result,\n                              EVT HiLoVT, SelectionDAG &DAG,\n                              SDValue LL = SDValue(),\n                              SDValue LH = SDValue()) const;\n\n  /// Expand funnel shift.\n  /// \\param N Node to expand\n  /// \\returns The expansion if successful, SDValue() otherwise\n  SDValue expandFunnelShift(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand rotations.\n  /// \\param N Node to expand\n  /// \\param AllowVectorOps expand vector rotate, this should only be performed\n  ///        if the legalization is happening outside of LegalizeVectorOps\n  /// \\returns The expansion if successful, SDValue() otherwise\n  SDValue expandROT(SDNode *N, bool AllowVectorOps, SelectionDAG &DAG) const;\n\n  /// Expand shift-by-parts.\n  /// \\param N Node to expand\n  /// \\param Lo lower-output-part after conversion\n  /// \\param Hi upper-output-part after conversion\n  void expandShiftParts(SDNode *N, SDValue &Lo, SDValue &Hi,\n                        SelectionDAG &DAG) const;\n\n  /// Expand float(f32) to SINT(i64) conversion\n  /// \\param N Node to expand\n  /// \\param Result output after conversion\n  /// \\returns True, if the expansion was successful, false otherwise\n  bool expandFP_TO_SINT(SDNode *N, SDValue &Result, SelectionDAG &DAG) const;\n\n  /// Expand float to UINT conversion\n  /// \\param N Node to expand\n  /// \\param Result output after conversion\n  /// \\param Chain output chain after conversion\n  /// \\returns True, if the expansion was successful, false otherwise\n  bool expandFP_TO_UINT(SDNode *N, SDValue &Result, SDValue &Chain,\n                        SelectionDAG &DAG) const;\n\n  /// Expand UINT(i64) to double(f64) conversion\n  /// \\param N Node to expand\n  /// \\param Result output after conversion\n  /// \\param Chain output chain after conversion\n  /// \\returns True, if the expansion was successful, false otherwise\n  bool expandUINT_TO_FP(SDNode *N, SDValue &Result, SDValue &Chain,\n                        SelectionDAG &DAG) const;\n\n  /// Expand fminnum/fmaxnum into fminnum_ieee/fmaxnum_ieee with quieted inputs.\n  SDValue expandFMINNUM_FMAXNUM(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand FP_TO_[US]INT_SAT into FP_TO_[US]INT and selects or min/max.\n  /// \\param N Node to expand\n  /// \\returns The expansion result\n  SDValue expandFP_TO_INT_SAT(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand check for floating point class.\n  /// \\param ResultVT The type of intrinsic call result.\n  /// \\param Op The tested value.\n  /// \\param Test The test to perform.\n  /// \\param Flags The optimization flags.\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandIS_FPCLASS(EVT ResultVT, SDValue Op, FPClassTest Test,\n                           SDNodeFlags Flags, const SDLoc &DL,\n                           SelectionDAG &DAG) const;\n\n  /// Expand CTPOP nodes. Expands vector/scalar CTPOP nodes,\n  /// vector nodes can only succeed if all operations are legal/custom.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandCTPOP(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand VP_CTPOP nodes.\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandVPCTPOP(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand CTLZ/CTLZ_ZERO_UNDEF nodes. Expands vector/scalar CTLZ nodes,\n  /// vector nodes can only succeed if all operations are legal/custom.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandCTLZ(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand VP_CTLZ/VP_CTLZ_ZERO_UNDEF nodes.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandVPCTLZ(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand CTTZ via Table Lookup.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue CTTZTableLookup(SDNode *N, SelectionDAG &DAG, const SDLoc &DL, EVT VT,\n                          SDValue Op, unsigned NumBitsPerElt) const;\n\n  /// Expand CTTZ/CTTZ_ZERO_UNDEF nodes. Expands vector/scalar CTTZ nodes,\n  /// vector nodes can only succeed if all operations are legal/custom.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandCTTZ(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand VP_CTTZ/VP_CTTZ_ZERO_UNDEF nodes.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandVPCTTZ(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand ABS nodes. Expands vector/scalar ABS nodes,\n  /// vector nodes can only succeed if all operations are legal/custom.\n  /// (ABS x) -> (XOR (ADD x, (SRA x, type_size)), (SRA x, type_size))\n  /// \\param N Node to expand\n  /// \\param IsNegative indicate negated abs\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandABS(SDNode *N, SelectionDAG &DAG,\n                    bool IsNegative = false) const;\n\n  /// Expand ABDS/ABDU nodes. Expands vector/scalar ABDS/ABDU nodes.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandABD(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand BSWAP nodes. Expands scalar/vector BSWAP nodes with i16/i32/i64\n  /// scalar types. Returns SDValue() if expand fails.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandBSWAP(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand VP_BSWAP nodes. Expands VP_BSWAP nodes with\n  /// i16/i32/i64 scalar types. Returns SDValue() if expand fails. \\param N Node\n  /// to expand \\returns The expansion result or SDValue() if it fails.\n  SDValue expandVPBSWAP(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand BITREVERSE nodes. Expands scalar/vector BITREVERSE nodes.\n  /// Returns SDValue() if expand fails.\n  /// \\param N Node to expand\n  /// \\returns The expansion result or SDValue() if it fails.\n  SDValue expandBITREVERSE(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Expand VP_BITREVERSE nodes. Expands VP_BITREVERSE nodes with\n  /// i8/i16/i32/i64 scalar types. \\param N Node to expand \\returns The\n  /// expansion result or SDValue() if it fails.\n  SDValue expandVPBITREVERSE(SDNode *N, SelectionDAG &DAG) const;\n\n  /// Turn load of vector type into a load of the individual elements.\n  /// \\param LD load to expand\n  /// \\returns BUILD_VECTOR and TokenFactor nodes.\n  std::pair<SDValue, SDValue> scalarizeVectorLoad(LoadSDNode *LD,\n                                                  SelectionDAG &DAG) const;\n\n  // Turn a store of a vector type into stores of the individual elements.\n  /// \\param ST Store with a vector value type\n  /// \\returns TokenFactor of the individual store chains.\n  SDValue scalarizeVectorStore(StoreSDNode *ST, SelectionDAG &DAG) const;\n\n  /// Expands an unaligned load to 2 half-size loads for an integer, and\n  /// possibly more for vectors.\n  std::pair<SDValue, SDValue> expandUnalignedLoad(LoadSDNode *LD,\n                                                  SelectionDAG &DAG) const;\n\n  /// Expands an unaligned store to 2 half-size stores for integer values, and\n  /// possibly more for vectors.\n  SDValue expandUnalignedStore(StoreSDNode *ST, SelectionDAG &DAG) const;\n\n  /// Increments memory address \\p Addr according to the type of the value\n  /// \\p DataVT that should be stored. If the data is stored in compressed\n  /// form, the memory address should be incremented according to the number of\n  /// the stored elements. This number is equal to the number of '1's bits\n  /// in the \\p Mask.\n  /// \\p DataVT is a vector type. \\p Mask is a vector value.\n  /// \\p DataVT and \\p Mask have the same number of vector elements.\n  SDValue IncrementMemoryAddress(SDValue Addr, SDValue Mask, const SDLoc &DL,\n                                 EVT DataVT, SelectionDAG &DAG,\n                                 bool IsCompressedMemory) const;\n\n  /// Get a pointer to vector element \\p Idx located in memory for a vector of\n  /// type \\p VecVT starting at a base address of \\p VecPtr. If \\p Idx is out of\n  /// bounds the returned pointer is unspecified, but will be within the vector\n  /// bounds.\n  SDValue getVectorElementPointer(SelectionDAG &DAG, SDValue VecPtr, EVT VecVT,\n                                  SDValue Index) const;\n\n  /// Get a pointer to a sub-vector of type \\p SubVecVT at index \\p Idx located\n  /// in memory for a vector of type \\p VecVT starting at a base address of\n  /// \\p VecPtr. If \\p Idx plus the size of \\p SubVecVT is out of bounds the\n  /// returned pointer is unspecified, but the value returned will be such that\n  /// the entire subvector would be within the vector bounds.\n  SDValue getVectorSubVecPointer(SelectionDAG &DAG, SDValue VecPtr, EVT VecVT,\n                                 EVT SubVecVT, SDValue Index) const;\n\n  /// Method for building the DAG expansion of ISD::[US][MIN|MAX]. This\n  /// method accepts integers as its arguments.\n  SDValue expandIntMINMAX(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::[US][ADD|SUB]SAT. This\n  /// method accepts integers as its arguments.\n  SDValue expandAddSubSat(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::[US]SHLSAT. This\n  /// method accepts integers as its arguments.\n  SDValue expandShlSat(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::[U|S]MULFIX[SAT]. This\n  /// method accepts integers as its arguments.\n  SDValue expandFixedPointMul(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::[US]DIVFIX[SAT]. This\n  /// method accepts integers as its arguments.\n  /// Note: This method may fail if the division could not be performed\n  /// within the type. Clients must retry with a wider type if this happens.\n  SDValue expandFixedPointDiv(unsigned Opcode, const SDLoc &dl,\n                              SDValue LHS, SDValue RHS,\n                              unsigned Scale, SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::U(ADD|SUB)O. Expansion\n  /// always suceeds and populates the Result and Overflow arguments.\n  void expandUADDSUBO(SDNode *Node, SDValue &Result, SDValue &Overflow,\n                      SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::S(ADD|SUB)O. Expansion\n  /// always suceeds and populates the Result and Overflow arguments.\n  void expandSADDSUBO(SDNode *Node, SDValue &Result, SDValue &Overflow,\n                      SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::[US]MULO. Returns whether\n  /// expansion was successful and populates the Result and Overflow arguments.\n  bool expandMULO(SDNode *Node, SDValue &Result, SDValue &Overflow,\n                  SelectionDAG &DAG) const;\n\n  /// forceExpandWideMUL - Unconditionally expand a MUL into either a libcall or\n  /// brute force via a wide multiplication. The expansion works by\n  /// attempting to do a multiplication on a wider type twice the size of the\n  /// original operands. LL and LH represent the lower and upper halves of the\n  /// first operand. RL and RH represent the lower and upper halves of the\n  /// second operand. The upper and lower halves of the result are stored in Lo\n  /// and Hi.\n  void forceExpandWideMUL(SelectionDAG &DAG, const SDLoc &dl, bool Signed,\n                          EVT WideVT, const SDValue LL, const SDValue LH,\n                          const SDValue RL, const SDValue RH, SDValue &Lo,\n                          SDValue &Hi) const;\n\n  /// Same as above, but creates the upper halves of each operand by\n  /// sign/zero-extending the operands.\n  void forceExpandWideMUL(SelectionDAG &DAG, const SDLoc &dl, bool Signed,\n                          const SDValue LHS, const SDValue RHS, SDValue &Lo,\n                          SDValue &Hi) const;\n\n  /// Expand a VECREDUCE_* into an explicit calculation. If Count is specified,\n  /// only the first Count elements of the vector are used.\n  SDValue expandVecReduce(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Expand a VECREDUCE_SEQ_* into an explicit ordered calculation.\n  SDValue expandVecReduceSeq(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Expand an SREM or UREM using SDIV/UDIV or SDIVREM/UDIVREM, if legal.\n  /// Returns true if the expansion was successful.\n  bool expandREM(SDNode *Node, SDValue &Result, SelectionDAG &DAG) const;\n\n  /// Method for building the DAG expansion of ISD::VECTOR_SPLICE. This\n  /// method accepts vectors as its arguments.\n  SDValue expandVectorSplice(SDNode *Node, SelectionDAG &DAG) const;\n\n  /// Legalize a SETCC or VP_SETCC with given LHS and RHS and condition code CC\n  /// on the current target. A VP_SETCC will additionally be given a Mask\n  /// and/or EVL not equal to SDValue().\n  ///\n  /// If the SETCC has been legalized using AND / OR, then the legalized node\n  /// will be stored in LHS. RHS and CC will be set to SDValue(). NeedInvert\n  /// will be set to false. This will also hold if the VP_SETCC has been\n  /// legalized using VP_AND / VP_OR.\n  ///\n  /// If the SETCC / VP_SETCC has been legalized by using\n  /// getSetCCSwappedOperands(), then the values of LHS and RHS will be\n  /// swapped, CC will be set to the new condition, and NeedInvert will be set\n  /// to false.\n  ///\n  /// If the SETCC / VP_SETCC has been legalized using the inverse condcode,\n  /// then LHS and RHS will be unchanged, CC will set to the inverted condcode,\n  /// and NeedInvert will be set to true. The caller must invert the result of\n  /// the SETCC with SelectionDAG::getLogicalNOT() or take equivalent action to\n  /// swap the effect of a true/false result.\n  ///\n  /// \\returns true if the SETCC / VP_SETCC has been legalized, false if it\n  /// hasn't.\n  bool LegalizeSetCCCondCode(SelectionDAG &DAG, EVT VT, SDValue &LHS,\n                             SDValue &RHS, SDValue &CC, SDValue Mask,\n                             SDValue EVL, bool &NeedInvert, const SDLoc &dl,\n                             SDValue &Chain, bool IsSignaling = false) const;\n\n  //===--------------------------------------------------------------------===//\n  // Instruction Emitting Hooks\n  //\n\n  /// This method should be implemented by targets that mark instructions with\n  /// the 'usesCustomInserter' flag.  These instructions are special in various\n  /// ways, which require special support to insert.  The specified MachineInstr\n  /// is created but not inserted into any basic blocks, and this method is\n  /// called to expand it into a sequence of instructions, potentially also\n  /// creating new basic blocks and control flow.\n  /// As long as the returned basic block is different (i.e., we created a new\n  /// one), the custom inserter is free to modify the rest of \\p MBB.\n  virtual MachineBasicBlock *\n  EmitInstrWithCustomInserter(MachineInstr &MI, MachineBasicBlock *MBB) const;\n\n  /// This method should be implemented by targets that mark instructions with\n  /// the 'hasPostISelHook' flag. These instructions must be adjusted after\n  /// instruction selection by target hooks.  e.g. To fill in optional defs for\n  /// ARM 's' setting instructions.\n  virtual void AdjustInstrPostInstrSelection(MachineInstr &MI,\n                                             SDNode *Node) const;\n\n  /// If this function returns true, SelectionDAGBuilder emits a\n  /// LOAD_STACK_GUARD node when it is lowering Intrinsic::stackprotector.\n  virtual bool useLoadStackGuardNode() const {\n    return false;\n  }\n\n  virtual SDValue emitStackGuardXorFP(SelectionDAG &DAG, SDValue Val,\n                                      const SDLoc &DL) const {\n    llvm_unreachable(\"not implemented for this target\");\n  }\n\n  /// Lower TLS global address SDNode for target independent emulated TLS model.\n  virtual SDValue LowerToTLSEmulatedModel(const GlobalAddressSDNode *GA,\n                                          SelectionDAG &DAG) const;\n\n  /// Expands target specific indirect branch for the case of JumpTable\n  /// expansion.\n  virtual SDValue expandIndirectJTBranch(const SDLoc &dl, SDValue Value,\n                                         SDValue Addr, int JTI,\n                                         SelectionDAG &DAG) const;\n\n  // seteq(x, 0) -> truncate(srl(ctlz(zext(x)), log2(#bits)))\n  // If we're comparing for equality to zero and isCtlzFast is true, expose the\n  // fact that this can be implemented as a ctlz/srl pair, so that the dag\n  // combiner can fold the new nodes.\n  SDValue lowerCmpEqZeroToCtlzSrl(SDValue Op, SelectionDAG &DAG) const;\n\n  // Return true if `X & Y eq/ne 0` is preferable to `X & Y ne/eq Y`\n  virtual bool isXAndYEqZeroPreferableToXAndYEqY(ISD::CondCode, EVT) const {\n    return true;\n  }\n\nprivate:\n  SDValue foldSetCCWithAnd(EVT VT, SDValue N0, SDValue N1, ISD::CondCode Cond,\n                           const SDLoc &DL, DAGCombinerInfo &DCI) const;\n  SDValue foldSetCCWithBinOp(EVT VT, SDValue N0, SDValue N1, ISD::CondCode Cond,\n                             const SDLoc &DL, DAGCombinerInfo &DCI) const;\n\n  SDValue optimizeSetCCOfSignedTruncationCheck(EVT SCCVT, SDValue N0,\n                                               SDValue N1, ISD::CondCode Cond,\n                                               DAGCombinerInfo &DCI,\n                                               const SDLoc &DL) const;\n\n  // (X & (C l>>/<< Y)) ==/!= 0  -->  ((X <</l>> Y) & C) ==/!= 0\n  SDValue optimizeSetCCByHoistingAndByConstFromLogicalShift(\n      EVT SCCVT, SDValue N0, SDValue N1C, ISD::CondCode Cond,\n      DAGCombinerInfo &DCI, const SDLoc &DL) const;\n\n  SDValue prepareUREMEqFold(EVT SETCCVT, SDValue REMNode,\n                            SDValue CompTargetNode, ISD::CondCode Cond,\n                            DAGCombinerInfo &DCI, const SDLoc &DL,\n                            SmallVectorImpl<SDNode *> &Created) const;\n  SDValue buildUREMEqFold(EVT SETCCVT, SDValue REMNode, SDValue CompTargetNode,\n                          ISD::CondCode Cond, DAGCombinerInfo &DCI,\n                          const SDLoc &DL) const;\n\n  SDValue prepareSREMEqFold(EVT SETCCVT, SDValue REMNode,\n                            SDValue CompTargetNode, ISD::CondCode Cond,\n                            DAGCombinerInfo &DCI, const SDLoc &DL,\n                            SmallVectorImpl<SDNode *> &Created) const;\n  SDValue buildSREMEqFold(EVT SETCCVT, SDValue REMNode, SDValue CompTargetNode,\n                          ISD::CondCode Cond, DAGCombinerInfo &DCI,\n                          const SDLoc &DL) const;\n};\n\n/// Given an LLVM IR type and return type attributes, compute the return value\n/// EVTs and flags, and optionally also the offsets, if the return value is\n/// being lowered to memory.\nvoid GetReturnInfo(CallingConv::ID CC, Type *ReturnType, AttributeList attr,\n                   SmallVectorImpl<ISD::OutputArg> &Outs,\n                   const TargetLowering &TLI, const DataLayout &DL);\n\n} // end namespace llvm\n\n#endif // LLVM_CODEGEN_TARGETLOWERING_H\n"}, {"id": "3BA1429FF09CB08E", "name": "llvm::SDValue::getValueType", "path": "llvm-project/llvm/include/llvm/CodeGen/SelectionDAGNodes.h", "start": {"line": 1161, "col": 1}, "end": {"line": 1163, "col": 1}, "code": "  return Node->getValueType(ResNo);\n}\n\ninline unsigned SDValue::getNumOperands() const {\n  return Node->getNumOperands();\n}\n\ninline const SDValue &SDValue::getOperand(unsigned i) const {\n  return Node->getOperand(i);\n}\n\ninline uint64_t SDValue::getConstantOperandVal(unsigned i) const {\n  return Node->getConstantOperandVal(i);\n}\n\ninline const APInt &SDValue::getConstantOperandAPInt(unsigned i) const {\n  return Node->getConstantOperandAPInt(i);\n}\n\ninline bool SDValue::isTargetOpcode() const {\n  return Node->isTargetOpcode();\n}\n\ninline bool SDValue::isTargetMemoryOpcode() const {\n  return Node->isTargetMemoryOpcode();\n}\n\ninline bool SDValue::isMachineOpcode() const {\n  return Node->isMachineOpcode();\n}\n\ninline unsigned SDValue::getMachineOpcode() const {\n  return Node->getMachineOpcode();\n}\n\ninline bool SDValue::isUndef() const {\n  return Node->isUndef();\n}\n\ninline bool SDValue::use_empty() const {\n  return !Node->hasAnyUseOfValue(ResNo);\n}\n\ninline bool SDValue::hasOneUse() const {\n  return Node->hasNUsesOfValue(1, ResNo);\n}\n\ninline const DebugLoc &SDValue::getDebugLoc() const {\n  return Node->getDebugLoc();\n}\n\ninline void SDValue::dump() const {\n  return Node->dump();\n}\n\ninline void SDValue::dump(const SelectionDAG *G) const {\n  return Node->dump(G);\n}\n\ninline void SDValue::dumpr() const {\n  return Node->dumpr();\n}\n\ninline void SDValue::dumpr(const SelectionDAG *G) const {\n  return Node->dumpr(G);\n}\n\n// Define inline functions from the SDUse class.\n\ninline void SDUse::set(const SDValue &V) {\n  if (Val.getNode()) removeFromList();\n  Val = V;\n  if (V.getNode())\n    V->addUse(*this);\n}\n\ninline void SDUse::setInitial(const SDValue &V) {\n  Val = V;\n  V->addUse(*this);\n}\n\ninline void SDUse::setNode(SDNode *N) {\n  if (Val.getNode()) removeFromList();\n  Val.setNode(N);\n  if (N) N->addUse(*this);\n}\n\n/// This class is used to form a handle around another node that\n/// is persistent and is updated across invocations of replaceAllUsesWith on its\n/// operand.  This node should be directly created by end-users and not added to\n/// the AllNodes list.\nclass HandleSDNode : public SDNode {\n  SDUse Op;\n\npublic:\n  explicit HandleSDNode(SDValue X)\n    : SDNode(ISD::HANDLENODE, 0, DebugLoc(), getSDVTList(MVT::Other)) {\n    // HandleSDNodes are never inserted into the DAG, so they won't be\n    // auto-numbered. Use ID 65535 as a sentinel.\n    PersistentId = 0xffff;\n\n    // Manually set up the operand list. This node type is special in that it's\n    // always stack allocated and SelectionDAG does not manage its operands.\n    // TODO: This should either (a) not be in the SDNode hierarchy, or (b) not\n    // be so special.\n    Op.setUser(this);\n    Op.setInitial(X);\n    NumOperands = 1;\n    OperandList = &Op;\n  }\n  ~HandleSDNode();\n\n  const SDValue &getValue() const { return Op; }\n};\n\nclass AddrSpaceCastSDNode : public SDNode {\nprivate:\n  unsigned SrcAddrSpace;\n  unsigned DestAddrSpace;\n\npublic:\n  AddrSpaceCastSDNode(unsigned Order, const DebugLoc &dl, EVT VT,\n                      unsigned SrcAS, unsigned DestAS);\n\n  unsigned getSrcAddressSpace() const { return SrcAddrSpace; }\n  unsigned getDestAddressSpace() const { return DestAddrSpace; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::ADDRSPACECAST;\n  }\n};\n\n/// This is an abstract virtual class for memory operations.\nclass MemSDNode : public SDNode {\nprivate:\n  // VT of in-memory value.\n  EVT MemoryVT;\n\nprotected:\n  /// Memory reference information.\n  MachineMemOperand *MMO;\n\npublic:\n  MemSDNode(unsigned Opc, unsigned Order, const DebugLoc &dl, SDVTList VTs,\n            EVT memvt, MachineMemOperand *MMO);\n\n  bool readMem() const { return MMO->isLoad(); }\n  bool writeMem() const { return MMO->isStore(); }\n\n  /// Returns alignment and volatility of the memory access\n  Align getOriginalAlign() const { return MMO->getBaseAlign(); }\n  Align getAlign() const { return MMO->getAlign(); }\n\n  /// Return the SubclassData value, without HasDebugValue. This contains an\n  /// encoding of the volatile flag, as well as bits used by subclasses. This\n  /// function should only be used to compute a FoldingSetNodeID value.\n  /// The HasDebugValue bit is masked out because CSE map needs to match\n  /// nodes with debug info with nodes without debug info. Same is about\n  /// isDivergent bit.\n  unsigned getRawSubclassData() const {\n    uint16_t Data;\n    union {\n      char RawSDNodeBits[sizeof(uint16_t)];\n      SDNodeBitfields SDNodeBits;\n    };\n    memcpy(&RawSDNodeBits, &this->RawSDNodeBits, sizeof(this->RawSDNodeBits));\n    SDNodeBits.HasDebugValue = 0;\n    SDNodeBits.IsDivergent = false;\n    memcpy(&Data, &RawSDNodeBits, sizeof(RawSDNodeBits));\n    return Data;\n  }\n\n  bool isVolatile() const { return MemSDNodeBits.IsVolatile; }\n  bool isNonTemporal() const { return MemSDNodeBits.IsNonTemporal; }\n  bool isDereferenceable() const { return MemSDNodeBits.IsDereferenceable; }\n  bool isInvariant() const { return MemSDNodeBits.IsInvariant; }\n\n  // Returns the offset from the location of the access.\n  int64_t getSrcValueOffset() const { return MMO->getOffset(); }\n\n  /// Returns the AA info that describes the dereference.\n  AAMDNodes getAAInfo() const { return MMO->getAAInfo(); }\n\n  /// Returns the Ranges that describes the dereference.\n  const MDNode *getRanges() const { return MMO->getRanges(); }\n\n  /// Returns the synchronization scope ID for this memory operation.\n  SyncScope::ID getSyncScopeID() const { return MMO->getSyncScopeID(); }\n\n  /// Return the atomic ordering requirements for this memory operation. For\n  /// cmpxchg atomic operations, return the atomic ordering requirements when\n  /// store occurs.\n  AtomicOrdering getSuccessOrdering() const {\n    return MMO->getSuccessOrdering();\n  }\n\n  /// Return a single atomic ordering that is at least as strong as both the\n  /// success and failure orderings for an atomic operation.  (For operations\n  /// other than cmpxchg, this is equivalent to getSuccessOrdering().)\n  AtomicOrdering getMergedOrdering() const { return MMO->getMergedOrdering(); }\n\n  /// Return true if the memory operation ordering is Unordered or higher.\n  bool isAtomic() const { return MMO->isAtomic(); }\n\n  /// Returns true if the memory operation doesn't imply any ordering\n  /// constraints on surrounding memory operations beyond the normal memory\n  /// aliasing rules.\n  bool isUnordered() const { return MMO->isUnordered(); }\n\n  /// Returns true if the memory operation is neither atomic or volatile.\n  bool isSimple() const { return !isAtomic() && !isVolatile(); }\n\n  /// Return the type of the in-memory value.\n  EVT getMemoryVT() const { return MemoryVT; }\n\n  /// Return a MachineMemOperand object describing the memory\n  /// reference performed by operation.\n  MachineMemOperand *getMemOperand() const { return MMO; }\n\n  const MachinePointerInfo &getPointerInfo() const {\n    return MMO->getPointerInfo();\n  }\n\n  /// Return the address space for the associated pointer\n  unsigned getAddressSpace() const {\n    return getPointerInfo().getAddrSpace();\n  }\n\n  /// Update this MemSDNode's MachineMemOperand information\n  /// to reflect the alignment of NewMMO, if it has a greater alignment.\n  /// This must only be used when the new alignment applies to all users of\n  /// this MachineMemOperand.\n  void refineAlignment(const MachineMemOperand *NewMMO) {\n    MMO->refineAlignment(NewMMO);\n  }\n\n  const SDValue &getChain() const { return getOperand(0); }\n\n  const SDValue &getBasePtr() const {\n    switch (getOpcode()) {\n    case ISD::STORE:\n    case ISD::ATOMIC_STORE:\n    case ISD::VP_STORE:\n    case ISD::MSTORE:\n    case ISD::VP_SCATTER:\n    case ISD::EXPERIMENTAL_VP_STRIDED_STORE:\n      return getOperand(2);\n    case ISD::MGATHER:\n    case ISD::MSCATTER:\n      return getOperand(3);\n    default:\n      return getOperand(1);\n    }\n  }\n\n  // Methods to support isa and dyn_cast\n  static bool classof(const SDNode *N) {\n    // For some targets, we lower some target intrinsics to a MemIntrinsicNode\n    // with either an intrinsic or a target opcode.\n    switch (N->getOpcode()) {\n    case ISD::LOAD:\n    case ISD::STORE:\n    case ISD::PREFETCH:\n    case ISD::ATOMIC_CMP_SWAP:\n    case ISD::ATOMIC_CMP_SWAP_WITH_SUCCESS:\n    case ISD::ATOMIC_SWAP:\n    case ISD::ATOMIC_LOAD_ADD:\n    case ISD::ATOMIC_LOAD_SUB:\n    case ISD::ATOMIC_LOAD_AND:\n    case ISD::ATOMIC_LOAD_CLR:\n    case ISD::ATOMIC_LOAD_OR:\n    case ISD::ATOMIC_LOAD_XOR:\n    case ISD::ATOMIC_LOAD_NAND:\n    case ISD::ATOMIC_LOAD_MIN:\n    case ISD::ATOMIC_LOAD_MAX:\n    case ISD::ATOMIC_LOAD_UMIN:\n    case ISD::ATOMIC_LOAD_UMAX:\n    case ISD::ATOMIC_LOAD_FADD:\n    case ISD::ATOMIC_LOAD_FSUB:\n    case ISD::ATOMIC_LOAD_FMAX:\n    case ISD::ATOMIC_LOAD_FMIN:\n    case ISD::ATOMIC_LOAD_UINC_WRAP:\n    case ISD::ATOMIC_LOAD_UDEC_WRAP:\n    case ISD::ATOMIC_LOAD:\n    case ISD::ATOMIC_STORE:\n    case ISD::MLOAD:\n    case ISD::MSTORE:\n    case ISD::MGATHER:\n    case ISD::MSCATTER:\n    case ISD::VP_LOAD:\n    case ISD::VP_STORE:\n    case ISD::VP_GATHER:\n    case ISD::VP_SCATTER:\n    case ISD::EXPERIMENTAL_VP_STRIDED_LOAD:\n    case ISD::EXPERIMENTAL_VP_STRIDED_STORE:\n    case ISD::GET_FPENV_MEM:\n    case ISD::SET_FPENV_MEM:\n      return true;\n    default:\n      return N->isMemIntrinsic() || N->isTargetMemoryOpcode();\n    }\n  }\n};\n\n/// This is an SDNode representing atomic operations.\nclass AtomicSDNode : public MemSDNode {\npublic:\n  AtomicSDNode(unsigned Opc, unsigned Order, const DebugLoc &dl, SDVTList VTL,\n               EVT MemVT, MachineMemOperand *MMO)\n    : MemSDNode(Opc, Order, dl, VTL, MemVT, MMO) {\n    assert(((Opc != ISD::ATOMIC_LOAD && Opc != ISD::ATOMIC_STORE) ||\n            MMO->isAtomic()) && \"then why are we using an AtomicSDNode?\");\n  }\n\n  const SDValue &getBasePtr() const {\n    return getOpcode() == ISD::ATOMIC_STORE ? getOperand(2) : getOperand(1);\n  }\n  const SDValue &getVal() const {\n    return getOpcode() == ISD::ATOMIC_STORE ? getOperand(1) : getOperand(2);\n  }\n\n  /// Returns true if this SDNode represents cmpxchg atomic operation, false\n  /// otherwise.\n  bool isCompareAndSwap() const {\n    unsigned Op = getOpcode();\n    return Op == ISD::ATOMIC_CMP_SWAP ||\n           Op == ISD::ATOMIC_CMP_SWAP_WITH_SUCCESS;\n  }\n\n  /// For cmpxchg atomic operations, return the atomic ordering requirements\n  /// when store does not occur.\n  AtomicOrdering getFailureOrdering() const {\n    assert(isCompareAndSwap() && \"Must be cmpxchg operation\");\n    return MMO->getFailureOrdering();\n  }\n\n  // Methods to support isa and dyn_cast\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::ATOMIC_CMP_SWAP     ||\n           N->getOpcode() == ISD::ATOMIC_CMP_SWAP_WITH_SUCCESS ||\n           N->getOpcode() == ISD::ATOMIC_SWAP         ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_ADD     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_SUB     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_AND     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_CLR     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_OR      ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_XOR     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_NAND    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_MIN     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_MAX     ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_UMIN    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_UMAX    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_FADD    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_FSUB    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_FMAX    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_FMIN    ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_UINC_WRAP ||\n           N->getOpcode() == ISD::ATOMIC_LOAD_UDEC_WRAP ||\n           N->getOpcode() == ISD::ATOMIC_LOAD         ||\n           N->getOpcode() == ISD::ATOMIC_STORE;\n  }\n};\n\n/// This SDNode is used for target intrinsics that touch\n/// memory and need an associated MachineMemOperand. Its opcode may be\n/// INTRINSIC_VOID, INTRINSIC_W_CHAIN, PREFETCH, or a target-specific opcode\n/// with a value not less than FIRST_TARGET_MEMORY_OPCODE.\nclass MemIntrinsicSDNode : public MemSDNode {\npublic:\n  MemIntrinsicSDNode(unsigned Opc, unsigned Order, const DebugLoc &dl,\n                     SDVTList VTs, EVT MemoryVT, MachineMemOperand *MMO)\n      : MemSDNode(Opc, Order, dl, VTs, MemoryVT, MMO) {\n    SDNodeBits.IsMemIntrinsic = true;\n  }\n\n  // Methods to support isa and dyn_cast\n  static bool classof(const SDNode *N) {\n    // We lower some target intrinsics to their target opcode\n    // early a node with a target opcode can be of this class\n    return N->isMemIntrinsic()             ||\n           N->getOpcode() == ISD::PREFETCH ||\n           N->isTargetMemoryOpcode();\n  }\n};\n\n/// This SDNode is used to implement the code generator\n/// support for the llvm IR shufflevector instruction.  It combines elements\n/// from two input vectors into a new input vector, with the selection and\n/// ordering of elements determined by an array of integers, referred to as\n/// the shuffle mask.  For input vectors of width N, mask indices of 0..N-1\n/// refer to elements from the LHS input, and indices from N to 2N-1 the RHS.\n/// An index of -1 is treated as undef, such that the code generator may put\n/// any value in the corresponding element of the result.\nclass ShuffleVectorSDNode : public SDNode {\n  // The memory for Mask is owned by the SelectionDAG's OperandAllocator, and\n  // is freed when the SelectionDAG object is destroyed.\n  const int *Mask;\n\nprotected:\n  friend class SelectionDAG;\n\n  ShuffleVectorSDNode(EVT VT, unsigned Order, const DebugLoc &dl, const int *M)\n      : SDNode(ISD::VECTOR_SHUFFLE, Order, dl, getSDVTList(VT)), Mask(M) {}\n\npublic:\n  ArrayRef<int> getMask() const {\n    EVT VT = getValueType(0);\n    return ArrayRef(Mask, VT.getVectorNumElements());\n  }\n\n  int getMaskElt(unsigned Idx) const {\n    assert(Idx < getValueType(0).getVectorNumElements() && \"Idx out of range!\");\n    return Mask[Idx];\n  }\n\n  bool isSplat() const { return isSplatMask(Mask, getValueType(0)); }\n\n  int getSplatIndex() const {\n    assert(isSplat() && \"Cannot get splat index for non-splat!\");\n    EVT VT = getValueType(0);\n    for (unsigned i = 0, e = VT.getVectorNumElements(); i != e; ++i)\n      if (Mask[i] >= 0)\n        return Mask[i];\n\n    // We can choose any index value here and be correct because all elements\n    // are undefined. Return 0 for better potential for callers to simplify.\n    return 0;\n  }\n\n  static bool isSplatMask(const int *Mask, EVT VT);\n\n  /// Change values in a shuffle permute mask assuming\n  /// the two vector operands have swapped position.\n  static void commuteMask(MutableArrayRef<int> Mask) {\n    unsigned NumElems = Mask.size();\n    for (unsigned i = 0; i != NumElems; ++i) {\n      int idx = Mask[i];\n      if (idx < 0)\n        continue;\n      else if (idx < (int)NumElems)\n        Mask[i] = idx + NumElems;\n      else\n        Mask[i] = idx - NumElems;\n    }\n  }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::VECTOR_SHUFFLE;\n  }\n};\n\nclass ConstantSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const ConstantInt *Value;\n\n  ConstantSDNode(bool isTarget, bool isOpaque, const ConstantInt *val, EVT VT)\n      : SDNode(isTarget ? ISD::TargetConstant : ISD::Constant, 0, DebugLoc(),\n               getSDVTList(VT)),\n        Value(val) {\n    ConstantSDNodeBits.IsOpaque = isOpaque;\n  }\n\npublic:\n  const ConstantInt *getConstantIntValue() const { return Value; }\n  const APInt &getAPIntValue() const { return Value->getValue(); }\n  uint64_t getZExtValue() const { return Value->getZExtValue(); }\n  int64_t getSExtValue() const { return Value->getSExtValue(); }\n  uint64_t getLimitedValue(uint64_t Limit = UINT64_MAX) {\n    return Value->getLimitedValue(Limit);\n  }\n  MaybeAlign getMaybeAlignValue() const { return Value->getMaybeAlignValue(); }\n  Align getAlignValue() const { return Value->getAlignValue(); }\n\n  bool isOne() const { return Value->isOne(); }\n  bool isZero() const { return Value->isZero(); }\n  bool isAllOnes() const { return Value->isMinusOne(); }\n  bool isMaxSignedValue() const { return Value->isMaxValue(true); }\n  bool isMinSignedValue() const { return Value->isMinValue(true); }\n\n  bool isOpaque() const { return ConstantSDNodeBits.IsOpaque; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::Constant ||\n           N->getOpcode() == ISD::TargetConstant;\n  }\n};\n\nuint64_t SDNode::getConstantOperandVal(unsigned Num) const {\n  return cast<ConstantSDNode>(getOperand(Num))->getZExtValue();\n}\n\nuint64_t SDNode::getAsZExtVal() const {\n  return cast<ConstantSDNode>(this)->getZExtValue();\n}\n\nconst APInt &SDNode::getConstantOperandAPInt(unsigned Num) const {\n  return cast<ConstantSDNode>(getOperand(Num))->getAPIntValue();\n}\n\nconst APInt &SDNode::getAsAPIntVal() const {\n  return cast<ConstantSDNode>(this)->getAPIntValue();\n}\n\nclass ConstantFPSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const ConstantFP *Value;\n\n  ConstantFPSDNode(bool isTarget, const ConstantFP *val, EVT VT)\n      : SDNode(isTarget ? ISD::TargetConstantFP : ISD::ConstantFP, 0,\n               DebugLoc(), getSDVTList(VT)),\n        Value(val) {}\n\npublic:\n  const APFloat& getValueAPF() const { return Value->getValueAPF(); }\n  const ConstantFP *getConstantFPValue() const { return Value; }\n\n  /// Return true if the value is positive or negative zero.\n  bool isZero() const { return Value->isZero(); }\n\n  /// Return true if the value is a NaN.\n  bool isNaN() const { return Value->isNaN(); }\n\n  /// Return true if the value is an infinity\n  bool isInfinity() const { return Value->isInfinity(); }\n\n  /// Return true if the value is negative.\n  bool isNegative() const { return Value->isNegative(); }\n\n  /// We don't rely on operator== working on double values, as\n  /// it returns true for things that are clearly not equal, like -0.0 and 0.0.\n  /// As such, this method can be used to do an exact bit-for-bit comparison of\n  /// two floating point values.\n\n  /// We leave the version with the double argument here because it's just so\n  /// convenient to write \"2.0\" and the like.  Without this function we'd\n  /// have to duplicate its logic everywhere it's called.\n  bool isExactlyValue(double V) const {\n    return Value->getValueAPF().isExactlyValue(V);\n  }\n  bool isExactlyValue(const APFloat& V) const;\n\n  static bool isValueValidForType(EVT VT, const APFloat& Val);\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::ConstantFP ||\n           N->getOpcode() == ISD::TargetConstantFP;\n  }\n};\n\n/// Returns true if \\p V is a constant integer zero.\nbool isNullConstant(SDValue V);\n\n/// Returns true if \\p V is an FP constant with a value of positive zero.\nbool isNullFPConstant(SDValue V);\n\n/// Returns true if \\p V is an integer constant with all bits set.\nbool isAllOnesConstant(SDValue V);\n\n/// Returns true if \\p V is a constant integer one.\nbool isOneConstant(SDValue V);\n\n/// Returns true if \\p V is a constant min signed integer value.\nbool isMinSignedConstant(SDValue V);\n\n/// Returns true if \\p V is a neutral element of Opc with Flags.\n/// When OperandNo is 0, it checks that V is a left identity. Otherwise, it\n/// checks that V is a right identity.\nbool isNeutralConstant(unsigned Opc, SDNodeFlags Flags, SDValue V,\n                       unsigned OperandNo);\n\n/// Return the non-bitcasted source operand of \\p V if it exists.\n/// If \\p V is not a bitcasted value, it is returned as-is.\nSDValue peekThroughBitcasts(SDValue V);\n\n/// Return the non-bitcasted and one-use source operand of \\p V if it exists.\n/// If \\p V is not a bitcasted one-use value, it is returned as-is.\nSDValue peekThroughOneUseBitcasts(SDValue V);\n\n/// Return the non-extracted vector source operand of \\p V if it exists.\n/// If \\p V is not an extracted subvector, it is returned as-is.\nSDValue peekThroughExtractSubvectors(SDValue V);\n\n/// Return the non-truncated source operand of \\p V if it exists.\n/// If \\p V is not a truncation, it is returned as-is.\nSDValue peekThroughTruncates(SDValue V);\n\n/// Returns true if \\p V is a bitwise not operation. Assumes that an all ones\n/// constant is canonicalized to be operand 1.\nbool isBitwiseNot(SDValue V, bool AllowUndefs = false);\n\n/// If \\p V is a bitwise not, returns the inverted operand. Otherwise returns\n/// an empty SDValue. Only bits set in \\p Mask are required to be inverted,\n/// other bits may be arbitrary.\nSDValue getBitwiseNotOperand(SDValue V, SDValue Mask, bool AllowUndefs);\n\n/// Returns the SDNode if it is a constant splat BuildVector or constant int.\nConstantSDNode *isConstOrConstSplat(SDValue N, bool AllowUndefs = false,\n                                    bool AllowTruncation = false);\n\n/// Returns the SDNode if it is a demanded constant splat BuildVector or\n/// constant int.\nConstantSDNode *isConstOrConstSplat(SDValue N, const APInt &DemandedElts,\n                                    bool AllowUndefs = false,\n                                    bool AllowTruncation = false);\n\n/// Returns the SDNode if it is a constant splat BuildVector or constant float.\nConstantFPSDNode *isConstOrConstSplatFP(SDValue N, bool AllowUndefs = false);\n\n/// Returns the SDNode if it is a demanded constant splat BuildVector or\n/// constant float.\nConstantFPSDNode *isConstOrConstSplatFP(SDValue N, const APInt &DemandedElts,\n                                        bool AllowUndefs = false);\n\n/// Return true if the value is a constant 0 integer or a splatted vector of\n/// a constant 0 integer (with no undefs by default).\n/// Build vector implicit truncation is not an issue for null values.\nbool isNullOrNullSplat(SDValue V, bool AllowUndefs = false);\n\n/// Return true if the value is a constant 1 integer or a splatted vector of a\n/// constant 1 integer (with no undefs).\n/// Build vector implicit truncation is allowed, but the truncated bits need to\n/// be zero.\nbool isOneOrOneSplat(SDValue V, bool AllowUndefs = false);\n\n/// Return true if the value is a constant -1 integer or a splatted vector of a\n/// constant -1 integer (with no undefs).\n/// Does not permit build vector implicit truncation.\nbool isAllOnesOrAllOnesSplat(SDValue V, bool AllowUndefs = false);\n\n/// Return true if \\p V is either a integer or FP constant.\ninline bool isIntOrFPConstant(SDValue V) {\n  return isa<ConstantSDNode>(V) || isa<ConstantFPSDNode>(V);\n}\n\nclass GlobalAddressSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const GlobalValue *TheGlobal;\n  int64_t Offset;\n  unsigned TargetFlags;\n\n  GlobalAddressSDNode(unsigned Opc, unsigned Order, const DebugLoc &DL,\n                      const GlobalValue *GA, EVT VT, int64_t o,\n                      unsigned TF);\n\npublic:\n  const GlobalValue *getGlobal() const { return TheGlobal; }\n  int64_t getOffset() const { return Offset; }\n  unsigned getTargetFlags() const { return TargetFlags; }\n  // Return the address space this GlobalAddress belongs to.\n  unsigned getAddressSpace() const;\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::GlobalAddress ||\n           N->getOpcode() == ISD::TargetGlobalAddress ||\n           N->getOpcode() == ISD::GlobalTLSAddress ||\n           N->getOpcode() == ISD::TargetGlobalTLSAddress;\n  }\n};\n\nclass FrameIndexSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  int FI;\n\n  FrameIndexSDNode(int fi, EVT VT, bool isTarg)\n    : SDNode(isTarg ? ISD::TargetFrameIndex : ISD::FrameIndex,\n      0, DebugLoc(), getSDVTList(VT)), FI(fi) {\n  }\n\npublic:\n  int getIndex() const { return FI; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::FrameIndex ||\n           N->getOpcode() == ISD::TargetFrameIndex;\n  }\n};\n\n/// This SDNode is used for LIFETIME_START/LIFETIME_END values, which indicate\n/// the offet and size that are started/ended in the underlying FrameIndex.\nclass LifetimeSDNode : public SDNode {\n  friend class SelectionDAG;\n  int64_t Size;\n  int64_t Offset; // -1 if offset is unknown.\n\n  LifetimeSDNode(unsigned Opcode, unsigned Order, const DebugLoc &dl,\n                 SDVTList VTs, int64_t Size, int64_t Offset)\n      : SDNode(Opcode, Order, dl, VTs), Size(Size), Offset(Offset) {}\npublic:\n  int64_t getFrameIndex() const {\n    return cast<FrameIndexSDNode>(getOperand(1))->getIndex();\n  }\n\n  bool hasOffset() const { return Offset >= 0; }\n  int64_t getOffset() const {\n    assert(hasOffset() && \"offset is unknown\");\n    return Offset;\n  }\n  int64_t getSize() const {\n    assert(hasOffset() && \"offset is unknown\");\n    return Size;\n  }\n\n  // Methods to support isa and dyn_cast\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::LIFETIME_START ||\n           N->getOpcode() == ISD::LIFETIME_END;\n  }\n};\n\n/// This SDNode is used for PSEUDO_PROBE values, which are the function guid and\n/// the index of the basic block being probed. A pseudo probe serves as a place\n/// holder and will be removed at the end of compilation. It does not have any\n/// operand because we do not want the instruction selection to deal with any.\nclass PseudoProbeSDNode : public SDNode {\n  friend class SelectionDAG;\n  uint64_t Guid;\n  uint64_t Index;\n  uint32_t Attributes;\n\n  PseudoProbeSDNode(unsigned Opcode, unsigned Order, const DebugLoc &Dl,\n                    SDVTList VTs, uint64_t Guid, uint64_t Index, uint32_t Attr)\n      : SDNode(Opcode, Order, Dl, VTs), Guid(Guid), Index(Index),\n        Attributes(Attr) {}\n\npublic:\n  uint64_t getGuid() const { return Guid; }\n  uint64_t getIndex() const { return Index; }\n  uint32_t getAttributes() const { return Attributes; }\n\n  // Methods to support isa and dyn_cast\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::PSEUDO_PROBE;\n  }\n};\n\nclass JumpTableSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  int JTI;\n  unsigned TargetFlags;\n\n  JumpTableSDNode(int jti, EVT VT, bool isTarg, unsigned TF)\n    : SDNode(isTarg ? ISD::TargetJumpTable : ISD::JumpTable,\n      0, DebugLoc(), getSDVTList(VT)), JTI(jti), TargetFlags(TF) {\n  }\n\npublic:\n  int getIndex() const { return JTI; }\n  unsigned getTargetFlags() const { return TargetFlags; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::JumpTable ||\n           N->getOpcode() == ISD::TargetJumpTable;\n  }\n};\n\nclass ConstantPoolSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  union {\n    const Constant *ConstVal;\n    MachineConstantPoolValue *MachineCPVal;\n  } Val;\n  int Offset;  // It's a MachineConstantPoolValue if top bit is set.\n  Align Alignment; // Minimum alignment requirement of CP.\n  unsigned TargetFlags;\n\n  ConstantPoolSDNode(bool isTarget, const Constant *c, EVT VT, int o,\n                     Align Alignment, unsigned TF)\n      : SDNode(isTarget ? ISD::TargetConstantPool : ISD::ConstantPool, 0,\n               DebugLoc(), getSDVTList(VT)),\n        Offset(o), Alignment(Alignment), TargetFlags(TF) {\n    assert(Offset >= 0 && \"Offset is too large\");\n    Val.ConstVal = c;\n  }\n\n  ConstantPoolSDNode(bool isTarget, MachineConstantPoolValue *v, EVT VT, int o,\n                     Align Alignment, unsigned TF)\n      : SDNode(isTarget ? ISD::TargetConstantPool : ISD::ConstantPool, 0,\n               DebugLoc(), getSDVTList(VT)),\n        Offset(o), Alignment(Alignment), TargetFlags(TF) {\n    assert(Offset >= 0 && \"Offset is too large\");\n    Val.MachineCPVal = v;\n    Offset |= 1 << (sizeof(unsigned)*CHAR_BIT-1);\n  }\n\npublic:\n  bool isMachineConstantPoolEntry() const {\n    return Offset < 0;\n  }\n\n  const Constant *getConstVal() const {\n    assert(!isMachineConstantPoolEntry() && \"Wrong constantpool type\");\n    return Val.ConstVal;\n  }\n\n  MachineConstantPoolValue *getMachineCPVal() const {\n    assert(isMachineConstantPoolEntry() && \"Wrong constantpool type\");\n    return Val.MachineCPVal;\n  }\n\n  int getOffset() const {\n    return Offset & ~(1 << (sizeof(unsigned)*CHAR_BIT-1));\n  }\n\n  // Return the alignment of this constant pool object, which is either 0 (for\n  // default alignment) or the desired value.\n  Align getAlign() const { return Alignment; }\n  unsigned getTargetFlags() const { return TargetFlags; }\n\n  Type *getType() const;\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::ConstantPool ||\n           N->getOpcode() == ISD::TargetConstantPool;\n  }\n};\n\n/// Completely target-dependent object reference.\nclass TargetIndexSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  unsigned TargetFlags;\n  int Index;\n  int64_t Offset;\n\npublic:\n  TargetIndexSDNode(int Idx, EVT VT, int64_t Ofs, unsigned TF)\n      : SDNode(ISD::TargetIndex, 0, DebugLoc(), getSDVTList(VT)),\n        TargetFlags(TF), Index(Idx), Offset(Ofs) {}\n\n  unsigned getTargetFlags() const { return TargetFlags; }\n  int getIndex() const { return Index; }\n  int64_t getOffset() const { return Offset; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::TargetIndex;\n  }\n};\n\nclass BasicBlockSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  MachineBasicBlock *MBB;\n\n  /// Debug info is meaningful and potentially useful here, but we create\n  /// blocks out of order when they're jumped to, which makes it a bit\n  /// harder.  Let's see if we need it first.\n  explicit BasicBlockSDNode(MachineBasicBlock *mbb)\n    : SDNode(ISD::BasicBlock, 0, DebugLoc(), getSDVTList(MVT::Other)), MBB(mbb)\n  {}\n\npublic:\n  MachineBasicBlock *getBasicBlock() const { return MBB; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::BasicBlock;\n  }\n};\n\n/// A \"pseudo-class\" with methods for operating on BUILD_VECTORs.\nclass BuildVectorSDNode : public SDNode {\npublic:\n  // These are constructed as SDNodes and then cast to BuildVectorSDNodes.\n  explicit BuildVectorSDNode() = delete;\n\n  /// Check if this is a constant splat, and if so, find the\n  /// smallest element size that splats the vector.  If MinSplatBits is\n  /// nonzero, the element size must be at least that large.  Note that the\n  /// splat element may be the entire vector (i.e., a one element vector).\n  /// Returns the splat element value in SplatValue.  Any undefined bits in\n  /// that value are zero, and the corresponding bits in the SplatUndef mask\n  /// are set.  The SplatBitSize value is set to the splat element size in\n  /// bits.  HasAnyUndefs is set to true if any bits in the vector are\n  /// undefined.  isBigEndian describes the endianness of the target.\n  bool isConstantSplat(APInt &SplatValue, APInt &SplatUndef,\n                       unsigned &SplatBitSize, bool &HasAnyUndefs,\n                       unsigned MinSplatBits = 0,\n                       bool isBigEndian = false) const;\n\n  /// Returns the demanded splatted value or a null value if this is not a\n  /// splat.\n  ///\n  /// The DemandedElts mask indicates the elements that must be in the splat.\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the vector width and set the bits where elements are undef.\n  SDValue getSplatValue(const APInt &DemandedElts,\n                        BitVector *UndefElements = nullptr) const;\n\n  /// Returns the splatted value or a null value if this is not a splat.\n  ///\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the vector width and set the bits where elements are undef.\n  SDValue getSplatValue(BitVector *UndefElements = nullptr) const;\n\n  /// Find the shortest repeating sequence of values in the build vector.\n  ///\n  /// e.g. { u, X, u, X, u, u, X, u } -> { X }\n  ///      { X, Y, u, Y, u, u, X, u } -> { X, Y }\n  ///\n  /// Currently this must be a power-of-2 build vector.\n  /// The DemandedElts mask indicates the elements that must be present,\n  /// undemanded elements in Sequence may be null (SDValue()). If passed a\n  /// non-null UndefElements bitvector, it will resize it to match the original\n  /// vector width and set the bits where elements are undef. If result is\n  /// false, Sequence will be empty.\n  bool getRepeatedSequence(const APInt &DemandedElts,\n                           SmallVectorImpl<SDValue> &Sequence,\n                           BitVector *UndefElements = nullptr) const;\n\n  /// Find the shortest repeating sequence of values in the build vector.\n  ///\n  /// e.g. { u, X, u, X, u, u, X, u } -> { X }\n  ///      { X, Y, u, Y, u, u, X, u } -> { X, Y }\n  ///\n  /// Currently this must be a power-of-2 build vector.\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the original vector width and set the bits where elements are undef.\n  /// If result is false, Sequence will be empty.\n  bool getRepeatedSequence(SmallVectorImpl<SDValue> &Sequence,\n                           BitVector *UndefElements = nullptr) const;\n\n  /// Returns the demanded splatted constant or null if this is not a constant\n  /// splat.\n  ///\n  /// The DemandedElts mask indicates the elements that must be in the splat.\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the vector width and set the bits where elements are undef.\n  ConstantSDNode *\n  getConstantSplatNode(const APInt &DemandedElts,\n                       BitVector *UndefElements = nullptr) const;\n\n  /// Returns the splatted constant or null if this is not a constant\n  /// splat.\n  ///\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the vector width and set the bits where elements are undef.\n  ConstantSDNode *\n  getConstantSplatNode(BitVector *UndefElements = nullptr) const;\n\n  /// Returns the demanded splatted constant FP or null if this is not a\n  /// constant FP splat.\n  ///\n  /// The DemandedElts mask indicates the elements that must be in the splat.\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the vector width and set the bits where elements are undef.\n  ConstantFPSDNode *\n  getConstantFPSplatNode(const APInt &DemandedElts,\n                         BitVector *UndefElements = nullptr) const;\n\n  /// Returns the splatted constant FP or null if this is not a constant\n  /// FP splat.\n  ///\n  /// If passed a non-null UndefElements bitvector, it will resize it to match\n  /// the vector width and set the bits where elements are undef.\n  ConstantFPSDNode *\n  getConstantFPSplatNode(BitVector *UndefElements = nullptr) const;\n\n  /// If this is a constant FP splat and the splatted constant FP is an\n  /// exact power or 2, return the log base 2 integer value.  Otherwise,\n  /// return -1.\n  ///\n  /// The BitWidth specifies the necessary bit precision.\n  int32_t getConstantFPSplatPow2ToLog2Int(BitVector *UndefElements,\n                                          uint32_t BitWidth) const;\n\n  /// Extract the raw bit data from a build vector of Undef, Constant or\n  /// ConstantFP node elements. Each raw bit element will be \\p\n  /// DstEltSizeInBits wide, undef elements are treated as zero, and entirely\n  /// undefined elements are flagged in \\p UndefElements.\n  bool getConstantRawBits(bool IsLittleEndian, unsigned DstEltSizeInBits,\n                          SmallVectorImpl<APInt> &RawBitElements,\n                          BitVector &UndefElements) const;\n\n  bool isConstant() const;\n\n  /// If this BuildVector is constant and represents the numerical series\n  /// \"<a, a+n, a+2n, a+3n, ...>\" where a is integer and n is a non-zero integer,\n  /// the value \"<a,n>\" is returned.\n  std::optional<std::pair<APInt, APInt>> isConstantSequence() const;\n\n  /// Recast bit data \\p SrcBitElements to \\p DstEltSizeInBits wide elements.\n  /// Undef elements are treated as zero, and entirely undefined elements are\n  /// flagged in \\p DstUndefElements.\n  static void recastRawBits(bool IsLittleEndian, unsigned DstEltSizeInBits,\n                            SmallVectorImpl<APInt> &DstBitElements,\n                            ArrayRef<APInt> SrcBitElements,\n                            BitVector &DstUndefElements,\n                            const BitVector &SrcUndefElements);\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::BUILD_VECTOR;\n  }\n};\n\n/// An SDNode that holds an arbitrary LLVM IR Value. This is\n/// used when the SelectionDAG needs to make a simple reference to something\n/// in the LLVM IR representation.\n///\nclass SrcValueSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const Value *V;\n\n  /// Create a SrcValue for a general value.\n  explicit SrcValueSDNode(const Value *v)\n    : SDNode(ISD::SRCVALUE, 0, DebugLoc(), getSDVTList(MVT::Other)), V(v) {}\n\npublic:\n  /// Return the contained Value.\n  const Value *getValue() const { return V; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::SRCVALUE;\n  }\n};\n\nclass MDNodeSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const MDNode *MD;\n\n  explicit MDNodeSDNode(const MDNode *md)\n  : SDNode(ISD::MDNODE_SDNODE, 0, DebugLoc(), getSDVTList(MVT::Other)), MD(md)\n  {}\n\npublic:\n  const MDNode *getMD() const { return MD; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::MDNODE_SDNODE;\n  }\n};\n\nclass RegisterSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  Register Reg;\n\n  RegisterSDNode(Register reg, EVT VT)\n    : SDNode(ISD::Register, 0, DebugLoc(), getSDVTList(VT)), Reg(reg) {}\n\npublic:\n  Register getReg() const { return Reg; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::Register;\n  }\n};\n\nclass RegisterMaskSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  // The memory for RegMask is not owned by the node.\n  const uint32_t *RegMask;\n\n  RegisterMaskSDNode(const uint32_t *mask)\n    : SDNode(ISD::RegisterMask, 0, DebugLoc(), getSDVTList(MVT::Untyped)),\n      RegMask(mask) {}\n\npublic:\n  const uint32_t *getRegMask() const { return RegMask; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::RegisterMask;\n  }\n};\n\nclass BlockAddressSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const BlockAddress *BA;\n  int64_t Offset;\n  unsigned TargetFlags;\n\n  BlockAddressSDNode(unsigned NodeTy, EVT VT, const BlockAddress *ba,\n                     int64_t o, unsigned Flags)\n    : SDNode(NodeTy, 0, DebugLoc(), getSDVTList(VT)),\n             BA(ba), Offset(o), TargetFlags(Flags) {}\n\npublic:\n  const BlockAddress *getBlockAddress() const { return BA; }\n  int64_t getOffset() const { return Offset; }\n  unsigned getTargetFlags() const { return TargetFlags; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::BlockAddress ||\n           N->getOpcode() == ISD::TargetBlockAddress;\n  }\n};\n\nclass LabelSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  MCSymbol *Label;\n\n  LabelSDNode(unsigned Opcode, unsigned Order, const DebugLoc &dl, MCSymbol *L)\n      : SDNode(Opcode, Order, dl, getSDVTList(MVT::Other)), Label(L) {\n    assert(LabelSDNode::classof(this) && \"not a label opcode\");\n  }\n\npublic:\n  MCSymbol *getLabel() const { return Label; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::EH_LABEL ||\n           N->getOpcode() == ISD::ANNOTATION_LABEL;\n  }\n};\n\nclass ExternalSymbolSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  const char *Symbol;\n  unsigned TargetFlags;\n\n  ExternalSymbolSDNode(bool isTarget, const char *Sym, unsigned TF, EVT VT)\n      : SDNode(isTarget ? ISD::TargetExternalSymbol : ISD::ExternalSymbol, 0,\n               DebugLoc(), getSDVTList(VT)),\n        Symbol(Sym), TargetFlags(TF) {}\n\npublic:\n  const char *getSymbol() const { return Symbol; }\n  unsigned getTargetFlags() const { return TargetFlags; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::ExternalSymbol ||\n           N->getOpcode() == ISD::TargetExternalSymbol;\n  }\n};\n\nclass MCSymbolSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  MCSymbol *Symbol;\n\n  MCSymbolSDNode(MCSymbol *Symbol, EVT VT)\n      : SDNode(ISD::MCSymbol, 0, DebugLoc(), getSDVTList(VT)), Symbol(Symbol) {}\n\npublic:\n  MCSymbol *getMCSymbol() const { return Symbol; }\n\n  static bool classof(const SDNode *N) {\n    return N->getOpcode() == ISD::MCSymbol;\n  }\n};\n\nclass CondCodeSDNode : public SDNode {\n  friend class SelectionDAG;\n\n  ISD::CondCode Condition;\n\n  explicit CondCodeSDNode(ISD::CondCode Cond)\n    : SDNode(ISD::CONDCODE, 0, DebugLoc(), getSDVTList(MVT::Other)),\n      Condition(Cond) {}\n\npublic:\n  ISD::CondCode get() const { return Condition; }\n\n  static bool classof(const SDNode *N) {\n"}], "code": "  virtual bool isTruncateFree(SDValue Val, EVT VT2) const {\n    // Fallback to type matching.\n    return isTruncateFree(Val.getValueType(), VT2);\n  }\n"}, "DCAD5D2D52DC76DF": {"calls": [{"id": "B789000627A8B936", "name": "llvm::SIInstrInfo::isLegalMUBUFImmOffset", "path": "llvm-project/llvm/lib/Target/AMDGPU/SIInstrInfo.cpp", "start": {"line": 8880, "col": 1}, "end": {"line": 8882, "col": 1}, "code": "  return Imm <= getMaxMUBUFImmOffset(ST);\n}\n\nunsigned SIInstrInfo::getMaxMUBUFImmOffset(const GCNSubtarget &ST) {\n  // GFX12 field is non-negative 24-bit signed byte offset.\n  const unsigned OffsetBits =\n      ST.getGeneration() >= AMDGPUSubtarget::GFX12 ? 23 : 12;\n  return (1 << OffsetBits) - 1;\n}\n\nvoid SIInstrInfo::fixImplicitOperands(MachineInstr &MI) const {\n  if (!ST.isWave32())\n    return;\n\n  if (MI.isInlineAsm())\n    return;\n\n  for (auto &Op : MI.implicit_operands()) {\n    if (Op.isReg() && Op.getReg() == AMDGPU::VCC)\n      Op.setReg(AMDGPU::VCC_LO);\n  }\n}\n\nbool SIInstrInfo::isBufferSMRD(const MachineInstr &MI) const {\n  if (!isSMRD(MI))\n    return false;\n\n  // Check that it is using a buffer resource.\n  int Idx = AMDGPU::getNamedOperandIdx(MI.getOpcode(), AMDGPU::OpName::sbase);\n  if (Idx == -1) // e.g. s_memtime\n    return false;\n\n  const auto RCID = MI.getDesc().operands()[Idx].RegClass;\n  return RI.getRegClass(RCID)->hasSubClassEq(&AMDGPU::SGPR_128RegClass);\n}\n\n// Given Imm, split it into the values to put into the SOffset and ImmOffset\n// fields in an MUBUF instruction. Return false if it is not possible (due to a\n// hardware bug needing a workaround).\n//\n// The required alignment ensures that individual address components remain\n// aligned if they are aligned to begin with. It also ensures that additional\n// offsets within the given alignment can be added to the resulting ImmOffset.\nbool SIInstrInfo::splitMUBUFOffset(uint32_t Imm, uint32_t &SOffset,\n                                   uint32_t &ImmOffset, Align Alignment) const {\n  const uint32_t MaxOffset = SIInstrInfo::getMaxMUBUFImmOffset(ST);\n  const uint32_t MaxImm = alignDown(MaxOffset, Alignment.value());\n  uint32_t Overflow = 0;\n\n  if (Imm > MaxImm) {\n    if (Imm <= MaxImm + 64) {\n      // Use an SOffset inline constant for 4..64\n      Overflow = Imm - MaxImm;\n      Imm = MaxImm;\n    } else {\n      // Try to keep the same value in SOffset for adjacent loads, so that\n      // the corresponding register contents can be re-used.\n      //\n      // Load values with all low-bits (except for alignment bits) set into\n      // SOffset, so that a larger range of values can be covered using\n      // s_movk_i32.\n      //\n      // Atomic operations fail to work correctly when individual address\n      // components are unaligned, even if their sum is aligned.\n      uint32_t High = (Imm + Alignment.value()) & ~MaxOffset;\n      uint32_t Low = (Imm + Alignment.value()) & MaxOffset;\n      Imm = Low;\n      Overflow = High - Alignment.value();\n    }\n  }\n\n  if (Overflow > 0) {\n    // There is a hardware bug in SI and CI which prevents address clamping in\n    // MUBUF instructions from working correctly with SOffsets. The immediate\n    // offset is unaffected.\n    if (ST.getGeneration() <= AMDGPUSubtarget::SEA_ISLANDS)\n      return false;\n\n    // It is not possible to set immediate in SOffset field on some targets.\n    if (ST.hasRestrictedSOffset())\n      return false;\n  }\n\n  ImmOffset = Imm;\n  SOffset = Overflow;\n  return true;\n}\n\n// Depending on the used address space and instructions, some immediate offsets\n// are allowed and some are not.\n// Pre-GFX12, flat instruction offsets can only be non-negative, global and\n// scratch instruction offsets can also be negative. On GFX12, offsets can be\n// negative for all variants.\n//\n// There are several bugs related to these offsets:\n// On gfx10.1, flat instructions that go into the global address space cannot\n// use an offset.\n//\n// For scratch instructions, the address can be either an SGPR or a VGPR.\n// The following offsets can be used, depending on the architecture (x means\n// cannot be used):\n// +----------------------------+------+------+\n// | Address-Mode               | SGPR | VGPR |\n// +----------------------------+------+------+\n// | gfx9                       |      |      |\n// | negative, 4-aligned offset | x    | ok   |\n// | negative, unaligned offset | x    | ok   |\n// +----------------------------+------+------+\n// | gfx10                      |      |      |\n// | negative, 4-aligned offset | ok   | ok   |\n// | negative, unaligned offset | ok   | x    |\n// +----------------------------+------+------+\n// | gfx10.3                    |      |      |\n// | negative, 4-aligned offset | ok   | ok   |\n// | negative, unaligned offset | ok   | ok   |\n// +----------------------------+------+------+\n//\n// This function ignores the addressing mode, so if an offset cannot be used in\n// one addressing mode, it is considered illegal.\nbool SIInstrInfo::isLegalFLATOffset(int64_t Offset, unsigned AddrSpace,\n                                    uint64_t FlatVariant) const {\n  // TODO: Should 0 be special cased?\n  if (!ST.hasFlatInstOffsets())\n    return false;\n\n  if (ST.hasFlatSegmentOffsetBug() && FlatVariant == SIInstrFlags::FLAT &&\n      (AddrSpace == AMDGPUAS::FLAT_ADDRESS ||\n       AddrSpace == AMDGPUAS::GLOBAL_ADDRESS))\n    return false;\n\n  if (ST.hasNegativeUnalignedScratchOffsetBug() &&\n      FlatVariant == SIInstrFlags::FlatScratch && Offset < 0 &&\n      (Offset % 4) != 0) {\n    return false;\n  }\n\n  bool AllowNegative = allowNegativeFlatOffset(FlatVariant);\n  unsigned N = AMDGPU::getNumFlatOffsetBits(ST);\n  return isIntN(N, Offset) && (AllowNegative || Offset >= 0);\n}\n\n// See comment on SIInstrInfo::isLegalFLATOffset for what is legal and what not.\nstd::pair<int64_t, int64_t>\nSIInstrInfo::splitFlatOffset(int64_t COffsetVal, unsigned AddrSpace,\n                             uint64_t FlatVariant) const {\n  int64_t RemainderOffset = COffsetVal;\n  int64_t ImmField = 0;\n\n  bool AllowNegative = allowNegativeFlatOffset(FlatVariant);\n  const unsigned NumBits = AMDGPU::getNumFlatOffsetBits(ST) - 1;\n\n  if (AllowNegative) {\n    // Use signed division by a power of two to truncate towards 0.\n    int64_t D = 1LL << NumBits;\n    RemainderOffset = (COffsetVal / D) * D;\n    ImmField = COffsetVal - RemainderOffset;\n\n    if (ST.hasNegativeUnalignedScratchOffsetBug() &&\n        FlatVariant == SIInstrFlags::FlatScratch && ImmField < 0 &&\n        (ImmField % 4) != 0) {\n      // Make ImmField a multiple of 4\n      RemainderOffset += ImmField % 4;\n      ImmField -= ImmField % 4;\n    }\n  } else if (COffsetVal >= 0) {\n    ImmField = COffsetVal & maskTrailingOnes<uint64_t>(NumBits);\n    RemainderOffset = COffsetVal - ImmField;\n  }\n\n  assert(isLegalFLATOffset(ImmField, AddrSpace, FlatVariant));\n  assert(RemainderOffset + ImmField == COffsetVal);\n  return {ImmField, RemainderOffset};\n}\n\nbool SIInstrInfo::allowNegativeFlatOffset(uint64_t FlatVariant) const {\n  if (ST.hasNegativeScratchOffsetBug() &&\n      FlatVariant == SIInstrFlags::FlatScratch)\n    return false;\n\n  return FlatVariant != SIInstrFlags::FLAT || AMDGPU::isGFX12Plus(ST);\n}\n\nstatic unsigned subtargetEncodingFamily(const GCNSubtarget &ST) {\n  switch (ST.getGeneration()) {\n  default:\n    break;\n  case AMDGPUSubtarget::SOUTHERN_ISLANDS:\n  case AMDGPUSubtarget::SEA_ISLANDS:\n    return SIEncodingFamily::SI;\n  case AMDGPUSubtarget::VOLCANIC_ISLANDS:\n  case AMDGPUSubtarget::GFX9:\n    return SIEncodingFamily::VI;\n  case AMDGPUSubtarget::GFX10:\n    return SIEncodingFamily::GFX10;\n  case AMDGPUSubtarget::GFX11:\n    return SIEncodingFamily::GFX11;\n  case AMDGPUSubtarget::GFX12:\n    return SIEncodingFamily::GFX12;\n  }\n  llvm_unreachable(\"Unknown subtarget generation!\");\n}\n\nbool SIInstrInfo::isAsmOnlyOpcode(int MCOp) const {\n  switch(MCOp) {\n  // These opcodes use indirect register addressing so\n  // they need special handling by codegen (currently missing).\n  // Therefore it is too risky to allow these opcodes\n  // to be selected by dpp combiner or sdwa peepholer.\n  case AMDGPU::V_MOVRELS_B32_dpp_gfx10:\n  case AMDGPU::V_MOVRELS_B32_sdwa_gfx10:\n  case AMDGPU::V_MOVRELD_B32_dpp_gfx10:\n  case AMDGPU::V_MOVRELD_B32_sdwa_gfx10:\n  case AMDGPU::V_MOVRELSD_B32_dpp_gfx10:\n  case AMDGPU::V_MOVRELSD_B32_sdwa_gfx10:\n  case AMDGPU::V_MOVRELSD_2_B32_dpp_gfx10:\n  case AMDGPU::V_MOVRELSD_2_B32_sdwa_gfx10:\n    return true;\n  default:\n    return false;\n  }\n}\n\nint SIInstrInfo::pseudoToMCOpcode(int Opcode) const {\n  Opcode = SIInstrInfo::getNonSoftWaitcntOpcode(Opcode);\n\n  unsigned Gen = subtargetEncodingFamily(ST);\n\n  if ((get(Opcode).TSFlags & SIInstrFlags::renamedInGFX9) != 0 &&\n    ST.getGeneration() == AMDGPUSubtarget::GFX9)\n    Gen = SIEncodingFamily::GFX9;\n\n  // Adjust the encoding family to GFX80 for D16 buffer instructions when the\n  // subtarget has UnpackedD16VMem feature.\n  // TODO: remove this when we discard GFX80 encoding.\n  if (ST.hasUnpackedD16VMem() && (get(Opcode).TSFlags & SIInstrFlags::D16Buf))\n    Gen = SIEncodingFamily::GFX80;\n\n  if (get(Opcode).TSFlags & SIInstrFlags::SDWA) {\n    switch (ST.getGeneration()) {\n    default:\n      Gen = SIEncodingFamily::SDWA;\n      break;\n    case AMDGPUSubtarget::GFX9:\n      Gen = SIEncodingFamily::SDWA9;\n      break;\n    case AMDGPUSubtarget::GFX10:\n      Gen = SIEncodingFamily::SDWA10;\n      break;\n    }\n  }\n\n  if (isMAI(Opcode)) {\n    int MFMAOp = AMDGPU::getMFMAEarlyClobberOp(Opcode);\n    if (MFMAOp != -1)\n      Opcode = MFMAOp;\n  }\n\n  int MCOp = AMDGPU::getMCOpcode(Opcode, Gen);\n\n  // -1 means that Opcode is already a native instruction.\n  if (MCOp == -1)\n    return Opcode;\n\n  if (ST.hasGFX90AInsts()) {\n    uint16_t NMCOp = (uint16_t)-1;\n    if (ST.hasGFX940Insts())\n      NMCOp = AMDGPU::getMCOpcode(Opcode, SIEncodingFamily::GFX940);\n    if (NMCOp == (uint16_t)-1)\n      NMCOp = AMDGPU::getMCOpcode(Opcode, SIEncodingFamily::GFX90A);\n    if (NMCOp == (uint16_t)-1)\n      NMCOp = AMDGPU::getMCOpcode(Opcode, SIEncodingFamily::GFX9);\n    if (NMCOp != (uint16_t)-1)\n      MCOp = NMCOp;\n  }\n\n  // (uint16_t)-1 means that Opcode is a pseudo instruction that has\n  // no encoding in the given subtarget generation.\n  if (MCOp == (uint16_t)-1)\n    return -1;\n\n  if (isAsmOnlyOpcode(MCOp))\n    return -1;\n\n  return MCOp;\n}\n\nstatic\nTargetInstrInfo::RegSubRegPair getRegOrUndef(const MachineOperand &RegOpnd) {\n  assert(RegOpnd.isReg());\n  return RegOpnd.isUndef() ? TargetInstrInfo::RegSubRegPair() :\n                             getRegSubRegPair(RegOpnd);\n}\n\nTargetInstrInfo::RegSubRegPair\nllvm::getRegSequenceSubReg(MachineInstr &MI, unsigned SubReg) {\n  assert(MI.isRegSequence());\n  for (unsigned I = 0, E = (MI.getNumOperands() - 1)/ 2; I < E; ++I)\n    if (MI.getOperand(1 + 2 * I + 1).getImm() == SubReg) {\n      auto &RegOp = MI.getOperand(1 + 2 * I);\n      return getRegOrUndef(RegOp);\n    }\n  return TargetInstrInfo::RegSubRegPair();\n}\n\n// Try to find the definition of reg:subreg in subreg-manipulation pseudos\n// Following a subreg of reg:subreg isn't supported\nstatic bool followSubRegDef(MachineInstr &MI,\n                            TargetInstrInfo::RegSubRegPair &RSR) {\n  if (!RSR.SubReg)\n    return false;\n  switch (MI.getOpcode()) {\n  default: break;\n  case AMDGPU::REG_SEQUENCE:\n    RSR = getRegSequenceSubReg(MI, RSR.SubReg);\n    return true;\n  // EXTRACT_SUBREG ins't supported as this would follow a subreg of subreg\n  case AMDGPU::INSERT_SUBREG:\n    if (RSR.SubReg == (unsigned)MI.getOperand(3).getImm())\n      // inserted the subreg we're looking for\n      RSR = getRegOrUndef(MI.getOperand(2));\n    else { // the subreg in the rest of the reg\n      auto R1 = getRegOrUndef(MI.getOperand(1));\n      if (R1.SubReg) // subreg of subreg isn't supported\n        return false;\n      RSR.Reg = R1.Reg;\n    }\n    return true;\n  }\n  return false;\n}\n\nMachineInstr *llvm::getVRegSubRegDef(const TargetInstrInfo::RegSubRegPair &P,\n                                     MachineRegisterInfo &MRI) {\n  assert(MRI.isSSA());\n  if (!P.Reg.isVirtual())\n    return nullptr;\n\n  auto RSR = P;\n  auto *DefInst = MRI.getVRegDef(RSR.Reg);\n  while (auto *MI = DefInst) {\n    DefInst = nullptr;\n    switch (MI->getOpcode()) {\n    case AMDGPU::COPY:\n    case AMDGPU::V_MOV_B32_e32: {\n      auto &Op1 = MI->getOperand(1);\n      if (Op1.isReg() && Op1.getReg().isVirtual()) {\n        if (Op1.isUndef())\n          return nullptr;\n        RSR = getRegSubRegPair(Op1);\n        DefInst = MRI.getVRegDef(RSR.Reg);\n      }\n      break;\n    }\n    default:\n      if (followSubRegDef(*MI, RSR)) {\n        if (!RSR.Reg)\n          return nullptr;\n        DefInst = MRI.getVRegDef(RSR.Reg);\n      }\n    }\n    if (!DefInst)\n      return MI;\n  }\n  return nullptr;\n}\n\nbool llvm::execMayBeModifiedBeforeUse(const MachineRegisterInfo &MRI,\n                                      Register VReg,\n                                      const MachineInstr &DefMI,\n                                      const MachineInstr &UseMI) {\n  assert(MRI.isSSA() && \"Must be run on SSA\");\n\n  auto *TRI = MRI.getTargetRegisterInfo();\n  auto *DefBB = DefMI.getParent();\n\n  // Don't bother searching between blocks, although it is possible this block\n  // doesn't modify exec.\n  if (UseMI.getParent() != DefBB)\n    return true;\n\n  const int MaxInstScan = 20;\n  int NumInst = 0;\n\n  // Stop scan at the use.\n  auto E = UseMI.getIterator();\n  for (auto I = std::next(DefMI.getIterator()); I != E; ++I) {\n    if (I->isDebugInstr())\n      continue;\n\n    if (++NumInst > MaxInstScan)\n      return true;\n\n    if (I->modifiesRegister(AMDGPU::EXEC, TRI))\n      return true;\n  }\n\n  return false;\n}\n\nbool llvm::execMayBeModifiedBeforeAnyUse(const MachineRegisterInfo &MRI,\n                                         Register VReg,\n                                         const MachineInstr &DefMI) {\n  assert(MRI.isSSA() && \"Must be run on SSA\");\n\n  auto *TRI = MRI.getTargetRegisterInfo();\n  auto *DefBB = DefMI.getParent();\n\n  const int MaxUseScan = 10;\n  int NumUse = 0;\n\n  for (auto &Use : MRI.use_nodbg_operands(VReg)) {\n    auto &UseInst = *Use.getParent();\n    // Don't bother searching between blocks, although it is possible this block\n    // doesn't modify exec.\n    if (UseInst.getParent() != DefBB || UseInst.isPHI())\n      return true;\n\n    if (++NumUse > MaxUseScan)\n      return true;\n  }\n\n  if (NumUse == 0)\n    return false;\n\n  const int MaxInstScan = 20;\n  int NumInst = 0;\n\n  // Stop scan when we have seen all the uses.\n  for (auto I = std::next(DefMI.getIterator()); ; ++I) {\n    assert(I != DefBB->end());\n\n    if (I->isDebugInstr())\n      continue;\n\n    if (++NumInst > MaxInstScan)\n      return true;\n\n    for (const MachineOperand &Op : I->operands()) {\n      // We don't check reg masks here as they're used only on calls:\n      // 1. EXEC is only considered const within one BB\n      // 2. Call should be a terminator instruction if present in a BB\n\n      if (!Op.isReg())\n        continue;\n\n      Register Reg = Op.getReg();\n      if (Op.isUse()) {\n        if (Reg == VReg && --NumUse == 0)\n          return false;\n      } else if (TRI->regsOverlap(Reg, AMDGPU::EXEC))\n        return true;\n    }\n  }\n}\n\nMachineInstr *SIInstrInfo::createPHIDestinationCopy(\n    MachineBasicBlock &MBB, MachineBasicBlock::iterator LastPHIIt,\n    const DebugLoc &DL, Register Src, Register Dst) const {\n  auto Cur = MBB.begin();\n  if (Cur != MBB.end())\n    do {\n      if (!Cur->isPHI() && Cur->readsRegister(Dst))\n        return BuildMI(MBB, Cur, DL, get(TargetOpcode::COPY), Dst).addReg(Src);\n      ++Cur;\n    } while (Cur != MBB.end() && Cur != LastPHIIt);\n\n  return TargetInstrInfo::createPHIDestinationCopy(MBB, LastPHIIt, DL, Src,\n                                                   Dst);\n}\n\nMachineInstr *SIInstrInfo::createPHISourceCopy(\n    MachineBasicBlock &MBB, MachineBasicBlock::iterator InsPt,\n    const DebugLoc &DL, Register Src, unsigned SrcSubReg, Register Dst) const {\n  if (InsPt != MBB.end() &&\n      (InsPt->getOpcode() == AMDGPU::SI_IF ||\n       InsPt->getOpcode() == AMDGPU::SI_ELSE ||\n       InsPt->getOpcode() == AMDGPU::SI_IF_BREAK) &&\n      InsPt->definesRegister(Src)) {\n    InsPt++;\n    return BuildMI(MBB, InsPt, DL,\n                   get(ST.isWave32() ? AMDGPU::S_MOV_B32_term\n                                     : AMDGPU::S_MOV_B64_term),\n                   Dst)\n        .addReg(Src, 0, SrcSubReg)\n        .addReg(AMDGPU::EXEC, RegState::Implicit);\n  }\n  return TargetInstrInfo::createPHISourceCopy(MBB, InsPt, DL, Src, SrcSubReg,\n                                              Dst);\n}\n\nbool llvm::SIInstrInfo::isWave32() const { return ST.isWave32(); }\n\nMachineInstr *SIInstrInfo::foldMemoryOperandImpl(\n    MachineFunction &MF, MachineInstr &MI, ArrayRef<unsigned> Ops,\n    MachineBasicBlock::iterator InsertPt, int FrameIndex, LiveIntervals *LIS,\n    VirtRegMap *VRM) const {\n  // This is a bit of a hack (copied from AArch64). Consider this instruction:\n  //\n  //   %0:sreg_32 = COPY $m0\n  //\n  // We explicitly chose SReg_32 for the virtual register so such a copy might\n  // be eliminated by RegisterCoalescer. However, that may not be possible, and\n  // %0 may even spill. We can't spill $m0 normally (it would require copying to\n  // a numbered SGPR anyway), and since it is in the SReg_32 register class,\n  // TargetInstrInfo::foldMemoryOperand() is going to try.\n  // A similar issue also exists with spilling and reloading $exec registers.\n  //\n  // To prevent that, constrain the %0 register class here.\n  if (isFullCopyInstr(MI)) {\n    Register DstReg = MI.getOperand(0).getReg();\n    Register SrcReg = MI.getOperand(1).getReg();\n    if ((DstReg.isVirtual() || SrcReg.isVirtual()) &&\n        (DstReg.isVirtual() != SrcReg.isVirtual())) {\n      MachineRegisterInfo &MRI = MF.getRegInfo();\n      Register VirtReg = DstReg.isVirtual() ? DstReg : SrcReg;\n      const TargetRegisterClass *RC = MRI.getRegClass(VirtReg);\n      if (RC->hasSuperClassEq(&AMDGPU::SReg_32RegClass)) {\n        MRI.constrainRegClass(VirtReg, &AMDGPU::SReg_32_XM0_XEXECRegClass);\n        return nullptr;\n      } else if (RC->hasSuperClassEq(&AMDGPU::SReg_64RegClass)) {\n        MRI.constrainRegClass(VirtReg, &AMDGPU::SReg_64_XEXECRegClass);\n        return nullptr;\n      }\n    }\n  }\n\n  return nullptr;\n}\n\nunsigned SIInstrInfo::getInstrLatency(const InstrItineraryData *ItinData,\n                                      const MachineInstr &MI,\n                                      unsigned *PredCost) const {\n  if (MI.isBundle()) {\n    MachineBasicBlock::const_instr_iterator I(MI.getIterator());\n    MachineBasicBlock::const_instr_iterator E(MI.getParent()->instr_end());\n    unsigned Lat = 0, Count = 0;\n    for (++I; I != E && I->isBundledWithPred(); ++I) {\n      ++Count;\n      Lat = std::max(Lat, SchedModel.computeInstrLatency(&*I));\n    }\n    return Lat + Count - 1;\n  }\n\n  return SchedModel.computeInstrLatency(&MI);\n}\n\nInstructionUniformity\nSIInstrInfo::getGenericInstructionUniformity(const MachineInstr &MI) const {\n  unsigned opcode = MI.getOpcode();\n  if (auto *GI = dyn_cast<GIntrinsic>(&MI)) {\n    auto IID = GI->getIntrinsicID();\n    if (AMDGPU::isIntrinsicSourceOfDivergence(IID))\n      return InstructionUniformity::NeverUniform;\n    if (AMDGPU::isIntrinsicAlwaysUniform(IID))\n      return InstructionUniformity::AlwaysUniform;\n\n    switch (IID) {\n    case Intrinsic::amdgcn_if:\n    case Intrinsic::amdgcn_else:\n      // FIXME: Uniform if second result\n      break;\n    }\n\n    return InstructionUniformity::Default;\n  }\n\n  // Loads from the private and flat address spaces are divergent, because\n  // threads can execute the load instruction with the same inputs and get\n  // different results.\n  //\n  // All other loads are not divergent, because if threads issue loads with the\n  // same arguments, they will always get the same result.\n  if (opcode == AMDGPU::G_LOAD) {\n    if (MI.memoperands_empty())\n      return InstructionUniformity::NeverUniform; // conservative assumption\n\n    if (llvm::any_of(MI.memoperands(), [](const MachineMemOperand *mmo) {\n          return mmo->getAddrSpace() == AMDGPUAS::PRIVATE_ADDRESS ||\n                 mmo->getAddrSpace() == AMDGPUAS::FLAT_ADDRESS;\n        })) {\n      // At least one MMO in a non-global address space.\n      return InstructionUniformity::NeverUniform;\n    }\n    return InstructionUniformity::Default;\n  }\n\n  if (SIInstrInfo::isGenericAtomicRMWOpcode(opcode) ||\n      opcode == AMDGPU::G_ATOMIC_CMPXCHG ||\n      opcode == AMDGPU::G_ATOMIC_CMPXCHG_WITH_SUCCESS ||\n      AMDGPU::isGenericAtomic(opcode)) {\n    return InstructionUniformity::NeverUniform;\n  }\n  return InstructionUniformity::Default;\n}\n\nInstructionUniformity\nSIInstrInfo::getInstructionUniformity(const MachineInstr &MI) const {\n\n  if (isNeverUniform(MI))\n    return InstructionUniformity::NeverUniform;\n\n  unsigned opcode = MI.getOpcode();\n  if (opcode == AMDGPU::V_READLANE_B32 ||\n      opcode == AMDGPU::V_READFIRSTLANE_B32 ||\n      opcode == AMDGPU::SI_RESTORE_S32_FROM_VGPR)\n    return InstructionUniformity::AlwaysUniform;\n\n  if (isCopyInstr(MI)) {\n    const MachineOperand &srcOp = MI.getOperand(1);\n    if (srcOp.isReg() && srcOp.getReg().isPhysical()) {\n      const TargetRegisterClass *regClass =\n          RI.getPhysRegBaseClass(srcOp.getReg());\n      return RI.isSGPRClass(regClass) ? InstructionUniformity::AlwaysUniform\n                                      : InstructionUniformity::NeverUniform;\n    }\n    return InstructionUniformity::Default;\n  }\n\n  // GMIR handling\n  if (MI.isPreISelOpcode())\n    return SIInstrInfo::getGenericInstructionUniformity(MI);\n\n  // Atomics are divergent because they are executed sequentially: when an\n  // atomic operation refers to the same address in each thread, then each\n  // thread after the first sees the value written by the previous thread as\n  // original value.\n\n  if (isAtomic(MI))\n    return InstructionUniformity::NeverUniform;\n\n  // Loads from the private and flat address spaces are divergent, because\n  // threads can execute the load instruction with the same inputs and get\n  // different results.\n  if (isFLAT(MI) && MI.mayLoad()) {\n    if (MI.memoperands_empty())\n      return InstructionUniformity::NeverUniform; // conservative assumption\n\n    if (llvm::any_of(MI.memoperands(), [](const MachineMemOperand *mmo) {\n          return mmo->getAddrSpace() == AMDGPUAS::PRIVATE_ADDRESS ||\n                 mmo->getAddrSpace() == AMDGPUAS::FLAT_ADDRESS;\n        })) {\n      // At least one MMO in a non-global address space.\n      return InstructionUniformity::NeverUniform;\n    }\n\n    return InstructionUniformity::Default;\n  }\n\n  const MachineRegisterInfo &MRI = MI.getParent()->getParent()->getRegInfo();\n  const AMDGPURegisterBankInfo *RBI = ST.getRegBankInfo();\n\n  // FIXME: It's conceptually broken to report this for an instruction, and not\n  // a specific def operand. For inline asm in particular, there could be mixed\n  // uniform and divergent results.\n  for (unsigned I = 0, E = MI.getNumOperands(); I != E; ++I) {\n    const MachineOperand &SrcOp = MI.getOperand(I);\n    if (!SrcOp.isReg())\n      continue;\n\n    Register Reg = SrcOp.getReg();\n    if (!Reg || !SrcOp.readsReg())\n      continue;\n\n    // If RegBank is null, this is unassigned or an unallocatable special\n    // register, which are all scalars.\n    const RegisterBank *RegBank = RBI->getRegBank(Reg, MRI, RI);\n    if (RegBank && RegBank->getID() != AMDGPU::SGPRRegBankID)\n      return InstructionUniformity::NeverUniform;\n  }\n\n  // TODO: Uniformity check condtions above can be rearranged for more\n  // redability\n\n  // TODO: amdgcn.{ballot, [if]cmp} should be AlwaysUniform, but they are\n  //       currently turned into no-op COPYs by SelectionDAG ISel and are\n  //       therefore no longer recognizable.\n\n  return InstructionUniformity::Default;\n}\n\nunsigned SIInstrInfo::getDSShaderTypeValue(const MachineFunction &MF) {\n  switch (MF.getFunction().getCallingConv()) {\n  case CallingConv::AMDGPU_PS:\n    return 1;\n  case CallingConv::AMDGPU_VS:\n    return 2;\n  case CallingConv::AMDGPU_GS:\n    return 3;\n  case CallingConv::AMDGPU_HS:\n  case CallingConv::AMDGPU_LS:\n  case CallingConv::AMDGPU_ES:\n    report_fatal_error(\"ds_ordered_count unsupported for this calling conv\");\n  case CallingConv::AMDGPU_CS:\n  case CallingConv::AMDGPU_KERNEL:\n  case CallingConv::C:\n  case CallingConv::Fast:\n  default:\n    // Assume other calling conventions are various compute callable functions\n    return 0;\n  }\n}\n\nbool SIInstrInfo::analyzeCompare(const MachineInstr &MI, Register &SrcReg,\n                                 Register &SrcReg2, int64_t &CmpMask,\n                                 int64_t &CmpValue) const {\n  if (!MI.getOperand(0).isReg() || MI.getOperand(0).getSubReg())\n    return false;\n\n  switch (MI.getOpcode()) {\n  default:\n    break;\n  case AMDGPU::S_CMP_EQ_U32:\n  case AMDGPU::S_CMP_EQ_I32:\n  case AMDGPU::S_CMP_LG_U32:\n  case AMDGPU::S_CMP_LG_I32:\n  case AMDGPU::S_CMP_LT_U32:\n  case AMDGPU::S_CMP_LT_I32:\n  case AMDGPU::S_CMP_GT_U32:\n  case AMDGPU::S_CMP_GT_I32:\n  case AMDGPU::S_CMP_LE_U32:\n  case AMDGPU::S_CMP_LE_I32:\n  case AMDGPU::S_CMP_GE_U32:\n  case AMDGPU::S_CMP_GE_I32:\n  case AMDGPU::S_CMP_EQ_U64:\n  case AMDGPU::S_CMP_LG_U64:\n    SrcReg = MI.getOperand(0).getReg();\n    if (MI.getOperand(1).isReg()) {\n      if (MI.getOperand(1).getSubReg())\n        return false;\n      SrcReg2 = MI.getOperand(1).getReg();\n      CmpValue = 0;\n    } else if (MI.getOperand(1).isImm()) {\n      SrcReg2 = Register();\n      CmpValue = MI.getOperand(1).getImm();\n    } else {\n      return false;\n    }\n    CmpMask = ~0;\n    return true;\n  case AMDGPU::S_CMPK_EQ_U32:\n  case AMDGPU::S_CMPK_EQ_I32:\n  case AMDGPU::S_CMPK_LG_U32:\n  case AMDGPU::S_CMPK_LG_I32:\n  case AMDGPU::S_CMPK_LT_U32:\n  case AMDGPU::S_CMPK_LT_I32:\n  case AMDGPU::S_CMPK_GT_U32:\n  case AMDGPU::S_CMPK_GT_I32:\n  case AMDGPU::S_CMPK_LE_U32:\n  case AMDGPU::S_CMPK_LE_I32:\n  case AMDGPU::S_CMPK_GE_U32:\n  case AMDGPU::S_CMPK_GE_I32:\n    SrcReg = MI.getOperand(0).getReg();\n    SrcReg2 = Register();\n    CmpValue = MI.getOperand(1).getImm();\n    CmpMask = ~0;\n    return true;\n  }\n\n  return false;\n}\n\nbool SIInstrInfo::optimizeCompareInstr(MachineInstr &CmpInstr, Register SrcReg,\n                                       Register SrcReg2, int64_t CmpMask,\n                                       int64_t CmpValue,\n                                       const MachineRegisterInfo *MRI) const {\n  if (!SrcReg || SrcReg.isPhysical())\n    return false;\n\n  if (SrcReg2 && !getFoldableImm(SrcReg2, *MRI, CmpValue))\n    return false;\n\n  const auto optimizeCmpAnd = [&CmpInstr, SrcReg, CmpValue, MRI,\n                               this](int64_t ExpectedValue, unsigned SrcSize,\n                                     bool IsReversible, bool IsSigned) -> bool {\n    // s_cmp_eq_u32 (s_and_b32 $src, 1 << n), 1 << n => s_and_b32 $src, 1 << n\n    // s_cmp_eq_i32 (s_and_b32 $src, 1 << n), 1 << n => s_and_b32 $src, 1 << n\n    // s_cmp_ge_u32 (s_and_b32 $src, 1 << n), 1 << n => s_and_b32 $src, 1 << n\n    // s_cmp_ge_i32 (s_and_b32 $src, 1 << n), 1 << n => s_and_b32 $src, 1 << n\n    // s_cmp_eq_u64 (s_and_b64 $src, 1 << n), 1 << n => s_and_b64 $src, 1 << n\n    // s_cmp_lg_u32 (s_and_b32 $src, 1 << n), 0 => s_and_b32 $src, 1 << n\n    // s_cmp_lg_i32 (s_and_b32 $src, 1 << n), 0 => s_and_b32 $src, 1 << n\n    // s_cmp_gt_u32 (s_and_b32 $src, 1 << n), 0 => s_and_b32 $src, 1 << n\n    // s_cmp_gt_i32 (s_and_b32 $src, 1 << n), 0 => s_and_b32 $src, 1 << n\n    // s_cmp_lg_u64 (s_and_b64 $src, 1 << n), 0 => s_and_b64 $src, 1 << n\n    //\n    // Signed ge/gt are not used for the sign bit.\n    //\n    // If result of the AND is unused except in the compare:\n    // s_and_b(32|64) $src, 1 << n => s_bitcmp1_b(32|64) $src, n\n    //\n    // s_cmp_eq_u32 (s_and_b32 $src, 1 << n), 0 => s_bitcmp0_b32 $src, n\n    // s_cmp_eq_i32 (s_and_b32 $src, 1 << n), 0 => s_bitcmp0_b32 $src, n\n    // s_cmp_eq_u64 (s_and_b64 $src, 1 << n), 0 => s_bitcmp0_b64 $src, n\n    // s_cmp_lg_u32 (s_and_b32 $src, 1 << n), 1 << n => s_bitcmp0_b32 $src, n\n    // s_cmp_lg_i32 (s_and_b32 $src, 1 << n), 1 << n => s_bitcmp0_b32 $src, n\n    // s_cmp_lg_u64 (s_and_b64 $src, 1 << n), 1 << n => s_bitcmp0_b64 $src, n\n\n    MachineInstr *Def = MRI->getUniqueVRegDef(SrcReg);\n    if (!Def || Def->getParent() != CmpInstr.getParent())\n      return false;\n\n    if (Def->getOpcode() != AMDGPU::S_AND_B32 &&\n        Def->getOpcode() != AMDGPU::S_AND_B64)\n      return false;\n\n    int64_t Mask;\n    const auto isMask = [&Mask, SrcSize](const MachineOperand *MO) -> bool {\n      if (MO->isImm())\n        Mask = MO->getImm();\n      else if (!getFoldableImm(MO, Mask))\n        return false;\n      Mask &= maxUIntN(SrcSize);\n      return isPowerOf2_64(Mask);\n    };\n\n    MachineOperand *SrcOp = &Def->getOperand(1);\n    if (isMask(SrcOp))\n      SrcOp = &Def->getOperand(2);\n    else if (isMask(&Def->getOperand(2)))\n      SrcOp = &Def->getOperand(1);\n    else\n      return false;\n\n    unsigned BitNo = llvm::countr_zero((uint64_t)Mask);\n    if (IsSigned && BitNo == SrcSize - 1)\n      return false;\n\n    ExpectedValue <<= BitNo;\n\n    bool IsReversedCC = false;\n    if (CmpValue != ExpectedValue) {\n      if (!IsReversible)\n        return false;\n      IsReversedCC = CmpValue == (ExpectedValue ^ Mask);\n      if (!IsReversedCC)\n        return false;\n    }\n\n    Register DefReg = Def->getOperand(0).getReg();\n    if (IsReversedCC && !MRI->hasOneNonDBGUse(DefReg))\n      return false;\n\n    for (auto I = std::next(Def->getIterator()), E = CmpInstr.getIterator();\n         I != E; ++I) {\n      if (I->modifiesRegister(AMDGPU::SCC, &RI) ||\n          I->killsRegister(AMDGPU::SCC, &RI))\n        return false;\n    }\n\n    MachineOperand *SccDef = Def->findRegisterDefOperand(AMDGPU::SCC);\n    SccDef->setIsDead(false);\n    CmpInstr.eraseFromParent();\n\n    if (!MRI->use_nodbg_empty(DefReg)) {\n      assert(!IsReversedCC);\n      return true;\n    }\n\n    // Replace AND with unused result with a S_BITCMP.\n    MachineBasicBlock *MBB = Def->getParent();\n\n    unsigned NewOpc = (SrcSize == 32) ? IsReversedCC ? AMDGPU::S_BITCMP0_B32\n                                                     : AMDGPU::S_BITCMP1_B32\n                                      : IsReversedCC ? AMDGPU::S_BITCMP0_B64\n                                                     : AMDGPU::S_BITCMP1_B64;\n\n    BuildMI(*MBB, Def, Def->getDebugLoc(), get(NewOpc))\n      .add(*SrcOp)\n      .addImm(BitNo);\n    Def->eraseFromParent();\n\n    return true;\n  };\n\n  switch (CmpInstr.getOpcode()) {\n  default:\n    break;\n  case AMDGPU::S_CMP_EQ_U32:\n  case AMDGPU::S_CMP_EQ_I32:\n  case AMDGPU::S_CMPK_EQ_U32:\n  case AMDGPU::S_CMPK_EQ_I32:\n    return optimizeCmpAnd(1, 32, true, false);\n  case AMDGPU::S_CMP_GE_U32:\n  case AMDGPU::S_CMPK_GE_U32:\n    return optimizeCmpAnd(1, 32, false, false);\n  case AMDGPU::S_CMP_GE_I32:\n  case AMDGPU::S_CMPK_GE_I32:\n    return optimizeCmpAnd(1, 32, false, true);\n  case AMDGPU::S_CMP_EQ_U64:\n    return optimizeCmpAnd(1, 64, true, false);\n  case AMDGPU::S_CMP_LG_U32:\n  case AMDGPU::S_CMP_LG_I32:\n  case AMDGPU::S_CMPK_LG_U32:\n  case AMDGPU::S_CMPK_LG_I32:\n    return optimizeCmpAnd(0, 32, true, false);\n  case AMDGPU::S_CMP_GT_U32:\n  case AMDGPU::S_CMPK_GT_U32:\n    return optimizeCmpAnd(0, 32, false, false);\n  case AMDGPU::S_CMP_GT_I32:\n  case AMDGPU::S_CMPK_GT_I32:\n    return optimizeCmpAnd(0, 32, false, true);\n  case AMDGPU::S_CMP_LG_U64:\n    return optimizeCmpAnd(0, 64, true, false);\n  }\n\n  return false;\n}\n\nvoid SIInstrInfo::enforceOperandRCAlignment(MachineInstr &MI,\n                                            unsigned OpName) const {\n  if (!ST.needsAlignedVGPRs())\n    return;\n\n  int OpNo = AMDGPU::getNamedOperandIdx(MI.getOpcode(), OpName);\n  if (OpNo < 0)\n    return;\n  MachineOperand &Op = MI.getOperand(OpNo);\n  if (getOpSize(MI, OpNo) > 4)\n    return;\n\n  // Add implicit aligned super-reg to force alignment on the data operand.\n  const DebugLoc &DL = MI.getDebugLoc();\n  MachineBasicBlock *BB = MI.getParent();\n  MachineRegisterInfo &MRI = BB->getParent()->getRegInfo();\n  Register DataReg = Op.getReg();\n  bool IsAGPR = RI.isAGPR(MRI, DataReg);\n  Register Undef = MRI.createVirtualRegister(\n      IsAGPR ? &AMDGPU::AGPR_32RegClass : &AMDGPU::VGPR_32RegClass);\n  BuildMI(*BB, MI, DL, get(AMDGPU::IMPLICIT_DEF), Undef);\n  Register NewVR =\n      MRI.createVirtualRegister(IsAGPR ? &AMDGPU::AReg_64_Align2RegClass\n                                       : &AMDGPU::VReg_64_Align2RegClass);\n  BuildMI(*BB, MI, DL, get(AMDGPU::REG_SEQUENCE), NewVR)\n      .addReg(DataReg, 0, Op.getSubReg())\n      .addImm(AMDGPU::sub0)\n      .addReg(Undef)\n      .addImm(AMDGPU::sub1);\n  Op.setReg(NewVR);\n  Op.setSubReg(AMDGPU::sub0);\n  MI.addOperand(MachineOperand::CreateReg(NewVR, false, true));\n}\n"}], "code": "void AMDGPUInstructionSelector::splitIllegalMUBUFOffset(\n  MachineIRBuilder &B, Register &SOffset, int64_t &ImmOffset) const {\n  if (TII.isLegalMUBUFImmOffset(ImmOffset))\n    return;\n\n  // Illegal offset, store it in soffset.\n  SOffset = MRI->createVirtualRegister(&AMDGPU::SReg_32RegClass);\n  B.buildInstr(AMDGPU::S_MOV_B32)\n    .addDef(SOffset)\n    .addImm(ImmOffset);\n  ImmOffset = 0;\n}\n"}, "3A3B56C79D8D1481": {"calls": [{"id": "4C6BEAF9E7C7CDF3", "name": "llvm::VPlan::getSCEVExpansion", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlan.h", "start": {"line": 3058, "col": 3}, "end": {"line": 3060, "col": 3}, "code": "    return SCEVToExpansion.lookup(S);\n  }\n\n  void addSCEVExpansion(const SCEV *S, VPValue *V) {\n    assert(!SCEVToExpansion.contains(S) && \"SCEV already expanded\");\n    SCEVToExpansion[S] = V;\n  }\n\n  /// \\return The block corresponding to the original preheader.\n  VPBasicBlock *getPreheader() { return Preheader; }\n  const VPBasicBlock *getPreheader() const { return Preheader; }\n\n  /// Clone the current VPlan, update all VPValues of the new VPlan and cloned\n  /// recipes to refer to the clones, and return it.\n  VPlan *duplicate();\n\nprivate:\n  /// Add to the given dominator tree the header block and every new basic block\n  /// that was created between it and the latch block, inclusive.\n  static void updateDominatorTree(DominatorTree *DT, BasicBlock *LoopLatchBB,\n                                  BasicBlock *LoopPreHeaderBB,\n                                  BasicBlock *LoopExitBB);\n};\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n/// VPlanPrinter prints a given VPlan to a given output stream. The printing is\n/// indented and follows the dot format.\nclass VPlanPrinter {\n  raw_ostream &OS;\n  const VPlan &Plan;\n  unsigned Depth = 0;\n  unsigned TabWidth = 2;\n  std::string Indent;\n  unsigned BID = 0;\n  SmallDenseMap<const VPBlockBase *, unsigned> BlockID;\n\n  VPSlotTracker SlotTracker;\n\n  /// Handle indentation.\n  void bumpIndent(int b) { Indent = std::string((Depth += b) * TabWidth, ' '); }\n\n  /// Print a given \\p Block of the Plan.\n  void dumpBlock(const VPBlockBase *Block);\n\n  /// Print the information related to the CFG edges going out of a given\n  /// \\p Block, followed by printing the successor blocks themselves.\n  void dumpEdges(const VPBlockBase *Block);\n\n  /// Print a given \\p BasicBlock, including its VPRecipes, followed by printing\n  /// its successor blocks.\n  void dumpBasicBlock(const VPBasicBlock *BasicBlock);\n\n  /// Print a given \\p Region of the Plan.\n  void dumpRegion(const VPRegionBlock *Region);\n\n  unsigned getOrCreateBID(const VPBlockBase *Block) {\n    return BlockID.count(Block) ? BlockID[Block] : BlockID[Block] = BID++;\n  }\n\n  Twine getOrCreateName(const VPBlockBase *Block);\n\n  Twine getUID(const VPBlockBase *Block);\n\n  /// Print the information related to a CFG edge between two VPBlockBases.\n  void drawEdge(const VPBlockBase *From, const VPBlockBase *To, bool Hidden,\n                const Twine &Label);\n\npublic:\n  VPlanPrinter(raw_ostream &O, const VPlan &P)\n      : OS(O), Plan(P), SlotTracker(&P) {}\n\n  LLVM_DUMP_METHOD void dump();\n};\n\nstruct VPlanIngredient {\n  const Value *V;\n\n  VPlanIngredient(const Value *V) : V(V) {}\n\n  void print(raw_ostream &O) const;\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const VPlanIngredient &I) {\n  I.print(OS);\n  return OS;\n}\n\ninline raw_ostream &operator<<(raw_ostream &OS, const VPlan &Plan) {\n  Plan.print(OS);\n  return OS;\n}\n#endif\n\n//===----------------------------------------------------------------------===//\n// VPlan Utilities\n//===----------------------------------------------------------------------===//\n\n/// Class that provides utilities for VPBlockBases in VPlan.\nclass VPBlockUtils {\npublic:\n  VPBlockUtils() = delete;\n\n  /// Insert disconnected VPBlockBase \\p NewBlock after \\p BlockPtr. Add \\p\n  /// NewBlock as successor of \\p BlockPtr and \\p BlockPtr as predecessor of \\p\n  /// NewBlock, and propagate \\p BlockPtr parent to \\p NewBlock. \\p BlockPtr's\n  /// successors are moved from \\p BlockPtr to \\p NewBlock. \\p NewBlock must\n  /// have neither successors nor predecessors.\n  static void insertBlockAfter(VPBlockBase *NewBlock, VPBlockBase *BlockPtr) {\n    assert(NewBlock->getSuccessors().empty() &&\n           NewBlock->getPredecessors().empty() &&\n           \"Can't insert new block with predecessors or successors.\");\n    NewBlock->setParent(BlockPtr->getParent());\n    SmallVector<VPBlockBase *> Succs(BlockPtr->successors());\n    for (VPBlockBase *Succ : Succs) {\n      disconnectBlocks(BlockPtr, Succ);\n      connectBlocks(NewBlock, Succ);\n    }\n    connectBlocks(BlockPtr, NewBlock);\n  }\n\n  /// Insert disconnected VPBlockBases \\p IfTrue and \\p IfFalse after \\p\n  /// BlockPtr. Add \\p IfTrue and \\p IfFalse as succesors of \\p BlockPtr and \\p\n  /// BlockPtr as predecessor of \\p IfTrue and \\p IfFalse. Propagate \\p BlockPtr\n  /// parent to \\p IfTrue and \\p IfFalse. \\p BlockPtr must have no successors\n  /// and \\p IfTrue and \\p IfFalse must have neither successors nor\n  /// predecessors.\n  static void insertTwoBlocksAfter(VPBlockBase *IfTrue, VPBlockBase *IfFalse,\n                                   VPBlockBase *BlockPtr) {\n    assert(IfTrue->getSuccessors().empty() &&\n           \"Can't insert IfTrue with successors.\");\n    assert(IfFalse->getSuccessors().empty() &&\n           \"Can't insert IfFalse with successors.\");\n    BlockPtr->setTwoSuccessors(IfTrue, IfFalse);\n    IfTrue->setPredecessors({BlockPtr});\n    IfFalse->setPredecessors({BlockPtr});\n    IfTrue->setParent(BlockPtr->getParent());\n    IfFalse->setParent(BlockPtr->getParent());\n  }\n\n  /// Connect VPBlockBases \\p From and \\p To bi-directionally. Append \\p To to\n  /// the successors of \\p From and \\p From to the predecessors of \\p To. Both\n  /// VPBlockBases must have the same parent, which can be null. Both\n  /// VPBlockBases can be already connected to other VPBlockBases.\n  static void connectBlocks(VPBlockBase *From, VPBlockBase *To) {\n    assert((From->getParent() == To->getParent()) &&\n           \"Can't connect two block with different parents\");\n    assert(From->getNumSuccessors() < 2 &&\n           \"Blocks can't have more than two successors.\");\n    From->appendSuccessor(To);\n    To->appendPredecessor(From);\n  }\n\n  /// Disconnect VPBlockBases \\p From and \\p To bi-directionally. Remove \\p To\n  /// from the successors of \\p From and \\p From from the predecessors of \\p To.\n  static void disconnectBlocks(VPBlockBase *From, VPBlockBase *To) {\n    assert(To && \"Successor to disconnect is null.\");\n    From->removeSuccessor(To);\n    To->removePredecessor(From);\n  }\n\n  /// Return an iterator range over \\p Range which only includes \\p BlockTy\n  /// blocks. The accesses are casted to \\p BlockTy.\n  template <typename BlockTy, typename T>\n  static auto blocksOnly(const T &Range) {\n    // Create BaseTy with correct const-ness based on BlockTy.\n    using BaseTy = std::conditional_t<std::is_const<BlockTy>::value,\n                                      const VPBlockBase, VPBlockBase>;\n\n    // We need to first create an iterator range over (const) BlocktTy & instead\n    // of (const) BlockTy * for filter_range to work properly.\n    auto Mapped =\n        map_range(Range, [](BaseTy *Block) -> BaseTy & { return *Block; });\n    auto Filter = make_filter_range(\n        Mapped, [](BaseTy &Block) { return isa<BlockTy>(&Block); });\n    return map_range(Filter, [](BaseTy &Block) -> BlockTy * {\n      return cast<BlockTy>(&Block);\n    });\n  }\n};\n\nclass VPInterleavedAccessInfo {\n  DenseMap<VPInstruction *, InterleaveGroup<VPInstruction> *>\n      InterleaveGroupMap;\n\n  /// Type for mapping of instruction based interleave groups to VPInstruction\n  /// interleave groups\n  using Old2NewTy = DenseMap<InterleaveGroup<Instruction> *,\n                             InterleaveGroup<VPInstruction> *>;\n\n  /// Recursively \\p Region and populate VPlan based interleave groups based on\n  /// \\p IAI.\n  void visitRegion(VPRegionBlock *Region, Old2NewTy &Old2New,\n                   InterleavedAccessInfo &IAI);\n  /// Recursively traverse \\p Block and populate VPlan based interleave groups\n  /// based on \\p IAI.\n  void visitBlock(VPBlockBase *Block, Old2NewTy &Old2New,\n                  InterleavedAccessInfo &IAI);\n\npublic:\n  VPInterleavedAccessInfo(VPlan &Plan, InterleavedAccessInfo &IAI);\n\n  ~VPInterleavedAccessInfo() {\n    SmallPtrSet<InterleaveGroup<VPInstruction> *, 4> DelSet;\n    // Avoid releasing a pointer twice.\n    for (auto &I : InterleaveGroupMap)\n      DelSet.insert(I.second);\n    for (auto *Ptr : DelSet)\n      delete Ptr;\n  }\n\n  /// Get the interleave group that \\p Instr belongs to.\n  ///\n  /// \\returns nullptr if doesn't have such group.\n  InterleaveGroup<VPInstruction> *\n  getInterleaveGroup(VPInstruction *Instr) const {\n    return InterleaveGroupMap.lookup(Instr);\n  }\n};\n\n/// Class that maps (parts of) an existing VPlan to trees of combined\n/// VPInstructions.\nclass VPlanSlp {\n  enum class OpMode { Failed, Load, Opcode };\n\n  /// A DenseMapInfo implementation for using SmallVector<VPValue *, 4> as\n  /// DenseMap keys.\n  struct BundleDenseMapInfo {\n    static SmallVector<VPValue *, 4> getEmptyKey() {\n      return {reinterpret_cast<VPValue *>(-1)};\n    }\n\n    static SmallVector<VPValue *, 4> getTombstoneKey() {\n      return {reinterpret_cast<VPValue *>(-2)};\n    }\n\n    static unsigned getHashValue(const SmallVector<VPValue *, 4> &V) {\n      return static_cast<unsigned>(hash_combine_range(V.begin(), V.end()));\n    }\n\n    static bool isEqual(const SmallVector<VPValue *, 4> &LHS,\n                        const SmallVector<VPValue *, 4> &RHS) {\n      return LHS == RHS;\n    }\n  };\n\n  /// Mapping of values in the original VPlan to a combined VPInstruction.\n  DenseMap<SmallVector<VPValue *, 4>, VPInstruction *, BundleDenseMapInfo>\n      BundleToCombined;\n\n  VPInterleavedAccessInfo &IAI;\n\n  /// Basic block to operate on. For now, only instructions in a single BB are\n  /// considered.\n  const VPBasicBlock &BB;\n\n  /// Indicates whether we managed to combine all visited instructions or not.\n  bool CompletelySLP = true;\n\n  /// Width of the widest combined bundle in bits.\n  unsigned WidestBundleBits = 0;\n\n  using MultiNodeOpTy =\n      typename std::pair<VPInstruction *, SmallVector<VPValue *, 4>>;\n\n  // Input operand bundles for the current multi node. Each multi node operand\n  // bundle contains values not matching the multi node's opcode. They will\n  // be reordered in reorderMultiNodeOps, once we completed building a\n  // multi node.\n  SmallVector<MultiNodeOpTy, 4> MultiNodeOps;\n\n  /// Indicates whether we are building a multi node currently.\n  bool MultiNodeActive = false;\n\n  /// Check if we can vectorize Operands together.\n  bool areVectorizable(ArrayRef<VPValue *> Operands) const;\n\n  /// Add combined instruction \\p New for the bundle \\p Operands.\n  void addCombined(ArrayRef<VPValue *> Operands, VPInstruction *New);\n\n  /// Indicate we hit a bundle we failed to combine. Returns nullptr for now.\n  VPInstruction *markFailed();\n\n  /// Reorder operands in the multi node to maximize sequential memory access\n  /// and commutative operations.\n  SmallVector<MultiNodeOpTy, 4> reorderMultiNodeOps();\n\n  /// Choose the best candidate to use for the lane after \\p Last. The set of\n  /// candidates to choose from are values with an opcode matching \\p Last's\n  /// or loads consecutive to \\p Last.\n  std::pair<OpMode, VPValue *> getBest(OpMode Mode, VPValue *Last,\n                                       SmallPtrSetImpl<VPValue *> &Candidates,\n                                       VPInterleavedAccessInfo &IAI);\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n  /// Print bundle \\p Values to dbgs().\n  void dumpBundle(ArrayRef<VPValue *> Values);\n#endif\n\npublic:\n  VPlanSlp(VPInterleavedAccessInfo &IAI, VPBasicBlock &BB) : IAI(IAI), BB(BB) {}\n\n  ~VPlanSlp() = default;\n\n  /// Tries to build an SLP tree rooted at \\p Operands and returns a\n  /// VPInstruction combining \\p Operands, if they can be combined.\n  VPInstruction *buildGraph(ArrayRef<VPValue *> Operands);\n\n  /// Return the width of the widest combined bundle in bits.\n  unsigned getWidestBundleBits() const { return WidestBundleBits; }\n\n  /// Return true if all visited instruction can be combined.\n  bool isCompletelySLP() const { return CompletelySLP; }\n};\n\nnamespace vputils {\n\n/// Returns true if only the first lane of \\p Def is used.\nbool onlyFirstLaneUsed(const VPValue *Def);\n\n/// Returns true if only the first part of \\p Def is used.\nbool onlyFirstPartUsed(const VPValue *Def);\n\n/// Get or create a VPValue that corresponds to the expansion of \\p Expr. If \\p\n/// Expr is a SCEVConstant or SCEVUnknown, return a VPValue wrapping the live-in\n/// value. Otherwise return a VPExpandSCEVRecipe to expand \\p Expr. If \\p Plan's\n/// pre-header already contains a recipe expanding \\p Expr, return it. If not,\n/// create a new one.\nVPValue *getOrCreateVPValueForSCEVExpr(VPlan &Plan, const SCEV *Expr,\n                                       ScalarEvolution &SE);\n\n/// Returns true if \\p VPV is uniform after vectorization.\ninline bool isUniformAfterVectorization(VPValue *VPV) {\n  // A value defined outside the vector region must be uniform after\n  // vectorization inside a vector region.\n  if (VPV->isDefinedOutsideVectorRegions())\n    return true;\n  VPRecipeBase *Def = VPV->getDefiningRecipe();\n  assert(Def && \"Must have definition for value defined inside vector region\");\n  if (auto Rep = dyn_cast<VPReplicateRecipe>(Def))\n    return Rep->isUniform();\n  if (auto *GEP = dyn_cast<VPWidenGEPRecipe>(Def))\n    return all_of(GEP->operands(), isUniformAfterVectorization);\n  if (auto *VPI = dyn_cast<VPInstruction>(Def))\n    return VPI->getOpcode() == VPInstruction::ComputeReductionResult;\n  return false;\n}\n} // end namespace vputils\n\n} // end namespace llvm\n\n#endif // LLVM_TRANSFORMS_VECTORIZE_VPLAN_H\n"}], "code": "VPValue *vputils::getOrCreateVPValueForSCEVExpr(VPlan &Plan, const SCEV *Expr,\n                                                ScalarEvolution &SE) {\n  if (auto *Expanded = Plan.getSCEVExpansion(Expr))\n    return Expanded;\n  VPValue *Expanded = nullptr;\n  if (auto *E = dyn_cast<SCEVConstant>(Expr))\n    Expanded = Plan.getVPValueOrAddLiveIn(E->getValue());\n  else if (auto *E = dyn_cast<SCEVUnknown>(Expr))\n    Expanded = Plan.getVPValueOrAddLiveIn(E->getValue());\n  else {\n    Expanded = new VPExpandSCEVRecipe(Expr, SE);\n    Plan.getPreheader()->appendRecipe(Expanded->getDefiningRecipe());\n  }\n  Plan.addSCEVExpansion(Expr, Expanded);\n  return Expanded;\n}\n"}, "CB2779E506111B64": {"calls": [{"id": "0BF3EA94CBA5D689", "name": "llvm::TargetInstrInfo::reMaterialize", "path": "llvm-project/llvm/lib/CodeGen/TargetInstrInfo.cpp", "start": {"line": 418, "col": 1}, "end": {"line": 426, "col": 1}, "code": "                                    MachineBasicBlock::iterator I,\n                                    Register DestReg, unsigned SubIdx,\n                                    const MachineInstr &Orig,\n                                    const TargetRegisterInfo &TRI) const {\n  MachineInstr *MI = MBB.getParent()->CloneMachineInstr(&Orig);\n  MI->substituteRegister(MI->getOperand(0).getReg(), DestReg, SubIdx, TRI);\n  MBB.insert(I, MI);\n}\n\nbool TargetInstrInfo::produceSameValue(const MachineInstr &MI0,\n                                       const MachineInstr &MI1,\n                                       const MachineRegisterInfo *MRI) const {\n  return MI0.isIdenticalTo(MI1, MachineInstr::IgnoreVRegDefs);\n}\n\nMachineInstr &\nTargetInstrInfo::duplicate(MachineBasicBlock &MBB,\n                           MachineBasicBlock::iterator InsertBefore,\n                           const MachineInstr &Orig) const {\n  MachineFunction &MF = *MBB.getParent();\n  // CFI instructions are marked as non-duplicable, because Darwin compact\n  // unwind info emission can't handle multiple prologue setups.\n  assert((!Orig.isNotDuplicable() ||\n          (!MF.getTarget().getTargetTriple().isOSDarwin() &&\n           Orig.isCFIInstruction())) &&\n         \"Instruction cannot be duplicated\");\n\n  return MF.cloneMachineInstrBundle(MBB, InsertBefore, Orig);\n}\n\n// If the COPY instruction in MI can be folded to a stack operation, return\n// the register class to use.\nstatic const TargetRegisterClass *canFoldCopy(const MachineInstr &MI,\n                                              const TargetInstrInfo &TII,\n                                              unsigned FoldIdx) {\n  assert(TII.isCopyInstr(MI) && \"MI must be a COPY instruction\");\n  if (MI.getNumOperands() != 2)\n    return nullptr;\n  assert(FoldIdx<2 && \"FoldIdx refers no nonexistent operand\");\n\n  const MachineOperand &FoldOp = MI.getOperand(FoldIdx);\n  const MachineOperand &LiveOp = MI.getOperand(1 - FoldIdx);\n\n  if (FoldOp.getSubReg() || LiveOp.getSubReg())\n    return nullptr;\n\n  Register FoldReg = FoldOp.getReg();\n  Register LiveReg = LiveOp.getReg();\n\n  assert(FoldReg.isVirtual() && \"Cannot fold physregs\");\n\n  const MachineRegisterInfo &MRI = MI.getMF()->getRegInfo();\n  const TargetRegisterClass *RC = MRI.getRegClass(FoldReg);\n\n  if (LiveOp.getReg().isPhysical())\n    return RC->contains(LiveOp.getReg()) ? RC : nullptr;\n\n  if (RC->hasSubClassEq(MRI.getRegClass(LiveReg)))\n    return RC;\n\n  // FIXME: Allow folding when register classes are memory compatible.\n  return nullptr;\n}\n\nMCInst TargetInstrInfo::getNop() const { llvm_unreachable(\"Not implemented\"); }\n\nstd::pair<unsigned, unsigned>\nTargetInstrInfo::getPatchpointUnfoldableRange(const MachineInstr &MI) const {\n  switch (MI.getOpcode()) {\n  case TargetOpcode::STACKMAP:\n    // StackMapLiveValues are foldable\n    return std::make_pair(0, StackMapOpers(&MI).getVarIdx());\n  case TargetOpcode::PATCHPOINT:\n    // For PatchPoint, the call args are not foldable (even if reported in the\n    // stackmap e.g. via anyregcc).\n    return std::make_pair(0, PatchPointOpers(&MI).getVarIdx());\n  case TargetOpcode::STATEPOINT:\n    // For statepoints, fold deopt and gc arguments, but not call arguments.\n    return std::make_pair(MI.getNumDefs(), StatepointOpers(&MI).getVarIdx());\n  default:\n    llvm_unreachable(\"unexpected stackmap opcode\");\n  }\n}\n\nstatic MachineInstr *foldPatchpoint(MachineFunction &MF, MachineInstr &MI,\n                                    ArrayRef<unsigned> Ops, int FrameIndex,\n                                    const TargetInstrInfo &TII) {\n  unsigned StartIdx = 0;\n  unsigned NumDefs = 0;\n  // getPatchpointUnfoldableRange throws guarantee if MI is not a patchpoint.\n  std::tie(NumDefs, StartIdx) = TII.getPatchpointUnfoldableRange(MI);\n\n  unsigned DefToFoldIdx = MI.getNumOperands();\n\n  // Return false if any operands requested for folding are not foldable (not\n  // part of the stackmap's live values).\n  for (unsigned Op : Ops) {\n    if (Op < NumDefs) {\n      assert(DefToFoldIdx == MI.getNumOperands() && \"Folding multiple defs\");\n      DefToFoldIdx = Op;\n    } else if (Op < StartIdx) {\n      return nullptr;\n    }\n    if (MI.getOperand(Op).isTied())\n      return nullptr;\n  }\n\n  MachineInstr *NewMI =\n      MF.CreateMachineInstr(TII.get(MI.getOpcode()), MI.getDebugLoc(), true);\n  MachineInstrBuilder MIB(MF, NewMI);\n\n  // No need to fold return, the meta data, and function arguments\n  for (unsigned i = 0; i < StartIdx; ++i)\n    if (i != DefToFoldIdx)\n      MIB.add(MI.getOperand(i));\n\n  for (unsigned i = StartIdx, e = MI.getNumOperands(); i < e; ++i) {\n    MachineOperand &MO = MI.getOperand(i);\n    unsigned TiedTo = e;\n    (void)MI.isRegTiedToDefOperand(i, &TiedTo);\n\n    if (is_contained(Ops, i)) {\n      assert(TiedTo == e && \"Cannot fold tied operands\");\n      unsigned SpillSize;\n      unsigned SpillOffset;\n      // Compute the spill slot size and offset.\n      const TargetRegisterClass *RC =\n        MF.getRegInfo().getRegClass(MO.getReg());\n      bool Valid =\n          TII.getStackSlotRange(RC, MO.getSubReg(), SpillSize, SpillOffset, MF);\n      if (!Valid)\n        report_fatal_error(\"cannot spill patchpoint subregister operand\");\n      MIB.addImm(StackMaps::IndirectMemRefOp);\n      MIB.addImm(SpillSize);\n      MIB.addFrameIndex(FrameIndex);\n      MIB.addImm(SpillOffset);\n    } else {\n      MIB.add(MO);\n      if (TiedTo < e) {\n        assert(TiedTo < NumDefs && \"Bad tied operand\");\n        if (TiedTo > DefToFoldIdx)\n          --TiedTo;\n        NewMI->tieOperands(TiedTo, NewMI->getNumOperands() - 1);\n      }\n    }\n  }\n  return NewMI;\n}\n\nstatic void foldInlineAsmMemOperand(MachineInstr *MI, unsigned OpNo, int FI,\n                                    const TargetInstrInfo &TII) {\n  // If the machine operand is tied, untie it first.\n  if (MI->getOperand(OpNo).isTied()) {\n    unsigned TiedTo = MI->findTiedOperandIdx(OpNo);\n    MI->untieRegOperand(OpNo);\n    // Intentional recursion!\n    foldInlineAsmMemOperand(MI, TiedTo, FI, TII);\n  }\n\n  SmallVector<MachineOperand, 5> NewOps;\n  TII.getFrameIndexOperands(NewOps, FI);\n  assert(!NewOps.empty() && \"getFrameIndexOperands didn't create any operands\");\n  MI->removeOperand(OpNo);\n  MI->insert(MI->operands_begin() + OpNo, NewOps);\n\n  // Change the previous operand to a MemKind InlineAsm::Flag. The second param\n  // is the per-target number of operands that represent the memory operand\n  // excluding this one (MD). This includes MO.\n  InlineAsm::Flag F(InlineAsm::Kind::Mem, NewOps.size());\n  F.setMemConstraint(InlineAsm::ConstraintCode::m);\n  MachineOperand &MD = MI->getOperand(OpNo - 1);\n  MD.setImm(F);\n}\n\n// Returns nullptr if not possible to fold.\nstatic MachineInstr *foldInlineAsmMemOperand(MachineInstr &MI,\n                                             ArrayRef<unsigned> Ops, int FI,\n                                             const TargetInstrInfo &TII) {\n  assert(MI.isInlineAsm() && \"wrong opcode\");\n  if (Ops.size() > 1)\n    return nullptr;\n  unsigned Op = Ops[0];\n  assert(Op && \"should never be first operand\");\n  assert(MI.getOperand(Op).isReg() && \"shouldn't be folding non-reg operands\");\n\n  if (!MI.mayFoldInlineAsmRegOp(Op))\n    return nullptr;\n\n  MachineInstr &NewMI = TII.duplicate(*MI.getParent(), MI.getIterator(), MI);\n\n  foldInlineAsmMemOperand(&NewMI, Op, FI, TII);\n\n  // Update mayload/maystore metadata, and memoperands.\n  const VirtRegInfo &RI =\n      AnalyzeVirtRegInBundle(MI, MI.getOperand(Op).getReg());\n  MachineOperand &ExtraMO = NewMI.getOperand(InlineAsm::MIOp_ExtraInfo);\n  MachineMemOperand::Flags Flags = MachineMemOperand::MONone;\n  if (RI.Reads) {\n    ExtraMO.setImm(ExtraMO.getImm() | InlineAsm::Extra_MayLoad);\n    Flags |= MachineMemOperand::MOLoad;\n  }\n  if (RI.Writes) {\n    ExtraMO.setImm(ExtraMO.getImm() | InlineAsm::Extra_MayStore);\n    Flags |= MachineMemOperand::MOStore;\n  }\n  MachineFunction *MF = NewMI.getMF();\n  const MachineFrameInfo &MFI = MF->getFrameInfo();\n  MachineMemOperand *MMO = MF->getMachineMemOperand(\n      MachinePointerInfo::getFixedStack(*MF, FI), Flags, MFI.getObjectSize(FI),\n      MFI.getObjectAlign(FI));\n  NewMI.addMemOperand(*MF, MMO);\n\n  return &NewMI;\n}\n\nMachineInstr *TargetInstrInfo::foldMemoryOperand(MachineInstr &MI,\n                                                 ArrayRef<unsigned> Ops, int FI,\n                                                 LiveIntervals *LIS,\n                                                 VirtRegMap *VRM) const {\n  auto Flags = MachineMemOperand::MONone;\n  for (unsigned OpIdx : Ops)\n    Flags |= MI.getOperand(OpIdx).isDef() ? MachineMemOperand::MOStore\n                                          : MachineMemOperand::MOLoad;\n\n  MachineBasicBlock *MBB = MI.getParent();\n  assert(MBB && \"foldMemoryOperand needs an inserted instruction\");\n  MachineFunction &MF = *MBB->getParent();\n\n  // If we're not folding a load into a subreg, the size of the load is the\n  // size of the spill slot. But if we are, we need to figure out what the\n  // actual load size is.\n  int64_t MemSize = 0;\n  const MachineFrameInfo &MFI = MF.getFrameInfo();\n  const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();\n\n  if (Flags & MachineMemOperand::MOStore) {\n    MemSize = MFI.getObjectSize(FI);\n  } else {\n    for (unsigned OpIdx : Ops) {\n      int64_t OpSize = MFI.getObjectSize(FI);\n\n      if (auto SubReg = MI.getOperand(OpIdx).getSubReg()) {\n        unsigned SubRegSize = TRI->getSubRegIdxSize(SubReg);\n        if (SubRegSize > 0 && !(SubRegSize % 8))\n          OpSize = SubRegSize / 8;\n      }\n\n      MemSize = std::max(MemSize, OpSize);\n    }\n  }\n\n  assert(MemSize && \"Did not expect a zero-sized stack slot\");\n\n  MachineInstr *NewMI = nullptr;\n\n  if (MI.getOpcode() == TargetOpcode::STACKMAP ||\n      MI.getOpcode() == TargetOpcode::PATCHPOINT ||\n      MI.getOpcode() == TargetOpcode::STATEPOINT) {\n    // Fold stackmap/patchpoint.\n    NewMI = foldPatchpoint(MF, MI, Ops, FI, *this);\n    if (NewMI)\n      MBB->insert(MI, NewMI);\n  } else if (MI.isInlineAsm()) {\n    return foldInlineAsmMemOperand(MI, Ops, FI, *this);\n  } else {\n    // Ask the target to do the actual folding.\n    NewMI = foldMemoryOperandImpl(MF, MI, Ops, MI, FI, LIS, VRM);\n  }\n\n  if (NewMI) {\n    NewMI->setMemRefs(MF, MI.memoperands());\n    // Add a memory operand, foldMemoryOperandImpl doesn't do that.\n    assert((!(Flags & MachineMemOperand::MOStore) ||\n            NewMI->mayStore()) &&\n           \"Folded a def to a non-store!\");\n    assert((!(Flags & MachineMemOperand::MOLoad) ||\n            NewMI->mayLoad()) &&\n           \"Folded a use to a non-load!\");\n    assert(MFI.getObjectOffset(FI) != -1);\n    MachineMemOperand *MMO =\n        MF.getMachineMemOperand(MachinePointerInfo::getFixedStack(MF, FI),\n                                Flags, MemSize, MFI.getObjectAlign(FI));\n    NewMI->addMemOperand(MF, MMO);\n\n    // The pass \"x86 speculative load hardening\" always attaches symbols to\n    // call instructions. We need copy it form old instruction.\n    NewMI->cloneInstrSymbols(MF, MI);\n\n    return NewMI;\n  }\n\n  // Straight COPY may fold as load/store.\n  if (!isCopyInstr(MI) || Ops.size() != 1)\n    return nullptr;\n\n  const TargetRegisterClass *RC = canFoldCopy(MI, *this, Ops[0]);\n  if (!RC)\n    return nullptr;\n\n  const MachineOperand &MO = MI.getOperand(1 - Ops[0]);\n  MachineBasicBlock::iterator Pos = MI;\n\n  if (Flags == MachineMemOperand::MOStore)\n    storeRegToStackSlot(*MBB, Pos, MO.getReg(), MO.isKill(), FI, RC, TRI,\n                        Register());\n  else\n    loadRegFromStackSlot(*MBB, Pos, MO.getReg(), FI, RC, TRI, Register());\n  return &*--Pos;\n}\n\nMachineInstr *TargetInstrInfo::foldMemoryOperand(MachineInstr &MI,\n                                                 ArrayRef<unsigned> Ops,\n                                                 MachineInstr &LoadMI,\n                                                 LiveIntervals *LIS) const {\n  assert(LoadMI.canFoldAsLoad() && \"LoadMI isn't foldable!\");\n#ifndef NDEBUG\n  for (unsigned OpIdx : Ops)\n    assert(MI.getOperand(OpIdx).isUse() && \"Folding load into def!\");\n#endif\n\n  MachineBasicBlock &MBB = *MI.getParent();\n  MachineFunction &MF = *MBB.getParent();\n\n  // Ask the target to do the actual folding.\n  MachineInstr *NewMI = nullptr;\n  int FrameIndex = 0;\n\n  if ((MI.getOpcode() == TargetOpcode::STACKMAP ||\n       MI.getOpcode() == TargetOpcode::PATCHPOINT ||\n       MI.getOpcode() == TargetOpcode::STATEPOINT) &&\n      isLoadFromStackSlot(LoadMI, FrameIndex)) {\n    // Fold stackmap/patchpoint.\n    NewMI = foldPatchpoint(MF, MI, Ops, FrameIndex, *this);\n    if (NewMI)\n      NewMI = &*MBB.insert(MI, NewMI);\n  } else if (MI.isInlineAsm() && isLoadFromStackSlot(LoadMI, FrameIndex)) {\n    return foldInlineAsmMemOperand(MI, Ops, FrameIndex, *this);\n  } else {\n    // Ask the target to do the actual folding.\n    NewMI = foldMemoryOperandImpl(MF, MI, Ops, MI, LoadMI, LIS);\n  }\n\n  if (!NewMI)\n    return nullptr;\n\n  // Copy the memoperands from the load to the folded instruction.\n  if (MI.memoperands_empty()) {\n    NewMI->setMemRefs(MF, LoadMI.memoperands());\n  } else {\n    // Handle the rare case of folding multiple loads.\n    NewMI->setMemRefs(MF, MI.memoperands());\n    for (MachineInstr::mmo_iterator I = LoadMI.memoperands_begin(),\n                                    E = LoadMI.memoperands_end();\n         I != E; ++I) {\n      NewMI->addMemOperand(MF, *I);\n    }\n  }\n  return NewMI;\n}\n\n/// transferImplicitOperands - MI is a pseudo-instruction, and the lowered\n/// replacement instructions immediately precede it.  Copy any implicit\n/// operands from MI to the replacement instruction.\nstatic void transferImplicitOperands(MachineInstr *MI,\n                                     const TargetRegisterInfo *TRI) {\n  MachineBasicBlock::iterator CopyMI = MI;\n  --CopyMI;\n\n  Register DstReg = MI->getOperand(0).getReg();\n  for (const MachineOperand &MO : MI->implicit_operands()) {\n    CopyMI->addOperand(MO);\n\n    // Be conservative about preserving kills when subregister defs are\n    // involved. If there was implicit kill of a super-register overlapping the\n    // copy result, we would kill the subregisters previous copies defined.\n\n    if (MO.isKill() && TRI->regsOverlap(DstReg, MO.getReg()))\n      CopyMI->getOperand(CopyMI->getNumOperands() - 1).setIsKill(false);\n  }\n}\n\nvoid TargetInstrInfo::lowerCopy(MachineInstr *MI,\n                                const TargetRegisterInfo *TRI) const {\n  if (MI->allDefsAreDead()) {\n    MI->setDesc(get(TargetOpcode::KILL));\n    return;\n  }\n\n  MachineOperand &DstMO = MI->getOperand(0);\n  MachineOperand &SrcMO = MI->getOperand(1);\n\n  bool IdentityCopy = (SrcMO.getReg() == DstMO.getReg());\n  if (IdentityCopy || SrcMO.isUndef()) {\n    // No need to insert an identity copy instruction, but replace with a KILL\n    // if liveness is changed.\n    if (SrcMO.isUndef() || MI->getNumOperands() > 2) {\n      // We must make sure the super-register gets killed. Replace the\n      // instruction with KILL.\n      MI->setDesc(get(TargetOpcode::KILL));\n      return;\n    }\n    // Vanilla identity copy.\n    MI->eraseFromParent();\n    return;\n  }\n\n  copyPhysReg(*MI->getParent(), MI, MI->getDebugLoc(), DstMO.getReg(),\n              SrcMO.getReg(), SrcMO.isKill());\n\n  if (MI->getNumOperands() > 2)\n    transferImplicitOperands(MI, TRI);\n  MI->eraseFromParent();\n}\n\nbool TargetInstrInfo::hasReassociableOperands(\n    const MachineInstr &Inst, const MachineBasicBlock *MBB) const {\n  const MachineOperand &Op1 = Inst.getOperand(1);\n  const MachineOperand &Op2 = Inst.getOperand(2);\n  const MachineRegisterInfo &MRI = MBB->getParent()->getRegInfo();\n\n  // We need virtual register definitions for the operands that we will\n  // reassociate.\n  MachineInstr *MI1 = nullptr;\n  MachineInstr *MI2 = nullptr;\n  if (Op1.isReg() && Op1.getReg().isVirtual())\n    MI1 = MRI.getUniqueVRegDef(Op1.getReg());\n  if (Op2.isReg() && Op2.getReg().isVirtual())\n"}, {"id": "EFED589E70EFBC81", "name": "llvm::MachineInstr::clearRegisterDeads", "path": "llvm-project/llvm/lib/CodeGen/MachineInstr.cpp", "start": {"line": 2057, "col": 1}, "end": {"line": 2063, "col": 1}, "code": "  for (MachineOperand &MO : operands()) {\n    if (!MO.isReg() || !MO.isDef() || MO.getReg() != Reg)\n      continue;\n    MO.setIsDead(false);\n  }\n}\n\nvoid MachineInstr::setRegisterDefReadUndef(Register Reg, bool IsUndef) {\n  for (MachineOperand &MO : operands()) {\n    if (!MO.isReg() || !MO.isDef() || MO.getReg() != Reg || MO.getSubReg() == 0)\n      continue;\n    MO.setIsUndef(IsUndef);\n  }\n}\n\nvoid MachineInstr::addRegisterDefined(Register Reg,\n                                      const TargetRegisterInfo *RegInfo) {\n  if (Reg.isPhysical()) {\n    MachineOperand *MO = findRegisterDefOperand(Reg, false, false, RegInfo);\n    if (MO)\n      return;\n  } else {\n    for (const MachineOperand &MO : operands()) {\n      if (MO.isReg() && MO.getReg() == Reg && MO.isDef() &&\n          MO.getSubReg() == 0)\n        return;\n    }\n  }\n  addOperand(MachineOperand::CreateReg(Reg,\n                                       true  /*IsDef*/,\n                                       true  /*IsImp*/));\n}\n\nvoid MachineInstr::setPhysRegsDeadExcept(ArrayRef<Register> UsedRegs,\n                                         const TargetRegisterInfo &TRI) {\n  bool HasRegMask = false;\n  for (MachineOperand &MO : operands()) {\n    if (MO.isRegMask()) {\n      HasRegMask = true;\n      continue;\n    }\n    if (!MO.isReg() || !MO.isDef()) continue;\n    Register Reg = MO.getReg();\n    if (!Reg.isPhysical())\n      continue;\n    // If there are no uses, including partial uses, the def is dead.\n    if (llvm::none_of(UsedRegs,\n                      [&](MCRegister Use) { return TRI.regsOverlap(Use, Reg); }))\n      MO.setIsDead();\n  }\n\n  // This is a call with a register mask operand.\n  // Mask clobbers are always dead, so add defs for the non-dead defines.\n  if (HasRegMask)\n    for (const Register &UsedReg : UsedRegs)\n      addRegisterDefined(UsedReg, &TRI);\n}\n\nunsigned\nMachineInstrExpressionTrait::getHashValue(const MachineInstr* const &MI) {\n  // Build up a buffer of hash code components.\n  SmallVector<size_t, 16> HashComponents;\n  HashComponents.reserve(MI->getNumOperands() + 1);\n  HashComponents.push_back(MI->getOpcode());\n  for (const MachineOperand &MO : MI->operands()) {\n    if (MO.isReg() && MO.isDef() && MO.getReg().isVirtual())\n      continue;  // Skip virtual register defs.\n\n    HashComponents.push_back(hash_value(MO));\n  }\n  return hash_combine_range(HashComponents.begin(), HashComponents.end());\n}\n\nvoid MachineInstr::emitError(StringRef Msg) const {\n  // Find the source location cookie.\n  uint64_t LocCookie = 0;\n  const MDNode *LocMD = nullptr;\n  for (unsigned i = getNumOperands(); i != 0; --i) {\n    if (getOperand(i-1).isMetadata() &&\n        (LocMD = getOperand(i-1).getMetadata()) &&\n        LocMD->getNumOperands() != 0) {\n      if (const ConstantInt *CI =\n              mdconst::dyn_extract<ConstantInt>(LocMD->getOperand(0))) {\n        LocCookie = CI->getZExtValue();\n        break;\n      }\n    }\n  }\n\n  if (const MachineBasicBlock *MBB = getParent())\n    if (const MachineFunction *MF = MBB->getParent())\n      return MF->getMMI().getModule()->getContext().emitError(LocCookie, Msg);\n  report_fatal_error(Msg);\n}\n\nMachineInstrBuilder llvm::BuildMI(MachineFunction &MF, const DebugLoc &DL,\n                                  const MCInstrDesc &MCID, bool IsIndirect,\n                                  Register Reg, const MDNode *Variable,\n                                  const MDNode *Expr) {\n  assert(isa<DILocalVariable>(Variable) && \"not a variable\");\n  assert(cast<DIExpression>(Expr)->isValid() && \"not an expression\");\n  assert(cast<DILocalVariable>(Variable)->isValidLocationForIntrinsic(DL) &&\n         \"Expected inlined-at fields to agree\");\n  auto MIB = BuildMI(MF, DL, MCID).addReg(Reg);\n  if (IsIndirect)\n    MIB.addImm(0U);\n  else\n    MIB.addReg(0U);\n  return MIB.addMetadata(Variable).addMetadata(Expr);\n}\n\nMachineInstrBuilder llvm::BuildMI(MachineFunction &MF, const DebugLoc &DL,\n                                  const MCInstrDesc &MCID, bool IsIndirect,\n                                  ArrayRef<MachineOperand> DebugOps,\n                                  const MDNode *Variable, const MDNode *Expr) {\n  assert(isa<DILocalVariable>(Variable) && \"not a variable\");\n  assert(cast<DIExpression>(Expr)->isValid() && \"not an expression\");\n  assert(cast<DILocalVariable>(Variable)->isValidLocationForIntrinsic(DL) &&\n         \"Expected inlined-at fields to agree\");\n  if (MCID.Opcode == TargetOpcode::DBG_VALUE) {\n    assert(DebugOps.size() == 1 &&\n           \"DBG_VALUE must contain exactly one debug operand\");\n    MachineOperand DebugOp = DebugOps[0];\n    if (DebugOp.isReg())\n      return BuildMI(MF, DL, MCID, IsIndirect, DebugOp.getReg(), Variable,\n                     Expr);\n\n    auto MIB = BuildMI(MF, DL, MCID).add(DebugOp);\n    if (IsIndirect)\n      MIB.addImm(0U);\n    else\n      MIB.addReg(0U);\n    return MIB.addMetadata(Variable).addMetadata(Expr);\n  }\n\n  auto MIB = BuildMI(MF, DL, MCID);\n  MIB.addMetadata(Variable).addMetadata(Expr);\n  for (const MachineOperand &DebugOp : DebugOps)\n    if (DebugOp.isReg())\n      MIB.addReg(DebugOp.getReg());\n    else\n      MIB.add(DebugOp);\n  return MIB;\n}\n\nMachineInstrBuilder llvm::BuildMI(MachineBasicBlock &BB,\n                                  MachineBasicBlock::iterator I,\n                                  const DebugLoc &DL, const MCInstrDesc &MCID,\n                                  bool IsIndirect, Register Reg,\n                                  const MDNode *Variable, const MDNode *Expr) {\n  MachineFunction &MF = *BB.getParent();\n  MachineInstr *MI = BuildMI(MF, DL, MCID, IsIndirect, Reg, Variable, Expr);\n  BB.insert(I, MI);\n  return MachineInstrBuilder(MF, MI);\n}\n\nMachineInstrBuilder llvm::BuildMI(MachineBasicBlock &BB,\n                                  MachineBasicBlock::iterator I,\n                                  const DebugLoc &DL, const MCInstrDesc &MCID,\n                                  bool IsIndirect,\n                                  ArrayRef<MachineOperand> DebugOps,\n                                  const MDNode *Variable, const MDNode *Expr) {\n  MachineFunction &MF = *BB.getParent();\n  MachineInstr *MI =\n      BuildMI(MF, DL, MCID, IsIndirect, DebugOps, Variable, Expr);\n  BB.insert(I, MI);\n  return MachineInstrBuilder(MF, *MI);\n}\n\n/// Compute the new DIExpression to use with a DBG_VALUE for a spill slot.\n/// This prepends DW_OP_deref when spilling an indirect DBG_VALUE.\nstatic const DIExpression *\ncomputeExprForSpill(const MachineInstr &MI,\n                    SmallVectorImpl<const MachineOperand *> &SpilledOperands) {\n  assert(MI.getDebugVariable()->isValidLocationForIntrinsic(MI.getDebugLoc()) &&\n         \"Expected inlined-at fields to agree\");\n\n  const DIExpression *Expr = MI.getDebugExpression();\n  if (MI.isIndirectDebugValue()) {\n    assert(MI.getDebugOffset().getImm() == 0 &&\n           \"DBG_VALUE with nonzero offset\");\n    Expr = DIExpression::prepend(Expr, DIExpression::DerefBefore);\n  } else if (MI.isDebugValueList()) {\n    // We will replace the spilled register with a frame index, so\n    // immediately deref all references to the spilled register.\n    std::array<uint64_t, 1> Ops{{dwarf::DW_OP_deref}};\n    for (const MachineOperand *Op : SpilledOperands) {\n      unsigned OpIdx = MI.getDebugOperandIndex(Op);\n      Expr = DIExpression::appendOpsToArg(Expr, Ops, OpIdx);\n    }\n  }\n  return Expr;\n}\nstatic const DIExpression *computeExprForSpill(const MachineInstr &MI,\n                                               Register SpillReg) {\n  assert(MI.hasDebugOperandForReg(SpillReg) && \"Spill Reg is not used in MI.\");\n  SmallVector<const MachineOperand *> SpillOperands;\n  for (const MachineOperand &Op : MI.getDebugOperandsForReg(SpillReg))\n    SpillOperands.push_back(&Op);\n  return computeExprForSpill(MI, SpillOperands);\n}\n\nMachineInstr *llvm::buildDbgValueForSpill(MachineBasicBlock &BB,\n                                          MachineBasicBlock::iterator I,\n                                          const MachineInstr &Orig,\n                                          int FrameIndex, Register SpillReg) {\n  assert(!Orig.isDebugRef() &&\n         \"DBG_INSTR_REF should not reference a virtual register.\");\n  const DIExpression *Expr = computeExprForSpill(Orig, SpillReg);\n  MachineInstrBuilder NewMI =\n      BuildMI(BB, I, Orig.getDebugLoc(), Orig.getDesc());\n  // Non-Variadic Operands: Location, Offset, Variable, Expression\n  // Variadic Operands:     Variable, Expression, Locations...\n  if (Orig.isNonListDebugValue())\n    NewMI.addFrameIndex(FrameIndex).addImm(0U);\n  NewMI.addMetadata(Orig.getDebugVariable()).addMetadata(Expr);\n  if (Orig.isDebugValueList()) {\n    for (const MachineOperand &Op : Orig.debug_operands())\n      if (Op.isReg() && Op.getReg() == SpillReg)\n        NewMI.addFrameIndex(FrameIndex);\n      else\n        NewMI.add(MachineOperand(Op));\n  }\n  return NewMI;\n}\nMachineInstr *llvm::buildDbgValueForSpill(\n    MachineBasicBlock &BB, MachineBasicBlock::iterator I,\n    const MachineInstr &Orig, int FrameIndex,\n    SmallVectorImpl<const MachineOperand *> &SpilledOperands) {\n  const DIExpression *Expr = computeExprForSpill(Orig, SpilledOperands);\n  MachineInstrBuilder NewMI =\n      BuildMI(BB, I, Orig.getDebugLoc(), Orig.getDesc());\n  // Non-Variadic Operands: Location, Offset, Variable, Expression\n  // Variadic Operands:     Variable, Expression, Locations...\n  if (Orig.isNonListDebugValue())\n    NewMI.addFrameIndex(FrameIndex).addImm(0U);\n  NewMI.addMetadata(Orig.getDebugVariable()).addMetadata(Expr);\n  if (Orig.isDebugValueList()) {\n    for (const MachineOperand &Op : Orig.debug_operands())\n      if (is_contained(SpilledOperands, &Op))\n        NewMI.addFrameIndex(FrameIndex);\n      else\n        NewMI.add(MachineOperand(Op));\n  }\n  return NewMI;\n}\n\nvoid llvm::updateDbgValueForSpill(MachineInstr &Orig, int FrameIndex,\n                                  Register Reg) {\n  const DIExpression *Expr = computeExprForSpill(Orig, Reg);\n  if (Orig.isNonListDebugValue())\n    Orig.getDebugOffset().ChangeToImmediate(0U);\n  for (MachineOperand &Op : Orig.getDebugOperandsForReg(Reg))\n    Op.ChangeToFrameIndex(FrameIndex);\n  Orig.getDebugExpressionOp().setMetadata(Expr);\n}\n\nvoid MachineInstr::collectDebugValues(\n                                SmallVectorImpl<MachineInstr *> &DbgValues) {\n  MachineInstr &MI = *this;\n  if (!MI.getOperand(0).isReg())\n    return;\n\n  MachineBasicBlock::iterator DI = MI; ++DI;\n  for (MachineBasicBlock::iterator DE = MI.getParent()->end();\n       DI != DE; ++DI) {\n    if (!DI->isDebugValue())\n      return;\n    if (DI->hasDebugOperandForReg(MI.getOperand(0).getReg()))\n      DbgValues.push_back(&*DI);\n  }\n}\n\nvoid MachineInstr::changeDebugValuesDefReg(Register Reg) {\n  // Collect matching debug values.\n  SmallVector<MachineInstr *, 2> DbgValues;\n\n  if (!getOperand(0).isReg())\n    return;\n\n  Register DefReg = getOperand(0).getReg();\n  auto *MRI = getRegInfo();\n  for (auto &MO : MRI->use_operands(DefReg)) {\n    auto *DI = MO.getParent();\n    if (!DI->isDebugValue())\n      continue;\n    if (DI->hasDebugOperandForReg(DefReg)) {\n      DbgValues.push_back(DI);\n    }\n  }\n\n  // Propagate Reg to debug value instructions.\n  for (auto *DBI : DbgValues)\n    for (MachineOperand &Op : DBI->getDebugOperandsForReg(DefReg))\n      Op.setReg(Reg);\n}\n\nusing MMOList = SmallVector<const MachineMemOperand *, 2>;\n\nstatic unsigned getSpillSlotSize(const MMOList &Accesses,\n                                 const MachineFrameInfo &MFI) {\n  unsigned Size = 0;\n  for (const auto *A : Accesses)\n    if (MFI.isSpillSlotObjectIndex(\n            cast<FixedStackPseudoSourceValue>(A->getPseudoValue())\n                ->getFrameIndex()))\n      Size += A->getSize();\n  return Size;\n}\n\nstd::optional<unsigned>\nMachineInstr::getSpillSize(const TargetInstrInfo *TII) const {\n  int FI;\n  if (TII->isStoreToStackSlotPostFE(*this, FI)) {\n    const MachineFrameInfo &MFI = getMF()->getFrameInfo();\n    if (MFI.isSpillSlotObjectIndex(FI))\n      return (*memoperands_begin())->getSize();\n  }\n  return std::nullopt;\n}\n\nstd::optional<unsigned>\nMachineInstr::getFoldedSpillSize(const TargetInstrInfo *TII) const {\n  MMOList Accesses;\n  if (TII->hasStoreToStackSlot(*this, Accesses))\n    return getSpillSlotSize(Accesses, getMF()->getFrameInfo());\n  return std::nullopt;\n}\n\nstd::optional<unsigned>\nMachineInstr::getRestoreSize(const TargetInstrInfo *TII) const {\n  int FI;\n  if (TII->isLoadFromStackSlotPostFE(*this, FI)) {\n    const MachineFrameInfo &MFI = getMF()->getFrameInfo();\n    if (MFI.isSpillSlotObjectIndex(FI))\n      return (*memoperands_begin())->getSize();\n  }\n  return std::nullopt;\n}\n\nstd::optional<unsigned>\nMachineInstr::getFoldedRestoreSize(const TargetInstrInfo *TII) const {\n  MMOList Accesses;\n  if (TII->hasLoadFromStackSlot(*this, Accesses))\n    return getSpillSlotSize(Accesses, getMF()->getFrameInfo());\n  return std::nullopt;\n}\n\nunsigned MachineInstr::getDebugInstrNum() {\n  if (DebugInstrNum == 0)\n    DebugInstrNum = getParent()->getParent()->getNewDebugInstrNum();\n  return DebugInstrNum;\n}\n\nunsigned MachineInstr::getDebugInstrNum(MachineFunction &MF) {\n  if (DebugInstrNum == 0)\n    DebugInstrNum = MF.getNewDebugInstrNum();\n  return DebugInstrNum;\n}\n\nstd::tuple<LLT, LLT> MachineInstr::getFirst2LLTs() const {\n  return std::tuple(getRegInfo()->getType(getOperand(0).getReg()),\n                    getRegInfo()->getType(getOperand(1).getReg()));\n}\n\nstd::tuple<LLT, LLT, LLT> MachineInstr::getFirst3LLTs() const {\n  return std::tuple(getRegInfo()->getType(getOperand(0).getReg()),\n                    getRegInfo()->getType(getOperand(1).getReg()),\n                    getRegInfo()->getType(getOperand(2).getReg()));\n}\n\nstd::tuple<LLT, LLT, LLT, LLT> MachineInstr::getFirst4LLTs() const {\n  return std::tuple(getRegInfo()->getType(getOperand(0).getReg()),\n                    getRegInfo()->getType(getOperand(1).getReg()),\n                    getRegInfo()->getType(getOperand(2).getReg()),\n                    getRegInfo()->getType(getOperand(3).getReg()));\n}\n\nstd::tuple<LLT, LLT, LLT, LLT, LLT> MachineInstr::getFirst5LLTs() const {\n  return std::tuple(getRegInfo()->getType(getOperand(0).getReg()),\n                    getRegInfo()->getType(getOperand(1).getReg()),\n                    getRegInfo()->getType(getOperand(2).getReg()),\n                    getRegInfo()->getType(getOperand(3).getReg()),\n                    getRegInfo()->getType(getOperand(4).getReg()));\n}\n\nstd::tuple<Register, LLT, Register, LLT>\nMachineInstr::getFirst2RegLLTs() const {\n  Register Reg0 = getOperand(0).getReg();\n  Register Reg1 = getOperand(1).getReg();\n  return std::tuple(Reg0, getRegInfo()->getType(Reg0), Reg1,\n                    getRegInfo()->getType(Reg1));\n}\n\nstd::tuple<Register, LLT, Register, LLT, Register, LLT>\nMachineInstr::getFirst3RegLLTs() const {\n  Register Reg0 = getOperand(0).getReg();\n  Register Reg1 = getOperand(1).getReg();\n  Register Reg2 = getOperand(2).getReg();\n  return std::tuple(Reg0, getRegInfo()->getType(Reg0), Reg1,\n                    getRegInfo()->getType(Reg1), Reg2,\n                    getRegInfo()->getType(Reg2));\n}\n\nstd::tuple<Register, LLT, Register, LLT, Register, LLT, Register, LLT>\nMachineInstr::getFirst4RegLLTs() const {\n  Register Reg0 = getOperand(0).getReg();\n  Register Reg1 = getOperand(1).getReg();\n  Register Reg2 = getOperand(2).getReg();\n  Register Reg3 = getOperand(3).getReg();\n  return std::tuple(\n      Reg0, getRegInfo()->getType(Reg0), Reg1, getRegInfo()->getType(Reg1),\n      Reg2, getRegInfo()->getType(Reg2), Reg3, getRegInfo()->getType(Reg3));\n}\n\nstd::tuple<Register, LLT, Register, LLT, Register, LLT, Register, LLT, Register,\n           LLT>\nMachineInstr::getFirst5RegLLTs() const {\n  Register Reg0 = getOperand(0).getReg();\n  Register Reg1 = getOperand(1).getReg();\n  Register Reg2 = getOperand(2).getReg();\n  Register Reg3 = getOperand(3).getReg();\n  Register Reg4 = getOperand(4).getReg();\n  return std::tuple(\n      Reg0, getRegInfo()->getType(Reg0), Reg1, getRegInfo()->getType(Reg1),\n      Reg2, getRegInfo()->getType(Reg2), Reg3, getRegInfo()->getType(Reg3),\n      Reg4, getRegInfo()->getType(Reg4));\n}\n\nvoid MachineInstr::insert(mop_iterator InsertBefore,\n                          ArrayRef<MachineOperand> Ops) {\n  assert(InsertBefore != nullptr && \"invalid iterator\");\n  assert(InsertBefore->getParent() == this &&\n         \"iterator points to operand of other inst\");\n  if (Ops.empty())\n    return;\n\n  // Do one pass to untie operands.\n  SmallDenseMap<unsigned, unsigned> TiedOpIndices;\n  for (const MachineOperand &MO : operands()) {\n    if (MO.isReg() && MO.isTied()) {\n      unsigned OpNo = getOperandNo(&MO);\n      unsigned TiedTo = findTiedOperandIdx(OpNo);\n      TiedOpIndices[OpNo] = TiedTo;\n      untieRegOperand(OpNo);\n    }\n  }\n\n  unsigned OpIdx = getOperandNo(InsertBefore);\n  unsigned NumOperands = getNumOperands();\n  unsigned OpsToMove = NumOperands - OpIdx;\n\n  SmallVector<MachineOperand> MovingOps;\n  MovingOps.reserve(OpsToMove);\n\n  for (unsigned I = 0; I < OpsToMove; ++I) {\n    MovingOps.emplace_back(getOperand(OpIdx));\n    removeOperand(OpIdx);\n  }\n  for (const MachineOperand &MO : Ops)\n    addOperand(MO);\n  for (const MachineOperand &OpMoved : MovingOps)\n    addOperand(OpMoved);\n\n  // Re-tie operands.\n  for (auto [Tie1, Tie2] : TiedOpIndices) {\n    if (Tie1 >= OpIdx)\n      Tie1 += Ops.size();\n    if (Tie2 >= OpIdx)\n      Tie2 += Ops.size();\n    tieOperands(Tie1, Tie2);\n  }\n}\n\nbool MachineInstr::mayFoldInlineAsmRegOp(unsigned OpId) const {\n  assert(OpId && \"expected non-zero operand id\");\n  assert(isInlineAsm() && \"should only be used on inline asm\");\n\n  if (!getOperand(OpId).isReg())\n    return false;\n\n  const MachineOperand &MD = getOperand(OpId - 1);\n  if (!MD.isImm())\n    return false;\n\n  InlineAsm::Flag F(MD.getImm());\n  if (F.isRegUseKind() || F.isRegDefKind() || F.isRegDefEarlyClobberKind())\n    return F.getRegMayBeFolded();\n  return false;\n}\n"}], "code": "SlotIndex LiveRangeEdit::rematerializeAt(MachineBasicBlock &MBB,\n                                         MachineBasicBlock::iterator MI,\n                                         Register DestReg, const Remat &RM,\n                                         const TargetRegisterInfo &tri,\n                                         bool Late, unsigned SubIdx,\n                                         MachineInstr *ReplaceIndexMI) {\n  assert(RM.OrigMI && \"Invalid remat\");\n  TII.reMaterialize(MBB, MI, DestReg, SubIdx, *RM.OrigMI, tri);\n  // DestReg of the cloned instruction cannot be Dead. Set isDead of DestReg\n  // to false anyway in case the isDead flag of RM.OrigMI's dest register\n  // is true.\n  (*--MI).clearRegisterDeads(DestReg);\n  Rematted.insert(RM.ParentVNI);\n  ++NumReMaterialization;\n\n  if (ReplaceIndexMI)\n    return LIS.ReplaceMachineInstrInMaps(*ReplaceIndexMI, *MI).getRegSlot();\n  return LIS.getSlotIndexes()->insertMachineInstrInMaps(*MI, Late).getRegSlot();\n}\n"}, "8E118F1D6EE743FE": {"calls": [{"id": "88889EF9A6AF85B9", "name": "llvm::SCEVExpander::getIVIncOperand", "path": "llvm-project/llvm/lib/Transforms/Utils/ScalarEvolutionExpander.cpp", "start": {"line": 662, "col": 1}, "end": {"line": 700, "col": 1}, "code": "                                           Instruction *InsertPos,\n                                           bool allowScale) {\n  if (IncV == InsertPos)\n    return nullptr;\n\n  switch (IncV->getOpcode()) {\n  default:\n    return nullptr;\n  // Check for a simple Add/Sub or GEP of a loop invariant step.\n  case Instruction::Add:\n  case Instruction::Sub: {\n    Instruction *OInst = dyn_cast<Instruction>(IncV->getOperand(1));\n    if (!OInst || SE.DT.dominates(OInst, InsertPos))\n      return dyn_cast<Instruction>(IncV->getOperand(0));\n    return nullptr;\n  }\n  case Instruction::BitCast:\n    return dyn_cast<Instruction>(IncV->getOperand(0));\n  case Instruction::GetElementPtr:\n    for (Use &U : llvm::drop_begin(IncV->operands())) {\n      if (isa<Constant>(U))\n        continue;\n      if (Instruction *OInst = dyn_cast<Instruction>(U)) {\n        if (!SE.DT.dominates(OInst, InsertPos))\n          return nullptr;\n      }\n      if (allowScale) {\n        // allow any kind of GEP as long as it can be hoisted.\n        continue;\n      }\n      // GEPs produced by SCEVExpander use i8 element type.\n      if (!cast<GEPOperator>(IncV)->getSourceElementType()->isIntegerTy(8))\n        return nullptr;\n      break;\n    }\n    return dyn_cast<Instruction>(IncV->getOperand(0));\n  }\n}\n\n/// If the insert point of the current builder or any of the builders on the\n/// stack of saved builders has 'I' as its insert point, update it to point to\n/// the instruction after 'I'.  This is intended to be used when the instruction\n/// 'I' is being moved.  If this fixup is not done and 'I' is moved to a\n/// different block, the inconsistent insert point (with a mismatched\n/// Instruction and Block) can lead to an instruction being inserted in a block\n/// other than its parent.\nvoid SCEVExpander::fixupInsertPoints(Instruction *I) {\n  BasicBlock::iterator It(*I);\n  BasicBlock::iterator NewInsertPt = std::next(It);\n  if (Builder.GetInsertPoint() == It)\n    Builder.SetInsertPoint(&*NewInsertPt);\n  for (auto *InsertPtGuard : InsertPointGuards)\n    if (InsertPtGuard->GetInsertPoint() == It)\n      InsertPtGuard->SetInsertPoint(NewInsertPt);\n}\n\n/// hoistStep - Attempt to hoist a simple IV increment above InsertPos to make\n/// it available to other uses in this loop. Recursively hoist any operands,\n/// until we reach a value that dominates InsertPos.\nbool SCEVExpander::hoistIVInc(Instruction *IncV, Instruction *InsertPos,\n                              bool RecomputePoisonFlags) {\n  auto FixupPoisonFlags = [this](Instruction *I) {\n    // Drop flags that are potentially inferred from old context and infer flags\n    // in new context.\n    I->dropPoisonGeneratingFlags();\n    if (auto *OBO = dyn_cast<OverflowingBinaryOperator>(I))\n      if (auto Flags = SE.getStrengthenedNoWrapFlagsFromBinOp(OBO)) {\n        auto *BO = cast<BinaryOperator>(I);\n        BO->setHasNoUnsignedWrap(\n            ScalarEvolution::maskFlags(*Flags, SCEV::FlagNUW) == SCEV::FlagNUW);\n        BO->setHasNoSignedWrap(\n            ScalarEvolution::maskFlags(*Flags, SCEV::FlagNSW) == SCEV::FlagNSW);\n      }\n  };\n\n  if (SE.DT.dominates(IncV, InsertPos)) {\n    if (RecomputePoisonFlags)\n      FixupPoisonFlags(IncV);\n    return true;\n  }\n\n  // InsertPos must itself dominate IncV so that IncV's new position satisfies\n  // its existing users.\n  if (isa<PHINode>(InsertPos) ||\n      !SE.DT.dominates(InsertPos->getParent(), IncV->getParent()))\n    return false;\n\n  if (!SE.LI.movementPreservesLCSSAForm(IncV, InsertPos))\n    return false;\n\n  // Check that the chain of IV operands leading back to Phi can be hoisted.\n  SmallVector<Instruction*, 4> IVIncs;\n  for(;;) {\n    Instruction *Oper = getIVIncOperand(IncV, InsertPos, /*allowScale*/true);\n    if (!Oper)\n      return false;\n    // IncV is safe to hoist.\n    IVIncs.push_back(IncV);\n    IncV = Oper;\n    if (SE.DT.dominates(IncV, InsertPos))\n      break;\n  }\n  for (Instruction *I : llvm::reverse(IVIncs)) {\n    fixupInsertPoints(I);\n    I->moveBefore(InsertPos);\n    if (RecomputePoisonFlags)\n      FixupPoisonFlags(I);\n  }\n  return true;\n}\n\n/// Determine if this cyclic phi is in a form that would have been generated by\n/// LSR. We don't care if the phi was actually expanded in this pass, as long\n/// as it is in a low-cost form, for example, no implied multiplication. This\n/// should match any patterns generated by getAddRecExprPHILiterally and\n/// expandAddtoGEP.\nbool SCEVExpander::isExpandedAddRecExprPHI(PHINode *PN, Instruction *IncV,\n                                           const Loop *L) {\n  for(Instruction *IVOper = IncV;\n      (IVOper = getIVIncOperand(IVOper, L->getLoopPreheader()->getTerminator(),\n                                /*allowScale=*/false));) {\n    if (IVOper == PN)\n      return true;\n  }\n  return false;\n}\n\n/// expandIVInc - Expand an IV increment at Builder's current InsertPos.\n/// Typically this is the LatchBlock terminator or IVIncInsertPos, but we may\n/// need to materialize IV increments elsewhere to handle difficult situations.\nValue *SCEVExpander::expandIVInc(PHINode *PN, Value *StepV, const Loop *L,\n                                 bool useSubtract) {\n  Value *IncV;\n  // If the PHI is a pointer, use a GEP, otherwise use an add or sub.\n  if (PN->getType()->isPointerTy()) {\n    // TODO: Change name to IVName.iv.next.\n    IncV = Builder.CreatePtrAdd(PN, StepV, \"scevgep\");\n  } else {\n    IncV = useSubtract ?\n      Builder.CreateSub(PN, StepV, Twine(IVName) + \".iv.next\") :\n      Builder.CreateAdd(PN, StepV, Twine(IVName) + \".iv.next\");\n  }\n  return IncV;\n}\n\n/// Check whether we can cheaply express the requested SCEV in terms of\n/// the available PHI SCEV by truncation and/or inversion of the step.\nstatic bool canBeCheaplyTransformed(ScalarEvolution &SE,\n                                    const SCEVAddRecExpr *Phi,\n                                    const SCEVAddRecExpr *Requested,\n                                    bool &InvertStep) {\n  // We can't transform to match a pointer PHI.\n  Type *PhiTy = Phi->getType();\n  Type *RequestedTy = Requested->getType();\n  if (PhiTy->isPointerTy() || RequestedTy->isPointerTy())\n    return false;\n\n  if (RequestedTy->getIntegerBitWidth() > PhiTy->getIntegerBitWidth())\n    return false;\n\n  // Try truncate it if necessary.\n  Phi = dyn_cast<SCEVAddRecExpr>(SE.getTruncateOrNoop(Phi, RequestedTy));\n  if (!Phi)\n    return false;\n\n  // Check whether truncation will help.\n  if (Phi == Requested) {\n    InvertStep = false;\n    return true;\n  }\n\n  // Check whether inverting will help: {R,+,-1} == R - {0,+,1}.\n  if (SE.getMinusSCEV(Requested->getStart(), Requested) == Phi) {\n    InvertStep = true;\n    return true;\n  }\n\n  return false;\n}\n\nstatic bool IsIncrementNSW(ScalarEvolution &SE, const SCEVAddRecExpr *AR) {\n  if (!isa<IntegerType>(AR->getType()))\n    return false;\n\n  unsigned BitWidth = cast<IntegerType>(AR->getType())->getBitWidth();\n  Type *WideTy = IntegerType::get(AR->getType()->getContext(), BitWidth * 2);\n  const SCEV *Step = AR->getStepRecurrence(SE);\n  const SCEV *OpAfterExtend = SE.getAddExpr(SE.getSignExtendExpr(Step, WideTy),\n                                            SE.getSignExtendExpr(AR, WideTy));\n  const SCEV *ExtendAfterOp =\n    SE.getSignExtendExpr(SE.getAddExpr(AR, Step), WideTy);\n  return ExtendAfterOp == OpAfterExtend;\n}\n\nstatic bool IsIncrementNUW(ScalarEvolution &SE, const SCEVAddRecExpr *AR) {\n  if (!isa<IntegerType>(AR->getType()))\n    return false;\n\n  unsigned BitWidth = cast<IntegerType>(AR->getType())->getBitWidth();\n  Type *WideTy = IntegerType::get(AR->getType()->getContext(), BitWidth * 2);\n  const SCEV *Step = AR->getStepRecurrence(SE);\n  const SCEV *OpAfterExtend = SE.getAddExpr(SE.getZeroExtendExpr(Step, WideTy),\n                                            SE.getZeroExtendExpr(AR, WideTy));\n  const SCEV *ExtendAfterOp =\n    SE.getZeroExtendExpr(SE.getAddExpr(AR, Step), WideTy);\n  return ExtendAfterOp == OpAfterExtend;\n}\n\n/// getAddRecExprPHILiterally - Helper for expandAddRecExprLiterally. Expand\n/// the base addrec, which is the addrec without any non-loop-dominating\n/// values, and return the PHI.\nPHINode *\nSCEVExpander::getAddRecExprPHILiterally(const SCEVAddRecExpr *Normalized,\n                                        const Loop *L, Type *&TruncTy,\n                                        bool &InvertStep) {\n  assert((!IVIncInsertLoop || IVIncInsertPos) &&\n         \"Uninitialized insert position\");\n\n  // Reuse a previously-inserted PHI, if present.\n  BasicBlock *LatchBlock = L->getLoopLatch();\n  if (LatchBlock) {\n    PHINode *AddRecPhiMatch = nullptr;\n    Instruction *IncV = nullptr;\n    TruncTy = nullptr;\n    InvertStep = false;\n\n    // Only try partially matching scevs that need truncation and/or\n    // step-inversion if we know this loop is outside the current loop.\n    bool TryNonMatchingSCEV =\n        IVIncInsertLoop &&\n        SE.DT.properlyDominates(LatchBlock, IVIncInsertLoop->getHeader());\n\n    for (PHINode &PN : L->getHeader()->phis()) {\n      if (!SE.isSCEVable(PN.getType()))\n        continue;\n\n      // We should not look for a incomplete PHI. Getting SCEV for a incomplete\n      // PHI has no meaning at all.\n      if (!PN.isComplete()) {\n        SCEV_DEBUG_WITH_TYPE(\n            DebugType, dbgs() << \"One incomplete PHI is found: \" << PN << \"\\n\");\n        continue;\n      }\n\n      const SCEVAddRecExpr *PhiSCEV = dyn_cast<SCEVAddRecExpr>(SE.getSCEV(&PN));\n      if (!PhiSCEV)\n        continue;\n\n      bool IsMatchingSCEV = PhiSCEV == Normalized;\n      // We only handle truncation and inversion of phi recurrences for the\n      // expanded expression if the expanded expression's loop dominates the\n      // loop we insert to. Check now, so we can bail out early.\n      if (!IsMatchingSCEV && !TryNonMatchingSCEV)\n          continue;\n\n      // TODO: this possibly can be reworked to avoid this cast at all.\n      Instruction *TempIncV =\n          dyn_cast<Instruction>(PN.getIncomingValueForBlock(LatchBlock));\n      if (!TempIncV)\n        continue;\n\n      // Check whether we can reuse this PHI node.\n      if (LSRMode) {\n        if (!isExpandedAddRecExprPHI(&PN, TempIncV, L))\n          continue;\n      } else {\n        if (!isNormalAddRecExprPHI(&PN, TempIncV, L))\n          continue;\n      }\n\n      // Stop if we have found an exact match SCEV.\n      if (IsMatchingSCEV) {\n        IncV = TempIncV;\n        TruncTy = nullptr;\n        InvertStep = false;\n        AddRecPhiMatch = &PN;\n        break;\n      }\n\n      // Try whether the phi can be translated into the requested form\n      // (truncated and/or offset by a constant).\n      if ((!TruncTy || InvertStep) &&\n          canBeCheaplyTransformed(SE, PhiSCEV, Normalized, InvertStep)) {\n        // Record the phi node. But don't stop we might find an exact match\n        // later.\n        AddRecPhiMatch = &PN;\n        IncV = TempIncV;\n        TruncTy = Normalized->getType();\n      }\n    }\n\n    if (AddRecPhiMatch) {\n      // Ok, the add recurrence looks usable.\n      // Remember this PHI, even in post-inc mode.\n      InsertedValues.insert(AddRecPhiMatch);\n      // Remember the increment.\n      rememberInstruction(IncV);\n      // Those values were not actually inserted but re-used.\n      ReusedValues.insert(AddRecPhiMatch);\n      ReusedValues.insert(IncV);\n      return AddRecPhiMatch;\n    }\n  }\n\n  // Save the original insertion point so we can restore it when we're done.\n  SCEVInsertPointGuard Guard(Builder, this);\n\n  // Another AddRec may need to be recursively expanded below. For example, if\n  // this AddRec is quadratic, the StepV may itself be an AddRec in this\n  // loop. Remove this loop from the PostIncLoops set before expanding such\n  // AddRecs. Otherwise, we cannot find a valid position for the step\n  // (i.e. StepV can never dominate its loop header).  Ideally, we could do\n  // SavedIncLoops.swap(PostIncLoops), but we generally have a single element,\n  // so it's not worth implementing SmallPtrSet::swap.\n  PostIncLoopSet SavedPostIncLoops = PostIncLoops;\n  PostIncLoops.clear();\n\n  // Expand code for the start value into the loop preheader.\n  assert(L->getLoopPreheader() &&\n         \"Can't expand add recurrences without a loop preheader!\");\n  Value *StartV =\n      expand(Normalized->getStart(), L->getLoopPreheader()->getTerminator());\n\n  // StartV must have been be inserted into L's preheader to dominate the new\n  // phi.\n  assert(!isa<Instruction>(StartV) ||\n         SE.DT.properlyDominates(cast<Instruction>(StartV)->getParent(),\n                                 L->getHeader()));\n\n  // Expand code for the step value. Do this before creating the PHI so that PHI\n  // reuse code doesn't see an incomplete PHI.\n  const SCEV *Step = Normalized->getStepRecurrence(SE);\n  Type *ExpandTy = Normalized->getType();\n  // If the stride is negative, insert a sub instead of an add for the increment\n  // (unless it's a constant, because subtracts of constants are canonicalized\n  // to adds).\n  bool useSubtract = !ExpandTy->isPointerTy() && Step->isNonConstantNegative();\n  if (useSubtract)\n    Step = SE.getNegativeSCEV(Step);\n  // Expand the step somewhere that dominates the loop header.\n  Value *StepV = expand(Step, L->getHeader()->getFirstInsertionPt());\n\n  // The no-wrap behavior proved by IsIncrement(NUW|NSW) is only applicable if\n  // we actually do emit an addition.  It does not apply if we emit a\n  // subtraction.\n  bool IncrementIsNUW = !useSubtract && IsIncrementNUW(SE, Normalized);\n  bool IncrementIsNSW = !useSubtract && IsIncrementNSW(SE, Normalized);\n\n  // Create the PHI.\n  BasicBlock *Header = L->getHeader();\n  Builder.SetInsertPoint(Header, Header->begin());\n  PHINode *PN =\n      Builder.CreatePHI(ExpandTy, pred_size(Header), Twine(IVName) + \".iv\");\n\n  // Create the step instructions and populate the PHI.\n  for (BasicBlock *Pred : predecessors(Header)) {\n    // Add a start value.\n    if (!L->contains(Pred)) {\n      PN->addIncoming(StartV, Pred);\n      continue;\n    }\n\n    // Create a step value and add it to the PHI.\n    // If IVIncInsertLoop is non-null and equal to the addrec's loop, insert the\n    // instructions at IVIncInsertPos.\n    Instruction *InsertPos = L == IVIncInsertLoop ?\n      IVIncInsertPos : Pred->getTerminator();\n    Builder.SetInsertPoint(InsertPos);\n    Value *IncV = expandIVInc(PN, StepV, L, useSubtract);\n\n    if (isa<OverflowingBinaryOperator>(IncV)) {\n      if (IncrementIsNUW)\n        cast<BinaryOperator>(IncV)->setHasNoUnsignedWrap();\n      if (IncrementIsNSW)\n        cast<BinaryOperator>(IncV)->setHasNoSignedWrap();\n    }\n    PN->addIncoming(IncV, Pred);\n  }\n\n  // After expanding subexpressions, restore the PostIncLoops set so the caller\n  // can ensure that IVIncrement dominates the current uses.\n  PostIncLoops = SavedPostIncLoops;\n\n  // Remember this PHI, even in post-inc mode. LSR SCEV-based salvaging is most\n  // effective when we are able to use an IV inserted here, so record it.\n  InsertedValues.insert(PN);\n  InsertedIVs.push_back(PN);\n  return PN;\n}\n\nValue *SCEVExpander::expandAddRecExprLiterally(const SCEVAddRecExpr *S) {\n  const Loop *L = S->getLoop();\n\n  // Determine a normalized form of this expression, which is the expression\n  // before any post-inc adjustment is made.\n  const SCEVAddRecExpr *Normalized = S;\n  if (PostIncLoops.count(L)) {\n    PostIncLoopSet Loops;\n    Loops.insert(L);\n    Normalized = cast<SCEVAddRecExpr>(\n        normalizeForPostIncUse(S, Loops, SE, /*CheckInvertible=*/false));\n  }\n\n  [[maybe_unused]] const SCEV *Start = Normalized->getStart();\n  const SCEV *Step = Normalized->getStepRecurrence(SE);\n  assert(SE.properlyDominates(Start, L->getHeader()) &&\n         \"Start does not properly dominate loop header\");\n  assert(SE.dominates(Step, L->getHeader()) && \"Step not dominate loop header\");\n\n  // In some cases, we decide to reuse an existing phi node but need to truncate\n  // it and/or invert the step.\n  Type *TruncTy = nullptr;\n  bool InvertStep = false;\n  PHINode *PN = getAddRecExprPHILiterally(Normalized, L, TruncTy, InvertStep);\n\n  // Accommodate post-inc mode, if necessary.\n  Value *Result;\n  if (!PostIncLoops.count(L))\n    Result = PN;\n  else {\n    // In PostInc mode, use the post-incremented value.\n    BasicBlock *LatchBlock = L->getLoopLatch();\n    assert(LatchBlock && \"PostInc mode requires a unique loop latch!\");\n    Result = PN->getIncomingValueForBlock(LatchBlock);\n\n    // We might be introducing a new use of the post-inc IV that is not poison\n    // safe, in which case we should drop poison generating flags. Only keep\n    // those flags for which SCEV has proven that they always hold.\n    if (isa<OverflowingBinaryOperator>(Result)) {\n      auto *I = cast<Instruction>(Result);\n      if (!S->hasNoUnsignedWrap())\n        I->setHasNoUnsignedWrap(false);\n      if (!S->hasNoSignedWrap())\n        I->setHasNoSignedWrap(false);\n    }\n\n    // For an expansion to use the postinc form, the client must call\n    // expandCodeFor with an InsertPoint that is either outside the PostIncLoop\n    // or dominated by IVIncInsertPos.\n    if (isa<Instruction>(Result) &&\n        !SE.DT.dominates(cast<Instruction>(Result),\n                         &*Builder.GetInsertPoint())) {\n      // The induction variable's postinc expansion does not dominate this use.\n      // IVUsers tries to prevent this case, so it is rare. However, it can\n      // happen when an IVUser outside the loop is not dominated by the latch\n      // block. Adjusting IVIncInsertPos before expansion begins cannot handle\n      // all cases. Consider a phi outside whose operand is replaced during\n      // expansion with the value of the postinc user. Without fundamentally\n      // changing the way postinc users are tracked, the only remedy is\n      // inserting an extra IV increment. StepV might fold into PostLoopOffset,\n      // but hopefully expandCodeFor handles that.\n      bool useSubtract =\n          !S->getType()->isPointerTy() && Step->isNonConstantNegative();\n      if (useSubtract)\n        Step = SE.getNegativeSCEV(Step);\n      Value *StepV;\n      {\n        // Expand the step somewhere that dominates the loop header.\n        SCEVInsertPointGuard Guard(Builder, this);\n        StepV = expand(Step, L->getHeader()->getFirstInsertionPt());\n      }\n      Result = expandIVInc(PN, StepV, L, useSubtract);\n    }\n  }\n\n  // We have decided to reuse an induction variable of a dominating loop. Apply\n  // truncation and/or inversion of the step.\n  if (TruncTy) {\n    // Truncate the result.\n    if (TruncTy != Result->getType())\n      Result = Builder.CreateTrunc(Result, TruncTy);\n\n    // Invert the result.\n    if (InvertStep)\n      Result = Builder.CreateSub(expand(Normalized->getStart()), Result);\n  }\n\n  return Result;\n}\n\nValue *SCEVExpander::visitAddRecExpr(const SCEVAddRecExpr *S) {\n  // In canonical mode we compute the addrec as an expression of a canonical IV\n  // using evaluateAtIteration and expand the resulting SCEV expression. This\n  // way we avoid introducing new IVs to carry on the computation of the addrec\n  // throughout the loop.\n  //\n  // For nested addrecs evaluateAtIteration might need a canonical IV of a\n  // type wider than the addrec itself. Emitting a canonical IV of the\n  // proper type might produce non-legal types, for example expanding an i64\n  // {0,+,2,+,1} addrec would need an i65 canonical IV. To avoid this just fall\n  // back to non-canonical mode for nested addrecs.\n  if (!CanonicalMode || (S->getNumOperands() > 2))\n    return expandAddRecExprLiterally(S);\n\n  Type *Ty = SE.getEffectiveSCEVType(S->getType());\n  const Loop *L = S->getLoop();\n\n  // First check for an existing canonical IV in a suitable type.\n  PHINode *CanonicalIV = nullptr;\n  if (PHINode *PN = L->getCanonicalInductionVariable())\n    if (SE.getTypeSizeInBits(PN->getType()) >= SE.getTypeSizeInBits(Ty))\n      CanonicalIV = PN;\n\n  // Rewrite an AddRec in terms of the canonical induction variable, if\n  // its type is more narrow.\n  if (CanonicalIV &&\n      SE.getTypeSizeInBits(CanonicalIV->getType()) > SE.getTypeSizeInBits(Ty) &&\n      !S->getType()->isPointerTy()) {\n    SmallVector<const SCEV *, 4> NewOps(S->getNumOperands());\n    for (unsigned i = 0, e = S->getNumOperands(); i != e; ++i)\n      NewOps[i] = SE.getAnyExtendExpr(S->getOperand(i), CanonicalIV->getType());\n    Value *V = expand(SE.getAddRecExpr(NewOps, S->getLoop(),\n                                       S->getNoWrapFlags(SCEV::FlagNW)));\n    BasicBlock::iterator NewInsertPt =\n        findInsertPointAfter(cast<Instruction>(V), &*Builder.GetInsertPoint());\n    V = expand(SE.getTruncateExpr(SE.getUnknown(V), Ty), NewInsertPt);\n    return V;\n  }\n\n  // {X,+,F} --> X + {0,+,F}\n  if (!S->getStart()->isZero()) {\n    if (isa<PointerType>(S->getType())) {\n      Value *StartV = expand(SE.getPointerBase(S));\n      return expandAddToGEP(SE.removePointerBase(S), StartV);\n    }\n\n    SmallVector<const SCEV *, 4> NewOps(S->operands());\n    NewOps[0] = SE.getConstant(Ty, 0);\n    const SCEV *Rest = SE.getAddRecExpr(NewOps, L,\n                                        S->getNoWrapFlags(SCEV::FlagNW));\n\n    // Just do a normal add. Pre-expand the operands to suppress folding.\n    //\n    // The LHS and RHS values are factored out of the expand call to make the\n    // output independent of the argument evaluation order.\n    const SCEV *AddExprLHS = SE.getUnknown(expand(S->getStart()));\n    const SCEV *AddExprRHS = SE.getUnknown(expand(Rest));\n    return expand(SE.getAddExpr(AddExprLHS, AddExprRHS));\n  }\n\n  // If we don't yet have a canonical IV, create one.\n  if (!CanonicalIV) {\n    // Create and insert the PHI node for the induction variable in the\n    // specified loop.\n    BasicBlock *Header = L->getHeader();\n    pred_iterator HPB = pred_begin(Header), HPE = pred_end(Header);\n    CanonicalIV = PHINode::Create(Ty, std::distance(HPB, HPE), \"indvar\");\n    CanonicalIV->insertBefore(Header->begin());\n    rememberInstruction(CanonicalIV);\n\n    SmallSet<BasicBlock *, 4> PredSeen;\n    Constant *One = ConstantInt::get(Ty, 1);\n    for (pred_iterator HPI = HPB; HPI != HPE; ++HPI) {\n      BasicBlock *HP = *HPI;\n      if (!PredSeen.insert(HP).second) {\n        // There must be an incoming value for each predecessor, even the\n        // duplicates!\n        CanonicalIV->addIncoming(CanonicalIV->getIncomingValueForBlock(HP), HP);\n        continue;\n      }\n\n      if (L->contains(HP)) {\n        // Insert a unit add instruction right before the terminator\n        // corresponding to the back-edge.\n        Instruction *Add = BinaryOperator::CreateAdd(CanonicalIV, One,\n                                                     \"indvar.next\",\n                                                     HP->getTerminator());\n        Add->setDebugLoc(HP->getTerminator()->getDebugLoc());\n        rememberInstruction(Add);\n        CanonicalIV->addIncoming(Add, HP);\n      } else {\n        CanonicalIV->addIncoming(Constant::getNullValue(Ty), HP);\n      }\n    }\n  }\n\n  // {0,+,1} --> Insert a canonical induction variable into the loop!\n  if (S->isAffine() && S->getOperand(1)->isOne()) {\n    assert(Ty == SE.getEffectiveSCEVType(CanonicalIV->getType()) &&\n           \"IVs with types different from the canonical IV should \"\n           \"already have been handled!\");\n    return CanonicalIV;\n  }\n\n  // {0,+,F} --> {0,+,1} * F\n\n  // If this is a simple linear addrec, emit it now as a special case.\n  if (S->isAffine())    // {0,+,F} --> i*F\n    return\n      expand(SE.getTruncateOrNoop(\n        SE.getMulExpr(SE.getUnknown(CanonicalIV),\n                      SE.getNoopOrAnyExtend(S->getOperand(1),\n                                            CanonicalIV->getType())),\n        Ty));\n\n  // If this is a chain of recurrences, turn it into a closed form, using the\n  // folders, then expandCodeFor the closed form.  This allows the folders to\n  // simplify the expression without having to build a bunch of special code\n  // into this folder.\n  const SCEV *IH = SE.getUnknown(CanonicalIV);   // Get I as a \"symbolic\" SCEV.\n\n  // Promote S up to the canonical IV type, if the cast is foldable.\n  const SCEV *NewS = S;\n  const SCEV *Ext = SE.getNoopOrAnyExtend(S, CanonicalIV->getType());\n  if (isa<SCEVAddRecExpr>(Ext))\n    NewS = Ext;\n\n  const SCEV *V = cast<SCEVAddRecExpr>(NewS)->evaluateAtIteration(IH, SE);\n\n  // Truncate the result down to the original type, if needed.\n  const SCEV *T = SE.getTruncateOrNoop(V, Ty);\n  return expand(T);\n}\n\nValue *SCEVExpander::visitPtrToIntExpr(const SCEVPtrToIntExpr *S) {\n  Value *V = expand(S->getOperand());\n  return ReuseOrCreateCast(V, S->getType(), CastInst::PtrToInt,\n                           GetOptimalInsertionPointForCastOf(V));\n}\n\nValue *SCEVExpander::visitTruncateExpr(const SCEVTruncateExpr *S) {\n  Value *V = expand(S->getOperand());\n  return Builder.CreateTrunc(V, S->getType());\n}\n\nValue *SCEVExpander::visitZeroExtendExpr(const SCEVZeroExtendExpr *S) {\n  Value *V = expand(S->getOperand());\n  return Builder.CreateZExt(V, S->getType(), \"\",\n                            SE.isKnownNonNegative(S->getOperand()));\n}\n\nValue *SCEVExpander::visitSignExtendExpr(const SCEVSignExtendExpr *S) {\n  Value *V = expand(S->getOperand());\n  return Builder.CreateSExt(V, S->getType());\n}\n\nValue *SCEVExpander::expandMinMaxExpr(const SCEVNAryExpr *S,\n                                      Intrinsic::ID IntrinID, Twine Name,\n                                      bool IsSequential) {\n  Value *LHS = expand(S->getOperand(S->getNumOperands() - 1));\n  Type *Ty = LHS->getType();\n  if (IsSequential)\n    LHS = Builder.CreateFreeze(LHS);\n  for (int i = S->getNumOperands() - 2; i >= 0; --i) {\n    Value *RHS = expand(S->getOperand(i));\n    if (IsSequential && i != 0)\n      RHS = Builder.CreateFreeze(RHS);\n    Value *Sel;\n    if (Ty->isIntegerTy())\n      Sel = Builder.CreateIntrinsic(IntrinID, {Ty}, {LHS, RHS},\n                                    /*FMFSource=*/nullptr, Name);\n    else {\n      Value *ICmp =\n          Builder.CreateICmp(MinMaxIntrinsic::getPredicate(IntrinID), LHS, RHS);\n      Sel = Builder.CreateSelect(ICmp, LHS, RHS, Name);\n    }\n    LHS = Sel;\n  }\n  return LHS;\n}\n\nValue *SCEVExpander::visitSMaxExpr(const SCEVSMaxExpr *S) {\n  return expandMinMaxExpr(S, Intrinsic::smax, \"smax\");\n}\n\nValue *SCEVExpander::visitUMaxExpr(const SCEVUMaxExpr *S) {\n  return expandMinMaxExpr(S, Intrinsic::umax, \"umax\");\n}\n\nValue *SCEVExpander::visitSMinExpr(const SCEVSMinExpr *S) {\n  return expandMinMaxExpr(S, Intrinsic::smin, \"smin\");\n}\n\nValue *SCEVExpander::visitUMinExpr(const SCEVUMinExpr *S) {\n  return expandMinMaxExpr(S, Intrinsic::umin, \"umin\");\n}\n\nValue *SCEVExpander::visitSequentialUMinExpr(const SCEVSequentialUMinExpr *S) {\n  return expandMinMaxExpr(S, Intrinsic::umin, \"umin\", /*IsSequential*/true);\n}\n\nValue *SCEVExpander::visitVScale(const SCEVVScale *S) {\n  return Builder.CreateVScale(ConstantInt::get(S->getType(), 1));\n}\n\nValue *SCEVExpander::expandCodeFor(const SCEV *SH, Type *Ty,\n                                   BasicBlock::iterator IP) {\n  setInsertPoint(IP);\n  Value *V = expandCodeFor(SH, Ty);\n  return V;\n}\n\nValue *SCEVExpander::expandCodeFor(const SCEV *SH, Type *Ty) {\n  // Expand the code for this SCEV.\n  Value *V = expand(SH);\n\n  if (Ty) {\n    assert(SE.getTypeSizeInBits(Ty) == SE.getTypeSizeInBits(SH->getType()) &&\n           \"non-trivial casts should be done with the SCEVs directly!\");\n    V = InsertNoopCastOfTo(V, Ty);\n  }\n"}], "code": "bool SCEVExpander::isExpandedAddRecExprPHI(PHINode *PN, Instruction *IncV,\n                                           const Loop *L) {\n  for(Instruction *IVOper = IncV;\n      (IVOper = getIVIncOperand(IVOper, L->getLoopPreheader()->getTerminator(),\n                                /*allowScale=*/false));) {\n    if (IVOper == PN)\n      return true;\n  }\n  return false;\n}\n"}, "1E5C45F37A76125F": {"calls": [{"id": "47185C2220F45BD8", "name": "addReplicateRegions", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp", "start": {"line": 332, "col": 1}, "end": {"line": 358, "col": 1}, "code": "  SmallVector<VPReplicateRecipe *> WorkList;\n  for (VPBasicBlock *VPBB : VPBlockUtils::blocksOnly<VPBasicBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    for (VPRecipeBase &R : *VPBB)\n      if (auto *RepR = dyn_cast<VPReplicateRecipe>(&R)) {\n        if (RepR->isPredicated())\n          WorkList.push_back(RepR);\n      }\n  }\n\n  unsigned BBNum = 0;\n  for (VPReplicateRecipe *RepR : WorkList) {\n    VPBasicBlock *CurrentBlock = RepR->getParent();\n    VPBasicBlock *SplitBlock = CurrentBlock->splitAt(RepR->getIterator());\n\n    BasicBlock *OrigBB = RepR->getUnderlyingInstr()->getParent();\n    SplitBlock->setName(\n        OrigBB->hasName() ? OrigBB->getName() + \".\" + Twine(BBNum++) : \"\");\n    // Record predicated instructions for above packing optimizations.\n    VPBlockBase *Region = createReplicateRegion(RepR, Plan);\n    Region->setParent(CurrentBlock->getParent());\n    VPBlockUtils::disconnectBlocks(CurrentBlock, SplitBlock);\n    VPBlockUtils::connectBlocks(CurrentBlock, Region);\n    VPBlockUtils::connectBlocks(Region, SplitBlock);\n  }\n}\n\nvoid VPlanTransforms::createAndOptimizeReplicateRegions(VPlan &Plan) {\n  // Convert masked VPReplicateRecipes to if-then region blocks.\n  addReplicateRegions(Plan);\n\n  bool ShouldSimplify = true;\n  while (ShouldSimplify) {\n    ShouldSimplify = sinkScalarOperands(Plan);\n    ShouldSimplify |= mergeReplicateRegionsIntoSuccessors(Plan);\n    ShouldSimplify |= VPlanTransforms::mergeBlocksIntoPredecessors(Plan);\n  }\n}\nbool VPlanTransforms::mergeBlocksIntoPredecessors(VPlan &Plan) {\n  SmallVector<VPBasicBlock *> WorkList;\n  for (VPBasicBlock *VPBB : VPBlockUtils::blocksOnly<VPBasicBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    auto *PredVPBB =\n        dyn_cast_or_null<VPBasicBlock>(VPBB->getSinglePredecessor());\n    if (PredVPBB && PredVPBB->getNumSuccessors() == 1)\n      WorkList.push_back(VPBB);\n  }\n\n  for (VPBasicBlock *VPBB : WorkList) {\n    VPBasicBlock *PredVPBB = cast<VPBasicBlock>(VPBB->getSinglePredecessor());\n    for (VPRecipeBase &R : make_early_inc_range(*VPBB))\n      R.moveBefore(*PredVPBB, PredVPBB->end());\n    VPBlockUtils::disconnectBlocks(PredVPBB, VPBB);\n    auto *ParentRegion = cast_or_null<VPRegionBlock>(VPBB->getParent());\n    if (ParentRegion && ParentRegion->getExiting() == VPBB)\n      ParentRegion->setExiting(PredVPBB);\n    for (auto *Succ : to_vector(VPBB->successors())) {\n      VPBlockUtils::disconnectBlocks(VPBB, Succ);\n      VPBlockUtils::connectBlocks(PredVPBB, Succ);\n    }\n    delete VPBB;\n  }\n  return !WorkList.empty();\n}\n\nvoid VPlanTransforms::removeRedundantInductionCasts(VPlan &Plan) {\n  for (auto &Phi : Plan.getVectorLoopRegion()->getEntryBasicBlock()->phis()) {\n    auto *IV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n    if (!IV || IV->getTruncInst())\n      continue;\n\n    // A sequence of IR Casts has potentially been recorded for IV, which\n    // *must be bypassed* when the IV is vectorized, because the vectorized IV\n    // will produce the desired casted value. This sequence forms a def-use\n    // chain and is provided in reverse order, ending with the cast that uses\n    // the IV phi. Search for the recipe of the last cast in the chain and\n    // replace it with the original IV. Note that only the final cast is\n    // expected to have users outside the cast-chain and the dead casts left\n    // over will be cleaned up later.\n    auto &Casts = IV->getInductionDescriptor().getCastInsts();\n    VPValue *FindMyCast = IV;\n    for (Instruction *IRCast : reverse(Casts)) {\n      VPSingleDefRecipe *FoundUserCast = nullptr;\n      for (auto *U : FindMyCast->users()) {\n        auto *UserCast = dyn_cast<VPSingleDefRecipe>(U);\n        if (UserCast && UserCast->getUnderlyingValue() == IRCast) {\n          FoundUserCast = UserCast;\n          break;\n        }\n      }\n      FindMyCast = FoundUserCast;\n    }\n    FindMyCast->replaceAllUsesWith(IV);\n  }\n}\n\nvoid VPlanTransforms::removeRedundantCanonicalIVs(VPlan &Plan) {\n  VPCanonicalIVPHIRecipe *CanonicalIV = Plan.getCanonicalIV();\n  VPWidenCanonicalIVRecipe *WidenNewIV = nullptr;\n  for (VPUser *U : CanonicalIV->users()) {\n    WidenNewIV = dyn_cast<VPWidenCanonicalIVRecipe>(U);\n    if (WidenNewIV)\n      break;\n  }\n\n  if (!WidenNewIV)\n    return;\n\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  for (VPRecipeBase &Phi : HeaderVPBB->phis()) {\n    auto *WidenOriginalIV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n\n    if (!WidenOriginalIV || !WidenOriginalIV->isCanonical() ||\n        WidenOriginalIV->getScalarType() != WidenNewIV->getScalarType())\n      continue;\n\n    // Replace WidenNewIV with WidenOriginalIV if WidenOriginalIV provides\n    // everything WidenNewIV's users need. That is, WidenOriginalIV will\n    // generate a vector phi or all users of WidenNewIV demand the first lane\n    // only.\n    if (any_of(WidenOriginalIV->users(),\n               [WidenOriginalIV](VPUser *U) {\n                 return !U->usesScalars(WidenOriginalIV);\n               }) ||\n        vputils::onlyFirstLaneUsed(WidenNewIV)) {\n      WidenNewIV->replaceAllUsesWith(WidenOriginalIV);\n      WidenNewIV->eraseFromParent();\n      return;\n    }\n  }\n}\n\nvoid VPlanTransforms::removeDeadRecipes(VPlan &Plan) {\n  ReversePostOrderTraversal<VPBlockDeepTraversalWrapper<VPBlockBase *>> RPOT(\n      Plan.getEntry());\n\n  for (VPBasicBlock *VPBB : reverse(VPBlockUtils::blocksOnly<VPBasicBlock>(RPOT))) {\n    // The recipes in the block are processed in reverse order, to catch chains\n    // of dead recipes.\n    for (VPRecipeBase &R : make_early_inc_range(reverse(*VPBB))) {\n      // A user keeps R alive:\n      if (any_of(R.definedValues(),\n                 [](VPValue *V) { return V->getNumUsers(); }))\n        continue;\n\n      // Having side effects keeps R alive, but do remove conditional assume\n      // instructions as their conditions may be flattened.\n      auto *RepR = dyn_cast<VPReplicateRecipe>(&R);\n      bool IsConditionalAssume =\n          RepR && RepR->isPredicated() &&\n          match(RepR->getUnderlyingInstr(), m_Intrinsic<Intrinsic::assume>());\n      if (R.mayHaveSideEffects() && !IsConditionalAssume)\n        continue;\n\n      R.eraseFromParent();\n    }\n  }\n}\n\nstatic VPValue *createScalarIVSteps(VPlan &Plan, const InductionDescriptor &ID,\n                                    ScalarEvolution &SE, Instruction *TruncI,\n                                    VPValue *StartV, VPValue *Step,\n                                    VPBasicBlock::iterator IP) {\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  VPCanonicalIVPHIRecipe *CanonicalIV = Plan.getCanonicalIV();\n  VPSingleDefRecipe *BaseIV = CanonicalIV;\n  if (!CanonicalIV->isCanonical(ID.getKind(), StartV, Step)) {\n    BaseIV = new VPDerivedIVRecipe(ID, StartV, CanonicalIV, Step);\n    HeaderVPBB->insert(BaseIV, IP);\n  }\n\n  // Truncate base induction if needed.\n  VPTypeAnalysis TypeInfo(SE.getContext());\n  Type *ResultTy = TypeInfo.inferScalarType(BaseIV);\n  if (TruncI) {\n    Type *TruncTy = TruncI->getType();\n    assert(ResultTy->getScalarSizeInBits() > TruncTy->getScalarSizeInBits() &&\n           \"Not truncating.\");\n    assert(ResultTy->isIntegerTy() && \"Truncation requires an integer type\");\n    BaseIV = new VPScalarCastRecipe(Instruction::Trunc, BaseIV, TruncTy);\n    HeaderVPBB->insert(BaseIV, IP);\n    ResultTy = TruncTy;\n  }\n\n  // Truncate step if needed.\n  Type *StepTy = TypeInfo.inferScalarType(Step);\n  if (ResultTy != StepTy) {\n    assert(StepTy->getScalarSizeInBits() > ResultTy->getScalarSizeInBits() &&\n           \"Not truncating.\");\n    assert(StepTy->isIntegerTy() && \"Truncation requires an integer type\");\n    Step = new VPScalarCastRecipe(Instruction::Trunc, Step, ResultTy);\n    auto *VecPreheader =\n        cast<VPBasicBlock>(HeaderVPBB->getSingleHierarchicalPredecessor());\n    VecPreheader->appendRecipe(Step->getDefiningRecipe());\n  }\n\n  VPScalarIVStepsRecipe *Steps = new VPScalarIVStepsRecipe(ID, BaseIV, Step);\n  HeaderVPBB->insert(Steps, IP);\n  return Steps;\n}\n\nvoid VPlanTransforms::optimizeInductions(VPlan &Plan, ScalarEvolution &SE) {\n  SmallVector<VPRecipeBase *> ToRemove;\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  bool HasOnlyVectorVFs = !Plan.hasVF(ElementCount::getFixed(1));\n  VPBasicBlock::iterator InsertPt = HeaderVPBB->getFirstNonPhi();\n  for (VPRecipeBase &Phi : HeaderVPBB->phis()) {\n    auto *WideIV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n    if (!WideIV)\n      continue;\n    if (HasOnlyVectorVFs && none_of(WideIV->users(), [WideIV](VPUser *U) {\n          return U->usesScalars(WideIV);\n        }))\n      continue;\n\n    const InductionDescriptor &ID = WideIV->getInductionDescriptor();\n    VPValue *Steps = createScalarIVSteps(Plan, ID, SE, WideIV->getTruncInst(),\n                                         WideIV->getStartValue(),\n                                         WideIV->getStepValue(), InsertPt);\n\n    // Update scalar users of IV to use Step instead.\n    if (!HasOnlyVectorVFs)\n      WideIV->replaceAllUsesWith(Steps);\n    else\n      WideIV->replaceUsesWithIf(Steps, [WideIV](VPUser &U, unsigned) {\n        return U.usesScalars(WideIV);\n      });\n  }\n}\n\nvoid VPlanTransforms::removeRedundantExpandSCEVRecipes(VPlan &Plan) {\n  DenseMap<const SCEV *, VPValue *> SCEV2VPV;\n\n  for (VPRecipeBase &R :\n       make_early_inc_range(*Plan.getEntry()->getEntryBasicBlock())) {\n    auto *ExpR = dyn_cast<VPExpandSCEVRecipe>(&R);\n    if (!ExpR)\n      continue;\n\n    auto I = SCEV2VPV.insert({ExpR->getSCEV(), ExpR});\n    if (I.second)\n      continue;\n    ExpR->replaceAllUsesWith(I.first->second);\n    ExpR->eraseFromParent();\n  }\n}\n\nstatic bool canSimplifyBranchOnCond(VPInstruction *Term) {\n  VPInstruction *Not = dyn_cast<VPInstruction>(Term->getOperand(0));\n  if (!Not || Not->getOpcode() != VPInstruction::Not)\n    return false;\n\n  VPInstruction *ALM = dyn_cast<VPInstruction>(Not->getOperand(0));\n  return ALM && ALM->getOpcode() == VPInstruction::ActiveLaneMask;\n}\n\nvoid VPlanTransforms::optimizeForVFAndUF(VPlan &Plan, ElementCount BestVF,\n                                         unsigned BestUF,\n                                         PredicatedScalarEvolution &PSE) {\n  assert(Plan.hasVF(BestVF) && \"BestVF is not available in Plan\");\n  assert(Plan.hasUF(BestUF) && \"BestUF is not available in Plan\");\n  VPBasicBlock *ExitingVPBB =\n      Plan.getVectorLoopRegion()->getExitingBasicBlock();\n  auto *Term = dyn_cast<VPInstruction>(&ExitingVPBB->back());\n  // Try to simplify the branch condition if TC <= VF * UF when preparing to\n  // execute the plan for the main vector loop. We only do this if the\n  // terminator is:\n  //  1. BranchOnCount, or\n  //  2. BranchOnCond where the input is Not(ActiveLaneMask).\n  if (!Term || (Term->getOpcode() != VPInstruction::BranchOnCount &&\n                (Term->getOpcode() != VPInstruction::BranchOnCond ||\n                 !canSimplifyBranchOnCond(Term))))\n    return;\n\n  Type *IdxTy =\n      Plan.getCanonicalIV()->getStartValue()->getLiveInIRValue()->getType();\n  const SCEV *TripCount = createTripCountSCEV(IdxTy, PSE);\n  ScalarEvolution &SE = *PSE.getSE();\n  const SCEV *C =\n      SE.getConstant(TripCount->getType(), BestVF.getKnownMinValue() * BestUF);\n  if (TripCount->isZero() ||\n      !SE.isKnownPredicate(CmpInst::ICMP_ULE, TripCount, C))\n    return;\n\n  LLVMContext &Ctx = SE.getContext();\n  auto *BOC = new VPInstruction(\n      VPInstruction::BranchOnCond,\n      {Plan.getVPValueOrAddLiveIn(ConstantInt::getTrue(Ctx))});\n  Term->eraseFromParent();\n  ExitingVPBB->appendRecipe(BOC);\n  Plan.setVF(BestVF);\n  Plan.setUF(BestUF);\n  // TODO: Further simplifications are possible\n  //      1. Replace inductions with constants.\n  //      2. Replace vector loop region with VPBasicBlock.\n}\n\n#ifndef NDEBUG\nstatic VPRegionBlock *GetReplicateRegion(VPRecipeBase *R) {\n  auto *Region = dyn_cast_or_null<VPRegionBlock>(R->getParent()->getParent());\n  if (Region && Region->isReplicator()) {\n    assert(Region->getNumSuccessors() == 1 &&\n           Region->getNumPredecessors() == 1 && \"Expected SESE region!\");\n    assert(R->getParent()->size() == 1 &&\n           \"A recipe in an original replicator region must be the only \"\n           \"recipe in its block\");\n    return Region;\n  }\n  return nullptr;\n}\n#endif\n\nstatic bool properlyDominates(const VPRecipeBase *A, const VPRecipeBase *B,\n                              VPDominatorTree &VPDT) {\n  if (A == B)\n    return false;\n\n  auto LocalComesBefore = [](const VPRecipeBase *A, const VPRecipeBase *B) {\n    for (auto &R : *A->getParent()) {\n      if (&R == A)\n        return true;\n      if (&R == B)\n        return false;\n    }\n    llvm_unreachable(\"recipe not found\");\n  };\n  const VPBlockBase *ParentA = A->getParent();\n  const VPBlockBase *ParentB = B->getParent();\n  if (ParentA == ParentB)\n    return LocalComesBefore(A, B);\n\n  assert(!GetReplicateRegion(const_cast<VPRecipeBase *>(A)) &&\n         \"No replicate regions expected at this point\");\n  assert(!GetReplicateRegion(const_cast<VPRecipeBase *>(B)) &&\n         \"No replicate regions expected at this point\");\n  return VPDT.properlyDominates(ParentA, ParentB);\n}\n\n/// Sink users of \\p FOR after the recipe defining the previous value \\p\n/// Previous of the recurrence. \\returns true if all users of \\p FOR could be\n/// re-arranged as needed or false if it is not possible.\nstatic bool\nsinkRecurrenceUsersAfterPrevious(VPFirstOrderRecurrencePHIRecipe *FOR,\n                                 VPRecipeBase *Previous,\n                                 VPDominatorTree &VPDT) {\n  // Collect recipes that need sinking.\n  SmallVector<VPRecipeBase *> WorkList;\n  SmallPtrSet<VPRecipeBase *, 8> Seen;\n  Seen.insert(Previous);\n  auto TryToPushSinkCandidate = [&](VPRecipeBase *SinkCandidate) {\n    // The previous value must not depend on the users of the recurrence phi. In\n    // that case, FOR is not a fixed order recurrence.\n    if (SinkCandidate == Previous)\n      return false;\n\n    if (isa<VPHeaderPHIRecipe>(SinkCandidate) ||\n        !Seen.insert(SinkCandidate).second ||\n        properlyDominates(Previous, SinkCandidate, VPDT))\n      return true;\n"}, {"id": "905293996326E17A", "name": "sinkScalarOperands", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp", "start": {"line": 101, "col": 1}, "end": {"line": 178, "col": 1}, "code": "  auto Iter = vp_depth_first_deep(Plan.getEntry());\n  bool Changed = false;\n  // First, collect the operands of all recipes in replicate blocks as seeds for\n  // sinking.\n  SetVector<std::pair<VPBasicBlock *, VPSingleDefRecipe *>> WorkList;\n  for (VPRegionBlock *VPR : VPBlockUtils::blocksOnly<VPRegionBlock>(Iter)) {\n    VPBasicBlock *EntryVPBB = VPR->getEntryBasicBlock();\n    if (!VPR->isReplicator() || EntryVPBB->getSuccessors().size() != 2)\n      continue;\n    VPBasicBlock *VPBB = dyn_cast<VPBasicBlock>(EntryVPBB->getSuccessors()[0]);\n    if (!VPBB || VPBB->getSingleSuccessor() != VPR->getExitingBasicBlock())\n      continue;\n    for (auto &Recipe : *VPBB) {\n      for (VPValue *Op : Recipe.operands())\n        if (auto *Def =\n                dyn_cast_or_null<VPSingleDefRecipe>(Op->getDefiningRecipe()))\n          WorkList.insert(std::make_pair(VPBB, Def));\n    }\n  }\n\n  bool ScalarVFOnly = Plan.hasScalarVFOnly();\n  // Try to sink each replicate or scalar IV steps recipe in the worklist.\n  for (unsigned I = 0; I != WorkList.size(); ++I) {\n    VPBasicBlock *SinkTo;\n    VPSingleDefRecipe *SinkCandidate;\n    std::tie(SinkTo, SinkCandidate) = WorkList[I];\n    if (SinkCandidate->getParent() == SinkTo ||\n        SinkCandidate->mayHaveSideEffects() ||\n        SinkCandidate->mayReadOrWriteMemory())\n      continue;\n    if (auto *RepR = dyn_cast<VPReplicateRecipe>(SinkCandidate)) {\n      if (!ScalarVFOnly && RepR->isUniform())\n        continue;\n    } else if (!isa<VPScalarIVStepsRecipe>(SinkCandidate))\n      continue;\n\n    bool NeedsDuplicating = false;\n    // All recipe users of the sink candidate must be in the same block SinkTo\n    // or all users outside of SinkTo must be uniform-after-vectorization (\n    // i.e., only first lane is used) . In the latter case, we need to duplicate\n    // SinkCandidate.\n    auto CanSinkWithUser = [SinkTo, &NeedsDuplicating,\n                            SinkCandidate](VPUser *U) {\n      auto *UI = dyn_cast<VPRecipeBase>(U);\n      if (!UI)\n        return false;\n      if (UI->getParent() == SinkTo)\n        return true;\n      NeedsDuplicating = UI->onlyFirstLaneUsed(SinkCandidate);\n      // We only know how to duplicate VPRecipeRecipes for now.\n      return NeedsDuplicating && isa<VPReplicateRecipe>(SinkCandidate);\n    };\n    if (!all_of(SinkCandidate->users(), CanSinkWithUser))\n      continue;\n\n    if (NeedsDuplicating) {\n      if (ScalarVFOnly)\n        continue;\n      Instruction *I = cast<Instruction>(\n          cast<VPReplicateRecipe>(SinkCandidate)->getUnderlyingValue());\n      auto *Clone = new VPReplicateRecipe(I, SinkCandidate->operands(), true);\n      // TODO: add \".cloned\" suffix to name of Clone's VPValue.\n\n      Clone->insertBefore(SinkCandidate);\n      SinkCandidate->replaceUsesWithIf(Clone, [SinkTo](VPUser &U, unsigned) {\n        return cast<VPRecipeBase>(&U)->getParent() != SinkTo;\n      });\n    }\n    SinkCandidate->moveBefore(*SinkTo, SinkTo->getFirstNonPhi());\n    for (VPValue *Op : SinkCandidate->operands())\n      if (auto *Def =\n              dyn_cast_or_null<VPSingleDefRecipe>(Op->getDefiningRecipe()))\n        WorkList.insert(std::make_pair(SinkTo, Def));\n    Changed = true;\n  }\n  return Changed;\n}\n\n/// If \\p R is a region with a VPBranchOnMaskRecipe in the entry block, return\n/// the mask.\nVPValue *getPredicatedMask(VPRegionBlock *R) {\n  auto *EntryBB = dyn_cast<VPBasicBlock>(R->getEntry());\n  if (!EntryBB || EntryBB->size() != 1 ||\n      !isa<VPBranchOnMaskRecipe>(EntryBB->begin()))\n    return nullptr;\n\n  return cast<VPBranchOnMaskRecipe>(&*EntryBB->begin())->getOperand(0);\n}\n\n/// If \\p R is a triangle region, return the 'then' block of the triangle.\nstatic VPBasicBlock *getPredicatedThenBlock(VPRegionBlock *R) {\n  auto *EntryBB = cast<VPBasicBlock>(R->getEntry());\n  if (EntryBB->getNumSuccessors() != 2)\n    return nullptr;\n\n  auto *Succ0 = dyn_cast<VPBasicBlock>(EntryBB->getSuccessors()[0]);\n  auto *Succ1 = dyn_cast<VPBasicBlock>(EntryBB->getSuccessors()[1]);\n  if (!Succ0 || !Succ1)\n    return nullptr;\n\n  if (Succ0->getNumSuccessors() + Succ1->getNumSuccessors() != 1)\n    return nullptr;\n  if (Succ0->getSingleSuccessor() == Succ1)\n    return Succ0;\n  if (Succ1->getSingleSuccessor() == Succ0)\n    return Succ1;\n  return nullptr;\n}\n\n// Merge replicate regions in their successor region, if a replicate region\n// is connected to a successor replicate region with the same predicate by a\n// single, empty VPBasicBlock.\nstatic bool mergeReplicateRegionsIntoSuccessors(VPlan &Plan) {\n  SetVector<VPRegionBlock *> DeletedRegions;\n\n  // Collect replicate regions followed by an empty block, followed by another\n  // replicate region with matching masks to process front. This is to avoid\n  // iterator invalidation issues while merging regions.\n  SmallVector<VPRegionBlock *, 8> WorkList;\n  for (VPRegionBlock *Region1 : VPBlockUtils::blocksOnly<VPRegionBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    if (!Region1->isReplicator())\n      continue;\n    auto *MiddleBasicBlock =\n        dyn_cast_or_null<VPBasicBlock>(Region1->getSingleSuccessor());\n    if (!MiddleBasicBlock || !MiddleBasicBlock->empty())\n      continue;\n\n    auto *Region2 =\n        dyn_cast_or_null<VPRegionBlock>(MiddleBasicBlock->getSingleSuccessor());\n    if (!Region2 || !Region2->isReplicator())\n      continue;\n\n    VPValue *Mask1 = getPredicatedMask(Region1);\n    VPValue *Mask2 = getPredicatedMask(Region2);\n    if (!Mask1 || Mask1 != Mask2)\n      continue;\n\n    assert(Mask1 && Mask2 && \"both region must have conditions\");\n    WorkList.push_back(Region1);\n  }\n\n  // Move recipes from Region1 to its successor region, if both are triangles.\n  for (VPRegionBlock *Region1 : WorkList) {\n    if (DeletedRegions.contains(Region1))\n      continue;\n    auto *MiddleBasicBlock = cast<VPBasicBlock>(Region1->getSingleSuccessor());\n    auto *Region2 = cast<VPRegionBlock>(MiddleBasicBlock->getSingleSuccessor());\n\n    VPBasicBlock *Then1 = getPredicatedThenBlock(Region1);\n    VPBasicBlock *Then2 = getPredicatedThenBlock(Region2);\n    if (!Then1 || !Then2)\n      continue;\n\n    // Note: No fusion-preventing memory dependencies are expected in either\n    // region. Such dependencies should be rejected during earlier dependence\n    // checks, which guarantee accesses can be re-ordered for vectorization.\n    //\n    // Move recipes to the successor region.\n    for (VPRecipeBase &ToMove : make_early_inc_range(reverse(*Then1)))\n      ToMove.moveBefore(*Then2, Then2->getFirstNonPhi());\n\n    auto *Merge1 = cast<VPBasicBlock>(Then1->getSingleSuccessor());\n    auto *Merge2 = cast<VPBasicBlock>(Then2->getSingleSuccessor());\n\n    // Move VPPredInstPHIRecipes from the merge block to the successor region's\n    // merge block. Update all users inside the successor region to use the\n    // original values.\n    for (VPRecipeBase &Phi1ToMove : make_early_inc_range(reverse(*Merge1))) {\n      VPValue *PredInst1 =\n          cast<VPPredInstPHIRecipe>(&Phi1ToMove)->getOperand(0);\n      VPValue *Phi1ToMoveV = Phi1ToMove.getVPSingleValue();\n      Phi1ToMoveV->replaceUsesWithIf(PredInst1, [Then2](VPUser &U, unsigned) {\n        auto *UI = dyn_cast<VPRecipeBase>(&U);\n        return UI && UI->getParent() == Then2;\n      });\n\n      Phi1ToMove.moveBefore(*Merge2, Merge2->begin());\n    }\n"}, {"id": "2F2D1CECAD9D3E4F", "name": "mergeReplicateRegionsIntoSuccessors", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp", "start": {"line": 214, "col": 1}, "end": {"line": 294, "col": 1}, "code": "  SetVector<VPRegionBlock *> DeletedRegions;\n\n  // Collect replicate regions followed by an empty block, followed by another\n  // replicate region with matching masks to process front. This is to avoid\n  // iterator invalidation issues while merging regions.\n  SmallVector<VPRegionBlock *, 8> WorkList;\n  for (VPRegionBlock *Region1 : VPBlockUtils::blocksOnly<VPRegionBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    if (!Region1->isReplicator())\n      continue;\n    auto *MiddleBasicBlock =\n        dyn_cast_or_null<VPBasicBlock>(Region1->getSingleSuccessor());\n    if (!MiddleBasicBlock || !MiddleBasicBlock->empty())\n      continue;\n\n    auto *Region2 =\n        dyn_cast_or_null<VPRegionBlock>(MiddleBasicBlock->getSingleSuccessor());\n    if (!Region2 || !Region2->isReplicator())\n      continue;\n\n    VPValue *Mask1 = getPredicatedMask(Region1);\n    VPValue *Mask2 = getPredicatedMask(Region2);\n    if (!Mask1 || Mask1 != Mask2)\n      continue;\n\n    assert(Mask1 && Mask2 && \"both region must have conditions\");\n    WorkList.push_back(Region1);\n  }\n\n  // Move recipes from Region1 to its successor region, if both are triangles.\n  for (VPRegionBlock *Region1 : WorkList) {\n    if (DeletedRegions.contains(Region1))\n      continue;\n    auto *MiddleBasicBlock = cast<VPBasicBlock>(Region1->getSingleSuccessor());\n    auto *Region2 = cast<VPRegionBlock>(MiddleBasicBlock->getSingleSuccessor());\n\n    VPBasicBlock *Then1 = getPredicatedThenBlock(Region1);\n    VPBasicBlock *Then2 = getPredicatedThenBlock(Region2);\n    if (!Then1 || !Then2)\n      continue;\n\n    // Note: No fusion-preventing memory dependencies are expected in either\n    // region. Such dependencies should be rejected during earlier dependence\n    // checks, which guarantee accesses can be re-ordered for vectorization.\n    //\n    // Move recipes to the successor region.\n    for (VPRecipeBase &ToMove : make_early_inc_range(reverse(*Then1)))\n      ToMove.moveBefore(*Then2, Then2->getFirstNonPhi());\n\n    auto *Merge1 = cast<VPBasicBlock>(Then1->getSingleSuccessor());\n    auto *Merge2 = cast<VPBasicBlock>(Then2->getSingleSuccessor());\n\n    // Move VPPredInstPHIRecipes from the merge block to the successor region's\n    // merge block. Update all users inside the successor region to use the\n    // original values.\n    for (VPRecipeBase &Phi1ToMove : make_early_inc_range(reverse(*Merge1))) {\n      VPValue *PredInst1 =\n          cast<VPPredInstPHIRecipe>(&Phi1ToMove)->getOperand(0);\n      VPValue *Phi1ToMoveV = Phi1ToMove.getVPSingleValue();\n      Phi1ToMoveV->replaceUsesWithIf(PredInst1, [Then2](VPUser &U, unsigned) {\n        auto *UI = dyn_cast<VPRecipeBase>(&U);\n        return UI && UI->getParent() == Then2;\n      });\n\n      Phi1ToMove.moveBefore(*Merge2, Merge2->begin());\n    }\n\n    // Finally, remove the first region.\n    for (VPBlockBase *Pred : make_early_inc_range(Region1->getPredecessors())) {\n      VPBlockUtils::disconnectBlocks(Pred, Region1);\n      VPBlockUtils::connectBlocks(Pred, MiddleBasicBlock);\n    }\n    VPBlockUtils::disconnectBlocks(Region1, MiddleBasicBlock);\n    DeletedRegions.insert(Region1);\n  }\n\n  for (VPRegionBlock *ToDelete : DeletedRegions)\n    delete ToDelete;\n  return !DeletedRegions.empty();\n}\n\nstatic VPRegionBlock *createReplicateRegion(VPReplicateRecipe *PredRecipe,\n                                            VPlan &Plan) {\n  Instruction *Instr = PredRecipe->getUnderlyingInstr();\n  // Build the triangular if-then region.\n  std::string RegionName = (Twine(\"pred.\") + Instr->getOpcodeName()).str();\n  assert(Instr->getParent() && \"Predicated instruction not in any basic block\");\n  auto *BlockInMask = PredRecipe->getMask();\n  auto *BOMRecipe = new VPBranchOnMaskRecipe(BlockInMask);\n  auto *Entry = new VPBasicBlock(Twine(RegionName) + \".entry\", BOMRecipe);\n\n  // Replace predicated replicate recipe with a replicate recipe without a\n  // mask but in the replicate region.\n  auto *RecipeWithoutMask = new VPReplicateRecipe(\n      PredRecipe->getUnderlyingInstr(),\n      make_range(PredRecipe->op_begin(), std::prev(PredRecipe->op_end())),\n      PredRecipe->isUniform());\n  auto *Pred = new VPBasicBlock(Twine(RegionName) + \".if\", RecipeWithoutMask);\n\n  VPPredInstPHIRecipe *PHIRecipe = nullptr;\n  if (PredRecipe->getNumUsers() != 0) {\n    PHIRecipe = new VPPredInstPHIRecipe(RecipeWithoutMask);\n    PredRecipe->replaceAllUsesWith(PHIRecipe);\n    PHIRecipe->setOperand(0, RecipeWithoutMask);\n  }\n  PredRecipe->eraseFromParent();\n  auto *Exiting = new VPBasicBlock(Twine(RegionName) + \".continue\", PHIRecipe);\n  VPRegionBlock *Region = new VPRegionBlock(Entry, Exiting, RegionName, true);\n\n  // Note: first set Entry as region entry and then connect successors starting\n  // from it in order, to propagate the \"parent\" of each VPBasicBlock.\n  VPBlockUtils::insertTwoBlocksAfter(Pred, Exiting, Entry);\n  VPBlockUtils::connectBlocks(Pred, Exiting);\n\n  return Region;\n}\n\nstatic void addReplicateRegions(VPlan &Plan) {\n  SmallVector<VPReplicateRecipe *> WorkList;\n  for (VPBasicBlock *VPBB : VPBlockUtils::blocksOnly<VPBasicBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    for (VPRecipeBase &R : *VPBB)\n      if (auto *RepR = dyn_cast<VPReplicateRecipe>(&R)) {\n        if (RepR->isPredicated())\n          WorkList.push_back(RepR);\n      }\n  }\n\n  unsigned BBNum = 0;\n  for (VPReplicateRecipe *RepR : WorkList) {\n    VPBasicBlock *CurrentBlock = RepR->getParent();\n    VPBasicBlock *SplitBlock = CurrentBlock->splitAt(RepR->getIterator());\n\n    BasicBlock *OrigBB = RepR->getUnderlyingInstr()->getParent();\n    SplitBlock->setName(\n        OrigBB->hasName() ? OrigBB->getName() + \".\" + Twine(BBNum++) : \"\");\n    // Record predicated instructions for above packing optimizations.\n    VPBlockBase *Region = createReplicateRegion(RepR, Plan);\n    Region->setParent(CurrentBlock->getParent());\n    VPBlockUtils::disconnectBlocks(CurrentBlock, SplitBlock);\n    VPBlockUtils::connectBlocks(CurrentBlock, Region);\n    VPBlockUtils::connectBlocks(Region, SplitBlock);\n  }\n}\n\nvoid VPlanTransforms::createAndOptimizeReplicateRegions(VPlan &Plan) {\n  // Convert masked VPReplicateRecipes to if-then region blocks.\n  addReplicateRegions(Plan);\n\n  bool ShouldSimplify = true;\n  while (ShouldSimplify) {\n    ShouldSimplify = sinkScalarOperands(Plan);\n    ShouldSimplify |= mergeReplicateRegionsIntoSuccessors(Plan);\n    ShouldSimplify |= VPlanTransforms::mergeBlocksIntoPredecessors(Plan);\n  }\n}\nbool VPlanTransforms::mergeBlocksIntoPredecessors(VPlan &Plan) {\n  SmallVector<VPBasicBlock *> WorkList;\n  for (VPBasicBlock *VPBB : VPBlockUtils::blocksOnly<VPBasicBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    auto *PredVPBB =\n        dyn_cast_or_null<VPBasicBlock>(VPBB->getSinglePredecessor());\n    if (PredVPBB && PredVPBB->getNumSuccessors() == 1)\n      WorkList.push_back(VPBB);\n  }\n\n  for (VPBasicBlock *VPBB : WorkList) {\n    VPBasicBlock *PredVPBB = cast<VPBasicBlock>(VPBB->getSinglePredecessor());\n    for (VPRecipeBase &R : make_early_inc_range(*VPBB))\n      R.moveBefore(*PredVPBB, PredVPBB->end());\n    VPBlockUtils::disconnectBlocks(PredVPBB, VPBB);\n    auto *ParentRegion = cast_or_null<VPRegionBlock>(VPBB->getParent());\n    if (ParentRegion && ParentRegion->getExiting() == VPBB)\n      ParentRegion->setExiting(PredVPBB);\n    for (auto *Succ : to_vector(VPBB->successors())) {\n      VPBlockUtils::disconnectBlocks(VPBB, Succ);\n      VPBlockUtils::connectBlocks(PredVPBB, Succ);\n    }\n    delete VPBB;\n  }\n  return !WorkList.empty();\n}\n\nvoid VPlanTransforms::removeRedundantInductionCasts(VPlan &Plan) {\n  for (auto &Phi : Plan.getVectorLoopRegion()->getEntryBasicBlock()->phis()) {\n    auto *IV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n    if (!IV || IV->getTruncInst())\n      continue;\n\n    // A sequence of IR Casts has potentially been recorded for IV, which\n    // *must be bypassed* when the IV is vectorized, because the vectorized IV\n    // will produce the desired casted value. This sequence forms a def-use\n    // chain and is provided in reverse order, ending with the cast that uses\n    // the IV phi. Search for the recipe of the last cast in the chain and\n    // replace it with the original IV. Note that only the final cast is\n    // expected to have users outside the cast-chain and the dead casts left\n    // over will be cleaned up later.\n    auto &Casts = IV->getInductionDescriptor().getCastInsts();\n    VPValue *FindMyCast = IV;\n    for (Instruction *IRCast : reverse(Casts)) {\n      VPSingleDefRecipe *FoundUserCast = nullptr;\n      for (auto *U : FindMyCast->users()) {\n        auto *UserCast = dyn_cast<VPSingleDefRecipe>(U);\n        if (UserCast && UserCast->getUnderlyingValue() == IRCast) {\n          FoundUserCast = UserCast;\n          break;\n        }\n      }\n      FindMyCast = FoundUserCast;\n    }\n    FindMyCast->replaceAllUsesWith(IV);\n  }\n}\n\nvoid VPlanTransforms::removeRedundantCanonicalIVs(VPlan &Plan) {\n  VPCanonicalIVPHIRecipe *CanonicalIV = Plan.getCanonicalIV();\n  VPWidenCanonicalIVRecipe *WidenNewIV = nullptr;\n  for (VPUser *U : CanonicalIV->users()) {\n    WidenNewIV = dyn_cast<VPWidenCanonicalIVRecipe>(U);\n    if (WidenNewIV)\n      break;\n  }\n\n  if (!WidenNewIV)\n    return;\n\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  for (VPRecipeBase &Phi : HeaderVPBB->phis()) {\n    auto *WidenOriginalIV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n\n    if (!WidenOriginalIV || !WidenOriginalIV->isCanonical() ||\n        WidenOriginalIV->getScalarType() != WidenNewIV->getScalarType())\n      continue;\n\n    // Replace WidenNewIV with WidenOriginalIV if WidenOriginalIV provides\n    // everything WidenNewIV's users need. That is, WidenOriginalIV will\n    // generate a vector phi or all users of WidenNewIV demand the first lane\n    // only.\n    if (any_of(WidenOriginalIV->users(),\n               [WidenOriginalIV](VPUser *U) {\n                 return !U->usesScalars(WidenOriginalIV);\n               }) ||\n        vputils::onlyFirstLaneUsed(WidenNewIV)) {\n      WidenNewIV->replaceAllUsesWith(WidenOriginalIV);\n      WidenNewIV->eraseFromParent();\n      return;\n    }\n  }\n}\n\nvoid VPlanTransforms::removeDeadRecipes(VPlan &Plan) {\n  ReversePostOrderTraversal<VPBlockDeepTraversalWrapper<VPBlockBase *>> RPOT(\n      Plan.getEntry());\n\n  for (VPBasicBlock *VPBB : reverse(VPBlockUtils::blocksOnly<VPBasicBlock>(RPOT))) {\n    // The recipes in the block are processed in reverse order, to catch chains\n    // of dead recipes.\n    for (VPRecipeBase &R : make_early_inc_range(reverse(*VPBB))) {\n      // A user keeps R alive:\n      if (any_of(R.definedValues(),\n                 [](VPValue *V) { return V->getNumUsers(); }))\n        continue;\n\n      // Having side effects keeps R alive, but do remove conditional assume\n      // instructions as their conditions may be flattened.\n      auto *RepR = dyn_cast<VPReplicateRecipe>(&R);\n      bool IsConditionalAssume =\n          RepR && RepR->isPredicated() &&\n          match(RepR->getUnderlyingInstr(), m_Intrinsic<Intrinsic::assume>());\n      if (R.mayHaveSideEffects() && !IsConditionalAssume)\n        continue;\n\n      R.eraseFromParent();\n    }\n  }\n}\n\nstatic VPValue *createScalarIVSteps(VPlan &Plan, const InductionDescriptor &ID,\n                                    ScalarEvolution &SE, Instruction *TruncI,\n                                    VPValue *StartV, VPValue *Step,\n                                    VPBasicBlock::iterator IP) {\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  VPCanonicalIVPHIRecipe *CanonicalIV = Plan.getCanonicalIV();\n  VPSingleDefRecipe *BaseIV = CanonicalIV;\n  if (!CanonicalIV->isCanonical(ID.getKind(), StartV, Step)) {\n    BaseIV = new VPDerivedIVRecipe(ID, StartV, CanonicalIV, Step);\n    HeaderVPBB->insert(BaseIV, IP);\n  }\n\n  // Truncate base induction if needed.\n  VPTypeAnalysis TypeInfo(SE.getContext());\n  Type *ResultTy = TypeInfo.inferScalarType(BaseIV);\n  if (TruncI) {\n    Type *TruncTy = TruncI->getType();\n    assert(ResultTy->getScalarSizeInBits() > TruncTy->getScalarSizeInBits() &&\n"}, {"id": "5C44FE778EC7AC63", "name": "llvm::VPlanTransforms::mergeBlocksIntoPredecessors", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlanTransforms.cpp", "start": {"line": 371, "col": 1}, "end": {"line": 396, "col": 1}, "code": "  SmallVector<VPBasicBlock *> WorkList;\n  for (VPBasicBlock *VPBB : VPBlockUtils::blocksOnly<VPBasicBlock>(\n           vp_depth_first_deep(Plan.getEntry()))) {\n    auto *PredVPBB =\n        dyn_cast_or_null<VPBasicBlock>(VPBB->getSinglePredecessor());\n    if (PredVPBB && PredVPBB->getNumSuccessors() == 1)\n      WorkList.push_back(VPBB);\n  }\n\n  for (VPBasicBlock *VPBB : WorkList) {\n    VPBasicBlock *PredVPBB = cast<VPBasicBlock>(VPBB->getSinglePredecessor());\n    for (VPRecipeBase &R : make_early_inc_range(*VPBB))\n      R.moveBefore(*PredVPBB, PredVPBB->end());\n    VPBlockUtils::disconnectBlocks(PredVPBB, VPBB);\n    auto *ParentRegion = cast_or_null<VPRegionBlock>(VPBB->getParent());\n    if (ParentRegion && ParentRegion->getExiting() == VPBB)\n      ParentRegion->setExiting(PredVPBB);\n    for (auto *Succ : to_vector(VPBB->successors())) {\n      VPBlockUtils::disconnectBlocks(VPBB, Succ);\n      VPBlockUtils::connectBlocks(PredVPBB, Succ);\n    }\n    delete VPBB;\n  }\n  return !WorkList.empty();\n}\n\nvoid VPlanTransforms::removeRedundantInductionCasts(VPlan &Plan) {\n  for (auto &Phi : Plan.getVectorLoopRegion()->getEntryBasicBlock()->phis()) {\n    auto *IV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n    if (!IV || IV->getTruncInst())\n      continue;\n\n    // A sequence of IR Casts has potentially been recorded for IV, which\n    // *must be bypassed* when the IV is vectorized, because the vectorized IV\n    // will produce the desired casted value. This sequence forms a def-use\n    // chain and is provided in reverse order, ending with the cast that uses\n    // the IV phi. Search for the recipe of the last cast in the chain and\n    // replace it with the original IV. Note that only the final cast is\n    // expected to have users outside the cast-chain and the dead casts left\n    // over will be cleaned up later.\n    auto &Casts = IV->getInductionDescriptor().getCastInsts();\n    VPValue *FindMyCast = IV;\n    for (Instruction *IRCast : reverse(Casts)) {\n      VPSingleDefRecipe *FoundUserCast = nullptr;\n      for (auto *U : FindMyCast->users()) {\n        auto *UserCast = dyn_cast<VPSingleDefRecipe>(U);\n        if (UserCast && UserCast->getUnderlyingValue() == IRCast) {\n          FoundUserCast = UserCast;\n          break;\n        }\n      }\n      FindMyCast = FoundUserCast;\n    }\n    FindMyCast->replaceAllUsesWith(IV);\n  }\n}\n\nvoid VPlanTransforms::removeRedundantCanonicalIVs(VPlan &Plan) {\n  VPCanonicalIVPHIRecipe *CanonicalIV = Plan.getCanonicalIV();\n  VPWidenCanonicalIVRecipe *WidenNewIV = nullptr;\n  for (VPUser *U : CanonicalIV->users()) {\n    WidenNewIV = dyn_cast<VPWidenCanonicalIVRecipe>(U);\n    if (WidenNewIV)\n      break;\n  }\n\n  if (!WidenNewIV)\n    return;\n\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  for (VPRecipeBase &Phi : HeaderVPBB->phis()) {\n    auto *WidenOriginalIV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n\n    if (!WidenOriginalIV || !WidenOriginalIV->isCanonical() ||\n        WidenOriginalIV->getScalarType() != WidenNewIV->getScalarType())\n      continue;\n\n    // Replace WidenNewIV with WidenOriginalIV if WidenOriginalIV provides\n    // everything WidenNewIV's users need. That is, WidenOriginalIV will\n    // generate a vector phi or all users of WidenNewIV demand the first lane\n    // only.\n    if (any_of(WidenOriginalIV->users(),\n               [WidenOriginalIV](VPUser *U) {\n                 return !U->usesScalars(WidenOriginalIV);\n               }) ||\n        vputils::onlyFirstLaneUsed(WidenNewIV)) {\n      WidenNewIV->replaceAllUsesWith(WidenOriginalIV);\n      WidenNewIV->eraseFromParent();\n      return;\n    }\n  }\n}\n\nvoid VPlanTransforms::removeDeadRecipes(VPlan &Plan) {\n  ReversePostOrderTraversal<VPBlockDeepTraversalWrapper<VPBlockBase *>> RPOT(\n      Plan.getEntry());\n\n  for (VPBasicBlock *VPBB : reverse(VPBlockUtils::blocksOnly<VPBasicBlock>(RPOT))) {\n    // The recipes in the block are processed in reverse order, to catch chains\n    // of dead recipes.\n    for (VPRecipeBase &R : make_early_inc_range(reverse(*VPBB))) {\n      // A user keeps R alive:\n      if (any_of(R.definedValues(),\n                 [](VPValue *V) { return V->getNumUsers(); }))\n        continue;\n\n      // Having side effects keeps R alive, but do remove conditional assume\n      // instructions as their conditions may be flattened.\n      auto *RepR = dyn_cast<VPReplicateRecipe>(&R);\n      bool IsConditionalAssume =\n          RepR && RepR->isPredicated() &&\n          match(RepR->getUnderlyingInstr(), m_Intrinsic<Intrinsic::assume>());\n      if (R.mayHaveSideEffects() && !IsConditionalAssume)\n        continue;\n\n      R.eraseFromParent();\n    }\n  }\n}\n\nstatic VPValue *createScalarIVSteps(VPlan &Plan, const InductionDescriptor &ID,\n                                    ScalarEvolution &SE, Instruction *TruncI,\n                                    VPValue *StartV, VPValue *Step,\n                                    VPBasicBlock::iterator IP) {\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  VPCanonicalIVPHIRecipe *CanonicalIV = Plan.getCanonicalIV();\n  VPSingleDefRecipe *BaseIV = CanonicalIV;\n  if (!CanonicalIV->isCanonical(ID.getKind(), StartV, Step)) {\n    BaseIV = new VPDerivedIVRecipe(ID, StartV, CanonicalIV, Step);\n    HeaderVPBB->insert(BaseIV, IP);\n  }\n\n  // Truncate base induction if needed.\n  VPTypeAnalysis TypeInfo(SE.getContext());\n  Type *ResultTy = TypeInfo.inferScalarType(BaseIV);\n  if (TruncI) {\n    Type *TruncTy = TruncI->getType();\n    assert(ResultTy->getScalarSizeInBits() > TruncTy->getScalarSizeInBits() &&\n           \"Not truncating.\");\n    assert(ResultTy->isIntegerTy() && \"Truncation requires an integer type\");\n    BaseIV = new VPScalarCastRecipe(Instruction::Trunc, BaseIV, TruncTy);\n    HeaderVPBB->insert(BaseIV, IP);\n    ResultTy = TruncTy;\n  }\n\n  // Truncate step if needed.\n  Type *StepTy = TypeInfo.inferScalarType(Step);\n  if (ResultTy != StepTy) {\n    assert(StepTy->getScalarSizeInBits() > ResultTy->getScalarSizeInBits() &&\n           \"Not truncating.\");\n    assert(StepTy->isIntegerTy() && \"Truncation requires an integer type\");\n    Step = new VPScalarCastRecipe(Instruction::Trunc, Step, ResultTy);\n    auto *VecPreheader =\n        cast<VPBasicBlock>(HeaderVPBB->getSingleHierarchicalPredecessor());\n    VecPreheader->appendRecipe(Step->getDefiningRecipe());\n  }\n\n  VPScalarIVStepsRecipe *Steps = new VPScalarIVStepsRecipe(ID, BaseIV, Step);\n  HeaderVPBB->insert(Steps, IP);\n  return Steps;\n}\n\nvoid VPlanTransforms::optimizeInductions(VPlan &Plan, ScalarEvolution &SE) {\n  SmallVector<VPRecipeBase *> ToRemove;\n  VPBasicBlock *HeaderVPBB = Plan.getVectorLoopRegion()->getEntryBasicBlock();\n  bool HasOnlyVectorVFs = !Plan.hasVF(ElementCount::getFixed(1));\n  VPBasicBlock::iterator InsertPt = HeaderVPBB->getFirstNonPhi();\n  for (VPRecipeBase &Phi : HeaderVPBB->phis()) {\n    auto *WideIV = dyn_cast<VPWidenIntOrFpInductionRecipe>(&Phi);\n    if (!WideIV)\n      continue;\n    if (HasOnlyVectorVFs && none_of(WideIV->users(), [WideIV](VPUser *U) {\n          return U->usesScalars(WideIV);\n        }))\n      continue;\n\n    const InductionDescriptor &ID = WideIV->getInductionDescriptor();\n    VPValue *Steps = createScalarIVSteps(Plan, ID, SE, WideIV->getTruncInst(),\n                                         WideIV->getStartValue(),\n                                         WideIV->getStepValue(), InsertPt);\n\n    // Update scalar users of IV to use Step instead.\n    if (!HasOnlyVectorVFs)\n      WideIV->replaceAllUsesWith(Steps);\n    else\n      WideIV->replaceUsesWithIf(Steps, [WideIV](VPUser &U, unsigned) {\n        return U.usesScalars(WideIV);\n      });\n  }\n}\n\nvoid VPlanTransforms::removeRedundantExpandSCEVRecipes(VPlan &Plan) {\n  DenseMap<const SCEV *, VPValue *> SCEV2VPV;\n\n  for (VPRecipeBase &R :\n       make_early_inc_range(*Plan.getEntry()->getEntryBasicBlock())) {\n    auto *ExpR = dyn_cast<VPExpandSCEVRecipe>(&R);\n    if (!ExpR)\n      continue;\n\n    auto I = SCEV2VPV.insert({ExpR->getSCEV(), ExpR});\n    if (I.second)\n      continue;\n    ExpR->replaceAllUsesWith(I.first->second);\n    ExpR->eraseFromParent();\n  }\n}\n\nstatic bool canSimplifyBranchOnCond(VPInstruction *Term) {\n  VPInstruction *Not = dyn_cast<VPInstruction>(Term->getOperand(0));\n  if (!Not || Not->getOpcode() != VPInstruction::Not)\n    return false;\n\n  VPInstruction *ALM = dyn_cast<VPInstruction>(Not->getOperand(0));\n  return ALM && ALM->getOpcode() == VPInstruction::ActiveLaneMask;\n}\n\nvoid VPlanTransforms::optimizeForVFAndUF(VPlan &Plan, ElementCount BestVF,\n                                         unsigned BestUF,\n                                         PredicatedScalarEvolution &PSE) {\n  assert(Plan.hasVF(BestVF) && \"BestVF is not available in Plan\");\n  assert(Plan.hasUF(BestUF) && \"BestUF is not available in Plan\");\n  VPBasicBlock *ExitingVPBB =\n      Plan.getVectorLoopRegion()->getExitingBasicBlock();\n  auto *Term = dyn_cast<VPInstruction>(&ExitingVPBB->back());\n  // Try to simplify the branch condition if TC <= VF * UF when preparing to\n  // execute the plan for the main vector loop. We only do this if the\n  // terminator is:\n  //  1. BranchOnCount, or\n  //  2. BranchOnCond where the input is Not(ActiveLaneMask).\n  if (!Term || (Term->getOpcode() != VPInstruction::BranchOnCount &&\n                (Term->getOpcode() != VPInstruction::BranchOnCond ||\n                 !canSimplifyBranchOnCond(Term))))\n    return;\n\n  Type *IdxTy =\n      Plan.getCanonicalIV()->getStartValue()->getLiveInIRValue()->getType();\n  const SCEV *TripCount = createTripCountSCEV(IdxTy, PSE);\n  ScalarEvolution &SE = *PSE.getSE();\n  const SCEV *C =\n      SE.getConstant(TripCount->getType(), BestVF.getKnownMinValue() * BestUF);\n  if (TripCount->isZero() ||\n      !SE.isKnownPredicate(CmpInst::ICMP_ULE, TripCount, C))\n    return;\n\n  LLVMContext &Ctx = SE.getContext();\n  auto *BOC = new VPInstruction(\n      VPInstruction::BranchOnCond,\n      {Plan.getVPValueOrAddLiveIn(ConstantInt::getTrue(Ctx))});\n  Term->eraseFromParent();\n  ExitingVPBB->appendRecipe(BOC);\n  Plan.setVF(BestVF);\n  Plan.setUF(BestUF);\n  // TODO: Further simplifications are possible\n  //      1. Replace inductions with constants.\n  //      2. Replace vector loop region with VPBasicBlock.\n}\n\n#ifndef NDEBUG\nstatic VPRegionBlock *GetReplicateRegion(VPRecipeBase *R) {\n  auto *Region = dyn_cast_or_null<VPRegionBlock>(R->getParent()->getParent());\n  if (Region && Region->isReplicator()) {\n    assert(Region->getNumSuccessors() == 1 &&\n           Region->getNumPredecessors() == 1 && \"Expected SESE region!\");\n    assert(R->getParent()->size() == 1 &&\n           \"A recipe in an original replicator region must be the only \"\n           \"recipe in its block\");\n    return Region;\n  }\n  return nullptr;\n}\n#endif\n\nstatic bool properlyDominates(const VPRecipeBase *A, const VPRecipeBase *B,\n                              VPDominatorTree &VPDT) {\n  if (A == B)\n    return false;\n\n  auto LocalComesBefore = [](const VPRecipeBase *A, const VPRecipeBase *B) {\n    for (auto &R : *A->getParent()) {\n      if (&R == A)\n        return true;\n      if (&R == B)\n        return false;\n    }\n    llvm_unreachable(\"recipe not found\");\n  };\n  const VPBlockBase *ParentA = A->getParent();\n  const VPBlockBase *ParentB = B->getParent();\n  if (ParentA == ParentB)\n    return LocalComesBefore(A, B);\n\n  assert(!GetReplicateRegion(const_cast<VPRecipeBase *>(A)) &&\n         \"No replicate regions expected at this point\");\n  assert(!GetReplicateRegion(const_cast<VPRecipeBase *>(B)) &&\n         \"No replicate regions expected at this point\");\n  return VPDT.properlyDominates(ParentA, ParentB);\n}\n\n/// Sink users of \\p FOR after the recipe defining the previous value \\p\n/// Previous of the recurrence. \\returns true if all users of \\p FOR could be\n/// re-arranged as needed or false if it is not possible.\nstatic bool\nsinkRecurrenceUsersAfterPrevious(VPFirstOrderRecurrencePHIRecipe *FOR,\n                                 VPRecipeBase *Previous,\n                                 VPDominatorTree &VPDT) {\n  // Collect recipes that need sinking.\n  SmallVector<VPRecipeBase *> WorkList;\n  SmallPtrSet<VPRecipeBase *, 8> Seen;\n  Seen.insert(Previous);\n  auto TryToPushSinkCandidate = [&](VPRecipeBase *SinkCandidate) {\n    // The previous value must not depend on the users of the recurrence phi. In\n    // that case, FOR is not a fixed order recurrence.\n    if (SinkCandidate == Previous)\n      return false;\n\n    if (isa<VPHeaderPHIRecipe>(SinkCandidate) ||\n        !Seen.insert(SinkCandidate).second ||\n        properlyDominates(Previous, SinkCandidate, VPDT))\n      return true;\n\n    if (SinkCandidate->mayHaveSideEffects())\n      return false;\n\n    WorkList.push_back(SinkCandidate);\n    return true;\n  };\n\n  // Recursively sink users of FOR after Previous.\n  WorkList.push_back(FOR);\n  for (unsigned I = 0; I != WorkList.size(); ++I) {\n    VPRecipeBase *Current = WorkList[I];\n    assert(Current->getNumDefinedValues() == 1 &&\n           \"only recipes with a single defined value expected\");\n\n    for (VPUser *User : Current->getVPSingleValue()->users()) {\n      if (auto *R = dyn_cast<VPRecipeBase>(User))\n        if (!TryToPushSinkCandidate(R))\n          return false;\n    }\n  }\n\n  // Keep recipes to sink ordered by dominance so earlier instructions are\n  // processed first.\n  sort(WorkList, [&VPDT](const VPRecipeBase *A, const VPRecipeBase *B) {\n    return properlyDominates(A, B, VPDT);\n  });\n\n  for (VPRecipeBase *SinkCandidate : WorkList) {\n    if (SinkCandidate == FOR)\n      continue;\n\n    SinkCandidate->moveAfter(Previous);\n    Previous = SinkCandidate;\n  }\n  return true;\n}\n\nbool VPlanTransforms::adjustFixedOrderRecurrences(VPlan &Plan,\n                                                  VPBuilder &Builder) {\n  VPDominatorTree VPDT;\n  VPDT.recalculate(Plan);\n\n  SmallVector<VPFirstOrderRecurrencePHIRecipe *> RecurrencePhis;\n  for (VPRecipeBase &R :\n       Plan.getVectorLoopRegion()->getEntry()->getEntryBasicBlock()->phis())\n    if (auto *FOR = dyn_cast<VPFirstOrderRecurrencePHIRecipe>(&R))\n      RecurrencePhis.push_back(FOR);\n\n  for (VPFirstOrderRecurrencePHIRecipe *FOR : RecurrencePhis) {\n    SmallPtrSet<VPFirstOrderRecurrencePHIRecipe *, 4> SeenPhis;\n    VPRecipeBase *Previous = FOR->getBackedgeValue()->getDefiningRecipe();\n    // Fixed-order recurrences do not contain cycles, so this loop is guaranteed\n    // to terminate.\n    while (auto *PrevPhi =\n               dyn_cast_or_null<VPFirstOrderRecurrencePHIRecipe>(Previous)) {\n      assert(PrevPhi->getParent() == FOR->getParent());\n      assert(SeenPhis.insert(PrevPhi).second);\n      Previous = PrevPhi->getBackedgeValue()->getDefiningRecipe();\n    }\n\n    if (!sinkRecurrenceUsersAfterPrevious(FOR, Previous, VPDT))\n      return false;\n\n    // Introduce a recipe to combine the incoming and previous values of a\n    // fixed-order recurrence.\n    VPBasicBlock *InsertBlock = Previous->getParent();\n    if (isa<VPHeaderPHIRecipe>(Previous))\n      Builder.setInsertPoint(InsertBlock, InsertBlock->getFirstNonPhi());\n    else\n      Builder.setInsertPoint(InsertBlock, std::next(Previous->getIterator()));\n\n    auto *RecurSplice = cast<VPInstruction>(\n        Builder.createNaryOp(VPInstruction::FirstOrderRecurrenceSplice,\n                             {FOR, FOR->getBackedgeValue()}));\n\n    FOR->replaceAllUsesWith(RecurSplice);\n"}], "code": "void VPlanTransforms::createAndOptimizeReplicateRegions(VPlan &Plan) {\n  // Convert masked VPReplicateRecipes to if-then region blocks.\n  addReplicateRegions(Plan);\n\n  bool ShouldSimplify = true;\n  while (ShouldSimplify) {\n    ShouldSimplify = sinkScalarOperands(Plan);\n    ShouldSimplify |= mergeReplicateRegionsIntoSuccessors(Plan);\n    ShouldSimplify |= VPlanTransforms::mergeBlocksIntoPredecessors(Plan);\n  }\n}\n"}, "21896FC1EC29AD52": {"calls": [{"id": "B60AC5C9F746D223", "name": "sanitizeFunctionName", "path": "llvm-project/llvm/lib/Analysis/TargetLibraryInfo.cpp", "start": {"line": 939, "col": 1}, "end": {"line": 948, "col": 1}, "code": "  // Filter out empty names and names containing null bytes, those can't be in\n  // our table.\n  if (funcName.empty() || funcName.contains('\\0'))\n    return StringRef();\n\n  // Check for \\01 prefix that is used to mangle __asm declarations and\n  // strip it if present.\n  return GlobalValue::dropLLVMManglingEscape(funcName);\n}\n\nstatic DenseMap<StringRef, LibFunc>\nbuildIndexMap(ArrayRef<StringLiteral> StandardNames) {\n  DenseMap<StringRef, LibFunc> Indices;\n  unsigned Idx = 0;\n  Indices.reserve(LibFunc::NumLibFuncs);\n  for (const auto &Func : StandardNames)\n    Indices[Func] = static_cast<LibFunc>(Idx++);\n  return Indices;\n}\n\nbool TargetLibraryInfoImpl::getLibFunc(StringRef funcName, LibFunc &F) const {\n  funcName = sanitizeFunctionName(funcName);\n  if (funcName.empty())\n    return false;\n\n  static const DenseMap<StringRef, LibFunc> Indices =\n      buildIndexMap(StandardNames);\n\n  if (auto Loc = Indices.find(funcName); Loc != Indices.end()) {\n    F = Loc->second;\n    return true;\n  }\n  return false;\n}\n\n// Return true if ArgTy matches Ty.\n\nstatic bool matchType(FuncArgTypeID ArgTy, const Type *Ty, unsigned IntBits,\n                      unsigned SizeTBits) {\n  switch (ArgTy) {\n  case Void:\n    return Ty->isVoidTy();\n  case Bool:\n    return Ty->isIntegerTy(8);\n  case Int16:\n    return Ty->isIntegerTy(16);\n  case Int32:\n    return Ty->isIntegerTy(32);\n  case Int:\n    return Ty->isIntegerTy(IntBits);\n  case IntPlus:\n    return Ty->isIntegerTy() && Ty->getPrimitiveSizeInBits() >= IntBits;\n  case IntX:\n    return Ty->isIntegerTy();\n  case Long:\n    // TODO: Figure out and use long size.\n    return Ty->isIntegerTy() && Ty->getPrimitiveSizeInBits() >= IntBits;\n  case Int64:\n    return Ty->isIntegerTy(64);\n  case LLong:\n    return Ty->isIntegerTy(64);\n  case SizeT:\n  case SSizeT:\n    return Ty->isIntegerTy(SizeTBits);\n  case Flt:\n    return Ty->isFloatTy();\n  case Dbl:\n    return Ty->isDoubleTy();\n    // TODO: Tighten this up.\n  case LDbl:\n    return Ty->isFloatingPointTy();\n  case Floating:\n    return Ty->isFloatingPointTy();\n  case Ptr:\n    return Ty->isPointerTy();\n  case Struct:\n    return Ty->isStructTy();\n  default:\n    break;\n  }\n\n  llvm_unreachable(\"Invalid type\");\n}\n\nbool TargetLibraryInfoImpl::isValidProtoForLibFunc(const FunctionType &FTy,\n                                                   LibFunc F,\n                                                   const Module &M) const {\n  unsigned NumParams = FTy.getNumParams();\n\n  switch (F) {\n    // Special handling for <complex.h> functions:\n  case LibFunc_cabs:\n  case LibFunc_cabsf:\n  case LibFunc_cabsl: {\n    Type *RetTy = FTy.getReturnType();\n    if (!RetTy->isFloatingPointTy())\n      return false;\n\n    Type *ParamTy = FTy.getParamType(0);\n    // NOTE: These prototypes are target specific and currently support\n    // \"complex\" passed as an array or discrete real & imaginary parameters.\n    // Add other calling conventions to enable libcall optimizations.\n    if (NumParams == 1)\n      return (ParamTy->isArrayTy() && ParamTy->getArrayNumElements() == 2 &&\n              ParamTy->getArrayElementType() == RetTy);\n    else if (NumParams == 2)\n      return ParamTy == RetTy && FTy.getParamType(1) == RetTy;\n\n    return false;\n  }\n    // Special handling for the sincospi functions that return either\n    // a struct or vector:\n  case LibFunc_sincospi_stret:\n  case LibFunc_sincospif_stret: {\n    if (NumParams != 1)\n      return false;\n\n    Type *RetTy = FTy.getReturnType();\n    Type *ParamTy = FTy.getParamType(0);\n    if (auto *Ty = dyn_cast<StructType>(RetTy)) {\n      if (Ty->getNumElements() != 2)\n        return false;\n      return (Ty->getElementType(0) == ParamTy &&\n              Ty->getElementType(1) == ParamTy);\n    }\n\n    if (auto *Ty = dyn_cast<FixedVectorType>(RetTy)) {\n      if (Ty->getNumElements() != 2)\n        return false;\n      return Ty->getElementType() == ParamTy;\n    }\n\n    return false;\n  }\n\n  default:\n    break;\n  }\n\n  unsigned IntBits = getIntSize();\n  unsigned SizeTBits = getSizeTSize(M);\n  unsigned Idx = 0;\n\n  // Iterate over the type ids in the function prototype, matching each\n  // against the function's type FTy, starting with its return type.\n  // Return true if both match in number and kind, inclduing the ellipsis.\n  Type *Ty = FTy.getReturnType(), *LastTy = Ty;\n  const auto &ProtoTypes = Signatures[F];\n  for (auto TyID : ProtoTypes) {\n    if (Idx && TyID == Void)\n      // Except in the first position where it designates the function's\n      // return type Void ends the argument list.\n      break;\n\n    if (TyID == Ellip) {\n      // The ellipsis ends the protoype list but is not a part of FTy's\n      // argument list.  Except when it's last it must be followed by\n      // Void.\n      assert(Idx == ProtoTypes.size() - 1 || ProtoTypes[Idx + 1] == Void);\n      return FTy.isFunctionVarArg();\n    }\n\n    if (TyID == Same) {\n      assert(Idx != 0 && \"Type ID 'Same' must not be first!\");\n      if (Ty != LastTy)\n        return false;\n    } else {\n      if (!Ty || !matchType(TyID, Ty, IntBits, SizeTBits))\n        return false;\n      LastTy = Ty;\n    }\n\n    if (Idx == NumParams) {\n      // There's at least one and at most two more type ids than there are\n      // arguments in FTy's argument list.\n      Ty = nullptr;\n      ++Idx;\n      continue;\n    }\n\n    Ty = FTy.getParamType(Idx++);\n  }\n\n  // Return success only if all entries on both lists have been processed\n  // and the function is not a variadic one.\n  return Idx == NumParams + 1 && !FTy.isFunctionVarArg();\n}\n\nbool TargetLibraryInfoImpl::getLibFunc(const Function &FDecl,\n                                       LibFunc &F) const {\n  // Intrinsics don't overlap w/libcalls; if our module has a large number of\n  // intrinsics, this ends up being an interesting compile time win since we\n  // avoid string normalization and comparison.\n  if (FDecl.isIntrinsic()) return false;\n\n  const Module *M = FDecl.getParent();\n  assert(M && \"Expecting FDecl to be connected to a Module.\");\n\n  if (FDecl.LibFuncCache == Function::UnknownLibFunc)\n    if (!getLibFunc(FDecl.getName(), FDecl.LibFuncCache))\n      FDecl.LibFuncCache = NotLibFunc;\n\n  if (FDecl.LibFuncCache == NotLibFunc)\n    return false;\n\n  F = FDecl.LibFuncCache;\n  return isValidProtoForLibFunc(*FDecl.getFunctionType(), F, *M);\n}\n\nbool TargetLibraryInfoImpl::getLibFunc(unsigned int Opcode, Type *Ty,\n                                       LibFunc &F) const {\n  // Must be a frem instruction with float or double arguments.\n  if (Opcode != Instruction::FRem || (!Ty->isDoubleTy() && !Ty->isFloatTy()))\n    return false;\n\n  F = Ty->isDoubleTy() ? LibFunc_fmod : LibFunc_fmodf;\n  return true;\n}\n\nvoid TargetLibraryInfoImpl::disableAllFunctions() {\n  memset(AvailableArray, 0, sizeof(AvailableArray));\n}\n\nstatic bool compareByScalarFnName(const VecDesc &LHS, const VecDesc &RHS) {\n  return LHS.getScalarFnName() < RHS.getScalarFnName();\n}\n\nstatic bool compareByVectorFnName(const VecDesc &LHS, const VecDesc &RHS) {\n  return LHS.getVectorFnName() < RHS.getVectorFnName();\n}\n\nstatic bool compareWithScalarFnName(const VecDesc &LHS, StringRef S) {\n  return LHS.getScalarFnName() < S;\n}\n\nvoid TargetLibraryInfoImpl::addVectorizableFunctions(ArrayRef<VecDesc> Fns) {\n  llvm::append_range(VectorDescs, Fns);\n  llvm::sort(VectorDescs, compareByScalarFnName);\n\n  llvm::append_range(ScalarDescs, Fns);\n  llvm::sort(ScalarDescs, compareByVectorFnName);\n}\n\nvoid TargetLibraryInfoImpl::addVectorizableFunctionsFromVecLib(\n    enum VectorLibrary VecLib, const llvm::Triple &TargetTriple) {\n  switch (VecLib) {\n  case Accelerate: {\n    const VecDesc VecFuncs[] = {\n    #define TLI_DEFINE_ACCELERATE_VECFUNCS\n    #include \"llvm/Analysis/VecFuncs.def\"\n    };\n    addVectorizableFunctions(VecFuncs);\n    break;\n  }\n  case DarwinLibSystemM: {\n    const VecDesc VecFuncs[] = {\n    #define TLI_DEFINE_DARWIN_LIBSYSTEM_M_VECFUNCS\n    #include \"llvm/Analysis/VecFuncs.def\"\n    };\n    addVectorizableFunctions(VecFuncs);\n    break;\n  }\n  case LIBMVEC_X86: {\n    const VecDesc VecFuncs[] = {\n    #define TLI_DEFINE_LIBMVEC_X86_VECFUNCS\n    #include \"llvm/Analysis/VecFuncs.def\"\n    };\n    addVectorizableFunctions(VecFuncs);\n    break;\n  }\n  case MASSV: {\n    const VecDesc VecFuncs[] = {\n    #define TLI_DEFINE_MASSV_VECFUNCS\n    #include \"llvm/Analysis/VecFuncs.def\"\n    };\n    addVectorizableFunctions(VecFuncs);\n    break;\n  }\n  case SVML: {\n    const VecDesc VecFuncs[] = {\n    #define TLI_DEFINE_SVML_VECFUNCS\n    #include \"llvm/Analysis/VecFuncs.def\"\n    };\n    addVectorizableFunctions(VecFuncs);\n    break;\n  }\n  case SLEEFGNUABI: {\n    const VecDesc VecFuncs_VF2[] = {\n#define TLI_DEFINE_SLEEFGNUABI_VF2_VECFUNCS\n#define TLI_DEFINE_VECFUNC(SCAL, VEC, VF, VABI_PREFIX)                         \\\n  {SCAL, VEC, VF, /* MASK = */ false, VABI_PREFIX},\n#include \"llvm/Analysis/VecFuncs.def\"\n    };\n    const VecDesc VecFuncs_VF4[] = {\n#define TLI_DEFINE_SLEEFGNUABI_VF4_VECFUNCS\n#define TLI_DEFINE_VECFUNC(SCAL, VEC, VF, VABI_PREFIX)                         \\\n  {SCAL, VEC, VF, /* MASK = */ false, VABI_PREFIX},\n#include \"llvm/Analysis/VecFuncs.def\"\n    };\n    const VecDesc VecFuncs_VFScalable[] = {\n#define TLI_DEFINE_SLEEFGNUABI_SCALABLE_VECFUNCS\n#define TLI_DEFINE_VECFUNC(SCAL, VEC, VF, MASK, VABI_PREFIX)                   \\\n  {SCAL, VEC, VF, MASK, VABI_PREFIX},\n#include \"llvm/Analysis/VecFuncs.def\"\n    };\n\n    switch (TargetTriple.getArch()) {\n    default:\n      break;\n    case llvm::Triple::aarch64:\n    case llvm::Triple::aarch64_be:\n      addVectorizableFunctions(VecFuncs_VF2);\n      addVectorizableFunctions(VecFuncs_VF4);\n      addVectorizableFunctions(VecFuncs_VFScalable);\n      break;\n    }\n    break;\n  }\n  case ArmPL: {\n    const VecDesc VecFuncs[] = {\n#define TLI_DEFINE_ARMPL_VECFUNCS\n#define TLI_DEFINE_VECFUNC(SCAL, VEC, VF, MASK, VABI_PREFIX)                   \\\n  {SCAL, VEC, VF, MASK, VABI_PREFIX},\n#include \"llvm/Analysis/VecFuncs.def\"\n    };\n\n    switch (TargetTriple.getArch()) {\n    default:\n      break;\n    case llvm::Triple::aarch64:\n    case llvm::Triple::aarch64_be:\n      addVectorizableFunctions(VecFuncs);\n      break;\n    }\n    break;\n  }\n  case NoLibrary:\n    break;\n  }\n}\n\nbool TargetLibraryInfoImpl::isFunctionVectorizable(StringRef funcName) const {\n  funcName = sanitizeFunctionName(funcName);\n  if (funcName.empty())\n    return false;\n\n  std::vector<VecDesc>::const_iterator I =\n      llvm::lower_bound(VectorDescs, funcName, compareWithScalarFnName);\n  return I != VectorDescs.end() && StringRef(I->getScalarFnName()) == funcName;\n}\n\nStringRef TargetLibraryInfoImpl::getVectorizedFunction(StringRef F,\n                                                       const ElementCount &VF,\n                                                       bool Masked) const {\n  const VecDesc *VD = getVectorMappingInfo(F, VF, Masked);\n  if (VD)\n    return VD->getVectorFnName();\n  return StringRef();\n}\n\nconst VecDesc *\nTargetLibraryInfoImpl::getVectorMappingInfo(StringRef F, const ElementCount &VF,\n                                            bool Masked) const {\n  F = sanitizeFunctionName(F);\n  if (F.empty())\n    return nullptr;\n  std::vector<VecDesc>::const_iterator I =\n      llvm::lower_bound(VectorDescs, F, compareWithScalarFnName);\n  while (I != VectorDescs.end() && StringRef(I->getScalarFnName()) == F) {\n    if ((I->getVectorizationFactor() == VF) && (I->isMasked() == Masked))\n      return &(*I);\n    ++I;\n  }\n  return nullptr;\n}\n\nTargetLibraryInfo TargetLibraryAnalysis::run(const Function &F,\n                                             FunctionAnalysisManager &) {\n  if (!BaselineInfoImpl)\n    BaselineInfoImpl =\n        TargetLibraryInfoImpl(Triple(F.getParent()->getTargetTriple()));\n  return TargetLibraryInfo(*BaselineInfoImpl, &F);\n}\n\nunsigned TargetLibraryInfoImpl::getWCharSize(const Module &M) const {\n  if (auto *ShortWChar = cast_or_null<ConstantAsMetadata>(\n      M.getModuleFlag(\"wchar_size\")))\n    return cast<ConstantInt>(ShortWChar->getValue())->getZExtValue();\n  return 0;\n}\n\nunsigned TargetLibraryInfoImpl::getSizeTSize(const Module &M) const {\n  // There is really no guarantee that sizeof(size_t) is equal to sizeof(int*).\n  // If that isn't true then it should be possible to derive the SizeTTy from\n  // the target triple here instead and do an early return.\n\n  // Historically LLVM assume that size_t has same size as intptr_t (hence\n  // deriving the size from sizeof(int*) in address space zero). This should\n  // work for most targets. For future consideration: DataLayout also implement\n  // getIndexSizeInBits which might map better to size_t compared to\n  // getPointerSizeInBits. Hard coding address space zero here might be\n  // unfortunate as well. Maybe getDefaultGlobalsAddressSpace() or\n  // getAllocaAddrSpace() is better.\n  unsigned AddressSpace = 0;\n  return M.getDataLayout().getPointerSizeInBits(AddressSpace);\n}\n\nTargetLibraryInfoWrapperPass::TargetLibraryInfoWrapperPass()\n    : ImmutablePass(ID), TLA(TargetLibraryInfoImpl()) {\n  initializeTargetLibraryInfoWrapperPassPass(*PassRegistry::getPassRegistry());\n}\n\nTargetLibraryInfoWrapperPass::TargetLibraryInfoWrapperPass(const Triple &T)\n    : ImmutablePass(ID), TLA(TargetLibraryInfoImpl(T)) {\n  initializeTargetLibraryInfoWrapperPassPass(*PassRegistry::getPassRegistry());\n}\n\nTargetLibraryInfoWrapperPass::TargetLibraryInfoWrapperPass(\n    const TargetLibraryInfoImpl &TLIImpl)\n    : ImmutablePass(ID), TLA(TLIImpl) {\n  initializeTargetLibraryInfoWrapperPassPass(*PassRegistry::getPassRegistry());\n}\n\nAnalysisKey TargetLibraryAnalysis::Key;\n\n// Register the basic pass.\nINITIALIZE_PASS(TargetLibraryInfoWrapperPass, \"targetlibinfo\",\n                \"Target Library Information\", false, true)\nchar TargetLibraryInfoWrapperPass::ID = 0;\n\nvoid TargetLibraryInfoWrapperPass::anchor() {}\n\nvoid TargetLibraryInfoImpl::getWidestVF(StringRef ScalarF,\n                                        ElementCount &FixedVF,\n                                        ElementCount &ScalableVF) const {\n  ScalarF = sanitizeFunctionName(ScalarF);\n  // Use '0' here because a type of the form <vscale x 1 x ElTy> is not the\n  // same as a scalar.\n  ScalableVF = ElementCount::getScalable(0);\n  FixedVF = ElementCount::getFixed(1);\n  if (ScalarF.empty())\n    return;\n\n  std::vector<VecDesc>::const_iterator I =\n      llvm::lower_bound(VectorDescs, ScalarF, compareWithScalarFnName);\n  while (I != VectorDescs.end() && StringRef(I->getScalarFnName()) == ScalarF) {\n    ElementCount *VF =\n        I->getVectorizationFactor().isScalable() ? &ScalableVF : &FixedVF;\n    if (ElementCount::isKnownGT(I->getVectorizationFactor(), *VF))\n      *VF = I->getVectorizationFactor();\n    ++I;\n  }\n}\n"}], "code": "bool TargetLibraryInfoImpl::isFunctionVectorizable(StringRef funcName) const {\n  funcName = sanitizeFunctionName(funcName);\n  if (funcName.empty())\n    return false;\n\n  std::vector<VecDesc>::const_iterator I =\n      llvm::lower_bound(VectorDescs, funcName, compareWithScalarFnName);\n  return I != VectorDescs.end() && StringRef(I->getScalarFnName()) == funcName;\n}\n"}, "C6A84ACD8DB87546": {"calls": [{"id": "F14AA2152168DD7E", "name": "llvm::SequenceToOffsetTable::isSuffix", "path": "llvm-project/llvm/utils/TableGen/SequenceToOffsetTable.h", "start": {"line": 72, "col": 3}, "end": {"line": 74, "col": 3}, "code": "    return A.size() <= B.size() && std::equal(A.rbegin(), A.rend(), B.rbegin());\n  }\n\npublic:\n  SequenceToOffsetTable() : Entries(0) {}\n\n  /// add - Add a sequence to the table.\n  /// This must be called before layout().\n  void add(const SeqT &Seq) {\n    assert(Entries == 0 && \"Cannot call add() after layout()\");\n    typename SeqMap::iterator I = Seqs.lower_bound(Seq);\n\n    // If SeqMap contains a sequence that has Seq as a suffix, I will be\n    // pointing to it.\n    if (I != Seqs.end() && isSuffix(Seq, I->first))\n      return;\n\n    I = Seqs.insert(I, std::make_pair(Seq, 0u));\n\n    // The entry before I may be a suffix of Seq that can now be erased.\n    if (I != Seqs.begin() && isSuffix((--I)->first, Seq))\n      Seqs.erase(I);\n  }\n\n  bool empty() const { return Seqs.empty(); }\n\n  unsigned size() const {\n    assert((empty() || Entries) && \"Call layout() before size()\");\n    return Entries;\n  }\n\n  /// layout - Computes the final table layout.\n  void layout() {\n    assert(Entries == 0 && \"Can only call layout() once\");\n    // Lay out the table in Seqs iteration order.\n    for (typename SeqMap::iterator I = Seqs.begin(), E = Seqs.end(); I != E;\n         ++I) {\n      I->second = Entries;\n      // Include space for a terminator.\n      Entries += I->first.size() + 1;\n    }\n  }\n\n  /// get - Returns the offset of Seq in the final table.\n  unsigned get(const SeqT &Seq) const {\n    assert(Entries && \"Call layout() before get()\");\n    typename SeqMap::const_iterator I = Seqs.lower_bound(Seq);\n    assert(I != Seqs.end() && isSuffix(Seq, I->first) &&\n           \"get() called with sequence that wasn't added first\");\n    return I->second + (I->first.size() - Seq.size());\n  }\n\n  /// `emitStringLiteralDef` - Print out the table as the body of an array\n  /// initializer, where each element is a C string literal terminated by\n  /// `\\0`. Falls back to emitting a comma-separated integer list if\n  /// `EmitLongStrLiterals` is false\n  void emitStringLiteralDef(raw_ostream &OS, const llvm::Twine &Decl) const {\n    assert(Entries && \"Call layout() before emitStringLiteralDef()\");\n    if (!EmitLongStrLiterals) {\n      OS << Decl << \" = {\\n\";\n      emit(OS, printChar, \"0\");\n      OS << \"  0\\n};\\n\\n\";\n      return;\n    }\n\n    OS << \"\\n#ifdef __GNUC__\\n\"\n       << \"#pragma GCC diagnostic push\\n\"\n       << \"#pragma GCC diagnostic ignored \\\"-Woverlength-strings\\\"\\n\"\n       << \"#endif\\n\"\n       << Decl << \" = {\\n\";\n    for (auto I : Seqs) {\n      OS << \"  /* \" << I.second << \" */ \\\"\";\n      OS.write_escaped(I.first);\n      OS << \"\\\\0\\\"\\n\";\n    }\n"}], "code": "  void add(const SeqT &Seq) {\n    assert(Entries == 0 && \"Cannot call add() after layout()\");\n    typename SeqMap::iterator I = Seqs.lower_bound(Seq);\n\n    // If SeqMap contains a sequence that has Seq as a suffix, I will be\n    // pointing to it.\n    if (I != Seqs.end() && isSuffix(Seq, I->first))\n      return;\n\n    I = Seqs.insert(I, std::make_pair(Seq, 0u));\n\n    // The entry before I may be a suffix of Seq that can now be erased.\n    if (I != Seqs.begin() && isSuffix((--I)->first, Seq))\n      Seqs.erase(I);\n  }\n"}, "347889ACE5A83B22": {"calls": [{"id": "0D1D628706323065", "name": "FindDepVarsOf", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp", "start": {"line": 4461, "col": 1}, "end": {"line": 4469, "col": 1}, "code": "  if (N.isLeaf()) {\n    if (N.hasName() && isa<DefInit>(N.getLeafValue()))\n      DepMap[N.getName()]++;\n  } else {\n    for (size_t i = 0, e = N.getNumChildren(); i != e; ++i)\n      FindDepVarsOf(N.getChild(i), DepMap);\n  }\n}\n\n/// Find dependent variables within child patterns\nstatic void FindDepVars(TreePatternNode &N, MultipleUseVarSet &DepVars) {\n  DepVarMap depcounts;\n  FindDepVarsOf(N, depcounts);\n  for (const auto &Pair : depcounts) {\n    if (Pair.getValue() > 1)\n      DepVars.insert(Pair.getKey());\n  }\n}\n\n#ifndef NDEBUG\n/// Dump the dependent variable set:\nstatic void DumpDepVars(MultipleUseVarSet &DepVars) {\n  if (DepVars.empty()) {\n    LLVM_DEBUG(errs() << \"<empty set>\");\n  } else {\n    LLVM_DEBUG(errs() << \"[ \");\n    for (const auto &DepVar : DepVars) {\n      LLVM_DEBUG(errs() << DepVar.getKey() << \" \");\n    }\n    LLVM_DEBUG(errs() << \"]\");\n  }\n}\n#endif\n\n/// CombineChildVariants - Given a bunch of permutations of each child of the\n/// 'operator' node, put them together in all possible ways.\nstatic void CombineChildVariants(\n    TreePatternNodePtr Orig,\n    const std::vector<std::vector<TreePatternNodePtr>> &ChildVariants,\n    std::vector<TreePatternNodePtr> &OutVariants, CodeGenDAGPatterns &CDP,\n    const MultipleUseVarSet &DepVars) {\n  // Make sure that each operand has at least one variant to choose from.\n  for (const auto &Variants : ChildVariants)\n    if (Variants.empty())\n      return;\n\n  // The end result is an all-pairs construction of the resultant pattern.\n  std::vector<unsigned> Idxs(ChildVariants.size());\n  bool NotDone;\n  do {\n#ifndef NDEBUG\n    LLVM_DEBUG(if (!Idxs.empty()) {\n      errs() << Orig->getOperator()->getName() << \": Idxs = [ \";\n      for (unsigned Idx : Idxs) {\n        errs() << Idx << \" \";\n      }\n      errs() << \"]\\n\";\n    });\n#endif\n    // Create the variant and add it to the output list.\n    std::vector<TreePatternNodePtr> NewChildren;\n    NewChildren.reserve(ChildVariants.size());\n    for (unsigned i = 0, e = ChildVariants.size(); i != e; ++i)\n      NewChildren.push_back(ChildVariants[i][Idxs[i]]);\n    TreePatternNodePtr R = makeIntrusiveRefCnt<TreePatternNode>(\n        Orig->getOperator(), std::move(NewChildren), Orig->getNumTypes());\n\n    // Copy over properties.\n    R->setName(Orig->getName());\n    R->setNamesAsPredicateArg(Orig->getNamesAsPredicateArg());\n    R->setPredicateCalls(Orig->getPredicateCalls());\n    R->setGISelFlagsRecord(Orig->getGISelFlagsRecord());\n    R->setTransformFn(Orig->getTransformFn());\n    for (unsigned i = 0, e = Orig->getNumTypes(); i != e; ++i)\n      R->setType(i, Orig->getExtType(i));\n\n    // If this pattern cannot match, do not include it as a variant.\n    std::string ErrString;\n    // Scan to see if this pattern has already been emitted.  We can get\n    // duplication due to things like commuting:\n    //   (and GPRC:$a, GPRC:$b) -> (and GPRC:$b, GPRC:$a)\n    // which are the same pattern.  Ignore the dups.\n    if (R->canPatternMatch(ErrString, CDP) &&\n        none_of(OutVariants, [&](TreePatternNodePtr Variant) {\n          return R->isIsomorphicTo(*Variant, DepVars);\n        }))\n      OutVariants.push_back(R);\n\n    // Increment indices to the next permutation by incrementing the\n    // indices from last index backward, e.g., generate the sequence\n    // [0, 0], [0, 1], [1, 0], [1, 1].\n    int IdxsIdx;\n    for (IdxsIdx = Idxs.size() - 1; IdxsIdx >= 0; --IdxsIdx) {\n      if (++Idxs[IdxsIdx] == ChildVariants[IdxsIdx].size())\n        Idxs[IdxsIdx] = 0;\n      else\n        break;\n    }\n    NotDone = (IdxsIdx >= 0);\n  } while (NotDone);\n}\n\n/// CombineChildVariants - A helper function for binary operators.\n///\nstatic void CombineChildVariants(TreePatternNodePtr Orig,\n                                 const std::vector<TreePatternNodePtr> &LHS,\n                                 const std::vector<TreePatternNodePtr> &RHS,\n                                 std::vector<TreePatternNodePtr> &OutVariants,\n                                 CodeGenDAGPatterns &CDP,\n                                 const MultipleUseVarSet &DepVars) {\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants;\n  ChildVariants.push_back(LHS);\n  ChildVariants.push_back(RHS);\n  CombineChildVariants(Orig, ChildVariants, OutVariants, CDP, DepVars);\n}\n\nstatic void\nGatherChildrenOfAssociativeOpcode(TreePatternNodePtr N,\n                                  std::vector<TreePatternNodePtr> &Children) {\n  assert(N->getNumChildren() == 2 &&\n         \"Associative but doesn't have 2 children!\");\n  Record *Operator = N->getOperator();\n\n  // Only permit raw nodes.\n  if (!N->getName().empty() || !N->getPredicateCalls().empty() ||\n      N->getTransformFn()) {\n    Children.push_back(N);\n    return;\n  }\n\n  if (N->getChild(0).isLeaf() || N->getChild(0).getOperator() != Operator)\n    Children.push_back(N->getChildShared(0));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(0), Children);\n\n  if (N->getChild(1).isLeaf() || N->getChild(1).getOperator() != Operator)\n    Children.push_back(N->getChildShared(1));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(1), Children);\n}\n\n/// GenerateVariantsOf - Given a pattern N, generate all permutations we can of\n/// the (potentially recursive) pattern by using algebraic laws.\n///\nstatic void GenerateVariantsOf(TreePatternNodePtr N,\n                               std::vector<TreePatternNodePtr> &OutVariants,\n                               CodeGenDAGPatterns &CDP,\n                               const MultipleUseVarSet &DepVars) {\n  // We cannot permute leaves or ComplexPattern uses.\n  if (N->isLeaf() || N->getOperator()->isSubClassOf(\"ComplexPattern\")) {\n    OutVariants.push_back(N);\n    return;\n  }\n\n  // Look up interesting info about the node.\n  const SDNodeInfo &NodeInfo = CDP.getSDNodeInfo(N->getOperator());\n\n  // If this node is associative, re-associate.\n  if (NodeInfo.hasProperty(SDNPAssociative)) {\n    // Re-associate by pulling together all of the linked operators\n    std::vector<TreePatternNodePtr> MaximalChildren;\n    GatherChildrenOfAssociativeOpcode(N, MaximalChildren);\n\n    // Only handle child sizes of 3.  Otherwise we'll end up trying too many\n    // permutations.\n    if (MaximalChildren.size() == 3) {\n      // Find the variants of all of our maximal children.\n      std::vector<TreePatternNodePtr> AVariants, BVariants, CVariants;\n      GenerateVariantsOf(MaximalChildren[0], AVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[1], BVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[2], CVariants, CDP, DepVars);\n\n      // There are only two ways we can permute the tree:\n      //   (A op B) op C    and    A op (B op C)\n      // Within these forms, we can also permute A/B/C.\n\n      // Generate legal pair permutations of A/B/C.\n      std::vector<TreePatternNodePtr> ABVariants;\n      std::vector<TreePatternNodePtr> BAVariants;\n      std::vector<TreePatternNodePtr> ACVariants;\n      std::vector<TreePatternNodePtr> CAVariants;\n      std::vector<TreePatternNodePtr> BCVariants;\n      std::vector<TreePatternNodePtr> CBVariants;\n      CombineChildVariants(N, AVariants, BVariants, ABVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, AVariants, BAVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CVariants, ACVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, AVariants, CAVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CVariants, BCVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BVariants, CBVariants, CDP, DepVars);\n\n      // Combine those into the result: (x op x) op x\n      CombineChildVariants(N, ABVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BAVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, ACVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CAVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BCVariants, AVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CBVariants, AVariants, OutVariants, CDP, DepVars);\n\n      // Combine those into the result: x op (x op x)\n      CombineChildVariants(N, CVariants, ABVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, ACVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, BCVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CBVariants, OutVariants, CDP, DepVars);\n      return;\n    }\n  }\n\n  // Compute permutations of all children.\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants(\n      N->getNumChildren());\n  for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i)\n    GenerateVariantsOf(N->getChildShared(i), ChildVariants[i], CDP, DepVars);\n\n  // Build all permutations based on how the children were formed.\n  CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n\n  // If this node is commutative, consider the commuted order.\n  bool isCommIntrinsic = N->isCommutativeIntrinsic(CDP);\n  if (NodeInfo.hasProperty(SDNPCommutative) || isCommIntrinsic) {\n    unsigned Skip = isCommIntrinsic ? 1 : 0; // First operand is intrinsic id.\n    assert(N->getNumChildren() >= (2 + Skip) &&\n           \"Commutative but doesn't have 2 children!\");\n    // Don't allow commuting children which are actually register references.\n    bool NoRegisters = true;\n    unsigned i = 0 + Skip;\n    unsigned e = 2 + Skip;\n    for (; i != e; ++i) {\n      TreePatternNode &Child = N->getChild(i);\n      if (Child.isLeaf())\n        if (DefInit *DI = dyn_cast<DefInit>(Child.getLeafValue())) {\n          Record *RR = DI->getDef();\n          if (RR->isSubClassOf(\"Register\"))\n            NoRegisters = false;\n        }\n    }\n    // Consider the commuted order.\n    if (NoRegisters) {\n      // Swap the first two operands after the intrinsic id, if present.\n      unsigned i = isCommIntrinsic ? 1 : 0;\n      std::swap(ChildVariants[i], ChildVariants[i + 1]);\n      CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n    }\n  }\n}\n\n// GenerateVariants - Generate variants.  For example, commutative patterns can\n// match multiple ways.  Add them to PatternsToMatch as well.\nvoid CodeGenDAGPatterns::GenerateVariants() {\n  LLVM_DEBUG(errs() << \"Generating instruction variants.\\n\");\n\n  // Loop over all of the patterns we've collected, checking to see if we can\n  // generate variants of the instruction, through the exploitation of\n  // identities.  This permits the target to provide aggressive matching without\n  // the .td file having to contain tons of variants of instructions.\n  //\n  // Note that this loop adds new patterns to the PatternsToMatch list, but we\n  // intentionally do not reconsider these.  Any variants of added patterns have\n  // already been added.\n  //\n  for (unsigned i = 0, e = PatternsToMatch.size(); i != e; ++i) {\n    MultipleUseVarSet DepVars;\n    std::vector<TreePatternNodePtr> Variants;\n    FindDepVars(PatternsToMatch[i].getSrcPattern(), DepVars);\n    LLVM_DEBUG(errs() << \"Dependent/multiply used variables: \");\n    LLVM_DEBUG(DumpDepVars(DepVars));\n    LLVM_DEBUG(errs() << \"\\n\");\n    GenerateVariantsOf(PatternsToMatch[i].getSrcPatternShared(), Variants,\n                       *this, DepVars);\n\n    assert(PatternsToMatch[i].getHwModeFeatures().empty() &&\n           \"HwModes should not have been expanded yet!\");\n\n    assert(!Variants.empty() && \"Must create at least original variant!\");\n    if (Variants.size() == 1) // No additional variants for this pattern.\n      continue;\n\n    LLVM_DEBUG(errs() << \"FOUND VARIANTS OF: \";\n               PatternsToMatch[i].getSrcPattern().dump(); errs() << \"\\n\");\n\n    for (unsigned v = 0, e = Variants.size(); v != e; ++v) {\n      TreePatternNodePtr Variant = Variants[v];\n\n      LLVM_DEBUG(errs() << \"  VAR#\" << v << \": \"; Variant->dump();\n                 errs() << \"\\n\");\n\n      // Scan to see if an instruction or explicit pattern already matches this.\n      bool AlreadyExists = false;\n      for (unsigned p = 0, e = PatternsToMatch.size(); p != e; ++p) {\n        // Skip if the top level predicates do not match.\n        if ((i != p) && (PatternsToMatch[i].getPredicates() !=\n                         PatternsToMatch[p].getPredicates()))\n          continue;\n        // Check to see if this variant already exists.\n        if (Variant->isIsomorphicTo(PatternsToMatch[p].getSrcPattern(),\n                                    DepVars)) {\n          LLVM_DEBUG(errs() << \"  *** ALREADY EXISTS, ignoring variant.\\n\");\n          AlreadyExists = true;\n          break;\n        }\n      }\n      // If we already have it, ignore the variant.\n      if (AlreadyExists)\n        continue;\n\n      // Otherwise, add it to the list of patterns we have.\n      PatternsToMatch.emplace_back(\n          PatternsToMatch[i].getSrcRecord(), PatternsToMatch[i].getPredicates(),\n          Variant, PatternsToMatch[i].getDstPatternShared(),\n          PatternsToMatch[i].getDstRegs(),\n          PatternsToMatch[i].getAddedComplexity(), Record::getNewUID(Records),\n          PatternsToMatch[i].getHwModeFeatures());\n    }\n\n    LLVM_DEBUG(errs() << \"\\n\");\n  }\n}\n"}], "code": "static void FindDepVars(TreePatternNode &N, MultipleUseVarSet &DepVars) {\n  DepVarMap depcounts;\n  FindDepVarsOf(N, depcounts);\n  for (const auto &Pair : depcounts) {\n    if (Pair.getValue() > 1)\n      DepVars.insert(Pair.getKey());\n  }\n}\n"}, "022B4872CF6D47FE": {"calls": [{"id": "A581A38F2A0CEA51", "name": "llvm::Matcher::getKind", "path": "llvm-project/llvm/utils/TableGen/DAGISelMatcher.h", "start": {"line": 112, "col": 3}, "end": {"line": 112, "col": 41}, "code": "\n  Matcher *getNext() { return Next.get(); }\n  const Matcher *getNext() const { return Next.get(); }\n  void setNext(Matcher *C) { Next.reset(C); }\n  Matcher *takeNext() { return Next.release(); }\n\n  std::unique_ptr<Matcher> &getNextPtr() { return Next; }\n\n  bool isEqual(const Matcher *M) const {\n    if (getKind() != M->getKind())\n      return false;\n    return isEqualImpl(M);\n  }\n\n  /// isSimplePredicateNode - Return true if this is a simple predicate that\n  /// operates on the node or its children without potential side effects or a\n  /// change of the current node.\n  bool isSimplePredicateNode() const {\n    switch (getKind()) {\n    default:\n      return false;\n    case CheckSame:\n    case CheckChildSame:\n    case CheckPatternPredicate:\n    case CheckPredicate:\n    case CheckOpcode:\n    case CheckType:\n    case CheckChildType:\n    case CheckInteger:\n    case CheckChildInteger:\n    case CheckCondCode:\n    case CheckChild2CondCode:\n    case CheckValueType:\n    case CheckAndImm:\n    case CheckOrImm:\n    case CheckImmAllOnesV:\n    case CheckImmAllZerosV:\n    case CheckFoldableChainNode:\n      return true;\n    }\n  }\n\n  /// isSimplePredicateOrRecordNode - Return true if this is a record node or\n  /// a simple predicate.\n  bool isSimplePredicateOrRecordNode() const {\n    return isSimplePredicateNode() || getKind() == RecordNode ||\n           getKind() == RecordChild;\n  }\n\n  /// unlinkNode - Unlink the specified node from this chain.  If Other ==\n  /// this, we unlink the next pointer and return it.  Otherwise we unlink\n  /// Other from the list and return this.\n  Matcher *unlinkNode(Matcher *Other);\n\n  /// canMoveBefore - Return true if this matcher is the same as Other, or if\n  /// we can move this matcher past all of the nodes in-between Other and this\n  /// node.  Other must be equal to or before this.\n  bool canMoveBefore(const Matcher *Other) const;\n\n  /// canMoveBeforeNode - Return true if it is safe to move the current\n  /// matcher across the specified one.\n  bool canMoveBeforeNode(const Matcher *Other) const;\n\n  /// isContradictory - Return true of these two matchers could never match on\n  /// the same node.\n  bool isContradictory(const Matcher *Other) const {\n    // Since this predicate is reflexive, we canonicalize the ordering so that\n    // we always match a node against nodes with kinds that are greater or\n    // equal to them.  For example, we'll pass in a CheckType node as an\n    // argument to the CheckOpcode method, not the other way around.\n    if (getKind() < Other->getKind())\n      return isContradictoryImpl(Other);\n    return Other->isContradictoryImpl(this);\n  }\n\n  void print(raw_ostream &OS, unsigned indent = 0) const;\n  void printOne(raw_ostream &OS) const;\n  void dump() const;\n\nprotected:\n  virtual void printImpl(raw_ostream &OS, unsigned indent) const = 0;\n  virtual bool isEqualImpl(const Matcher *M) const = 0;\n  virtual bool isContradictoryImpl(const Matcher *M) const { return false; }\n};\n\n/// ScopeMatcher - This attempts to match each of its children to find the first\n/// one that successfully matches.  If one child fails, it tries the next child.\n/// If none of the children match then this check fails.  It never has a 'next'.\nclass ScopeMatcher : public Matcher {\n  SmallVector<Matcher *, 4> Children;\n\npublic:\n  ScopeMatcher(SmallVectorImpl<Matcher *> &&children)\n      : Matcher(Scope), Children(std::move(children)) {}\n  ~ScopeMatcher() override;\n\n  unsigned getNumChildren() const { return Children.size(); }\n\n  Matcher *getChild(unsigned i) { return Children[i]; }\n  const Matcher *getChild(unsigned i) const { return Children[i]; }\n\n  void resetChild(unsigned i, Matcher *N) {\n    delete Children[i];\n    Children[i] = N;\n  }\n\n  Matcher *takeChild(unsigned i) {\n    Matcher *Res = Children[i];\n    Children[i] = nullptr;\n    return Res;\n  }\n\n  void setNumChildren(unsigned NC) {\n"}, {"id": "76EB9DEBC6BD37B4", "name": "llvm::Matcher::isContradictoryImpl", "path": "llvm-project/llvm/utils/TableGen/DAGISelMatcher.h", "start": {"line": 195, "col": 3}, "end": {"line": 195, "col": 76}, "code": "};\n\n/// ScopeMatcher - This attempts to match each of its children to find the first\n/// one that successfully matches.  If one child fails, it tries the next child.\n/// If none of the children match then this check fails.  It never has a 'next'.\nclass ScopeMatcher : public Matcher {\n  SmallVector<Matcher *, 4> Children;\n\npublic:\n  ScopeMatcher(SmallVectorImpl<Matcher *> &&children)\n      : Matcher(Scope), Children(std::move(children)) {}\n  ~ScopeMatcher() override;\n\n  unsigned getNumChildren() const { return Children.size(); }\n\n  Matcher *getChild(unsigned i) { return Children[i]; }\n  const Matcher *getChild(unsigned i) const { return Children[i]; }\n\n  void resetChild(unsigned i, Matcher *N) {\n    delete Children[i];\n    Children[i] = N;\n  }\n\n  Matcher *takeChild(unsigned i) {\n    Matcher *Res = Children[i];\n    Children[i] = nullptr;\n    return Res;\n  }\n\n  void setNumChildren(unsigned NC) {\n    if (NC < Children.size()) {\n      // delete any children we're about to lose pointers to.\n      for (unsigned i = NC, e = Children.size(); i != e; ++i)\n        delete Children[i];\n    }\n    Children.resize(NC);\n  }\n\n  static bool classof(const Matcher *N) { return N->getKind() == Scope; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override { return false; }\n};\n\n/// RecordMatcher - Save the current node in the operand list.\nclass RecordMatcher : public Matcher {\n  /// WhatFor - This is a string indicating why we're recording this.  This\n  /// should only be used for comment generation not anything semantic.\n  std::string WhatFor;\n\n  /// ResultNo - The slot number in the RecordedNodes vector that this will be,\n  /// just printed as a comment.\n  unsigned ResultNo;\n\npublic:\n  RecordMatcher(const std::string &whatfor, unsigned resultNo)\n      : Matcher(RecordNode), WhatFor(whatfor), ResultNo(resultNo) {}\n\n  const std::string &getWhatFor() const { return WhatFor; }\n  unsigned getResultNo() const { return ResultNo; }\n\n  static bool classof(const Matcher *N) { return N->getKind() == RecordNode; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override { return true; }\n};\n\n/// RecordChildMatcher - Save a numbered child of the current node, or fail\n/// the match if it doesn't exist.  This is logically equivalent to:\n///    MoveChild N + RecordNode + MoveParent.\nclass RecordChildMatcher : public Matcher {\n  unsigned ChildNo;\n\n  /// WhatFor - This is a string indicating why we're recording this.  This\n  /// should only be used for comment generation not anything semantic.\n  std::string WhatFor;\n\n  /// ResultNo - The slot number in the RecordedNodes vector that this will be,\n  /// just printed as a comment.\n  unsigned ResultNo;\n\npublic:\n  RecordChildMatcher(unsigned childno, const std::string &whatfor,\n                     unsigned resultNo)\n      : Matcher(RecordChild), ChildNo(childno), WhatFor(whatfor),\n        ResultNo(resultNo) {}\n\n  unsigned getChildNo() const { return ChildNo; }\n  const std::string &getWhatFor() const { return WhatFor; }\n  unsigned getResultNo() const { return ResultNo; }\n\n  static bool classof(const Matcher *N) { return N->getKind() == RecordChild; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override {\n    return cast<RecordChildMatcher>(M)->getChildNo() == getChildNo();\n  }\n};\n\n/// RecordMemRefMatcher - Save the current node's memref.\nclass RecordMemRefMatcher : public Matcher {\npublic:\n  RecordMemRefMatcher() : Matcher(RecordMemRef) {}\n\n  static bool classof(const Matcher *N) { return N->getKind() == RecordMemRef; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override { return true; }\n};\n\n/// CaptureGlueInputMatcher - If the current record has a glue input, record\n/// it so that it is used as an input to the generated code.\nclass CaptureGlueInputMatcher : public Matcher {\npublic:\n  CaptureGlueInputMatcher() : Matcher(CaptureGlueInput) {}\n\n  static bool classof(const Matcher *N) {\n    return N->getKind() == CaptureGlueInput;\n  }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override { return true; }\n};\n\n/// MoveChildMatcher - This tells the interpreter to move into the\n/// specified child node.\nclass MoveChildMatcher : public Matcher {\n  unsigned ChildNo;\n\npublic:\n  MoveChildMatcher(unsigned childNo) : Matcher(MoveChild), ChildNo(childNo) {}\n\n  unsigned getChildNo() const { return ChildNo; }\n\n  static bool classof(const Matcher *N) { return N->getKind() == MoveChild; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override {\n    return cast<MoveChildMatcher>(M)->getChildNo() == getChildNo();\n  }\n};\n\n/// MoveSiblingMatcher - This tells the interpreter to move into the\n/// specified sibling node.\nclass MoveSiblingMatcher : public Matcher {\n  unsigned SiblingNo;\n\npublic:\n  MoveSiblingMatcher(unsigned SiblingNo)\n      : Matcher(MoveSibling), SiblingNo(SiblingNo) {}\n\n  unsigned getSiblingNo() const { return SiblingNo; }\n\n  static bool classof(const Matcher *N) { return N->getKind() == MoveSibling; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned Indent) const override;\n  bool isEqualImpl(const Matcher *M) const override {\n    return cast<MoveSiblingMatcher>(M)->getSiblingNo() == getSiblingNo();\n  }\n};\n\n/// MoveParentMatcher - This tells the interpreter to move to the parent\n/// of the current node.\nclass MoveParentMatcher : public Matcher {\npublic:\n  MoveParentMatcher() : Matcher(MoveParent) {}\n\n  static bool classof(const Matcher *N) { return N->getKind() == MoveParent; }\n\nprivate:\n  void printImpl(raw_ostream &OS, unsigned indent) const override;\n  bool isEqualImpl(const Matcher *M) const override { return true; }\n};\n\n/// CheckSameMatcher - This checks to see if this node is exactly the same\n/// node as the specified match that was recorded with 'Record'.  This is used\n/// when patterns have the same name in them, like '(mul GPR:$in, GPR:$in)'.\nclass CheckSameMatcher : public Matcher {\n  unsigned MatchNumber;\n\npublic:\n  CheckSameMatcher(unsigned matchnumber)\n      : Matcher(CheckSame), MatchNumber(matchnumber) {}\n\n  unsigned getMatchNumber() const { return MatchNumber; }\n\n  static bool classof(const Matcher *N) { return N->getKind() == CheckSame; }\n\nprivate:\n"}], "code": "  bool isContradictory(const Matcher *Other) const {\n    // Since this predicate is reflexive, we canonicalize the ordering so that\n    // we always match a node against nodes with kinds that are greater or\n    // equal to them.  For example, we'll pass in a CheckType node as an\n    // argument to the CheckOpcode method, not the other way around.\n    if (getKind() < Other->getKind())\n      return isContradictoryImpl(Other);\n    return Other->isContradictoryImpl(this);\n  }\n"}, "D2DFB13208EA8A37": {"calls": [{"id": "215A6B9A3CFAF965", "name": "llvm::TreePredicateFn::isPredefinedPredicateEqualTo", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp", "start": {"line": 1170, "col": 1}, "end": {"line": 1178, "col": 1}, "code": "                                                   bool Value) const {\n  bool Unset;\n  bool Result =\n      getOrigPatFragRecord()->getRecord()->getValueAsBitOrUnset(Field, Unset);\n  if (Unset)\n    return false;\n  return Result == Value;\n}\nbool TreePredicateFn::usesOperands() const {\n  return isPredefinedPredicateEqualTo(\"PredicateCodeUsesOperands\", true);\n}\nbool TreePredicateFn::hasNoUse() const {\n  return isPredefinedPredicateEqualTo(\"HasNoUse\", true);\n}\nbool TreePredicateFn::isLoad() const {\n  return isPredefinedPredicateEqualTo(\"IsLoad\", true);\n}\nbool TreePredicateFn::isStore() const {\n  return isPredefinedPredicateEqualTo(\"IsStore\", true);\n}\nbool TreePredicateFn::isAtomic() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomic\", true);\n}\nbool TreePredicateFn::isUnindexed() const {\n  return isPredefinedPredicateEqualTo(\"IsUnindexed\", true);\n}\nbool TreePredicateFn::isNonExtLoad() const {\n  return isPredefinedPredicateEqualTo(\"IsNonExtLoad\", true);\n}\nbool TreePredicateFn::isAnyExtLoad() const {\n  return isPredefinedPredicateEqualTo(\"IsAnyExtLoad\", true);\n}\nbool TreePredicateFn::isSignExtLoad() const {\n  return isPredefinedPredicateEqualTo(\"IsSignExtLoad\", true);\n}\nbool TreePredicateFn::isZeroExtLoad() const {\n  return isPredefinedPredicateEqualTo(\"IsZeroExtLoad\", true);\n}\nbool TreePredicateFn::isNonTruncStore() const {\n  return isPredefinedPredicateEqualTo(\"IsTruncStore\", false);\n}\nbool TreePredicateFn::isTruncStore() const {\n  return isPredefinedPredicateEqualTo(\"IsTruncStore\", true);\n}\nbool TreePredicateFn::isAtomicOrderingMonotonic() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingMonotonic\", true);\n}\nbool TreePredicateFn::isAtomicOrderingAcquire() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingAcquire\", true);\n}\nbool TreePredicateFn::isAtomicOrderingRelease() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingRelease\", true);\n}\nbool TreePredicateFn::isAtomicOrderingAcquireRelease() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingAcquireRelease\", true);\n}\nbool TreePredicateFn::isAtomicOrderingSequentiallyConsistent() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingSequentiallyConsistent\",\n                                      true);\n}\nbool TreePredicateFn::isAtomicOrderingAcquireOrStronger() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingAcquireOrStronger\",\n                                      true);\n}\nbool TreePredicateFn::isAtomicOrderingWeakerThanAcquire() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingAcquireOrStronger\",\n                                      false);\n}\nbool TreePredicateFn::isAtomicOrderingReleaseOrStronger() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingReleaseOrStronger\",\n                                      true);\n}\nbool TreePredicateFn::isAtomicOrderingWeakerThanRelease() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingReleaseOrStronger\",\n                                      false);\n}\nRecord *TreePredicateFn::getMemoryVT() const {\n  Record *R = getOrigPatFragRecord()->getRecord();\n  if (R->isValueUnset(\"MemoryVT\"))\n    return nullptr;\n  return R->getValueAsDef(\"MemoryVT\");\n}\n\nListInit *TreePredicateFn::getAddressSpaces() const {\n  Record *R = getOrigPatFragRecord()->getRecord();\n  if (R->isValueUnset(\"AddressSpaces\"))\n    return nullptr;\n  return R->getValueAsListInit(\"AddressSpaces\");\n}\n\nint64_t TreePredicateFn::getMinAlignment() const {\n  Record *R = getOrigPatFragRecord()->getRecord();\n  if (R->isValueUnset(\"MinAlignment\"))\n    return 0;\n  return R->getValueAsInt(\"MinAlignment\");\n}\n\nRecord *TreePredicateFn::getScalarMemoryVT() const {\n  Record *R = getOrigPatFragRecord()->getRecord();\n  if (R->isValueUnset(\"ScalarMemoryVT\"))\n    return nullptr;\n  return R->getValueAsDef(\"ScalarMemoryVT\");\n}\nbool TreePredicateFn::hasGISelPredicateCode() const {\n  return !PatFragRec->getRecord()\n              ->getValueAsString(\"GISelPredicateCode\")\n              .empty();\n}\nstd::string TreePredicateFn::getGISelPredicateCode() const {\n  return std::string(\n      PatFragRec->getRecord()->getValueAsString(\"GISelPredicateCode\"));\n}\n\nStringRef TreePredicateFn::getImmType() const {\n  if (immCodeUsesAPInt())\n    return \"const APInt &\";\n  if (immCodeUsesAPFloat())\n    return \"const APFloat &\";\n  return \"int64_t\";\n}\n\nStringRef TreePredicateFn::getImmTypeIdentifier() const {\n  if (immCodeUsesAPInt())\n    return \"APInt\";\n  if (immCodeUsesAPFloat())\n    return \"APFloat\";\n  return \"I64\";\n}\n\n/// isAlwaysTrue - Return true if this is a noop predicate.\nbool TreePredicateFn::isAlwaysTrue() const {\n  return !hasPredCode() && !hasImmCode();\n}\n\n/// Return the name to use in the generated code to reference this, this is\n/// \"Predicate_foo\" if from a pattern fragment \"foo\".\nstd::string TreePredicateFn::getFnName() const {\n  return \"Predicate_\" + PatFragRec->getRecord()->getName().str();\n}\n\n/// getCodeToRunOnSDNode - Return the code for the function body that\n/// evaluates this predicate.  The argument is expected to be in \"Node\",\n/// not N.  This handles casting and conversion to a concrete node type as\n/// appropriate.\nstd::string TreePredicateFn::getCodeToRunOnSDNode() const {\n  // Handle immediate predicates first.\n  std::string ImmCode = getImmCode();\n  if (!ImmCode.empty()) {\n    if (isLoad())\n      PrintFatalError(getOrigPatFragRecord()->getRecord()->getLoc(),\n                      \"IsLoad cannot be used with ImmLeaf or its subclasses\");\n    if (isStore())\n      PrintFatalError(getOrigPatFragRecord()->getRecord()->getLoc(),\n                      \"IsStore cannot be used with ImmLeaf or its subclasses\");\n    if (isUnindexed())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsUnindexed cannot be used with ImmLeaf or its subclasses\");\n    if (isNonExtLoad())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsNonExtLoad cannot be used with ImmLeaf or its subclasses\");\n    if (isAnyExtLoad())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsAnyExtLoad cannot be used with ImmLeaf or its subclasses\");\n    if (isSignExtLoad())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsSignExtLoad cannot be used with ImmLeaf or its subclasses\");\n    if (isZeroExtLoad())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsZeroExtLoad cannot be used with ImmLeaf or its subclasses\");\n    if (isNonTruncStore())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsNonTruncStore cannot be used with ImmLeaf or its subclasses\");\n    if (isTruncStore())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"IsTruncStore cannot be used with ImmLeaf or its subclasses\");\n    if (getMemoryVT())\n      PrintFatalError(getOrigPatFragRecord()->getRecord()->getLoc(),\n                      \"MemoryVT cannot be used with ImmLeaf or its subclasses\");\n    if (getScalarMemoryVT())\n      PrintFatalError(\n          getOrigPatFragRecord()->getRecord()->getLoc(),\n          \"ScalarMemoryVT cannot be used with ImmLeaf or its subclasses\");\n\n    std::string Result = (\"    \" + getImmType() + \" Imm = \").str();\n    if (immCodeUsesAPFloat())\n      Result += \"cast<ConstantFPSDNode>(Node)->getValueAPF();\\n\";\n    else if (immCodeUsesAPInt())\n      Result += \"Node->getAsAPIntVal();\\n\";\n    else\n      Result += \"cast<ConstantSDNode>(Node)->getSExtValue();\\n\";\n    return Result + ImmCode;\n  }\n\n  // Handle arbitrary node predicates.\n  assert(hasPredCode() && \"Don't have any predicate code!\");\n\n  // If this is using PatFrags, there are multiple trees to search. They should\n  // all have the same class.  FIXME: Is there a way to find a common\n  // superclass?\n  StringRef ClassName;\n  for (const auto &Tree : PatFragRec->getTrees()) {\n    StringRef TreeClassName;\n    if (Tree->isLeaf())\n      TreeClassName = \"SDNode\";\n    else {\n      Record *Op = Tree->getOperator();\n      const SDNodeInfo &Info = PatFragRec->getDAGPatterns().getSDNodeInfo(Op);\n      TreeClassName = Info.getSDClassName();\n    }\n\n    if (ClassName.empty())\n      ClassName = TreeClassName;\n    else if (ClassName != TreeClassName) {\n      PrintFatalError(getOrigPatFragRecord()->getRecord()->getLoc(),\n                      \"PatFrags trees do not have consistent class\");\n    }\n  }\n\n  std::string Result;\n  if (ClassName == \"SDNode\")\n    Result = \"    SDNode *N = Node;\\n\";\n  else\n    Result = \"    auto *N = cast<\" + ClassName.str() + \">(Node);\\n\";\n\n  return (Twine(Result) + \"    (void)N;\\n\" + getPredCode()).str();\n}\n\n//===----------------------------------------------------------------------===//\n// PatternToMatch implementation\n//\n\nstatic bool isImmAllOnesAllZerosMatch(const TreePatternNode &P) {\n  if (!P.isLeaf())\n    return false;\n  DefInit *DI = dyn_cast<DefInit>(P.getLeafValue());\n  if (!DI)\n    return false;\n\n  Record *R = DI->getDef();\n  return R->getName() == \"immAllOnesV\" || R->getName() == \"immAllZerosV\";\n}\n\n/// getPatternSize - Return the 'size' of this pattern.  We want to match large\n/// patterns before small ones.  This is used to determine the size of a\n/// pattern.\nstatic unsigned getPatternSize(const TreePatternNode &P,\n                               const CodeGenDAGPatterns &CGP) {\n  unsigned Size = 3; // The node itself.\n  // If the root node is a ConstantSDNode, increases its size.\n  // e.g. (set R32:$dst, 0).\n  if (P.isLeaf() && isa<IntInit>(P.getLeafValue()))\n    Size += 2;\n\n  if (const ComplexPattern *AM = P.getComplexPatternInfo(CGP)) {\n    Size += AM->getComplexity();\n    // We don't want to count any children twice, so return early.\n    return Size;\n  }\n\n  // If this node has some predicate function that must match, it adds to the\n  // complexity of this node.\n  if (!P.getPredicateCalls().empty())\n    ++Size;\n\n  // Count children in the count if they are also nodes.\n  for (unsigned i = 0, e = P.getNumChildren(); i != e; ++i) {\n    const TreePatternNode &Child = P.getChild(i);\n    if (!Child.isLeaf() && Child.getNumTypes()) {\n      const TypeSetByHwMode &T0 = Child.getExtType(0);\n      // At this point, all variable type sets should be simple, i.e. only\n      // have a default mode.\n      if (T0.getMachineValueType() != MVT::Other) {\n        Size += getPatternSize(Child, CGP);\n        continue;\n      }\n    }\n    if (Child.isLeaf()) {\n      if (isa<IntInit>(Child.getLeafValue()))\n        Size += 5; // Matches a ConstantSDNode (+3) and a specific value (+2).\n      else if (Child.getComplexPatternInfo(CGP))\n        Size += getPatternSize(Child, CGP);\n      else if (isImmAllOnesAllZerosMatch(Child))\n        Size += 4; // Matches a build_vector(+3) and a predicate (+1).\n      else if (!Child.getPredicateCalls().empty())\n        ++Size;\n    }\n  }\n\n  return Size;\n}\n\n/// Compute the complexity metric for the input pattern.  This roughly\n/// corresponds to the number of nodes that are covered.\nint PatternToMatch::getPatternComplexity(const CodeGenDAGPatterns &CGP) const {\n  return getPatternSize(getSrcPattern(), CGP) + getAddedComplexity();\n}\n\nvoid PatternToMatch::getPredicateRecords(\n    SmallVectorImpl<Record *> &PredicateRecs) const {\n  for (Init *I : Predicates->getValues()) {\n    if (DefInit *Pred = dyn_cast<DefInit>(I)) {\n      Record *Def = Pred->getDef();\n      if (!Def->isSubClassOf(\"Predicate\")) {\n#ifndef NDEBUG\n        Def->dump();\n#endif\n        llvm_unreachable(\"Unknown predicate type!\");\n      }\n      PredicateRecs.push_back(Def);\n    }\n  }\n  // Sort so that different orders get canonicalized to the same string.\n  llvm::sort(PredicateRecs, LessRecord());\n  // Remove duplicate predicates.\n  PredicateRecs.erase(std::unique(PredicateRecs.begin(), PredicateRecs.end()),\n                      PredicateRecs.end());\n}\n\n/// getPredicateCheck - Return a single string containing all of this\n/// pattern's predicates concatenated with \"&&\" operators.\n///\nstd::string PatternToMatch::getPredicateCheck() const {\n  SmallVector<Record *, 4> PredicateRecs;\n  getPredicateRecords(PredicateRecs);\n\n  SmallString<128> PredicateCheck;\n  raw_svector_ostream OS(PredicateCheck);\n  ListSeparator LS(\" && \");\n  for (Record *Pred : PredicateRecs) {\n    StringRef CondString = Pred->getValueAsString(\"CondString\");\n    if (CondString.empty())\n      continue;\n    OS << LS << '(' << CondString << ')';\n  }\n\n  if (!HwModeFeatures.empty())\n    OS << LS << HwModeFeatures;\n\n  return std::string(PredicateCheck);\n}\n\n//===----------------------------------------------------------------------===//\n// SDTypeConstraint implementation\n//\n\nSDTypeConstraint::SDTypeConstraint(Record *R, const CodeGenHwModes &CGH) {\n  OperandNo = R->getValueAsInt(\"OperandNum\");\n\n  if (R->isSubClassOf(\"SDTCisVT\")) {\n    ConstraintType = SDTCisVT;\n    VVT = getValueTypeByHwMode(R->getValueAsDef(\"VT\"), CGH);\n    for (const auto &P : VVT)\n      if (P.second == MVT::isVoid)\n        PrintFatalError(R->getLoc(), \"Cannot use 'Void' as type to SDTCisVT\");\n  } else if (R->isSubClassOf(\"SDTCisPtrTy\")) {\n    ConstraintType = SDTCisPtrTy;\n  } else if (R->isSubClassOf(\"SDTCisInt\")) {\n    ConstraintType = SDTCisInt;\n  } else if (R->isSubClassOf(\"SDTCisFP\")) {\n    ConstraintType = SDTCisFP;\n  } else if (R->isSubClassOf(\"SDTCisVec\")) {\n    ConstraintType = SDTCisVec;\n  } else if (R->isSubClassOf(\"SDTCisSameAs\")) {\n    ConstraintType = SDTCisSameAs;\n    x.SDTCisSameAs_Info.OtherOperandNum = R->getValueAsInt(\"OtherOperandNum\");\n  } else if (R->isSubClassOf(\"SDTCisVTSmallerThanOp\")) {\n    ConstraintType = SDTCisVTSmallerThanOp;\n    x.SDTCisVTSmallerThanOp_Info.OtherOperandNum =\n        R->getValueAsInt(\"OtherOperandNum\");\n  } else if (R->isSubClassOf(\"SDTCisOpSmallerThanOp\")) {\n    ConstraintType = SDTCisOpSmallerThanOp;\n    x.SDTCisOpSmallerThanOp_Info.BigOperandNum =\n        R->getValueAsInt(\"BigOperandNum\");\n  } else if (R->isSubClassOf(\"SDTCisEltOfVec\")) {\n    ConstraintType = SDTCisEltOfVec;\n    x.SDTCisEltOfVec_Info.OtherOperandNum = R->getValueAsInt(\"OtherOpNum\");\n  } else if (R->isSubClassOf(\"SDTCisSubVecOfVec\")) {\n    ConstraintType = SDTCisSubVecOfVec;\n    x.SDTCisSubVecOfVec_Info.OtherOperandNum = R->getValueAsInt(\"OtherOpNum\");\n  } else if (R->isSubClassOf(\"SDTCVecEltisVT\")) {\n    ConstraintType = SDTCVecEltisVT;\n    VVT = getValueTypeByHwMode(R->getValueAsDef(\"VT\"), CGH);\n    for (const auto &P : VVT) {\n      MVT T = P.second;\n      if (T.isVector())\n        PrintFatalError(R->getLoc(),\n                        \"Cannot use vector type as SDTCVecEltisVT\");\n      if (!T.isInteger() && !T.isFloatingPoint())\n        PrintFatalError(R->getLoc(), \"Must use integer or floating point type \"\n                                     \"as SDTCVecEltisVT\");\n    }\n  } else if (R->isSubClassOf(\"SDTCisSameNumEltsAs\")) {\n    ConstraintType = SDTCisSameNumEltsAs;\n    x.SDTCisSameNumEltsAs_Info.OtherOperandNum =\n        R->getValueAsInt(\"OtherOperandNum\");\n  } else if (R->isSubClassOf(\"SDTCisSameSizeAs\")) {\n    ConstraintType = SDTCisSameSizeAs;\n    x.SDTCisSameSizeAs_Info.OtherOperandNum =\n        R->getValueAsInt(\"OtherOperandNum\");\n  } else {\n    PrintFatalError(R->getLoc(),\n                    \"Unrecognized SDTypeConstraint '\" + R->getName() + \"'!\\n\");\n  }\n}\n\n/// getOperandNum - Return the node corresponding to operand #OpNo in tree\n/// N, and the result number in ResNo.\nstatic TreePatternNode &getOperandNum(unsigned OpNo, TreePatternNode &N,\n                                      const SDNodeInfo &NodeInfo,\n                                      unsigned &ResNo) {\n  unsigned NumResults = NodeInfo.getNumResults();\n  if (OpNo < NumResults) {\n    ResNo = OpNo;\n    return N;\n  }\n\n  OpNo -= NumResults;\n\n  if (OpNo >= N.getNumChildren()) {\n    std::string S;\n    raw_string_ostream OS(S);\n    OS << \"Invalid operand number in type constraint \" << (OpNo + NumResults)\n       << \" \";\n    N.print(OS);\n    PrintFatalError(S);\n  }\n\n  return N.getChild(OpNo);\n}\n\n/// ApplyTypeConstraint - Given a node in a pattern, apply this type\n/// constraint to the nodes operands.  This returns true if it makes a\n/// change, false otherwise.  If a type contradiction is found, flag an error.\nbool SDTypeConstraint::ApplyTypeConstraint(TreePatternNode &N,\n                                           const SDNodeInfo &NodeInfo,\n                                           TreePattern &TP) const {\n  if (TP.hasError())\n    return false;\n\n  unsigned ResNo = 0; // The result number being referenced.\n  TreePatternNode &NodeToApply = getOperandNum(OperandNo, N, NodeInfo, ResNo);\n  TypeInfer &TI = TP.getInfer();\n\n  switch (ConstraintType) {\n  case SDTCisVT:\n    // Operand must be a particular type.\n    return NodeToApply.UpdateNodeType(ResNo, VVT, TP);\n  case SDTCisPtrTy:\n    // Operand must be same as target pointer type.\n    return NodeToApply.UpdateNodeType(ResNo, MVT::iPTR, TP);\n  case SDTCisInt:\n    // Require it to be one of the legal integer VTs.\n    return TI.EnforceInteger(NodeToApply.getExtType(ResNo));\n  case SDTCisFP:\n    // Require it to be one of the legal fp VTs.\n    return TI.EnforceFloatingPoint(NodeToApply.getExtType(ResNo));\n  case SDTCisVec:\n    // Require it to be one of the legal vector VTs.\n    return TI.EnforceVector(NodeToApply.getExtType(ResNo));\n  case SDTCisSameAs: {\n    unsigned OResNo = 0;\n    TreePatternNode &OtherNode =\n        getOperandNum(x.SDTCisSameAs_Info.OtherOperandNum, N, NodeInfo, OResNo);\n    return (int)NodeToApply.UpdateNodeType(ResNo, OtherNode.getExtType(OResNo),\n                                           TP) |\n           (int)OtherNode.UpdateNodeType(OResNo, NodeToApply.getExtType(ResNo),\n                                         TP);\n  }\n  case SDTCisVTSmallerThanOp: {\n    // The NodeToApply must be a leaf node that is a VT.  OtherOperandNum must\n    // have an integer type that is smaller than the VT.\n    if (!NodeToApply.isLeaf() || !isa<DefInit>(NodeToApply.getLeafValue()) ||\n        !cast<DefInit>(NodeToApply.getLeafValue())\n             ->getDef()\n             ->isSubClassOf(\"ValueType\")) {\n      TP.error(N.getOperator()->getName() + \" expects a VT operand!\");\n      return false;\n    }\n    DefInit *DI = cast<DefInit>(NodeToApply.getLeafValue());\n    const CodeGenTarget &T = TP.getDAGPatterns().getTargetInfo();\n    auto VVT = getValueTypeByHwMode(DI->getDef(), T.getHwModes());\n    TypeSetByHwMode TypeListTmp(VVT);\n\n    unsigned OResNo = 0;\n    TreePatternNode &OtherNode = getOperandNum(\n        x.SDTCisVTSmallerThanOp_Info.OtherOperandNum, N, NodeInfo, OResNo);\n\n    return TI.EnforceSmallerThan(TypeListTmp, OtherNode.getExtType(OResNo),\n                                 /*SmallIsVT*/ true);\n  }\n  case SDTCisOpSmallerThanOp: {\n    unsigned BResNo = 0;\n    TreePatternNode &BigOperand = getOperandNum(\n        x.SDTCisOpSmallerThanOp_Info.BigOperandNum, N, NodeInfo, BResNo);\n    return TI.EnforceSmallerThan(NodeToApply.getExtType(ResNo),\n                                 BigOperand.getExtType(BResNo));\n  }\n  case SDTCisEltOfVec: {\n    unsigned VResNo = 0;\n    TreePatternNode &VecOperand = getOperandNum(\n        x.SDTCisEltOfVec_Info.OtherOperandNum, N, NodeInfo, VResNo);\n    // Filter vector types out of VecOperand that don't have the right element\n    // type.\n    return TI.EnforceVectorEltTypeIs(VecOperand.getExtType(VResNo),\n                                     NodeToApply.getExtType(ResNo));\n  }\n  case SDTCisSubVecOfVec: {\n    unsigned VResNo = 0;\n    TreePatternNode &BigVecOperand = getOperandNum(\n        x.SDTCisSubVecOfVec_Info.OtherOperandNum, N, NodeInfo, VResNo);\n\n    // Filter vector types out of BigVecOperand that don't have the\n    // right subvector type.\n    return TI.EnforceVectorSubVectorTypeIs(BigVecOperand.getExtType(VResNo),\n                                           NodeToApply.getExtType(ResNo));\n  }\n  case SDTCVecEltisVT: {\n    return TI.EnforceVectorEltTypeIs(NodeToApply.getExtType(ResNo), VVT);\n  }\n  case SDTCisSameNumEltsAs: {\n    unsigned OResNo = 0;\n    TreePatternNode &OtherNode = getOperandNum(\n        x.SDTCisSameNumEltsAs_Info.OtherOperandNum, N, NodeInfo, OResNo);\n    return TI.EnforceSameNumElts(OtherNode.getExtType(OResNo),\n                                 NodeToApply.getExtType(ResNo));\n  }\n  case SDTCisSameSizeAs: {\n    unsigned OResNo = 0;\n    TreePatternNode &OtherNode = getOperandNum(\n        x.SDTCisSameSizeAs_Info.OtherOperandNum, N, NodeInfo, OResNo);\n    return TI.EnforceSameSize(OtherNode.getExtType(OResNo),\n                              NodeToApply.getExtType(ResNo));\n  }\n  }\n  llvm_unreachable(\"Invalid ConstraintType!\");\n}\n\n// Update the node type to match an instruction operand or result as specified\n// in the ins or outs lists on the instruction definition. Return true if the\n// type was actually changed.\nbool TreePatternNode::UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand,\n                                             TreePattern &TP) {\n  // The 'unknown' operand indicates that types should be inferred from the\n  // context.\n  if (Operand->isSubClassOf(\"unknown_class\"))\n    return false;\n\n  // The Operand class specifies a type directly.\n  if (Operand->isSubClassOf(\"Operand\")) {\n    Record *R = Operand->getValueAsDef(\"Type\");\n    const CodeGenTarget &T = TP.getDAGPatterns().getTargetInfo();\n    return UpdateNodeType(ResNo, getValueTypeByHwMode(R, T.getHwModes()), TP);\n  }\n\n  // PointerLikeRegClass has a type that is determined at runtime.\n  if (Operand->isSubClassOf(\"PointerLikeRegClass\"))\n    return UpdateNodeType(ResNo, MVT::iPTR, TP);\n\n  // Both RegisterClass and RegisterOperand operands derive their types from a\n  // register class def.\n  Record *RC = nullptr;\n  if (Operand->isSubClassOf(\"RegisterClass\"))\n    RC = Operand;\n  else if (Operand->isSubClassOf(\"RegisterOperand\"))\n    RC = Operand->getValueAsDef(\"RegClass\");\n\n  assert(RC && \"Unknown operand type\");\n  CodeGenTarget &Tgt = TP.getDAGPatterns().getTargetInfo();\n  return UpdateNodeType(ResNo, Tgt.getRegisterClass(RC).getValueTypes(), TP);\n}\n\nbool TreePatternNode::ContainsUnresolvedType(TreePattern &TP) const {\n  for (unsigned i = 0, e = Types.size(); i != e; ++i)\n    if (!TP.getInfer().isConcrete(Types[i], true))\n      return true;\n  for (unsigned i = 0, e = getNumChildren(); i != e; ++i)\n    if (getChild(i).ContainsUnresolvedType(TP))\n      return true;\n  return false;\n}\n\nbool TreePatternNode::hasProperTypeByHwMode() const {\n  for (const TypeSetByHwMode &S : Types)\n    if (!S.isSimple())\n      return true;\n  for (const TreePatternNodePtr &C : Children)\n    if (C->hasProperTypeByHwMode())\n      return true;\n  return false;\n}\n\nbool TreePatternNode::hasPossibleType() const {\n  for (const TypeSetByHwMode &S : Types)\n    if (!S.isPossible())\n      return false;\n  for (const TreePatternNodePtr &C : Children)\n    if (!C->hasPossibleType())\n      return false;\n  return true;\n}\n\nbool TreePatternNode::setDefaultMode(unsigned Mode) {\n  for (TypeSetByHwMode &S : Types) {\n    S.makeSimple(Mode);\n    // Check if the selected mode had a type conflict.\n    if (S.get(DefaultMode).empty())\n      return false;\n  }\n  for (const TreePatternNodePtr &C : Children)\n    if (!C->setDefaultMode(Mode))\n      return false;\n  return true;\n}\n\n//===----------------------------------------------------------------------===//\n// SDNodeInfo implementation\n//\nSDNodeInfo::SDNodeInfo(Record *R, const CodeGenHwModes &CGH) : Def(R) {\n  EnumName = R->getValueAsString(\"Opcode\");\n  SDClassName = R->getValueAsString(\"SDClass\");\n  Record *TypeProfile = R->getValueAsDef(\"TypeProfile\");\n  NumResults = TypeProfile->getValueAsInt(\"NumResults\");\n  NumOperands = TypeProfile->getValueAsInt(\"NumOperands\");\n\n  // Parse the properties.\n  Properties = parseSDPatternOperatorProperties(R);\n\n  // Parse the type constraints.\n  std::vector<Record *> ConstraintList =\n      TypeProfile->getValueAsListOfDefs(\"Constraints\");\n  for (Record *R : ConstraintList)\n    TypeConstraints.emplace_back(R, CGH);\n}\n\n/// getKnownType - If the type constraints on this node imply a fixed type\n/// (e.g. all stores return void, etc), then return it as an\n/// MVT::SimpleValueType.  Otherwise, return EEVT::Other.\nMVT::SimpleValueType SDNodeInfo::getKnownType(unsigned ResNo) const {\n  unsigned NumResults = getNumResults();\n  assert(NumResults <= 1 &&\n         \"We only work with nodes with zero or one result so far!\");\n  assert(ResNo == 0 && \"Only handles single result nodes so far\");\n\n  for (const SDTypeConstraint &Constraint : TypeConstraints) {\n    // Make sure that this applies to the correct node result.\n    if (Constraint.OperandNo >= NumResults) // FIXME: need value #\n      continue;\n\n    switch (Constraint.ConstraintType) {\n    default:\n      break;\n    case SDTypeConstraint::SDTCisVT:\n      if (Constraint.VVT.isSimple())\n        return Constraint.VVT.getSimple().SimpleTy;\n      break;\n    case SDTypeConstraint::SDTCisPtrTy:\n      return MVT::iPTR;\n    }\n  }\n  return MVT::Other;\n}\n\n//===----------------------------------------------------------------------===//\n// TreePatternNode implementation\n//\n\nstatic unsigned GetNumNodeResults(Record *Operator, CodeGenDAGPatterns &CDP) {\n  if (Operator->getName() == \"set\" || Operator->getName() == \"implicit\")\n    return 0; // All return nothing.\n\n  if (Operator->isSubClassOf(\"Intrinsic\"))\n    return CDP.getIntrinsic(Operator).IS.RetTys.size();\n\n  if (Operator->isSubClassOf(\"SDNode\"))\n    return CDP.getSDNodeInfo(Operator).getNumResults();\n\n  if (Operator->isSubClassOf(\"PatFrags\")) {\n    // If we've already parsed this pattern fragment, get it.  Otherwise, handle\n    // the forward reference case where one pattern fragment references another\n    // before it is processed.\n    if (TreePattern *PFRec = CDP.getPatternFragmentIfRead(Operator)) {\n      // The number of results of a fragment with alternative records is the\n      // maximum number of results across all alternatives.\n      unsigned NumResults = 0;\n      for (const auto &T : PFRec->getTrees())\n        NumResults = std::max(NumResults, T->getNumTypes());\n      return NumResults;\n    }\n\n    ListInit *LI = Operator->getValueAsListInit(\"Fragments\");\n    assert(LI && \"Invalid Fragment\");\n    unsigned NumResults = 0;\n    for (Init *I : LI->getValues()) {\n      Record *Op = nullptr;\n      if (DagInit *Dag = dyn_cast<DagInit>(I))\n        if (DefInit *DI = dyn_cast<DefInit>(Dag->getOperator()))\n          Op = DI->getDef();\n      assert(Op && \"Invalid Fragment\");\n      NumResults = std::max(NumResults, GetNumNodeResults(Op, CDP));\n    }\n    return NumResults;\n  }\n\n  if (Operator->isSubClassOf(\"Instruction\")) {\n    CodeGenInstruction &InstInfo = CDP.getTargetInfo().getInstruction(Operator);\n\n    unsigned NumDefsToAdd = InstInfo.Operands.NumDefs;\n\n    // Subtract any defaulted outputs.\n    for (unsigned i = 0; i != InstInfo.Operands.NumDefs; ++i) {\n      Record *OperandNode = InstInfo.Operands[i].Rec;\n\n      if (OperandNode->isSubClassOf(\"OperandWithDefaultOps\") &&\n          !CDP.getDefaultOperand(OperandNode).DefaultOps.empty())\n        --NumDefsToAdd;\n    }\n\n    // Add on one implicit def if it has a resolvable type.\n    if (InstInfo.HasOneImplicitDefWithKnownVT(CDP.getTargetInfo()) !=\n        MVT::Other)\n      ++NumDefsToAdd;\n    return NumDefsToAdd;\n  }\n\n  if (Operator->isSubClassOf(\"SDNodeXForm\"))\n    return 1; // FIXME: Generalize SDNodeXForm\n\n  if (Operator->isSubClassOf(\"ValueType\"))\n    return 1; // A type-cast of one result.\n\n  if (Operator->isSubClassOf(\"ComplexPattern\"))\n    return 1;\n\n  errs() << *Operator;\n  PrintFatalError(\"Unhandled node in GetNumNodeResults\");\n}\n\nvoid TreePatternNode::print(raw_ostream &OS) const {\n  if (isLeaf())\n    OS << *getLeafValue();\n  else\n    OS << '(' << getOperator()->getName();\n\n  for (unsigned i = 0, e = Types.size(); i != e; ++i) {\n    OS << ':';\n    getExtType(i).writeToStream(OS);\n  }\n\n  if (!isLeaf()) {\n    if (getNumChildren() != 0) {\n      OS << \" \";\n      ListSeparator LS;\n      for (unsigned i = 0, e = getNumChildren(); i != e; ++i) {\n        OS << LS;\n        getChild(i).print(OS);\n      }\n    }\n    OS << \")\";\n  }\n\n  for (const TreePredicateCall &Pred : PredicateCalls) {\n    OS << \"<<P:\";\n    if (Pred.Scope)\n      OS << Pred.Scope << \":\";\n    OS << Pred.Fn.getFnName() << \">>\";\n  }\n  if (TransformFn)\n    OS << \"<<X:\" << TransformFn->getName() << \">>\";\n  if (!getName().empty())\n    OS << \":$\" << getName();\n\n  for (const ScopedName &Name : NamesAsPredicateArg)\n    OS << \":$pred:\" << Name.getScope() << \":\" << Name.getIdentifier();\n}\nvoid TreePatternNode::dump() const { print(errs()); }\n\n/// isIsomorphicTo - Return true if this node is recursively\n/// isomorphic to the specified node.  For this comparison, the node's\n/// entire state is considered. The assigned name is ignored, since\n/// nodes with differing names are considered isomorphic. However, if\n/// the assigned name is present in the dependent variable set, then\n/// the assigned name is considered significant and the node is\n/// isomorphic if the names match.\nbool TreePatternNode::isIsomorphicTo(const TreePatternNode &N,\n                                     const MultipleUseVarSet &DepVars) const {\n  if (&N == this)\n    return true;\n  if (N.isLeaf() != isLeaf())\n    return false;\n\n  // Check operator of non-leaves early since it can be cheaper than checking\n  // types.\n  if (!isLeaf())\n    if (N.getOperator() != getOperator() ||\n        N.getNumChildren() != getNumChildren())\n      return false;\n\n  if (getExtTypes() != N.getExtTypes() ||\n      getPredicateCalls() != N.getPredicateCalls() ||\n      getTransformFn() != N.getTransformFn())\n    return false;\n\n  if (isLeaf()) {\n    if (DefInit *DI = dyn_cast<DefInit>(getLeafValue())) {\n      if (DefInit *NDI = dyn_cast<DefInit>(N.getLeafValue())) {\n        return ((DI->getDef() == NDI->getDef()) &&\n                (!DepVars.contains(getName()) || getName() == N.getName()));\n      }\n    }\n    return getLeafValue() == N.getLeafValue();\n  }\n\n  for (unsigned i = 0, e = getNumChildren(); i != e; ++i)\n    if (!getChild(i).isIsomorphicTo(N.getChild(i), DepVars))\n      return false;\n  return true;\n}\n\n/// clone - Make a copy of this tree and all of its children.\n///\nTreePatternNodePtr TreePatternNode::clone() const {\n  TreePatternNodePtr New;\n  if (isLeaf()) {\n    New = makeIntrusiveRefCnt<TreePatternNode>(getLeafValue(), getNumTypes());\n  } else {\n    std::vector<TreePatternNodePtr> CChildren;\n    CChildren.reserve(Children.size());\n    for (unsigned i = 0, e = getNumChildren(); i != e; ++i)\n      CChildren.push_back(getChild(i).clone());\n    New = makeIntrusiveRefCnt<TreePatternNode>(\n        getOperator(), std::move(CChildren), getNumTypes());\n  }\n  New->setName(getName());\n  New->setNamesAsPredicateArg(getNamesAsPredicateArg());\n  New->Types = Types;\n  New->setPredicateCalls(getPredicateCalls());\n  New->setGISelFlagsRecord(getGISelFlagsRecord());\n  New->setTransformFn(getTransformFn());\n  return New;\n}\n\n/// RemoveAllTypes - Recursively strip all the types of this tree.\nvoid TreePatternNode::RemoveAllTypes() {\n  // Reset to unknown type.\n  std::fill(Types.begin(), Types.end(), TypeSetByHwMode());\n  if (isLeaf())\n    return;\n  for (unsigned i = 0, e = getNumChildren(); i != e; ++i)\n    getChild(i).RemoveAllTypes();\n}\n\n/// SubstituteFormalArguments - Replace the formal arguments in this tree\n/// with actual values specified by ArgMap.\nvoid TreePatternNode::SubstituteFormalArguments(\n    std::map<std::string, TreePatternNodePtr> &ArgMap) {\n  if (isLeaf())\n    return;\n\n  for (unsigned i = 0, e = getNumChildren(); i != e; ++i) {\n    TreePatternNode &Child = getChild(i);\n    if (Child.isLeaf()) {\n      Init *Val = Child.getLeafValue();\n      // Note that, when substituting into an output pattern, Val might be an\n      // UnsetInit.\n      if (isa<UnsetInit>(Val) ||\n          (isa<DefInit>(Val) &&\n           cast<DefInit>(Val)->getDef()->getName() == \"node\")) {\n        // We found a use of a formal argument, replace it with its value.\n        TreePatternNodePtr NewChild = ArgMap[Child.getName()];\n        assert(NewChild && \"Couldn't find formal argument!\");\n        assert((Child.getPredicateCalls().empty() ||\n                NewChild->getPredicateCalls() == Child.getPredicateCalls()) &&\n               \"Non-empty child predicate clobbered!\");\n        setChild(i, std::move(NewChild));\n      }\n    } else {\n      getChild(i).SubstituteFormalArguments(ArgMap);\n    }\n  }\n}\n\n/// InlinePatternFragments - If this pattern refers to any pattern\n/// fragments, return the set of inlined versions (this can be more than\n/// one if a PatFrags record has multiple alternatives).\nvoid TreePatternNode::InlinePatternFragments(\n    TreePattern &TP, std::vector<TreePatternNodePtr> &OutAlternatives) {\n\n  if (TP.hasError())\n    return;\n\n  if (isLeaf()) {\n    OutAlternatives.push_back(this); // nothing to do.\n    return;\n  }\n\n  Record *Op = getOperator();\n\n  if (!Op->isSubClassOf(\"PatFrags\")) {\n    if (getNumChildren() == 0) {\n      OutAlternatives.push_back(this);\n      return;\n    }\n\n    // Recursively inline children nodes.\n    std::vector<std::vector<TreePatternNodePtr>> ChildAlternatives(\n        getNumChildren());\n    for (unsigned i = 0, e = getNumChildren(); i != e; ++i) {\n      TreePatternNodePtr Child = getChildShared(i);\n      Child->InlinePatternFragments(TP, ChildAlternatives[i]);\n      // If there are no alternatives for any child, there are no\n      // alternatives for this expression as whole.\n      if (ChildAlternatives[i].empty())\n        return;\n\n      assert((Child->getPredicateCalls().empty() ||\n              llvm::all_of(ChildAlternatives[i],\n                           [&](const TreePatternNodePtr &NewChild) {\n                             return NewChild->getPredicateCalls() ==\n                                    Child->getPredicateCalls();\n                           })) &&\n             \"Non-empty child predicate clobbered!\");\n    }\n\n    // The end result is an all-pairs construction of the resultant pattern.\n    std::vector<unsigned> Idxs(ChildAlternatives.size());\n    bool NotDone;\n    do {\n      // Create the variant and add it to the output list.\n      std::vector<TreePatternNodePtr> NewChildren;\n      NewChildren.reserve(ChildAlternatives.size());\n      for (unsigned i = 0, e = ChildAlternatives.size(); i != e; ++i)\n        NewChildren.push_back(ChildAlternatives[i][Idxs[i]]);\n      TreePatternNodePtr R = makeIntrusiveRefCnt<TreePatternNode>(\n          getOperator(), std::move(NewChildren), getNumTypes());\n\n      // Copy over properties.\n      R->setName(getName());\n      R->setNamesAsPredicateArg(getNamesAsPredicateArg());\n      R->setPredicateCalls(getPredicateCalls());\n      R->setGISelFlagsRecord(getGISelFlagsRecord());\n      R->setTransformFn(getTransformFn());\n      for (unsigned i = 0, e = getNumTypes(); i != e; ++i)\n        R->setType(i, getExtType(i));\n      for (unsigned i = 0, e = getNumResults(); i != e; ++i)\n        R->setResultIndex(i, getResultIndex(i));\n\n      // Register alternative.\n      OutAlternatives.push_back(R);\n\n      // Increment indices to the next permutation by incrementing the\n      // indices from last index backward, e.g., generate the sequence\n      // [0, 0], [0, 1], [1, 0], [1, 1].\n      int IdxsIdx;\n      for (IdxsIdx = Idxs.size() - 1; IdxsIdx >= 0; --IdxsIdx) {\n        if (++Idxs[IdxsIdx] == ChildAlternatives[IdxsIdx].size())\n          Idxs[IdxsIdx] = 0;\n        else\n          break;\n      }\n      NotDone = (IdxsIdx >= 0);\n    } while (NotDone);\n\n    return;\n  }\n\n  // Otherwise, we found a reference to a fragment.  First, look up its\n  // TreePattern record.\n  TreePattern *Frag = TP.getDAGPatterns().getPatternFragment(Op);\n\n  // Verify that we are passing the right number of operands.\n  if (Frag->getNumArgs() != getNumChildren()) {\n    TP.error(\"'\" + Op->getName() + \"' fragment requires \" +\n             Twine(Frag->getNumArgs()) + \" operands!\");\n    return;\n  }\n\n  TreePredicateFn PredFn(Frag);\n  unsigned Scope = 0;\n  if (TreePredicateFn(Frag).usesOperands())\n    Scope = TP.getDAGPatterns().allocateScope();\n\n  // Compute the map of formal to actual arguments.\n  std::map<std::string, TreePatternNodePtr> ArgMap;\n  for (unsigned i = 0, e = Frag->getNumArgs(); i != e; ++i) {\n    TreePatternNodePtr Child = getChildShared(i);\n    if (Scope != 0) {\n      Child = Child->clone();\n      Child->addNameAsPredicateArg(ScopedName(Scope, Frag->getArgName(i)));\n    }\n    ArgMap[Frag->getArgName(i)] = Child;\n  }\n\n  // Loop over all fragment alternatives.\n  for (const auto &Alternative : Frag->getTrees()) {\n    TreePatternNodePtr FragTree = Alternative->clone();\n\n    if (!PredFn.isAlwaysTrue())\n      FragTree->addPredicateCall(PredFn, Scope);\n\n    // Resolve formal arguments to their actual value.\n    if (Frag->getNumArgs())\n      FragTree->SubstituteFormalArguments(ArgMap);\n\n    // Transfer types.  Note that the resolved alternative may have fewer\n    // (but not more) results than the PatFrags node.\n    FragTree->setName(getName());\n    for (unsigned i = 0, e = FragTree->getNumTypes(); i != e; ++i)\n      FragTree->UpdateNodeType(i, getExtType(i), TP);\n\n    if (Op->isSubClassOf(\"GISelFlags\"))\n      FragTree->setGISelFlagsRecord(Op);\n\n    // Transfer in the old predicates.\n    for (const TreePredicateCall &Pred : getPredicateCalls())\n      FragTree->addPredicateCall(Pred);\n\n    // The fragment we inlined could have recursive inlining that is needed. See\n    // if there are any pattern fragments in it and inline them as needed.\n    FragTree->InlinePatternFragments(TP, OutAlternatives);\n  }\n}\n\n/// getImplicitType - Check to see if the specified record has an implicit\n/// type which should be applied to it.  This will infer the type of register\n/// references from the register file information, for example.\n///\n/// When Unnamed is set, return the type of a DAG operand with no name, such as\n/// the F8RC register class argument in:\n///\n///   (COPY_TO_REGCLASS GPR:$src, F8RC)\n///\n/// When Unnamed is false, return the type of a named DAG operand such as the\n/// GPR:$src operand above.\n///\nstatic TypeSetByHwMode getImplicitType(Record *R, unsigned ResNo,\n                                       bool NotRegisters, bool Unnamed,\n                                       TreePattern &TP) {\n  CodeGenDAGPatterns &CDP = TP.getDAGPatterns();\n\n  // Check to see if this is a register operand.\n  if (R->isSubClassOf(\"RegisterOperand\")) {\n    assert(ResNo == 0 && \"Regoperand ref only has one result!\");\n    if (NotRegisters)\n      return TypeSetByHwMode(); // Unknown.\n    Record *RegClass = R->getValueAsDef(\"RegClass\");\n    const CodeGenTarget &T = TP.getDAGPatterns().getTargetInfo();\n    return TypeSetByHwMode(T.getRegisterClass(RegClass).getValueTypes());\n  }\n\n  // Check to see if this is a register or a register class.\n  if (R->isSubClassOf(\"RegisterClass\")) {\n    assert(ResNo == 0 && \"Regclass ref only has one result!\");\n    // An unnamed register class represents itself as an i32 immediate, for\n    // example on a COPY_TO_REGCLASS instruction.\n    if (Unnamed)\n      return TypeSetByHwMode(MVT::i32);\n\n    // In a named operand, the register class provides the possible set of\n    // types.\n    if (NotRegisters)\n      return TypeSetByHwMode(); // Unknown.\n    const CodeGenTarget &T = TP.getDAGPatterns().getTargetInfo();\n    return TypeSetByHwMode(T.getRegisterClass(R).getValueTypes());\n  }\n\n  if (R->isSubClassOf(\"PatFrags\")) {\n    assert(ResNo == 0 && \"FIXME: PatFrag with multiple results?\");\n    // Pattern fragment types will be resolved when they are inlined.\n    return TypeSetByHwMode(); // Unknown.\n  }\n\n  if (R->isSubClassOf(\"Register\")) {\n    assert(ResNo == 0 && \"Registers only produce one result!\");\n    if (NotRegisters)\n      return TypeSetByHwMode(); // Unknown.\n    const CodeGenTarget &T = TP.getDAGPatterns().getTargetInfo();\n    return TypeSetByHwMode(T.getRegisterVTs(R));\n  }\n\n  if (R->isSubClassOf(\"SubRegIndex\")) {\n    assert(ResNo == 0 && \"SubRegisterIndices only produce one result!\");\n    return TypeSetByHwMode(MVT::i32);\n  }\n\n  if (R->isSubClassOf(\"ValueType\")) {\n    assert(ResNo == 0 && \"This node only has one result!\");\n    // An unnamed VTSDNode represents itself as an MVT::Other immediate.\n    //\n    //   (sext_inreg GPR:$src, i16)\n    //                         ~~~\n    if (Unnamed)\n      return TypeSetByHwMode(MVT::Other);\n    // With a name, the ValueType simply provides the type of the named\n    // variable.\n    //\n    //   (sext_inreg i32:$src, i16)\n    //               ~~~~~~~~\n    if (NotRegisters)\n      return TypeSetByHwMode(); // Unknown.\n    const CodeGenHwModes &CGH = CDP.getTargetInfo().getHwModes();\n    return TypeSetByHwMode(getValueTypeByHwMode(R, CGH));\n  }\n\n  if (R->isSubClassOf(\"CondCode\")) {\n    assert(ResNo == 0 && \"This node only has one result!\");\n    // Using a CondCodeSDNode.\n    return TypeSetByHwMode(MVT::Other);\n  }\n\n  if (R->isSubClassOf(\"ComplexPattern\")) {\n    assert(ResNo == 0 && \"FIXME: ComplexPattern with multiple results?\");\n    if (NotRegisters)\n      return TypeSetByHwMode(); // Unknown.\n    Record *T = CDP.getComplexPattern(R).getValueType();\n    const CodeGenHwModes &CGH = CDP.getTargetInfo().getHwModes();\n    return TypeSetByHwMode(getValueTypeByHwMode(T, CGH));\n  }\n  if (R->isSubClassOf(\"PointerLikeRegClass\")) {\n    assert(ResNo == 0 && \"Regclass can only have one result!\");\n    TypeSetByHwMode VTS(MVT::iPTR);\n    TP.getInfer().expandOverloads(VTS);\n    return VTS;\n  }\n\n  if (R->getName() == \"node\" || R->getName() == \"srcvalue\" ||\n      R->getName() == \"zero_reg\" || R->getName() == \"immAllOnesV\" ||\n      R->getName() == \"immAllZerosV\" || R->getName() == \"undef_tied_input\") {\n    // Placeholder.\n    return TypeSetByHwMode(); // Unknown.\n  }\n\n  if (R->isSubClassOf(\"Operand\")) {\n    const CodeGenHwModes &CGH = CDP.getTargetInfo().getHwModes();\n    Record *T = R->getValueAsDef(\"Type\");\n    return TypeSetByHwMode(getValueTypeByHwMode(T, CGH));\n  }\n\n  TP.error(\"Unknown node flavor used in pattern: \" + R->getName());\n  return TypeSetByHwMode(MVT::Other);\n}\n\n/// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n/// CodeGenIntrinsic information for it, otherwise return a null pointer.\nconst CodeGenIntrinsic *\nTreePatternNode::getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const {\n  if (getOperator() != CDP.get_intrinsic_void_sdnode() &&\n      getOperator() != CDP.get_intrinsic_w_chain_sdnode() &&\n      getOperator() != CDP.get_intrinsic_wo_chain_sdnode())\n    return nullptr;\n\n  unsigned IID = cast<IntInit>(getChild(0).getLeafValue())->getValue();\n  return &CDP.getIntrinsicInfo(IID);\n}\n\n/// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n/// return the ComplexPattern information, otherwise return null.\nconst ComplexPattern *\nTreePatternNode::getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const {\n  Record *Rec;\n  if (isLeaf()) {\n    DefInit *DI = dyn_cast<DefInit>(getLeafValue());\n    if (!DI)\n      return nullptr;\n    Rec = DI->getDef();\n  } else\n    Rec = getOperator();\n\n  if (!Rec->isSubClassOf(\"ComplexPattern\"))\n    return nullptr;\n  return &CGP.getComplexPattern(Rec);\n}\n\n"}], "code": "bool TreePredicateFn::isAtomicOrderingWeakerThanRelease() const {\n  return isPredefinedPredicateEqualTo(\"IsAtomicOrderingReleaseOrStronger\",\n                                      false);\n}\n"}, "5FF38911DE3E69F9": {"calls": [{"id": "3D9B3AFDC648F067", "name": "llvm::CGIOperandList::getSubOperandNumber", "path": "llvm-project/llvm/utils/TableGen/CodeGenInstruction.h", "start": {"line": 204, "col": 3}, "end": {"line": 210, "col": 3}, "code": "    for (unsigned i = 0;; ++i) {\n      assert(i < OperandList.size() && \"Invalid flat operand #\");\n      if (OperandList[i].MIOperandNo + OperandList[i].MINumOperands > Op)\n        return std::make_pair(i, Op - OperandList[i].MIOperandNo);\n    }\n  }\n\n  /// isFlatOperandNotEmitted - Return true if the specified flat operand #\n  /// should not be emitted with the code emitter.\n  bool isFlatOperandNotEmitted(unsigned FlatOpNo) const {\n    std::pair<unsigned, unsigned> Op = getSubOperandNumber(FlatOpNo);\n    if (OperandList[Op.first].DoNotEncode.size() > Op.second)\n      return OperandList[Op.first].DoNotEncode[Op.second];\n    return false;\n  }\n\n  void ProcessDisableEncoding(StringRef Value);\n};\n\nclass CodeGenInstruction {\npublic:\n  Record *TheDef;      // The actual record defining this instruction.\n  StringRef Namespace; // The namespace the instruction is in.\n\n  /// AsmString - The format string used to emit a .s file for the\n  /// instruction.\n  std::string AsmString;\n\n  /// Operands - This is information about the (ins) and (outs) list specified\n  /// to the instruction.\n  CGIOperandList Operands;\n\n  /// ImplicitDefs/ImplicitUses - These are lists of registers that are\n  /// implicitly defined and used by the instruction.\n  std::vector<Record *> ImplicitDefs, ImplicitUses;\n\n  // Various boolean values we track for the instruction.\n  bool isPreISelOpcode : 1;\n  bool isReturn : 1;\n  bool isEHScopeReturn : 1;\n  bool isBranch : 1;\n  bool isIndirectBranch : 1;\n  bool isCompare : 1;\n  bool isMoveImm : 1;\n  bool isMoveReg : 1;\n  bool isBitcast : 1;\n  bool isSelect : 1;\n  bool isBarrier : 1;\n  bool isCall : 1;\n  bool isAdd : 1;\n  bool isTrap : 1;\n  bool canFoldAsLoad : 1;\n  bool mayLoad : 1;\n  bool mayLoad_Unset : 1;\n  bool mayStore : 1;\n  bool mayStore_Unset : 1;\n  bool mayRaiseFPException : 1;\n  bool isPredicable : 1;\n  bool isConvertibleToThreeAddress : 1;\n  bool isCommutable : 1;\n  bool isTerminator : 1;\n  bool isReMaterializable : 1;\n  bool hasDelaySlot : 1;\n  bool usesCustomInserter : 1;\n  bool hasPostISelHook : 1;\n  bool hasCtrlDep : 1;\n  bool isNotDuplicable : 1;\n  bool hasSideEffects : 1;\n  bool hasSideEffects_Unset : 1;\n  bool isAsCheapAsAMove : 1;\n  bool hasExtraSrcRegAllocReq : 1;\n  bool hasExtraDefRegAllocReq : 1;\n  bool isCodeGenOnly : 1;\n  bool isPseudo : 1;\n  bool isMeta : 1;\n  bool isRegSequence : 1;\n  bool isExtractSubreg : 1;\n  bool isInsertSubreg : 1;\n  bool isConvergent : 1;\n  bool hasNoSchedulingInfo : 1;\n  bool FastISelShouldIgnore : 1;\n  bool hasChain : 1;\n  bool hasChain_Inferred : 1;\n  bool variadicOpsAreDefs : 1;\n  bool isAuthenticated : 1;\n\n  std::string DeprecatedReason;\n  bool HasComplexDeprecationPredicate;\n\n  /// Are there any undefined flags?\n  bool hasUndefFlags() const {\n    return mayLoad_Unset || mayStore_Unset || hasSideEffects_Unset;\n  }\n\n  // The record used to infer instruction flags, or NULL if no flag values\n  // have been inferred.\n  Record *InferredFrom;\n\n  // The enum value assigned by CodeGenTarget::computeInstrsByEnum.\n  mutable unsigned EnumVal;\n\n  CodeGenInstruction(Record *R);\n\n  /// HasOneImplicitDefWithKnownVT - If the instruction has at least one\n  /// implicit def and it has a known VT, return the VT, otherwise return\n  /// MVT::Other.\n  MVT::SimpleValueType\n  HasOneImplicitDefWithKnownVT(const CodeGenTarget &TargetInfo) const;\n\n  /// FlattenAsmStringVariants - Flatten the specified AsmString to only\n  /// include text from the specified variant, returning the new string.\n  static std::string FlattenAsmStringVariants(StringRef AsmString,\n                                              unsigned Variant);\n\n  // Is the specified operand in a generic instruction implicitly a pointer.\n  // This can be used on intructions that use typeN or ptypeN to identify\n  // operands that should be considered as pointers even though SelectionDAG\n  // didn't make a distinction between integer and pointers.\n  bool isInOperandAPointer(unsigned i) const {\n    return isOperandImpl(\"InOperandList\", i, \"IsPointer\");\n  }\n\n  bool isOutOperandAPointer(unsigned i) const {\n    return isOperandImpl(\"OutOperandList\", i, \"IsPointer\");\n  }\n\n  /// Check if the operand is required to be an immediate.\n  bool isInOperandImmArg(unsigned i) const {\n    return isOperandImpl(\"InOperandList\", i, \"IsImmediate\");\n  }\n\nprivate:\n  bool isOperandImpl(StringRef OpListName, unsigned i,\n                     StringRef PropertyName) const;\n};\n} // namespace llvm\n\n#endif\n"}], "code": "  bool isFlatOperandNotEmitted(unsigned FlatOpNo) const {\n    std::pair<unsigned, unsigned> Op = getSubOperandNumber(FlatOpNo);\n    if (OperandList[Op.first].DoNotEncode.size() > Op.second)\n      return OperandList[Op.first].DoNotEncode[Op.second];\n    return false;\n  }\n"}, "61FDF85A255190F3": {"calls": [{"id": "EFC9DF8CFA3CAA6C", "name": "llvm::TargetInstrInfo::isLoadFromStackSlot", "path": "llvm-project/llvm/include/llvm/CodeGen/TargetInstrInfo.h", "start": {"line": 272, "col": 3}, "end": {"line": 275, "col": 3}, "code": "                                       int &FrameIndex) const {\n    return 0;\n  }\n\n  /// Optional extension of isLoadFromStackSlot that returns the number of\n  /// bytes loaded from the stack. This must be implemented if a backend\n  /// supports partial stack slot spills/loads to further disambiguate\n  /// what the load does.\n  virtual Register isLoadFromStackSlot(const MachineInstr &MI,\n                                       int &FrameIndex,\n                                       unsigned &MemBytes) const {\n    MemBytes = 0;\n    return isLoadFromStackSlot(MI, FrameIndex);\n  }\n\n  /// Check for post-frame ptr elimination stack locations as well.\n  /// This uses a heuristic so it isn't reliable for correctness.\n  virtual Register isLoadFromStackSlotPostFE(const MachineInstr &MI,\n                                             int &FrameIndex) const {\n    return 0;\n  }\n\n  /// If the specified machine instruction has a load from a stack slot,\n  /// return true along with the FrameIndices of the loaded stack slot and the\n  /// machine mem operands containing the reference.\n  /// If not, return false.  Unlike isLoadFromStackSlot, this returns true for\n  /// any instructions that loads from the stack.  This is just a hint, as some\n  /// cases may be missed.\n  virtual bool hasLoadFromStackSlot(\n      const MachineInstr &MI,\n      SmallVectorImpl<const MachineMemOperand *> &Accesses) const;\n\n  /// If the specified machine instruction is a direct\n  /// store to a stack slot, return the virtual or physical register number of\n  /// the source reg along with the FrameIndex of the loaded stack slot.  If\n  /// not, return 0.  This predicate must return 0 if the instruction has\n  /// any side effects other than storing to the stack slot.\n  virtual Register isStoreToStackSlot(const MachineInstr &MI,\n                                      int &FrameIndex) const {\n    return 0;\n  }\n\n  /// Optional extension of isStoreToStackSlot that returns the number of\n  /// bytes stored to the stack. This must be implemented if a backend\n  /// supports partial stack slot spills/loads to further disambiguate\n  /// what the store does.\n  virtual Register isStoreToStackSlot(const MachineInstr &MI,\n                                      int &FrameIndex,\n                                      unsigned &MemBytes) const {\n    MemBytes = 0;\n    return isStoreToStackSlot(MI, FrameIndex);\n  }\n\n  /// Check for post-frame ptr elimination stack locations as well.\n  /// This uses a heuristic, so it isn't reliable for correctness.\n  virtual Register isStoreToStackSlotPostFE(const MachineInstr &MI,\n                                            int &FrameIndex) const {\n    return 0;\n  }\n\n  /// If the specified machine instruction has a store to a stack slot,\n  /// return true along with the FrameIndices of the loaded stack slot and the\n  /// machine mem operands containing the reference.\n  /// If not, return false.  Unlike isStoreToStackSlot,\n  /// this returns true for any instructions that stores to the\n  /// stack.  This is just a hint, as some cases may be missed.\n  virtual bool hasStoreToStackSlot(\n      const MachineInstr &MI,\n      SmallVectorImpl<const MachineMemOperand *> &Accesses) const;\n\n  /// Return true if the specified machine instruction\n  /// is a copy of one stack slot to another and has no other effect.\n  /// Provide the identity of the two frame indices.\n  virtual bool isStackSlotCopy(const MachineInstr &MI, int &DestFrameIndex,\n                               int &SrcFrameIndex) const {\n    return false;\n  }\n\n  /// Compute the size in bytes and offset within a stack slot of a spilled\n  /// register or subregister.\n  ///\n  /// \\param [out] Size in bytes of the spilled value.\n  /// \\param [out] Offset in bytes within the stack slot.\n  /// \\returns true if both Size and Offset are successfully computed.\n  ///\n  /// Not all subregisters have computable spill slots. For example,\n  /// subregisters registers may not be byte-sized, and a pair of discontiguous\n  /// subregisters has no single offset.\n  ///\n  /// Targets with nontrivial bigendian implementations may need to override\n  /// this, particularly to support spilled vector registers.\n  virtual bool getStackSlotRange(const TargetRegisterClass *RC, unsigned SubIdx,\n                                 unsigned &Size, unsigned &Offset,\n                                 const MachineFunction &MF) const;\n\n  /// Return true if the given instruction is terminator that is unspillable,\n  /// according to isUnspillableTerminatorImpl.\n  bool isUnspillableTerminator(const MachineInstr *MI) const {\n    return MI->isTerminator() && isUnspillableTerminatorImpl(MI);\n  }\n\n  /// Returns the size in bytes of the specified MachineInstr, or ~0U\n  /// when this function is not implemented by a target.\n  virtual unsigned getInstSizeInBytes(const MachineInstr &MI) const {\n    return ~0U;\n  }\n\n  /// Return true if the instruction is as cheap as a move instruction.\n  ///\n  /// Targets for different archs need to override this, and different\n  /// micro-architectures can also be finely tuned inside.\n  virtual bool isAsCheapAsAMove(const MachineInstr &MI) const {\n    return MI.isAsCheapAsAMove();\n  }\n\n  /// Return true if the instruction should be sunk by MachineSink.\n  ///\n  /// MachineSink determines on its own whether the instruction is safe to sink;\n  /// this gives the target a hook to override the default behavior with regards\n  /// to which instructions should be sunk.\n  virtual bool shouldSink(const MachineInstr &MI) const { return true; }\n\n  /// Return false if the instruction should not be hoisted by MachineLICM.\n  ///\n  /// MachineLICM determines on its own whether the instruction is safe to\n  /// hoist; this gives the target a hook to extend this assessment and prevent\n  /// an instruction being hoisted from a given loop for target specific\n  /// reasons.\n  virtual bool shouldHoist(const MachineInstr &MI,\n                           const MachineLoop *FromLoop) const {\n    return true;\n  }\n\n  /// Re-issue the specified 'original' instruction at the\n  /// specific location targeting a new destination register.\n  /// The register in Orig->getOperand(0).getReg() will be substituted by\n  /// DestReg:SubIdx. Any existing subreg index is preserved or composed with\n  /// SubIdx.\n  virtual void reMaterialize(MachineBasicBlock &MBB,\n                             MachineBasicBlock::iterator MI, Register DestReg,\n                             unsigned SubIdx, const MachineInstr &Orig,\n                             const TargetRegisterInfo &TRI) const;\n\n  /// Clones instruction or the whole instruction bundle \\p Orig and\n  /// insert into \\p MBB before \\p InsertBefore. The target may update operands\n  /// that are required to be unique.\n  ///\n  /// \\p Orig must not return true for MachineInstr::isNotDuplicable().\n  virtual MachineInstr &duplicate(MachineBasicBlock &MBB,\n                                  MachineBasicBlock::iterator InsertBefore,\n                                  const MachineInstr &Orig) const;\n\n  /// This method must be implemented by targets that\n  /// set the M_CONVERTIBLE_TO_3_ADDR flag.  When this flag is set, the target\n  /// may be able to convert a two-address instruction into one or more true\n  /// three-address instructions on demand.  This allows the X86 target (for\n  /// example) to convert ADD and SHL instructions into LEA instructions if they\n  /// would require register copies due to two-addressness.\n  ///\n  /// This method returns a null pointer if the transformation cannot be\n  /// performed, otherwise it returns the last new instruction.\n  ///\n  /// If \\p LIS is not nullptr, the LiveIntervals info should be updated for\n  /// replacing \\p MI with new instructions, even though this function does not\n  /// remove MI.\n  virtual MachineInstr *convertToThreeAddress(MachineInstr &MI,\n                                              LiveVariables *LV,\n                                              LiveIntervals *LIS) const {\n    return nullptr;\n  }\n\n  // This constant can be used as an input value of operand index passed to\n  // the method findCommutedOpIndices() to tell the method that the\n  // corresponding operand index is not pre-defined and that the method\n  // can pick any commutable operand.\n  static const unsigned CommuteAnyOperandIndex = ~0U;\n\n  /// This method commutes the operands of the given machine instruction MI.\n  ///\n  /// The operands to be commuted are specified by their indices OpIdx1 and\n  /// OpIdx2. OpIdx1 and OpIdx2 arguments may be set to a special value\n  /// 'CommuteAnyOperandIndex', which means that the method is free to choose\n  /// any arbitrarily chosen commutable operand. If both arguments are set to\n  /// 'CommuteAnyOperandIndex' then the method looks for 2 different commutable\n  /// operands; then commutes them if such operands could be found.\n  ///\n  /// If NewMI is false, MI is modified in place and returned; otherwise, a\n  /// new machine instruction is created and returned.\n  ///\n  /// Do not call this method for a non-commutable instruction or\n  /// for non-commuable operands.\n  /// Even though the instruction is commutable, the method may still\n  /// fail to commute the operands, null pointer is returned in such cases.\n  MachineInstr *\n  commuteInstruction(MachineInstr &MI, bool NewMI = false,\n                     unsigned OpIdx1 = CommuteAnyOperandIndex,\n                     unsigned OpIdx2 = CommuteAnyOperandIndex) const;\n\n  /// Returns true iff the routine could find two commutable operands in the\n  /// given machine instruction.\n  /// The 'SrcOpIdx1' and 'SrcOpIdx2' are INPUT and OUTPUT arguments.\n  /// If any of the INPUT values is set to the special value\n  /// 'CommuteAnyOperandIndex' then the method arbitrarily picks a commutable\n  /// operand, then returns its index in the corresponding argument.\n  /// If both of INPUT values are set to 'CommuteAnyOperandIndex' then method\n  /// looks for 2 commutable operands.\n  /// If INPUT values refer to some operands of MI, then the method simply\n  /// returns true if the corresponding operands are commutable and returns\n  /// false otherwise.\n  ///\n  /// For example, calling this method this way:\n  ///     unsigned Op1 = 1, Op2 = CommuteAnyOperandIndex;\n  ///     findCommutedOpIndices(MI, Op1, Op2);\n  /// can be interpreted as a query asking to find an operand that would be\n  /// commutable with the operand#1.\n  virtual bool findCommutedOpIndices(const MachineInstr &MI,\n                                     unsigned &SrcOpIdx1,\n                                     unsigned &SrcOpIdx2) const;\n\n  /// Returns true if the target has a preference on the operands order of\n  /// the given machine instruction. And specify if \\p Commute is required to\n  /// get the desired operands order.\n  virtual bool hasCommutePreference(MachineInstr &MI, bool &Commute) const {\n    return false;\n  }\n\n  /// A pair composed of a register and a sub-register index.\n  /// Used to give some type checking when modeling Reg:SubReg.\n  struct RegSubRegPair {\n    Register Reg;\n    unsigned SubReg;\n\n    RegSubRegPair(Register Reg = Register(), unsigned SubReg = 0)\n        : Reg(Reg), SubReg(SubReg) {}\n\n    bool operator==(const RegSubRegPair& P) const {\n      return Reg == P.Reg && SubReg == P.SubReg;\n    }\n    bool operator!=(const RegSubRegPair& P) const {\n      return !(*this == P);\n    }\n  };\n\n  /// A pair composed of a pair of a register and a sub-register index,\n  /// and another sub-register index.\n  /// Used to give some type checking when modeling Reg:SubReg1, SubReg2.\n  struct RegSubRegPairAndIdx : RegSubRegPair {\n    unsigned SubIdx;\n\n    RegSubRegPairAndIdx(Register Reg = Register(), unsigned SubReg = 0,\n                        unsigned SubIdx = 0)\n        : RegSubRegPair(Reg, SubReg), SubIdx(SubIdx) {}\n  };\n\n  /// Build the equivalent inputs of a REG_SEQUENCE for the given \\p MI\n  /// and \\p DefIdx.\n  /// \\p [out] InputRegs of the equivalent REG_SEQUENCE. Each element of\n  /// the list is modeled as <Reg:SubReg, SubIdx>. Operands with the undef\n  /// flag are not added to this list.\n  /// E.g., REG_SEQUENCE %1:sub1, sub0, %2, sub1 would produce\n  /// two elements:\n  /// - %1:sub1, sub0\n  /// - %2<:0>, sub1\n  ///\n  /// \\returns true if it is possible to build such an input sequence\n  /// with the pair \\p MI, \\p DefIdx. False otherwise.\n  ///\n  /// \\pre MI.isRegSequence() or MI.isRegSequenceLike().\n  ///\n  /// \\note The generic implementation does not provide any support for\n  /// MI.isRegSequenceLike(). In other words, one has to override\n  /// getRegSequenceLikeInputs for target specific instructions.\n  bool\n  getRegSequenceInputs(const MachineInstr &MI, unsigned DefIdx,\n                       SmallVectorImpl<RegSubRegPairAndIdx> &InputRegs) const;\n\n"}], "code": "  virtual Register isLoadFromStackSlot(const MachineInstr &MI,\n                                       int &FrameIndex,\n                                       unsigned &MemBytes) const {\n    MemBytes = 0;\n    return isLoadFromStackSlot(MI, FrameIndex);\n  }\n"}, "F1AB034FF9F54521": {"calls": [{"id": "497C3F703A9ACB4A", "name": "lookupFoldTableImpl", "path": "llvm-project/llvm/lib/Target/X86/X86InstrFoldTables.cpp", "start": {"line": 89, "col": 1}, "end": {"line": 122, "col": 1}, "code": "lookupFoldTableImpl(ArrayRef<X86FoldTableEntry> Table, unsigned RegOp) {\n#ifndef NDEBUG\n#define CHECK_SORTED_UNIQUE(TABLE)                                             \\\n  assert(llvm::is_sorted(TABLE) && #TABLE \" is not sorted\");                   \\\n  assert(std::adjacent_find(std::begin(Table), std::end(Table)) ==             \\\n             std::end(Table) &&                                                \\\n         #TABLE \" is not unique\");\n\n  // Make sure the tables are sorted.\n  static std::atomic<bool> FoldTablesChecked(false);\n  if (!FoldTablesChecked.load(std::memory_order_relaxed)) {\n    CHECK_SORTED_UNIQUE(Table2Addr)\n    CHECK_SORTED_UNIQUE(Table0)\n    CHECK_SORTED_UNIQUE(Table1)\n    CHECK_SORTED_UNIQUE(Table2)\n    CHECK_SORTED_UNIQUE(Table3)\n    CHECK_SORTED_UNIQUE(Table4)\n    CHECK_SORTED_UNIQUE(BroadcastTable1)\n    CHECK_SORTED_UNIQUE(BroadcastTable2)\n    CHECK_SORTED_UNIQUE(BroadcastTable3)\n    CHECK_SORTED_UNIQUE(BroadcastTable4)\n    CHECK_SORTED_UNIQUE(BroadcastSizeTable2)\n    CHECK_SORTED_UNIQUE(BroadcastSizeTable3)\n    FoldTablesChecked.store(true, std::memory_order_relaxed);\n  }\n#endif\n\n  const X86FoldTableEntry *Data = llvm::lower_bound(Table, RegOp);\n  if (Data != Table.end() && Data->KeyOp == RegOp &&\n      !(Data->Flags & TB_NO_FORWARD))\n    return Data;\n  return nullptr;\n}\n\nconst X86FoldTableEntry *llvm::lookupTwoAddrFoldTable(unsigned RegOp) {\n  return lookupFoldTableImpl(Table2Addr, RegOp);\n}\n\nconst X86FoldTableEntry *llvm::lookupFoldTable(unsigned RegOp, unsigned OpNum) {\n  ArrayRef<X86FoldTableEntry> FoldTable;\n  if (OpNum == 0)\n    FoldTable = ArrayRef(Table0);\n  else if (OpNum == 1)\n    FoldTable = ArrayRef(Table1);\n  else if (OpNum == 2)\n    FoldTable = ArrayRef(Table2);\n  else if (OpNum == 3)\n    FoldTable = ArrayRef(Table3);\n  else if (OpNum == 4)\n    FoldTable = ArrayRef(Table4);\n  else\n    return nullptr;\n\n  return lookupFoldTableImpl(FoldTable, RegOp);\n}\n\nconst X86FoldTableEntry *llvm::lookupBroadcastFoldTable(unsigned RegOp,\n                                                        unsigned OpNum) {\n  ArrayRef<X86FoldTableEntry> FoldTable;\n  if (OpNum == 1)\n    FoldTable = ArrayRef(BroadcastTable1);\n  else if (OpNum == 2)\n    FoldTable = ArrayRef(BroadcastTable2);\n  else if (OpNum == 3)\n    FoldTable = ArrayRef(BroadcastTable3);\n  else if (OpNum == 4)\n    FoldTable = ArrayRef(BroadcastTable4);\n  else\n    return nullptr;\n\n  return lookupFoldTableImpl(FoldTable, RegOp);\n}\n\nnamespace {\n\n// This class stores the memory unfolding tables. It is instantiated as a\n// function scope static variable to lazily init the unfolding table.\nstruct X86MemUnfoldTable {\n  // Stores memory unfolding tables entries sorted by opcode.\n  std::vector<X86FoldTableEntry> Table;\n\n  X86MemUnfoldTable() {\n    for (const X86FoldTableEntry &Entry : Table2Addr)\n      // Index 0, folded load and store, no alignment requirement.\n      addTableEntry(Entry, TB_INDEX_0 | TB_FOLDED_LOAD | TB_FOLDED_STORE);\n\n    for (const X86FoldTableEntry &Entry : Table0)\n      // Index 0, mix of loads and stores.\n      addTableEntry(Entry, TB_INDEX_0);\n\n    for (const X86FoldTableEntry &Entry : Table1)\n      // Index 1, folded load\n      addTableEntry(Entry, TB_INDEX_1 | TB_FOLDED_LOAD);\n\n    for (const X86FoldTableEntry &Entry : Table2)\n      // Index 2, folded load\n      addTableEntry(Entry, TB_INDEX_2 | TB_FOLDED_LOAD);\n\n    for (const X86FoldTableEntry &Entry : Table3)\n      // Index 3, folded load\n      addTableEntry(Entry, TB_INDEX_3 | TB_FOLDED_LOAD);\n\n    for (const X86FoldTableEntry &Entry : Table4)\n      // Index 4, folded load\n      addTableEntry(Entry, TB_INDEX_4 | TB_FOLDED_LOAD);\n\n    // Broadcast tables.\n    for (const X86FoldTableEntry &Entry : BroadcastTable1)\n      // Index 1, folded broadcast\n      addTableEntry(Entry, TB_INDEX_1 | TB_FOLDED_LOAD);\n\n    for (const X86FoldTableEntry &Entry : BroadcastTable2)\n      // Index 2, folded broadcast\n      addTableEntry(Entry, TB_INDEX_2 | TB_FOLDED_LOAD);\n\n    for (const X86FoldTableEntry &Entry : BroadcastTable3)\n      // Index 3, folded broadcast\n      addTableEntry(Entry, TB_INDEX_3 | TB_FOLDED_LOAD);\n\n    for (const X86FoldTableEntry &Entry : BroadcastTable4)\n      // Index 4, folded broadcast\n      addTableEntry(Entry, TB_INDEX_4 | TB_FOLDED_LOAD);\n\n"}], "code": "const X86FoldTableEntry *llvm::lookupBroadcastFoldTable(unsigned RegOp,\n                                                        unsigned OpNum) {\n  ArrayRef<X86FoldTableEntry> FoldTable;\n  if (OpNum == 1)\n    FoldTable = ArrayRef(BroadcastTable1);\n  else if (OpNum == 2)\n    FoldTable = ArrayRef(BroadcastTable2);\n  else if (OpNum == 3)\n    FoldTable = ArrayRef(BroadcastTable3);\n  else if (OpNum == 4)\n    FoldTable = ArrayRef(BroadcastTable4);\n  else\n    return nullptr;\n\n  return lookupFoldTableImpl(FoldTable, RegOp);\n}\n"}, "A9F73F1640F117BA": {"calls": [{"id": "0313D1E33D0074E5", "name": "llvm::dsymutil::DwarfLinkerForBinary::AddressManager::getRelocations", "path": "llvm-project/llvm/tools/dsymutil/DwarfLinkerForBinary.cpp", "start": {"line": 1005, "col": 1}, "end": {"line": 1020, "col": 1}, "code": "    const std::vector<ValidReloc> &Relocs, uint64_t StartPos, uint64_t EndPos) {\n  std::vector<ValidReloc> Res;\n\n  auto CurReloc = partition_point(Relocs, [StartPos](const ValidReloc &Reloc) {\n    return (uint64_t)Reloc.Offset < StartPos;\n  });\n\n  while (CurReloc != Relocs.end() && CurReloc->Offset >= StartPos &&\n         (uint64_t)CurReloc->Offset < EndPos) {\n    Res.push_back(*CurReloc);\n    CurReloc++;\n  }\n\n  return Res;\n}\n\nvoid DwarfLinkerForBinary::AddressManager::printReloc(const ValidReloc &Reloc) {\n  const auto &Mapping = Reloc.SymbolMapping;\n  const uint64_t ObjectAddress = Mapping.ObjectAddress\n                                     ? uint64_t(*Mapping.ObjectAddress)\n                                     : std::numeric_limits<uint64_t>::max();\n\n  outs() << \"Found valid debug map entry: \" << Reloc.SymbolName << \"\\t\"\n         << format(\"0x%016\" PRIx64 \" => 0x%016\" PRIx64 \"\\n\", ObjectAddress,\n                   uint64_t(Mapping.BinaryAddress));\n}\n\nint64_t\nDwarfLinkerForBinary::AddressManager::getRelocValue(const ValidReloc &Reloc) {\n  int64_t AddrAdjust = relocate(Reloc);\n  if (Reloc.SymbolMapping.ObjectAddress)\n    AddrAdjust -= uint64_t(*Reloc.SymbolMapping.ObjectAddress);\n  return AddrAdjust;\n}\n\nstd::optional<int64_t>\nDwarfLinkerForBinary::AddressManager::hasValidRelocationAt(\n    const std::vector<ValidReloc> &AllRelocs, uint64_t StartOffset,\n    uint64_t EndOffset, bool Verbose) {\n  std::vector<ValidReloc> Relocs =\n      getRelocations(AllRelocs, StartOffset, EndOffset);\n  if (Relocs.size() == 0)\n    return std::nullopt;\n\n  if (Verbose)\n    printReloc(Relocs[0]);\n\n  return getRelocValue(Relocs[0]);\n}\n\n/// Get the starting and ending (exclusive) offset for the\n/// attribute with index \\p Idx descibed by \\p Abbrev. \\p Offset is\n/// supposed to point to the position of the first attribute described\n/// by \\p Abbrev.\n/// \\return [StartOffset, EndOffset) as a pair.\nstatic std::pair<uint64_t, uint64_t>\ngetAttributeOffsets(const DWARFAbbreviationDeclaration *Abbrev, unsigned Idx,\n                    uint64_t Offset, const DWARFUnit &Unit) {\n  DataExtractor Data = Unit.getDebugInfoExtractor();\n\n  for (unsigned I = 0; I < Idx; ++I)\n    DWARFFormValue::skipValue(Abbrev->getFormByIndex(I), Data, &Offset,\n                              Unit.getFormParams());\n\n  uint64_t End = Offset;\n  DWARFFormValue::skipValue(Abbrev->getFormByIndex(Idx), Data, &End,\n                            Unit.getFormParams());\n\n  return std::make_pair(Offset, End);\n}\n\nstd::optional<int64_t>\nDwarfLinkerForBinary::AddressManager::getExprOpAddressRelocAdjustment(\n    DWARFUnit &U, const DWARFExpression::Operation &Op, uint64_t StartOffset,\n    uint64_t EndOffset, bool Verbose) {\n  switch (Op.getCode()) {\n  default: {\n    assert(false && \"Specified operation does not have address operand\");\n  } break;\n  case dwarf::DW_OP_const2u:\n  case dwarf::DW_OP_const4u:\n  case dwarf::DW_OP_const8u:\n  case dwarf::DW_OP_const2s:\n  case dwarf::DW_OP_const4s:\n  case dwarf::DW_OP_const8s:\n  case dwarf::DW_OP_addr: {\n    return hasValidRelocationAt(ValidDebugInfoRelocs, StartOffset, EndOffset,\n                                Verbose);\n  } break;\n  case dwarf::DW_OP_constx:\n  case dwarf::DW_OP_addrx: {\n    return hasValidRelocationAt(ValidDebugAddrRelocs, StartOffset, EndOffset,\n                                Verbose);\n  } break;\n  }\n\n  return std::nullopt;\n}\n\nstd::optional<int64_t>\nDwarfLinkerForBinary::AddressManager::getSubprogramRelocAdjustment(\n    const DWARFDie &DIE, bool Verbose) {\n  const auto *Abbrev = DIE.getAbbreviationDeclarationPtr();\n\n  std::optional<uint32_t> LowPcIdx =\n      Abbrev->findAttributeIndex(dwarf::DW_AT_low_pc);\n  if (!LowPcIdx)\n    return std::nullopt;\n\n  dwarf::Form Form = Abbrev->getFormByIndex(*LowPcIdx);\n\n  switch (Form) {\n  case dwarf::DW_FORM_addr: {\n    uint64_t Offset = DIE.getOffset() + getULEB128Size(Abbrev->getCode());\n    uint64_t LowPcOffset, LowPcEndOffset;\n    std::tie(LowPcOffset, LowPcEndOffset) =\n        getAttributeOffsets(Abbrev, *LowPcIdx, Offset, *DIE.getDwarfUnit());\n    return hasValidRelocationAt(ValidDebugInfoRelocs, LowPcOffset,\n                                LowPcEndOffset, Verbose);\n  }\n  case dwarf::DW_FORM_addrx:\n  case dwarf::DW_FORM_addrx1:\n  case dwarf::DW_FORM_addrx2:\n  case dwarf::DW_FORM_addrx3:\n  case dwarf::DW_FORM_addrx4: {\n    std::optional<DWARFFormValue> AddrValue = DIE.find(dwarf::DW_AT_low_pc);\n    if (std::optional<uint64_t> AddressOffset =\n            DIE.getDwarfUnit()->getIndexedAddressOffset(\n                AddrValue->getRawUValue()))\n      return hasValidRelocationAt(\n          ValidDebugAddrRelocs, *AddressOffset,\n          *AddressOffset + DIE.getDwarfUnit()->getAddressByteSize(), Verbose);\n\n    Linker.reportWarning(\"no base offset for address table\", SrcFileName);\n    return std::nullopt;\n  }\n  default:\n    return std::nullopt;\n  }\n}\n\nstd::optional<StringRef>\nDwarfLinkerForBinary::AddressManager::getLibraryInstallName() {\n  return LibInstallName;\n}\n\nuint64_t\nDwarfLinkerForBinary::AddressManager::relocate(const ValidReloc &Reloc) const {\n  return Reloc.SymbolMapping.BinaryAddress + Reloc.Addend;\n}\n\nvoid DwarfLinkerForBinary::AddressManager::updateAndSaveValidRelocs(\n    bool IsDWARF5, uint64_t OriginalUnitOffset, int64_t LinkedOffset,\n    uint64_t StartOffset, uint64_t EndOffset) {\n  std::vector<ValidReloc> InRelocs =\n      getRelocations(ValidDebugInfoRelocs, StartOffset, EndOffset);\n  if (IsDWARF5)\n    InRelocs = getRelocations(ValidDebugAddrRelocs, StartOffset, EndOffset);\n  DwarfLinkerRelocMap->updateAndSaveValidRelocs(\n      IsDWARF5, InRelocs, OriginalUnitOffset, LinkedOffset);\n}\n\nvoid DwarfLinkerForBinary::AddressManager::updateRelocationsWithUnitOffset(\n    uint64_t OriginalUnitOffset, uint64_t OutputUnitOffset) {\n  DwarfLinkerRelocMap->updateRelocationsWithUnitOffset(OriginalUnitOffset,\n                                                       OutputUnitOffset);\n}\n/// Apply the valid relocations found by findValidRelocs() to\n/// the buffer \\p Data, taking into account that Data is at \\p BaseOffset\n/// in the debug_info section.\n///\n/// Like for findValidRelocs(), this function must be called with\n/// monotonic \\p BaseOffset values.\n///\n/// \\returns whether any reloc has been applied.\nbool DwarfLinkerForBinary::AddressManager::applyValidRelocs(\n    MutableArrayRef<char> Data, uint64_t BaseOffset, bool IsLittleEndian) {\n\n  std::vector<ValidReloc> Relocs = getRelocations(\n      ValidDebugInfoRelocs, BaseOffset, BaseOffset + Data.size());\n\n  for (const ValidReloc &CurReloc : Relocs) {\n    assert(CurReloc.Offset - BaseOffset < Data.size());\n    assert(CurReloc.Offset - BaseOffset + CurReloc.Size <= Data.size());\n    char Buf[8];\n    uint64_t Value = relocate(CurReloc);\n    for (unsigned I = 0; I != CurReloc.Size; ++I) {\n      unsigned Index = IsLittleEndian ? I : (CurReloc.Size - I - 1);\n      Buf[I] = uint8_t(Value >> (Index * 8));\n    }\n    assert(CurReloc.Size <= sizeof(Buf));\n    memcpy(&Data[CurReloc.Offset - BaseOffset], Buf, CurReloc.Size);\n  }\n  return Relocs.size() > 0;\n}\n\nvoid DwarfLinkerForBinaryRelocationMap::init(DWARFContext &Context) {\n  for (const std::unique_ptr<DWARFUnit> &CU : Context.compile_units())\n    StoredValidDebugInfoRelocsMap.insert(\n        std::make_pair(CU->getOffset(), std::vector<ValidReloc>()));\n  // FIXME: Support relocations debug_addr (DWARF5).\n}\n\nvoid DwarfLinkerForBinaryRelocationMap::addValidRelocs(RelocationMap &RM) {\n  for (const auto &DebugInfoRelocs : StoredValidDebugInfoRelocsMap) {\n    for (const auto &InfoReloc : DebugInfoRelocs.second)\n      RM.addRelocationMapEntry(InfoReloc);\n  }\n  // FIXME: Support relocations debug_addr (DWARF5).\n}\n\nvoid DwarfLinkerForBinaryRelocationMap::updateRelocationsWithUnitOffset(\n    uint64_t OriginalUnitOffset, uint64_t OutputUnitOffset) {\n  std::vector<ValidReloc> &StoredValidDebugInfoRelocs =\n      StoredValidDebugInfoRelocsMap[OriginalUnitOffset];\n  for (ValidReloc &R : StoredValidDebugInfoRelocs) {\n    R.Offset = (uint64_t)R.Offset + OutputUnitOffset;\n  }\n  // FIXME: Support relocations debug_addr (DWARF5).\n}\n\nvoid DwarfLinkerForBinaryRelocationMap::updateAndSaveValidRelocs(\n    bool IsDWARF5, std::vector<ValidReloc> &InRelocs, uint64_t UnitOffset,\n    int64_t LinkedOffset) {\n  std::vector<ValidReloc> &OutRelocs =\n      StoredValidDebugInfoRelocsMap[UnitOffset];\n  if (IsDWARF5)\n    OutRelocs = StoredValidDebugAddrRelocsMap[UnitOffset];\n\n  for (ValidReloc &R : InRelocs) {\n    OutRelocs.emplace_back(R.Offset + LinkedOffset, R.Size, R.Addend,\n                           R.SymbolName, R.SymbolMapping);\n  }\n}\n\n} // namespace dsymutil\n} // namespace llvm\n"}], "code": "std::optional<int64_t>\nDwarfLinkerForBinary::AddressManager::hasValidRelocationAt(\n    const std::vector<ValidReloc> &AllRelocs, uint64_t StartOffset,\n    uint64_t EndOffset, bool Verbose) {\n  std::vector<ValidReloc> Relocs =\n      getRelocations(AllRelocs, StartOffset, EndOffset);\n  if (Relocs.size() == 0)\n    return std::nullopt;\n\n  if (Verbose)\n    printReloc(Relocs[0]);\n\n  return getRelocValue(Relocs[0]);\n}\n"}, "F4FABCF2EFB953C6": {"calls": [{"id": "841530267C597645", "name": "FunctionVarLocsBuilder::insertVariable", "path": "llvm-project/llvm/lib/CodeGen/AssignmentTrackingAnalysis.cpp", "start": {"line": 114, "col": 3}, "end": {"line": 116, "col": 3}, "code": "    return static_cast<VariableID>(Variables.insert(V));\n  }\n\n  /// Get a variable from its \\p ID.\n  const DebugVariable &getVariable(VariableID ID) const {\n    return Variables[static_cast<unsigned>(ID)];\n  }\n\n  /// Return ptr to wedge of defs or nullptr if no defs come just before /p\n  /// Before.\n  const SmallVectorImpl<VarLocInfo> *getWedge(VarLocInsertPt Before) const {\n    auto R = VarLocsBeforeInst.find(Before);\n    if (R == VarLocsBeforeInst.end())\n      return nullptr;\n    return &R->second;\n  }\n\n  /// Replace the defs that come just before /p Before with /p Wedge.\n  void setWedge(VarLocInsertPt Before, SmallVector<VarLocInfo> &&Wedge) {\n    VarLocsBeforeInst[Before] = std::move(Wedge);\n  }\n\n  /// Add a def for a variable that is valid for its lifetime.\n  void addSingleLocVar(DebugVariable Var, DIExpression *Expr, DebugLoc DL,\n                       RawLocationWrapper R) {\n    VarLocInfo VarLoc;\n    VarLoc.VariableID = insertVariable(Var);\n    VarLoc.Expr = Expr;\n    VarLoc.DL = DL;\n    VarLoc.Values = R;\n    SingleLocVars.emplace_back(VarLoc);\n  }\n\n  /// Add a def to the wedge of defs just before /p Before.\n  void addVarLoc(VarLocInsertPt Before, DebugVariable Var, DIExpression *Expr,\n                 DebugLoc DL, RawLocationWrapper R) {\n    VarLocInfo VarLoc;\n    VarLoc.VariableID = insertVariable(Var);\n    VarLoc.Expr = Expr;\n    VarLoc.DL = DL;\n    VarLoc.Values = R;\n    VarLocsBeforeInst[Before].emplace_back(VarLoc);\n  }\n};\n\nvoid FunctionVarLocs::print(raw_ostream &OS, const Function &Fn) const {\n  // Print the variable table first. TODO: Sorting by variable could make the\n  // output more stable?\n  unsigned Counter = -1;\n  OS << \"=== Variables ===\\n\";\n  for (const DebugVariable &V : Variables) {\n    ++Counter;\n    // Skip first entry because it is a dummy entry.\n    if (Counter == 0) {\n      continue;\n    }\n    OS << \"[\" << Counter << \"] \" << V.getVariable()->getName();\n    if (auto F = V.getFragment())\n      OS << \" bits [\" << F->OffsetInBits << \", \"\n         << F->OffsetInBits + F->SizeInBits << \")\";\n    if (const auto *IA = V.getInlinedAt())\n      OS << \" inlined-at \" << *IA;\n    OS << \"\\n\";\n  }\n\n  auto PrintLoc = [&OS](const VarLocInfo &Loc) {\n    OS << \"DEF Var=[\" << (unsigned)Loc.VariableID << \"]\"\n       << \" Expr=\" << *Loc.Expr << \" Values=(\";\n    for (auto *Op : Loc.Values.location_ops()) {\n      errs() << Op->getName() << \" \";\n    }\n    errs() << \")\\n\";\n  };\n\n  // Print the single location variables.\n  OS << \"=== Single location vars ===\\n\";\n  for (auto It = single_locs_begin(), End = single_locs_end(); It != End;\n       ++It) {\n    PrintLoc(*It);\n  }\n\n  // Print the non-single-location defs in line with IR.\n  OS << \"=== In-line variable defs ===\";\n  for (const BasicBlock &BB : Fn) {\n    OS << \"\\n\" << BB.getName() << \":\\n\";\n    for (const Instruction &I : BB) {\n      for (auto It = locs_begin(&I), End = locs_end(&I); It != End; ++It) {\n        PrintLoc(*It);\n      }\n      OS << I << \"\\n\";\n    }\n  }\n}\n\nvoid FunctionVarLocs::init(FunctionVarLocsBuilder &Builder) {\n  // Add the single-location variables first.\n  for (const auto &VarLoc : Builder.SingleLocVars)\n    VarLocRecords.emplace_back(VarLoc);\n  // Mark the end of the section.\n  SingleVarLocEnd = VarLocRecords.size();\n\n  // Insert a contiguous block of VarLocInfos for each instruction, mapping it\n  // to the start and end position in the vector with VarLocsBeforeInst. This\n  // block includes VarLocs for any DPValues attached to that instruction.\n  for (auto &P : Builder.VarLocsBeforeInst) {\n    // Process VarLocs attached to a DPValue alongside their marker Instruction.\n    if (isa<const DPValue *>(P.first))\n      continue;\n    const Instruction *I = cast<const Instruction *>(P.first);\n    unsigned BlockStart = VarLocRecords.size();\n    // Any VarLocInfos attached to a DPValue should now be remapped to their\n    // marker Instruction, in order of DPValue appearance and prior to any\n    // VarLocInfos attached directly to that instruction.\n    for (const DPValue &DPV : I->getDbgValueRange()) {\n      // Even though DPV defines a variable location, VarLocsBeforeInst can\n      // still be empty if that VarLoc was redundant.\n      if (!Builder.VarLocsBeforeInst.count(&DPV))\n"}], "code": "  void addVarLoc(VarLocInsertPt Before, DebugVariable Var, DIExpression *Expr,\n                 DebugLoc DL, RawLocationWrapper R) {\n    VarLocInfo VarLoc;\n    VarLoc.VariableID = insertVariable(Var);\n    VarLoc.Expr = Expr;\n    VarLoc.DL = DL;\n    VarLoc.Values = R;\n    VarLocsBeforeInst[Before].emplace_back(VarLoc);\n  }\n"}, "C9181FD72A40273A": {"calls": [{"id": "626DE03159D44FE8", "name": "llvm::getDebuginfodDebuginfoUrlPath", "path": "llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp", "start": {"line": 150, "col": 1}, "end": {"line": 155, "col": 1}, "code": "  SmallString<64> UrlPath;\n  sys::path::append(UrlPath, sys::path::Style::posix, \"buildid\",\n                    buildIDToString(ID), \"debuginfo\");\n  return std::string(UrlPath);\n}\n\nExpected<std::string> getCachedOrDownloadDebuginfo(BuildIDRef ID) {\n  std::string UrlPath = getDebuginfodDebuginfoUrlPath(ID);\n  return getCachedOrDownloadArtifact(getDebuginfodCacheKey(UrlPath), UrlPath);\n}\n\n// General fetching function.\nExpected<std::string> getCachedOrDownloadArtifact(StringRef UniqueKey,\n                                                  StringRef UrlPath) {\n  SmallString<10> CacheDir;\n\n  Expected<std::string> CacheDirOrErr = getDefaultDebuginfodCacheDirectory();\n  if (!CacheDirOrErr)\n    return CacheDirOrErr.takeError();\n  CacheDir = *CacheDirOrErr;\n\n  return getCachedOrDownloadArtifact(UniqueKey, UrlPath, CacheDir,\n                                     getDefaultDebuginfodUrls(),\n                                     getDefaultDebuginfodTimeout());\n}\n\nnamespace {\n\n/// A simple handler which streams the returned data to a cache file. The cache\n/// file is only created if a 200 OK status is observed.\nclass StreamedHTTPResponseHandler : public HTTPResponseHandler {\n  using CreateStreamFn =\n      std::function<Expected<std::unique_ptr<CachedFileStream>>()>;\n  CreateStreamFn CreateStream;\n  HTTPClient &Client;\n  std::unique_ptr<CachedFileStream> FileStream;\n\npublic:\n  StreamedHTTPResponseHandler(CreateStreamFn CreateStream, HTTPClient &Client)\n      : CreateStream(CreateStream), Client(Client) {}\n  virtual ~StreamedHTTPResponseHandler() = default;\n\n  Error handleBodyChunk(StringRef BodyChunk) override;\n};\n\n} // namespace\n\nError StreamedHTTPResponseHandler::handleBodyChunk(StringRef BodyChunk) {\n  if (!FileStream) {\n    unsigned Code = Client.responseCode();\n    if (Code && Code != 200)\n      return Error::success();\n    Expected<std::unique_ptr<CachedFileStream>> FileStreamOrError =\n        CreateStream();\n    if (!FileStreamOrError)\n      return FileStreamOrError.takeError();\n    FileStream = std::move(*FileStreamOrError);\n  }\n  *FileStream->OS << BodyChunk;\n  return Error::success();\n}\n\n// An over-accepting simplification of the HTTP RFC 7230 spec.\nstatic bool isHeader(StringRef S) {\n  StringRef Name;\n  StringRef Value;\n  std::tie(Name, Value) = S.split(':');\n  if (Name.empty() || Value.empty())\n    return false;\n  return all_of(Name, [](char C) { return llvm::isPrint(C) && C != ' '; }) &&\n         all_of(Value, [](char C) { return llvm::isPrint(C) || C == '\\t'; });\n}\n\nstatic SmallVector<std::string, 0> getHeaders() {\n  const char *Filename = getenv(\"DEBUGINFOD_HEADERS_FILE\");\n  if (!Filename)\n    return {};\n  ErrorOr<std::unique_ptr<MemoryBuffer>> HeadersFile =\n      MemoryBuffer::getFile(Filename, /*IsText=*/true);\n  if (!HeadersFile)\n    return {};\n\n  SmallVector<std::string, 0> Headers;\n  uint64_t LineNumber = 0;\n  for (StringRef Line : llvm::split((*HeadersFile)->getBuffer(), '\\n')) {\n    LineNumber++;\n    if (!Line.empty() && Line.back() == '\\r')\n      Line = Line.drop_back();\n    if (!isHeader(Line)) {\n      if (!all_of(Line, llvm::isSpace))\n        WithColor::warning()\n            << \"could not parse debuginfod header: \" << Filename << ':'\n            << LineNumber << '\\n';\n      continue;\n    }\n    Headers.emplace_back(Line);\n  }\n  return Headers;\n}\n\nExpected<std::string> getCachedOrDownloadArtifact(\n    StringRef UniqueKey, StringRef UrlPath, StringRef CacheDirectoryPath,\n    ArrayRef<StringRef> DebuginfodUrls, std::chrono::milliseconds Timeout) {\n  SmallString<64> AbsCachedArtifactPath;\n  sys::path::append(AbsCachedArtifactPath, CacheDirectoryPath,\n                    \"llvmcache-\" + UniqueKey);\n\n  Expected<FileCache> CacheOrErr =\n      localCache(\"Debuginfod-client\", \".debuginfod-client\", CacheDirectoryPath);\n  if (!CacheOrErr)\n    return CacheOrErr.takeError();\n\n  FileCache Cache = *CacheOrErr;\n  // We choose an arbitrary Task parameter as we do not make use of it.\n  unsigned Task = 0;\n  Expected<AddStreamFn> CacheAddStreamOrErr = Cache(Task, UniqueKey, \"\");\n  if (!CacheAddStreamOrErr)\n    return CacheAddStreamOrErr.takeError();\n  AddStreamFn &CacheAddStream = *CacheAddStreamOrErr;\n  if (!CacheAddStream)\n    return std::string(AbsCachedArtifactPath);\n  // The artifact was not found in the local cache, query the debuginfod\n  // servers.\n  if (!HTTPClient::isAvailable())\n    return createStringError(errc::io_error,\n                             \"No working HTTP client is available.\");\n\n  if (!HTTPClient::IsInitialized)\n    return createStringError(\n        errc::io_error,\n        \"A working HTTP client is available, but it is not initialized. To \"\n        \"allow Debuginfod to make HTTP requests, call HTTPClient::initialize() \"\n        \"at the beginning of main.\");\n\n  HTTPClient Client;\n  Client.setTimeout(Timeout);\n  for (StringRef ServerUrl : DebuginfodUrls) {\n    SmallString<64> ArtifactUrl;\n    sys::path::append(ArtifactUrl, sys::path::Style::posix, ServerUrl, UrlPath);\n\n    // Perform the HTTP request and if successful, write the response body to\n    // the cache.\n    {\n      StreamedHTTPResponseHandler Handler(\n          [&]() { return CacheAddStream(Task, \"\"); }, Client);\n      HTTPRequest Request(ArtifactUrl);\n      Request.Headers = getHeaders();\n      Error Err = Client.perform(Request, Handler);\n      if (Err)\n        return std::move(Err);\n\n      unsigned Code = Client.responseCode();\n      if (Code && Code != 200)\n        continue;\n    }\n\n"}, {"id": "7BEDDA2F247D06E7", "name": "llvm::getCachedOrDownloadArtifact", "path": "llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp", "start": {"line": 163, "col": 1}, "end": {"line": 175, "col": 1}, "code": "                                                  StringRef UrlPath) {\n  SmallString<10> CacheDir;\n\n  Expected<std::string> CacheDirOrErr = getDefaultDebuginfodCacheDirectory();\n  if (!CacheDirOrErr)\n    return CacheDirOrErr.takeError();\n  CacheDir = *CacheDirOrErr;\n\n  return getCachedOrDownloadArtifact(UniqueKey, UrlPath, CacheDir,\n                                     getDefaultDebuginfodUrls(),\n                                     getDefaultDebuginfodTimeout());\n}\n\nnamespace {\n\n/// A simple handler which streams the returned data to a cache file. The cache\n/// file is only created if a 200 OK status is observed.\nclass StreamedHTTPResponseHandler : public HTTPResponseHandler {\n  using CreateStreamFn =\n      std::function<Expected<std::unique_ptr<CachedFileStream>>()>;\n  CreateStreamFn CreateStream;\n  HTTPClient &Client;\n  std::unique_ptr<CachedFileStream> FileStream;\n\npublic:\n  StreamedHTTPResponseHandler(CreateStreamFn CreateStream, HTTPClient &Client)\n      : CreateStream(CreateStream), Client(Client) {}\n  virtual ~StreamedHTTPResponseHandler() = default;\n\n  Error handleBodyChunk(StringRef BodyChunk) override;\n};\n\n} // namespace\n\nError StreamedHTTPResponseHandler::handleBodyChunk(StringRef BodyChunk) {\n  if (!FileStream) {\n    unsigned Code = Client.responseCode();\n    if (Code && Code != 200)\n      return Error::success();\n    Expected<std::unique_ptr<CachedFileStream>> FileStreamOrError =\n        CreateStream();\n    if (!FileStreamOrError)\n      return FileStreamOrError.takeError();\n    FileStream = std::move(*FileStreamOrError);\n  }\n  *FileStream->OS << BodyChunk;\n  return Error::success();\n}\n\n// An over-accepting simplification of the HTTP RFC 7230 spec.\nstatic bool isHeader(StringRef S) {\n  StringRef Name;\n  StringRef Value;\n  std::tie(Name, Value) = S.split(':');\n  if (Name.empty() || Value.empty())\n    return false;\n  return all_of(Name, [](char C) { return llvm::isPrint(C) && C != ' '; }) &&\n         all_of(Value, [](char C) { return llvm::isPrint(C) || C == '\\t'; });\n}\n\nstatic SmallVector<std::string, 0> getHeaders() {\n  const char *Filename = getenv(\"DEBUGINFOD_HEADERS_FILE\");\n  if (!Filename)\n    return {};\n  ErrorOr<std::unique_ptr<MemoryBuffer>> HeadersFile =\n      MemoryBuffer::getFile(Filename, /*IsText=*/true);\n  if (!HeadersFile)\n    return {};\n\n  SmallVector<std::string, 0> Headers;\n  uint64_t LineNumber = 0;\n  for (StringRef Line : llvm::split((*HeadersFile)->getBuffer(), '\\n')) {\n    LineNumber++;\n    if (!Line.empty() && Line.back() == '\\r')\n      Line = Line.drop_back();\n    if (!isHeader(Line)) {\n      if (!all_of(Line, llvm::isSpace))\n        WithColor::warning()\n            << \"could not parse debuginfod header: \" << Filename << ':'\n            << LineNumber << '\\n';\n      continue;\n    }\n    Headers.emplace_back(Line);\n  }\n  return Headers;\n}\n\nExpected<std::string> getCachedOrDownloadArtifact(\n    StringRef UniqueKey, StringRef UrlPath, StringRef CacheDirectoryPath,\n    ArrayRef<StringRef> DebuginfodUrls, std::chrono::milliseconds Timeout) {\n  SmallString<64> AbsCachedArtifactPath;\n  sys::path::append(AbsCachedArtifactPath, CacheDirectoryPath,\n                    \"llvmcache-\" + UniqueKey);\n\n  Expected<FileCache> CacheOrErr =\n      localCache(\"Debuginfod-client\", \".debuginfod-client\", CacheDirectoryPath);\n  if (!CacheOrErr)\n    return CacheOrErr.takeError();\n\n  FileCache Cache = *CacheOrErr;\n  // We choose an arbitrary Task parameter as we do not make use of it.\n  unsigned Task = 0;\n  Expected<AddStreamFn> CacheAddStreamOrErr = Cache(Task, UniqueKey, \"\");\n  if (!CacheAddStreamOrErr)\n    return CacheAddStreamOrErr.takeError();\n  AddStreamFn &CacheAddStream = *CacheAddStreamOrErr;\n  if (!CacheAddStream)\n    return std::string(AbsCachedArtifactPath);\n  // The artifact was not found in the local cache, query the debuginfod\n  // servers.\n  if (!HTTPClient::isAvailable())\n    return createStringError(errc::io_error,\n                             \"No working HTTP client is available.\");\n\n  if (!HTTPClient::IsInitialized)\n    return createStringError(\n        errc::io_error,\n        \"A working HTTP client is available, but it is not initialized. To \"\n        \"allow Debuginfod to make HTTP requests, call HTTPClient::initialize() \"\n        \"at the beginning of main.\");\n\n  HTTPClient Client;\n  Client.setTimeout(Timeout);\n  for (StringRef ServerUrl : DebuginfodUrls) {\n    SmallString<64> ArtifactUrl;\n    sys::path::append(ArtifactUrl, sys::path::Style::posix, ServerUrl, UrlPath);\n\n    // Perform the HTTP request and if successful, write the response body to\n    // the cache.\n    {\n      StreamedHTTPResponseHandler Handler(\n          [&]() { return CacheAddStream(Task, \"\"); }, Client);\n      HTTPRequest Request(ArtifactUrl);\n      Request.Headers = getHeaders();\n      Error Err = Client.perform(Request, Handler);\n      if (Err)\n        return std::move(Err);\n\n      unsigned Code = Client.responseCode();\n      if (Code && Code != 200)\n        continue;\n    }\n\n    Expected<CachePruningPolicy> PruningPolicyOrErr =\n        parseCachePruningPolicy(std::getenv(\"DEBUGINFOD_CACHE_POLICY\"));\n    if (!PruningPolicyOrErr)\n      return PruningPolicyOrErr.takeError();\n    pruneCache(CacheDirectoryPath, *PruningPolicyOrErr);\n\n    // Return the path to the artifact on disk.\n    return std::string(AbsCachedArtifactPath);\n  }\n\n  return createStringError(errc::argument_out_of_domain, \"build id not found\");\n}\n\nDebuginfodLogEntry::DebuginfodLogEntry(const Twine &Message)\n    : Message(Message.str()) {}\n\nvoid DebuginfodLog::push(const Twine &Message) {\n  push(DebuginfodLogEntry(Message));\n}\n\nvoid DebuginfodLog::push(DebuginfodLogEntry Entry) {\n  {\n    std::lock_guard<std::mutex> Guard(QueueMutex);\n    LogEntryQueue.push(Entry);\n  }\n  QueueCondition.notify_one();\n}\n\nDebuginfodLogEntry DebuginfodLog::pop() {\n  {\n    std::unique_lock<std::mutex> Guard(QueueMutex);\n    // Wait for messages to be pushed into the queue.\n    QueueCondition.wait(Guard, [&] { return !LogEntryQueue.empty(); });\n"}, {"id": "C5BCA9E9D8A489C1", "name": "llvm::getDebuginfodCacheKey", "path": "llvm-project/llvm/lib/Debuginfod/Debuginfod.cpp", "start": {"line": 57, "col": 1}, "end": {"line": 59, "col": 1}, "code": "  return utostr(xxh3_64bits(S));\n}\n\n// Returns a binary BuildID as a normalized hex string.\n// Uses lowercase for compatibility with common debuginfod servers.\nstatic std::string buildIDToString(BuildIDRef ID) {\n  return llvm::toHex(ID, /*LowerCase=*/true);\n}\n\nbool canUseDebuginfod() {\n  return HTTPClient::isAvailable() && !getDefaultDebuginfodUrls().empty();\n}\n\nSmallVector<StringRef> getDefaultDebuginfodUrls() {\n  std::shared_lock<llvm::sys::RWMutex> ReadGuard(UrlsMutex);\n  if (!DebuginfodUrls) {\n    // Only read from the environment variable if the user hasn't already\n    // set the value.\n    ReadGuard.unlock();\n    std::unique_lock<llvm::sys::RWMutex> WriteGuard(UrlsMutex);\n    DebuginfodUrls = SmallVector<StringRef>();\n    if (const char *DebuginfodUrlsEnv = std::getenv(\"DEBUGINFOD_URLS\")) {\n      StringRef(DebuginfodUrlsEnv)\n          .split(DebuginfodUrls.value(), \" \", -1, false);\n    }\n    WriteGuard.unlock();\n    ReadGuard.lock();\n  }\n  return DebuginfodUrls.value();\n}\n\n// Set the default debuginfod URL list, override the environment variable.\nvoid setDefaultDebuginfodUrls(const SmallVector<StringRef> &URLs) {\n  std::unique_lock<llvm::sys::RWMutex> WriteGuard(UrlsMutex);\n  DebuginfodUrls = URLs;\n}\n\n/// Finds a default local file caching directory for the debuginfod client,\n/// first checking DEBUGINFOD_CACHE_PATH.\nExpected<std::string> getDefaultDebuginfodCacheDirectory() {\n  if (const char *CacheDirectoryEnv = std::getenv(\"DEBUGINFOD_CACHE_PATH\"))\n    return CacheDirectoryEnv;\n\n  SmallString<64> CacheDirectory;\n  if (!sys::path::cache_directory(CacheDirectory))\n    return createStringError(\n        errc::io_error, \"Unable to determine appropriate cache directory.\");\n  sys::path::append(CacheDirectory, \"llvm-debuginfod\", \"client\");\n  return std::string(CacheDirectory);\n}\n\nstd::chrono::milliseconds getDefaultDebuginfodTimeout() {\n  long Timeout;\n  const char *DebuginfodTimeoutEnv = std::getenv(\"DEBUGINFOD_TIMEOUT\");\n  if (DebuginfodTimeoutEnv &&\n      to_integer(StringRef(DebuginfodTimeoutEnv).trim(), Timeout, 10))\n    return std::chrono::milliseconds(Timeout * 1000);\n\n  return std::chrono::milliseconds(90 * 1000);\n}\n"}], "code": "Expected<std::string> getCachedOrDownloadDebuginfo(BuildIDRef ID) {\n  std::string UrlPath = getDebuginfodDebuginfoUrlPath(ID);\n  return getCachedOrDownloadArtifact(getDebuginfodCacheKey(UrlPath), UrlPath);\n}\n"}, "DB9278CCBDD4AA03": {"calls": [{"id": "3A26296B4DB7232B", "name": "llvm::SetVector::canBeSmall", "path": "llvm-project/llvm/include/llvm/ADT/SetVector.h", "start": {"line": 353, "col": 17}, "end": {"line": 353, "col": 69}, "code": "\n  [[nodiscard]] bool isSmall() const { return set_.empty(); }\n\n  void makeBig() {\n    if constexpr (canBeSmall())\n      for (const auto &entry : vector_)\n        set_.insert(entry);\n  }\n\n  set_type set_;         ///< The set.\n  vector_type vector_;   ///< The vector.\n};\n\n/// A SetVector that performs no allocations if smaller than\n/// a certain size.\ntemplate <typename T, unsigned N>\nclass SmallSetVector : public SetVector<T, SmallVector<T, N>, DenseSet<T>, N> {\npublic:\n  SmallSetVector() = default;\n\n  /// Initialize a SmallSetVector with a range of elements\n  template<typename It>\n  SmallSetVector(It Start, It End) {\n    this->insert(Start, End);\n  }\n};\n\n} // end namespace llvm\n\nnamespace std {\n\n/// Implement std::swap in terms of SetVector swap.\ntemplate <typename T, typename V, typename S, unsigned N>\ninline void swap(llvm::SetVector<T, V, S, N> &LHS,\n                 llvm::SetVector<T, V, S, N> &RHS) {\n  LHS.swap(RHS);\n}\n\n/// Implement std::swap in terms of SmallSetVector swap.\ntemplate<typename T, unsigned N>\ninline void\nswap(llvm::SmallSetVector<T, N> &LHS, llvm::SmallSetVector<T, N> &RHS) {\n  LHS.swap(RHS);\n}\n\n} // end namespace std\n\n#endif // LLVM_ADT_SETVECTOR_H\n"}, {"id": "6BB3C83C79F96706", "name": "llvm::SetVector::isSmall", "path": "llvm-project/llvm/include/llvm/ADT/SetVector.h", "start": {"line": 355, "col": 17}, "end": {"line": 355, "col": 61}, "code": "\n  void makeBig() {\n    if constexpr (canBeSmall())\n      for (const auto &entry : vector_)\n        set_.insert(entry);\n  }\n\n  set_type set_;         ///< The set.\n  vector_type vector_;   ///< The vector.\n};\n\n/// A SetVector that performs no allocations if smaller than\n/// a certain size.\ntemplate <typename T, unsigned N>\nclass SmallSetVector : public SetVector<T, SmallVector<T, N>, DenseSet<T>, N> {\npublic:\n  SmallSetVector() = default;\n\n  /// Initialize a SmallSetVector with a range of elements\n  template<typename It>\n  SmallSetVector(It Start, It End) {\n    this->insert(Start, End);\n  }\n};\n\n} // end namespace llvm\n\nnamespace std {\n\n/// Implement std::swap in terms of SetVector swap.\ntemplate <typename T, typename V, typename S, unsigned N>\ninline void swap(llvm::SetVector<T, V, S, N> &LHS,\n                 llvm::SetVector<T, V, S, N> &RHS) {\n  LHS.swap(RHS);\n}\n\n/// Implement std::swap in terms of SmallSetVector swap.\ntemplate<typename T, unsigned N>\ninline void\nswap(llvm::SmallSetVector<T, N> &LHS, llvm::SmallSetVector<T, N> &RHS) {\n  LHS.swap(RHS);\n}\n\n} // end namespace std\n\n#endif // LLVM_ADT_SETVECTOR_H\n"}, {"id": "80C9C33AA48DB577", "name": "llvm::SetVector::makeBig", "path": "llvm-project/llvm/include/llvm/ADT/SetVector.h", "start": {"line": 357, "col": 3}, "end": {"line": 361, "col": 3}, "code": "    if constexpr (canBeSmall())\n      for (const auto &entry : vector_)\n        set_.insert(entry);\n  }\n\n  set_type set_;         ///< The set.\n  vector_type vector_;   ///< The vector.\n};\n\n/// A SetVector that performs no allocations if smaller than\n/// a certain size.\ntemplate <typename T, unsigned N>\nclass SmallSetVector : public SetVector<T, SmallVector<T, N>, DenseSet<T>, N> {\npublic:\n  SmallSetVector() = default;\n\n  /// Initialize a SmallSetVector with a range of elements\n  template<typename It>\n  SmallSetVector(It Start, It End) {\n    this->insert(Start, End);\n  }\n};\n\n} // end namespace llvm\n\nnamespace std {\n\n/// Implement std::swap in terms of SetVector swap.\ntemplate <typename T, typename V, typename S, unsigned N>\ninline void swap(llvm::SetVector<T, V, S, N> &LHS,\n                 llvm::SetVector<T, V, S, N> &RHS) {\n  LHS.swap(RHS);\n}\n\n/// Implement std::swap in terms of SmallSetVector swap.\ntemplate<typename T, unsigned N>\ninline void\nswap(llvm::SmallSetVector<T, N> &LHS, llvm::SmallSetVector<T, N> &RHS) {\n  LHS.swap(RHS);\n}\n\n} // end namespace std\n\n#endif // LLVM_ADT_SETVECTOR_H\n"}], "code": "  bool insert(const value_type &X) {\n    if constexpr (canBeSmall())\n      if (isSmall()) {\n        if (!llvm::is_contained(vector_, X)) {\n          vector_.push_back(X);\n          if (vector_.size() > N)\n            makeBig();\n          return true;\n        }\n        return false;\n      }\n\n    bool result = set_.insert(X).second;\n    if (result)\n      vector_.push_back(X);\n    return result;\n  }\n"}, "DC59B5FC4D1431C9": {"calls": [], "code": "static void processDbgDeclares(FunctionLoweringInfo &FuncInfo) {\n  for (const auto &I : instructions(*FuncInfo.Fn)) {\n    const auto *DI = dyn_cast<DbgDeclareInst>(&I);\n    if (DI && processDbgDeclare(FuncInfo, DI->getAddress(), DI->getExpression(),\n                                DI->getVariable(), DI->getDebugLoc()))\n      FuncInfo.PreprocessedDbgDeclares.insert(DI);\n\n    for (const DPValue &DPV : I.getDbgValueRange()) {\n      if (DPV.getType() == DPValue::LocationType::Declare &&\n          processDbgDeclare(FuncInfo, DPV.getVariableLocationOp(0),\n                            DPV.getExpression(), DPV.getVariable(),\n                            DPV.getDebugLoc()))\n        FuncInfo.PreprocessedDPVDeclares.insert(&DPV);\n    }\n  }\n}\n"}, "58EA62325D0C48FF": {"calls": [], "code": "void DebugInfoFinder::processInstruction(const Module &M,\n                                         const Instruction &I) {\n  if (auto *DVI = dyn_cast<DbgVariableIntrinsic>(&I))\n    processVariable(M, DVI->getVariable());\n\n  if (auto DbgLoc = I.getDebugLoc())\n    processLocation(M, DbgLoc.get());\n\n  for (const DPValue &DPV : I.getDbgValueRange())\n    processDPValue(M, DPV);\n}\n"}, "56E03C653BFF681D": {"calls": [], "code": "bool isInlinableLiteralV216(uint32_t Literal, uint8_t OpType) {\n  switch (OpType) {\n  case AMDGPU::OPERAND_REG_IMM_V2INT16:\n  case AMDGPU::OPERAND_REG_INLINE_C_V2INT16:\n  case AMDGPU::OPERAND_REG_INLINE_AC_V2INT16:\n    return getInlineEncodingV216(false, Literal).has_value();\n  case AMDGPU::OPERAND_REG_IMM_V2FP16:\n  case AMDGPU::OPERAND_REG_INLINE_C_V2FP16:\n  case AMDGPU::OPERAND_REG_INLINE_AC_V2FP16:\n    return getInlineEncodingV216(true, Literal).has_value();\n  default:\n    llvm_unreachable(\"bad packed operand type\");\n  }\n}\n"}, "6FEDAEEA24DD55B0": {"calls": [], "code": "Value *llvm::createAnyOfOp(IRBuilderBase &Builder, Value *StartVal,\n                           RecurKind RK, Value *Left, Value *Right) {\n  if (auto VTy = dyn_cast<VectorType>(Left->getType()))\n    StartVal = Builder.CreateVectorSplat(VTy->getElementCount(), StartVal);\n  Value *Cmp =\n      Builder.CreateCmp(CmpInst::ICMP_NE, Left, StartVal, \"rdx.select.cmp\");\n  return Builder.CreateSelect(Cmp, Left, Right, \"rdx.select\");\n}\n"}, "2154C620E839CDEB": {"calls": [], "code": "Constant *llvm::ConstantFoldLoadFromUniformValue(Constant *C, Type *Ty) {\n  if (isa<PoisonValue>(C))\n    return PoisonValue::get(Ty);\n  if (isa<UndefValue>(C))\n    return UndefValue::get(Ty);\n  if (C->isNullValue() && !Ty->isX86_MMXTy() && !Ty->isX86_AMXTy())\n    return Constant::getNullValue(Ty);\n  if (C->isAllOnesValue() &&\n      (Ty->isIntOrIntVectorTy() || Ty->isFPOrFPVectorTy()))\n    return Constant::getAllOnesValue(Ty);\n  return nullptr;\n}\n"}, "F90B550650B98F0A": {"calls": [], "code": "bool CombinerHelper::tryCombineConcatVectors(MachineInstr &MI) {\n  bool IsUndef = false;\n  SmallVector<Register, 4> Ops;\n  if (matchCombineConcatVectors(MI, IsUndef, Ops)) {\n    applyCombineConcatVectors(MI, IsUndef, Ops);\n    return true;\n  }\n  return false;\n}\n"}, "70EEF13BFD6CD7B9": {"calls": [], "code": "  CodeGenSubRegIndex *addComposite(CodeGenSubRegIndex *A,\n                                   CodeGenSubRegIndex *B) {\n    assert(A && B);\n    std::pair<CompMap::iterator, bool> Ins =\n        Composed.insert(std::make_pair(A, B));\n    // Synthetic subreg indices that aren't contiguous (for instance ARM\n    // register tuples) don't have a bit range, so it's OK to let\n    // B->Offset == -1. For the other cases, accumulate the offset and set\n    // the size here. Only do so if there is no offset yet though.\n    if ((Offset != (uint16_t)-1 && A->Offset != (uint16_t)-1) &&\n        (B->Offset == (uint16_t)-1)) {\n      B->Offset = Offset + A->Offset;\n      B->Size = A->Size;\n    }\n    return (Ins.second || Ins.first->second == B) ? nullptr : Ins.first->second;\n  }\n"}, "8FD16A68609F8B70": {"calls": [], "code": "std::pair<Value *, FPClassTest> llvm::fcmpToClassTest(FCmpInst::Predicate Pred,\n                                                      const Function &F,\n                                                      Value *LHS, Value *RHS,\n                                                      bool LookThroughSrc) {\n  const APFloat *ConstRHS;\n  if (!match(RHS, m_APFloatAllowUndef(ConstRHS)))\n    return {nullptr, fcAllFlags};\n\n  return fcmpToClassTest(Pred, F, LHS, ConstRHS, LookThroughSrc);\n}\n"}, "4AAC00F9DBAB2703": {"calls": [], "code": "void CodeGenRegBank::addToMaps(CodeGenRegisterClass *RC) {\n  if (Record *Def = RC->getDef())\n    Def2RC.insert(std::make_pair(Def, RC));\n\n  // Duplicate classes are rejected by insert().\n  // That's OK, we only care about the properties handled by CGRC::Key.\n  CodeGenRegisterClass::Key K(*RC);\n  Key2RC.insert(std::make_pair(K, RC));\n}\n"}, "C769B65650756DEB": {"calls": [], "code": "static Register getMaxPushPopReg(const MachineFunction &MF,\n                                 const std::vector<CalleeSavedInfo> &CSI) {\n  Register MaxPushPopReg = RISCV::NoRegister;\n  for (auto &CS : CSI) {\n    // RISCVRegisterInfo::hasReservedSpillSlot assigns negative frame indices to\n    // registers which can be saved by Zcmp Push.\n    if (CS.getFrameIdx() < 0)\n      MaxPushPopReg = std::max(MaxPushPopReg.id(), CS.getReg().id());\n  }\n  // if rlist is {rs, s0-s10}, then s11 will also be included\n  if (MaxPushPopReg == RISCV::X26)\n    MaxPushPopReg = RISCV::X27;\n  return MaxPushPopReg;\n}\n"}, "292D96CBB32F5AF6": {"calls": [], "code": "  unsigned newRegUnit(unsigned Weight) {\n    RegUnits.resize(RegUnits.size() + 1);\n    RegUnits.back().Weight = Weight;\n    return RegUnits.size() - 1;\n  }\n"}, "5FA5D3F4E05F7A0B": {"calls": [], "code": "  unsigned newRegUnit(CodeGenRegister *R0, CodeGenRegister *R1 = nullptr) {\n    RegUnits.resize(RegUnits.size() + 1);\n    RegUnit &RU = RegUnits.back();\n    RU.Roots[0] = R0;\n    RU.Roots[1] = R1;\n    RU.Artificial = R0->Artificial;\n    if (R1)\n      RU.Artificial |= R1->Artificial;\n    return RegUnits.size() - 1;\n  }\n"}, "7A1498112E0F97DE": {"calls": [], "code": "  unsigned getTopoSig() const {\n    assert(SuperRegsComplete && \"TopoSigs haven't been computed yet.\");\n    return TopoSig;\n  }\n"}, "FD5686A3D786BAAE": {"calls": [], "code": "CodeGenSubRegIndex *CodeGenRegBank::getSubRegIdx(Record *Def) {\n  CodeGenSubRegIndex *&Idx = Def2SubRegIdx[Def];\n  if (Idx)\n    return Idx;\n  SubRegIndices.emplace_back(Def, SubRegIndices.size() + 1);\n  Idx = &SubRegIndices.back();\n  return Idx;\n}\n"}, "79BD5116DDE48C39": {"calls": [{"id": "9EE8FDB9605C55BC", "name": "llvm::MachineInstr::getOpcode", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineInstr.h", "start": {"line": 543, "col": 3}, "end": {"line": 543, "col": 53}, "code": "\n  /// Retuns the total number of operands.\n  unsigned getNumOperands() const { return NumOperands; }\n\n  /// Returns the total number of operands which are debug locations.\n  unsigned getNumDebugOperands() const {\n    return std::distance(debug_operands().begin(), debug_operands().end());\n  }\n\n  const MachineOperand& getOperand(unsigned i) const {\n    assert(i < getNumOperands() && \"getOperand() out of range!\");\n    return Operands[i];\n  }\n  MachineOperand& getOperand(unsigned i) {\n    assert(i < getNumOperands() && \"getOperand() out of range!\");\n    return Operands[i];\n  }\n\n  MachineOperand &getDebugOperand(unsigned Index) {\n    assert(Index < getNumDebugOperands() && \"getDebugOperand() out of range!\");\n    return *(debug_operands().begin() + Index);\n  }\n  const MachineOperand &getDebugOperand(unsigned Index) const {\n    assert(Index < getNumDebugOperands() && \"getDebugOperand() out of range!\");\n    return *(debug_operands().begin() + Index);\n  }\n\n  /// Returns whether this debug value has at least one debug operand with the\n  /// register \\p Reg.\n  bool hasDebugOperandForReg(Register Reg) const {\n    return any_of(debug_operands(), [Reg](const MachineOperand &Op) {\n      return Op.isReg() && Op.getReg() == Reg;\n    });\n  }\n\n  /// Returns a range of all of the operands that correspond to a debug use of\n  /// \\p Reg.\n  template <typename Operand, typename Instruction>\n  static iterator_range<\n      filter_iterator<Operand *, std::function<bool(Operand &Op)>>>\n  getDebugOperandsForReg(Instruction *MI, Register Reg) {\n    std::function<bool(Operand & Op)> OpUsesReg(\n        [Reg](Operand &Op) { return Op.isReg() && Op.getReg() == Reg; });\n    return make_filter_range(MI->debug_operands(), OpUsesReg);\n  }\n  iterator_range<filter_iterator<const MachineOperand *,\n                                 std::function<bool(const MachineOperand &Op)>>>\n  getDebugOperandsForReg(Register Reg) const {\n    return MachineInstr::getDebugOperandsForReg<const MachineOperand,\n                                                const MachineInstr>(this, Reg);\n  }\n  iterator_range<filter_iterator<MachineOperand *,\n                                 std::function<bool(MachineOperand &Op)>>>\n  getDebugOperandsForReg(Register Reg) {\n    return MachineInstr::getDebugOperandsForReg<MachineOperand, MachineInstr>(\n        this, Reg);\n  }\n\n  bool isDebugOperand(const MachineOperand *Op) const {\n    return Op >= adl_begin(debug_operands()) && Op <= adl_end(debug_operands());\n  }\n\n  unsigned getDebugOperandIndex(const MachineOperand *Op) const {\n    assert(isDebugOperand(Op) && \"Expected a debug operand.\");\n    return std::distance(adl_begin(debug_operands()), Op);\n  }\n\n  /// Returns the total number of definitions.\n  unsigned getNumDefs() const {\n    return getNumExplicitDefs() + MCID->implicit_defs().size();\n  }\n\n  /// Returns true if the instruction has implicit definition.\n  bool hasImplicitDef() const {\n    for (const MachineOperand &MO : implicit_operands())\n      if (MO.isDef() && MO.isImplicit())\n        return true;\n    return false;\n  }\n\n  /// Returns the implicit operands number.\n  unsigned getNumImplicitOperands() const {\n    return getNumOperands() - getNumExplicitOperands();\n  }\n\n  /// Return true if operand \\p OpIdx is a subregister index.\n  bool isOperandSubregIdx(unsigned OpIdx) const {\n    assert(getOperand(OpIdx).isImm() && \"Expected MO_Immediate operand type.\");\n    if (isExtractSubreg() && OpIdx == 2)\n      return true;\n    if (isInsertSubreg() && OpIdx == 3)\n      return true;\n    if (isRegSequence() && OpIdx > 1 && (OpIdx % 2) == 0)\n      return true;\n    if (isSubregToReg() && OpIdx == 3)\n      return true;\n    return false;\n  }\n\n  /// Returns the number of non-implicit operands.\n  unsigned getNumExplicitOperands() const;\n\n  /// Returns the number of non-implicit definitions.\n  unsigned getNumExplicitDefs() const;\n\n  /// iterator/begin/end - Iterate over all operands of a machine instruction.\n  using mop_iterator = MachineOperand *;\n  using const_mop_iterator = const MachineOperand *;\n\n  mop_iterator operands_begin() { return Operands; }\n  mop_iterator operands_end() { return Operands + NumOperands; }\n\n  const_mop_iterator operands_begin() const { return Operands; }\n  const_mop_iterator operands_end() const { return Operands + NumOperands; }\n\n  iterator_range<mop_iterator> operands() {\n    return make_range(operands_begin(), operands_end());\n  }\n  iterator_range<const_mop_iterator> operands() const {\n    return make_range(operands_begin(), operands_end());\n  }\n  iterator_range<mop_iterator> explicit_operands() {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n  iterator_range<const_mop_iterator> explicit_operands() const {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n  iterator_range<mop_iterator> implicit_operands() {\n    return make_range(explicit_operands().end(), operands_end());\n  }\n  iterator_range<const_mop_iterator> implicit_operands() const {\n    return make_range(explicit_operands().end(), operands_end());\n  }\n  /// Returns a range over all operands that are used to determine the variable\n  /// location for this DBG_VALUE instruction.\n  iterator_range<mop_iterator> debug_operands() {\n    assert((isDebugValueLike()) && \"Must be a debug value instruction.\");\n    return isNonListDebugValue()\n               ? make_range(operands_begin(), operands_begin() + 1)\n               : make_range(operands_begin() + 2, operands_end());\n  }\n  /// \\copydoc debug_operands()\n  iterator_range<const_mop_iterator> debug_operands() const {\n    assert((isDebugValueLike()) && \"Must be a debug value instruction.\");\n    return isNonListDebugValue()\n               ? make_range(operands_begin(), operands_begin() + 1)\n               : make_range(operands_begin() + 2, operands_end());\n  }\n  /// Returns a range over all explicit operands that are register definitions.\n  /// Implicit definition are not included!\n  iterator_range<mop_iterator> defs() {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitDefs());\n  }\n  /// \\copydoc defs()\n  iterator_range<const_mop_iterator> defs() const {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitDefs());\n  }\n  /// Returns a range that includes all operands that are register uses.\n  /// This may include unrelated operands which are not register uses.\n  iterator_range<mop_iterator> uses() {\n    return make_range(operands_begin() + getNumExplicitDefs(), operands_end());\n  }\n  /// \\copydoc uses()\n  iterator_range<const_mop_iterator> uses() const {\n    return make_range(operands_begin() + getNumExplicitDefs(), operands_end());\n  }\n  iterator_range<mop_iterator> explicit_uses() {\n    return make_range(operands_begin() + getNumExplicitDefs(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n  iterator_range<const_mop_iterator> explicit_uses() const {\n    return make_range(operands_begin() + getNumExplicitDefs(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n\n  using filtered_mop_iterator =\n      filter_iterator<mop_iterator, bool (*)(const MachineOperand &)>;\n  using filtered_const_mop_iterator =\n      filter_iterator<const_mop_iterator, bool (*)(const MachineOperand &)>;\n\n  /// Returns an iterator range over all operands that are (explicit or\n  /// implicit) register defs.\n  iterator_range<filtered_mop_iterator> all_defs() {\n    return make_filter_range(operands(), opIsRegDef);\n  }\n  /// \\copydoc all_defs()\n  iterator_range<filtered_const_mop_iterator> all_defs() const {\n    return make_filter_range(operands(), opIsRegDef);\n  }\n\n  /// Returns an iterator range over all operands that are (explicit or\n  /// implicit) register uses.\n  iterator_range<filtered_mop_iterator> all_uses() {\n    return make_filter_range(uses(), opIsRegUse);\n  }\n  /// \\copydoc all_uses()\n  iterator_range<filtered_const_mop_iterator> all_uses() const {\n    return make_filter_range(uses(), opIsRegUse);\n  }\n\n  /// Returns the number of the operand iterator \\p I points to.\n  unsigned getOperandNo(const_mop_iterator I) const {\n    return I - operands_begin();\n  }\n\n  /// Access to memory operands of the instruction. If there are none, that does\n  /// not imply anything about whether the function accesses memory. Instead,\n  /// the caller must behave conservatively.\n  ArrayRef<MachineMemOperand *> memoperands() const {\n    if (!Info)\n      return {};\n\n    if (Info.is<EIIK_MMO>())\n      return ArrayRef(Info.getAddrOfZeroTagPointer(), 1);\n\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getMMOs();\n\n    return {};\n  }\n\n  /// Access to memory operands of the instruction.\n  ///\n  /// If `memoperands_begin() == memoperands_end()`, that does not imply\n  /// anything about whether the function accesses memory. Instead, the caller\n  /// must behave conservatively.\n  mmo_iterator memoperands_begin() const { return memoperands().begin(); }\n\n  /// Access to memory operands of the instruction.\n  ///\n  /// If `memoperands_begin() == memoperands_end()`, that does not imply\n  /// anything about whether the function accesses memory. Instead, the caller\n  /// must behave conservatively.\n  mmo_iterator memoperands_end() const { return memoperands().end(); }\n\n  /// Return true if we don't have any memory operands which described the\n  /// memory access done by this instruction.  If this is true, calling code\n  /// must be conservative.\n  bool memoperands_empty() const { return memoperands().empty(); }\n\n  /// Return true if this instruction has exactly one MachineMemOperand.\n  bool hasOneMemOperand() const { return memoperands().size() == 1; }\n\n  /// Return the number of memory operands.\n  unsigned getNumMemOperands() const { return memoperands().size(); }\n\n  /// Helper to extract a pre-instruction symbol if one has been added.\n  MCSymbol *getPreInstrSymbol() const {\n    if (!Info)\n      return nullptr;\n    if (MCSymbol *S = Info.get<EIIK_PreInstrSymbol>())\n      return S;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getPreInstrSymbol();\n\n    return nullptr;\n  }\n\n  /// Helper to extract a post-instruction symbol if one has been added.\n  MCSymbol *getPostInstrSymbol() const {\n    if (!Info)\n      return nullptr;\n    if (MCSymbol *S = Info.get<EIIK_PostInstrSymbol>())\n      return S;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getPostInstrSymbol();\n\n    return nullptr;\n  }\n\n  /// Helper to extract a heap alloc marker if one has been added.\n  MDNode *getHeapAllocMarker() const {\n    if (!Info)\n      return nullptr;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getHeapAllocMarker();\n\n    return nullptr;\n  }\n\n  /// Helper to extract PCSections metadata target sections.\n  MDNode *getPCSections() const {\n    if (!Info)\n      return nullptr;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getPCSections();\n\n    return nullptr;\n  }\n\n  /// Helper to extract a CFI type hash if one has been added.\n  uint32_t getCFIType() const {\n    if (!Info)\n      return 0;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getCFIType();\n\n    return 0;\n  }\n\n  /// API for querying MachineInstr properties. They are the same as MCInstrDesc\n  /// queries but they are bundle aware.\n\n  enum QueryType {\n    IgnoreBundle,    // Ignore bundles\n    AnyInBundle,     // Return true if any instruction in bundle has property\n    AllInBundle      // Return true if all instructions in bundle have property\n  };\n\n  /// Return true if the instruction (or in the case of a bundle,\n  /// the instructions inside the bundle) has the specified property.\n  /// The first argument is the property being queried.\n  /// The second argument indicates whether the query should look inside\n  /// instruction bundles.\n  bool hasProperty(unsigned MCFlag, QueryType Type = AnyInBundle) const {\n    assert(MCFlag < 64 &&\n           \"MCFlag out of range for bit mask in getFlags/hasPropertyInBundle.\");\n    // Inline the fast path for unbundled or bundle-internal instructions.\n    if (Type == IgnoreBundle || !isBundled() || isBundledWithPred())\n      return getDesc().getFlags() & (1ULL << MCFlag);\n\n    // If this is the first instruction in a bundle, take the slow path.\n    return hasPropertyInBundle(1ULL << MCFlag, Type);\n  }\n\n  /// Return true if this is an instruction that should go through the usual\n  /// legalization steps.\n  bool isPreISelOpcode(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::PreISelOpcode, Type);\n  }\n\n  /// Return true if this instruction can have a variable number of operands.\n  /// In this case, the variable operands will be after the normal\n  /// operands but before the implicit definitions and uses (if any are\n  /// present).\n  bool isVariadic(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Variadic, Type);\n  }\n\n  /// Set if this instruction has an optional definition, e.g.\n  /// ARM instructions which can set condition code if 's' bit is set.\n  bool hasOptionalDef(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::HasOptionalDef, Type);\n  }\n\n  /// Return true if this is a pseudo instruction that doesn't\n  /// correspond to a real machine instruction.\n  bool isPseudo(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Pseudo, Type);\n  }\n\n  /// Return true if this instruction doesn't produce any output in the form of\n  /// executable instructions.\n  bool isMetaInstruction(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Meta, Type);\n  }\n\n  bool isReturn(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Return, Type);\n  }\n\n  /// Return true if this is an instruction that marks the end of an EH scope,\n  /// i.e., a catchpad or a cleanuppad instruction.\n  bool isEHScopeReturn(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::EHScopeReturn, Type);\n  }\n\n  bool isCall(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Call, Type);\n  }\n\n  /// Return true if this is a call instruction that may have an associated\n  /// call site entry in the debug info.\n  bool isCandidateForCallSiteEntry(QueryType Type = IgnoreBundle) const;\n  /// Return true if copying, moving, or erasing this instruction requires\n  /// updating Call Site Info (see \\ref copyCallSiteInfo, \\ref moveCallSiteInfo,\n  /// \\ref eraseCallSiteInfo).\n  bool shouldUpdateCallSiteInfo() const;\n\n  /// Returns true if the specified instruction stops control flow\n  /// from executing the instruction immediately following it.  Examples include\n  /// unconditional branches and return instructions.\n  bool isBarrier(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Barrier, Type);\n  }\n\n  /// Returns true if this instruction part of the terminator for a basic block.\n  /// Typically this is things like return and branch instructions.\n  ///\n  /// Various passes use this to insert code into the bottom of a basic block,\n  /// but before control flow occurs.\n  bool isTerminator(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Terminator, Type);\n  }\n\n  /// Returns true if this is a conditional, unconditional, or indirect branch.\n  /// Predicates below can be used to discriminate between\n  /// these cases, and the TargetInstrInfo::analyzeBranch method can be used to\n  /// get more information.\n  bool isBranch(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Branch, Type);\n  }\n\n  /// Return true if this is an indirect branch, such as a\n  /// branch through a register.\n  bool isIndirectBranch(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::IndirectBranch, Type);\n  }\n\n  /// Return true if this is a branch which may fall\n  /// through to the next instruction or may transfer control flow to some other\n  /// block.  The TargetInstrInfo::analyzeBranch method can be used to get more\n  /// information about this branch.\n  bool isConditionalBranch(QueryType Type = AnyInBundle) const {\n    return isBranch(Type) && !isBarrier(Type) && !isIndirectBranch(Type);\n  }\n\n  /// Return true if this is a branch which always\n  /// transfers control flow to some other block.  The\n  /// TargetInstrInfo::analyzeBranch method can be used to get more information\n  /// about this branch.\n  bool isUnconditionalBranch(QueryType Type = AnyInBundle) const {\n    return isBranch(Type) && isBarrier(Type) && !isIndirectBranch(Type);\n  }\n\n  /// Return true if this instruction has a predicate operand that\n  /// controls execution.  It may be set to 'always', or may be set to other\n  /// values.   There are various methods in TargetInstrInfo that can be used to\n  /// control and modify the predicate in this instruction.\n  bool isPredicable(QueryType Type = AllInBundle) const {\n    // If it's a bundle than all bundled instructions must be predicable for this\n    // to return true.\n    return hasProperty(MCID::Predicable, Type);\n  }\n\n  /// Return true if this instruction is a comparison.\n  bool isCompare(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Compare, Type);\n  }\n\n  /// Return true if this instruction is a move immediate\n  /// (including conditional moves) instruction.\n  bool isMoveImmediate(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::MoveImm, Type);\n  }\n\n  /// Return true if this instruction is a register move.\n  /// (including moving values from subreg to reg)\n  bool isMoveReg(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::MoveReg, Type);\n  }\n\n  /// Return true if this instruction is a bitcast instruction.\n  bool isBitcast(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Bitcast, Type);\n  }\n\n  /// Return true if this instruction is a select instruction.\n  bool isSelect(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Select, Type);\n  }\n\n  /// Return true if this instruction cannot be safely duplicated.\n  /// For example, if the instruction has a unique labels attached\n  /// to it, duplicating it would cause multiple definition errors.\n  bool isNotDuplicable(QueryType Type = AnyInBundle) const {\n    if (getPreInstrSymbol() || getPostInstrSymbol())\n      return true;\n    return hasProperty(MCID::NotDuplicable, Type);\n  }\n\n  /// Return true if this instruction is convergent.\n  /// Convergent instructions can not be made control-dependent on any\n  /// additional values.\n  bool isConvergent(QueryType Type = AnyInBundle) const {\n    if (isInlineAsm()) {\n      unsigned ExtraInfo = getOperand(InlineAsm::MIOp_ExtraInfo).getImm();\n      if (ExtraInfo & InlineAsm::Extra_IsConvergent)\n        return true;\n    }\n    if (getFlag(NoConvergent))\n      return false;\n    return hasProperty(MCID::Convergent, Type);\n  }\n\n  /// Returns true if the specified instruction has a delay slot\n  /// which must be filled by the code generator.\n  bool hasDelaySlot(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::DelaySlot, Type);\n  }\n\n  /// Return true for instructions that can be folded as\n  /// memory operands in other instructions. The most common use for this\n  /// is instructions that are simple loads from memory that don't modify\n  /// the loaded value in any way, but it can also be used for instructions\n  /// that can be expressed as constant-pool loads, such as V_SETALLONES\n  /// on x86, to allow them to be folded when it is beneficial.\n  /// This should only be set on instructions that return a value in their\n  /// only virtual register definition.\n  bool canFoldAsLoad(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::FoldableAsLoad, Type);\n  }\n\n  /// Return true if this instruction behaves\n  /// the same way as the generic REG_SEQUENCE instructions.\n  /// E.g., on ARM,\n  /// dX VMOVDRR rY, rZ\n  /// is equivalent to\n  /// dX = REG_SEQUENCE rY, ssub_0, rZ, ssub_1.\n  ///\n  /// Note that for the optimizers to be able to take advantage of\n  /// this property, TargetInstrInfo::getRegSequenceLikeInputs has to be\n  /// override accordingly.\n  bool isRegSequenceLike(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::RegSequence, Type);\n  }\n\n  /// Return true if this instruction behaves\n  /// the same way as the generic EXTRACT_SUBREG instructions.\n  /// E.g., on ARM,\n  /// rX, rY VMOVRRD dZ\n  /// is equivalent to two EXTRACT_SUBREG:\n  /// rX = EXTRACT_SUBREG dZ, ssub_0\n  /// rY = EXTRACT_SUBREG dZ, ssub_1\n  ///\n  /// Note that for the optimizers to be able to take advantage of\n  /// this property, TargetInstrInfo::getExtractSubregLikeInputs has to be\n  /// override accordingly.\n  bool isExtractSubregLike(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::ExtractSubreg, Type);\n  }\n\n  /// Return true if this instruction behaves\n  /// the same way as the generic INSERT_SUBREG instructions.\n  /// E.g., on ARM,\n  /// dX = VSETLNi32 dY, rZ, Imm\n  /// is equivalent to a INSERT_SUBREG:\n  /// dX = INSERT_SUBREG dY, rZ, translateImmToSubIdx(Imm)\n  ///\n  /// Note that for the optimizers to be able to take advantage of\n"}, {"id": "D0DA705F8AC926A2", "name": "llvm::MachineInstr::getNumDefs", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineInstr.h", "start": {"line": 612, "col": 3}, "end": {"line": 614, "col": 3}, "code": "    return getNumExplicitDefs() + MCID->implicit_defs().size();\n  }\n\n  /// Returns true if the instruction has implicit definition.\n  bool hasImplicitDef() const {\n    for (const MachineOperand &MO : implicit_operands())\n      if (MO.isDef() && MO.isImplicit())\n        return true;\n    return false;\n  }\n\n  /// Returns the implicit operands number.\n  unsigned getNumImplicitOperands() const {\n    return getNumOperands() - getNumExplicitOperands();\n  }\n\n  /// Return true if operand \\p OpIdx is a subregister index.\n  bool isOperandSubregIdx(unsigned OpIdx) const {\n    assert(getOperand(OpIdx).isImm() && \"Expected MO_Immediate operand type.\");\n    if (isExtractSubreg() && OpIdx == 2)\n      return true;\n    if (isInsertSubreg() && OpIdx == 3)\n      return true;\n    if (isRegSequence() && OpIdx > 1 && (OpIdx % 2) == 0)\n      return true;\n    if (isSubregToReg() && OpIdx == 3)\n      return true;\n    return false;\n  }\n\n  /// Returns the number of non-implicit operands.\n  unsigned getNumExplicitOperands() const;\n\n  /// Returns the number of non-implicit definitions.\n  unsigned getNumExplicitDefs() const;\n\n  /// iterator/begin/end - Iterate over all operands of a machine instruction.\n  using mop_iterator = MachineOperand *;\n  using const_mop_iterator = const MachineOperand *;\n\n  mop_iterator operands_begin() { return Operands; }\n  mop_iterator operands_end() { return Operands + NumOperands; }\n\n  const_mop_iterator operands_begin() const { return Operands; }\n  const_mop_iterator operands_end() const { return Operands + NumOperands; }\n\n  iterator_range<mop_iterator> operands() {\n    return make_range(operands_begin(), operands_end());\n  }\n  iterator_range<const_mop_iterator> operands() const {\n    return make_range(operands_begin(), operands_end());\n  }\n  iterator_range<mop_iterator> explicit_operands() {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n  iterator_range<const_mop_iterator> explicit_operands() const {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n  iterator_range<mop_iterator> implicit_operands() {\n    return make_range(explicit_operands().end(), operands_end());\n  }\n  iterator_range<const_mop_iterator> implicit_operands() const {\n    return make_range(explicit_operands().end(), operands_end());\n  }\n  /// Returns a range over all operands that are used to determine the variable\n  /// location for this DBG_VALUE instruction.\n  iterator_range<mop_iterator> debug_operands() {\n    assert((isDebugValueLike()) && \"Must be a debug value instruction.\");\n    return isNonListDebugValue()\n               ? make_range(operands_begin(), operands_begin() + 1)\n               : make_range(operands_begin() + 2, operands_end());\n  }\n  /// \\copydoc debug_operands()\n  iterator_range<const_mop_iterator> debug_operands() const {\n    assert((isDebugValueLike()) && \"Must be a debug value instruction.\");\n    return isNonListDebugValue()\n               ? make_range(operands_begin(), operands_begin() + 1)\n               : make_range(operands_begin() + 2, operands_end());\n  }\n  /// Returns a range over all explicit operands that are register definitions.\n  /// Implicit definition are not included!\n  iterator_range<mop_iterator> defs() {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitDefs());\n  }\n  /// \\copydoc defs()\n  iterator_range<const_mop_iterator> defs() const {\n    return make_range(operands_begin(),\n                      operands_begin() + getNumExplicitDefs());\n  }\n  /// Returns a range that includes all operands that are register uses.\n  /// This may include unrelated operands which are not register uses.\n  iterator_range<mop_iterator> uses() {\n    return make_range(operands_begin() + getNumExplicitDefs(), operands_end());\n  }\n  /// \\copydoc uses()\n  iterator_range<const_mop_iterator> uses() const {\n    return make_range(operands_begin() + getNumExplicitDefs(), operands_end());\n  }\n  iterator_range<mop_iterator> explicit_uses() {\n    return make_range(operands_begin() + getNumExplicitDefs(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n  iterator_range<const_mop_iterator> explicit_uses() const {\n    return make_range(operands_begin() + getNumExplicitDefs(),\n                      operands_begin() + getNumExplicitOperands());\n  }\n\n  using filtered_mop_iterator =\n      filter_iterator<mop_iterator, bool (*)(const MachineOperand &)>;\n  using filtered_const_mop_iterator =\n      filter_iterator<const_mop_iterator, bool (*)(const MachineOperand &)>;\n\n  /// Returns an iterator range over all operands that are (explicit or\n  /// implicit) register defs.\n  iterator_range<filtered_mop_iterator> all_defs() {\n    return make_filter_range(operands(), opIsRegDef);\n  }\n  /// \\copydoc all_defs()\n  iterator_range<filtered_const_mop_iterator> all_defs() const {\n    return make_filter_range(operands(), opIsRegDef);\n  }\n\n  /// Returns an iterator range over all operands that are (explicit or\n  /// implicit) register uses.\n  iterator_range<filtered_mop_iterator> all_uses() {\n    return make_filter_range(uses(), opIsRegUse);\n  }\n  /// \\copydoc all_uses()\n  iterator_range<filtered_const_mop_iterator> all_uses() const {\n    return make_filter_range(uses(), opIsRegUse);\n  }\n\n  /// Returns the number of the operand iterator \\p I points to.\n  unsigned getOperandNo(const_mop_iterator I) const {\n    return I - operands_begin();\n  }\n\n  /// Access to memory operands of the instruction. If there are none, that does\n  /// not imply anything about whether the function accesses memory. Instead,\n  /// the caller must behave conservatively.\n  ArrayRef<MachineMemOperand *> memoperands() const {\n    if (!Info)\n      return {};\n\n    if (Info.is<EIIK_MMO>())\n      return ArrayRef(Info.getAddrOfZeroTagPointer(), 1);\n\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getMMOs();\n\n    return {};\n  }\n\n  /// Access to memory operands of the instruction.\n  ///\n  /// If `memoperands_begin() == memoperands_end()`, that does not imply\n  /// anything about whether the function accesses memory. Instead, the caller\n  /// must behave conservatively.\n  mmo_iterator memoperands_begin() const { return memoperands().begin(); }\n\n  /// Access to memory operands of the instruction.\n  ///\n  /// If `memoperands_begin() == memoperands_end()`, that does not imply\n  /// anything about whether the function accesses memory. Instead, the caller\n  /// must behave conservatively.\n  mmo_iterator memoperands_end() const { return memoperands().end(); }\n\n  /// Return true if we don't have any memory operands which described the\n  /// memory access done by this instruction.  If this is true, calling code\n  /// must be conservative.\n  bool memoperands_empty() const { return memoperands().empty(); }\n\n  /// Return true if this instruction has exactly one MachineMemOperand.\n  bool hasOneMemOperand() const { return memoperands().size() == 1; }\n\n  /// Return the number of memory operands.\n  unsigned getNumMemOperands() const { return memoperands().size(); }\n\n  /// Helper to extract a pre-instruction symbol if one has been added.\n  MCSymbol *getPreInstrSymbol() const {\n    if (!Info)\n      return nullptr;\n    if (MCSymbol *S = Info.get<EIIK_PreInstrSymbol>())\n      return S;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getPreInstrSymbol();\n\n    return nullptr;\n  }\n\n  /// Helper to extract a post-instruction symbol if one has been added.\n  MCSymbol *getPostInstrSymbol() const {\n    if (!Info)\n      return nullptr;\n    if (MCSymbol *S = Info.get<EIIK_PostInstrSymbol>())\n      return S;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getPostInstrSymbol();\n\n    return nullptr;\n  }\n\n  /// Helper to extract a heap alloc marker if one has been added.\n  MDNode *getHeapAllocMarker() const {\n    if (!Info)\n      return nullptr;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getHeapAllocMarker();\n\n    return nullptr;\n  }\n\n  /// Helper to extract PCSections metadata target sections.\n  MDNode *getPCSections() const {\n    if (!Info)\n      return nullptr;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getPCSections();\n\n    return nullptr;\n  }\n\n  /// Helper to extract a CFI type hash if one has been added.\n  uint32_t getCFIType() const {\n    if (!Info)\n      return 0;\n    if (ExtraInfo *EI = Info.get<EIIK_OutOfLine>())\n      return EI->getCFIType();\n\n    return 0;\n  }\n\n  /// API for querying MachineInstr properties. They are the same as MCInstrDesc\n  /// queries but they are bundle aware.\n\n  enum QueryType {\n    IgnoreBundle,    // Ignore bundles\n    AnyInBundle,     // Return true if any instruction in bundle has property\n    AllInBundle      // Return true if all instructions in bundle have property\n  };\n\n  /// Return true if the instruction (or in the case of a bundle,\n  /// the instructions inside the bundle) has the specified property.\n  /// The first argument is the property being queried.\n  /// The second argument indicates whether the query should look inside\n  /// instruction bundles.\n  bool hasProperty(unsigned MCFlag, QueryType Type = AnyInBundle) const {\n    assert(MCFlag < 64 &&\n           \"MCFlag out of range for bit mask in getFlags/hasPropertyInBundle.\");\n    // Inline the fast path for unbundled or bundle-internal instructions.\n    if (Type == IgnoreBundle || !isBundled() || isBundledWithPred())\n      return getDesc().getFlags() & (1ULL << MCFlag);\n\n    // If this is the first instruction in a bundle, take the slow path.\n    return hasPropertyInBundle(1ULL << MCFlag, Type);\n  }\n\n  /// Return true if this is an instruction that should go through the usual\n  /// legalization steps.\n  bool isPreISelOpcode(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::PreISelOpcode, Type);\n  }\n\n  /// Return true if this instruction can have a variable number of operands.\n  /// In this case, the variable operands will be after the normal\n  /// operands but before the implicit definitions and uses (if any are\n  /// present).\n  bool isVariadic(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Variadic, Type);\n  }\n\n  /// Set if this instruction has an optional definition, e.g.\n  /// ARM instructions which can set condition code if 's' bit is set.\n  bool hasOptionalDef(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::HasOptionalDef, Type);\n  }\n\n  /// Return true if this is a pseudo instruction that doesn't\n  /// correspond to a real machine instruction.\n  bool isPseudo(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Pseudo, Type);\n  }\n\n  /// Return true if this instruction doesn't produce any output in the form of\n  /// executable instructions.\n  bool isMetaInstruction(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Meta, Type);\n  }\n\n  bool isReturn(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Return, Type);\n  }\n\n  /// Return true if this is an instruction that marks the end of an EH scope,\n  /// i.e., a catchpad or a cleanuppad instruction.\n  bool isEHScopeReturn(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::EHScopeReturn, Type);\n  }\n\n  bool isCall(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Call, Type);\n  }\n\n  /// Return true if this is a call instruction that may have an associated\n  /// call site entry in the debug info.\n  bool isCandidateForCallSiteEntry(QueryType Type = IgnoreBundle) const;\n  /// Return true if copying, moving, or erasing this instruction requires\n  /// updating Call Site Info (see \\ref copyCallSiteInfo, \\ref moveCallSiteInfo,\n  /// \\ref eraseCallSiteInfo).\n  bool shouldUpdateCallSiteInfo() const;\n\n  /// Returns true if the specified instruction stops control flow\n  /// from executing the instruction immediately following it.  Examples include\n  /// unconditional branches and return instructions.\n  bool isBarrier(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Barrier, Type);\n  }\n\n  /// Returns true if this instruction part of the terminator for a basic block.\n  /// Typically this is things like return and branch instructions.\n  ///\n  /// Various passes use this to insert code into the bottom of a basic block,\n  /// but before control flow occurs.\n  bool isTerminator(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Terminator, Type);\n  }\n\n  /// Returns true if this is a conditional, unconditional, or indirect branch.\n  /// Predicates below can be used to discriminate between\n  /// these cases, and the TargetInstrInfo::analyzeBranch method can be used to\n  /// get more information.\n  bool isBranch(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::Branch, Type);\n  }\n\n  /// Return true if this is an indirect branch, such as a\n  /// branch through a register.\n  bool isIndirectBranch(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::IndirectBranch, Type);\n  }\n\n  /// Return true if this is a branch which may fall\n  /// through to the next instruction or may transfer control flow to some other\n  /// block.  The TargetInstrInfo::analyzeBranch method can be used to get more\n  /// information about this branch.\n  bool isConditionalBranch(QueryType Type = AnyInBundle) const {\n    return isBranch(Type) && !isBarrier(Type) && !isIndirectBranch(Type);\n  }\n\n  /// Return true if this is a branch which always\n  /// transfers control flow to some other block.  The\n  /// TargetInstrInfo::analyzeBranch method can be used to get more information\n  /// about this branch.\n  bool isUnconditionalBranch(QueryType Type = AnyInBundle) const {\n    return isBranch(Type) && isBarrier(Type) && !isIndirectBranch(Type);\n  }\n\n  /// Return true if this instruction has a predicate operand that\n  /// controls execution.  It may be set to 'always', or may be set to other\n  /// values.   There are various methods in TargetInstrInfo that can be used to\n  /// control and modify the predicate in this instruction.\n  bool isPredicable(QueryType Type = AllInBundle) const {\n    // If it's a bundle than all bundled instructions must be predicable for this\n    // to return true.\n    return hasProperty(MCID::Predicable, Type);\n  }\n\n  /// Return true if this instruction is a comparison.\n  bool isCompare(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Compare, Type);\n  }\n\n  /// Return true if this instruction is a move immediate\n  /// (including conditional moves) instruction.\n  bool isMoveImmediate(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::MoveImm, Type);\n  }\n\n  /// Return true if this instruction is a register move.\n  /// (including moving values from subreg to reg)\n  bool isMoveReg(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::MoveReg, Type);\n  }\n\n  /// Return true if this instruction is a bitcast instruction.\n  bool isBitcast(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Bitcast, Type);\n  }\n\n  /// Return true if this instruction is a select instruction.\n  bool isSelect(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Select, Type);\n  }\n\n  /// Return true if this instruction cannot be safely duplicated.\n  /// For example, if the instruction has a unique labels attached\n  /// to it, duplicating it would cause multiple definition errors.\n  bool isNotDuplicable(QueryType Type = AnyInBundle) const {\n    if (getPreInstrSymbol() || getPostInstrSymbol())\n      return true;\n    return hasProperty(MCID::NotDuplicable, Type);\n  }\n\n  /// Return true if this instruction is convergent.\n  /// Convergent instructions can not be made control-dependent on any\n  /// additional values.\n  bool isConvergent(QueryType Type = AnyInBundle) const {\n    if (isInlineAsm()) {\n      unsigned ExtraInfo = getOperand(InlineAsm::MIOp_ExtraInfo).getImm();\n      if (ExtraInfo & InlineAsm::Extra_IsConvergent)\n        return true;\n    }\n    if (getFlag(NoConvergent))\n      return false;\n    return hasProperty(MCID::Convergent, Type);\n  }\n\n  /// Returns true if the specified instruction has a delay slot\n  /// which must be filled by the code generator.\n  bool hasDelaySlot(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::DelaySlot, Type);\n  }\n\n  /// Return true for instructions that can be folded as\n  /// memory operands in other instructions. The most common use for this\n  /// is instructions that are simple loads from memory that don't modify\n  /// the loaded value in any way, but it can also be used for instructions\n  /// that can be expressed as constant-pool loads, such as V_SETALLONES\n  /// on x86, to allow them to be folded when it is beneficial.\n  /// This should only be set on instructions that return a value in their\n  /// only virtual register definition.\n  bool canFoldAsLoad(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::FoldableAsLoad, Type);\n  }\n\n  /// Return true if this instruction behaves\n  /// the same way as the generic REG_SEQUENCE instructions.\n  /// E.g., on ARM,\n  /// dX VMOVDRR rY, rZ\n  /// is equivalent to\n  /// dX = REG_SEQUENCE rY, ssub_0, rZ, ssub_1.\n  ///\n  /// Note that for the optimizers to be able to take advantage of\n  /// this property, TargetInstrInfo::getRegSequenceLikeInputs has to be\n  /// override accordingly.\n  bool isRegSequenceLike(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::RegSequence, Type);\n  }\n\n  /// Return true if this instruction behaves\n  /// the same way as the generic EXTRACT_SUBREG instructions.\n  /// E.g., on ARM,\n  /// rX, rY VMOVRRD dZ\n  /// is equivalent to two EXTRACT_SUBREG:\n  /// rX = EXTRACT_SUBREG dZ, ssub_0\n  /// rY = EXTRACT_SUBREG dZ, ssub_1\n  ///\n  /// Note that for the optimizers to be able to take advantage of\n  /// this property, TargetInstrInfo::getExtractSubregLikeInputs has to be\n  /// override accordingly.\n  bool isExtractSubregLike(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::ExtractSubreg, Type);\n  }\n\n  /// Return true if this instruction behaves\n  /// the same way as the generic INSERT_SUBREG instructions.\n  /// E.g., on ARM,\n  /// dX = VSETLNi32 dY, rZ, Imm\n  /// is equivalent to a INSERT_SUBREG:\n  /// dX = INSERT_SUBREG dY, rZ, translateImmToSubIdx(Imm)\n  ///\n  /// Note that for the optimizers to be able to take advantage of\n  /// this property, TargetInstrInfo::getInsertSubregLikeInputs has to be\n  /// override accordingly.\n  bool isInsertSubregLike(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::InsertSubreg, Type);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Side Effect Analysis\n  //===--------------------------------------------------------------------===//\n\n  /// Return true if this instruction could possibly read memory.\n  /// Instructions with this flag set are not necessarily simple load\n  /// instructions, they may load a value and modify it, for example.\n  bool mayLoad(QueryType Type = AnyInBundle) const {\n    if (isInlineAsm()) {\n      unsigned ExtraInfo = getOperand(InlineAsm::MIOp_ExtraInfo).getImm();\n      if (ExtraInfo & InlineAsm::Extra_MayLoad)\n        return true;\n    }\n    return hasProperty(MCID::MayLoad, Type);\n  }\n\n  /// Return true if this instruction could possibly modify memory.\n  /// Instructions with this flag set are not necessarily simple store\n  /// instructions, they may store a modified value based on their operands, or\n  /// may not actually modify anything, for example.\n  bool mayStore(QueryType Type = AnyInBundle) const {\n    if (isInlineAsm()) {\n      unsigned ExtraInfo = getOperand(InlineAsm::MIOp_ExtraInfo).getImm();\n      if (ExtraInfo & InlineAsm::Extra_MayStore)\n        return true;\n    }\n    return hasProperty(MCID::MayStore, Type);\n  }\n\n  /// Return true if this instruction could possibly read or modify memory.\n  bool mayLoadOrStore(QueryType Type = AnyInBundle) const {\n    return mayLoad(Type) || mayStore(Type);\n  }\n\n  /// Return true if this instruction could possibly raise a floating-point\n  /// exception.  This is the case if the instruction is a floating-point\n  /// instruction that can in principle raise an exception, as indicated\n  /// by the MCID::MayRaiseFPException property, *and* at the same time,\n  /// the instruction is used in a context where we expect floating-point\n  /// exceptions are not disabled, as indicated by the NoFPExcept MI flag.\n  bool mayRaiseFPException() const {\n    return hasProperty(MCID::MayRaiseFPException) &&\n           !getFlag(MachineInstr::MIFlag::NoFPExcept);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Flags that indicate whether an instruction can be modified by a method.\n  //===--------------------------------------------------------------------===//\n\n  /// Return true if this may be a 2- or 3-address\n  /// instruction (of the form \"X = op Y, Z, ...\"), which produces the same\n  /// result if Y and Z are exchanged.  If this flag is set, then the\n  /// TargetInstrInfo::commuteInstruction method may be used to hack on the\n  /// instruction.\n  ///\n  /// Note that this flag may be set on instructions that are only commutable\n  /// sometimes.  In these cases, the call to commuteInstruction will fail.\n  /// Also note that some instructions require non-trivial modification to\n  /// commute them.\n  bool isCommutable(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::Commutable, Type);\n  }\n\n  /// Return true if this is a 2-address instruction\n  /// which can be changed into a 3-address instruction if needed.  Doing this\n  /// transformation can be profitable in the register allocator, because it\n  /// means that the instruction can use a 2-address form if possible, but\n  /// degrade into a less efficient form if the source and dest register cannot\n  /// be assigned to the same register.  For example, this allows the x86\n  /// backend to turn a \"shl reg, 3\" instruction into an LEA instruction, which\n  /// is the same speed as the shift but has bigger code size.\n  ///\n  /// If this returns true, then the target must implement the\n  /// TargetInstrInfo::convertToThreeAddress method for this instruction, which\n  /// is allowed to fail if the transformation isn't valid for this specific\n  /// instruction (e.g. shl reg, 4 on x86).\n  ///\n  bool isConvertibleTo3Addr(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::ConvertibleTo3Addr, Type);\n  }\n\n  /// Return true if this instruction requires\n  /// custom insertion support when the DAG scheduler is inserting it into a\n  /// machine basic block.  If this is true for the instruction, it basically\n  /// means that it is a pseudo instruction used at SelectionDAG time that is\n  /// expanded out into magic code by the target when MachineInstrs are formed.\n  ///\n  /// If this is true, the TargetLoweringInfo::InsertAtEndOfBasicBlock method\n  /// is used to insert this into the MachineBasicBlock.\n  bool usesCustomInsertionHook(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::UsesCustomInserter, Type);\n  }\n\n  /// Return true if this instruction requires *adjustment*\n  /// after instruction selection by calling a target hook. For example, this\n  /// can be used to fill in ARM 's' optional operand depending on whether\n  /// the conditional flag register is used.\n  bool hasPostISelHook(QueryType Type = IgnoreBundle) const {\n    return hasProperty(MCID::HasPostISelHook, Type);\n  }\n\n  /// Returns true if this instruction is a candidate for remat.\n  /// This flag is deprecated, please don't use it anymore.  If this\n  /// flag is set, the isReallyTriviallyReMaterializable() method is called to\n  /// verify the instruction is really rematerializable.\n  bool isRematerializable(QueryType Type = AllInBundle) const {\n    // It's only possible to re-mat a bundle if all bundled instructions are\n    // re-materializable.\n    return hasProperty(MCID::Rematerializable, Type);\n  }\n\n  /// Returns true if this instruction has the same cost (or less) than a move\n  /// instruction. This is useful during certain types of optimizations\n  /// (e.g., remat during two-address conversion or machine licm)\n  /// where we would like to remat or hoist the instruction, but not if it costs\n  /// more than moving the instruction into the appropriate register. Note, we\n  /// are not marking copies from and to the same register class with this flag.\n  bool isAsCheapAsAMove(QueryType Type = AllInBundle) const {\n    // Only returns true for a bundle if all bundled instructions are cheap.\n    return hasProperty(MCID::CheapAsAMove, Type);\n  }\n\n  /// Returns true if this instruction source operands\n  /// have special register allocation requirements that are not captured by the\n  /// operand register classes. e.g. ARM::STRD's two source registers must be an\n  /// even / odd pair, ARM::STM registers have to be in ascending order.\n  /// Post-register allocation passes should not attempt to change allocations\n  /// for sources of instructions with this flag.\n  bool hasExtraSrcRegAllocReq(QueryType Type = AnyInBundle) const {\n    return hasProperty(MCID::ExtraSrcRegAllocReq, Type);\n  }\n\n  /// Returns true if this instruction def operands\n  /// have special register allocation requirements that are not captured by the\n"}, {"id": "67DE6A7E30450520", "name": "llvm::MachineRegisterInfo::use_nodbg_empty", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineRegisterInfo.h", "start": {"line": 590, "col": 3}, "end": {"line": 592, "col": 3}, "code": "    return use_nodbg_begin(RegNo) == use_nodbg_end();\n  }\n\n  /// hasOneNonDBGUse - Return true if there is exactly one non-Debug\n  /// use of the specified register.\n  bool hasOneNonDBGUse(Register RegNo) const;\n\n  /// hasOneNonDBGUse - Return true if there is exactly one non-Debug\n  /// instruction using the specified register. Said instruction may have\n  /// multiple uses.\n  bool hasOneNonDBGUser(Register RegNo) const;\n\n\n  /// hasAtMostUses - Return true if the given register has at most \\p MaxUsers\n  /// non-debug user instructions.\n  bool hasAtMostUserInstrs(Register Reg, unsigned MaxUsers) const;\n\n  /// replaceRegWith - Replace all instances of FromReg with ToReg in the\n  /// machine function.  This is like llvm-level X->replaceAllUsesWith(Y),\n  /// except that it also changes any definitions of the register as well.\n  ///\n  /// Note that it is usually necessary to first constrain ToReg's register\n  /// class and register bank to match the FromReg constraints using one of the\n  /// methods:\n  ///\n  ///   constrainRegClass(ToReg, getRegClass(FromReg))\n  ///   constrainRegAttrs(ToReg, FromReg)\n  ///   RegisterBankInfo::constrainGenericRegister(ToReg,\n  ///       *MRI.getRegClass(FromReg), MRI)\n  ///\n  /// These functions will return a falsy result if the virtual registers have\n  /// incompatible constraints.\n  ///\n  /// Note that if ToReg is a physical register the function will replace and\n  /// apply sub registers to ToReg in order to obtain a final/proper physical\n  /// register.\n  void replaceRegWith(Register FromReg, Register ToReg);\n\n  /// getVRegDef - Return the machine instr that defines the specified virtual\n  /// register or null if none is found.  This assumes that the code is in SSA\n  /// form, so there should only be one definition.\n  MachineInstr *getVRegDef(Register Reg) const;\n\n  /// getUniqueVRegDef - Return the unique machine instr that defines the\n  /// specified virtual register or null if none is found.  If there are\n  /// multiple definitions or no definition, return null.\n  MachineInstr *getUniqueVRegDef(Register Reg) const;\n\n  /// clearKillFlags - Iterate over all the uses of the given register and\n  /// clear the kill flag from the MachineOperand. This function is used by\n  /// optimization passes which extend register lifetimes and need only\n  /// preserve conservative kill flag information.\n  void clearKillFlags(Register Reg) const;\n\n  void dumpUses(Register RegNo) const;\n\n  /// Returns true if PhysReg is unallocatable and constant throughout the\n  /// function. Writing to a constant register has no effect.\n  bool isConstantPhysReg(MCRegister PhysReg) const;\n\n  /// Get an iterator over the pressure sets affected by the given physical or\n  /// virtual register. If RegUnit is physical, it must be a register unit (from\n  /// MCRegUnitIterator).\n  PSetIterator getPressureSets(Register RegUnit) const;\n\n  //===--------------------------------------------------------------------===//\n  // Virtual Register Info\n  //===--------------------------------------------------------------------===//\n\n  /// Return the register class of the specified virtual register.\n  /// This shouldn't be used directly unless \\p Reg has a register class.\n  /// \\see getRegClassOrNull when this might happen.\n  const TargetRegisterClass *getRegClass(Register Reg) const {\n    assert(isa<const TargetRegisterClass *>(VRegInfo[Reg.id()].first) &&\n           \"Register class not set, wrong accessor\");\n    return cast<const TargetRegisterClass *>(VRegInfo[Reg.id()].first);\n  }\n\n  /// Return the register class of \\p Reg, or null if Reg has not been assigned\n  /// a register class yet.\n  ///\n  /// \\note A null register class can only happen when these two\n  /// conditions are met:\n  /// 1. Generic virtual registers are created.\n  /// 2. The machine function has not completely been through the\n  ///    instruction selection process.\n  /// None of this condition is possible without GlobalISel for now.\n  /// In other words, if GlobalISel is not used or if the query happens after\n  /// the select pass, using getRegClass is safe.\n  const TargetRegisterClass *getRegClassOrNull(Register Reg) const {\n    const RegClassOrRegBank &Val = VRegInfo[Reg].first;\n    return dyn_cast_if_present<const TargetRegisterClass *>(Val);\n  }\n\n  /// Return the register bank of \\p Reg, or null if Reg has not been assigned\n  /// a register bank or has been assigned a register class.\n  /// \\note It is possible to get the register bank from the register class via\n  /// RegisterBankInfo::getRegBankFromRegClass.\n  const RegisterBank *getRegBankOrNull(Register Reg) const {\n    const RegClassOrRegBank &Val = VRegInfo[Reg].first;\n    return dyn_cast_if_present<const RegisterBank *>(Val);\n  }\n\n  /// Return the register bank or register class of \\p Reg.\n  /// \\note Before the register bank gets assigned (i.e., before the\n  /// RegBankSelect pass) \\p Reg may not have either.\n  const RegClassOrRegBank &getRegClassOrRegBank(Register Reg) const {\n    return VRegInfo[Reg].first;\n  }\n\n  /// setRegClass - Set the register class of the specified virtual register.\n  void setRegClass(Register Reg, const TargetRegisterClass *RC);\n\n  /// Set the register bank to \\p RegBank for \\p Reg.\n  void setRegBank(Register Reg, const RegisterBank &RegBank);\n\n  void setRegClassOrRegBank(Register Reg,\n                            const RegClassOrRegBank &RCOrRB){\n    VRegInfo[Reg].first = RCOrRB;\n  }\n\n  /// constrainRegClass - Constrain the register class of the specified virtual\n  /// register to be a common subclass of RC and the current register class,\n  /// but only if the new class has at least MinNumRegs registers.  Return the\n  /// new register class, or NULL if no such class exists.\n  /// This should only be used when the constraint is known to be trivial, like\n  /// GR32 -> GR32_NOSP. Beware of increasing register pressure.\n  ///\n  /// \\note Assumes that the register has a register class assigned.\n  /// Use RegisterBankInfo::constrainGenericRegister in GlobalISel's\n  /// InstructionSelect pass and constrainRegAttrs in every other pass,\n  /// including non-select passes of GlobalISel, instead.\n  const TargetRegisterClass *constrainRegClass(Register Reg,\n                                               const TargetRegisterClass *RC,\n                                               unsigned MinNumRegs = 0);\n\n  /// Constrain the register class or the register bank of the virtual register\n  /// \\p Reg (and low-level type) to be a common subclass or a common bank of\n  /// both registers provided respectively (and a common low-level type). Do\n  /// nothing if any of the attributes (classes, banks, or low-level types) of\n  /// the registers are deemed incompatible, or if the resulting register will\n  /// have a class smaller than before and of size less than \\p MinNumRegs.\n  /// Return true if such register attributes exist, false otherwise.\n  ///\n  /// \\note Use this method instead of constrainRegClass and\n  /// RegisterBankInfo::constrainGenericRegister everywhere but SelectionDAG\n  /// ISel / FastISel and GlobalISel's InstructionSelect pass respectively.\n  bool constrainRegAttrs(Register Reg, Register ConstrainingReg,\n                         unsigned MinNumRegs = 0);\n\n  /// recomputeRegClass - Try to find a legal super-class of Reg's register\n  /// class that still satisfies the constraints from the instructions using\n  /// Reg.  Returns true if Reg was upgraded.\n  ///\n  /// This method can be used after constraints have been removed from a\n  /// virtual register, for example after removing instructions or splitting\n  /// the live range.\n  bool recomputeRegClass(Register Reg);\n\n  /// createVirtualRegister - Create and return a new virtual register in the\n  /// function with the specified register class.\n  Register createVirtualRegister(const TargetRegisterClass *RegClass,\n                                 StringRef Name = \"\");\n\n  /// All attributes(register class or bank and low-level type) a virtual\n  /// register can have.\n  struct VRegAttrs {\n    RegClassOrRegBank RCOrRB;\n    LLT Ty;\n  };\n\n  /// Returns register class or bank and low level type of \\p Reg. Always safe\n  /// to use. Special values are returned when \\p Reg does not have some of the\n  /// attributes.\n  VRegAttrs getVRegAttrs(Register Reg) {\n    return {getRegClassOrRegBank(Reg), getType(Reg)};\n  }\n\n  /// Create and return a new virtual register in the function with the\n  /// specified register attributes(register class or bank and low level type).\n  Register createVirtualRegister(VRegAttrs RegAttr, StringRef Name = \"\");\n\n  /// Create and return a new virtual register in the function with the same\n  /// attributes as the given register.\n  Register cloneVirtualRegister(Register VReg, StringRef Name = \"\");\n\n  /// Get the low-level type of \\p Reg or LLT{} if Reg is not a generic\n  /// (target independent) virtual register.\n  LLT getType(Register Reg) const {\n    if (Reg.isVirtual() && VRegToType.inBounds(Reg))\n      return VRegToType[Reg];\n    return LLT{};\n  }\n\n  /// Set the low-level type of \\p VReg to \\p Ty.\n  void setType(Register VReg, LLT Ty);\n\n  /// Create and return a new generic virtual register with low-level\n  /// type \\p Ty.\n  Register createGenericVirtualRegister(LLT Ty, StringRef Name = \"\");\n\n  /// Remove all types associated to virtual registers (after instruction\n  /// selection and constraining of all generic virtual registers).\n  void clearVirtRegTypes();\n\n  /// Creates a new virtual register that has no register class, register bank\n  /// or size assigned yet. This is only allowed to be used\n  /// temporarily while constructing machine instructions. Most operations are\n  /// undefined on an incomplete register until one of setRegClass(),\n  /// setRegBank() or setSize() has been called on it.\n  Register createIncompleteVirtualRegister(StringRef Name = \"\");\n\n  /// getNumVirtRegs - Return the number of virtual registers created.\n  unsigned getNumVirtRegs() const { return VRegInfo.size(); }\n\n  /// clearVirtRegs - Remove all virtual registers (after physreg assignment).\n  void clearVirtRegs();\n\n  /// setRegAllocationHint - Specify a register allocation hint for the\n  /// specified virtual register. This is typically used by target, and in case\n  /// of an earlier hint it will be overwritten.\n  void setRegAllocationHint(Register VReg, unsigned Type, Register PrefReg) {\n    assert(VReg.isVirtual());\n    RegAllocHints[VReg].first  = Type;\n    RegAllocHints[VReg].second.clear();\n    RegAllocHints[VReg].second.push_back(PrefReg);\n  }\n\n  /// addRegAllocationHint - Add a register allocation hint to the hints\n  /// vector for VReg.\n  void addRegAllocationHint(Register VReg, Register PrefReg) {\n    assert(VReg.isVirtual());\n    RegAllocHints[VReg].second.push_back(PrefReg);\n  }\n\n  /// Specify the preferred (target independent) register allocation hint for\n  /// the specified virtual register.\n  void setSimpleHint(Register VReg, Register PrefReg) {\n    setRegAllocationHint(VReg, /*Type=*/0, PrefReg);\n  }\n\n  void clearSimpleHint(Register VReg) {\n    assert (!RegAllocHints[VReg].first &&\n            \"Expected to clear a non-target hint!\");\n    RegAllocHints[VReg].second.clear();\n  }\n\n  /// getRegAllocationHint - Return the register allocation hint for the\n  /// specified virtual register. If there are many hints, this returns the\n  /// one with the greatest weight.\n  std::pair<unsigned, Register> getRegAllocationHint(Register VReg) const {\n    assert(VReg.isVirtual());\n    Register BestHint = (RegAllocHints[VReg.id()].second.size() ?\n                         RegAllocHints[VReg.id()].second[0] : Register());\n    return {RegAllocHints[VReg.id()].first, BestHint};\n  }\n\n  /// getSimpleHint - same as getRegAllocationHint except it will only return\n  /// a target independent hint.\n  Register getSimpleHint(Register VReg) const {\n    assert(VReg.isVirtual());\n    std::pair<unsigned, Register> Hint = getRegAllocationHint(VReg);\n    return Hint.first ? Register() : Hint.second;\n  }\n\n  /// getRegAllocationHints - Return a reference to the vector of all\n  /// register allocation hints for VReg.\n  const std::pair<unsigned, SmallVector<Register, 4>> &\n  getRegAllocationHints(Register VReg) const {\n    assert(VReg.isVirtual());\n    return RegAllocHints[VReg];\n  }\n\n  /// markUsesInDebugValueAsUndef - Mark every DBG_VALUE referencing the\n  /// specified register as undefined which causes the DBG_VALUE to be\n  /// deleted during LiveDebugVariables analysis.\n  void markUsesInDebugValueAsUndef(Register Reg) const;\n\n  /// updateDbgUsersToReg - Update a collection of debug instructions\n  /// to refer to the designated register.\n  void updateDbgUsersToReg(MCRegister OldReg, MCRegister NewReg,\n                           ArrayRef<MachineInstr *> Users) const {\n    // If this operand is a register, check whether it overlaps with OldReg.\n    // If it does, replace with NewReg.\n    auto UpdateOp = [this, &NewReg, &OldReg](MachineOperand &Op) {\n      if (Op.isReg() &&\n          getTargetRegisterInfo()->regsOverlap(Op.getReg(), OldReg))\n        Op.setReg(NewReg);\n    };\n\n    // Iterate through (possibly several) operands to DBG_VALUEs and update\n    // each. For DBG_PHIs, only one operand will be present.\n    for (MachineInstr *MI : Users) {\n      if (MI->isDebugValue()) {\n        for (auto &Op : MI->debug_operands())\n          UpdateOp(Op);\n        assert(MI->hasDebugOperandForReg(NewReg) &&\n               \"Expected debug value to have some overlap with OldReg\");\n      } else if (MI->isDebugPHI()) {\n        UpdateOp(MI->getOperand(0));\n      } else {\n        llvm_unreachable(\"Non-DBG_VALUE, Non-DBG_PHI debug instr updated\");\n      }\n    }\n  }\n\n  /// Return true if the specified register is modified in this function.\n  /// This checks that no defining machine operands exist for the register or\n  /// any of its aliases. Definitions found on functions marked noreturn are\n  /// ignored, to consider them pass 'true' for optional parameter\n  /// SkipNoReturnDef. The register is also considered modified when it is set\n  /// in the UsedPhysRegMask.\n  bool isPhysRegModified(MCRegister PhysReg, bool SkipNoReturnDef = false) const;\n\n  /// Return true if the specified register is modified or read in this\n  /// function. This checks that no machine operands exist for the register or\n  /// any of its aliases. If SkipRegMaskTest is false, the register is\n  /// considered used when it is set in the UsedPhysRegMask.\n  bool isPhysRegUsed(MCRegister PhysReg, bool SkipRegMaskTest = false) const;\n\n  /// addPhysRegsUsedFromRegMask - Mark any registers not in RegMask as used.\n  /// This corresponds to the bit mask attached to register mask operands.\n  void addPhysRegsUsedFromRegMask(const uint32_t *RegMask) {\n    UsedPhysRegMask.setBitsNotInMask(RegMask);\n  }\n\n  const BitVector &getUsedPhysRegsMask() const { return UsedPhysRegMask; }\n\n  //===--------------------------------------------------------------------===//\n  // Reserved Register Info\n  //===--------------------------------------------------------------------===//\n  //\n  // The set of reserved registers must be invariant during register\n  // allocation.  For example, the target cannot suddenly decide it needs a\n  // frame pointer when the register allocator has already used the frame\n  // pointer register for something else.\n  //\n  // These methods can be used by target hooks like hasFP() to avoid changing\n  // the reserved register set during register allocation.\n\n  /// freezeReservedRegs - Called by the register allocator to freeze the set\n  /// of reserved registers before allocation begins.\n  void freezeReservedRegs(const MachineFunction&);\n\n  /// reserveReg -- Mark a register as reserved so checks like isAllocatable \n  /// will not suggest using it. This should not be used during the middle\n  /// of a function walk, or when liveness info is available.\n  void reserveReg(MCRegister PhysReg, const TargetRegisterInfo *TRI) {\n    assert(reservedRegsFrozen() &&\n           \"Reserved registers haven't been frozen yet. \");\n    MCRegAliasIterator R(PhysReg, TRI, true);\n\n    for (; R.isValid(); ++R)\n      ReservedRegs.set(*R);\n  }\n\n  /// reservedRegsFrozen - Returns true after freezeReservedRegs() was called\n  /// to ensure the set of reserved registers stays constant.\n  bool reservedRegsFrozen() const {\n    return !ReservedRegs.empty();\n  }\n\n  /// canReserveReg - Returns true if PhysReg can be used as a reserved\n  /// register.  Any register can be reserved before freezeReservedRegs() is\n  /// called.\n  bool canReserveReg(MCRegister PhysReg) const {\n    return !reservedRegsFrozen() || ReservedRegs.test(PhysReg);\n  }\n\n  /// getReservedRegs - Returns a reference to the frozen set of reserved\n  /// registers. This method should always be preferred to calling\n  /// TRI::getReservedRegs() when possible.\n  const BitVector &getReservedRegs() const {\n    assert(reservedRegsFrozen() &&\n           \"Reserved registers haven't been frozen yet. \"\n           \"Use TRI::getReservedRegs().\");\n    return ReservedRegs;\n  }\n\n  /// isReserved - Returns true when PhysReg is a reserved register.\n  ///\n  /// Reserved registers may belong to an allocatable register class, but the\n  /// target has explicitly requested that they are not used.\n  bool isReserved(MCRegister PhysReg) const {\n    return getReservedRegs().test(PhysReg.id());\n  }\n\n  /// Returns true when the given register unit is considered reserved.\n  ///\n  /// Register units are considered reserved when for at least one of their\n  /// root registers, the root register and all super registers are reserved.\n  /// This currently iterates the register hierarchy and may be slower than\n  /// expected.\n  bool isReservedRegUnit(unsigned Unit) const;\n\n  /// isAllocatable - Returns true when PhysReg belongs to an allocatable\n  /// register class and it hasn't been reserved.\n  ///\n  /// Allocatable registers may show up in the allocation order of some virtual\n  /// register, so a register allocator needs to track its liveness and\n  /// availability.\n  bool isAllocatable(MCRegister PhysReg) const {\n    return getTargetRegisterInfo()->isInAllocatableClass(PhysReg) &&\n      !isReserved(PhysReg);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // LiveIn Management\n  //===--------------------------------------------------------------------===//\n\n  /// addLiveIn - Add the specified register as a live-in.  Note that it\n  /// is an error to add the same register to the same set more than once.\n  void addLiveIn(MCRegister Reg, Register vreg = Register()) {\n    LiveIns.push_back(std::make_pair(Reg, vreg));\n  }\n\n  // Iteration support for the live-ins set.  It's kept in sorted order\n  // by register number.\n  using livein_iterator =\n      std::vector<std::pair<MCRegister,Register>>::const_iterator;\n  livein_iterator livein_begin() const { return LiveIns.begin(); }\n  livein_iterator livein_end()   const { return LiveIns.end(); }\n  bool            livein_empty() const { return LiveIns.empty(); }\n\n  ArrayRef<std::pair<MCRegister, Register>> liveins() const {\n    return LiveIns;\n  }\n\n  bool isLiveIn(Register Reg) const;\n\n  /// getLiveInPhysReg - If VReg is a live-in virtual register, return the\n  /// corresponding live-in physical register.\n  MCRegister getLiveInPhysReg(Register VReg) const;\n\n  /// getLiveInVirtReg - If PReg is a live-in physical register, return the\n  /// corresponding live-in virtual register.\n  Register getLiveInVirtReg(MCRegister PReg) const;\n\n  /// EmitLiveInCopies - Emit copies to initialize livein virtual registers\n  /// into the given entry block.\n  void EmitLiveInCopies(MachineBasicBlock *EntryMBB,\n                        const TargetRegisterInfo &TRI,\n                        const TargetInstrInfo &TII);\n\n  /// Returns a mask covering all bits that can appear in lane masks of\n  /// subregisters of the virtual register @p Reg.\n  LaneBitmask getMaxLaneMaskForVReg(Register Reg) const;\n\n  /// defusechain_iterator - This class provides iterator support for machine\n  /// operands in the function that use or define a specific register.  If\n  /// ReturnUses is true it returns uses of registers, if ReturnDefs is true it\n  /// returns defs.  If neither are true then you are silly and it always\n  /// returns end().  If SkipDebug is true it skips uses marked Debug\n  /// when incrementing.\n  template <bool ReturnUses, bool ReturnDefs, bool SkipDebug, bool ByOperand,\n            bool ByInstr, bool ByBundle>\n  class defusechain_iterator {\n    friend class MachineRegisterInfo;\n\n  public:\n    using iterator_category = std::forward_iterator_tag;\n    using value_type = MachineOperand;\n    using difference_type = std::ptrdiff_t;\n    using pointer = value_type *;\n    using reference = value_type &;\n\n  private:\n    MachineOperand *Op = nullptr;\n\n    explicit defusechain_iterator(MachineOperand *op) : Op(op) {\n      // If the first node isn't one we're interested in, advance to one that\n      // we are interested in.\n      if (op) {\n        if ((!ReturnUses && op->isUse()) ||\n            (!ReturnDefs && op->isDef()) ||\n            (SkipDebug && op->isDebug()))\n          advance();\n      }\n    }\n\n    void advance() {\n      assert(Op && \"Cannot increment end iterator!\");\n      Op = getNextOperandForReg(Op);\n\n      // All defs come before the uses, so stop def_iterator early.\n      if (!ReturnUses) {\n        if (Op) {\n          if (Op->isUse())\n            Op = nullptr;\n          else\n            assert(!Op->isDebug() && \"Can't have debug defs\");\n        }\n      } else {\n        // If this is an operand we don't care about, skip it.\n        while (Op && ((!ReturnDefs && Op->isDef()) ||\n                      (SkipDebug && Op->isDebug())))\n          Op = getNextOperandForReg(Op);\n      }\n    }\n\n  public:\n    defusechain_iterator() = default;\n\n    bool operator==(const defusechain_iterator &x) const {\n      return Op == x.Op;\n    }\n    bool operator!=(const defusechain_iterator &x) const {\n      return !operator==(x);\n    }\n\n    /// atEnd - return true if this iterator is equal to reg_end() on the value.\n    bool atEnd() const { return Op == nullptr; }\n\n    // Iterator traversal: forward iteration only\n    defusechain_iterator &operator++() {          // Preincrement\n      assert(Op && \"Cannot increment end iterator!\");\n      if (ByOperand)\n        advance();\n      else if (ByInstr) {\n        MachineInstr *P = Op->getParent();\n        do {\n          advance();\n        } while (Op && Op->getParent() == P);\n      } else if (ByBundle) {\n        MachineBasicBlock::instr_iterator P =\n            getBundleStart(Op->getParent()->getIterator());\n        do {\n          advance();\n        } while (Op && getBundleStart(Op->getParent()->getIterator()) == P);\n      }\n\n      return *this;\n    }\n    defusechain_iterator operator++(int) {        // Postincrement\n      defusechain_iterator tmp = *this; ++*this; return tmp;\n    }\n\n    /// getOperandNo - Return the operand # of this MachineOperand in its\n    /// MachineInstr.\n    unsigned getOperandNo() const {\n      assert(Op && \"Cannot dereference end iterator!\");\n      return Op - &Op->getParent()->getOperand(0);\n    }\n\n    // Retrieve a reference to the current operand.\n    MachineOperand &operator*() const {\n      assert(Op && \"Cannot dereference end iterator!\");\n      return *Op;\n    }\n\n    MachineOperand *operator->() const {\n      assert(Op && \"Cannot dereference end iterator!\");\n      return Op;\n    }\n  };\n\n  /// defusechain_iterator - This class provides iterator support for machine\n  /// operands in the function that use or define a specific register.  If\n  /// ReturnUses is true it returns uses of registers, if ReturnDefs is true it\n  /// returns defs.  If neither are true then you are silly and it always\n  /// returns end().  If SkipDebug is true it skips uses marked Debug\n  /// when incrementing.\n  template <bool ReturnUses, bool ReturnDefs, bool SkipDebug, bool ByOperand,\n            bool ByInstr, bool ByBundle>\n  class defusechain_instr_iterator {\n    friend class MachineRegisterInfo;\n\n  public:\n    using iterator_category = std::forward_iterator_tag;\n    using value_type = MachineInstr;\n    using difference_type = std::ptrdiff_t;\n    using pointer = value_type *;\n    using reference = value_type &;\n\n  private:\n    MachineOperand *Op = nullptr;\n\n    explicit defusechain_instr_iterator(MachineOperand *op) : Op(op) {\n      // If the first node isn't one we're interested in, advance to one that\n      // we are interested in.\n      if (op) {\n        if ((!ReturnUses && op->isUse()) ||\n            (!ReturnDefs && op->isDef()) ||\n            (SkipDebug && op->isDebug()))\n          advance();\n      }\n    }\n\n    void advance() {\n      assert(Op && \"Cannot increment end iterator!\");\n      Op = getNextOperandForReg(Op);\n\n      // All defs come before the uses, so stop def_iterator early.\n"}, {"id": "714FCD7EA84B468E", "name": "llvm::MachineOperand::getReg", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineOperand.h", "start": {"line": 369, "col": 3}, "end": {"line": 372, "col": 3}, "code": "    assert(isReg() && \"This is not a register operand!\");\n    return Register(SmallContents.RegNo);\n  }\n\n  unsigned getSubReg() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return SubReg_TargetFlags;\n  }\n\n  bool isUse() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return !IsDef;\n  }\n\n  bool isDef() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsDef;\n  }\n\n  bool isImplicit() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsImp;\n  }\n\n  bool isDead() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsDeadOrKill & IsDef;\n  }\n\n  bool isKill() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsDeadOrKill & !IsDef;\n  }\n\n  bool isUndef() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsUndef;\n  }\n\n  /// isRenamable - Returns true if this register may be renamed, i.e. it does\n  /// not generate a value that is somehow read in a way that is not represented\n  /// by the Machine IR (e.g. to meet an ABI or ISA requirement).  This is only\n  /// valid on physical register operands.  Virtual registers are assumed to\n  /// always be renamable regardless of the value of this field.\n  ///\n  /// Operands that are renamable can freely be changed to any other register\n  /// that is a member of the register class returned by\n  /// MI->getRegClassConstraint().\n  ///\n  /// isRenamable can return false for several different reasons:\n  ///\n  /// - ABI constraints (since liveness is not always precisely modeled).  We\n  ///   conservatively handle these cases by setting all physical register\n  ///   operands that didn\u2019t start out as virtual regs to not be renamable.\n  ///   Also any physical register operands created after register allocation or\n  ///   whose register is changed after register allocation will not be\n  ///   renamable.  This state is tracked in the MachineOperand::IsRenamable\n  ///   bit.\n  ///\n  /// - Opcode/target constraints: for opcodes that have complex register class\n  ///   requirements (e.g. that depend on other operands/instructions), we set\n  ///   hasExtraSrcRegAllocReq/hasExtraDstRegAllocReq in the machine opcode\n  ///   description.  Operands belonging to instructions with opcodes that are\n  ///   marked hasExtraSrcRegAllocReq/hasExtraDstRegAllocReq return false from\n  ///   isRenamable().  Additionally, the AllowRegisterRenaming target property\n  ///   prevents any operands from being marked renamable for targets that don't\n  ///   have detailed opcode hasExtraSrcRegAllocReq/hasExtraDstRegAllocReq\n  ///   values.\n  bool isRenamable() const;\n\n  bool isInternalRead() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsInternalRead;\n  }\n\n  bool isEarlyClobber() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsEarlyClobber;\n  }\n\n  bool isTied() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return TiedTo;\n  }\n\n  bool isDebug() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return IsDebug;\n  }\n\n  /// readsReg - Returns true if this operand reads the previous value of its\n  /// register.  A use operand with the <undef> flag set doesn't read its\n  /// register.  A sub-register def implicitly reads the other parts of the\n  /// register being redefined unless the <undef> flag is set.\n  ///\n  /// This refers to reading the register value from before the current\n  /// instruction or bundle. Internal bundle reads are not included.\n  bool readsReg() const {\n    assert(isReg() && \"Wrong MachineOperand accessor\");\n    return !isUndef() && !isInternalRead() && (isUse() || getSubReg());\n  }\n\n  /// Return true if this operand can validly be appended to an arbitrary\n  /// operand list. i.e. this behaves like an implicit operand.\n  bool isValidExcessOperand() const {\n    if ((isReg() && isImplicit()) || isRegMask())\n      return true;\n\n    // Debug operands\n    return isMetadata() || isMCSymbol();\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Mutators for Register Operands\n  //===--------------------------------------------------------------------===//\n\n  /// Change the register this operand corresponds to.\n  ///\n  void setReg(Register Reg);\n\n  void setSubReg(unsigned subReg) {\n    assert(isReg() && \"Wrong MachineOperand mutator\");\n    SubReg_TargetFlags = subReg;\n    assert(SubReg_TargetFlags == subReg && \"SubReg out of range\");\n  }\n\n  /// substVirtReg - Substitute the current register with the virtual\n  /// subregister Reg:SubReg. Take any existing SubReg index into account,\n  /// using TargetRegisterInfo to compose the subreg indices if necessary.\n  /// Reg must be a virtual register, SubIdx can be 0.\n  ///\n  void substVirtReg(Register Reg, unsigned SubIdx, const TargetRegisterInfo&);\n\n  /// substPhysReg - Substitute the current register with the physical register\n  /// Reg, taking any existing SubReg into account. For instance,\n  /// substPhysReg(%eax) will change %reg1024:sub_8bit to %al.\n  ///\n  void substPhysReg(MCRegister Reg, const TargetRegisterInfo&);\n\n  void setIsUse(bool Val = true) { setIsDef(!Val); }\n\n  /// Change a def to a use, or a use to a def.\n  void setIsDef(bool Val = true);\n\n  void setImplicit(bool Val = true) {\n    assert(isReg() && \"Wrong MachineOperand mutator\");\n    IsImp = Val;\n  }\n\n  void setIsKill(bool Val = true) {\n    assert(isReg() && !IsDef && \"Wrong MachineOperand mutator\");\n    assert((!Val || !isDebug()) && \"Marking a debug operation as kill\");\n    IsDeadOrKill = Val;\n  }\n\n  void setIsDead(bool Val = true) {\n    assert(isReg() && IsDef && \"Wrong MachineOperand mutator\");\n    IsDeadOrKill = Val;\n  }\n\n  void setIsUndef(bool Val = true) {\n    assert(isReg() && \"Wrong MachineOperand mutator\");\n    IsUndef = Val;\n  }\n\n  void setIsRenamable(bool Val = true);\n\n  void setIsInternalRead(bool Val = true) {\n    assert(isReg() && \"Wrong MachineOperand mutator\");\n    IsInternalRead = Val;\n  }\n\n  void setIsEarlyClobber(bool Val = true) {\n    assert(isReg() && IsDef && \"Wrong MachineOperand mutator\");\n    IsEarlyClobber = Val;\n  }\n\n  void setIsDebug(bool Val = true) {\n    assert(isReg() && !IsDef && \"Wrong MachineOperand mutator\");\n    IsDebug = Val;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Accessors for various operand types.\n  //===--------------------------------------------------------------------===//\n\n  int64_t getImm() const {\n    assert(isImm() && \"Wrong MachineOperand accessor\");\n    return Contents.ImmVal;\n  }\n\n  const ConstantInt *getCImm() const {\n    assert(isCImm() && \"Wrong MachineOperand accessor\");\n    return Contents.CI;\n  }\n\n  const ConstantFP *getFPImm() const {\n    assert(isFPImm() && \"Wrong MachineOperand accessor\");\n    return Contents.CFP;\n  }\n\n  MachineBasicBlock *getMBB() const {\n    assert(isMBB() && \"Wrong MachineOperand accessor\");\n    return Contents.MBB;\n  }\n\n  int getIndex() const {\n    assert((isFI() || isCPI() || isTargetIndex() || isJTI()) &&\n           \"Wrong MachineOperand accessor\");\n    return Contents.OffsetedInfo.Val.Index;\n  }\n\n  const GlobalValue *getGlobal() const {\n    assert(isGlobal() && \"Wrong MachineOperand accessor\");\n    return Contents.OffsetedInfo.Val.GV;\n  }\n\n  const BlockAddress *getBlockAddress() const {\n    assert(isBlockAddress() && \"Wrong MachineOperand accessor\");\n    return Contents.OffsetedInfo.Val.BA;\n  }\n\n  MCSymbol *getMCSymbol() const {\n    assert(isMCSymbol() && \"Wrong MachineOperand accessor\");\n    return Contents.Sym;\n  }\n\n  unsigned getInstrRefInstrIndex() const {\n    assert(isDbgInstrRef() && \"Wrong MachineOperand accessor\");\n    return Contents.InstrRef.InstrIdx;\n  }\n\n  unsigned getInstrRefOpIndex() const {\n    assert(isDbgInstrRef() && \"Wrong MachineOperand accessor\");\n    return Contents.InstrRef.OpIdx;\n  }\n\n  unsigned getCFIIndex() const {\n    assert(isCFIIndex() && \"Wrong MachineOperand accessor\");\n    return Contents.CFIIndex;\n  }\n\n  Intrinsic::ID getIntrinsicID() const {\n    assert(isIntrinsicID() && \"Wrong MachineOperand accessor\");\n    return Contents.IntrinsicID;\n  }\n\n  unsigned getPredicate() const {\n    assert(isPredicate() && \"Wrong MachineOperand accessor\");\n    return Contents.Pred;\n  }\n\n  ArrayRef<int> getShuffleMask() const {\n    assert(isShuffleMask() && \"Wrong MachineOperand accessor\");\n    return Contents.ShuffleMask;\n  }\n\n  /// Return the offset from the symbol in this operand. This always returns 0\n  /// for ExternalSymbol operands.\n  int64_t getOffset() const {\n    assert((isGlobal() || isSymbol() || isMCSymbol() || isCPI() ||\n            isTargetIndex() || isBlockAddress()) &&\n           \"Wrong MachineOperand accessor\");\n    return int64_t(uint64_t(Contents.OffsetedInfo.OffsetHi) << 32) |\n           SmallContents.OffsetLo;\n  }\n\n  const char *getSymbolName() const {\n    assert(isSymbol() && \"Wrong MachineOperand accessor\");\n    return Contents.OffsetedInfo.Val.SymbolName;\n  }\n\n  /// clobbersPhysReg - Returns true if this RegMask clobbers PhysReg.\n  /// It is sometimes necessary to detach the register mask pointer from its\n  /// machine operand. This static method can be used for such detached bit\n  /// mask pointers.\n  static bool clobbersPhysReg(const uint32_t *RegMask, MCRegister PhysReg) {\n    // See TargetRegisterInfo.h.\n    assert(PhysReg < (1u << 30) && \"Not a physical register\");\n    return !(RegMask[PhysReg / 32] & (1u << PhysReg % 32));\n  }\n\n  /// clobbersPhysReg - Returns true if this RegMask operand clobbers PhysReg.\n  bool clobbersPhysReg(MCRegister PhysReg) const {\n     return clobbersPhysReg(getRegMask(), PhysReg);\n  }\n\n  /// getRegMask - Returns a bit mask of registers preserved by this RegMask\n  /// operand.\n  const uint32_t *getRegMask() const {\n    assert(isRegMask() && \"Wrong MachineOperand accessor\");\n    return Contents.RegMask;\n  }\n\n  /// Returns number of elements needed for a regmask array.\n  static unsigned getRegMaskSize(unsigned NumRegs) {\n    return (NumRegs + 31) / 32;\n  }\n\n  /// getRegLiveOut - Returns a bit mask of live-out registers.\n  const uint32_t *getRegLiveOut() const {\n    assert(isRegLiveOut() && \"Wrong MachineOperand accessor\");\n    return Contents.RegMask;\n  }\n\n  const MDNode *getMetadata() const {\n    assert(isMetadata() && \"Wrong MachineOperand accessor\");\n    return Contents.MD;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Mutators for various operand types.\n  //===--------------------------------------------------------------------===//\n\n  void setImm(int64_t immVal) {\n    assert(isImm() && \"Wrong MachineOperand mutator\");\n    Contents.ImmVal = immVal;\n  }\n\n  void setCImm(const ConstantInt *CI) {\n    assert(isCImm() && \"Wrong MachineOperand mutator\");\n    Contents.CI = CI;\n  }\n\n  void setFPImm(const ConstantFP *CFP) {\n    assert(isFPImm() && \"Wrong MachineOperand mutator\");\n    Contents.CFP = CFP;\n  }\n\n  void setOffset(int64_t Offset) {\n    assert((isGlobal() || isSymbol() || isMCSymbol() || isCPI() ||\n            isTargetIndex() || isBlockAddress()) &&\n           \"Wrong MachineOperand mutator\");\n    SmallContents.OffsetLo = unsigned(Offset);\n    Contents.OffsetedInfo.OffsetHi = int(Offset >> 32);\n  }\n\n  void setIndex(int Idx) {\n    assert((isFI() || isCPI() || isTargetIndex() || isJTI()) &&\n           \"Wrong MachineOperand mutator\");\n    Contents.OffsetedInfo.Val.Index = Idx;\n  }\n\n  void setMetadata(const MDNode *MD) {\n    assert(isMetadata() && \"Wrong MachineOperand mutator\");\n    Contents.MD = MD;\n  }\n\n  void setInstrRefInstrIndex(unsigned InstrIdx) {\n    assert(isDbgInstrRef() && \"Wrong MachineOperand mutator\");\n    Contents.InstrRef.InstrIdx = InstrIdx;\n  }\n  void setInstrRefOpIndex(unsigned OpIdx) {\n    assert(isDbgInstrRef() && \"Wrong MachineOperand mutator\");\n    Contents.InstrRef.OpIdx = OpIdx;\n  }\n\n  void setMBB(MachineBasicBlock *MBB) {\n    assert(isMBB() && \"Wrong MachineOperand mutator\");\n    Contents.MBB = MBB;\n  }\n\n  /// Sets value of register mask operand referencing Mask.  The\n  /// operand does not take ownership of the memory referenced by Mask, it must\n  /// remain valid for the lifetime of the operand. See CreateRegMask().\n  /// Any physreg with a 0 bit in the mask is clobbered by the instruction.\n  void setRegMask(const uint32_t *RegMaskPtr) {\n    assert(isRegMask() && \"Wrong MachineOperand mutator\");\n    Contents.RegMask = RegMaskPtr;\n  }\n\n  void setIntrinsicID(Intrinsic::ID IID) {\n    assert(isIntrinsicID() && \"Wrong MachineOperand mutator\");\n"}], "code": "bool CombinerHelper::matchCombineUnmergeWithDeadLanesToTrunc(MachineInstr &MI) {\n  assert(MI.getOpcode() == TargetOpcode::G_UNMERGE_VALUES &&\n         \"Expected an unmerge\");\n  // Check that all the lanes are dead except the first one.\n  for (unsigned Idx = 1, EndIdx = MI.getNumDefs(); Idx != EndIdx; ++Idx) {\n    if (!MRI.use_nodbg_empty(MI.getOperand(Idx).getReg()))\n      return false;\n  }\n  return true;\n}\n"}, "2D830BDA333FFC11": {"calls": [{"id": "27A60F8EDF53EEC4", "name": "llvm::raw_ostream::operator<<", "path": "llvm-project/llvm/include/llvm/Support/raw_ostream.h", "start": {"line": 256, "col": 3}, "end": {"line": 261, "col": 3}, "code": "    // Inline fast path, particularly for constant strings where a sufficiently\n    // smart compiler will simplify strlen.\n\n    return this->operator<<(StringRef(Str));\n  }\n\n  raw_ostream &operator<<(const std::string &Str) {\n    // Avoid the fast path, it would only increase code size for a marginal win.\n    return write(Str.data(), Str.length());\n  }\n\n  raw_ostream &operator<<(const std::string_view &Str) {\n    return write(Str.data(), Str.length());\n  }\n\n  raw_ostream &operator<<(const SmallVectorImpl<char> &Str) {\n    return write(Str.data(), Str.size());\n  }\n\n  raw_ostream &operator<<(unsigned long N);\n  raw_ostream &operator<<(long N);\n  raw_ostream &operator<<(unsigned long long N);\n  raw_ostream &operator<<(long long N);\n  raw_ostream &operator<<(const void *P);\n\n  raw_ostream &operator<<(unsigned int N) {\n    return this->operator<<(static_cast<unsigned long>(N));\n  }\n\n  raw_ostream &operator<<(int N) {\n    return this->operator<<(static_cast<long>(N));\n  }\n\n  raw_ostream &operator<<(double N);\n\n  /// Output \\p N in hexadecimal, without any prefix or padding.\n  raw_ostream &write_hex(unsigned long long N);\n\n  // Change the foreground color of text.\n  raw_ostream &operator<<(Colors C);\n\n  /// Output a formatted UUID with dash separators.\n  using uuid_t = uint8_t[16];\n  raw_ostream &write_uuid(const uuid_t UUID);\n\n  /// Output \\p Str, turning '\\\\', '\\t', '\\n', '\"', and anything that doesn't\n  /// satisfy llvm::isPrint into an escape sequence.\n  raw_ostream &write_escaped(StringRef Str, bool UseHexEscapes = false);\n\n  raw_ostream &write(unsigned char C);\n  raw_ostream &write(const char *Ptr, size_t Size);\n\n  // Formatted output, see the format() function in Support/Format.h.\n  raw_ostream &operator<<(const format_object_base &Fmt);\n\n  // Formatted output, see the leftJustify() function in Support/Format.h.\n  raw_ostream &operator<<(const FormattedString &);\n\n  // Formatted output, see the formatHex() function in Support/Format.h.\n  raw_ostream &operator<<(const FormattedNumber &);\n\n  // Formatted output, see the formatv() function in Support/FormatVariadic.h.\n  raw_ostream &operator<<(const formatv_object_base &);\n\n  // Formatted output, see the format_bytes() function in Support/Format.h.\n  raw_ostream &operator<<(const FormattedBytes &);\n\n  /// indent - Insert 'NumSpaces' spaces.\n  raw_ostream &indent(unsigned NumSpaces);\n\n  /// write_zeros - Insert 'NumZeros' nulls.\n  raw_ostream &write_zeros(unsigned NumZeros);\n\n  /// Changes the foreground color of text that will be output from this point\n  /// forward.\n  /// @param Color ANSI color to use, the special SAVEDCOLOR can be used to\n  /// change only the bold attribute, and keep colors untouched\n  /// @param Bold bold/brighter text, default false\n  /// @param BG if true change the background, default: change foreground\n  /// @returns itself so it can be used within << invocations\n  virtual raw_ostream &changeColor(enum Colors Color, bool Bold = false,\n                                   bool BG = false);\n\n  /// Resets the colors to terminal defaults. Call this when you are done\n  /// outputting colored text, or before program exit.\n  virtual raw_ostream &resetColor();\n\n  /// Reverses the foreground and background colors.\n  virtual raw_ostream &reverseColor();\n\n  /// This function determines if this stream is connected to a \"tty\" or\n  /// \"console\" window. That is, the output would be displayed to the user\n  /// rather than being put on a pipe or stored in a file.\n  virtual bool is_displayed() const { return false; }\n\n  /// This function determines if this stream is displayed and supports colors.\n  /// The result is unaffected by calls to enable_color().\n  virtual bool has_colors() const { return is_displayed(); }\n\n  // Enable or disable colors. Once enable_colors(false) is called,\n  // changeColor() has no effect until enable_colors(true) is called.\n  virtual void enable_colors(bool enable) { ColorEnabled = enable; }\n\n  bool colors_enabled() const { return ColorEnabled; }\n\n  /// Tie this stream to the specified stream. Replaces any existing tied-to\n  /// stream. Specifying a nullptr unties the stream.\n  void tie(raw_ostream *TieTo) { TiedStream = TieTo; }\n\n  //===--------------------------------------------------------------------===//\n  // Subclass Interface\n  //===--------------------------------------------------------------------===//\n\nprivate:\n  /// The is the piece of the class that is implemented by subclasses.  This\n  /// writes the \\p Size bytes starting at\n  /// \\p Ptr to the underlying stream.\n  ///\n  /// This function is guaranteed to only be called at a point at which it is\n  /// safe for the subclass to install a new buffer via SetBuffer.\n  ///\n  /// \\param Ptr The start of the data to be written. For buffered streams this\n  /// is guaranteed to be the start of the buffer.\n  ///\n  /// \\param Size The number of bytes to be written.\n  ///\n  /// \\invariant { Size > 0 }\n  virtual void write_impl(const char *Ptr, size_t Size) = 0;\n\n  /// Return the current position within the stream, not counting the bytes\n  /// currently in the buffer.\n  virtual uint64_t current_pos() const = 0;\n\nprotected:\n  /// Use the provided buffer as the raw_ostream buffer. This is intended for\n  /// use only by subclasses which can arrange for the output to go directly\n  /// into the desired output buffer, instead of being copied on each flush.\n  void SetBuffer(char *BufferStart, size_t Size) {\n    SetBufferAndMode(BufferStart, Size, BufferKind::ExternalBuffer);\n  }\n\n  /// Return an efficient buffer size for the underlying output mechanism.\n  virtual size_t preferred_buffer_size() const;\n\n  /// Return the beginning of the current stream buffer, or 0 if the stream is\n  /// unbuffered.\n  const char *getBufferStart() const { return OutBufStart; }\n\n  //===--------------------------------------------------------------------===//\n  // Private Interface\n  //===--------------------------------------------------------------------===//\nprivate:\n  /// Install the given buffer and mode.\n  void SetBufferAndMode(char *BufferStart, size_t Size, BufferKind Mode);\n\n  /// Flush the current buffer, which is known to be non-empty. This outputs the\n  /// currently buffered data and resets the buffer to empty.\n  void flush_nonempty();\n\n  /// Copy data into the buffer. Size must not be greater than the number of\n  /// unused bytes in the buffer.\n  void copy_to_buffer(const char *Ptr, size_t Size);\n\n  /// Compute whether colors should be used and do the necessary work such as\n  /// flushing. The result is affected by calls to enable_color().\n  bool prepare_colors();\n\n  /// Flush the tied-to stream (if present) and then write the required data.\n  void flush_tied_then_write(const char *Ptr, size_t Size);\n\n  virtual void anchor();\n};\n\n/// Call the appropriate insertion operator, given an rvalue reference to a\n/// raw_ostream object and return a stream of the same type as the argument.\ntemplate <typename OStream, typename T>\nstd::enable_if_t<!std::is_reference_v<OStream> &&\n                     std::is_base_of_v<raw_ostream, OStream>,\n                 OStream &&>\noperator<<(OStream &&OS, const T &Value) {\n  OS << Value;\n  return std::move(OS);\n}\n\n/// An abstract base class for streams implementations that also support a\n/// pwrite operation. This is useful for code that can mostly stream out data,\n/// but needs to patch in a header that needs to know the output size.\nclass raw_pwrite_stream : public raw_ostream {\n  virtual void pwrite_impl(const char *Ptr, size_t Size, uint64_t Offset) = 0;\n  void anchor() override;\n\npublic:\n  explicit raw_pwrite_stream(bool Unbuffered = false,\n                             OStreamKind K = OStreamKind::OK_OStream)\n      : raw_ostream(Unbuffered, K) {}\n  void pwrite(const char *Ptr, size_t Size, uint64_t Offset) {\n#ifndef NDEBUG\n    uint64_t Pos = tell();\n    // /dev/null always reports a pos of 0, so we cannot perform this check\n    // in that case.\n    if (Pos)\n      assert(Size + Offset <= Pos && \"We don't support extending the stream\");\n#endif\n    pwrite_impl(Ptr, Size, Offset);\n  }\n};\n\n//===----------------------------------------------------------------------===//\n// File Output Streams\n//===----------------------------------------------------------------------===//\n\n/// A raw_ostream that writes to a file descriptor.\n///\nclass raw_fd_ostream : public raw_pwrite_stream {\n  int FD;\n  bool ShouldClose;\n  bool SupportsSeeking = false;\n  bool IsRegularFile = false;\n  mutable std::optional<bool> HasColors;\n\n#ifdef _WIN32\n  /// True if this fd refers to a Windows console device. Mintty and other\n  /// terminal emulators are TTYs, but they are not consoles.\n  bool IsWindowsConsole = false;\n#endif\n\n  std::error_code EC;\n\n  uint64_t pos = 0;\n\n  /// See raw_ostream::write_impl.\n  void write_impl(const char *Ptr, size_t Size) override;\n\n  void pwrite_impl(const char *Ptr, size_t Size, uint64_t Offset) override;\n\n  /// Return the current position within the stream, not counting the bytes\n  /// currently in the buffer.\n  uint64_t current_pos() const override { return pos; }\n\n  /// Determine an efficient buffer size.\n  size_t preferred_buffer_size() const override;\n\n  void anchor() override;\n\nprotected:\n  /// Set the flag indicating that an output error has been encountered.\n  void error_detected(std::error_code EC) { this->EC = EC; }\n\n  /// Return the file descriptor.\n  int get_fd() const { return FD; }\n\n  // Update the file position by increasing \\p Delta.\n  void inc_pos(uint64_t Delta) { pos += Delta; }\n\npublic:\n  /// Open the specified file for writing. If an error occurs, information\n  /// about the error is put into EC, and the stream should be immediately\n  /// destroyed;\n  /// \\p Flags allows optional flags to control how the file will be opened.\n  ///\n  /// As a special case, if Filename is \"-\", then the stream will use\n  /// STDOUT_FILENO instead of opening a file. This will not close the stdout\n"}, {"id": "EB6223A0817B1713", "name": "verifyRegionRec", "path": "llvm-project/llvm/lib/Transforms/Vectorize/VPlanVerifier.cpp", "start": {"line": 114, "col": 1}, "end": {"line": 124, "col": 1}, "code": "  verifyRegion(Region);\n\n  // Recurse inside nested regions.\n  for (const VPBlockBase *VPB : make_range(\n           df_iterator<const VPBlockBase *>::begin(Region->getEntry()),\n           df_iterator<const VPBlockBase *>::end(Region->getExiting()))) {\n    if (const auto *SubRegion = dyn_cast<VPRegionBlock>(VPB))\n      verifyRegionRec(SubRegion);\n  }\n}\n\nvoid VPlanVerifier::verifyHierarchicalCFG(\n    const VPRegionBlock *TopRegion) const {\n  if (!EnableHCFGVerifier)\n    return;\n\n  LLVM_DEBUG(dbgs() << \"Verifying VPlan H-CFG.\\n\");\n  assert(!TopRegion->getParent() && \"VPlan Top Region should have no parent.\");\n  verifyRegionRec(TopRegion);\n}\n\n// Verify that phi-like recipes are at the beginning of \\p VPBB, with no\n// other recipes in between. Also check that only header blocks contain\n// VPHeaderPHIRecipes.\nstatic bool verifyPhiRecipes(const VPBasicBlock *VPBB) {\n  auto RecipeI = VPBB->begin();\n  auto End = VPBB->end();\n  unsigned NumActiveLaneMaskPhiRecipes = 0;\n  const VPRegionBlock *ParentR = VPBB->getParent();\n  bool IsHeaderVPBB = ParentR && !ParentR->isReplicator() &&\n                      ParentR->getEntryBasicBlock() == VPBB;\n  while (RecipeI != End && RecipeI->isPhi()) {\n    if (isa<VPActiveLaneMaskPHIRecipe>(RecipeI))\n      NumActiveLaneMaskPhiRecipes++;\n\n    if (IsHeaderVPBB && !isa<VPHeaderPHIRecipe>(*RecipeI)) {\n      errs() << \"Found non-header PHI recipe in header VPBB\";\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n      errs() << \": \";\n      RecipeI->dump();\n#endif\n      return false;\n    }\n\n    if (!IsHeaderVPBB && isa<VPHeaderPHIRecipe>(*RecipeI)) {\n      errs() << \"Found header PHI recipe in non-header VPBB\";\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n      errs() << \": \";\n      RecipeI->dump();\n#endif\n      return false;\n    }\n\n    RecipeI++;\n  }\n\n  if (NumActiveLaneMaskPhiRecipes > 1) {\n    errs() << \"There should be no more than one VPActiveLaneMaskPHIRecipe\";\n    return false;\n  }\n\n  while (RecipeI != End) {\n    if (RecipeI->isPhi() && !isa<VPBlendRecipe>(&*RecipeI)) {\n      errs() << \"Found phi-like recipe after non-phi recipe\";\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\n      errs() << \": \";\n      RecipeI->dump();\n      errs() << \"after\\n\";\n      std::prev(RecipeI)->dump();\n#endif\n      return false;\n    }\n    RecipeI++;\n  }\n  return true;\n}\n\nstatic bool verifyVPBasicBlock(const VPBasicBlock *VPBB,\n                               VPDominatorTree &VPDT) {\n  if (!verifyPhiRecipes(VPBB))\n    return false;\n\n  // Verify that defs in VPBB dominate all their uses. The current\n  // implementation is still incomplete.\n  DenseMap<const VPRecipeBase *, unsigned> RecipeNumbering;\n  unsigned Cnt = 0;\n  for (const VPRecipeBase &R : *VPBB)\n    RecipeNumbering[&R] = Cnt++;\n\n  for (const VPRecipeBase &R : *VPBB) {\n    for (const VPValue *V : R.definedValues()) {\n      for (const VPUser *U : V->users()) {\n        auto *UI = dyn_cast<VPRecipeBase>(U);\n        // TODO: check dominance of incoming values for phis properly.\n        if (!UI || isa<VPHeaderPHIRecipe>(UI) || isa<VPPredInstPHIRecipe>(UI))\n          continue;\n\n        // If the user is in the same block, check it comes after R in the\n        // block.\n        if (UI->getParent() == VPBB) {\n          if (RecipeNumbering[UI] < RecipeNumbering[&R]) {\n            errs() << \"Use before def!\\n\";\n            return false;\n          }\n          continue;\n        }\n\n        if (!VPDT.dominates(VPBB, UI->getParent())) {\n          errs() << \"Use before def!\\n\";\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}\n\nbool VPlanVerifier::verifyPlanIsValid(const VPlan &Plan) {\n  VPDominatorTree VPDT;\n  VPDT.recalculate(const_cast<VPlan &>(Plan));\n\n  auto Iter = vp_depth_first_deep(Plan.getEntry());\n  for (const VPBasicBlock *VPBB :\n       VPBlockUtils::blocksOnly<const VPBasicBlock>(Iter)) {\n"}], "code": "void VPlanVerifier::verifyHierarchicalCFG(\n    const VPRegionBlock *TopRegion) const {\n  if (!EnableHCFGVerifier)\n    return;\n\n  LLVM_DEBUG(dbgs() << \"Verifying VPlan H-CFG.\\n\");\n  assert(!TopRegion->getParent() && \"VPlan Top Region should have no parent.\");\n  verifyRegionRec(TopRegion);\n}\n"}, "3241D0D94F5756B0": {"calls": [{"id": "DB1E9DC48D2256E3", "name": "llvm::TargetSubtargetInfo::getTargetLowering", "path": "llvm-project/llvm/include/llvm/CodeGen/TargetSubtargetInfo.h", "start": {"line": 100, "col": 3}, "end": {"line": 100, "col": 77}, "code": "  virtual const SelectionDAGTargetInfo *getSelectionDAGInfo() const {\n    return nullptr;\n  }\n  virtual const CallLowering *getCallLowering() const { return nullptr; }\n\n  virtual const InlineAsmLowering *getInlineAsmLowering() const {\n    return nullptr;\n  }\n\n  // FIXME: This lets targets specialize the selector by subtarget (which lets\n  // us do things like a dedicated avx512 selector).  However, we might want\n  // to also specialize selectors by MachineFunction, which would let us be\n  // aware of optsize/optnone and such.\n  virtual InstructionSelector *getInstructionSelector() const {\n    return nullptr;\n  }\n\n  /// Target can subclass this hook to select a different DAG scheduler.\n  virtual RegisterScheduler::FunctionPassCtor\n  getDAGScheduler(CodeGenOptLevel) const {\n    return nullptr;\n  }\n\n  virtual const LegalizerInfo *getLegalizerInfo() const { return nullptr; }\n\n  /// getRegisterInfo - If register information is available, return it.  If\n  /// not, return null.\n  virtual const TargetRegisterInfo *getRegisterInfo() const { return nullptr; }\n\n  /// If the information for the register banks is available, return it.\n  /// Otherwise return nullptr.\n  virtual const RegisterBankInfo *getRegBankInfo() const { return nullptr; }\n\n  /// getInstrItineraryData - Returns instruction itinerary data for the target\n  /// or specific subtarget.\n  virtual const InstrItineraryData *getInstrItineraryData() const {\n    return nullptr;\n  }\n\n  /// Resolve a SchedClass at runtime, where SchedClass identifies an\n  /// MCSchedClassDesc with the isVariant property. This may return the ID of\n  /// another variant SchedClass, but repeated invocation must quickly terminate\n  /// in a nonvariant SchedClass.\n  virtual unsigned resolveSchedClass(unsigned SchedClass,\n                                     const MachineInstr *MI,\n                                     const TargetSchedModel *SchedModel) const {\n    return 0;\n  }\n\n  /// Returns true if MI is a dependency breaking zero-idiom instruction for the\n  /// subtarget.\n  ///\n  /// This function also sets bits in Mask related to input operands that\n  /// are not in a data dependency relationship.  There is one bit for each\n  /// machine operand; implicit operands follow explicit operands in the bit\n  /// representation used for Mask.  An empty (i.e. a mask with all bits\n  /// cleared) means: data dependencies are \"broken\" for all the explicit input\n  /// machine operands of MI.\n  virtual bool isZeroIdiom(const MachineInstr *MI, APInt &Mask) const {\n    return false;\n  }\n\n  /// Returns true if MI is a dependency breaking instruction for the subtarget.\n  ///\n  /// Similar in behavior to `isZeroIdiom`. However, it knows how to identify\n  /// all dependency breaking instructions (i.e. not just zero-idioms).\n  /// \n  /// As for `isZeroIdiom`, this method returns a mask of \"broken\" dependencies.\n  /// (See method `isZeroIdiom` for a detailed description of Mask).\n  virtual bool isDependencyBreaking(const MachineInstr *MI, APInt &Mask) const {\n    return isZeroIdiom(MI, Mask);\n  }\n\n  /// Returns true if MI is a candidate for move elimination.\n  ///\n  /// A candidate for move elimination may be optimized out at register renaming\n  /// stage. Subtargets can specify the set of optimizable moves by\n  /// instantiating tablegen class `IsOptimizableRegisterMove` (see\n  /// llvm/Target/TargetInstrPredicate.td).\n  ///\n  /// SubtargetEmitter is responsible for processing all the definitions of class\n  /// IsOptimizableRegisterMove, and auto-generate an override for this method.\n  virtual bool isOptimizableRegisterMove(const MachineInstr *MI) const {\n    return false;\n  }\n\n  /// True if the subtarget should run MachineScheduler after aggressive\n  /// coalescing.\n  ///\n  /// This currently replaces the SelectionDAG scheduler with the \"source\" order\n  /// scheduler (though see below for an option to turn this off and use the\n  /// TargetLowering preference). It does not yet disable the postRA scheduler.\n  virtual bool enableMachineScheduler() const;\n\n  /// True if the machine scheduler should disable the TLI preference\n  /// for preRA scheduling with the source level scheduler.\n  virtual bool enableMachineSchedDefaultSched() const { return true; }\n\n  /// True if the subtarget should run MachinePipeliner\n  virtual bool enableMachinePipeliner() const { return true; };\n\n"}], "code": "LegalizerHelper::LegalizeResult\nllvm::createLibcall(MachineIRBuilder &MIRBuilder, RTLIB::Libcall Libcall,\n                    const CallLowering::ArgInfo &Result,\n                    ArrayRef<CallLowering::ArgInfo> Args,\n                    LostDebugLocObserver &LocObserver, MachineInstr *MI) {\n  auto &TLI = *MIRBuilder.getMF().getSubtarget().getTargetLowering();\n  const char *Name = TLI.getLibcallName(Libcall);\n  const CallingConv::ID CC = TLI.getLibcallCallingConv(Libcall);\n  return createLibcall(MIRBuilder, Name, Result, Args, CC, LocObserver, MI);\n}\n"}, "6E2C5D1F01DE0934": {"calls": [{"id": "5ADF08EDD9757C26", "name": "llvm::AArch64FunctionInfo::getTailCallReservedStack", "path": "llvm-project/llvm/lib/Target/AArch64/AArch64MachineFunctionInfo.h", "start": {"line": 242, "col": 3}, "end": {"line": 242, "col": 77}, "code": "  void setTailCallReservedStack(unsigned bytes) {\n    TailCallReservedStack = bytes;\n  }\n\n  bool hasCalculatedStackSizeSVE() const { return HasCalculatedStackSizeSVE; }\n\n  void setStackSizeSVE(uint64_t S) {\n    HasCalculatedStackSizeSVE = true;\n    StackSizeSVE = S;\n  }\n\n  uint64_t getStackSizeSVE() const { return StackSizeSVE; }\n\n  bool hasStackFrame() const { return HasStackFrame; }\n  void setHasStackFrame(bool s) { HasStackFrame = s; }\n\n  bool isStackRealigned() const { return StackRealigned; }\n  void setStackRealigned(bool s) { StackRealigned = s; }\n\n  bool hasCalleeSaveStackFreeSpace() const {\n    return CalleeSaveStackHasFreeSpace;\n  }\n  void setCalleeSaveStackHasFreeSpace(bool s) {\n    CalleeSaveStackHasFreeSpace = s;\n  }\n  bool isSplitCSR() const { return IsSplitCSR; }\n  void setIsSplitCSR(bool s) { IsSplitCSR = s; }\n\n  void setLocalStackSize(uint64_t Size) { LocalStackSize = Size; }\n  uint64_t getLocalStackSize() const { return LocalStackSize; }\n\n  void setOutliningStyle(std::string Style) { OutliningStyle = Style; }\n  std::optional<std::string> getOutliningStyle() const {\n    return OutliningStyle;\n  }\n\n  void setCalleeSavedStackSize(unsigned Size) {\n    CalleeSavedStackSize = Size;\n    HasCalleeSavedStackSize = true;\n  }\n\n  // When CalleeSavedStackSize has not been set (for example when\n  // some MachineIR pass is run in isolation), then recalculate\n  // the CalleeSavedStackSize directly from the CalleeSavedInfo.\n  // Note: This information can only be recalculated after PEI\n  // has assigned offsets to the callee save objects.\n  unsigned getCalleeSavedStackSize(const MachineFrameInfo &MFI) const {\n    bool ValidateCalleeSavedStackSize = false;\n\n#ifndef NDEBUG\n    // Make sure the calculated size derived from the CalleeSavedInfo\n    // equals the cached size that was calculated elsewhere (e.g. in\n    // determineCalleeSaves).\n    ValidateCalleeSavedStackSize = HasCalleeSavedStackSize;\n#endif\n\n    if (!HasCalleeSavedStackSize || ValidateCalleeSavedStackSize) {\n      assert(MFI.isCalleeSavedInfoValid() && \"CalleeSavedInfo not calculated\");\n      if (MFI.getCalleeSavedInfo().empty())\n        return 0;\n\n      int64_t MinOffset = std::numeric_limits<int64_t>::max();\n      int64_t MaxOffset = std::numeric_limits<int64_t>::min();\n      for (const auto &Info : MFI.getCalleeSavedInfo()) {\n        int FrameIdx = Info.getFrameIdx();\n        if (MFI.getStackID(FrameIdx) != TargetStackID::Default)\n          continue;\n        int64_t Offset = MFI.getObjectOffset(FrameIdx);\n        int64_t ObjSize = MFI.getObjectSize(FrameIdx);\n        MinOffset = std::min<int64_t>(Offset, MinOffset);\n        MaxOffset = std::max<int64_t>(Offset + ObjSize, MaxOffset);\n      }\n\n      if (SwiftAsyncContextFrameIdx != std::numeric_limits<int>::max()) {\n        int64_t Offset = MFI.getObjectOffset(getSwiftAsyncContextFrameIdx());\n        int64_t ObjSize = MFI.getObjectSize(getSwiftAsyncContextFrameIdx());\n        MinOffset = std::min<int64_t>(Offset, MinOffset);\n        MaxOffset = std::max<int64_t>(Offset + ObjSize, MaxOffset);\n      }\n\n      unsigned Size = alignTo(MaxOffset - MinOffset, 16);\n      assert((!HasCalleeSavedStackSize || getCalleeSavedStackSize() == Size) &&\n             \"Invalid size calculated for callee saves\");\n      return Size;\n    }\n\n    return getCalleeSavedStackSize();\n  }\n\n  unsigned getCalleeSavedStackSize() const {\n    assert(HasCalleeSavedStackSize &&\n           \"CalleeSavedStackSize has not been calculated\");\n    return CalleeSavedStackSize;\n  }\n\n  // Saves the CalleeSavedStackSize for SVE vectors in 'scalable bytes'\n  void setSVECalleeSavedStackSize(unsigned Size) {\n    SVECalleeSavedStackSize = Size;\n  }\n  unsigned getSVECalleeSavedStackSize() const {\n    return SVECalleeSavedStackSize;\n  }\n\n  void setMinMaxSVECSFrameIndex(int Min, int Max) {\n    MinSVECSFrameIndex = Min;\n    MaxSVECSFrameIndex = Max;\n  }\n\n  int getMinSVECSFrameIndex() const { return MinSVECSFrameIndex; }\n  int getMaxSVECSFrameIndex() const { return MaxSVECSFrameIndex; }\n\n  void incNumLocalDynamicTLSAccesses() { ++NumLocalDynamicTLSAccesses; }\n  unsigned getNumLocalDynamicTLSAccesses() const {\n    return NumLocalDynamicTLSAccesses;\n  }\n\n  std::optional<bool> hasRedZone() const { return HasRedZone; }\n  void setHasRedZone(bool s) { HasRedZone = s; }\n\n  int getVarArgsStackIndex() const { return VarArgsStackIndex; }\n  void setVarArgsStackIndex(int Index) { VarArgsStackIndex = Index; }\n\n  unsigned getVarArgsStackOffset() const { return VarArgsStackOffset; }\n  void setVarArgsStackOffset(unsigned Offset) { VarArgsStackOffset = Offset; }\n\n  int getVarArgsGPRIndex() const { return VarArgsGPRIndex; }\n  void setVarArgsGPRIndex(int Index) { VarArgsGPRIndex = Index; }\n\n  unsigned getVarArgsGPRSize() const { return VarArgsGPRSize; }\n  void setVarArgsGPRSize(unsigned Size) { VarArgsGPRSize = Size; }\n\n  int getVarArgsFPRIndex() const { return VarArgsFPRIndex; }\n  void setVarArgsFPRIndex(int Index) { VarArgsFPRIndex = Index; }\n\n  unsigned getVarArgsFPRSize() const { return VarArgsFPRSize; }\n  void setVarArgsFPRSize(unsigned Size) { VarArgsFPRSize = Size; }\n\n  unsigned getSRetReturnReg() const { return SRetReturnReg; }\n  void setSRetReturnReg(unsigned Reg) { SRetReturnReg = Reg; }\n\n  unsigned getJumpTableEntrySize(int Idx) const {\n    return JumpTableEntryInfo[Idx].first;\n  }\n  MCSymbol *getJumpTableEntryPCRelSymbol(int Idx) const {\n    return JumpTableEntryInfo[Idx].second;\n  }\n  void setJumpTableEntryInfo(int Idx, unsigned Size, MCSymbol *PCRelSym) {\n    if ((unsigned)Idx >= JumpTableEntryInfo.size())\n      JumpTableEntryInfo.resize(Idx+1);\n    JumpTableEntryInfo[Idx] = std::make_pair(Size, PCRelSym);\n  }\n\n  using SetOfInstructions = SmallPtrSet<const MachineInstr *, 16>;\n\n  const SetOfInstructions &getLOHRelated() const { return LOHRelated; }\n\n  // Shortcuts for LOH related types.\n  class MILOHDirective {\n    MCLOHType Kind;\n\n    /// Arguments of this directive. Order matters.\n    SmallVector<const MachineInstr *, 3> Args;\n\n  public:\n    using LOHArgs = ArrayRef<const MachineInstr *>;\n\n    MILOHDirective(MCLOHType Kind, LOHArgs Args)\n        : Kind(Kind), Args(Args.begin(), Args.end()) {\n      assert(isValidMCLOHType(Kind) && \"Invalid LOH directive type!\");\n    }\n\n    MCLOHType getKind() const { return Kind; }\n    LOHArgs getArgs() const { return Args; }\n  };\n\n  using MILOHArgs = MILOHDirective::LOHArgs;\n  using MILOHContainer = SmallVector<MILOHDirective, 32>;\n\n  const MILOHContainer &getLOHContainer() const { return LOHContainerSet; }\n\n  /// Add a LOH directive of this @p Kind and this @p Args.\n  void addLOHDirective(MCLOHType Kind, MILOHArgs Args) {\n    LOHContainerSet.push_back(MILOHDirective(Kind, Args));\n    LOHRelated.insert(Args.begin(), Args.end());\n  }\n\n  SmallVectorImpl<ForwardedRegister> &getForwardedMustTailRegParms() {\n    return ForwardedMustTailRegParms;\n  }\n\n  std::optional<int> getTaggedBasePointerIndex() const {\n    return TaggedBasePointerIndex;\n  }\n  void setTaggedBasePointerIndex(int Index) { TaggedBasePointerIndex = Index; }\n\n  unsigned getTaggedBasePointerOffset() const {\n    return TaggedBasePointerOffset;\n  }\n  void setTaggedBasePointerOffset(unsigned Offset) {\n    TaggedBasePointerOffset = Offset;\n  }\n\n  int getCalleeSaveBaseToFrameRecordOffset() const {\n    return CalleeSaveBaseToFrameRecordOffset;\n  }\n  void setCalleeSaveBaseToFrameRecordOffset(int Offset) {\n    CalleeSaveBaseToFrameRecordOffset = Offset;\n  }\n\n  bool shouldSignReturnAddress(const MachineFunction &MF) const;\n  bool shouldSignReturnAddress(bool SpillsLR) const;\n\n  bool needsShadowCallStackPrologueEpilogue(MachineFunction &MF) const;\n\n  bool shouldSignWithBKey() const { return SignWithBKey; }\n\n  MCSymbol *getSigningInstrLabel() const { return SignInstrLabel; }\n  void setSigningInstrLabel(MCSymbol *Label) { SignInstrLabel = Label; }\n\n  bool isMTETagged() const { return IsMTETagged; }\n\n  bool branchTargetEnforcement() const { return BranchTargetEnforcement; }\n\n  bool branchProtectionPAuthLR() const { return BranchProtectionPAuthLR; }\n\n  void setHasSwiftAsyncContext(bool HasContext) {\n    HasSwiftAsyncContext = HasContext;\n  }\n  bool hasSwiftAsyncContext() const { return HasSwiftAsyncContext; }\n\n  void setSwiftAsyncContextFrameIdx(int FI) {\n    SwiftAsyncContextFrameIdx = FI;\n  }\n  int getSwiftAsyncContextFrameIdx() const { return SwiftAsyncContextFrameIdx; }\n\n  bool needsDwarfUnwindInfo(const MachineFunction &MF) const;\n  bool needsAsyncDwarfUnwindInfo(const MachineFunction &MF) const;\n\n  bool hasStreamingModeChanges() const { return HasStreamingModeChanges; }\n  void setHasStreamingModeChanges(bool HasChanges) {\n    HasStreamingModeChanges = HasChanges;\n  }\n\n"}, {"id": "D09C9C8E52997311", "name": "llvm::report_fatal_error", "path": "llvm-project/llvm/lib/Support/ErrorHandling.cpp", "start": {"line": 82, "col": 1}, "end": {"line": 84, "col": 1}, "code": "  report_fatal_error(Twine(Reason), GenCrashDiag);\n}\n\nvoid llvm::report_fatal_error(StringRef Reason, bool GenCrashDiag) {\n  report_fatal_error(Twine(Reason), GenCrashDiag);\n}\n\nvoid llvm::report_fatal_error(const Twine &Reason, bool GenCrashDiag) {\n  llvm::fatal_error_handler_t handler = nullptr;\n  void* handlerData = nullptr;\n  {\n    // Only acquire the mutex while reading the handler, so as not to invoke a\n    // user-supplied callback under a lock.\n"}, {"id": "6D9213272F2714AF", "name": "llvm::AArch64FunctionInfo::getVarArgsGPRSize", "path": "llvm-project/llvm/lib/Target/AArch64/AArch64MachineFunctionInfo.h", "start": {"line": 371, "col": 3}, "end": {"line": 371, "col": 63}, "code": "  void setVarArgsGPRSize(unsigned Size) { VarArgsGPRSize = Size; }\n\n  int getVarArgsFPRIndex() const { return VarArgsFPRIndex; }\n  void setVarArgsFPRIndex(int Index) { VarArgsFPRIndex = Index; }\n\n  unsigned getVarArgsFPRSize() const { return VarArgsFPRSize; }\n  void setVarArgsFPRSize(unsigned Size) { VarArgsFPRSize = Size; }\n\n  unsigned getSRetReturnReg() const { return SRetReturnReg; }\n  void setSRetReturnReg(unsigned Reg) { SRetReturnReg = Reg; }\n\n  unsigned getJumpTableEntrySize(int Idx) const {\n    return JumpTableEntryInfo[Idx].first;\n  }\n  MCSymbol *getJumpTableEntryPCRelSymbol(int Idx) const {\n    return JumpTableEntryInfo[Idx].second;\n  }\n  void setJumpTableEntryInfo(int Idx, unsigned Size, MCSymbol *PCRelSym) {\n    if ((unsigned)Idx >= JumpTableEntryInfo.size())\n      JumpTableEntryInfo.resize(Idx+1);\n    JumpTableEntryInfo[Idx] = std::make_pair(Size, PCRelSym);\n  }\n\n  using SetOfInstructions = SmallPtrSet<const MachineInstr *, 16>;\n\n  const SetOfInstructions &getLOHRelated() const { return LOHRelated; }\n\n  // Shortcuts for LOH related types.\n  class MILOHDirective {\n    MCLOHType Kind;\n\n    /// Arguments of this directive. Order matters.\n    SmallVector<const MachineInstr *, 3> Args;\n\n  public:\n    using LOHArgs = ArrayRef<const MachineInstr *>;\n\n    MILOHDirective(MCLOHType Kind, LOHArgs Args)\n        : Kind(Kind), Args(Args.begin(), Args.end()) {\n      assert(isValidMCLOHType(Kind) && \"Invalid LOH directive type!\");\n    }\n\n    MCLOHType getKind() const { return Kind; }\n    LOHArgs getArgs() const { return Args; }\n  };\n\n  using MILOHArgs = MILOHDirective::LOHArgs;\n  using MILOHContainer = SmallVector<MILOHDirective, 32>;\n\n  const MILOHContainer &getLOHContainer() const { return LOHContainerSet; }\n\n  /// Add a LOH directive of this @p Kind and this @p Args.\n  void addLOHDirective(MCLOHType Kind, MILOHArgs Args) {\n    LOHContainerSet.push_back(MILOHDirective(Kind, Args));\n    LOHRelated.insert(Args.begin(), Args.end());\n  }\n\n  SmallVectorImpl<ForwardedRegister> &getForwardedMustTailRegParms() {\n    return ForwardedMustTailRegParms;\n  }\n\n  std::optional<int> getTaggedBasePointerIndex() const {\n    return TaggedBasePointerIndex;\n  }\n  void setTaggedBasePointerIndex(int Index) { TaggedBasePointerIndex = Index; }\n\n  unsigned getTaggedBasePointerOffset() const {\n    return TaggedBasePointerOffset;\n  }\n  void setTaggedBasePointerOffset(unsigned Offset) {\n    TaggedBasePointerOffset = Offset;\n  }\n\n  int getCalleeSaveBaseToFrameRecordOffset() const {\n    return CalleeSaveBaseToFrameRecordOffset;\n  }\n  void setCalleeSaveBaseToFrameRecordOffset(int Offset) {\n    CalleeSaveBaseToFrameRecordOffset = Offset;\n  }\n\n  bool shouldSignReturnAddress(const MachineFunction &MF) const;\n  bool shouldSignReturnAddress(bool SpillsLR) const;\n\n  bool needsShadowCallStackPrologueEpilogue(MachineFunction &MF) const;\n\n  bool shouldSignWithBKey() const { return SignWithBKey; }\n\n  MCSymbol *getSigningInstrLabel() const { return SignInstrLabel; }\n  void setSigningInstrLabel(MCSymbol *Label) { SignInstrLabel = Label; }\n\n  bool isMTETagged() const { return IsMTETagged; }\n\n  bool branchTargetEnforcement() const { return BranchTargetEnforcement; }\n\n  bool branchProtectionPAuthLR() const { return BranchProtectionPAuthLR; }\n\n  void setHasSwiftAsyncContext(bool HasContext) {\n    HasSwiftAsyncContext = HasContext;\n  }\n  bool hasSwiftAsyncContext() const { return HasSwiftAsyncContext; }\n\n  void setSwiftAsyncContextFrameIdx(int FI) {\n    SwiftAsyncContextFrameIdx = FI;\n  }\n  int getSwiftAsyncContextFrameIdx() const { return SwiftAsyncContextFrameIdx; }\n\n  bool needsDwarfUnwindInfo(const MachineFunction &MF) const;\n  bool needsAsyncDwarfUnwindInfo(const MachineFunction &MF) const;\n\n  bool hasStreamingModeChanges() const { return HasStreamingModeChanges; }\n  void setHasStreamingModeChanges(bool HasChanges) {\n    HasStreamingModeChanges = HasChanges;\n  }\n\n  bool hasStackProbing() const { return StackProbeSize != 0; }\n\n  int64_t getStackProbeSize() const { return StackProbeSize; }\n\nprivate:\n  // Hold the lists of LOHs.\n  MILOHContainer LOHContainerSet;\n  SetOfInstructions LOHRelated;\n\n  SmallVector<std::pair<unsigned, MCSymbol *>, 2> JumpTableEntryInfo;\n};\n\nnamespace yaml {\nstruct AArch64FunctionInfo final : public yaml::MachineFunctionInfo {\n  std::optional<bool> HasRedZone;\n\n  AArch64FunctionInfo() = default;\n  AArch64FunctionInfo(const llvm::AArch64FunctionInfo &MFI);\n\n  void mappingImpl(yaml::IO &YamlIO) override;\n  ~AArch64FunctionInfo() = default;\n};\n\ntemplate <> struct MappingTraits<AArch64FunctionInfo> {\n  static void mapping(IO &YamlIO, AArch64FunctionInfo &MFI) {\n    YamlIO.mapOptional(\"hasRedZone\", MFI.HasRedZone);\n  }\n};\n\n} // end namespace yaml\n\n} // end namespace llvm\n\n#endif // LLVM_LIB_TARGET_AARCH64_AARCH64MACHINEFUNCTIONINFO_H\n"}, {"id": "7C18A114F878E55E", "name": "llvm::MachineFunction::hasEHFunclets", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineFunction.h", "start": {"line": 1169, "col": 3}, "end": {"line": 1169, "col": 54}, "code": "  void setHasEHFunclets(bool V) { HasEHFunclets = V; }\n\n  bool isOutlined() const { return IsOutlined; }\n  void setIsOutlined(bool V) { IsOutlined = V; }\n\n  /// Find or create an LandingPadInfo for the specified MachineBasicBlock.\n  LandingPadInfo &getOrCreateLandingPadInfo(MachineBasicBlock *LandingPad);\n\n  /// Return a reference to the landing pad info for the current function.\n  const std::vector<LandingPadInfo> &getLandingPads() const {\n    return LandingPads;\n  }\n\n  /// Provide the begin and end labels of an invoke style call and associate it\n  /// with a try landing pad block.\n  void addInvoke(MachineBasicBlock *LandingPad,\n                 MCSymbol *BeginLabel, MCSymbol *EndLabel);\n\n  /// Add a new panding pad, and extract the exception handling information from\n  /// the landingpad instruction. Returns the label ID for the landing pad\n  /// entry.\n  MCSymbol *addLandingPad(MachineBasicBlock *LandingPad);\n\n  /// Return the type id for the specified typeinfo.  This is function wide.\n  unsigned getTypeIDFor(const GlobalValue *TI);\n\n  /// Return the id of the filter encoded by TyIds.  This is function wide.\n  int getFilterIDFor(ArrayRef<unsigned> TyIds);\n\n  /// Map the landing pad's EH symbol to the call site indexes.\n  void setCallSiteLandingPad(MCSymbol *Sym, ArrayRef<unsigned> Sites);\n\n  /// Return if there is any wasm exception handling.\n  bool hasAnyWasmLandingPadIndex() const {\n    return !WasmLPadToIndexMap.empty();\n  }\n\n  /// Map the landing pad to its index. Used for Wasm exception handling.\n  void setWasmLandingPadIndex(const MachineBasicBlock *LPad, unsigned Index) {\n    WasmLPadToIndexMap[LPad] = Index;\n  }\n\n  /// Returns true if the landing pad has an associate index in wasm EH.\n  bool hasWasmLandingPadIndex(const MachineBasicBlock *LPad) const {\n    return WasmLPadToIndexMap.count(LPad);\n  }\n\n  /// Get the index in wasm EH for a given landing pad.\n  unsigned getWasmLandingPadIndex(const MachineBasicBlock *LPad) const {\n    assert(hasWasmLandingPadIndex(LPad));\n    return WasmLPadToIndexMap.lookup(LPad);\n  }\n\n  bool hasAnyCallSiteLandingPad() const {\n    return !LPadToCallSiteMap.empty();\n  }\n\n  /// Get the call site indexes for a landing pad EH symbol.\n  SmallVectorImpl<unsigned> &getCallSiteLandingPad(MCSymbol *Sym) {\n    assert(hasCallSiteLandingPad(Sym) &&\n           \"missing call site number for landing pad!\");\n    return LPadToCallSiteMap[Sym];\n  }\n\n  /// Return true if the landing pad Eh symbol has an associated call site.\n  bool hasCallSiteLandingPad(MCSymbol *Sym) {\n    return !LPadToCallSiteMap[Sym].empty();\n  }\n\n  bool hasAnyCallSiteLabel() const {\n    return !CallSiteMap.empty();\n  }\n\n  /// Map the begin label for a call site.\n  void setCallSiteBeginLabel(MCSymbol *BeginLabel, unsigned Site) {\n    CallSiteMap[BeginLabel] = Site;\n  }\n\n  /// Get the call site number for a begin label.\n  unsigned getCallSiteBeginLabel(MCSymbol *BeginLabel) const {\n    assert(hasCallSiteBeginLabel(BeginLabel) &&\n           \"Missing call site number for EH_LABEL!\");\n    return CallSiteMap.lookup(BeginLabel);\n  }\n\n  /// Return true if the begin label has a call site number associated with it.\n  bool hasCallSiteBeginLabel(MCSymbol *BeginLabel) const {\n    return CallSiteMap.count(BeginLabel);\n  }\n\n  /// Record annotations associated with a particular label.\n  void addCodeViewAnnotation(MCSymbol *Label, MDNode *MD) {\n    CodeViewAnnotations.push_back({Label, MD});\n  }\n\n  ArrayRef<std::pair<MCSymbol *, MDNode *>> getCodeViewAnnotations() const {\n    return CodeViewAnnotations;\n  }\n\n  /// Return a reference to the C++ typeinfo for the current function.\n  const std::vector<const GlobalValue *> &getTypeInfos() const {\n    return TypeInfos;\n  }\n\n  /// Return a reference to the typeids encoding filters used in the current\n  /// function.\n  const std::vector<unsigned> &getFilterIds() const {\n    return FilterIds;\n  }\n\n  /// \\}\n\n  /// Collect information used to emit debugging information of a variable in a\n  /// stack slot.\n  void setVariableDbgInfo(const DILocalVariable *Var, const DIExpression *Expr,\n                          int Slot, const DILocation *Loc) {\n    VariableDbgInfos.emplace_back(Var, Expr, Slot, Loc);\n  }\n\n  /// Collect information used to emit debugging information of a variable in\n  /// the entry value of a register.\n  void setVariableDbgInfo(const DILocalVariable *Var, const DIExpression *Expr,\n                          MCRegister Reg, const DILocation *Loc) {\n    VariableDbgInfos.emplace_back(Var, Expr, Reg, Loc);\n  }\n\n  VariableDbgInfoMapTy &getVariableDbgInfo() { return VariableDbgInfos; }\n  const VariableDbgInfoMapTy &getVariableDbgInfo() const {\n    return VariableDbgInfos;\n  }\n\n  /// Returns the collection of variables for which we have debug info and that\n  /// have been assigned a stack slot.\n  auto getInStackSlotVariableDbgInfo() {\n    return make_filter_range(getVariableDbgInfo(), [](auto &VarInfo) {\n      return VarInfo.inStackSlot();\n    });\n  }\n\n  /// Returns the collection of variables for which we have debug info and that\n  /// have been assigned a stack slot.\n  auto getInStackSlotVariableDbgInfo() const {\n    return make_filter_range(getVariableDbgInfo(), [](const auto &VarInfo) {\n      return VarInfo.inStackSlot();\n    });\n  }\n\n  /// Returns the collection of variables for which we have debug info and that\n  /// have been assigned an entry value register.\n  auto getEntryValueVariableDbgInfo() const {\n    return make_filter_range(getVariableDbgInfo(), [](const auto &VarInfo) {\n      return VarInfo.inEntryValueRegister();\n    });\n  }\n\n  /// Start tracking the arguments passed to the call \\p CallI.\n  void addCallArgsForwardingRegs(const MachineInstr *CallI,\n                                 CallSiteInfoImpl &&CallInfo) {\n    assert(CallI->isCandidateForCallSiteEntry());\n    bool Inserted =\n        CallSitesInfo.try_emplace(CallI, std::move(CallInfo)).second;\n    (void)Inserted;\n    assert(Inserted && \"Call site info not unique\");\n  }\n\n  const CallSiteInfoMap &getCallSitesInfo() const {\n    return CallSitesInfo;\n  }\n\n  /// Following functions update call site info. They should be called before\n  /// removing, replacing or copying call instruction.\n\n  /// Erase the call site info for \\p MI. It is used to remove a call\n  /// instruction from the instruction stream.\n  void eraseCallSiteInfo(const MachineInstr *MI);\n  /// Copy the call site info from \\p Old to \\ New. Its usage is when we are\n  /// making a copy of the instruction that will be inserted at different point\n  /// of the instruction stream.\n  void copyCallSiteInfo(const MachineInstr *Old,\n                        const MachineInstr *New);\n\n  /// Move the call site info from \\p Old to \\New call site info. This function\n  /// is used when we are replacing one call instruction with another one to\n  /// the same callee.\n  void moveCallSiteInfo(const MachineInstr *Old,\n                        const MachineInstr *New);\n\n  unsigned getNewDebugInstrNum() {\n    return ++DebugInstrNumberingCount;\n  }\n};\n\n//===--------------------------------------------------------------------===//\n// GraphTraits specializations for function basic block graphs (CFGs)\n//===--------------------------------------------------------------------===//\n\n// Provide specializations of GraphTraits to be able to treat a\n// machine function as a graph of machine basic blocks... these are\n// the same as the machine basic block iterators, except that the root\n// node is implicitly the first node of the function.\n//\ntemplate <> struct GraphTraits<MachineFunction*> :\n  public GraphTraits<MachineBasicBlock*> {\n  static NodeRef getEntryNode(MachineFunction *F) { return &F->front(); }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator = pointer_iterator<MachineFunction::iterator>;\n\n  static nodes_iterator nodes_begin(MachineFunction *F) {\n    return nodes_iterator(F->begin());\n  }\n\n  static nodes_iterator nodes_end(MachineFunction *F) {\n    return nodes_iterator(F->end());\n  }\n\n  static unsigned       size       (MachineFunction *F) { return F->size(); }\n};\ntemplate <> struct GraphTraits<const MachineFunction*> :\n  public GraphTraits<const MachineBasicBlock*> {\n  static NodeRef getEntryNode(const MachineFunction *F) { return &F->front(); }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator = pointer_iterator<MachineFunction::const_iterator>;\n\n  static nodes_iterator nodes_begin(const MachineFunction *F) {\n    return nodes_iterator(F->begin());\n  }\n\n  static nodes_iterator nodes_end  (const MachineFunction *F) {\n    return nodes_iterator(F->end());\n  }\n\n  static unsigned       size       (const MachineFunction *F)  {\n    return F->size();\n  }\n};\n\n// Provide specializations of GraphTraits to be able to treat a function as a\n// graph of basic blocks... and to walk it in inverse order.  Inverse order for\n// a function is considered to be when traversing the predecessor edges of a BB\n// instead of the successor edges.\n//\ntemplate <> struct GraphTraits<Inverse<MachineFunction*>> :\n  public GraphTraits<Inverse<MachineBasicBlock*>> {\n  static NodeRef getEntryNode(Inverse<MachineFunction *> G) {\n    return &G.Graph->front();\n  }\n};\ntemplate <> struct GraphTraits<Inverse<const MachineFunction*>> :\n  public GraphTraits<Inverse<const MachineBasicBlock*>> {\n  static NodeRef getEntryNode(Inverse<const MachineFunction *> G) {\n    return &G.Graph->front();\n  }\n};\n\nvoid verifyMachineFunction(const std::string &Banner,\n                           const MachineFunction &MF);\n\n} // end namespace llvm\n\n#endif // LLVM_CODEGEN_MACHINEFUNCTION_H\n"}, {"id": "349C5BE710CB236F", "name": "llvm::alignTo", "path": "llvm-project/llvm/include/llvm/Support/MathExtras.h", "start": {"line": 377, "col": 1}, "end": {"line": 380, "col": 1}, "code": "  assert(Align != 0u && \"Align can't be 0.\");\n  return (Value + Align - 1) / Align * Align;\n}\n\ninline uint64_t alignToPowerOf2(uint64_t Value, uint64_t Align) {\n  assert(Align != 0 && (Align & (Align - 1)) == 0 &&\n         \"Align must be a power of 2\");\n  // Replace unary minus to avoid compilation error on Windows:\n  // \"unary minus operator applied to unsigned type, result still unsigned\"\n  uint64_t negAlign = (~Align) + 1;\n  return (Value + Align - 1) & negAlign;\n}\n\n/// If non-zero \\p Skew is specified, the return value will be a minimal integer\n/// that is greater than or equal to \\p Size and equal to \\p A * N + \\p Skew for\n/// some integer N. If \\p Skew is larger than \\p A, its value is adjusted to '\\p\n/// Skew mod \\p A'. \\p Align must be non-zero.\n///\n/// Examples:\n/// \\code\n///   alignTo(5, 8, 7) = 7\n///   alignTo(17, 8, 1) = 17\n///   alignTo(~0LL, 8, 3) = 3\n///   alignTo(321, 255, 42) = 552\n/// \\endcode\ninline uint64_t alignTo(uint64_t Value, uint64_t Align, uint64_t Skew) {\n  assert(Align != 0u && \"Align can't be 0.\");\n  Skew %= Align;\n  return alignTo(Value - Skew, Align) + Skew;\n}\n\n/// Returns the next integer (mod 2**64) that is greater than or equal to\n/// \\p Value and is a multiple of \\c Align. \\c Align must be non-zero.\ntemplate <uint64_t Align> constexpr inline uint64_t alignTo(uint64_t Value) {\n  static_assert(Align != 0u, \"Align must be non-zero\");\n  return (Value + Align - 1) / Align * Align;\n}\n\n/// Returns the integer ceil(Numerator / Denominator).\ninline uint64_t divideCeil(uint64_t Numerator, uint64_t Denominator) {\n  return alignTo(Numerator, Denominator) / Denominator;\n}\n\n/// Returns the integer nearest(Numerator / Denominator).\ninline uint64_t divideNearest(uint64_t Numerator, uint64_t Denominator) {\n  return (Numerator + (Denominator / 2)) / Denominator;\n}\n\n/// Returns the largest uint64_t less than or equal to \\p Value and is\n/// \\p Skew mod \\p Align. \\p Align must be non-zero\ninline uint64_t alignDown(uint64_t Value, uint64_t Align, uint64_t Skew = 0) {\n  assert(Align != 0u && \"Align can't be 0.\");\n  Skew %= Align;\n  return (Value - Skew) / Align * Align + Skew;\n}\n\n/// Sign-extend the number in the bottom B bits of X to a 32-bit integer.\n/// Requires 0 < B <= 32.\ntemplate <unsigned B> constexpr inline int32_t SignExtend32(uint32_t X) {\n  static_assert(B > 0, \"Bit width can't be 0.\");\n  static_assert(B <= 32, \"Bit width out of range.\");\n  return int32_t(X << (32 - B)) >> (32 - B);\n}\n\n/// Sign-extend the number in the bottom B bits of X to a 32-bit integer.\n/// Requires 0 < B <= 32.\ninline int32_t SignExtend32(uint32_t X, unsigned B) {\n  assert(B > 0 && \"Bit width can't be 0.\");\n  assert(B <= 32 && \"Bit width out of range.\");\n  return int32_t(X << (32 - B)) >> (32 - B);\n}\n\n/// Sign-extend the number in the bottom B bits of X to a 64-bit integer.\n/// Requires 0 < B <= 64.\ntemplate <unsigned B> constexpr inline int64_t SignExtend64(uint64_t x) {\n  static_assert(B > 0, \"Bit width can't be 0.\");\n  static_assert(B <= 64, \"Bit width out of range.\");\n  return int64_t(x << (64 - B)) >> (64 - B);\n}\n\n/// Sign-extend the number in the bottom B bits of X to a 64-bit integer.\n/// Requires 0 < B <= 64.\ninline int64_t SignExtend64(uint64_t X, unsigned B) {\n  assert(B > 0 && \"Bit width can't be 0.\");\n  assert(B <= 64 && \"Bit width out of range.\");\n  return int64_t(X << (64 - B)) >> (64 - B);\n}\n\n/// Subtract two unsigned integers, X and Y, of type T and return the absolute\n/// value of the result.\ntemplate <typename T>\nstd::enable_if_t<std::is_unsigned_v<T>, T> AbsoluteDifference(T X, T Y) {\n  return X > Y ? (X - Y) : (Y - X);\n}\n\n/// Add two unsigned integers, X and Y, of type T.  Clamp the result to the\n/// maximum representable value of T on overflow.  ResultOverflowed indicates if\n/// the result is larger than the maximum representable value of type T.\ntemplate <typename T>\nstd::enable_if_t<std::is_unsigned_v<T>, T>\nSaturatingAdd(T X, T Y, bool *ResultOverflowed = nullptr) {\n  bool Dummy;\n  bool &Overflowed = ResultOverflowed ? *ResultOverflowed : Dummy;\n  // Hacker's Delight, p. 29\n  T Z = X + Y;\n  Overflowed = (Z < X || Z < Y);\n  if (Overflowed)\n    return std::numeric_limits<T>::max();\n  else\n    return Z;\n}\n\n/// Add multiple unsigned integers of type T.  Clamp the result to the\n/// maximum representable value of T on overflow.\ntemplate <class T, class... Ts>\nstd::enable_if_t<std::is_unsigned_v<T>, T> SaturatingAdd(T X, T Y, T Z,\n                                                         Ts... Args) {\n  bool Overflowed = false;\n  T XY = SaturatingAdd(X, Y, &Overflowed);\n  if (Overflowed)\n    return SaturatingAdd(std::numeric_limits<T>::max(), T(1), Args...);\n  return SaturatingAdd(XY, Z, Args...);\n}\n\n/// Multiply two unsigned integers, X and Y, of type T.  Clamp the result to the\n/// maximum representable value of T on overflow.  ResultOverflowed indicates if\n/// the result is larger than the maximum representable value of type T.\ntemplate <typename T>\nstd::enable_if_t<std::is_unsigned_v<T>, T>\nSaturatingMultiply(T X, T Y, bool *ResultOverflowed = nullptr) {\n  bool Dummy;\n  bool &Overflowed = ResultOverflowed ? *ResultOverflowed : Dummy;\n\n  // Hacker's Delight, p. 30 has a different algorithm, but we don't use that\n  // because it fails for uint16_t (where multiplication can have undefined\n  // behavior due to promotion to int), and requires a division in addition\n  // to the multiplication.\n\n  Overflowed = false;\n\n  // Log2(Z) would be either Log2Z or Log2Z + 1.\n  // Special case: if X or Y is 0, Log2_64 gives -1, and Log2Z\n  // will necessarily be less than Log2Max as desired.\n  int Log2Z = Log2_64(X) + Log2_64(Y);\n  const T Max = std::numeric_limits<T>::max();\n  int Log2Max = Log2_64(Max);\n  if (Log2Z < Log2Max) {\n    return X * Y;\n  }\n  if (Log2Z > Log2Max) {\n    Overflowed = true;\n    return Max;\n  }\n\n  // We're going to use the top bit, and maybe overflow one\n  // bit past it. Multiply all but the bottom bit then add\n  // that on at the end.\n  T Z = (X >> 1) * Y;\n  if (Z & ~(Max >> 1)) {\n    Overflowed = true;\n    return Max;\n  }\n  Z <<= 1;\n  if (X & 1)\n    return SaturatingAdd(Z, Y, ResultOverflowed);\n\n  return Z;\n}\n\n/// Multiply two unsigned integers, X and Y, and add the unsigned integer, A to\n/// the product. Clamp the result to the maximum representable value of T on\n/// overflow. ResultOverflowed indicates if the result is larger than the\n/// maximum representable value of type T.\ntemplate <typename T>\nstd::enable_if_t<std::is_unsigned_v<T>, T>\nSaturatingMultiplyAdd(T X, T Y, T A, bool *ResultOverflowed = nullptr) {\n  bool Dummy;\n  bool &Overflowed = ResultOverflowed ? *ResultOverflowed : Dummy;\n\n  T Product = SaturatingMultiply(X, Y, &Overflowed);\n  if (Overflowed)\n    return Product;\n\n  return SaturatingAdd(A, Product, &Overflowed);\n}\n\n/// Use this rather than HUGE_VALF; the latter causes warnings on MSVC.\nextern const float huge_valf;\n\n\n/// Add two signed integers, computing the two's complement truncated result,\n/// returning true if overflow occurred.\ntemplate <typename T>\nstd::enable_if_t<std::is_signed_v<T>, T> AddOverflow(T X, T Y, T &Result) {\n  // Perform the unsigned addition.\n  using U = std::make_unsigned_t<T>;\n  const U UX = static_cast<U>(X);\n  const U UY = static_cast<U>(Y);\n  const U UResult = UX + UY;\n\n  // Convert to signed.\n  Result = static_cast<T>(UResult);\n\n  // Adding two positive numbers should result in a positive number.\n  if (X > 0 && Y > 0)\n    return Result <= 0;\n  // Adding two negatives should result in a negative number.\n  if (X < 0 && Y < 0)\n    return Result >= 0;\n  return false;\n}\n\n/// Subtract two signed integers, computing the two's complement truncated\n/// result, returning true if an overflow ocurred.\ntemplate <typename T>\nstd::enable_if_t<std::is_signed_v<T>, T> SubOverflow(T X, T Y, T &Result) {\n  // Perform the unsigned addition.\n  using U = std::make_unsigned_t<T>;\n  const U UX = static_cast<U>(X);\n  const U UY = static_cast<U>(Y);\n  const U UResult = UX - UY;\n\n  // Convert to signed.\n  Result = static_cast<T>(UResult);\n\n  // Subtracting a positive number from a negative results in a negative number.\n  if (X <= 0 && Y > 0)\n    return Result >= 0;\n  // Subtracting a negative number from a positive results in a positive number.\n  if (X >= 0 && Y < 0)\n    return Result <= 0;\n  return false;\n}\n\n/// Multiply two signed integers, computing the two's complement truncated\n/// result, returning true if an overflow ocurred.\ntemplate <typename T>\nstd::enable_if_t<std::is_signed_v<T>, T> MulOverflow(T X, T Y, T &Result) {\n  // Perform the unsigned multiplication on absolute values.\n  using U = std::make_unsigned_t<T>;\n  const U UX = X < 0 ? (0 - static_cast<U>(X)) : static_cast<U>(X);\n  const U UY = Y < 0 ? (0 - static_cast<U>(Y)) : static_cast<U>(Y);\n  const U UResult = UX * UY;\n\n  // Convert to signed.\n  const bool IsNegative = (X < 0) ^ (Y < 0);\n  Result = IsNegative ? (0 - UResult) : UResult;\n\n  // If any of the args was 0, result is 0 and no overflow occurs.\n  if (UX == 0 || UY == 0)\n    return false;\n\n  // UX and UY are in [1, 2^n], where n is the number of digits.\n  // Check how the max allowed absolute value (2^n for negative, 2^(n-1) for\n  // positive) divided by an argument compares to the other.\n  if (IsNegative)\n    return UX > (static_cast<U>(std::numeric_limits<T>::max()) + U(1)) / UY;\n  else\n    return UX > (static_cast<U>(std::numeric_limits<T>::max())) / UY;\n}\n\n} // End llvm namespace\n\n"}], "code": "static unsigned getFixedObjectSize(const MachineFunction &MF,\n                                   const AArch64FunctionInfo *AFI, bool IsWin64,\n                                   bool IsFunclet) {\n  if (!IsWin64 || IsFunclet) {\n    return AFI->getTailCallReservedStack();\n  } else {\n    if (AFI->getTailCallReservedStack() != 0)\n      report_fatal_error(\"cannot generate ABI-changing tail call for Win64\");\n    // Var args are stored here in the primary function.\n    const unsigned VarArgsArea = AFI->getVarArgsGPRSize();\n    // To support EH funclets we allocate an UnwindHelp object\n    const unsigned UnwindHelpObject = (MF.hasEHFunclets() ? 8 : 0);\n    return alignTo(VarArgsArea + UnwindHelpObject, 16);\n  }\n}\n"}, "0B22468A30F51D0C": {"calls": [{"id": "5434171004F4D02D", "name": "llvm::MachineFunction::getRegInfo", "path": "llvm-project/llvm/include/llvm/CodeGen/MachineFunction.h", "start": {"line": 726, "col": 3}, "end": {"line": 726, "col": 56}, "code": "  const MachineRegisterInfo &getRegInfo() const { return *RegInfo; }\n\n  /// getFrameInfo - Return the frame info object for the current function.\n  /// This object contains information about objects allocated on the stack\n  /// frame of the current function in an abstract way.\n  MachineFrameInfo &getFrameInfo() { return *FrameInfo; }\n  const MachineFrameInfo &getFrameInfo() const { return *FrameInfo; }\n\n  /// getJumpTableInfo - Return the jump table info object for the current\n  /// function.  This object contains information about jump tables in the\n  /// current function.  If the current function has no jump tables, this will\n  /// return null.\n  const MachineJumpTableInfo *getJumpTableInfo() const { return JumpTableInfo; }\n  MachineJumpTableInfo *getJumpTableInfo() { return JumpTableInfo; }\n\n  /// getOrCreateJumpTableInfo - Get the JumpTableInfo for this function, if it\n  /// does already exist, allocate one.\n  MachineJumpTableInfo *getOrCreateJumpTableInfo(unsigned JTEntryKind);\n\n  /// getConstantPool - Return the constant pool object for the current\n  /// function.\n  MachineConstantPool *getConstantPool() { return ConstantPool; }\n  const MachineConstantPool *getConstantPool() const { return ConstantPool; }\n\n  /// getWasmEHFuncInfo - Return information about how the current function uses\n  /// Wasm exception handling. Returns null for functions that don't use wasm\n  /// exception handling.\n  const WasmEHFuncInfo *getWasmEHFuncInfo() const { return WasmEHInfo; }\n  WasmEHFuncInfo *getWasmEHFuncInfo() { return WasmEHInfo; }\n\n  /// getWinEHFuncInfo - Return information about how the current function uses\n  /// Windows exception handling. Returns null for functions that don't use\n  /// funclets for exception handling.\n  const WinEHFuncInfo *getWinEHFuncInfo() const { return WinEHInfo; }\n  WinEHFuncInfo *getWinEHFuncInfo() { return WinEHInfo; }\n\n  /// getAlignment - Return the alignment of the function.\n  Align getAlignment() const { return Alignment; }\n\n  /// setAlignment - Set the alignment of the function.\n  void setAlignment(Align A) { Alignment = A; }\n\n  /// ensureAlignment - Make sure the function is at least A bytes aligned.\n  void ensureAlignment(Align A) {\n    if (Alignment < A)\n      Alignment = A;\n  }\n\n  /// exposesReturnsTwice - Returns true if the function calls setjmp or\n  /// any other similar functions with attribute \"returns twice\" without\n  /// having the attribute itself.\n  bool exposesReturnsTwice() const {\n    return ExposesReturnsTwice;\n  }\n\n  /// setCallsSetJmp - Set a flag that indicates if there's a call to\n  /// a \"returns twice\" function.\n  void setExposesReturnsTwice(bool B) {\n    ExposesReturnsTwice = B;\n  }\n\n  /// Returns true if the function contains any inline assembly.\n  bool hasInlineAsm() const {\n    return HasInlineAsm;\n  }\n\n  /// Set a flag that indicates that the function contains inline assembly.\n  void setHasInlineAsm(bool B) {\n    HasInlineAsm = B;\n  }\n\n  bool hasWinCFI() const {\n    return HasWinCFI;\n  }\n  void setHasWinCFI(bool v) { HasWinCFI = v; }\n\n  /// True if this function needs frame moves for debug or exceptions.\n  bool needsFrameMoves() const;\n\n  /// Get the function properties\n  const MachineFunctionProperties &getProperties() const { return Properties; }\n  MachineFunctionProperties &getProperties() { return Properties; }\n\n  /// getInfo - Keep track of various per-function pieces of information for\n  /// backends that would like to do so.\n  ///\n  template<typename Ty>\n  Ty *getInfo() {\n    return static_cast<Ty*>(MFInfo);\n  }\n\n  template<typename Ty>\n  const Ty *getInfo() const {\n    return static_cast<const Ty *>(MFInfo);\n  }\n\n  template <typename Ty> Ty *cloneInfo(const Ty &Old) {\n    assert(!MFInfo);\n    MFInfo = Ty::template create<Ty>(Allocator, Old);\n    return static_cast<Ty *>(MFInfo);\n  }\n\n  /// Initialize the target specific MachineFunctionInfo\n  void initTargetMachineFunctionInfo(const TargetSubtargetInfo &STI);\n\n  MachineFunctionInfo *cloneInfoFrom(\n      const MachineFunction &OrigMF,\n      const DenseMap<MachineBasicBlock *, MachineBasicBlock *> &Src2DstMBB) {\n    assert(!MFInfo && \"new function already has MachineFunctionInfo\");\n    if (!OrigMF.MFInfo)\n      return nullptr;\n    return OrigMF.MFInfo->clone(Allocator, *this, Src2DstMBB);\n  }\n\n  /// Returns the denormal handling type for the default rounding mode of the\n  /// function.\n  DenormalMode getDenormalMode(const fltSemantics &FPType) const;\n\n  /// getBlockNumbered - MachineBasicBlocks are automatically numbered when they\n  /// are inserted into the machine function.  The block number for a machine\n  /// basic block can be found by using the MBB::getNumber method, this method\n  /// provides the inverse mapping.\n  MachineBasicBlock *getBlockNumbered(unsigned N) const {\n    assert(N < MBBNumbering.size() && \"Illegal block number\");\n    assert(MBBNumbering[N] && \"Block was removed from the machine function!\");\n    return MBBNumbering[N];\n  }\n\n  /// Should we be emitting segmented stack stuff for the function\n  bool shouldSplitStack() const;\n\n  /// getNumBlockIDs - Return the number of MBB ID's allocated.\n  unsigned getNumBlockIDs() const { return (unsigned)MBBNumbering.size(); }\n\n  /// RenumberBlocks - This discards all of the MachineBasicBlock numbers and\n  /// recomputes them.  This guarantees that the MBB numbers are sequential,\n  /// dense, and match the ordering of the blocks within the function.  If a\n  /// specific MachineBasicBlock is specified, only that block and those after\n  /// it are renumbered.\n  void RenumberBlocks(MachineBasicBlock *MBBFrom = nullptr);\n\n  /// print - Print out the MachineFunction in a format suitable for debugging\n  /// to the specified stream.\n  void print(raw_ostream &OS, const SlotIndexes* = nullptr) const;\n\n  /// viewCFG - This function is meant for use from the debugger.  You can just\n  /// say 'call F->viewCFG()' and a ghostview window should pop up from the\n  /// program, displaying the CFG of the current function with the code for each\n  /// basic block inside.  This depends on there being a 'dot' and 'gv' program\n  /// in your path.\n  void viewCFG() const;\n\n  /// viewCFGOnly - This function is meant for use from the debugger.  It works\n  /// just like viewCFG, but it does not include the contents of basic blocks\n  /// into the nodes, just the label.  If you are only interested in the CFG\n  /// this can make the graph smaller.\n  ///\n  void viewCFGOnly() const;\n\n  /// dump - Print the current MachineFunction to cerr, useful for debugger use.\n  void dump() const;\n\n  /// Run the current MachineFunction through the machine code verifier, useful\n  /// for debugger use.\n  /// \\returns true if no problems were found.\n  bool verify(Pass *p = nullptr, const char *Banner = nullptr,\n              bool AbortOnError = true) const;\n\n  /// Run the current MachineFunction through the machine code verifier, useful\n  /// for debugger use.\n  /// \\returns true if no problems were found.\n  bool verify(LiveIntervals *LiveInts, SlotIndexes *Indexes,\n              const char *Banner = nullptr, bool AbortOnError = true) const;\n\n  // Provide accessors for the MachineBasicBlock list...\n  using iterator = BasicBlockListType::iterator;\n  using const_iterator = BasicBlockListType::const_iterator;\n  using const_reverse_iterator = BasicBlockListType::const_reverse_iterator;\n  using reverse_iterator = BasicBlockListType::reverse_iterator;\n\n  /// Support for MachineBasicBlock::getNextNode().\n  static BasicBlockListType MachineFunction::*\n  getSublistAccess(MachineBasicBlock *) {\n    return &MachineFunction::BasicBlocks;\n  }\n\n  /// addLiveIn - Add the specified physical register as a live-in value and\n  /// create a corresponding virtual register for it.\n  Register addLiveIn(MCRegister PReg, const TargetRegisterClass *RC);\n\n  //===--------------------------------------------------------------------===//\n  // BasicBlock accessor functions.\n  //\n  iterator                 begin()       { return BasicBlocks.begin(); }\n  const_iterator           begin() const { return BasicBlocks.begin(); }\n  iterator                 end  ()       { return BasicBlocks.end();   }\n  const_iterator           end  () const { return BasicBlocks.end();   }\n\n  reverse_iterator        rbegin()       { return BasicBlocks.rbegin(); }\n  const_reverse_iterator  rbegin() const { return BasicBlocks.rbegin(); }\n  reverse_iterator        rend  ()       { return BasicBlocks.rend();   }\n  const_reverse_iterator  rend  () const { return BasicBlocks.rend();   }\n\n  unsigned                  size() const { return (unsigned)BasicBlocks.size();}\n  bool                     empty() const { return BasicBlocks.empty(); }\n  const MachineBasicBlock &front() const { return BasicBlocks.front(); }\n        MachineBasicBlock &front()       { return BasicBlocks.front(); }\n  const MachineBasicBlock & back() const { return BasicBlocks.back(); }\n        MachineBasicBlock & back()       { return BasicBlocks.back(); }\n\n  void push_back (MachineBasicBlock *MBB) { BasicBlocks.push_back (MBB); }\n  void push_front(MachineBasicBlock *MBB) { BasicBlocks.push_front(MBB); }\n  void insert(iterator MBBI, MachineBasicBlock *MBB) {\n    BasicBlocks.insert(MBBI, MBB);\n  }\n  void splice(iterator InsertPt, iterator MBBI) {\n    BasicBlocks.splice(InsertPt, BasicBlocks, MBBI);\n  }\n  void splice(iterator InsertPt, MachineBasicBlock *MBB) {\n    BasicBlocks.splice(InsertPt, BasicBlocks, MBB);\n  }\n  void splice(iterator InsertPt, iterator MBBI, iterator MBBE) {\n    BasicBlocks.splice(InsertPt, BasicBlocks, MBBI, MBBE);\n  }\n\n  void remove(iterator MBBI) { BasicBlocks.remove(MBBI); }\n  void remove(MachineBasicBlock *MBBI) { BasicBlocks.remove(MBBI); }\n  void erase(iterator MBBI) { BasicBlocks.erase(MBBI); }\n  void erase(MachineBasicBlock *MBBI) { BasicBlocks.erase(MBBI); }\n\n  template <typename Comp>\n  void sort(Comp comp) {\n    BasicBlocks.sort(comp);\n  }\n\n  /// Return the number of \\p MachineInstrs in this \\p MachineFunction.\n  unsigned getInstructionCount() const {\n    unsigned InstrCount = 0;\n    for (const MachineBasicBlock &MBB : BasicBlocks)\n      InstrCount += MBB.size();\n    return InstrCount;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Internal functions used to automatically number MachineBasicBlocks\n\n  /// Adds the MBB to the internal numbering. Returns the unique number\n  /// assigned to the MBB.\n  unsigned addToMBBNumbering(MachineBasicBlock *MBB) {\n    MBBNumbering.push_back(MBB);\n    return (unsigned)MBBNumbering.size()-1;\n  }\n\n  /// removeFromMBBNumbering - Remove the specific machine basic block from our\n  /// tracker, this is only really to be used by the MachineBasicBlock\n  /// implementation.\n  void removeFromMBBNumbering(unsigned N) {\n    assert(N < MBBNumbering.size() && \"Illegal basic block #\");\n    MBBNumbering[N] = nullptr;\n  }\n\n  /// CreateMachineInstr - Allocate a new MachineInstr. Use this instead\n  /// of `new MachineInstr'.\n  MachineInstr *CreateMachineInstr(const MCInstrDesc &MCID, DebugLoc DL,\n                                   bool NoImplicit = false);\n\n  /// Create a new MachineInstr which is a copy of \\p Orig, identical in all\n  /// ways except the instruction has no parent, prev, or next. Bundling flags\n  /// are reset.\n  ///\n  /// Note: Clones a single instruction, not whole instruction bundles.\n  /// Does not perform target specific adjustments; consider using\n  /// TargetInstrInfo::duplicate() instead.\n  MachineInstr *CloneMachineInstr(const MachineInstr *Orig);\n\n  /// Clones instruction or the whole instruction bundle \\p Orig and insert\n  /// into \\p MBB before \\p InsertBefore.\n  ///\n  /// Note: Does not perform target specific adjustments; consider using\n  /// TargetInstrInfo::duplicate() intead.\n  MachineInstr &\n  cloneMachineInstrBundle(MachineBasicBlock &MBB,\n                          MachineBasicBlock::iterator InsertBefore,\n                          const MachineInstr &Orig);\n\n  /// DeleteMachineInstr - Delete the given MachineInstr.\n  void deleteMachineInstr(MachineInstr *MI);\n\n  /// CreateMachineBasicBlock - Allocate a new MachineBasicBlock. Use this\n  /// instead of `new MachineBasicBlock'. Sets `MachineBasicBlock::BBID` if\n  /// basic-block-sections is enabled for the function.\n  MachineBasicBlock *\n  CreateMachineBasicBlock(const BasicBlock *BB = nullptr,\n                          std::optional<UniqueBBID> BBID = std::nullopt);\n\n  /// DeleteMachineBasicBlock - Delete the given MachineBasicBlock.\n  void deleteMachineBasicBlock(MachineBasicBlock *MBB);\n\n  /// getMachineMemOperand - Allocate a new MachineMemOperand.\n  /// MachineMemOperands are owned by the MachineFunction and need not be\n  /// explicitly deallocated.\n  MachineMemOperand *getMachineMemOperand(\n      MachinePointerInfo PtrInfo, MachineMemOperand::Flags f, uint64_t s,\n      Align base_alignment, const AAMDNodes &AAInfo = AAMDNodes(),\n      const MDNode *Ranges = nullptr, SyncScope::ID SSID = SyncScope::System,\n      AtomicOrdering Ordering = AtomicOrdering::NotAtomic,\n      AtomicOrdering FailureOrdering = AtomicOrdering::NotAtomic);\n\n  MachineMemOperand *getMachineMemOperand(\n      MachinePointerInfo PtrInfo, MachineMemOperand::Flags f, LLT MemTy,\n      Align base_alignment, const AAMDNodes &AAInfo = AAMDNodes(),\n      const MDNode *Ranges = nullptr, SyncScope::ID SSID = SyncScope::System,\n      AtomicOrdering Ordering = AtomicOrdering::NotAtomic,\n      AtomicOrdering FailureOrdering = AtomicOrdering::NotAtomic);\n\n  /// getMachineMemOperand - Allocate a new MachineMemOperand by copying\n  /// an existing one, adjusting by an offset and using the given size.\n  /// MachineMemOperands are owned by the MachineFunction and need not be\n  /// explicitly deallocated.\n  MachineMemOperand *getMachineMemOperand(const MachineMemOperand *MMO,\n                                          int64_t Offset, LLT Ty);\n  MachineMemOperand *getMachineMemOperand(const MachineMemOperand *MMO,\n                                          int64_t Offset, uint64_t Size) {\n    return getMachineMemOperand(\n        MMO, Offset, Size == ~UINT64_C(0) ? LLT() : LLT::scalar(8 * Size));\n  }\n\n  /// getMachineMemOperand - Allocate a new MachineMemOperand by copying\n  /// an existing one, replacing only the MachinePointerInfo and size.\n  /// MachineMemOperands are owned by the MachineFunction and need not be\n  /// explicitly deallocated.\n  MachineMemOperand *getMachineMemOperand(const MachineMemOperand *MMO,\n                                          const MachinePointerInfo &PtrInfo,\n                                          uint64_t Size);\n  MachineMemOperand *getMachineMemOperand(const MachineMemOperand *MMO,\n                                          const MachinePointerInfo &PtrInfo,\n                                          LLT Ty);\n\n  /// Allocate a new MachineMemOperand by copying an existing one,\n  /// replacing only AliasAnalysis information. MachineMemOperands are owned\n  /// by the MachineFunction and need not be explicitly deallocated.\n  MachineMemOperand *getMachineMemOperand(const MachineMemOperand *MMO,\n                                          const AAMDNodes &AAInfo);\n\n  /// Allocate a new MachineMemOperand by copying an existing one,\n  /// replacing the flags. MachineMemOperands are owned\n  /// by the MachineFunction and need not be explicitly deallocated.\n  MachineMemOperand *getMachineMemOperand(const MachineMemOperand *MMO,\n                                          MachineMemOperand::Flags Flags);\n\n  using OperandCapacity = ArrayRecycler<MachineOperand>::Capacity;\n\n  /// Allocate an array of MachineOperands. This is only intended for use by\n  /// internal MachineInstr functions.\n  MachineOperand *allocateOperandArray(OperandCapacity Cap) {\n    return OperandRecycler.allocate(Cap, Allocator);\n  }\n\n  /// Dellocate an array of MachineOperands and recycle the memory. This is\n  /// only intended for use by internal MachineInstr functions.\n  /// Cap must be the same capacity that was used to allocate the array.\n  void deallocateOperandArray(OperandCapacity Cap, MachineOperand *Array) {\n    OperandRecycler.deallocate(Cap, Array);\n  }\n\n  /// Allocate and initialize a register mask with @p NumRegister bits.\n  uint32_t *allocateRegMask();\n\n  ArrayRef<int> allocateShuffleMask(ArrayRef<int> Mask);\n\n  /// Allocate and construct an extra info structure for a `MachineInstr`.\n  ///\n  /// This is allocated on the function's allocator and so lives the life of\n  /// the function.\n  MachineInstr::ExtraInfo *createMIExtraInfo(\n      ArrayRef<MachineMemOperand *> MMOs, MCSymbol *PreInstrSymbol = nullptr,\n      MCSymbol *PostInstrSymbol = nullptr, MDNode *HeapAllocMarker = nullptr,\n      MDNode *PCSections = nullptr, uint32_t CFIType = 0);\n\n  /// Allocate a string and populate it with the given external symbol name.\n  const char *createExternalSymbolName(StringRef Name);\n\n  //===--------------------------------------------------------------------===//\n  // Label Manipulation.\n\n  /// getJTISymbol - Return the MCSymbol for the specified non-empty jump table.\n  /// If isLinkerPrivate is specified, an 'l' label is returned, otherwise a\n  /// normal 'L' label is returned.\n  MCSymbol *getJTISymbol(unsigned JTI, MCContext &Ctx,\n                         bool isLinkerPrivate = false) const;\n\n  /// getPICBaseSymbol - Return a function-local symbol to represent the PIC\n  /// base.\n  MCSymbol *getPICBaseSymbol() const;\n\n  /// Returns a reference to a list of cfi instructions in the function's\n  /// prologue.  Used to construct frame maps for debug and exception handling\n  /// comsumers.\n  const std::vector<MCCFIInstruction> &getFrameInstructions() const {\n    return FrameInstructions;\n  }\n\n  [[nodiscard]] unsigned addFrameInst(const MCCFIInstruction &Inst);\n\n  /// Returns a reference to a list of symbols immediately following calls to\n  /// _setjmp in the function. Used to construct the longjmp target table used\n  /// by Windows Control Flow Guard.\n  const std::vector<MCSymbol *> &getLongjmpTargets() const {\n    return LongjmpTargets;\n  }\n\n  /// Add the specified symbol to the list of valid longjmp targets for Windows\n  /// Control Flow Guard.\n  void addLongjmpTarget(MCSymbol *Target) { LongjmpTargets.push_back(Target); }\n\n  /// Returns a reference to a list of symbols that we have catchrets.\n  /// Used to construct the catchret target table used by Windows EHCont Guard.\n  const std::vector<MCSymbol *> &getCatchretTargets() const {\n    return CatchretTargets;\n  }\n\n  /// Add the specified symbol to the list of valid catchret targets for Windows\n  /// EHCont Guard.\n  void addCatchretTarget(MCSymbol *Target) {\n    CatchretTargets.push_back(Target);\n  }\n\n  /// \\name Exception Handling\n  /// \\{\n\n  bool callsEHReturn() const { return CallsEHReturn; }\n  void setCallsEHReturn(bool b) { CallsEHReturn = b; }\n\n  bool callsUnwindInit() const { return CallsUnwindInit; }\n  void setCallsUnwindInit(bool b) { CallsUnwindInit = b; }\n\n  bool hasEHCatchret() const { return HasEHCatchret; }\n  void setHasEHCatchret(bool V) { HasEHCatchret = V; }\n\n  bool hasEHScopes() const { return HasEHScopes; }\n  void setHasEHScopes(bool V) { HasEHScopes = V; }\n\n  bool hasEHFunclets() const { return HasEHFunclets; }\n  void setHasEHFunclets(bool V) { HasEHFunclets = V; }\n\n  bool isOutlined() const { return IsOutlined; }\n  void setIsOutlined(bool V) { IsOutlined = V; }\n\n  /// Find or create an LandingPadInfo for the specified MachineBasicBlock.\n  LandingPadInfo &getOrCreateLandingPadInfo(MachineBasicBlock *LandingPad);\n\n  /// Return a reference to the landing pad info for the current function.\n  const std::vector<LandingPadInfo> &getLandingPads() const {\n    return LandingPads;\n  }\n\n  /// Provide the begin and end labels of an invoke style call and associate it\n  /// with a try landing pad block.\n  void addInvoke(MachineBasicBlock *LandingPad,\n                 MCSymbol *BeginLabel, MCSymbol *EndLabel);\n\n  /// Add a new panding pad, and extract the exception handling information from\n  /// the landingpad instruction. Returns the label ID for the landing pad\n  /// entry.\n  MCSymbol *addLandingPad(MachineBasicBlock *LandingPad);\n\n  /// Return the type id for the specified typeinfo.  This is function wide.\n  unsigned getTypeIDFor(const GlobalValue *TI);\n\n  /// Return the id of the filter encoded by TyIds.  This is function wide.\n  int getFilterIDFor(ArrayRef<unsigned> TyIds);\n\n  /// Map the landing pad's EH symbol to the call site indexes.\n  void setCallSiteLandingPad(MCSymbol *Sym, ArrayRef<unsigned> Sites);\n\n  /// Return if there is any wasm exception handling.\n  bool hasAnyWasmLandingPadIndex() const {\n    return !WasmLPadToIndexMap.empty();\n  }\n\n  /// Map the landing pad to its index. Used for Wasm exception handling.\n  void setWasmLandingPadIndex(const MachineBasicBlock *LPad, unsigned Index) {\n    WasmLPadToIndexMap[LPad] = Index;\n  }\n\n  /// Returns true if the landing pad has an associate index in wasm EH.\n  bool hasWasmLandingPadIndex(const MachineBasicBlock *LPad) const {\n    return WasmLPadToIndexMap.count(LPad);\n  }\n\n  /// Get the index in wasm EH for a given landing pad.\n  unsigned getWasmLandingPadIndex(const MachineBasicBlock *LPad) const {\n    assert(hasWasmLandingPadIndex(LPad));\n    return WasmLPadToIndexMap.lookup(LPad);\n  }\n\n  bool hasAnyCallSiteLandingPad() const {\n    return !LPadToCallSiteMap.empty();\n  }\n\n  /// Get the call site indexes for a landing pad EH symbol.\n  SmallVectorImpl<unsigned> &getCallSiteLandingPad(MCSymbol *Sym) {\n    assert(hasCallSiteLandingPad(Sym) &&\n           \"missing call site number for landing pad!\");\n    return LPadToCallSiteMap[Sym];\n  }\n\n  /// Return true if the landing pad Eh symbol has an associated call site.\n  bool hasCallSiteLandingPad(MCSymbol *Sym) {\n    return !LPadToCallSiteMap[Sym].empty();\n  }\n\n  bool hasAnyCallSiteLabel() const {\n    return !CallSiteMap.empty();\n  }\n\n  /// Map the begin label for a call site.\n  void setCallSiteBeginLabel(MCSymbol *BeginLabel, unsigned Site) {\n    CallSiteMap[BeginLabel] = Site;\n  }\n\n  /// Get the call site number for a begin label.\n  unsigned getCallSiteBeginLabel(MCSymbol *BeginLabel) const {\n    assert(hasCallSiteBeginLabel(BeginLabel) &&\n           \"Missing call site number for EH_LABEL!\");\n    return CallSiteMap.lookup(BeginLabel);\n  }\n\n  /// Return true if the begin label has a call site number associated with it.\n  bool hasCallSiteBeginLabel(MCSymbol *BeginLabel) const {\n    return CallSiteMap.count(BeginLabel);\n  }\n\n  /// Record annotations associated with a particular label.\n  void addCodeViewAnnotation(MCSymbol *Label, MDNode *MD) {\n    CodeViewAnnotations.push_back({Label, MD});\n  }\n\n  ArrayRef<std::pair<MCSymbol *, MDNode *>> getCodeViewAnnotations() const {\n    return CodeViewAnnotations;\n  }\n\n  /// Return a reference to the C++ typeinfo for the current function.\n  const std::vector<const GlobalValue *> &getTypeInfos() const {\n    return TypeInfos;\n  }\n\n  /// Return a reference to the typeids encoding filters used in the current\n  /// function.\n  const std::vector<unsigned> &getFilterIds() const {\n    return FilterIds;\n  }\n\n  /// \\}\n\n  /// Collect information used to emit debugging information of a variable in a\n  /// stack slot.\n  void setVariableDbgInfo(const DILocalVariable *Var, const DIExpression *Expr,\n                          int Slot, const DILocation *Loc) {\n    VariableDbgInfos.emplace_back(Var, Expr, Slot, Loc);\n  }\n\n  /// Collect information used to emit debugging information of a variable in\n  /// the entry value of a register.\n  void setVariableDbgInfo(const DILocalVariable *Var, const DIExpression *Expr,\n                          MCRegister Reg, const DILocation *Loc) {\n    VariableDbgInfos.emplace_back(Var, Expr, Reg, Loc);\n  }\n\n  VariableDbgInfoMapTy &getVariableDbgInfo() { return VariableDbgInfos; }\n  const VariableDbgInfoMapTy &getVariableDbgInfo() const {\n    return VariableDbgInfos;\n  }\n\n  /// Returns the collection of variables for which we have debug info and that\n  /// have been assigned a stack slot.\n  auto getInStackSlotVariableDbgInfo() {\n    return make_filter_range(getVariableDbgInfo(), [](auto &VarInfo) {\n      return VarInfo.inStackSlot();\n    });\n  }\n\n  /// Returns the collection of variables for which we have debug info and that\n  /// have been assigned a stack slot.\n  auto getInStackSlotVariableDbgInfo() const {\n    return make_filter_range(getVariableDbgInfo(), [](const auto &VarInfo) {\n      return VarInfo.inStackSlot();\n    });\n  }\n\n  /// Returns the collection of variables for which we have debug info and that\n  /// have been assigned an entry value register.\n  auto getEntryValueVariableDbgInfo() const {\n    return make_filter_range(getVariableDbgInfo(), [](const auto &VarInfo) {\n      return VarInfo.inEntryValueRegister();\n    });\n  }\n\n  /// Start tracking the arguments passed to the call \\p CallI.\n  void addCallArgsForwardingRegs(const MachineInstr *CallI,\n                                 CallSiteInfoImpl &&CallInfo) {\n    assert(CallI->isCandidateForCallSiteEntry());\n    bool Inserted =\n        CallSitesInfo.try_emplace(CallI, std::move(CallInfo)).second;\n    (void)Inserted;\n    assert(Inserted && \"Call site info not unique\");\n  }\n\n  const CallSiteInfoMap &getCallSitesInfo() const {\n    return CallSitesInfo;\n  }\n\n  /// Following functions update call site info. They should be called before\n  /// removing, replacing or copying call instruction.\n\n  /// Erase the call site info for \\p MI. It is used to remove a call\n  /// instruction from the instruction stream.\n  void eraseCallSiteInfo(const MachineInstr *MI);\n  /// Copy the call site info from \\p Old to \\ New. Its usage is when we are\n  /// making a copy of the instruction that will be inserted at different point\n  /// of the instruction stream.\n  void copyCallSiteInfo(const MachineInstr *Old,\n                        const MachineInstr *New);\n\n  /// Move the call site info from \\p Old to \\New call site info. This function\n  /// is used when we are replacing one call instruction with another one to\n  /// the same callee.\n  void moveCallSiteInfo(const MachineInstr *Old,\n                        const MachineInstr *New);\n\n  unsigned getNewDebugInstrNum() {\n    return ++DebugInstrNumberingCount;\n  }\n};\n\n//===--------------------------------------------------------------------===//\n// GraphTraits specializations for function basic block graphs (CFGs)\n//===--------------------------------------------------------------------===//\n\n// Provide specializations of GraphTraits to be able to treat a\n// machine function as a graph of machine basic blocks... these are\n// the same as the machine basic block iterators, except that the root\n// node is implicitly the first node of the function.\n//\ntemplate <> struct GraphTraits<MachineFunction*> :\n  public GraphTraits<MachineBasicBlock*> {\n  static NodeRef getEntryNode(MachineFunction *F) { return &F->front(); }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator = pointer_iterator<MachineFunction::iterator>;\n\n  static nodes_iterator nodes_begin(MachineFunction *F) {\n    return nodes_iterator(F->begin());\n  }\n\n  static nodes_iterator nodes_end(MachineFunction *F) {\n    return nodes_iterator(F->end());\n  }\n\n  static unsigned       size       (MachineFunction *F) { return F->size(); }\n};\ntemplate <> struct GraphTraits<const MachineFunction*> :\n  public GraphTraits<const MachineBasicBlock*> {\n  static NodeRef getEntryNode(const MachineFunction *F) { return &F->front(); }\n\n  // nodes_iterator/begin/end - Allow iteration over all nodes in the graph\n  using nodes_iterator = pointer_iterator<MachineFunction::const_iterator>;\n\n  static nodes_iterator nodes_begin(const MachineFunction *F) {\n    return nodes_iterator(F->begin());\n  }\n\n  static nodes_iterator nodes_end  (const MachineFunction *F) {\n    return nodes_iterator(F->end());\n  }\n\n  static unsigned       size       (const MachineFunction *F)  {\n    return F->size();\n  }\n};\n\n// Provide specializations of GraphTraits to be able to treat a function as a\n// graph of basic blocks... and to walk it in inverse order.  Inverse order for\n// a function is considered to be when traversing the predecessor edges of a BB\n// instead of the successor edges.\n//\ntemplate <> struct GraphTraits<Inverse<MachineFunction*>> :\n  public GraphTraits<Inverse<MachineBasicBlock*>> {\n  static NodeRef getEntryNode(Inverse<MachineFunction *> G) {\n    return &G.Graph->front();\n  }\n};\ntemplate <> struct GraphTraits<Inverse<const MachineFunction*>> :\n  public GraphTraits<Inverse<const MachineBasicBlock*>> {\n  static NodeRef getEntryNode(Inverse<const MachineFunction *> G) {\n    return &G.Graph->front();\n  }\n};\n\nvoid verifyMachineFunction(const std::string &Banner,\n                           const MachineFunction &MF);\n\n} // end namespace llvm\n\n#endif // LLVM_CODEGEN_MACHINEFUNCTION_H\n"}], "code": "MachineInstrBuilder\nSIInstrInfo::getAddNoCarry(MachineBasicBlock &MBB,\n                           MachineBasicBlock::iterator I,\n                           const DebugLoc &DL,\n                           Register DestReg) const {\n  if (ST.hasAddNoCarry())\n    return BuildMI(MBB, I, DL, get(AMDGPU::V_ADD_U32_e64), DestReg);\n\n  MachineRegisterInfo &MRI = MBB.getParent()->getRegInfo();\n  Register UnusedCarry = MRI.createVirtualRegister(RI.getBoolRC());\n  MRI.setRegAllocationHint(UnusedCarry, 0, RI.getVCC());\n\n  return BuildMI(MBB, I, DL, get(AMDGPU::V_ADD_CO_U32_e64), DestReg)\n           .addReg(UnusedCarry, RegState::Define | RegState::Dead);\n}\n"}, "5812479803CFD38A": {"calls": [{"id": "CCC7EC6A29D0CDD0", "name": "llvm::InstrProfSymtab::finalizeSymtab", "path": "llvm-project/llvm/include/llvm/ProfileData/InstrProf.h", "start": {"line": 559, "col": 1}, "end": {"line": 568, "col": 1}, "code": "  if (Sorted)\n    return;\n  llvm::sort(MD5NameMap, less_first());\n  llvm::sort(MD5FuncMap, less_first());\n  llvm::sort(AddrToMD5Map, less_first());\n  AddrToMD5Map.erase(std::unique(AddrToMD5Map.begin(), AddrToMD5Map.end()),\n                     AddrToMD5Map.end());\n  Sorted = true;\n}\n\nStringRef InstrProfSymtab::getFuncOrVarNameIfDefined(uint64_t MD5Hash) {\n  StringRef ret = getFuncOrVarName(MD5Hash);\n  if (ret.empty())\n    return InstrProfSymtab::getExternalSymbol();\n  return ret;\n}\n\nStringRef InstrProfSymtab::getFuncOrVarName(uint64_t MD5Hash) {\n  finalizeSymtab();\n  auto Result = llvm::lower_bound(MD5NameMap, MD5Hash,\n                                  [](const std::pair<uint64_t, StringRef> &LHS,\n                                     uint64_t RHS) { return LHS.first < RHS; });\n  if (Result != MD5NameMap.end() && Result->first == MD5Hash)\n    return Result->second;\n  return StringRef();\n}\n\nFunction* InstrProfSymtab::getFunction(uint64_t FuncMD5Hash) {\n  finalizeSymtab();\n  auto Result = llvm::lower_bound(MD5FuncMap, FuncMD5Hash,\n                                  [](const std::pair<uint64_t, Function *> &LHS,\n                                     uint64_t RHS) { return LHS.first < RHS; });\n  if (Result != MD5FuncMap.end() && Result->first == FuncMD5Hash)\n    return Result->second;\n  return nullptr;\n}\n\n// To store the sums of profile count values, or the percentage of\n// the sums of the total count values.\nstruct CountSumOrPercent {\n  uint64_t NumEntries;\n  double CountSum;\n  double ValueCounts[IPVK_Last - IPVK_First + 1];\n  CountSumOrPercent() : NumEntries(0), CountSum(0.0f), ValueCounts() {}\n  void reset() {\n    NumEntries = 0;\n    CountSum = 0.0f;\n    for (double &VC : ValueCounts)\n      VC = 0.0f;\n  }\n};\n\n// Function level or program level overlap information.\nstruct OverlapStats {\n  enum OverlapStatsLevel { ProgramLevel, FunctionLevel };\n  // Sum of the total count values for the base profile.\n  CountSumOrPercent Base;\n  // Sum of the total count values for the test profile.\n  CountSumOrPercent Test;\n  // Overlap lap score. Should be in range of [0.0f to 1.0f].\n  CountSumOrPercent Overlap;\n  CountSumOrPercent Mismatch;\n  CountSumOrPercent Unique;\n  OverlapStatsLevel Level;\n  const std::string *BaseFilename;\n  const std::string *TestFilename;\n  StringRef FuncName;\n  uint64_t FuncHash;\n  bool Valid;\n\n  OverlapStats(OverlapStatsLevel L = ProgramLevel)\n      : Level(L), BaseFilename(nullptr), TestFilename(nullptr), FuncHash(0),\n        Valid(false) {}\n\n  void dump(raw_fd_ostream &OS) const;\n\n  void setFuncInfo(StringRef Name, uint64_t Hash) {\n    FuncName = Name;\n    FuncHash = Hash;\n  }\n\n  Error accumulateCounts(const std::string &BaseFilename,\n                         const std::string &TestFilename, bool IsCS);\n  void addOneMismatch(const CountSumOrPercent &MismatchFunc);\n  void addOneUnique(const CountSumOrPercent &UniqueFunc);\n\n  static inline double score(uint64_t Val1, uint64_t Val2, double Sum1,\n                             double Sum2) {\n    if (Sum1 < 1.0f || Sum2 < 1.0f)\n      return 0.0f;\n    return std::min(Val1 / Sum1, Val2 / Sum2);\n  }\n};\n\n// This is used to filter the functions whose overlap information\n// to be output.\nstruct OverlapFuncFilters {\n  uint64_t ValueCutoff;\n  const std::string NameFilter;\n};\n\nstruct InstrProfValueSiteRecord {\n  /// Value profiling data pairs at a given value site.\n  std::list<InstrProfValueData> ValueData;\n\n  InstrProfValueSiteRecord() { ValueData.clear(); }\n  template <class InputIterator>\n  InstrProfValueSiteRecord(InputIterator F, InputIterator L)\n      : ValueData(F, L) {}\n\n  /// Sort ValueData ascending by Value\n  void sortByTargetValues() {\n    ValueData.sort(\n        [](const InstrProfValueData &left, const InstrProfValueData &right) {\n          return left.Value < right.Value;\n        });\n  }\n  /// Sort ValueData Descending by Count\n  inline void sortByCount();\n\n  /// Merge data from another InstrProfValueSiteRecord\n  /// Optionally scale merged counts by \\p Weight.\n  void merge(InstrProfValueSiteRecord &Input, uint64_t Weight,\n             function_ref<void(instrprof_error)> Warn);\n  /// Scale up value profile data counts by N (Numerator) / D (Denominator).\n  void scale(uint64_t N, uint64_t D, function_ref<void(instrprof_error)> Warn);\n\n  /// Compute the overlap b/w this record and Input record.\n  void overlap(InstrProfValueSiteRecord &Input, uint32_t ValueKind,\n               OverlapStats &Overlap, OverlapStats &FuncLevelOverlap);\n};\n\n/// Profiling information for a single function.\nstruct InstrProfRecord {\n  std::vector<uint64_t> Counts;\n  std::vector<uint8_t> BitmapBytes;\n\n  InstrProfRecord() = default;\n  InstrProfRecord(std::vector<uint64_t> Counts) : Counts(std::move(Counts)) {}\n  InstrProfRecord(std::vector<uint64_t> Counts,\n                  std::vector<uint8_t> BitmapBytes)\n      : Counts(std::move(Counts)), BitmapBytes(std::move(BitmapBytes)) {}\n  InstrProfRecord(InstrProfRecord &&) = default;\n  InstrProfRecord(const InstrProfRecord &RHS)\n      : Counts(RHS.Counts), BitmapBytes(RHS.BitmapBytes),\n        ValueData(RHS.ValueData\n                      ? std::make_unique<ValueProfData>(*RHS.ValueData)\n                      : nullptr) {}\n  InstrProfRecord &operator=(InstrProfRecord &&) = default;\n  InstrProfRecord &operator=(const InstrProfRecord &RHS) {\n    Counts = RHS.Counts;\n    BitmapBytes = RHS.BitmapBytes;\n    if (!RHS.ValueData) {\n      ValueData = nullptr;\n      return *this;\n    }\n    if (!ValueData)\n      ValueData = std::make_unique<ValueProfData>(*RHS.ValueData);\n    else\n      *ValueData = *RHS.ValueData;\n    return *this;\n  }\n\n  /// Return the number of value profile kinds with non-zero number\n  /// of profile sites.\n  inline uint32_t getNumValueKinds() const;\n  /// Return the number of instrumented sites for ValueKind.\n  inline uint32_t getNumValueSites(uint32_t ValueKind) const;\n\n  /// Return the total number of ValueData for ValueKind.\n  inline uint32_t getNumValueData(uint32_t ValueKind) const;\n\n  /// Return the number of value data collected for ValueKind at profiling\n  /// site: Site.\n  inline uint32_t getNumValueDataForSite(uint32_t ValueKind,\n                                         uint32_t Site) const;\n\n  /// Return the array of profiled values at \\p Site. If \\p TotalC\n  /// is not null, the total count of all target values at this site\n  /// will be stored in \\c *TotalC.\n  inline std::unique_ptr<InstrProfValueData[]>\n  getValueForSite(uint32_t ValueKind, uint32_t Site,\n                  uint64_t *TotalC = nullptr) const;\n\n  /// Get the target value/counts of kind \\p ValueKind collected at site\n  /// \\p Site and store the result in array \\p Dest. Return the total\n  /// counts of all target values at this site.\n  inline uint64_t getValueForSite(InstrProfValueData Dest[], uint32_t ValueKind,\n                                  uint32_t Site) const;\n\n  /// Reserve space for NumValueSites sites.\n  inline void reserveSites(uint32_t ValueKind, uint32_t NumValueSites);\n\n  /// Add ValueData for ValueKind at value Site.\n  void addValueData(uint32_t ValueKind, uint32_t Site,\n                    InstrProfValueData *VData, uint32_t N,\n                    InstrProfSymtab *SymTab);\n\n  /// Merge the counts in \\p Other into this one.\n  /// Optionally scale merged counts by \\p Weight.\n  void merge(InstrProfRecord &Other, uint64_t Weight,\n             function_ref<void(instrprof_error)> Warn);\n\n  /// Scale up profile counts (including value profile data) by\n  /// a factor of (N / D).\n  void scale(uint64_t N, uint64_t D, function_ref<void(instrprof_error)> Warn);\n\n  /// Sort value profile data (per site) by count.\n  void sortValueData() {\n    for (uint32_t Kind = IPVK_First; Kind <= IPVK_Last; ++Kind)\n      for (auto &SR : getValueSitesForKind(Kind))\n        SR.sortByCount();\n  }\n\n  /// Clear value data entries and edge counters.\n  void Clear() {\n    Counts.clear();\n    clearValueData();\n  }\n\n  /// Clear value data entries\n  void clearValueData() { ValueData = nullptr; }\n\n  /// Compute the sums of all counts and store in Sum.\n  void accumulateCounts(CountSumOrPercent &Sum) const;\n\n  /// Compute the overlap b/w this IntrprofRecord and Other.\n  void overlap(InstrProfRecord &Other, OverlapStats &Overlap,\n               OverlapStats &FuncLevelOverlap, uint64_t ValueCutoff);\n\n  /// Compute the overlap of value profile counts.\n  void overlapValueProfData(uint32_t ValueKind, InstrProfRecord &Src,\n                            OverlapStats &Overlap,\n                            OverlapStats &FuncLevelOverlap);\n\n  enum CountPseudoKind {\n    NotPseudo = 0,\n    PseudoHot,\n    PseudoWarm,\n  };\n  enum PseudoCountVal {\n    HotFunctionVal = -1,\n    WarmFunctionVal = -2,\n  };\n  CountPseudoKind getCountPseudoKind() const {\n    uint64_t FirstCount = Counts[0];\n    if (FirstCount == (uint64_t)HotFunctionVal)\n      return PseudoHot;\n    if (FirstCount == (uint64_t)WarmFunctionVal)\n      return PseudoWarm;\n    return NotPseudo;\n  }\n  void setPseudoCount(CountPseudoKind Kind) {\n    if (Kind == PseudoHot)\n      Counts[0] = (uint64_t)HotFunctionVal;\n    else if (Kind == PseudoWarm)\n      Counts[0] = (uint64_t)WarmFunctionVal;\n  }\n\nprivate:\n  struct ValueProfData {\n    std::vector<InstrProfValueSiteRecord> IndirectCallSites;\n    std::vector<InstrProfValueSiteRecord> MemOPSizes;\n  };\n  std::unique_ptr<ValueProfData> ValueData;\n\n  MutableArrayRef<InstrProfValueSiteRecord>\n  getValueSitesForKind(uint32_t ValueKind) {\n    // Cast to /add/ const (should be an implicit_cast, ideally, if that's ever\n    // implemented in LLVM) to call the const overload of this function, then\n    // cast away the constness from the result.\n    auto AR = const_cast<const InstrProfRecord *>(this)->getValueSitesForKind(\n        ValueKind);\n    return MutableArrayRef(\n        const_cast<InstrProfValueSiteRecord *>(AR.data()), AR.size());\n  }\n  ArrayRef<InstrProfValueSiteRecord>\n  getValueSitesForKind(uint32_t ValueKind) const {\n    if (!ValueData)\n      return std::nullopt;\n    switch (ValueKind) {\n    case IPVK_IndirectCallTarget:\n      return ValueData->IndirectCallSites;\n    case IPVK_MemOPSize:\n      return ValueData->MemOPSizes;\n    default:\n      llvm_unreachable(\"Unknown value kind!\");\n    }\n  }\n\n  std::vector<InstrProfValueSiteRecord> &\n  getOrCreateValueSitesForKind(uint32_t ValueKind) {\n    if (!ValueData)\n      ValueData = std::make_unique<ValueProfData>();\n    switch (ValueKind) {\n    case IPVK_IndirectCallTarget:\n      return ValueData->IndirectCallSites;\n    case IPVK_MemOPSize:\n      return ValueData->MemOPSizes;\n    default:\n      llvm_unreachable(\"Unknown value kind!\");\n    }\n  }\n\n  // Map indirect call target name hash to name string.\n  uint64_t remapValue(uint64_t Value, uint32_t ValueKind,\n                      InstrProfSymtab *SymTab);\n\n  // Merge Value Profile data from Src record to this record for ValueKind.\n  // Scale merged value counts by \\p Weight.\n  void mergeValueProfData(uint32_t ValkeKind, InstrProfRecord &Src,\n                          uint64_t Weight,\n                          function_ref<void(instrprof_error)> Warn);\n\n  // Scale up value profile data count by N (Numerator) / D (Denominator).\n  void scaleValueProfData(uint32_t ValueKind, uint64_t N, uint64_t D,\n                          function_ref<void(instrprof_error)> Warn);\n};\n\nstruct NamedInstrProfRecord : InstrProfRecord {\n  StringRef Name;\n  uint64_t Hash;\n\n  // We reserve this bit as the flag for context sensitive profile record.\n  static const int CS_FLAG_IN_FUNC_HASH = 60;\n\n  NamedInstrProfRecord() = default;\n  NamedInstrProfRecord(StringRef Name, uint64_t Hash,\n                       std::vector<uint64_t> Counts)\n      : InstrProfRecord(std::move(Counts)), Name(Name), Hash(Hash) {}\n  NamedInstrProfRecord(StringRef Name, uint64_t Hash,\n                       std::vector<uint64_t> Counts,\n                       std::vector<uint8_t> BitmapBytes)\n      : InstrProfRecord(std::move(Counts), std::move(BitmapBytes)), Name(Name),\n        Hash(Hash) {}\n\n  static bool hasCSFlagInHash(uint64_t FuncHash) {\n    return ((FuncHash >> CS_FLAG_IN_FUNC_HASH) & 1);\n  }\n  static void setCSFlagInHash(uint64_t &FuncHash) {\n    FuncHash |= ((uint64_t)1 << CS_FLAG_IN_FUNC_HASH);\n  }\n};\n\nuint32_t InstrProfRecord::getNumValueKinds() const {\n  uint32_t NumValueKinds = 0;\n  for (uint32_t Kind = IPVK_First; Kind <= IPVK_Last; ++Kind)\n    NumValueKinds += !(getValueSitesForKind(Kind).empty());\n  return NumValueKinds;\n}\n\nuint32_t InstrProfRecord::getNumValueData(uint32_t ValueKind) const {\n  uint32_t N = 0;\n  for (const auto &SR : getValueSitesForKind(ValueKind))\n    N += SR.ValueData.size();\n  return N;\n}\n\nuint32_t InstrProfRecord::getNumValueSites(uint32_t ValueKind) const {\n  return getValueSitesForKind(ValueKind).size();\n}\n\nuint32_t InstrProfRecord::getNumValueDataForSite(uint32_t ValueKind,\n                                                 uint32_t Site) const {\n  return getValueSitesForKind(ValueKind)[Site].ValueData.size();\n}\n\nstd::unique_ptr<InstrProfValueData[]>\nInstrProfRecord::getValueForSite(uint32_t ValueKind, uint32_t Site,\n                                 uint64_t *TotalC) const {\n  uint64_t Dummy = 0;\n  uint64_t &TotalCount = (TotalC == nullptr ? Dummy : *TotalC);\n  uint32_t N = getNumValueDataForSite(ValueKind, Site);\n  if (N == 0) {\n    TotalCount = 0;\n    return std::unique_ptr<InstrProfValueData[]>(nullptr);\n  }\n\n  auto VD = std::make_unique<InstrProfValueData[]>(N);\n  TotalCount = getValueForSite(VD.get(), ValueKind, Site);\n\n  return VD;\n}\n\nuint64_t InstrProfRecord::getValueForSite(InstrProfValueData Dest[],\n                                          uint32_t ValueKind,\n                                          uint32_t Site) const {\n  uint32_t I = 0;\n  uint64_t TotalCount = 0;\n  for (auto V : getValueSitesForKind(ValueKind)[Site].ValueData) {\n    Dest[I].Value = V.Value;\n    Dest[I].Count = V.Count;\n    TotalCount = SaturatingAdd(TotalCount, V.Count);\n    I++;\n  }\n  return TotalCount;\n}\n\nvoid InstrProfRecord::reserveSites(uint32_t ValueKind, uint32_t NumValueSites) {\n  if (!NumValueSites)\n    return;\n  getOrCreateValueSitesForKind(ValueKind).reserve(NumValueSites);\n}\n\n// Include definitions for value profile data\n#define INSTR_PROF_VALUE_PROF_DATA\n#include \"llvm/ProfileData/InstrProfData.inc\"\n\nvoid InstrProfValueSiteRecord::sortByCount() {\n  ValueData.sort(\n      [](const InstrProfValueData &left, const InstrProfValueData &right) {\n        return left.Count > right.Count;\n      });\n  // Now truncate\n  size_t max_s = INSTR_PROF_MAX_NUM_VAL_PER_SITE;\n  if (ValueData.size() > max_s)\n    ValueData.resize(max_s);\n}\n\nnamespace IndexedInstrProf {\n\nenum class HashT : uint32_t {\n  MD5,\n  Last = MD5\n};\n\ninline uint64_t ComputeHash(HashT Type, StringRef K) {\n  switch (Type) {\n  case HashT::MD5:\n    return MD5Hash(K);\n  }\n  llvm_unreachable(\"Unhandled hash type\");\n}\n\nconst uint64_t Magic = 0x8169666f72706cff; // \"\\xfflprofi\\x81\"\n\nenum ProfVersion {\n  // Version 1 is the first version. In this version, the value of\n  // a key/value pair can only include profile data of a single function.\n  // Due to this restriction, the number of block counters for a given\n  // function is not recorded but derived from the length of the value.\n  Version1 = 1,\n  // The version 2 format supports recording profile data of multiple\n  // functions which share the same key in one value field. To support this,\n  // the number block counters is recorded as an uint64_t field right after the\n  // function structural hash.\n  Version2 = 2,\n  // Version 3 supports value profile data. The value profile data is expected\n  // to follow the block counter profile data.\n  Version3 = 3,\n  // In this version, profile summary data \\c IndexedInstrProf::Summary is\n  // stored after the profile header.\n  Version4 = 4,\n  // In this version, the frontend PGO stable hash algorithm defaults to V2.\n  Version5 = 5,\n  // In this version, the frontend PGO stable hash algorithm got fixed and\n  // may produce hashes different from Version5.\n  Version6 = 6,\n  // An additional counter is added around logical operators.\n  Version7 = 7,\n  // An additional (optional) memory profile type is added.\n  Version8 = 8,\n  // Binary ids are added.\n  Version9 = 9,\n  // An additional (optional) temporal profile traces section is added.\n  Version10 = 10,\n  // An additional field is used for bitmap bytes.\n  Version11 = 11,\n  // The current version is 11.\n  CurrentVersion = INSTR_PROF_INDEX_VERSION\n};\nconst uint64_t Version = ProfVersion::CurrentVersion;\n\nconst HashT HashType = HashT::MD5;\n\ninline uint64_t ComputeHash(StringRef K) { return ComputeHash(HashType, K); }\n\n// This structure defines the file header of the LLVM profile\n// data file in indexed-format. Please update llvm/docs/InstrProfileFormat.rst\n// as appropriate when updating the indexed profile format.\nstruct Header {\n  uint64_t Magic;\n  uint64_t Version;\n  uint64_t Unused; // Becomes unused since version 4\n  uint64_t HashType;\n  uint64_t HashOffset;\n  uint64_t MemProfOffset;\n  uint64_t BinaryIdOffset;\n  uint64_t TemporalProfTracesOffset;\n  // New fields should only be added at the end to ensure that the size\n  // computation is correct. The methods below need to be updated to ensure that\n  // the new field is read correctly.\n\n  // Reads a header struct from the buffer.\n  static Expected<Header> readFromBuffer(const unsigned char *Buffer);\n\n  // Returns the size of the header in bytes for all valid fields based on the\n  // version. I.e a older version header will return a smaller size.\n  size_t size() const;\n\n  // Returns the format version in little endian. The header retains the version\n  // in native endian of the compiler runtime.\n  uint64_t formatVersion() const;\n};\n\n// Profile summary data recorded in the profile data file in indexed\n// format. It is introduced in version 4. The summary data follows\n// right after the profile file header.\nstruct Summary {\n  struct Entry {\n    uint64_t Cutoff; ///< The required percentile of total execution count.\n    uint64_t\n        MinBlockCount;  ///< The minimum execution count for this percentile.\n    uint64_t NumBlocks; ///< Number of blocks >= the minumum execution count.\n  };\n  // The field kind enumerator to assigned value mapping should remain\n  // unchanged  when a new kind is added or an old kind gets deleted in\n  // the future.\n  enum SummaryFieldKind {\n    /// The total number of functions instrumented.\n    TotalNumFunctions = 0,\n    /// Total number of instrumented blocks/edges.\n    TotalNumBlocks = 1,\n    /// The maximal execution count among all functions.\n    /// This field does not exist for profile data from IR based\n    /// instrumentation.\n    MaxFunctionCount = 2,\n    /// Max block count of the program.\n    MaxBlockCount = 3,\n    /// Max internal block count of the program (excluding entry blocks).\n    MaxInternalBlockCount = 4,\n    /// The sum of all instrumented block counts.\n    TotalBlockCount = 5,\n    NumKinds = TotalBlockCount + 1\n  };\n\n  // The number of summmary fields following the summary header.\n  uint64_t NumSummaryFields;\n  // The number of Cutoff Entries (Summary::Entry) following summary fields.\n  uint64_t NumCutoffEntries;\n\n  Summary() = delete;\n  Summary(uint32_t Size) { memset(this, 0, Size); }\n\n  void operator delete(void *ptr) { ::operator delete(ptr); }\n\n  static uint32_t getSize(uint32_t NumSumFields, uint32_t NumCutoffEntries) {\n    return sizeof(Summary) + NumCutoffEntries * sizeof(Entry) +\n           NumSumFields * sizeof(uint64_t);\n  }\n\n  const uint64_t *getSummaryDataBase() const {\n    return reinterpret_cast<const uint64_t *>(this + 1);\n  }\n\n  uint64_t *getSummaryDataBase() {\n    return reinterpret_cast<uint64_t *>(this + 1);\n  }\n\n  const Entry *getCutoffEntryBase() const {\n    return reinterpret_cast<const Entry *>(\n        &getSummaryDataBase()[NumSummaryFields]);\n  }\n\n  Entry *getCutoffEntryBase() {\n    return reinterpret_cast<Entry *>(&getSummaryDataBase()[NumSummaryFields]);\n  }\n\n  uint64_t get(SummaryFieldKind K) const {\n"}], "code": "uint64_t InstrProfSymtab::getFunctionHashFromAddress(uint64_t Address) {\n  finalizeSymtab();\n  auto It = partition_point(AddrToMD5Map, [=](std::pair<uint64_t, uint64_t> A) {\n    return A.first < Address;\n  });\n  // Raw function pointer collected by value profiler may be from\n  // external functions that are not instrumented. They won't have\n  // mapping data to be used by the deserializer. Force the value to\n  // be 0 in this case.\n  if (It != AddrToMD5Map.end() && It->first == Address)\n    return (uint64_t)It->second;\n  return 0;\n}\n"}, "AA232096EAC1EC91": {"calls": [{"id": "65F2F4BA858E2829", "name": "llvm::TreePatternNode::getOperator", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 719, "col": 3}, "end": {"line": 722, "col": 3}, "code": "    assert(!isLeaf());\n    return cast<Record *>(OperatorOrVal);\n  }\n\n  unsigned getNumChildren() const { return Children.size(); }\n  const TreePatternNode &getChild(unsigned N) const {\n    return *Children[N].get();\n  }\n  TreePatternNode &getChild(unsigned N) { return *Children[N].get(); }\n  const TreePatternNodePtr &getChildShared(unsigned N) const {\n    return Children[N];\n  }\n  TreePatternNodePtr &getChildSharedPtr(unsigned N) { return Children[N]; }\n  void setChild(unsigned i, TreePatternNodePtr N) { Children[i] = N; }\n\n  /// hasChild - Return true if N is any of our children.\n  bool hasChild(const TreePatternNode *N) const {\n    for (unsigned i = 0, e = Children.size(); i != e; ++i)\n      if (Children[i].get() == N)\n        return true;\n    return false;\n  }\n\n  bool hasProperTypeByHwMode() const;\n  bool hasPossibleType() const;\n  bool setDefaultMode(unsigned Mode);\n\n  bool hasAnyPredicate() const { return !PredicateCalls.empty(); }\n\n  const std::vector<TreePredicateCall> &getPredicateCalls() const {\n    return PredicateCalls;\n  }\n  void clearPredicateCalls() { PredicateCalls.clear(); }\n  void setPredicateCalls(const std::vector<TreePredicateCall> &Calls) {\n    assert(PredicateCalls.empty() && \"Overwriting non-empty predicate list!\");\n    PredicateCalls = Calls;\n  }\n  void addPredicateCall(const TreePredicateCall &Call) {\n    assert(!Call.Fn.isAlwaysTrue() && \"Empty predicate string!\");\n    assert(!is_contained(PredicateCalls, Call) &&\n           \"predicate applied recursively\");\n    PredicateCalls.push_back(Call);\n  }\n  void addPredicateCall(const TreePredicateFn &Fn, unsigned Scope) {\n    assert((Scope != 0) == Fn.usesOperands());\n    addPredicateCall(TreePredicateCall(Fn, Scope));\n  }\n\n  Record *getTransformFn() const { return TransformFn; }\n  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "A2EE9A7617A9AC66", "name": "llvm::CodeGenDAGPatterns::get_intrinsic_void_sdnode", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 1213, "col": 3}, "end": {"line": 1213, "col": 77}, "code": "  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "97608C7DABED5B14", "name": "llvm::CodeGenDAGPatterns::get_intrinsic_w_chain_sdnode", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 1214, "col": 3}, "end": {"line": 1216, "col": 3}, "code": "    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "664F982F0FFC4296", "name": "llvm::CodeGenDAGPatterns::get_intrinsic_wo_chain_sdnode", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 1217, "col": 3}, "end": {"line": 1219, "col": 3}, "code": "    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "13926D3CB9025EBF", "name": "llvm::IntInit::getValue", "path": "llvm-project/llvm/include/llvm/TableGen/Record.h", "start": {"line": 647, "col": 3}, "end": {"line": 647, "col": 44}, "code": "\n  Init *convertInitializerTo(RecTy *Ty) const override;\n  Init *convertInitializerBitRange(ArrayRef<unsigned> Bits) const override;\n\n  bool isConcrete() const override { return true; }\n  std::string getAsString() const override;\n\n  Init *getBit(unsigned Bit) const override {\n    return BitInit::get(getRecordKeeper(), (Value & (1ULL << Bit)) != 0);\n  }\n};\n\n/// \"anonymous_n\" - Represent an anonymous record name\nclass AnonymousNameInit : public TypedInit {\n  unsigned Value;\n\n  explicit AnonymousNameInit(RecordKeeper &RK, unsigned V)\n      : TypedInit(IK_AnonymousNameInit, StringRecTy::get(RK)), Value(V) {}\n\npublic:\n  AnonymousNameInit(const AnonymousNameInit &) = delete;\n  AnonymousNameInit &operator=(const AnonymousNameInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_AnonymousNameInit;\n  }\n\n  static AnonymousNameInit *get(RecordKeeper &RK, unsigned);\n\n  unsigned getValue() const { return Value; }\n\n  StringInit *getNameInit() const;\n\n  std::string getAsString() const override;\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  Init *getBit(unsigned Bit) const override {\n    llvm_unreachable(\"Illegal bit reference off string\");\n  }\n};\n\n/// \"foo\" - Represent an initialization by a string value.\nclass StringInit : public TypedInit {\npublic:\n  enum StringFormat {\n    SF_String, // Format as \"text\"\n    SF_Code,   // Format as [{text}]\n  };\n\nprivate:\n  StringRef Value;\n  StringFormat Format;\n\n  explicit StringInit(RecordKeeper &RK, StringRef V, StringFormat Fmt)\n      : TypedInit(IK_StringInit, StringRecTy::get(RK)), Value(V), Format(Fmt) {}\n\npublic:\n  StringInit(const StringInit &) = delete;\n  StringInit &operator=(const StringInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_StringInit;\n  }\n\n  static StringInit *get(RecordKeeper &RK, StringRef,\n                         StringFormat Fmt = SF_String);\n\n  static StringFormat determineFormat(StringFormat Fmt1, StringFormat Fmt2) {\n    return (Fmt1 == SF_Code || Fmt2 == SF_Code) ? SF_Code : SF_String;\n  }\n\n  StringRef getValue() const { return Value; }\n  StringFormat getFormat() const { return Format; }\n  bool hasCodeFormat() const { return Format == SF_Code; }\n\n  Init *convertInitializerTo(RecTy *Ty) const override;\n\n  bool isConcrete() const override { return true; }\n\n  std::string getAsString() const override {\n    if (Format == SF_String)\n      return \"\\\"\" + Value.str() + \"\\\"\";\n    else\n      return \"[{\" + Value.str() + \"}]\";\n  }\n\n  std::string getAsUnquotedString() const override {\n    return std::string(Value);\n  }\n\n  Init *getBit(unsigned Bit) const override {\n    llvm_unreachable(\"Illegal bit reference off string\");\n  }\n};\n\n/// [AL, AH, CL] - Represent a list of defs\n///\nclass ListInit final : public TypedInit, public FoldingSetNode,\n                       public TrailingObjects<ListInit, Init *> {\n  unsigned NumValues;\n\npublic:\n  using const_iterator = Init *const *;\n\nprivate:\n  explicit ListInit(unsigned N, RecTy *EltTy)\n      : TypedInit(IK_ListInit, ListRecTy::get(EltTy)), NumValues(N) {}\n\npublic:\n  ListInit(const ListInit &) = delete;\n  ListInit &operator=(const ListInit &) = delete;\n\n  // Do not use sized deallocation due to trailing objects.\n  void operator delete(void *p) { ::operator delete(p); }\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_ListInit;\n  }\n  static ListInit *get(ArrayRef<Init *> Range, RecTy *EltTy);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  Init *getElement(unsigned i) const {\n    assert(i < NumValues && \"List element index out of range!\");\n    return getTrailingObjects<Init *>()[i];\n  }\n  RecTy *getElementType() const {\n    return cast<ListRecTy>(getType())->getElementType();\n  }\n\n  Record *getElementAsRecord(unsigned i) const;\n\n  Init *convertInitializerTo(RecTy *Ty) const override;\n\n  /// This method is used by classes that refer to other\n  /// variables which may not be defined at the time they expression is formed.\n  /// If a value is set for the variable later, this method will be called on\n  /// users of the value to allow the value to propagate out.\n  ///\n  Init *resolveReferences(Resolver &R) const override;\n\n  bool isComplete() const override;\n  bool isConcrete() const override;\n  std::string getAsString() const override;\n\n  ArrayRef<Init*> getValues() const {\n    return ArrayRef(getTrailingObjects<Init *>(), NumValues);\n  }\n\n  const_iterator begin() const { return getTrailingObjects<Init *>(); }\n  const_iterator end  () const { return begin() + NumValues; }\n\n  size_t         size () const { return NumValues;  }\n  bool           empty() const { return NumValues == 0; }\n\n  Init *getBit(unsigned Bit) const override {\n    llvm_unreachable(\"Illegal bit reference off list\");\n  }\n};\n\n/// Base class for operators\n///\nclass OpInit : public TypedInit {\nprotected:\n  explicit OpInit(InitKind K, RecTy *Type, uint8_t Opc)\n    : TypedInit(K, Type, Opc) {}\n\npublic:\n  OpInit(const OpInit &) = delete;\n  OpInit &operator=(OpInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() >= IK_FirstOpInit &&\n           I->getKind() <= IK_LastOpInit;\n  }\n\n  // Clone - Clone this operator, replacing arguments with the new list\n  virtual OpInit *clone(ArrayRef<Init *> Operands) const = 0;\n\n  virtual unsigned getNumOperands() const = 0;\n  virtual Init *getOperand(unsigned i) const = 0;\n\n  Init *getBit(unsigned Bit) const override;\n};\n\n/// !op (X) - Transform an init.\n///\nclass UnOpInit : public OpInit, public FoldingSetNode {\npublic:\n  enum UnaryOp : uint8_t {\n    TOLOWER,\n    TOUPPER,\n    CAST,\n    NOT,\n    HEAD,\n    TAIL,\n    SIZE,\n    EMPTY,\n    GETDAGOP,\n    LOG2,\n    REPR\n  };\n\nprivate:\n  Init *LHS;\n\n  UnOpInit(UnaryOp opc, Init *lhs, RecTy *Type)\n    : OpInit(IK_UnOpInit, Type, opc), LHS(lhs) {}\n\npublic:\n  UnOpInit(const UnOpInit &) = delete;\n  UnOpInit &operator=(const UnOpInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_UnOpInit;\n  }\n\n  static UnOpInit *get(UnaryOp opc, Init *lhs, RecTy *Type);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  // Clone - Clone this operator, replacing arguments with the new list\n  OpInit *clone(ArrayRef<Init *> Operands) const override {\n    assert(Operands.size() == 1 &&\n           \"Wrong number of operands for unary operation\");\n    return UnOpInit::get(getOpcode(), *Operands.begin(), getType());\n  }\n\n  unsigned getNumOperands() const override { return 1; }\n\n  Init *getOperand(unsigned i) const override {\n    assert(i == 0 && \"Invalid operand id for unary operator\");\n    return getOperand();\n  }\n\n  UnaryOp getOpcode() const { return (UnaryOp)Opc; }\n  Init *getOperand() const { return LHS; }\n\n  // Fold - If possible, fold this to a simpler init.  Return this if not\n  // possible to fold.\n  Init *Fold(Record *CurRec, bool IsFinal = false) const;\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  std::string getAsString() const override;\n};\n\n/// !op (X, Y) - Combine two inits.\nclass BinOpInit : public OpInit, public FoldingSetNode {\npublic:\n  enum BinaryOp : uint8_t {\n    ADD,\n    SUB,\n    MUL,\n    DIV,\n    AND,\n    OR,\n    XOR,\n    SHL,\n    SRA,\n    SRL,\n    LISTCONCAT,\n    LISTSPLAT,\n    LISTREMOVE,\n    LISTELEM,\n    LISTSLICE,\n    RANGEC,\n    STRCONCAT,\n    INTERLEAVE,\n    CONCAT,\n    EQ,\n    NE,\n    LE,\n    LT,\n    GE,\n    GT,\n    GETDAGARG,\n    GETDAGNAME,\n    SETDAGOP,\n  };\n\nprivate:\n  Init *LHS, *RHS;\n\n  BinOpInit(BinaryOp opc, Init *lhs, Init *rhs, RecTy *Type) :\n      OpInit(IK_BinOpInit, Type, opc), LHS(lhs), RHS(rhs) {}\n\npublic:\n  BinOpInit(const BinOpInit &) = delete;\n  BinOpInit &operator=(const BinOpInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_BinOpInit;\n  }\n\n  static BinOpInit *get(BinaryOp opc, Init *lhs, Init *rhs,\n                        RecTy *Type);\n  static Init *getStrConcat(Init *lhs, Init *rhs);\n  static Init *getListConcat(TypedInit *lhs, Init *rhs);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  // Clone - Clone this operator, replacing arguments with the new list\n  OpInit *clone(ArrayRef<Init *> Operands) const override {\n    assert(Operands.size() == 2 &&\n           \"Wrong number of operands for binary operation\");\n    return BinOpInit::get(getOpcode(), Operands[0], Operands[1], getType());\n  }\n\n  unsigned getNumOperands() const override { return 2; }\n  Init *getOperand(unsigned i) const override {\n    switch (i) {\n    default: llvm_unreachable(\"Invalid operand id for binary operator\");\n    case 0: return getLHS();\n    case 1: return getRHS();\n    }\n  }\n\n  BinaryOp getOpcode() const { return (BinaryOp)Opc; }\n  Init *getLHS() const { return LHS; }\n  Init *getRHS() const { return RHS; }\n\n  std::optional<bool> CompareInit(unsigned Opc, Init *LHS, Init *RHS) const;\n\n  // Fold - If possible, fold this to a simpler init.  Return this if not\n  // possible to fold.\n  Init *Fold(Record *CurRec) const;\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  std::string getAsString() const override;\n};\n\n/// !op (X, Y, Z) - Combine two inits.\nclass TernOpInit : public OpInit, public FoldingSetNode {\npublic:\n  enum TernaryOp : uint8_t {\n    SUBST,\n    FOREACH,\n    FILTER,\n    IF,\n    DAG,\n    RANGE,\n    SUBSTR,\n    FIND,\n    SETDAGARG,\n    SETDAGNAME,\n  };\n\nprivate:\n  Init *LHS, *MHS, *RHS;\n\n  TernOpInit(TernaryOp opc, Init *lhs, Init *mhs, Init *rhs,\n             RecTy *Type) :\n      OpInit(IK_TernOpInit, Type, opc), LHS(lhs), MHS(mhs), RHS(rhs) {}\n\npublic:\n  TernOpInit(const TernOpInit &) = delete;\n  TernOpInit &operator=(const TernOpInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_TernOpInit;\n  }\n\n  static TernOpInit *get(TernaryOp opc, Init *lhs,\n                         Init *mhs, Init *rhs,\n                         RecTy *Type);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  // Clone - Clone this operator, replacing arguments with the new list\n  OpInit *clone(ArrayRef<Init *> Operands) const override {\n    assert(Operands.size() == 3 &&\n           \"Wrong number of operands for ternary operation\");\n    return TernOpInit::get(getOpcode(), Operands[0], Operands[1], Operands[2],\n                           getType());\n  }\n\n  unsigned getNumOperands() const override { return 3; }\n  Init *getOperand(unsigned i) const override {\n    switch (i) {\n    default: llvm_unreachable(\"Invalid operand id for ternary operator\");\n    case 0: return getLHS();\n    case 1: return getMHS();\n    case 2: return getRHS();\n    }\n  }\n\n  TernaryOp getOpcode() const { return (TernaryOp)Opc; }\n  Init *getLHS() const { return LHS; }\n  Init *getMHS() const { return MHS; }\n  Init *getRHS() const { return RHS; }\n\n  // Fold - If possible, fold this to a simpler init.  Return this if not\n  // possible to fold.\n  Init *Fold(Record *CurRec) const;\n\n  bool isComplete() const override {\n    return LHS->isComplete() && MHS->isComplete() && RHS->isComplete();\n  }\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  std::string getAsString() const override;\n};\n\n/// !cond(condition_1: value1, ... , condition_n: value)\n/// Selects the first value for which condition is true.\n/// Otherwise reports an error.\nclass CondOpInit final : public TypedInit, public FoldingSetNode,\n                      public TrailingObjects<CondOpInit, Init *> {\n  unsigned NumConds;\n  RecTy *ValType;\n\n  CondOpInit(unsigned NC, RecTy *Type)\n    : TypedInit(IK_CondOpInit, Type),\n      NumConds(NC), ValType(Type) {}\n\n  size_t numTrailingObjects(OverloadToken<Init *>) const {\n    return 2*NumConds;\n  }\n\npublic:\n  CondOpInit(const CondOpInit &) = delete;\n  CondOpInit &operator=(const CondOpInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_CondOpInit;\n  }\n\n  static CondOpInit *get(ArrayRef<Init*> C, ArrayRef<Init*> V,\n                        RecTy *Type);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  RecTy *getValType() const { return ValType; }\n\n  unsigned getNumConds() const { return NumConds; }\n\n  Init *getCond(unsigned Num) const {\n    assert(Num < NumConds && \"Condition number out of range!\");\n    return getTrailingObjects<Init *>()[Num];\n  }\n\n  Init *getVal(unsigned Num) const {\n    assert(Num < NumConds && \"Val number out of range!\");\n    return getTrailingObjects<Init *>()[Num+NumConds];\n  }\n\n  ArrayRef<Init *> getConds() const {\n    return ArrayRef(getTrailingObjects<Init *>(), NumConds);\n  }\n\n  ArrayRef<Init *> getVals() const {\n    return ArrayRef(getTrailingObjects<Init *>() + NumConds, NumConds);\n  }\n\n  Init *Fold(Record *CurRec) const;\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  bool isConcrete() const override;\n  bool isComplete() const override;\n  std::string getAsString() const override;\n\n  using const_case_iterator = SmallVectorImpl<Init*>::const_iterator;\n  using const_val_iterator = SmallVectorImpl<Init*>::const_iterator;\n\n  inline const_case_iterator  arg_begin() const { return getConds().begin(); }\n  inline const_case_iterator  arg_end  () const { return getConds().end(); }\n\n  inline size_t              case_size () const { return NumConds; }\n  inline bool                case_empty() const { return NumConds == 0; }\n\n  inline const_val_iterator name_begin() const { return getVals().begin();}\n  inline const_val_iterator name_end  () const { return getVals().end(); }\n\n  inline size_t              val_size () const { return NumConds; }\n  inline bool                val_empty() const { return NumConds == 0; }\n\n  Init *getBit(unsigned Bit) const override;\n};\n\n/// !foldl (a, b, expr, start, lst) - Fold over a list.\nclass FoldOpInit : public TypedInit, public FoldingSetNode {\nprivate:\n  Init *Start;\n  Init *List;\n  Init *A;\n  Init *B;\n  Init *Expr;\n\n  FoldOpInit(Init *Start, Init *List, Init *A, Init *B, Init *Expr, RecTy *Type)\n      : TypedInit(IK_FoldOpInit, Type), Start(Start), List(List), A(A), B(B),\n        Expr(Expr) {}\n\npublic:\n  FoldOpInit(const FoldOpInit &) = delete;\n  FoldOpInit &operator=(const FoldOpInit &) = delete;\n\n  static bool classof(const Init *I) { return I->getKind() == IK_FoldOpInit; }\n\n  static FoldOpInit *get(Init *Start, Init *List, Init *A, Init *B, Init *Expr,\n                         RecTy *Type);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  // Fold - If possible, fold this to a simpler init.  Return this if not\n  // possible to fold.\n  Init *Fold(Record *CurRec) const;\n\n  bool isComplete() const override { return false; }\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  Init *getBit(unsigned Bit) const override;\n\n  std::string getAsString() const override;\n};\n\n/// !isa<type>(expr) - Dynamically determine the type of an expression.\nclass IsAOpInit : public TypedInit, public FoldingSetNode {\nprivate:\n  RecTy *CheckType;\n  Init *Expr;\n\n  IsAOpInit(RecTy *CheckType, Init *Expr)\n      : TypedInit(IK_IsAOpInit, IntRecTy::get(CheckType->getRecordKeeper())),\n        CheckType(CheckType), Expr(Expr) {}\n\npublic:\n  IsAOpInit(const IsAOpInit &) = delete;\n  IsAOpInit &operator=(const IsAOpInit &) = delete;\n\n  static bool classof(const Init *I) { return I->getKind() == IK_IsAOpInit; }\n\n  static IsAOpInit *get(RecTy *CheckType, Init *Expr);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  // Fold - If possible, fold this to a simpler init.  Return this if not\n  // possible to fold.\n  Init *Fold() const;\n\n  bool isComplete() const override { return false; }\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  Init *getBit(unsigned Bit) const override;\n\n  std::string getAsString() const override;\n};\n\n/// !exists<type>(expr) - Dynamically determine if a record of `type` named\n/// `expr` exists.\nclass ExistsOpInit : public TypedInit, public FoldingSetNode {\nprivate:\n  RecTy *CheckType;\n  Init *Expr;\n\n  ExistsOpInit(RecTy *CheckType, Init *Expr)\n      : TypedInit(IK_ExistsOpInit, IntRecTy::get(CheckType->getRecordKeeper())),\n        CheckType(CheckType), Expr(Expr) {}\n\npublic:\n  ExistsOpInit(const ExistsOpInit &) = delete;\n  ExistsOpInit &operator=(const ExistsOpInit &) = delete;\n\n  static bool classof(const Init *I) { return I->getKind() == IK_ExistsOpInit; }\n\n  static ExistsOpInit *get(RecTy *CheckType, Init *Expr);\n\n  void Profile(FoldingSetNodeID &ID) const;\n\n  // Fold - If possible, fold this to a simpler init.  Return this if not\n  // possible to fold.\n  Init *Fold(Record *CurRec, bool IsFinal = false) const;\n\n  bool isComplete() const override { return false; }\n\n  Init *resolveReferences(Resolver &R) const override;\n\n  Init *getBit(unsigned Bit) const override;\n\n  std::string getAsString() const override;\n};\n\n/// 'Opcode' - Represent a reference to an entire variable object.\nclass VarInit : public TypedInit {\n  Init *VarName;\n\n  explicit VarInit(Init *VN, RecTy *T)\n      : TypedInit(IK_VarInit, T), VarName(VN) {}\n\npublic:\n  VarInit(const VarInit &) = delete;\n  VarInit &operator=(const VarInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_VarInit;\n  }\n\n  static VarInit *get(StringRef VN, RecTy *T);\n  static VarInit *get(Init *VN, RecTy *T);\n\n  StringRef getName() const;\n  Init *getNameInit() const { return VarName; }\n\n  std::string getNameInitAsString() const {\n    return getNameInit()->getAsUnquotedString();\n  }\n\n  /// This method is used by classes that refer to other\n  /// variables which may not be defined at the time they expression is formed.\n  /// If a value is set for the variable later, this method will be called on\n  /// users of the value to allow the value to propagate out.\n  ///\n  Init *resolveReferences(Resolver &R) const override;\n\n  Init *getBit(unsigned Bit) const override;\n\n  std::string getAsString() const override { return std::string(getName()); }\n};\n\n/// Opcode{0} - Represent access to one bit of a variable or field.\nclass VarBitInit final : public TypedInit {\n  TypedInit *TI;\n  unsigned Bit;\n\n  VarBitInit(TypedInit *T, unsigned B)\n      : TypedInit(IK_VarBitInit, BitRecTy::get(T->getRecordKeeper())), TI(T),\n        Bit(B) {\n    assert(T->getType() &&\n           (isa<IntRecTy>(T->getType()) ||\n            (isa<BitsRecTy>(T->getType()) &&\n             cast<BitsRecTy>(T->getType())->getNumBits() > B)) &&\n           \"Illegal VarBitInit expression!\");\n  }\n\npublic:\n  VarBitInit(const VarBitInit &) = delete;\n  VarBitInit &operator=(const VarBitInit &) = delete;\n\n  static bool classof(const Init *I) {\n    return I->getKind() == IK_VarBitInit;\n  }\n\n"}, {"id": "6970F2A26A23E6AB", "name": "llvm::TreePatternNode::getLeafValue", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 715, "col": 3}, "end": {"line": 718, "col": 3}, "code": "    assert(isLeaf());\n    return cast<Init *>(OperatorOrVal);\n  }\n  Record *getOperator() const {\n    assert(!isLeaf());\n    return cast<Record *>(OperatorOrVal);\n  }\n\n  unsigned getNumChildren() const { return Children.size(); }\n  const TreePatternNode &getChild(unsigned N) const {\n    return *Children[N].get();\n  }\n  TreePatternNode &getChild(unsigned N) { return *Children[N].get(); }\n  const TreePatternNodePtr &getChildShared(unsigned N) const {\n    return Children[N];\n  }\n  TreePatternNodePtr &getChildSharedPtr(unsigned N) { return Children[N]; }\n  void setChild(unsigned i, TreePatternNodePtr N) { Children[i] = N; }\n\n  /// hasChild - Return true if N is any of our children.\n  bool hasChild(const TreePatternNode *N) const {\n    for (unsigned i = 0, e = Children.size(); i != e; ++i)\n      if (Children[i].get() == N)\n        return true;\n    return false;\n  }\n\n  bool hasProperTypeByHwMode() const;\n  bool hasPossibleType() const;\n  bool setDefaultMode(unsigned Mode);\n\n  bool hasAnyPredicate() const { return !PredicateCalls.empty(); }\n\n  const std::vector<TreePredicateCall> &getPredicateCalls() const {\n    return PredicateCalls;\n  }\n  void clearPredicateCalls() { PredicateCalls.clear(); }\n  void setPredicateCalls(const std::vector<TreePredicateCall> &Calls) {\n    assert(PredicateCalls.empty() && \"Overwriting non-empty predicate list!\");\n    PredicateCalls = Calls;\n  }\n  void addPredicateCall(const TreePredicateCall &Call) {\n    assert(!Call.Fn.isAlwaysTrue() && \"Empty predicate string!\");\n    assert(!is_contained(PredicateCalls, Call) &&\n           \"predicate applied recursively\");\n    PredicateCalls.push_back(Call);\n  }\n  void addPredicateCall(const TreePredicateFn &Fn, unsigned Scope) {\n    assert((Scope != 0) == Fn.usesOperands());\n    addPredicateCall(TreePredicateCall(Fn, Scope));\n  }\n\n  Record *getTransformFn() const { return TransformFn; }\n  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "3FA2833DEBE919D2", "name": "llvm::CodeGenDAGPatterns::getIntrinsicInfo", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 1158, "col": 3}, "end": {"line": 1162, "col": 3}, "code": "    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}], "code": "const CodeGenIntrinsic *\nTreePatternNode::getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const {\n  if (getOperator() != CDP.get_intrinsic_void_sdnode() &&\n      getOperator() != CDP.get_intrinsic_w_chain_sdnode() &&\n      getOperator() != CDP.get_intrinsic_wo_chain_sdnode())\n    return nullptr;\n\n  unsigned IID = cast<IntInit>(getChild(0).getLeafValue())->getValue();\n  return &CDP.getIntrinsicInfo(IID);\n}\n"}, "7D36128668CA20A7": {"calls": [{"id": "2DEF2489EBC0C3D5", "name": "llvm::Record::getValueAsDef", "path": "llvm-project/llvm/lib/TableGen/Record.cpp", "start": {"line": 3054, "col": 1}, "end": {"line": 3064, "col": 1}, "code": "  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a def initializer!\");\n}\n\nRecord *Record::getValueAsOptionalDef(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  if (isa<UnsetInit>(R->getValue()))\n    return nullptr;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have either a def initializer or '?'!\");\n}\n\n\nbool Record::getValueAsBit(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nbool Record::getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName.str() + \"'!\\n\");\n\n  if (isa<UnsetInit>(R->getValue())) {\n    Unset = true;\n    return false;\n  }\n  Unset = false;\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nDagInit *Record::getValueAsDag(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DagInit *DI = dyn_cast<DagInit>(R->getValue()))\n    return DI;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a dag initializer!\");\n}\n\n// Check all record assertions: For each one, resolve the condition\n// and message, then call CheckAssert().\n// Note: The condition and message are probably already resolved,\n//       but resolving again allows calls before records are resolved.\nvoid Record::checkRecordAssertions() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Assertion : getAssertions()) {\n    Init *Condition = Assertion.Condition->resolveReferences(R);\n    Init *Message = Assertion.Message->resolveReferences(R);\n    CheckAssert(Assertion.Loc, Condition, Message);\n  }\n}\n\nvoid Record::emitRecordDumps() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Dump : getDumps()) {\n    Init *Message = Dump.Message->resolveReferences(R);\n    dumpMessage(Dump.Loc, Message);\n  }\n}\n\n// Report a warning if the record has unused template arguments.\nvoid Record::checkUnusedTemplateArgs() {\n  for (const Init *TA : getTemplateArgs()) {\n    const RecordVal *Arg = getValue(TA);\n    if (!Arg->isUsed())\n      PrintWarning(Arg->getLoc(),\n                   \"unused template argument: \" + Twine(Arg->getName()));\n  }\n}\n\nRecordKeeper::RecordKeeper()\n    : Impl(std::make_unique<detail::RecordKeeperImpl>(*this)) {}\nRecordKeeper::~RecordKeeper() = default;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\nLLVM_DUMP_METHOD void RecordKeeper::dump() const { errs() << *this; }\n#endif\n\nraw_ostream &llvm::operator<<(raw_ostream &OS, const RecordKeeper &RK) {\n  OS << \"------------- Classes -----------------\\n\";\n  for (const auto &C : RK.getClasses())\n    OS << \"class \" << *C.second;\n\n  OS << \"------------- Defs -----------------\\n\";\n  for (const auto &D : RK.getDefs())\n    OS << \"def \" << *D.second;\n  return OS;\n}\n\n/// GetNewAnonymousName - Generate a unique anonymous name that can be used as\n/// an identifier.\nInit *RecordKeeper::getNewAnonymousName() {\n  return AnonymousNameInit::get(*this, getImpl().AnonCounter++);\n}\n\n// These functions implement the phase timing facility. Starting a timer\n// when one is already running stops the running one.\n\nvoid RecordKeeper::startTimer(StringRef Name) {\n  if (TimingGroup) {\n    if (LastTimer && LastTimer->isRunning()) {\n      LastTimer->stopTimer();\n      if (BackendTimer) {\n        LastTimer->clear();\n        BackendTimer = false;\n      }\n    }\n\n    LastTimer = new Timer(\"\", Name, *TimingGroup);\n    LastTimer->startTimer();\n  }\n}\n\nvoid RecordKeeper::stopTimer() {\n  if (TimingGroup) {\n    assert(LastTimer && \"No phase timer was started\");\n    LastTimer->stopTimer();\n  }\n}\n\nvoid RecordKeeper::startBackendTimer(StringRef Name) {\n  if (TimingGroup) {\n    startTimer(Name);\n    BackendTimer = true;\n  }\n}\n\nvoid RecordKeeper::stopBackendTimer() {\n  if (TimingGroup) {\n    if (BackendTimer) {\n      stopTimer();\n      BackendTimer = false;\n    }\n  }\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitions(StringRef ClassName) const {\n  // We cache the record vectors for single classes. Many backends request\n  // the same vectors multiple times.\n  auto Pair = ClassRecordsMap.try_emplace(ClassName);\n  if (Pair.second)\n    Pair.first->second = getAllDerivedDefinitions(ArrayRef(ClassName));\n\n  return Pair.first->second;\n}\n\nstd::vector<Record *> RecordKeeper::getAllDerivedDefinitions(\n    ArrayRef<StringRef> ClassNames) const {\n  SmallVector<Record *, 2> ClassRecs;\n  std::vector<Record *> Defs;\n\n  assert(ClassNames.size() > 0 && \"At least one class must be passed.\");\n  for (const auto &ClassName : ClassNames) {\n    Record *Class = getClass(ClassName);\n    if (!Class)\n      PrintFatalError(\"The class '\" + ClassName + \"' is not defined\\n\");\n    ClassRecs.push_back(Class);\n  }\n\n  for (const auto &OneDef : getDefs()) {\n    if (all_of(ClassRecs, [&OneDef](const Record *Class) {\n                            return OneDef.second->isSubClassOf(Class);\n                          }))\n      Defs.push_back(OneDef.second.get());\n  }\n\n  llvm::sort(Defs, [](Record *LHS, Record *RHS) {\n    return LHS->getName().compare_numeric(RHS->getName()) < 0;\n  });\n\n  return Defs;\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitionsIfDefined(StringRef ClassName) const {\n  return getClass(ClassName) ? getAllDerivedDefinitions(ClassName)\n                             : std::vector<Record *>();\n}\n\nInit *MapResolver::resolve(Init *VarName) {\n  auto It = Map.find(VarName);\n  if (It == Map.end())\n    return nullptr;\n\n  Init *I = It->second.V;\n\n  if (!It->second.Resolved && Map.size() > 1) {\n    // Resolve mutual references among the mapped variables, but prevent\n    // infinite recursion.\n    Map.erase(It);\n    I = I->resolveReferences(*this);\n    Map[VarName] = {I, true};\n  }\n\n  return I;\n}\n\nInit *RecordResolver::resolve(Init *VarName) {\n  Init *Val = Cache.lookup(VarName);\n  if (Val)\n    return Val;\n\n  if (llvm::is_contained(Stack, VarName))\n    return nullptr; // prevent infinite recursion\n\n  if (RecordVal *RV = getCurrentRecord()->getValue(VarName)) {\n    if (!isa<UnsetInit>(RV->getValue())) {\n      Val = RV->getValue();\n      Stack.push_back(VarName);\n      Val = Val->resolveReferences(*this);\n      Stack.pop_back();\n    }\n  } else if (Name && VarName == getCurrentRecord()->getNameInit()) {\n    Stack.push_back(VarName);\n    Val = Name->resolveReferences(*this);\n    Stack.pop_back();\n  }\n\n  Cache[VarName] = Val;\n  return Val;\n}\n\nInit *TrackUnresolvedResolver::resolve(Init *VarName) {\n  Init *I = nullptr;\n\n  if (R) {\n    I = R->resolve(VarName);\n    if (I && !FoundUnresolved) {\n      // Do not recurse into the resolved initializer, as that would change\n      // the behavior of the resolver we're delegating, but do check to see\n      // if there are unresolved variables remaining.\n      TrackUnresolvedResolver Sub;\n      I->resolveReferences(Sub);\n      FoundUnresolved |= Sub.FoundUnresolved;\n    }\n  }\n\n  if (!I)\n    FoundUnresolved = true;\n  return I;\n}\n\nInit *HasReferenceResolver::resolve(Init *VarName)\n{\n  if (VarName == VarNameToTrack)\n    Found = true;\n  return nullptr;\n}\n"}, {"id": "6C0383008ACD4960", "name": "llvm::Record::getValueAsInt", "path": "llvm-project/llvm/lib/TableGen/Record.cpp", "start": {"line": 3008, "col": 1}, "end": {"line": 3020, "col": 1}, "code": "  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (IntInit *II = dyn_cast<IntInit>(R->getValue()))\n    return II->getValue();\n  PrintFatalError(getLoc(), Twine(\"Record `\") + getName() + \"', field `\" +\n                                FieldName +\n                                \"' exists but does not have an int value: \" +\n                                R->getValue()->getAsString());\n}\n\nstd::vector<int64_t>\nRecord::getValueAsListOfInts(StringRef FieldName) const {\n  ListInit *List = getValueAsListInit(FieldName);\n  std::vector<int64_t> Ints;\n  for (Init *I : List->getValues()) {\n    if (IntInit *II = dyn_cast<IntInit>(I))\n      Ints.push_back(II->getValue());\n    else\n      PrintFatalError(getLoc(),\n                      Twine(\"Record `\") + getName() + \"', field `\" + FieldName +\n                          \"' exists but does not have a list of ints value: \" +\n                          I->getAsString());\n  }\n  return Ints;\n}\n\nstd::vector<StringRef>\nRecord::getValueAsListOfStrings(StringRef FieldName) const {\n  ListInit *List = getValueAsListInit(FieldName);\n  std::vector<StringRef> Strings;\n  for (Init *I : List->getValues()) {\n    if (StringInit *SI = dyn_cast<StringInit>(I))\n      Strings.push_back(SI->getValue());\n    else\n      PrintFatalError(getLoc(),\n                      Twine(\"Record `\") + getName() + \"', field `\" + FieldName +\n                          \"' exists but does not have a list of strings value: \" +\n                          I->getAsString());\n  }\n  return Strings;\n}\n\nRecord *Record::getValueAsDef(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a def initializer!\");\n}\n\nRecord *Record::getValueAsOptionalDef(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  if (isa<UnsetInit>(R->getValue()))\n    return nullptr;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have either a def initializer or '?'!\");\n}\n\n\nbool Record::getValueAsBit(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nbool Record::getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName.str() + \"'!\\n\");\n\n  if (isa<UnsetInit>(R->getValue())) {\n    Unset = true;\n    return false;\n  }\n  Unset = false;\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nDagInit *Record::getValueAsDag(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DagInit *DI = dyn_cast<DagInit>(R->getValue()))\n    return DI;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a dag initializer!\");\n}\n\n// Check all record assertions: For each one, resolve the condition\n// and message, then call CheckAssert().\n// Note: The condition and message are probably already resolved,\n//       but resolving again allows calls before records are resolved.\nvoid Record::checkRecordAssertions() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Assertion : getAssertions()) {\n    Init *Condition = Assertion.Condition->resolveReferences(R);\n    Init *Message = Assertion.Message->resolveReferences(R);\n    CheckAssert(Assertion.Loc, Condition, Message);\n  }\n}\n\nvoid Record::emitRecordDumps() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Dump : getDumps()) {\n    Init *Message = Dump.Message->resolveReferences(R);\n    dumpMessage(Dump.Loc, Message);\n  }\n}\n\n// Report a warning if the record has unused template arguments.\nvoid Record::checkUnusedTemplateArgs() {\n  for (const Init *TA : getTemplateArgs()) {\n    const RecordVal *Arg = getValue(TA);\n    if (!Arg->isUsed())\n      PrintWarning(Arg->getLoc(),\n                   \"unused template argument: \" + Twine(Arg->getName()));\n  }\n}\n\nRecordKeeper::RecordKeeper()\n    : Impl(std::make_unique<detail::RecordKeeperImpl>(*this)) {}\nRecordKeeper::~RecordKeeper() = default;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\nLLVM_DUMP_METHOD void RecordKeeper::dump() const { errs() << *this; }\n#endif\n\nraw_ostream &llvm::operator<<(raw_ostream &OS, const RecordKeeper &RK) {\n  OS << \"------------- Classes -----------------\\n\";\n  for (const auto &C : RK.getClasses())\n    OS << \"class \" << *C.second;\n\n  OS << \"------------- Defs -----------------\\n\";\n  for (const auto &D : RK.getDefs())\n    OS << \"def \" << *D.second;\n  return OS;\n}\n\n/// GetNewAnonymousName - Generate a unique anonymous name that can be used as\n/// an identifier.\nInit *RecordKeeper::getNewAnonymousName() {\n  return AnonymousNameInit::get(*this, getImpl().AnonCounter++);\n}\n\n// These functions implement the phase timing facility. Starting a timer\n// when one is already running stops the running one.\n\nvoid RecordKeeper::startTimer(StringRef Name) {\n  if (TimingGroup) {\n    if (LastTimer && LastTimer->isRunning()) {\n      LastTimer->stopTimer();\n      if (BackendTimer) {\n        LastTimer->clear();\n        BackendTimer = false;\n      }\n    }\n\n    LastTimer = new Timer(\"\", Name, *TimingGroup);\n    LastTimer->startTimer();\n  }\n}\n\nvoid RecordKeeper::stopTimer() {\n  if (TimingGroup) {\n    assert(LastTimer && \"No phase timer was started\");\n    LastTimer->stopTimer();\n  }\n}\n\nvoid RecordKeeper::startBackendTimer(StringRef Name) {\n  if (TimingGroup) {\n    startTimer(Name);\n    BackendTimer = true;\n  }\n}\n\nvoid RecordKeeper::stopBackendTimer() {\n  if (TimingGroup) {\n    if (BackendTimer) {\n      stopTimer();\n      BackendTimer = false;\n    }\n  }\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitions(StringRef ClassName) const {\n  // We cache the record vectors for single classes. Many backends request\n  // the same vectors multiple times.\n  auto Pair = ClassRecordsMap.try_emplace(ClassName);\n  if (Pair.second)\n    Pair.first->second = getAllDerivedDefinitions(ArrayRef(ClassName));\n\n  return Pair.first->second;\n}\n\nstd::vector<Record *> RecordKeeper::getAllDerivedDefinitions(\n    ArrayRef<StringRef> ClassNames) const {\n  SmallVector<Record *, 2> ClassRecs;\n  std::vector<Record *> Defs;\n\n  assert(ClassNames.size() > 0 && \"At least one class must be passed.\");\n  for (const auto &ClassName : ClassNames) {\n    Record *Class = getClass(ClassName);\n    if (!Class)\n      PrintFatalError(\"The class '\" + ClassName + \"' is not defined\\n\");\n    ClassRecs.push_back(Class);\n  }\n\n  for (const auto &OneDef : getDefs()) {\n    if (all_of(ClassRecs, [&OneDef](const Record *Class) {\n                            return OneDef.second->isSubClassOf(Class);\n                          }))\n      Defs.push_back(OneDef.second.get());\n  }\n\n  llvm::sort(Defs, [](Record *LHS, Record *RHS) {\n    return LHS->getName().compare_numeric(RHS->getName()) < 0;\n  });\n\n  return Defs;\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitionsIfDefined(StringRef ClassName) const {\n  return getClass(ClassName) ? getAllDerivedDefinitions(ClassName)\n                             : std::vector<Record *>();\n}\n\nInit *MapResolver::resolve(Init *VarName) {\n  auto It = Map.find(VarName);\n  if (It == Map.end())\n    return nullptr;\n\n  Init *I = It->second.V;\n\n  if (!It->second.Resolved && Map.size() > 1) {\n    // Resolve mutual references among the mapped variables, but prevent\n    // infinite recursion.\n    Map.erase(It);\n    I = I->resolveReferences(*this);\n    Map[VarName] = {I, true};\n  }\n\n  return I;\n}\n\nInit *RecordResolver::resolve(Init *VarName) {\n  Init *Val = Cache.lookup(VarName);\n  if (Val)\n    return Val;\n\n  if (llvm::is_contained(Stack, VarName))\n    return nullptr; // prevent infinite recursion\n\n  if (RecordVal *RV = getCurrentRecord()->getValue(VarName)) {\n    if (!isa<UnsetInit>(RV->getValue())) {\n      Val = RV->getValue();\n      Stack.push_back(VarName);\n      Val = Val->resolveReferences(*this);\n      Stack.pop_back();\n    }\n  } else if (Name && VarName == getCurrentRecord()->getNameInit()) {\n    Stack.push_back(VarName);\n    Val = Name->resolveReferences(*this);\n    Stack.pop_back();\n  }\n\n  Cache[VarName] = Val;\n  return Val;\n}\n\nInit *TrackUnresolvedResolver::resolve(Init *VarName) {\n  Init *I = nullptr;\n\n  if (R) {\n    I = R->resolve(VarName);\n    if (I && !FoundUnresolved) {\n      // Do not recurse into the resolved initializer, as that would change\n      // the behavior of the resolver we're delegating, but do check to see\n      // if there are unresolved variables remaining.\n      TrackUnresolvedResolver Sub;\n      I->resolveReferences(Sub);\n      FoundUnresolved |= Sub.FoundUnresolved;\n    }\n  }\n\n  if (!I)\n    FoundUnresolved = true;\n  return I;\n}\n\nInit *HasReferenceResolver::resolve(Init *VarName)\n{\n  if (VarName == VarNameToTrack)\n    Found = true;\n  return nullptr;\n}\n"}, {"id": "139F4BCC4CBD1341", "name": "llvm::parseSDPatternOperatorProperties", "path": "llvm-project/llvm/utils/TableGen/SDNodeProperties.cpp", "start": {"line": 16, "col": 1}, "end": {"line": 40, "col": 1}, "code": "  unsigned Properties = 0;\n  for (Record *Property : R->getValueAsListOfDefs(\"Properties\")) {\n    auto Offset = StringSwitch<unsigned>(Property->getName())\n                      .Case(\"SDNPCommutative\", SDNPCommutative)\n                      .Case(\"SDNPAssociative\", SDNPAssociative)\n                      .Case(\"SDNPHasChain\", SDNPHasChain)\n                      .Case(\"SDNPOutGlue\", SDNPOutGlue)\n                      .Case(\"SDNPInGlue\", SDNPInGlue)\n                      .Case(\"SDNPOptInGlue\", SDNPOptInGlue)\n                      .Case(\"SDNPMayStore\", SDNPMayStore)\n                      .Case(\"SDNPMayLoad\", SDNPMayLoad)\n                      .Case(\"SDNPSideEffect\", SDNPSideEffect)\n                      .Case(\"SDNPMemOperand\", SDNPMemOperand)\n                      .Case(\"SDNPVariadic\", SDNPVariadic)\n                      .Default(-1u);\n    if (Offset != -1u)\n      Properties |= 1 << Offset;\n    else\n      PrintFatalError(R->getLoc(), \"Unknown SD Node property '\" +\n                                       Property->getName() + \"' on node '\" +\n                                       R->getName() + \"'!\");\n  }\n  return Properties;\n}\n"}, {"id": "0DDC792993C141DF", "name": "llvm::Record::getValueAsListOfDefs", "path": "llvm-project/llvm/lib/TableGen/Record.cpp", "start": {"line": 2994, "col": 1}, "end": {"line": 3006, "col": 1}, "code": "Record::getValueAsListOfDefs(StringRef FieldName) const {\n  ListInit *List = getValueAsListInit(FieldName);\n  std::vector<Record*> Defs;\n  for (Init *I : List->getValues()) {\n    if (DefInit *DI = dyn_cast<DefInit>(I))\n      Defs.push_back(DI->getDef());\n    else\n      PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n        FieldName + \"' list is not entirely DefInit!\");\n  }\n  return Defs;\n}\n\nint64_t Record::getValueAsInt(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (IntInit *II = dyn_cast<IntInit>(R->getValue()))\n    return II->getValue();\n  PrintFatalError(getLoc(), Twine(\"Record `\") + getName() + \"', field `\" +\n                                FieldName +\n                                \"' exists but does not have an int value: \" +\n                                R->getValue()->getAsString());\n}\n\nstd::vector<int64_t>\nRecord::getValueAsListOfInts(StringRef FieldName) const {\n  ListInit *List = getValueAsListInit(FieldName);\n  std::vector<int64_t> Ints;\n  for (Init *I : List->getValues()) {\n    if (IntInit *II = dyn_cast<IntInit>(I))\n      Ints.push_back(II->getValue());\n    else\n      PrintFatalError(getLoc(),\n                      Twine(\"Record `\") + getName() + \"', field `\" + FieldName +\n                          \"' exists but does not have a list of ints value: \" +\n                          I->getAsString());\n  }\n  return Ints;\n}\n\nstd::vector<StringRef>\nRecord::getValueAsListOfStrings(StringRef FieldName) const {\n  ListInit *List = getValueAsListInit(FieldName);\n  std::vector<StringRef> Strings;\n  for (Init *I : List->getValues()) {\n    if (StringInit *SI = dyn_cast<StringInit>(I))\n      Strings.push_back(SI->getValue());\n    else\n      PrintFatalError(getLoc(),\n                      Twine(\"Record `\") + getName() + \"', field `\" + FieldName +\n                          \"' exists but does not have a list of strings value: \" +\n                          I->getAsString());\n  }\n  return Strings;\n}\n\nRecord *Record::getValueAsDef(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a def initializer!\");\n}\n\nRecord *Record::getValueAsOptionalDef(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  if (isa<UnsetInit>(R->getValue()))\n    return nullptr;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have either a def initializer or '?'!\");\n}\n\n\nbool Record::getValueAsBit(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nbool Record::getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName.str() + \"'!\\n\");\n\n  if (isa<UnsetInit>(R->getValue())) {\n    Unset = true;\n    return false;\n  }\n  Unset = false;\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nDagInit *Record::getValueAsDag(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DagInit *DI = dyn_cast<DagInit>(R->getValue()))\n    return DI;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a dag initializer!\");\n}\n\n// Check all record assertions: For each one, resolve the condition\n// and message, then call CheckAssert().\n// Note: The condition and message are probably already resolved,\n//       but resolving again allows calls before records are resolved.\nvoid Record::checkRecordAssertions() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Assertion : getAssertions()) {\n    Init *Condition = Assertion.Condition->resolveReferences(R);\n    Init *Message = Assertion.Message->resolveReferences(R);\n    CheckAssert(Assertion.Loc, Condition, Message);\n  }\n}\n\nvoid Record::emitRecordDumps() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Dump : getDumps()) {\n    Init *Message = Dump.Message->resolveReferences(R);\n    dumpMessage(Dump.Loc, Message);\n  }\n}\n\n// Report a warning if the record has unused template arguments.\nvoid Record::checkUnusedTemplateArgs() {\n  for (const Init *TA : getTemplateArgs()) {\n    const RecordVal *Arg = getValue(TA);\n    if (!Arg->isUsed())\n      PrintWarning(Arg->getLoc(),\n                   \"unused template argument: \" + Twine(Arg->getName()));\n  }\n}\n\nRecordKeeper::RecordKeeper()\n    : Impl(std::make_unique<detail::RecordKeeperImpl>(*this)) {}\nRecordKeeper::~RecordKeeper() = default;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\nLLVM_DUMP_METHOD void RecordKeeper::dump() const { errs() << *this; }\n#endif\n\nraw_ostream &llvm::operator<<(raw_ostream &OS, const RecordKeeper &RK) {\n  OS << \"------------- Classes -----------------\\n\";\n  for (const auto &C : RK.getClasses())\n    OS << \"class \" << *C.second;\n\n  OS << \"------------- Defs -----------------\\n\";\n  for (const auto &D : RK.getDefs())\n    OS << \"def \" << *D.second;\n  return OS;\n}\n\n/// GetNewAnonymousName - Generate a unique anonymous name that can be used as\n/// an identifier.\nInit *RecordKeeper::getNewAnonymousName() {\n  return AnonymousNameInit::get(*this, getImpl().AnonCounter++);\n}\n\n// These functions implement the phase timing facility. Starting a timer\n// when one is already running stops the running one.\n\nvoid RecordKeeper::startTimer(StringRef Name) {\n  if (TimingGroup) {\n    if (LastTimer && LastTimer->isRunning()) {\n      LastTimer->stopTimer();\n      if (BackendTimer) {\n        LastTimer->clear();\n        BackendTimer = false;\n      }\n    }\n\n    LastTimer = new Timer(\"\", Name, *TimingGroup);\n    LastTimer->startTimer();\n  }\n}\n\nvoid RecordKeeper::stopTimer() {\n  if (TimingGroup) {\n    assert(LastTimer && \"No phase timer was started\");\n    LastTimer->stopTimer();\n  }\n}\n\nvoid RecordKeeper::startBackendTimer(StringRef Name) {\n  if (TimingGroup) {\n    startTimer(Name);\n    BackendTimer = true;\n  }\n}\n\nvoid RecordKeeper::stopBackendTimer() {\n  if (TimingGroup) {\n    if (BackendTimer) {\n      stopTimer();\n      BackendTimer = false;\n    }\n  }\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitions(StringRef ClassName) const {\n  // We cache the record vectors for single classes. Many backends request\n  // the same vectors multiple times.\n  auto Pair = ClassRecordsMap.try_emplace(ClassName);\n  if (Pair.second)\n    Pair.first->second = getAllDerivedDefinitions(ArrayRef(ClassName));\n\n  return Pair.first->second;\n}\n\nstd::vector<Record *> RecordKeeper::getAllDerivedDefinitions(\n    ArrayRef<StringRef> ClassNames) const {\n  SmallVector<Record *, 2> ClassRecs;\n  std::vector<Record *> Defs;\n\n  assert(ClassNames.size() > 0 && \"At least one class must be passed.\");\n  for (const auto &ClassName : ClassNames) {\n    Record *Class = getClass(ClassName);\n    if (!Class)\n      PrintFatalError(\"The class '\" + ClassName + \"' is not defined\\n\");\n    ClassRecs.push_back(Class);\n  }\n\n  for (const auto &OneDef : getDefs()) {\n    if (all_of(ClassRecs, [&OneDef](const Record *Class) {\n                            return OneDef.second->isSubClassOf(Class);\n                          }))\n      Defs.push_back(OneDef.second.get());\n  }\n\n  llvm::sort(Defs, [](Record *LHS, Record *RHS) {\n    return LHS->getName().compare_numeric(RHS->getName()) < 0;\n  });\n\n  return Defs;\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitionsIfDefined(StringRef ClassName) const {\n  return getClass(ClassName) ? getAllDerivedDefinitions(ClassName)\n                             : std::vector<Record *>();\n}\n\nInit *MapResolver::resolve(Init *VarName) {\n  auto It = Map.find(VarName);\n  if (It == Map.end())\n    return nullptr;\n\n  Init *I = It->second.V;\n\n  if (!It->second.Resolved && Map.size() > 1) {\n    // Resolve mutual references among the mapped variables, but prevent\n    // infinite recursion.\n    Map.erase(It);\n    I = I->resolveReferences(*this);\n    Map[VarName] = {I, true};\n  }\n\n  return I;\n}\n\nInit *RecordResolver::resolve(Init *VarName) {\n  Init *Val = Cache.lookup(VarName);\n  if (Val)\n    return Val;\n\n  if (llvm::is_contained(Stack, VarName))\n    return nullptr; // prevent infinite recursion\n\n  if (RecordVal *RV = getCurrentRecord()->getValue(VarName)) {\n    if (!isa<UnsetInit>(RV->getValue())) {\n      Val = RV->getValue();\n      Stack.push_back(VarName);\n      Val = Val->resolveReferences(*this);\n      Stack.pop_back();\n    }\n  } else if (Name && VarName == getCurrentRecord()->getNameInit()) {\n    Stack.push_back(VarName);\n    Val = Name->resolveReferences(*this);\n    Stack.pop_back();\n  }\n\n  Cache[VarName] = Val;\n  return Val;\n}\n\nInit *TrackUnresolvedResolver::resolve(Init *VarName) {\n  Init *I = nullptr;\n\n  if (R) {\n    I = R->resolve(VarName);\n    if (I && !FoundUnresolved) {\n      // Do not recurse into the resolved initializer, as that would change\n      // the behavior of the resolver we're delegating, but do check to see\n      // if there are unresolved variables remaining.\n      TrackUnresolvedResolver Sub;\n      I->resolveReferences(Sub);\n      FoundUnresolved |= Sub.FoundUnresolved;\n    }\n  }\n\n  if (!I)\n    FoundUnresolved = true;\n  return I;\n}\n\nInit *HasReferenceResolver::resolve(Init *VarName)\n{\n  if (VarName == VarNameToTrack)\n    Found = true;\n  return nullptr;\n}\n"}], "code": "SDNodeInfo::SDNodeInfo(Record *R, const CodeGenHwModes &CGH) : Def(R) {\n  EnumName = R->getValueAsString(\"Opcode\");\n  SDClassName = R->getValueAsString(\"SDClass\");\n  Record *TypeProfile = R->getValueAsDef(\"TypeProfile\");\n  NumResults = TypeProfile->getValueAsInt(\"NumResults\");\n  NumOperands = TypeProfile->getValueAsInt(\"NumOperands\");\n\n  // Parse the properties.\n  Properties = parseSDPatternOperatorProperties(R);\n\n  // Parse the type constraints.\n  std::vector<Record *> ConstraintList =\n      TypeProfile->getValueAsListOfDefs(\"Constraints\");\n  for (Record *R : ConstraintList)\n    TypeConstraints.emplace_back(R, CGH);\n}\n"}, "4C1DC2D4407A506B": {"calls": [{"id": "86E09B01B1212ECF", "name": "llvm::PrintFatalError", "path": "llvm-project/llvm/lib/TableGen/Error.cpp", "start": {"line": 132, "col": 1}, "end": {"line": 137, "col": 1}, "code": "  PrintError(ErrorLoc, Msg);\n  // The following call runs the file cleanup handlers.\n  sys::RunInterruptHandlers();\n  std::exit(1);\n}\n\n// This method takes a Record and uses the source location\n// stored in it.\nvoid PrintFatalError(const Record *Rec, const Twine &Msg) {\n  PrintError(Rec->getLoc(), Msg);\n  // The following call runs the file cleanup handlers.\n  sys::RunInterruptHandlers();\n  std::exit(1);\n}\n\n// This method takes a RecordVal and uses the source location\n// stored in it.\nvoid PrintFatalError(const RecordVal *RecVal, const Twine &Msg) {\n  PrintError(RecVal->getLoc(), Msg);\n  // The following call runs the file cleanup handlers.\n  sys::RunInterruptHandlers();\n  std::exit(1);\n}\n\n// Check an assertion: Obtain the condition value and be sure it is true.\n// If not, print a nonfatal error along with the message.\nvoid CheckAssert(SMLoc Loc, Init *Condition, Init *Message) {\n  auto *CondValue = dyn_cast_or_null<IntInit>(Condition->convertInitializerTo(\n      IntRecTy::get(Condition->getRecordKeeper())));\n  if (!CondValue)\n    PrintError(Loc, \"assert condition must of type bit, bits, or int.\");\n  else if (!CondValue->getValue()) {\n    PrintError(Loc, \"assertion failed\");\n    if (auto *MessageInit = dyn_cast<StringInit>(Message))\n      PrintNote(MessageInit->getValue());\n    else\n      PrintNote(\"(assert message is not a string)\");\n  }\n}\n\n// Dump a message to stderr.\nvoid dumpMessage(SMLoc Loc, Init *Message) {\n  auto *MessageInit = dyn_cast<StringInit>(Message);\n  assert(MessageInit && \"no debug message to print\");\n  PrintNote(Loc, MessageInit->getValue());\n}\n\n} // end namespace llvm\n"}, {"id": "E81CB1DE1A69E0C1", "name": "llvm::Record::getLoc", "path": "llvm-project/llvm/include/llvm/TableGen/Record.h", "start": {"line": 1723, "col": 3}, "end": {"line": 1723, "col": 49}, "code": "  void appendLoc(SMLoc Loc) { Locs.push_back(Loc); }\n\n  ArrayRef<SMLoc> getForwardDeclarationLocs() const {\n    return ForwardDeclarationLocs;\n  }\n\n  /// Add a reference to this record value.\n  void appendReferenceLoc(SMRange Loc) { ReferenceLocs.push_back(Loc); }\n\n  /// Return the references of this record value.\n  ArrayRef<SMRange> getReferenceLocs() const { return ReferenceLocs; }\n\n  // Update a class location when encountering a (re-)definition.\n  void updateClassLoc(SMLoc Loc);\n\n  // Make the type that this record should have based on its superclasses.\n  RecordRecTy *getType();\n\n  /// get the corresponding DefInit.\n  DefInit *getDefInit();\n\n  bool isClass() const { return Kind == RK_Class; }\n\n  bool isMultiClass() const { return Kind == RK_MultiClass; }\n\n  bool isAnonymous() const { return Kind == RK_AnonymousDef; }\n\n  ArrayRef<Init *> getTemplateArgs() const {\n    return TemplateArgs;\n  }\n\n  ArrayRef<RecordVal> getValues() const { return Values; }\n\n  ArrayRef<AssertionInfo> getAssertions() const { return Assertions; }\n  ArrayRef<DumpInfo> getDumps() const { return Dumps; }\n\n  ArrayRef<std::pair<Record *, SMRange>>  getSuperClasses() const {\n    return SuperClasses;\n  }\n\n  /// Determine whether this record has the specified direct superclass.\n  bool hasDirectSuperClass(const Record *SuperClass) const;\n\n  /// Append the direct superclasses of this record to Classes.\n  void getDirectSuperClasses(SmallVectorImpl<Record *> &Classes) const;\n\n  bool isTemplateArg(Init *Name) const {\n    return llvm::is_contained(TemplateArgs, Name);\n  }\n\n  const RecordVal *getValue(const Init *Name) const {\n    for (const RecordVal &Val : Values)\n      if (Val.Name == Name) return &Val;\n    return nullptr;\n  }\n\n  const RecordVal *getValue(StringRef Name) const {\n    return getValue(StringInit::get(getRecords(), Name));\n  }\n\n  RecordVal *getValue(const Init *Name) {\n    return const_cast<RecordVal *>(static_cast<const Record *>(this)->getValue(Name));\n  }\n\n  RecordVal *getValue(StringRef Name) {\n    return const_cast<RecordVal *>(static_cast<const Record *>(this)->getValue(Name));\n  }\n\n  void addTemplateArg(Init *Name) {\n    assert(!isTemplateArg(Name) && \"Template arg already defined!\");\n    TemplateArgs.push_back(Name);\n  }\n\n  void addValue(const RecordVal &RV) {\n    assert(getValue(RV.getNameInit()) == nullptr && \"Value already added!\");\n    Values.push_back(RV);\n  }\n\n  void removeValue(Init *Name) {\n    for (unsigned i = 0, e = Values.size(); i != e; ++i)\n      if (Values[i].getNameInit() == Name) {\n        Values.erase(Values.begin()+i);\n        return;\n      }\n    llvm_unreachable(\"Cannot remove an entry that does not exist!\");\n  }\n\n  void removeValue(StringRef Name) {\n    removeValue(StringInit::get(getRecords(), Name));\n  }\n\n  void addAssertion(SMLoc Loc, Init *Condition, Init *Message) {\n    Assertions.push_back(AssertionInfo(Loc, Condition, Message));\n  }\n\n  void addDump(SMLoc Loc, Init *Message) {\n    Dumps.push_back(DumpInfo(Loc, Message));\n  }\n\n  void appendAssertions(const Record *Rec) {\n    Assertions.append(Rec->Assertions);\n  }\n\n  void appendDumps(const Record *Rec) { Dumps.append(Rec->Dumps); }\n\n  void checkRecordAssertions();\n  void emitRecordDumps();\n  void checkUnusedTemplateArgs();\n\n  bool isSubClassOf(const Record *R) const {\n    for (const auto &SCPair : SuperClasses)\n      if (SCPair.first == R)\n        return true;\n    return false;\n  }\n\n  bool isSubClassOf(StringRef Name) const {\n    for (const auto &SCPair : SuperClasses) {\n      if (const auto *SI = dyn_cast<StringInit>(SCPair.first->getNameInit())) {\n        if (SI->getValue() == Name)\n          return true;\n      } else if (SCPair.first->getNameInitAsString() == Name) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  void addSuperClass(Record *R, SMRange Range) {\n    assert(!CorrespondingDefInit &&\n           \"changing type of record after it has been referenced\");\n    assert(!isSubClassOf(R) && \"Already subclassing record!\");\n    SuperClasses.push_back(std::make_pair(R, Range));\n  }\n\n  /// If there are any field references that refer to fields that have been\n  /// filled in, we can propagate the values now.\n  ///\n  /// This is a final resolve: any error messages, e.g. due to undefined !cast\n  /// references, are generated now.\n  void resolveReferences(Init *NewName = nullptr);\n\n  /// Apply the resolver to the name of the record as well as to the\n  /// initializers of all fields of the record except SkipVal.\n  ///\n  /// The resolver should not resolve any of the fields itself, to avoid\n  /// recursion / infinite loops.\n  void resolveReferences(Resolver &R, const RecordVal *SkipVal = nullptr);\n\n  RecordKeeper &getRecords() const {\n    return TrackedRecords;\n  }\n\n  void dump() const;\n\n  //===--------------------------------------------------------------------===//\n  // High-level methods useful to tablegen back-ends\n  //\n\n  /// Return the source location for the named field.\n  SMLoc getFieldLoc(StringRef FieldName) const;\n\n  /// Return the initializer for a value with the specified name, or throw an\n  /// exception if the field does not exist.\n  Init *getValueInit(StringRef FieldName) const;\n\n  /// Return true if the named field is unset.\n  bool isValueUnset(StringRef FieldName) const {\n    return isa<UnsetInit>(getValueInit(FieldName));\n  }\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the field does not exist or if the value\n  /// is not a string.\n  StringRef getValueAsString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the value is not a string and\n  /// std::nullopt if the field does not exist.\n  std::optional<StringRef> getValueAsOptionalString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// BitsInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  BitsInit *getValueAsBitsInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// ListInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  ListInit *getValueAsListInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of records, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<Record*> getValueAsListOfDefs(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of integers, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<int64_t> getValueAsListOfInts(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of strings, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<StringRef> getValueAsListOfStrings(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, throwing an exception if the field does not exist or if the value\n  /// is not the right type.\n  Record *getValueAsDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, returning null if the field exists but is \"uninitialized\" (i.e.\n  /// set to `?`), and throwing an exception if the field does not exist or if\n  /// its value is not the right type.\n  Record *getValueAsOptionalDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  bool getValueAsBit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit.\n  /// If the field is unset, sets Unset to true and returns false.\n  bool getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const;\n\n  /// This method looks up the specified field and returns its value as an\n  /// int64_t, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  int64_t getValueAsInt(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as an Dag,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  DagInit *getValueAsDag(StringRef FieldName) const;\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const Record &R);\n\nclass RecordKeeper {\n  using RecordMap = std::map<std::string, std::unique_ptr<Record>, std::less<>>;\n  using GlobalMap = std::map<std::string, Init *, std::less<>>;\n\npublic:\n  RecordKeeper();\n  ~RecordKeeper();\n\n  /// Return the internal implementation of the RecordKeeper.\n  detail::RecordKeeperImpl &getImpl() { return *Impl; }\n\n  /// Get the main TableGen input file's name.\n  const std::string getInputFilename() const { return InputFilename; }\n\n  /// Get the map of classes.\n  const RecordMap &getClasses() const { return Classes; }\n\n  /// Get the map of records (defs).\n  const RecordMap &getDefs() const { return Defs; }\n\n  /// Get the map of global variables.\n  const GlobalMap &getGlobals() const { return ExtraGlobals; }\n\n  /// Get the class with the specified name.\n  Record *getClass(StringRef Name) const {\n    auto I = Classes.find(Name);\n    return I == Classes.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the concrete record with the specified name.\n  Record *getDef(StringRef Name) const {\n    auto I = Defs.find(Name);\n    return I == Defs.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the \\p Init value of the specified global variable.\n  Init *getGlobal(StringRef Name) const {\n    if (Record *R = getDef(Name))\n      return R->getDefInit();\n    auto It = ExtraGlobals.find(Name);\n    return It == ExtraGlobals.end() ? nullptr : It->second;\n  }\n\n  void saveInputFilename(std::string Filename) {\n    InputFilename = Filename;\n  }\n\n  void addClass(std::unique_ptr<Record> R) {\n    bool Ins = Classes.insert(std::make_pair(std::string(R->getName()),\n                                             std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Class already exists\");\n  }\n\n  void addDef(std::unique_ptr<Record> R) {\n    bool Ins = Defs.insert(std::make_pair(std::string(R->getName()),\n                                          std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Record already exists\");\n  }\n\n  void addExtraGlobal(StringRef Name, Init *I) {\n    bool Ins = ExtraGlobals.insert(std::make_pair(std::string(Name), I)).second;\n    (void)Ins;\n    assert(!getDef(Name));\n    assert(Ins && \"Global already exists\");\n  }\n\n  Init *getNewAnonymousName();\n\n  /// Start phase timing; called if the --time-phases option is specified.\n  void startPhaseTiming() {\n    TimingGroup = new TimerGroup(\"TableGen\", \"TableGen Phase Timing\");\n  }\n\n  /// Start timing a phase. Automatically stops any previous phase timer.\n  void startTimer(StringRef Name);\n\n  /// Stop timing a phase.\n  void stopTimer();\n\n  /// Start timing the overall backend. If the backend itself starts a timer,\n  /// then this timer is cleared.\n  void startBackendTimer(StringRef Name);\n\n  /// Stop timing the overall backend.\n  void stopBackendTimer();\n\n  /// Stop phase timing and print the report.\n  void stopPhaseTiming() {\n    if (TimingGroup)\n      delete TimingGroup;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // High-level helper methods, useful for tablegen backends.\n\n  /// Get all the concrete records that inherit from the one specified\n  /// class. The class must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(StringRef ClassName) const;\n\n  /// Get all the concrete records that inherit from all the specified\n  /// classes. The classes must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(\n      ArrayRef<StringRef> ClassNames) const;\n\n  /// Get all the concrete records that inherit from specified class, if the\n  /// class is defined. Returns an empty vector if the class is not defined.\n  std::vector<Record *>\n  getAllDerivedDefinitionsIfDefined(StringRef ClassName) const;\n\n  void dump() const;\n\nprivate:\n  RecordKeeper(RecordKeeper &&) = delete;\n  RecordKeeper(const RecordKeeper &) = delete;\n  RecordKeeper &operator=(RecordKeeper &&) = delete;\n  RecordKeeper &operator=(const RecordKeeper &) = delete;\n\n  std::string InputFilename;\n  RecordMap Classes, Defs;\n  mutable StringMap<std::vector<Record *>> ClassRecordsMap;\n  GlobalMap ExtraGlobals;\n\n  // These members are for the phase timing feature. We need a timer group,\n  // the last timer started, and a flag to say whether the last timer\n  // is the special \"backend overall timer.\"\n  TimerGroup *TimingGroup = nullptr;\n  Timer *LastTimer = nullptr;\n  bool BackendTimer = false;\n\n  /// The internal uniquer implementation of the RecordKeeper.\n  std::unique_ptr<detail::RecordKeeperImpl> Impl;\n};\n\n/// Sorting predicate to sort record pointers by name.\nstruct LessRecord {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return StringRef(Rec1->getName()).compare_numeric(Rec2->getName()) < 0;\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// unique ID. If you just need a deterministic order, use this, since it\n/// just compares two `unsigned`; the other sorting predicates require\n/// string manipulation.\nstruct LessRecordByID {\n  bool operator()(const Record *LHS, const Record *RHS) const {\n    return LHS->getID() < RHS->getID();\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// name field.\nstruct LessRecordFieldName {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return Rec1->getValueAsString(\"Name\") < Rec2->getValueAsString(\"Name\");\n  }\n};\n\nstruct LessRecordRegister {\n  struct RecordParts {\n    SmallVector<std::pair< bool, StringRef>, 4> Parts;\n\n    RecordParts(StringRef Rec) {\n      if (Rec.empty())\n        return;\n\n      size_t Len = 0;\n      const char *Start = Rec.data();\n      const char *Curr = Start;\n      bool IsDigitPart = isDigit(Curr[0]);\n      for (size_t I = 0, E = Rec.size(); I != E; ++I, ++Len) {\n        bool IsDigit = isDigit(Curr[I]);\n        if (IsDigit != IsDigitPart) {\n          Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n          Len = 0;\n          Start = &Curr[I];\n          IsDigitPart = isDigit(Curr[I]);\n        }\n      }\n      // Push the last part.\n      Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n    }\n\n    size_t size() { return Parts.size(); }\n\n    std::pair<bool, StringRef> getPart(size_t i) {\n      assert (i < Parts.size() && \"Invalid idx!\");\n      return Parts[i];\n    }\n  };\n\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    int64_t LHSPositionOrder = Rec1->getValueAsInt(\"PositionOrder\");\n    int64_t RHSPositionOrder = Rec2->getValueAsInt(\"PositionOrder\");\n    if (LHSPositionOrder != RHSPositionOrder)\n      return LHSPositionOrder < RHSPositionOrder;\n\n    RecordParts LHSParts(StringRef(Rec1->getName()));\n    RecordParts RHSParts(StringRef(Rec2->getName()));\n\n    size_t LHSNumParts = LHSParts.size();\n    size_t RHSNumParts = RHSParts.size();\n    assert (LHSNumParts && RHSNumParts && \"Expected at least one part!\");\n\n    if (LHSNumParts != RHSNumParts)\n      return LHSNumParts < RHSNumParts;\n\n    // We expect the registers to be of the form [_a-zA-Z]+([0-9]*[_a-zA-Z]*)*.\n    for (size_t I = 0, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect even part to always be alpha.\n      assert (LHSPart.first == false && RHSPart.first == false &&\n              \"Expected both parts to be alpha.\");\n      if (int Res = LHSPart.second.compare(RHSPart.second))\n        return Res < 0;\n    }\n    for (size_t I = 1, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect odd part to always be numeric.\n      assert (LHSPart.first == true && RHSPart.first == true &&\n              \"Expected both parts to be numeric.\");\n      if (LHSPart.second.size() != RHSPart.second.size())\n        return LHSPart.second.size() < RHSPart.second.size();\n\n      unsigned LHSVal, RHSVal;\n\n      bool LHSFailed = LHSPart.second.getAsInteger(10, LHSVal); (void)LHSFailed;\n      assert(!LHSFailed && \"Unable to convert LHS to integer.\");\n      bool RHSFailed = RHSPart.second.getAsInteger(10, RHSVal); (void)RHSFailed;\n      assert(!RHSFailed && \"Unable to convert RHS to integer.\");\n\n      if (LHSVal != RHSVal)\n        return LHSVal < RHSVal;\n    }\n    return LHSNumParts < RHSNumParts;\n  }\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const RecordKeeper &RK);\n\n//===----------------------------------------------------------------------===//\n//  Resolvers\n//===----------------------------------------------------------------------===//\n\n/// Interface for looking up the initializer for a variable name, used by\n/// Init::resolveReferences.\nclass Resolver {\n  Record *CurRec;\n  bool IsFinal = false;\n\npublic:\n  explicit Resolver(Record *CurRec) : CurRec(CurRec) {}\n  virtual ~Resolver() = default;\n\n  Record *getCurrentRecord() const { return CurRec; }\n\n  /// Return the initializer for the given variable name (should normally be a\n  /// StringInit), or nullptr if the name could not be resolved.\n  virtual Init *resolve(Init *VarName) = 0;\n\n  // Whether bits in a BitsInit should stay unresolved if resolving them would\n  // result in a ? (UnsetInit). This behavior is used to represent instruction\n  // encodings by keeping references to unset variables within a record.\n  virtual bool keepUnsetBits() const { return false; }\n\n  // Whether this is the final resolve step before adding a record to the\n  // RecordKeeper. Error reporting during resolve and related constant folding\n  // should only happen when this is true.\n  bool isFinal() const { return IsFinal; }\n\n  void setFinal(bool Final) { IsFinal = Final; }\n};\n\n/// Resolve arbitrary mappings.\nclass MapResolver final : public Resolver {\n  struct MappedValue {\n    Init *V;\n    bool Resolved;\n\n    MappedValue() : V(nullptr), Resolved(false) {}\n    MappedValue(Init *V, bool Resolved) : V(V), Resolved(Resolved) {}\n  };\n\n  DenseMap<Init *, MappedValue> Map;\n\npublic:\n  explicit MapResolver(Record *CurRec = nullptr) : Resolver(CurRec) {}\n\n  void set(Init *Key, Init *Value) { Map[Key] = {Value, false}; }\n\n  bool isComplete(Init *VarName) const {\n    auto It = Map.find(VarName);\n    assert(It != Map.end() && \"key must be present in map\");\n    return It->second.V->isComplete();\n  }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Resolve all variables from a record except for unset variables.\nclass RecordResolver final : public Resolver {\n  DenseMap<Init *, Init *> Cache;\n  SmallVector<Init *, 4> Stack;\n  Init *Name = nullptr;\n\npublic:\n  explicit RecordResolver(Record &R) : Resolver(&R) {}\n\n  void setName(Init *NewName) { Name = NewName; }\n\n  Init *resolve(Init *VarName) override;\n\n  bool keepUnsetBits() const override { return true; }\n};\n\n/// Delegate resolving to a sub-resolver, but shadow some variable names.\nclass ShadowResolver final : public Resolver {\n  Resolver &R;\n  DenseSet<Init *> Shadowed;\n\npublic:\n  explicit ShadowResolver(Resolver &R)\n      : Resolver(R.getCurrentRecord()), R(R) {\n    setFinal(R.isFinal());\n  }\n\n  void addShadow(Init *Key) { Shadowed.insert(Key); }\n\n  Init *resolve(Init *VarName) override {\n    if (Shadowed.count(VarName))\n      return nullptr;\n    return R.resolve(VarName);\n  }\n};\n\n/// (Optionally) delegate resolving to a sub-resolver, and keep track whether\n/// there were unresolved references.\nclass TrackUnresolvedResolver final : public Resolver {\n  Resolver *R;\n  bool FoundUnresolved = false;\n\npublic:\n  explicit TrackUnresolvedResolver(Resolver *R = nullptr)\n      : Resolver(R ? R->getCurrentRecord() : nullptr), R(R) {}\n\n  bool foundUnresolved() const { return FoundUnresolved; }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Do not resolve anything, but keep track of whether a given variable was\n/// referenced.\nclass HasReferenceResolver final : public Resolver {\n  Init *VarNameToTrack;\n  bool Found = false;\n\npublic:\n  explicit HasReferenceResolver(Init *VarNameToTrack)\n      : Resolver(nullptr), VarNameToTrack(VarNameToTrack) {}\n\n  bool found() const { return Found; }\n\n  Init *resolve(Init *VarName) override;\n};\n\nvoid EmitDetailedRecords(RecordKeeper &RK, raw_ostream &OS);\nvoid EmitJSON(RecordKeeper &RK, raw_ostream &OS);\n\n} // end namespace llvm\n\n#endif // LLVM_TABLEGEN_RECORD_H\n"}], "code": "CodeGenRegisterClass *CodeGenRegBank::getRegClass(const Record *Def) const {\n  if (CodeGenRegisterClass *RC = Def2RC.lookup(Def))\n    return RC;\n\n  PrintFatalError(Def->getLoc(), \"Not a known RegisterClass!\");\n}\n"}, "6EF0AC47AE4C4498": {"calls": [{"id": "791D518B7EAC5F5D", "name": "llvm::TreePatternNode::isLeaf", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 687, "col": 3}, "end": {"line": 687, "col": 60}, "code": "\n  // Type accessors.\n  unsigned getNumTypes() const { return Types.size(); }\n  ValueTypeByHwMode getType(unsigned ResNo) const {\n    return Types[ResNo].getValueTypeByHwMode();\n  }\n  const std::vector<TypeSetByHwMode> &getExtTypes() const { return Types; }\n  const TypeSetByHwMode &getExtType(unsigned ResNo) const {\n    return Types[ResNo];\n  }\n  TypeSetByHwMode &getExtType(unsigned ResNo) { return Types[ResNo]; }\n  void setType(unsigned ResNo, const TypeSetByHwMode &T) { Types[ResNo] = T; }\n  MVT::SimpleValueType getSimpleType(unsigned ResNo) const {\n    return Types[ResNo].getMachineValueType().SimpleTy;\n  }\n\n  bool hasConcreteType(unsigned ResNo) const {\n    return Types[ResNo].isValueTypeByHwMode(false);\n  }\n  bool isTypeCompletelyUnknown(unsigned ResNo, TreePattern &TP) const {\n    return Types[ResNo].empty();\n  }\n\n  unsigned getNumResults() const { return ResultPerm.size(); }\n  unsigned getResultIndex(unsigned ResNo) const { return ResultPerm[ResNo]; }\n  void setResultIndex(unsigned ResNo, unsigned RI) { ResultPerm[ResNo] = RI; }\n\n  Init *getLeafValue() const {\n    assert(isLeaf());\n    return cast<Init *>(OperatorOrVal);\n  }\n  Record *getOperator() const {\n    assert(!isLeaf());\n    return cast<Record *>(OperatorOrVal);\n  }\n\n  unsigned getNumChildren() const { return Children.size(); }\n  const TreePatternNode &getChild(unsigned N) const {\n    return *Children[N].get();\n  }\n  TreePatternNode &getChild(unsigned N) { return *Children[N].get(); }\n  const TreePatternNodePtr &getChildShared(unsigned N) const {\n    return Children[N];\n  }\n  TreePatternNodePtr &getChildSharedPtr(unsigned N) { return Children[N]; }\n  void setChild(unsigned i, TreePatternNodePtr N) { Children[i] = N; }\n\n  /// hasChild - Return true if N is any of our children.\n  bool hasChild(const TreePatternNode *N) const {\n    for (unsigned i = 0, e = Children.size(); i != e; ++i)\n      if (Children[i].get() == N)\n        return true;\n    return false;\n  }\n\n  bool hasProperTypeByHwMode() const;\n  bool hasPossibleType() const;\n  bool setDefaultMode(unsigned Mode);\n\n  bool hasAnyPredicate() const { return !PredicateCalls.empty(); }\n\n  const std::vector<TreePredicateCall> &getPredicateCalls() const {\n    return PredicateCalls;\n  }\n  void clearPredicateCalls() { PredicateCalls.clear(); }\n  void setPredicateCalls(const std::vector<TreePredicateCall> &Calls) {\n    assert(PredicateCalls.empty() && \"Overwriting non-empty predicate list!\");\n    PredicateCalls = Calls;\n  }\n  void addPredicateCall(const TreePredicateCall &Call) {\n    assert(!Call.Fn.isAlwaysTrue() && \"Empty predicate string!\");\n    assert(!is_contained(PredicateCalls, Call) &&\n           \"predicate applied recursively\");\n    PredicateCalls.push_back(Call);\n  }\n  void addPredicateCall(const TreePredicateFn &Fn, unsigned Scope) {\n    assert((Scope != 0) == Fn.usesOperands());\n    addPredicateCall(TreePredicateCall(Fn, Scope));\n  }\n\n  Record *getTransformFn() const { return TransformFn; }\n  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "8D724CC5DF1BE249", "name": "llvm::Record::isSubClassOf", "path": "llvm-project/llvm/include/llvm/TableGen/Record.h", "start": {"line": 1840, "col": 3}, "end": {"line": 1850, "col": 3}, "code": "    for (const auto &SCPair : SuperClasses) {\n      if (const auto *SI = dyn_cast<StringInit>(SCPair.first->getNameInit())) {\n        if (SI->getValue() == Name)\n          return true;\n      } else if (SCPair.first->getNameInitAsString() == Name) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  void addSuperClass(Record *R, SMRange Range) {\n    assert(!CorrespondingDefInit &&\n           \"changing type of record after it has been referenced\");\n    assert(!isSubClassOf(R) && \"Already subclassing record!\");\n    SuperClasses.push_back(std::make_pair(R, Range));\n  }\n\n  /// If there are any field references that refer to fields that have been\n  /// filled in, we can propagate the values now.\n  ///\n  /// This is a final resolve: any error messages, e.g. due to undefined !cast\n  /// references, are generated now.\n  void resolveReferences(Init *NewName = nullptr);\n\n  /// Apply the resolver to the name of the record as well as to the\n  /// initializers of all fields of the record except SkipVal.\n  ///\n  /// The resolver should not resolve any of the fields itself, to avoid\n  /// recursion / infinite loops.\n  void resolveReferences(Resolver &R, const RecordVal *SkipVal = nullptr);\n\n  RecordKeeper &getRecords() const {\n    return TrackedRecords;\n  }\n\n  void dump() const;\n\n  //===--------------------------------------------------------------------===//\n  // High-level methods useful to tablegen back-ends\n  //\n\n  /// Return the source location for the named field.\n  SMLoc getFieldLoc(StringRef FieldName) const;\n\n  /// Return the initializer for a value with the specified name, or throw an\n  /// exception if the field does not exist.\n  Init *getValueInit(StringRef FieldName) const;\n\n  /// Return true if the named field is unset.\n  bool isValueUnset(StringRef FieldName) const {\n    return isa<UnsetInit>(getValueInit(FieldName));\n  }\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the field does not exist or if the value\n  /// is not a string.\n  StringRef getValueAsString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the value is not a string and\n  /// std::nullopt if the field does not exist.\n  std::optional<StringRef> getValueAsOptionalString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// BitsInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  BitsInit *getValueAsBitsInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// ListInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  ListInit *getValueAsListInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of records, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<Record*> getValueAsListOfDefs(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of integers, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<int64_t> getValueAsListOfInts(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of strings, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<StringRef> getValueAsListOfStrings(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, throwing an exception if the field does not exist or if the value\n  /// is not the right type.\n  Record *getValueAsDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, returning null if the field exists but is \"uninitialized\" (i.e.\n  /// set to `?`), and throwing an exception if the field does not exist or if\n  /// its value is not the right type.\n  Record *getValueAsOptionalDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  bool getValueAsBit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit.\n  /// If the field is unset, sets Unset to true and returns false.\n  bool getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const;\n\n  /// This method looks up the specified field and returns its value as an\n  /// int64_t, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  int64_t getValueAsInt(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as an Dag,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  DagInit *getValueAsDag(StringRef FieldName) const;\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const Record &R);\n\nclass RecordKeeper {\n  using RecordMap = std::map<std::string, std::unique_ptr<Record>, std::less<>>;\n  using GlobalMap = std::map<std::string, Init *, std::less<>>;\n\npublic:\n  RecordKeeper();\n  ~RecordKeeper();\n\n  /// Return the internal implementation of the RecordKeeper.\n  detail::RecordKeeperImpl &getImpl() { return *Impl; }\n\n  /// Get the main TableGen input file's name.\n  const std::string getInputFilename() const { return InputFilename; }\n\n  /// Get the map of classes.\n  const RecordMap &getClasses() const { return Classes; }\n\n  /// Get the map of records (defs).\n  const RecordMap &getDefs() const { return Defs; }\n\n  /// Get the map of global variables.\n  const GlobalMap &getGlobals() const { return ExtraGlobals; }\n\n  /// Get the class with the specified name.\n  Record *getClass(StringRef Name) const {\n    auto I = Classes.find(Name);\n    return I == Classes.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the concrete record with the specified name.\n  Record *getDef(StringRef Name) const {\n    auto I = Defs.find(Name);\n    return I == Defs.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the \\p Init value of the specified global variable.\n  Init *getGlobal(StringRef Name) const {\n    if (Record *R = getDef(Name))\n      return R->getDefInit();\n    auto It = ExtraGlobals.find(Name);\n    return It == ExtraGlobals.end() ? nullptr : It->second;\n  }\n\n  void saveInputFilename(std::string Filename) {\n    InputFilename = Filename;\n  }\n\n  void addClass(std::unique_ptr<Record> R) {\n    bool Ins = Classes.insert(std::make_pair(std::string(R->getName()),\n                                             std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Class already exists\");\n  }\n\n  void addDef(std::unique_ptr<Record> R) {\n    bool Ins = Defs.insert(std::make_pair(std::string(R->getName()),\n                                          std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Record already exists\");\n  }\n\n  void addExtraGlobal(StringRef Name, Init *I) {\n    bool Ins = ExtraGlobals.insert(std::make_pair(std::string(Name), I)).second;\n    (void)Ins;\n    assert(!getDef(Name));\n    assert(Ins && \"Global already exists\");\n  }\n\n  Init *getNewAnonymousName();\n\n  /// Start phase timing; called if the --time-phases option is specified.\n  void startPhaseTiming() {\n    TimingGroup = new TimerGroup(\"TableGen\", \"TableGen Phase Timing\");\n  }\n\n  /// Start timing a phase. Automatically stops any previous phase timer.\n  void startTimer(StringRef Name);\n\n  /// Stop timing a phase.\n  void stopTimer();\n\n  /// Start timing the overall backend. If the backend itself starts a timer,\n  /// then this timer is cleared.\n  void startBackendTimer(StringRef Name);\n\n  /// Stop timing the overall backend.\n  void stopBackendTimer();\n\n  /// Stop phase timing and print the report.\n  void stopPhaseTiming() {\n    if (TimingGroup)\n      delete TimingGroup;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // High-level helper methods, useful for tablegen backends.\n\n  /// Get all the concrete records that inherit from the one specified\n  /// class. The class must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(StringRef ClassName) const;\n\n  /// Get all the concrete records that inherit from all the specified\n  /// classes. The classes must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(\n      ArrayRef<StringRef> ClassNames) const;\n\n  /// Get all the concrete records that inherit from specified class, if the\n  /// class is defined. Returns an empty vector if the class is not defined.\n  std::vector<Record *>\n  getAllDerivedDefinitionsIfDefined(StringRef ClassName) const;\n\n  void dump() const;\n\nprivate:\n  RecordKeeper(RecordKeeper &&) = delete;\n  RecordKeeper(const RecordKeeper &) = delete;\n  RecordKeeper &operator=(RecordKeeper &&) = delete;\n  RecordKeeper &operator=(const RecordKeeper &) = delete;\n\n  std::string InputFilename;\n  RecordMap Classes, Defs;\n  mutable StringMap<std::vector<Record *>> ClassRecordsMap;\n  GlobalMap ExtraGlobals;\n\n  // These members are for the phase timing feature. We need a timer group,\n  // the last timer started, and a flag to say whether the last timer\n  // is the special \"backend overall timer.\"\n  TimerGroup *TimingGroup = nullptr;\n  Timer *LastTimer = nullptr;\n  bool BackendTimer = false;\n\n  /// The internal uniquer implementation of the RecordKeeper.\n  std::unique_ptr<detail::RecordKeeperImpl> Impl;\n};\n\n/// Sorting predicate to sort record pointers by name.\nstruct LessRecord {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return StringRef(Rec1->getName()).compare_numeric(Rec2->getName()) < 0;\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// unique ID. If you just need a deterministic order, use this, since it\n/// just compares two `unsigned`; the other sorting predicates require\n/// string manipulation.\nstruct LessRecordByID {\n  bool operator()(const Record *LHS, const Record *RHS) const {\n    return LHS->getID() < RHS->getID();\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// name field.\nstruct LessRecordFieldName {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return Rec1->getValueAsString(\"Name\") < Rec2->getValueAsString(\"Name\");\n  }\n};\n\nstruct LessRecordRegister {\n  struct RecordParts {\n    SmallVector<std::pair< bool, StringRef>, 4> Parts;\n\n    RecordParts(StringRef Rec) {\n      if (Rec.empty())\n        return;\n\n      size_t Len = 0;\n      const char *Start = Rec.data();\n      const char *Curr = Start;\n      bool IsDigitPart = isDigit(Curr[0]);\n      for (size_t I = 0, E = Rec.size(); I != E; ++I, ++Len) {\n        bool IsDigit = isDigit(Curr[I]);\n        if (IsDigit != IsDigitPart) {\n          Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n          Len = 0;\n          Start = &Curr[I];\n          IsDigitPart = isDigit(Curr[I]);\n        }\n      }\n      // Push the last part.\n      Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n    }\n\n    size_t size() { return Parts.size(); }\n\n    std::pair<bool, StringRef> getPart(size_t i) {\n      assert (i < Parts.size() && \"Invalid idx!\");\n      return Parts[i];\n    }\n  };\n\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    int64_t LHSPositionOrder = Rec1->getValueAsInt(\"PositionOrder\");\n    int64_t RHSPositionOrder = Rec2->getValueAsInt(\"PositionOrder\");\n    if (LHSPositionOrder != RHSPositionOrder)\n      return LHSPositionOrder < RHSPositionOrder;\n\n    RecordParts LHSParts(StringRef(Rec1->getName()));\n    RecordParts RHSParts(StringRef(Rec2->getName()));\n\n    size_t LHSNumParts = LHSParts.size();\n    size_t RHSNumParts = RHSParts.size();\n    assert (LHSNumParts && RHSNumParts && \"Expected at least one part!\");\n\n    if (LHSNumParts != RHSNumParts)\n      return LHSNumParts < RHSNumParts;\n\n    // We expect the registers to be of the form [_a-zA-Z]+([0-9]*[_a-zA-Z]*)*.\n    for (size_t I = 0, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect even part to always be alpha.\n      assert (LHSPart.first == false && RHSPart.first == false &&\n              \"Expected both parts to be alpha.\");\n      if (int Res = LHSPart.second.compare(RHSPart.second))\n        return Res < 0;\n    }\n    for (size_t I = 1, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect odd part to always be numeric.\n      assert (LHSPart.first == true && RHSPart.first == true &&\n              \"Expected both parts to be numeric.\");\n      if (LHSPart.second.size() != RHSPart.second.size())\n        return LHSPart.second.size() < RHSPart.second.size();\n\n      unsigned LHSVal, RHSVal;\n\n      bool LHSFailed = LHSPart.second.getAsInteger(10, LHSVal); (void)LHSFailed;\n      assert(!LHSFailed && \"Unable to convert LHS to integer.\");\n      bool RHSFailed = RHSPart.second.getAsInteger(10, RHSVal); (void)RHSFailed;\n      assert(!RHSFailed && \"Unable to convert RHS to integer.\");\n\n      if (LHSVal != RHSVal)\n        return LHSVal < RHSVal;\n    }\n    return LHSNumParts < RHSNumParts;\n  }\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const RecordKeeper &RK);\n\n//===----------------------------------------------------------------------===//\n//  Resolvers\n//===----------------------------------------------------------------------===//\n\n/// Interface for looking up the initializer for a variable name, used by\n/// Init::resolveReferences.\nclass Resolver {\n  Record *CurRec;\n  bool IsFinal = false;\n\npublic:\n  explicit Resolver(Record *CurRec) : CurRec(CurRec) {}\n  virtual ~Resolver() = default;\n\n  Record *getCurrentRecord() const { return CurRec; }\n\n  /// Return the initializer for the given variable name (should normally be a\n  /// StringInit), or nullptr if the name could not be resolved.\n  virtual Init *resolve(Init *VarName) = 0;\n\n  // Whether bits in a BitsInit should stay unresolved if resolving them would\n  // result in a ? (UnsetInit). This behavior is used to represent instruction\n  // encodings by keeping references to unset variables within a record.\n  virtual bool keepUnsetBits() const { return false; }\n\n  // Whether this is the final resolve step before adding a record to the\n  // RecordKeeper. Error reporting during resolve and related constant folding\n  // should only happen when this is true.\n  bool isFinal() const { return IsFinal; }\n\n  void setFinal(bool Final) { IsFinal = Final; }\n};\n\n/// Resolve arbitrary mappings.\nclass MapResolver final : public Resolver {\n  struct MappedValue {\n    Init *V;\n    bool Resolved;\n\n    MappedValue() : V(nullptr), Resolved(false) {}\n    MappedValue(Init *V, bool Resolved) : V(V), Resolved(Resolved) {}\n  };\n\n  DenseMap<Init *, MappedValue> Map;\n\npublic:\n  explicit MapResolver(Record *CurRec = nullptr) : Resolver(CurRec) {}\n\n  void set(Init *Key, Init *Value) { Map[Key] = {Value, false}; }\n\n  bool isComplete(Init *VarName) const {\n    auto It = Map.find(VarName);\n    assert(It != Map.end() && \"key must be present in map\");\n    return It->second.V->isComplete();\n  }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Resolve all variables from a record except for unset variables.\nclass RecordResolver final : public Resolver {\n  DenseMap<Init *, Init *> Cache;\n  SmallVector<Init *, 4> Stack;\n  Init *Name = nullptr;\n\npublic:\n  explicit RecordResolver(Record &R) : Resolver(&R) {}\n\n  void setName(Init *NewName) { Name = NewName; }\n\n  Init *resolve(Init *VarName) override;\n\n  bool keepUnsetBits() const override { return true; }\n};\n\n/// Delegate resolving to a sub-resolver, but shadow some variable names.\nclass ShadowResolver final : public Resolver {\n  Resolver &R;\n  DenseSet<Init *> Shadowed;\n\npublic:\n  explicit ShadowResolver(Resolver &R)\n      : Resolver(R.getCurrentRecord()), R(R) {\n    setFinal(R.isFinal());\n  }\n\n  void addShadow(Init *Key) { Shadowed.insert(Key); }\n\n  Init *resolve(Init *VarName) override {\n    if (Shadowed.count(VarName))\n      return nullptr;\n    return R.resolve(VarName);\n  }\n};\n\n/// (Optionally) delegate resolving to a sub-resolver, and keep track whether\n/// there were unresolved references.\nclass TrackUnresolvedResolver final : public Resolver {\n  Resolver *R;\n  bool FoundUnresolved = false;\n\npublic:\n  explicit TrackUnresolvedResolver(Resolver *R = nullptr)\n      : Resolver(R ? R->getCurrentRecord() : nullptr), R(R) {}\n\n  bool foundUnresolved() const { return FoundUnresolved; }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Do not resolve anything, but keep track of whether a given variable was\n/// referenced.\nclass HasReferenceResolver final : public Resolver {\n  Init *VarNameToTrack;\n  bool Found = false;\n\npublic:\n  explicit HasReferenceResolver(Init *VarNameToTrack)\n      : Resolver(nullptr), VarNameToTrack(VarNameToTrack) {}\n\n  bool found() const { return Found; }\n\n  Init *resolve(Init *VarName) override;\n};\n\nvoid EmitDetailedRecords(RecordKeeper &RK, raw_ostream &OS);\nvoid EmitJSON(RecordKeeper &RK, raw_ostream &OS);\n\n} // end namespace llvm\n\n#endif // LLVM_TABLEGEN_RECORD_H\n"}, {"id": "65F2F4BA858E2829", "name": "llvm::TreePatternNode::getOperator", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 719, "col": 3}, "end": {"line": 722, "col": 3}, "code": "    assert(!isLeaf());\n    return cast<Record *>(OperatorOrVal);\n  }\n\n  unsigned getNumChildren() const { return Children.size(); }\n  const TreePatternNode &getChild(unsigned N) const {\n    return *Children[N].get();\n  }\n  TreePatternNode &getChild(unsigned N) { return *Children[N].get(); }\n  const TreePatternNodePtr &getChildShared(unsigned N) const {\n    return Children[N];\n  }\n  TreePatternNodePtr &getChildSharedPtr(unsigned N) { return Children[N]; }\n  void setChild(unsigned i, TreePatternNodePtr N) { Children[i] = N; }\n\n  /// hasChild - Return true if N is any of our children.\n  bool hasChild(const TreePatternNode *N) const {\n    for (unsigned i = 0, e = Children.size(); i != e; ++i)\n      if (Children[i].get() == N)\n        return true;\n    return false;\n  }\n\n  bool hasProperTypeByHwMode() const;\n  bool hasPossibleType() const;\n  bool setDefaultMode(unsigned Mode);\n\n  bool hasAnyPredicate() const { return !PredicateCalls.empty(); }\n\n  const std::vector<TreePredicateCall> &getPredicateCalls() const {\n    return PredicateCalls;\n  }\n  void clearPredicateCalls() { PredicateCalls.clear(); }\n  void setPredicateCalls(const std::vector<TreePredicateCall> &Calls) {\n    assert(PredicateCalls.empty() && \"Overwriting non-empty predicate list!\");\n    PredicateCalls = Calls;\n  }\n  void addPredicateCall(const TreePredicateCall &Call) {\n    assert(!Call.Fn.isAlwaysTrue() && \"Empty predicate string!\");\n    assert(!is_contained(PredicateCalls, Call) &&\n           \"predicate applied recursively\");\n    PredicateCalls.push_back(Call);\n  }\n  void addPredicateCall(const TreePredicateFn &Fn, unsigned Scope) {\n    assert((Scope != 0) == Fn.usesOperands());\n    addPredicateCall(TreePredicateCall(Fn, Scope));\n  }\n\n  Record *getTransformFn() const { return TransformFn; }\n  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "CEA8224CEBAA759E", "name": "llvm::TreePatternNode::getNumChildren", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 724, "col": 3}, "end": {"line": 724, "col": 61}, "code": "  const TreePatternNode &getChild(unsigned N) const {\n    return *Children[N].get();\n  }\n  TreePatternNode &getChild(unsigned N) { return *Children[N].get(); }\n  const TreePatternNodePtr &getChildShared(unsigned N) const {\n    return Children[N];\n  }\n  TreePatternNodePtr &getChildSharedPtr(unsigned N) { return Children[N]; }\n  void setChild(unsigned i, TreePatternNodePtr N) { Children[i] = N; }\n\n  /// hasChild - Return true if N is any of our children.\n  bool hasChild(const TreePatternNode *N) const {\n    for (unsigned i = 0, e = Children.size(); i != e; ++i)\n      if (Children[i].get() == N)\n        return true;\n    return false;\n  }\n\n  bool hasProperTypeByHwMode() const;\n  bool hasPossibleType() const;\n  bool setDefaultMode(unsigned Mode);\n\n  bool hasAnyPredicate() const { return !PredicateCalls.empty(); }\n\n  const std::vector<TreePredicateCall> &getPredicateCalls() const {\n    return PredicateCalls;\n  }\n  void clearPredicateCalls() { PredicateCalls.clear(); }\n  void setPredicateCalls(const std::vector<TreePredicateCall> &Calls) {\n    assert(PredicateCalls.empty() && \"Overwriting non-empty predicate list!\");\n    PredicateCalls = Calls;\n  }\n  void addPredicateCall(const TreePredicateCall &Call) {\n    assert(!Call.Fn.isAlwaysTrue() && \"Empty predicate string!\");\n    assert(!is_contained(PredicateCalls, Call) &&\n           \"predicate applied recursively\");\n    PredicateCalls.push_back(Call);\n  }\n  void addPredicateCall(const TreePredicateFn &Fn, unsigned Scope) {\n    assert((Scope != 0) == Fn.usesOperands());\n    addPredicateCall(TreePredicateCall(Fn, Scope));\n  }\n\n  Record *getTransformFn() const { return TransformFn; }\n  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "6EF0AC47AE4C4498", "name": "getInstructionsInTree", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp", "start": {"line": 3726, "col": 1}, "end": {"line": 3734, "col": 1}, "code": "                                  SmallVectorImpl<Record *> &Instrs) {\n  if (Tree.isLeaf())\n    return;\n  if (Tree.getOperator()->isSubClassOf(\"Instruction\"))\n    Instrs.push_back(Tree.getOperator());\n  for (unsigned i = 0, e = Tree.getNumChildren(); i != e; ++i)\n    getInstructionsInTree(Tree.getChild(i), Instrs);\n}\n\n/// Check the class of a pattern leaf node against the instruction operand it\n/// represents.\nstatic bool checkOperandClass(CGIOperandList::OperandInfo &OI, Record *Leaf) {\n  if (OI.Rec == Leaf)\n    return true;\n\n  // Allow direct value types to be used in instruction set patterns.\n  // The type will be checked later.\n  if (Leaf->isSubClassOf(\"ValueType\"))\n    return true;\n\n  // Patterns can also be ComplexPattern instances.\n  if (Leaf->isSubClassOf(\"ComplexPattern\"))\n    return true;\n\n  return false;\n}\n\nvoid CodeGenDAGPatterns::parseInstructionPattern(CodeGenInstruction &CGI,\n                                                 ListInit *Pat,\n                                                 DAGInstMap &DAGInsts) {\n\n  assert(!DAGInsts.count(CGI.TheDef) && \"Instruction already parsed!\");\n\n  // Parse the instruction.\n  TreePattern I(CGI.TheDef, Pat, true, *this);\n\n  // InstInputs - Keep track of all of the inputs of the instruction, along\n  // with the record they are declared as.\n  std::map<std::string, TreePatternNodePtr> InstInputs;\n\n  // InstResults - Keep track of all the virtual registers that are 'set'\n  // in the instruction, including what reg class they are.\n  MapVector<std::string, TreePatternNodePtr, std::map<std::string, unsigned>>\n      InstResults;\n\n  std::vector<Record *> InstImpResults;\n\n  // Verify that the top-level forms in the instruction are of void type, and\n  // fill in the InstResults map.\n  SmallString<32> TypesString;\n  for (unsigned j = 0, e = I.getNumTrees(); j != e; ++j) {\n    TypesString.clear();\n    TreePatternNodePtr Pat = I.getTree(j);\n    if (Pat->getNumTypes() != 0) {\n      raw_svector_ostream OS(TypesString);\n      ListSeparator LS;\n      for (unsigned k = 0, ke = Pat->getNumTypes(); k != ke; ++k) {\n        OS << LS;\n        Pat->getExtType(k).writeToStream(OS);\n      }\n      I.error(\"Top-level forms in instruction pattern should have\"\n              \" void types, has types \" +\n              OS.str());\n    }\n\n    // Find inputs and outputs, and verify the structure of the uses/defs.\n    FindPatternInputsAndOutputs(I, Pat, InstInputs, InstResults,\n                                InstImpResults);\n  }\n\n  // Now that we have inputs and outputs of the pattern, inspect the operands\n  // list for the instruction.  This determines the order that operands are\n  // added to the machine instruction the node corresponds to.\n  unsigned NumResults = InstResults.size();\n\n  // Parse the operands list from the (ops) list, validating it.\n  assert(I.getArgList().empty() && \"Args list should still be empty here!\");\n\n  // Check that all of the results occur first in the list.\n  std::vector<Record *> Results;\n  std::vector<unsigned> ResultIndices;\n  SmallVector<TreePatternNodePtr, 2> ResNodes;\n  for (unsigned i = 0; i != NumResults; ++i) {\n    if (i == CGI.Operands.size()) {\n      const std::string &OpName =\n          llvm::find_if(\n              InstResults,\n              [](const std::pair<std::string, TreePatternNodePtr> &P) {\n                return P.second;\n              })\n              ->first;\n\n      I.error(\"'\" + OpName + \"' set but does not appear in operand list!\");\n    }\n\n    const std::string &OpName = CGI.Operands[i].Name;\n\n    // Check that it exists in InstResults.\n    auto InstResultIter = InstResults.find(OpName);\n    if (InstResultIter == InstResults.end() || !InstResultIter->second)\n      I.error(\"Operand $\" + OpName + \" does not exist in operand list!\");\n\n    TreePatternNodePtr RNode = InstResultIter->second;\n    Record *R = cast<DefInit>(RNode->getLeafValue())->getDef();\n    ResNodes.push_back(std::move(RNode));\n    if (!R)\n      I.error(\"Operand $\" + OpName +\n              \" should be a set destination: all \"\n              \"outputs must occur before inputs in operand list!\");\n\n    if (!checkOperandClass(CGI.Operands[i], R))\n      I.error(\"Operand $\" + OpName + \" class mismatch!\");\n\n    // Remember the return type.\n    Results.push_back(CGI.Operands[i].Rec);\n\n    // Remember the result index.\n    ResultIndices.push_back(std::distance(InstResults.begin(), InstResultIter));\n\n    // Okay, this one checks out.\n    InstResultIter->second = nullptr;\n  }\n\n  // Loop over the inputs next.\n  std::vector<TreePatternNodePtr> ResultNodeOperands;\n  std::vector<Record *> Operands;\n  for (unsigned i = NumResults, e = CGI.Operands.size(); i != e; ++i) {\n    CGIOperandList::OperandInfo &Op = CGI.Operands[i];\n    const std::string &OpName = Op.Name;\n    if (OpName.empty())\n      I.error(\"Operand #\" + Twine(i) + \" in operands list has no name!\");\n\n    if (!InstInputs.count(OpName)) {\n      // If this is an operand with a DefaultOps set filled in, we can ignore\n      // this.  When we codegen it, we will do so as always executed.\n      if (Op.Rec->isSubClassOf(\"OperandWithDefaultOps\")) {\n        // Does it have a non-empty DefaultOps field?  If so, ignore this\n        // operand.\n        if (!getDefaultOperand(Op.Rec).DefaultOps.empty())\n          continue;\n      }\n      I.error(\"Operand $\" + OpName +\n              \" does not appear in the instruction pattern\");\n    }\n    TreePatternNodePtr InVal = InstInputs[OpName];\n    InstInputs.erase(OpName); // It occurred, remove from map.\n\n    if (InVal->isLeaf() && isa<DefInit>(InVal->getLeafValue())) {\n      Record *InRec = cast<DefInit>(InVal->getLeafValue())->getDef();\n      if (!checkOperandClass(Op, InRec))\n        I.error(\"Operand $\" + OpName +\n                \"'s register class disagrees\"\n                \" between the operand and pattern\");\n    }\n    Operands.push_back(Op.Rec);\n\n    // Construct the result for the dest-pattern operand list.\n    TreePatternNodePtr OpNode = InVal->clone();\n\n    // No predicate is useful on the result.\n    OpNode->clearPredicateCalls();\n\n    // Promote the xform function to be an explicit node if set.\n    if (Record *Xform = OpNode->getTransformFn()) {\n      OpNode->setTransformFn(nullptr);\n      std::vector<TreePatternNodePtr> Children;\n      Children.push_back(OpNode);\n      OpNode = makeIntrusiveRefCnt<TreePatternNode>(Xform, std::move(Children),\n                                                    OpNode->getNumTypes());\n    }\n\n    ResultNodeOperands.push_back(std::move(OpNode));\n  }\n\n  if (!InstInputs.empty())\n    I.error(\"Input operand $\" + InstInputs.begin()->first +\n            \" occurs in pattern but not in operands list!\");\n\n  TreePatternNodePtr ResultPattern = makeIntrusiveRefCnt<TreePatternNode>(\n      I.getRecord(), std::move(ResultNodeOperands),\n      GetNumNodeResults(I.getRecord(), *this));\n  // Copy fully inferred output node types to instruction result pattern.\n  for (unsigned i = 0; i != NumResults; ++i) {\n    assert(ResNodes[i]->getNumTypes() == 1 && \"FIXME: Unhandled\");\n    ResultPattern->setType(i, ResNodes[i]->getExtType(0));\n    ResultPattern->setResultIndex(i, ResultIndices[i]);\n  }\n\n  // FIXME: Assume only the first tree is the pattern. The others are clobber\n  // nodes.\n  TreePatternNodePtr Pattern = I.getTree(0);\n  TreePatternNodePtr SrcPattern;\n  if (Pattern->getOperator()->getName() == \"set\") {\n    SrcPattern = Pattern->getChild(Pattern->getNumChildren() - 1).clone();\n  } else {\n    // Not a set (store or something?)\n    SrcPattern = Pattern;\n  }\n\n  // Create and insert the instruction.\n  // FIXME: InstImpResults should not be part of DAGInstruction.\n  Record *R = I.getRecord();\n  DAGInsts.try_emplace(R, std::move(Results), std::move(Operands),\n                       std::move(InstImpResults), SrcPattern, ResultPattern);\n\n  LLVM_DEBUG(I.dump());\n}\n\n/// ParseInstructions - Parse all of the instructions, inlining and resolving\n/// any fragments involved.  This populates the Instructions list with fully\n/// resolved instructions.\nvoid CodeGenDAGPatterns::ParseInstructions() {\n  std::vector<Record *> Instrs =\n      Records.getAllDerivedDefinitions(\"Instruction\");\n\n  for (Record *Instr : Instrs) {\n    ListInit *LI = nullptr;\n\n    if (isa<ListInit>(Instr->getValueInit(\"Pattern\")))\n      LI = Instr->getValueAsListInit(\"Pattern\");\n\n    // If there is no pattern, only collect minimal information about the\n    // instruction for its operand list.  We have to assume that there is one\n    // result, as we have no detailed info. A pattern which references the\n    // null_frag operator is as-if no pattern were specified. Normally this\n    // is from a multiclass expansion w/ a SDPatternOperator passed in as\n    // null_frag.\n    if (!LI || LI->empty() || hasNullFragReference(LI)) {\n      std::vector<Record *> Results;\n      std::vector<Record *> Operands;\n\n      CodeGenInstruction &InstInfo = Target.getInstruction(Instr);\n\n      if (InstInfo.Operands.size() != 0) {\n        for (unsigned j = 0, e = InstInfo.Operands.NumDefs; j < e; ++j)\n          Results.push_back(InstInfo.Operands[j].Rec);\n\n        // The rest are inputs.\n        for (unsigned j = InstInfo.Operands.NumDefs,\n                      e = InstInfo.Operands.size();\n             j < e; ++j)\n          Operands.push_back(InstInfo.Operands[j].Rec);\n      }\n\n      // Create and insert the instruction.\n      Instructions.try_emplace(Instr, std::move(Results), std::move(Operands),\n                               std::vector<Record *>());\n      continue; // no pattern.\n    }\n\n    CodeGenInstruction &CGI = Target.getInstruction(Instr);\n    parseInstructionPattern(CGI, LI, Instructions);\n  }\n\n  // If we can, convert the instructions to be patterns that are matched!\n  for (auto &Entry : Instructions) {\n    Record *Instr = Entry.first;\n    DAGInstruction &TheInst = Entry.second;\n    TreePatternNodePtr SrcPattern = TheInst.getSrcPattern();\n    TreePatternNodePtr ResultPattern = TheInst.getResultPattern();\n\n    if (SrcPattern && ResultPattern) {\n      TreePattern Pattern(Instr, SrcPattern, true, *this);\n      TreePattern Result(Instr, ResultPattern, false, *this);\n      ParseOnePattern(Instr, Pattern, Result, TheInst.getImpResults());\n    }\n  }\n}\n\ntypedef std::pair<TreePatternNode *, unsigned> NameRecord;\n\nstatic void FindNames(TreePatternNode &P,\n                      std::map<std::string, NameRecord> &Names,\n                      TreePattern *PatternTop) {\n  if (!P.getName().empty()) {\n    NameRecord &Rec = Names[P.getName()];\n    // If this is the first instance of the name, remember the node.\n    if (Rec.second++ == 0)\n      Rec.first = &P;\n    else if (Rec.first->getExtTypes() != P.getExtTypes())\n      PatternTop->error(\"repetition of value: $\" + P.getName() +\n                        \" where different uses have different types!\");\n  }\n\n  if (!P.isLeaf()) {\n    for (unsigned i = 0, e = P.getNumChildren(); i != e; ++i)\n      FindNames(P.getChild(i), Names, PatternTop);\n  }\n}\n\nvoid CodeGenDAGPatterns::AddPatternToMatch(TreePattern *Pattern,\n                                           PatternToMatch &&PTM) {\n  // Do some sanity checking on the pattern we're about to match.\n  std::string Reason;\n  if (!PTM.getSrcPattern().canPatternMatch(Reason, *this)) {\n    PrintWarning(Pattern->getRecord()->getLoc(),\n                 Twine(\"Pattern can never match: \") + Reason);\n    return;\n  }\n\n  // If the source pattern's root is a complex pattern, that complex pattern\n  // must specify the nodes it can potentially match.\n  if (const ComplexPattern *CP =\n          PTM.getSrcPattern().getComplexPatternInfo(*this))\n    if (CP->getRootNodes().empty())\n      Pattern->error(\"ComplexPattern at root must specify list of opcodes it\"\n                     \" could match\");\n\n  // Find all of the named values in the input and output, ensure they have the\n  // same type.\n  std::map<std::string, NameRecord> SrcNames, DstNames;\n  FindNames(PTM.getSrcPattern(), SrcNames, Pattern);\n  FindNames(PTM.getDstPattern(), DstNames, Pattern);\n\n  // Scan all of the named values in the destination pattern, rejecting them if\n  // they don't exist in the input pattern.\n  for (const auto &Entry : DstNames) {\n    if (SrcNames[Entry.first].first == nullptr)\n      Pattern->error(\"Pattern has input without matching name in output: $\" +\n                     Entry.first);\n  }\n\n  // Scan all of the named values in the source pattern, rejecting them if the\n  // name isn't used in the dest, and isn't used to tie two values together.\n  for (const auto &Entry : SrcNames)\n    if (DstNames[Entry.first].first == nullptr &&\n        SrcNames[Entry.first].second == 1)\n      Pattern->error(\"Pattern has dead named input: $\" + Entry.first);\n\n  PatternsToMatch.push_back(std::move(PTM));\n}\n\nvoid CodeGenDAGPatterns::InferInstructionFlags() {\n  ArrayRef<const CodeGenInstruction *> Instructions =\n      Target.getInstructionsByEnumValue();\n\n  unsigned Errors = 0;\n\n  // Try to infer flags from all patterns in PatternToMatch.  These include\n  // both the primary instruction patterns (which always come first) and\n  // patterns defined outside the instruction.\n  for (const PatternToMatch &PTM : ptms()) {\n    // We can only infer from single-instruction patterns, otherwise we won't\n    // know which instruction should get the flags.\n    SmallVector<Record *, 8> PatInstrs;\n    getInstructionsInTree(PTM.getDstPattern(), PatInstrs);\n    if (PatInstrs.size() != 1)\n      continue;\n\n    // Get the single instruction.\n    CodeGenInstruction &InstInfo = Target.getInstruction(PatInstrs.front());\n\n    // Only infer properties from the first pattern. We'll verify the others.\n    if (InstInfo.InferredFrom)\n      continue;\n\n    InstAnalyzer PatInfo(*this);\n    PatInfo.Analyze(PTM);\n    Errors += InferFromPattern(InstInfo, PatInfo, PTM.getSrcRecord());\n  }\n\n  if (Errors)\n    PrintFatalError(\"pattern conflicts\");\n\n  // If requested by the target, guess any undefined properties.\n  if (Target.guessInstructionProperties()) {\n    for (unsigned i = 0, e = Instructions.size(); i != e; ++i) {\n      CodeGenInstruction *InstInfo =\n          const_cast<CodeGenInstruction *>(Instructions[i]);\n      if (InstInfo->InferredFrom)\n        continue;\n      // The mayLoad and mayStore flags default to false.\n      // Conservatively assume hasSideEffects if it wasn't explicit.\n      if (InstInfo->hasSideEffects_Unset)\n        InstInfo->hasSideEffects = true;\n    }\n    return;\n  }\n\n  // Complain about any flags that are still undefined.\n  for (unsigned i = 0, e = Instructions.size(); i != e; ++i) {\n    CodeGenInstruction *InstInfo =\n        const_cast<CodeGenInstruction *>(Instructions[i]);\n    if (InstInfo->InferredFrom)\n      continue;\n    if (InstInfo->hasSideEffects_Unset)\n      PrintError(InstInfo->TheDef->getLoc(),\n                 \"Can't infer hasSideEffects from patterns\");\n    if (InstInfo->mayStore_Unset)\n      PrintError(InstInfo->TheDef->getLoc(),\n                 \"Can't infer mayStore from patterns\");\n    if (InstInfo->mayLoad_Unset)\n      PrintError(InstInfo->TheDef->getLoc(),\n                 \"Can't infer mayLoad from patterns\");\n  }\n}\n\n/// Verify instruction flags against pattern node properties.\nvoid CodeGenDAGPatterns::VerifyInstructionFlags() {\n  unsigned Errors = 0;\n  for (const PatternToMatch &PTM : ptms()) {\n    SmallVector<Record *, 8> Instrs;\n    getInstructionsInTree(PTM.getDstPattern(), Instrs);\n    if (Instrs.empty())\n      continue;\n\n    // Count the number of instructions with each flag set.\n    unsigned NumSideEffects = 0;\n    unsigned NumStores = 0;\n    unsigned NumLoads = 0;\n    for (const Record *Instr : Instrs) {\n      const CodeGenInstruction &InstInfo = Target.getInstruction(Instr);\n      NumSideEffects += InstInfo.hasSideEffects;\n      NumStores += InstInfo.mayStore;\n      NumLoads += InstInfo.mayLoad;\n    }\n\n    // Analyze the source pattern.\n    InstAnalyzer PatInfo(*this);\n    PatInfo.Analyze(PTM);\n\n    // Collect error messages.\n    SmallVector<std::string, 4> Msgs;\n\n    // Check for missing flags in the output.\n    // Permit extra flags for now at least.\n    if (PatInfo.hasSideEffects && !NumSideEffects)\n      Msgs.push_back(\"pattern has side effects, but hasSideEffects isn't set\");\n\n    // Don't verify store flags on instructions with side effects. At least for\n    // intrinsics, side effects implies mayStore.\n    if (!PatInfo.hasSideEffects && PatInfo.mayStore && !NumStores)\n      Msgs.push_back(\"pattern may store, but mayStore isn't set\");\n\n    // Similarly, mayStore implies mayLoad on intrinsics.\n    if (!PatInfo.mayStore && PatInfo.mayLoad && !NumLoads)\n      Msgs.push_back(\"pattern may load, but mayLoad isn't set\");\n\n    // Print error messages.\n    if (Msgs.empty())\n      continue;\n    ++Errors;\n\n    for (const std::string &Msg : Msgs)\n      PrintError(\n          PTM.getSrcRecord()->getLoc(),\n          Twine(Msg) + \" on the \" +\n              (Instrs.size() == 1 ? \"instruction\" : \"output instructions\"));\n    // Provide the location of the relevant instruction definitions.\n    for (const Record *Instr : Instrs) {\n      if (Instr != PTM.getSrcRecord())\n        PrintError(Instr->getLoc(), \"defined here\");\n      const CodeGenInstruction &InstInfo = Target.getInstruction(Instr);\n      if (InstInfo.InferredFrom && InstInfo.InferredFrom != InstInfo.TheDef &&\n          InstInfo.InferredFrom != PTM.getSrcRecord())\n        PrintError(InstInfo.InferredFrom->getLoc(), \"inferred from pattern\");\n    }\n  }\n  if (Errors)\n    PrintFatalError(\"Errors in DAG patterns\");\n}\n\n/// Given a pattern result with an unresolved type, see if we can find one\n/// instruction with an unresolved result type.  Force this result type to an\n/// arbitrary element if it's possible types to converge results.\nstatic bool ForceArbitraryInstResultType(TreePatternNode &N, TreePattern &TP) {\n  if (N.isLeaf())\n    return false;\n\n  // Analyze children.\n  for (unsigned i = 0, e = N.getNumChildren(); i != e; ++i)\n    if (ForceArbitraryInstResultType(N.getChild(i), TP))\n      return true;\n\n  if (!N.getOperator()->isSubClassOf(\"Instruction\"))\n    return false;\n\n  // If this type is already concrete or completely unknown we can't do\n  // anything.\n  TypeInfer &TI = TP.getInfer();\n  for (unsigned i = 0, e = N.getNumTypes(); i != e; ++i) {\n    if (N.getExtType(i).empty() || TI.isConcrete(N.getExtType(i), false))\n      continue;\n\n    // Otherwise, force its type to an arbitrary choice.\n    if (TI.forceArbitrary(N.getExtType(i)))\n      return true;\n  }\n\n  return false;\n}\n\n// Promote xform function to be an explicit node wherever set.\nstatic TreePatternNodePtr PromoteXForms(TreePatternNodePtr N) {\n  if (Record *Xform = N->getTransformFn()) {\n    N->setTransformFn(nullptr);\n    std::vector<TreePatternNodePtr> Children;\n    Children.push_back(PromoteXForms(N));\n    return makeIntrusiveRefCnt<TreePatternNode>(Xform, std::move(Children),\n                                                N->getNumTypes());\n  }\n\n  if (!N->isLeaf())\n    for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i) {\n      TreePatternNodePtr Child = N->getChildShared(i);\n      N->setChild(i, PromoteXForms(Child));\n    }\n  return N;\n}\n\nvoid CodeGenDAGPatterns::ParseOnePattern(\n    Record *TheDef, TreePattern &Pattern, TreePattern &Result,\n    const std::vector<Record *> &InstImpResults) {\n\n  // Inline pattern fragments and expand multiple alternatives.\n  Pattern.InlinePatternFragments();\n  Result.InlinePatternFragments();\n\n  if (Result.getNumTrees() != 1)\n    Result.error(\"Cannot use multi-alternative fragments in result pattern!\");\n\n  // Infer types.\n  bool IterateInference;\n  bool InferredAllPatternTypes, InferredAllResultTypes;\n  do {\n    // Infer as many types as possible.  If we cannot infer all of them, we\n    // can never do anything with this pattern: report it to the user.\n    InferredAllPatternTypes =\n        Pattern.InferAllTypes(&Pattern.getNamedNodesMap());\n\n    // Infer as many types as possible.  If we cannot infer all of them, we\n    // can never do anything with this pattern: report it to the user.\n    InferredAllResultTypes = Result.InferAllTypes(&Pattern.getNamedNodesMap());\n\n    IterateInference = false;\n\n    // Apply the type of the result to the source pattern.  This helps us\n    // resolve cases where the input type is known to be a pointer type (which\n    // is considered resolved), but the result knows it needs to be 32- or\n    // 64-bits.  Infer the other way for good measure.\n    for (const auto &T : Pattern.getTrees())\n      for (unsigned i = 0, e = std::min(Result.getOnlyTree()->getNumTypes(),\n                                        T->getNumTypes());\n           i != e; ++i) {\n        IterateInference |=\n            T->UpdateNodeType(i, Result.getOnlyTree()->getExtType(i), Result);\n        IterateInference |=\n            Result.getOnlyTree()->UpdateNodeType(i, T->getExtType(i), Result);\n      }\n\n    // If our iteration has converged and the input pattern's types are fully\n    // resolved but the result pattern is not fully resolved, we may have a\n    // situation where we have two instructions in the result pattern and\n    // the instructions require a common register class, but don't care about\n    // what actual MVT is used.  This is actually a bug in our modelling:\n    // output patterns should have register classes, not MVTs.\n    //\n    // In any case, to handle this, we just go through and disambiguate some\n    // arbitrary types to the result pattern's nodes.\n    if (!IterateInference && InferredAllPatternTypes && !InferredAllResultTypes)\n      IterateInference =\n          ForceArbitraryInstResultType(*Result.getTree(0), Result);\n  } while (IterateInference);\n\n  // Verify that we inferred enough types that we can do something with the\n  // pattern and result.  If these fire the user has to add type casts.\n  if (!InferredAllPatternTypes)\n    Pattern.error(\"Could not infer all types in pattern!\");\n  if (!InferredAllResultTypes) {\n    Pattern.dump();\n    Result.error(\"Could not infer all types in pattern result!\");\n  }\n\n  // Promote xform function to be an explicit node wherever set.\n  TreePatternNodePtr DstShared = PromoteXForms(Result.getOnlyTree());\n\n  TreePattern Temp(Result.getRecord(), DstShared, false, *this);\n  Temp.InferAllTypes();\n\n  ListInit *Preds = TheDef->getValueAsListInit(\"Predicates\");\n  int Complexity = TheDef->getValueAsInt(\"AddedComplexity\");\n\n  if (PatternRewriter)\n    PatternRewriter(&Pattern);\n\n  // A pattern may end up with an \"impossible\" type, i.e. a situation\n  // where all types have been eliminated for some node in this pattern.\n  // This could occur for intrinsics that only make sense for a specific\n  // value type, and use a specific register class. If, for some mode,\n  // that register class does not accept that type, the type inference\n  // will lead to a contradiction, which is not an error however, but\n  // a sign that this pattern will simply never match.\n  if (Temp.getOnlyTree()->hasPossibleType()) {\n    for (const auto &T : Pattern.getTrees()) {\n      if (T->hasPossibleType())\n        AddPatternToMatch(&Pattern,\n                          PatternToMatch(TheDef, Preds, T, Temp.getOnlyTree(),\n                                         InstImpResults, Complexity,\n                                         TheDef->getID()));\n    }\n  } else {\n    // Show a message about a dropped pattern with some info to make it\n    // easier to identify it in the .td files.\n    LLVM_DEBUG({\n      dbgs() << \"Dropping: \";\n      Pattern.dump();\n      Temp.getOnlyTree()->dump();\n      dbgs() << \"\\n\";\n    });\n  }\n}\n\nvoid CodeGenDAGPatterns::ParsePatterns() {\n  std::vector<Record *> Patterns = Records.getAllDerivedDefinitions(\"Pattern\");\n\n  for (Record *CurPattern : Patterns) {\n    DagInit *Tree = CurPattern->getValueAsDag(\"PatternToMatch\");\n\n    // If the pattern references the null_frag, there's nothing to do.\n    if (hasNullFragReference(Tree))\n      continue;\n\n    TreePattern Pattern(CurPattern, Tree, true, *this);\n\n    ListInit *LI = CurPattern->getValueAsListInit(\"ResultInstrs\");\n    if (LI->empty())\n      continue; // no pattern.\n\n    // Parse the instruction.\n    TreePattern Result(CurPattern, LI, false, *this);\n\n    if (Result.getNumTrees() != 1)\n      Result.error(\"Cannot handle instructions producing instructions \"\n                   \"with temporaries yet!\");\n\n    // Validate that the input pattern is correct.\n    std::map<std::string, TreePatternNodePtr> InstInputs;\n    MapVector<std::string, TreePatternNodePtr, std::map<std::string, unsigned>>\n        InstResults;\n    std::vector<Record *> InstImpResults;\n    for (unsigned j = 0, ee = Pattern.getNumTrees(); j != ee; ++j)\n      FindPatternInputsAndOutputs(Pattern, Pattern.getTree(j), InstInputs,\n                                  InstResults, InstImpResults);\n\n    ParseOnePattern(CurPattern, Pattern, Result, InstImpResults);\n  }\n}\n\nstatic void collectModes(std::set<unsigned> &Modes, const TreePatternNode &N) {\n  for (const TypeSetByHwMode &VTS : N.getExtTypes())\n    for (const auto &I : VTS)\n      Modes.insert(I.first);\n\n  for (unsigned i = 0, e = N.getNumChildren(); i != e; ++i)\n    collectModes(Modes, N.getChild(i));\n}\n\nvoid CodeGenDAGPatterns::ExpandHwModeBasedTypes() {\n  const CodeGenHwModes &CGH = getTargetInfo().getHwModes();\n  if (CGH.getNumModeIds() == 1)\n    return;\n\n  std::vector<PatternToMatch> Copy;\n  PatternsToMatch.swap(Copy);\n\n  auto AppendPattern = [this](PatternToMatch &P, unsigned Mode,\n                              StringRef Check) {\n    TreePatternNodePtr NewSrc = P.getSrcPattern().clone();\n    TreePatternNodePtr NewDst = P.getDstPattern().clone();\n    if (!NewSrc->setDefaultMode(Mode) || !NewDst->setDefaultMode(Mode)) {\n      return;\n    }\n\n    PatternsToMatch.emplace_back(P.getSrcRecord(), P.getPredicates(),\n                                 std::move(NewSrc), std::move(NewDst),\n                                 P.getDstRegs(), P.getAddedComplexity(),\n                                 Record::getNewUID(Records), Check);\n  };\n\n  for (PatternToMatch &P : Copy) {\n    const TreePatternNode *SrcP = nullptr, *DstP = nullptr;\n    if (P.getSrcPattern().hasProperTypeByHwMode())\n      SrcP = &P.getSrcPattern();\n    if (P.getDstPattern().hasProperTypeByHwMode())\n      DstP = &P.getDstPattern();\n    if (!SrcP && !DstP) {\n      PatternsToMatch.push_back(P);\n      continue;\n    }\n\n    std::set<unsigned> Modes;\n    if (SrcP)\n      collectModes(Modes, *SrcP);\n    if (DstP)\n      collectModes(Modes, *DstP);\n\n    // The predicate for the default mode needs to be constructed for each\n    // pattern separately.\n    // Since not all modes must be present in each pattern, if a mode m is\n    // absent, then there is no point in constructing a check for m. If such\n    // a check was created, it would be equivalent to checking the default\n    // mode, except not all modes' predicates would be a part of the checking\n    // code. The subsequently generated check for the default mode would then\n    // have the exact same patterns, but a different predicate code. To avoid\n    // duplicated patterns with different predicate checks, construct the\n    // default check as a negation of all predicates that are actually present\n    // in the source/destination patterns.\n    SmallString<128> DefaultCheck;\n\n    for (unsigned M : Modes) {\n      if (M == DefaultMode)\n        continue;\n\n      // Fill the map entry for this mode.\n      const HwMode &HM = CGH.getMode(M);\n      AppendPattern(P, M, HM.Predicates);\n\n      // Add negations of the HM's predicates to the default predicate.\n      if (!DefaultCheck.empty())\n        DefaultCheck += \" && \";\n      DefaultCheck += \"!(\";\n      DefaultCheck += HM.Predicates;\n      DefaultCheck += \")\";\n    }\n\n    bool HasDefault = Modes.count(DefaultMode);\n    if (HasDefault)\n      AppendPattern(P, DefaultMode, DefaultCheck);\n  }\n}\n\n/// Dependent variable map for CodeGenDAGPattern variant generation\ntypedef StringMap<int> DepVarMap;\n\nstatic void FindDepVarsOf(TreePatternNode &N, DepVarMap &DepMap) {\n  if (N.isLeaf()) {\n    if (N.hasName() && isa<DefInit>(N.getLeafValue()))\n      DepMap[N.getName()]++;\n  } else {\n    for (size_t i = 0, e = N.getNumChildren(); i != e; ++i)\n      FindDepVarsOf(N.getChild(i), DepMap);\n  }\n}\n\n/// Find dependent variables within child patterns\nstatic void FindDepVars(TreePatternNode &N, MultipleUseVarSet &DepVars) {\n  DepVarMap depcounts;\n  FindDepVarsOf(N, depcounts);\n  for (const auto &Pair : depcounts) {\n    if (Pair.getValue() > 1)\n      DepVars.insert(Pair.getKey());\n  }\n}\n\n#ifndef NDEBUG\n/// Dump the dependent variable set:\nstatic void DumpDepVars(MultipleUseVarSet &DepVars) {\n  if (DepVars.empty()) {\n    LLVM_DEBUG(errs() << \"<empty set>\");\n  } else {\n    LLVM_DEBUG(errs() << \"[ \");\n    for (const auto &DepVar : DepVars) {\n      LLVM_DEBUG(errs() << DepVar.getKey() << \" \");\n    }\n    LLVM_DEBUG(errs() << \"]\");\n  }\n}\n#endif\n\n/// CombineChildVariants - Given a bunch of permutations of each child of the\n/// 'operator' node, put them together in all possible ways.\nstatic void CombineChildVariants(\n    TreePatternNodePtr Orig,\n    const std::vector<std::vector<TreePatternNodePtr>> &ChildVariants,\n    std::vector<TreePatternNodePtr> &OutVariants, CodeGenDAGPatterns &CDP,\n    const MultipleUseVarSet &DepVars) {\n  // Make sure that each operand has at least one variant to choose from.\n  for (const auto &Variants : ChildVariants)\n    if (Variants.empty())\n      return;\n\n  // The end result is an all-pairs construction of the resultant pattern.\n  std::vector<unsigned> Idxs(ChildVariants.size());\n  bool NotDone;\n  do {\n#ifndef NDEBUG\n    LLVM_DEBUG(if (!Idxs.empty()) {\n      errs() << Orig->getOperator()->getName() << \": Idxs = [ \";\n      for (unsigned Idx : Idxs) {\n        errs() << Idx << \" \";\n      }\n      errs() << \"]\\n\";\n    });\n#endif\n    // Create the variant and add it to the output list.\n    std::vector<TreePatternNodePtr> NewChildren;\n    NewChildren.reserve(ChildVariants.size());\n    for (unsigned i = 0, e = ChildVariants.size(); i != e; ++i)\n      NewChildren.push_back(ChildVariants[i][Idxs[i]]);\n    TreePatternNodePtr R = makeIntrusiveRefCnt<TreePatternNode>(\n        Orig->getOperator(), std::move(NewChildren), Orig->getNumTypes());\n\n    // Copy over properties.\n    R->setName(Orig->getName());\n    R->setNamesAsPredicateArg(Orig->getNamesAsPredicateArg());\n    R->setPredicateCalls(Orig->getPredicateCalls());\n    R->setGISelFlagsRecord(Orig->getGISelFlagsRecord());\n    R->setTransformFn(Orig->getTransformFn());\n    for (unsigned i = 0, e = Orig->getNumTypes(); i != e; ++i)\n      R->setType(i, Orig->getExtType(i));\n\n    // If this pattern cannot match, do not include it as a variant.\n    std::string ErrString;\n    // Scan to see if this pattern has already been emitted.  We can get\n    // duplication due to things like commuting:\n    //   (and GPRC:$a, GPRC:$b) -> (and GPRC:$b, GPRC:$a)\n    // which are the same pattern.  Ignore the dups.\n    if (R->canPatternMatch(ErrString, CDP) &&\n        none_of(OutVariants, [&](TreePatternNodePtr Variant) {\n          return R->isIsomorphicTo(*Variant, DepVars);\n        }))\n      OutVariants.push_back(R);\n\n    // Increment indices to the next permutation by incrementing the\n    // indices from last index backward, e.g., generate the sequence\n    // [0, 0], [0, 1], [1, 0], [1, 1].\n    int IdxsIdx;\n    for (IdxsIdx = Idxs.size() - 1; IdxsIdx >= 0; --IdxsIdx) {\n      if (++Idxs[IdxsIdx] == ChildVariants[IdxsIdx].size())\n        Idxs[IdxsIdx] = 0;\n      else\n        break;\n    }\n    NotDone = (IdxsIdx >= 0);\n  } while (NotDone);\n}\n\n/// CombineChildVariants - A helper function for binary operators.\n///\nstatic void CombineChildVariants(TreePatternNodePtr Orig,\n                                 const std::vector<TreePatternNodePtr> &LHS,\n                                 const std::vector<TreePatternNodePtr> &RHS,\n                                 std::vector<TreePatternNodePtr> &OutVariants,\n                                 CodeGenDAGPatterns &CDP,\n                                 const MultipleUseVarSet &DepVars) {\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants;\n  ChildVariants.push_back(LHS);\n  ChildVariants.push_back(RHS);\n  CombineChildVariants(Orig, ChildVariants, OutVariants, CDP, DepVars);\n}\n\nstatic void\nGatherChildrenOfAssociativeOpcode(TreePatternNodePtr N,\n                                  std::vector<TreePatternNodePtr> &Children) {\n  assert(N->getNumChildren() == 2 &&\n         \"Associative but doesn't have 2 children!\");\n  Record *Operator = N->getOperator();\n\n  // Only permit raw nodes.\n  if (!N->getName().empty() || !N->getPredicateCalls().empty() ||\n      N->getTransformFn()) {\n    Children.push_back(N);\n    return;\n  }\n\n  if (N->getChild(0).isLeaf() || N->getChild(0).getOperator() != Operator)\n    Children.push_back(N->getChildShared(0));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(0), Children);\n\n  if (N->getChild(1).isLeaf() || N->getChild(1).getOperator() != Operator)\n    Children.push_back(N->getChildShared(1));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(1), Children);\n}\n\n/// GenerateVariantsOf - Given a pattern N, generate all permutations we can of\n/// the (potentially recursive) pattern by using algebraic laws.\n///\nstatic void GenerateVariantsOf(TreePatternNodePtr N,\n                               std::vector<TreePatternNodePtr> &OutVariants,\n                               CodeGenDAGPatterns &CDP,\n                               const MultipleUseVarSet &DepVars) {\n  // We cannot permute leaves or ComplexPattern uses.\n  if (N->isLeaf() || N->getOperator()->isSubClassOf(\"ComplexPattern\")) {\n    OutVariants.push_back(N);\n    return;\n  }\n\n  // Look up interesting info about the node.\n  const SDNodeInfo &NodeInfo = CDP.getSDNodeInfo(N->getOperator());\n\n  // If this node is associative, re-associate.\n  if (NodeInfo.hasProperty(SDNPAssociative)) {\n    // Re-associate by pulling together all of the linked operators\n    std::vector<TreePatternNodePtr> MaximalChildren;\n    GatherChildrenOfAssociativeOpcode(N, MaximalChildren);\n\n    // Only handle child sizes of 3.  Otherwise we'll end up trying too many\n    // permutations.\n    if (MaximalChildren.size() == 3) {\n      // Find the variants of all of our maximal children.\n      std::vector<TreePatternNodePtr> AVariants, BVariants, CVariants;\n      GenerateVariantsOf(MaximalChildren[0], AVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[1], BVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[2], CVariants, CDP, DepVars);\n\n      // There are only two ways we can permute the tree:\n      //   (A op B) op C    and    A op (B op C)\n      // Within these forms, we can also permute A/B/C.\n\n      // Generate legal pair permutations of A/B/C.\n      std::vector<TreePatternNodePtr> ABVariants;\n      std::vector<TreePatternNodePtr> BAVariants;\n      std::vector<TreePatternNodePtr> ACVariants;\n      std::vector<TreePatternNodePtr> CAVariants;\n      std::vector<TreePatternNodePtr> BCVariants;\n      std::vector<TreePatternNodePtr> CBVariants;\n      CombineChildVariants(N, AVariants, BVariants, ABVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, AVariants, BAVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CVariants, ACVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, AVariants, CAVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CVariants, BCVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BVariants, CBVariants, CDP, DepVars);\n\n      // Combine those into the result: (x op x) op x\n      CombineChildVariants(N, ABVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BAVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, ACVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CAVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BCVariants, AVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CBVariants, AVariants, OutVariants, CDP, DepVars);\n\n      // Combine those into the result: x op (x op x)\n      CombineChildVariants(N, CVariants, ABVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, ACVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, BCVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CBVariants, OutVariants, CDP, DepVars);\n      return;\n    }\n  }\n\n  // Compute permutations of all children.\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants(\n      N->getNumChildren());\n  for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i)\n    GenerateVariantsOf(N->getChildShared(i), ChildVariants[i], CDP, DepVars);\n\n  // Build all permutations based on how the children were formed.\n  CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n\n  // If this node is commutative, consider the commuted order.\n  bool isCommIntrinsic = N->isCommutativeIntrinsic(CDP);\n  if (NodeInfo.hasProperty(SDNPCommutative) || isCommIntrinsic) {\n    unsigned Skip = isCommIntrinsic ? 1 : 0; // First operand is intrinsic id.\n    assert(N->getNumChildren() >= (2 + Skip) &&\n           \"Commutative but doesn't have 2 children!\");\n    // Don't allow commuting children which are actually register references.\n    bool NoRegisters = true;\n    unsigned i = 0 + Skip;\n    unsigned e = 2 + Skip;\n    for (; i != e; ++i) {\n      TreePatternNode &Child = N->getChild(i);\n      if (Child.isLeaf())\n        if (DefInit *DI = dyn_cast<DefInit>(Child.getLeafValue())) {\n          Record *RR = DI->getDef();\n          if (RR->isSubClassOf(\"Register\"))\n            NoRegisters = false;\n        }\n    }\n    // Consider the commuted order.\n    if (NoRegisters) {\n      // Swap the first two operands after the intrinsic id, if present.\n      unsigned i = isCommIntrinsic ? 1 : 0;\n      std::swap(ChildVariants[i], ChildVariants[i + 1]);\n      CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n    }\n  }\n}\n\n// GenerateVariants - Generate variants.  For example, commutative patterns can\n// match multiple ways.  Add them to PatternsToMatch as well.\nvoid CodeGenDAGPatterns::GenerateVariants() {\n  LLVM_DEBUG(errs() << \"Generating instruction variants.\\n\");\n\n  // Loop over all of the patterns we've collected, checking to see if we can\n  // generate variants of the instruction, through the exploitation of\n  // identities.  This permits the target to provide aggressive matching without\n  // the .td file having to contain tons of variants of instructions.\n  //\n  // Note that this loop adds new patterns to the PatternsToMatch list, but we\n  // intentionally do not reconsider these.  Any variants of added patterns have\n  // already been added.\n  //\n  for (unsigned i = 0, e = PatternsToMatch.size(); i != e; ++i) {\n    MultipleUseVarSet DepVars;\n    std::vector<TreePatternNodePtr> Variants;\n    FindDepVars(PatternsToMatch[i].getSrcPattern(), DepVars);\n    LLVM_DEBUG(errs() << \"Dependent/multiply used variables: \");\n    LLVM_DEBUG(DumpDepVars(DepVars));\n    LLVM_DEBUG(errs() << \"\\n\");\n    GenerateVariantsOf(PatternsToMatch[i].getSrcPatternShared(), Variants,\n                       *this, DepVars);\n\n    assert(PatternsToMatch[i].getHwModeFeatures().empty() &&\n           \"HwModes should not have been expanded yet!\");\n\n    assert(!Variants.empty() && \"Must create at least original variant!\");\n    if (Variants.size() == 1) // No additional variants for this pattern.\n      continue;\n\n    LLVM_DEBUG(errs() << \"FOUND VARIANTS OF: \";\n               PatternsToMatch[i].getSrcPattern().dump(); errs() << \"\\n\");\n\n    for (unsigned v = 0, e = Variants.size(); v != e; ++v) {\n      TreePatternNodePtr Variant = Variants[v];\n\n      LLVM_DEBUG(errs() << \"  VAR#\" << v << \": \"; Variant->dump();\n                 errs() << \"\\n\");\n\n      // Scan to see if an instruction or explicit pattern already matches this.\n      bool AlreadyExists = false;\n      for (unsigned p = 0, e = PatternsToMatch.size(); p != e; ++p) {\n        // Skip if the top level predicates do not match.\n        if ((i != p) && (PatternsToMatch[i].getPredicates() !=\n                         PatternsToMatch[p].getPredicates()))\n          continue;\n        // Check to see if this variant already exists.\n        if (Variant->isIsomorphicTo(PatternsToMatch[p].getSrcPattern(),\n                                    DepVars)) {\n          LLVM_DEBUG(errs() << \"  *** ALREADY EXISTS, ignoring variant.\\n\");\n          AlreadyExists = true;\n          break;\n        }\n      }\n      // If we already have it, ignore the variant.\n      if (AlreadyExists)\n        continue;\n\n      // Otherwise, add it to the list of patterns we have.\n      PatternsToMatch.emplace_back(\n          PatternsToMatch[i].getSrcRecord(), PatternsToMatch[i].getPredicates(),\n          Variant, PatternsToMatch[i].getDstPatternShared(),\n          PatternsToMatch[i].getDstRegs(),\n          PatternsToMatch[i].getAddedComplexity(), Record::getNewUID(Records),\n          PatternsToMatch[i].getHwModeFeatures());\n    }\n\n    LLVM_DEBUG(errs() << \"\\n\");\n  }\n}\n"}, {"id": "A17F8AE78A1AFB39", "name": "llvm::TreePatternNode::getChild", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 728, "col": 3}, "end": {"line": 728, "col": 70}, "code": "  const TreePatternNodePtr &getChildShared(unsigned N) const {\n    return Children[N];\n  }\n  TreePatternNodePtr &getChildSharedPtr(unsigned N) { return Children[N]; }\n  void setChild(unsigned i, TreePatternNodePtr N) { Children[i] = N; }\n\n  /// hasChild - Return true if N is any of our children.\n  bool hasChild(const TreePatternNode *N) const {\n    for (unsigned i = 0, e = Children.size(); i != e; ++i)\n      if (Children[i].get() == N)\n        return true;\n    return false;\n  }\n\n  bool hasProperTypeByHwMode() const;\n  bool hasPossibleType() const;\n  bool setDefaultMode(unsigned Mode);\n\n  bool hasAnyPredicate() const { return !PredicateCalls.empty(); }\n\n  const std::vector<TreePredicateCall> &getPredicateCalls() const {\n    return PredicateCalls;\n  }\n  void clearPredicateCalls() { PredicateCalls.clear(); }\n  void setPredicateCalls(const std::vector<TreePredicateCall> &Calls) {\n    assert(PredicateCalls.empty() && \"Overwriting non-empty predicate list!\");\n    PredicateCalls = Calls;\n  }\n  void addPredicateCall(const TreePredicateCall &Call) {\n    assert(!Call.Fn.isAlwaysTrue() && \"Empty predicate string!\");\n    assert(!is_contained(PredicateCalls, Call) &&\n           \"predicate applied recursively\");\n    PredicateCalls.push_back(Call);\n  }\n  void addPredicateCall(const TreePredicateFn &Fn, unsigned Scope) {\n    assert((Scope != 0) == Fn.usesOperands());\n    addPredicateCall(TreePredicateCall(Fn, Scope));\n  }\n\n  Record *getTransformFn() const { return TransformFn; }\n  void setTransformFn(Record *Fn) { TransformFn = Fn; }\n\n  /// getIntrinsicInfo - If this node corresponds to an intrinsic, return the\n  /// CodeGenIntrinsic information for it, otherwise return a null pointer.\n  const CodeGenIntrinsic *getIntrinsicInfo(const CodeGenDAGPatterns &CDP) const;\n\n  /// getComplexPatternInfo - If this node corresponds to a ComplexPattern,\n  /// return the ComplexPattern information, otherwise return null.\n  const ComplexPattern *\n  getComplexPatternInfo(const CodeGenDAGPatterns &CGP) const;\n\n  /// Returns the number of MachineInstr operands that would be produced by this\n  /// node if it mapped directly to an output Instruction's\n  /// operand. ComplexPattern specifies this explicitly; MIOperandInfo gives it\n  /// for Operands; otherwise 1.\n  unsigned getNumMIResults(const CodeGenDAGPatterns &CGP) const;\n\n  /// NodeHasProperty - Return true if this node has the specified property.\n  bool NodeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// TreeHasProperty - Return true if any node in this tree has the specified\n  /// property.\n  bool TreeHasProperty(SDNP Property, const CodeGenDAGPatterns &CGP) const;\n\n  /// isCommutativeIntrinsic - Return true if the node is an intrinsic which is\n  /// marked isCommutative.\n  bool isCommutativeIntrinsic(const CodeGenDAGPatterns &CDP) const;\n\n  void setGISelFlagsRecord(const Record *R) { GISelFlags = R; }\n  const Record *getGISelFlagsRecord() const { return GISelFlags; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\npublic: // Higher level manipulation routines.\n  /// clone - Return a new copy of this tree.\n  ///\n  TreePatternNodePtr clone() const;\n\n  /// RemoveAllTypes - Recursively strip all the types of this tree.\n  void RemoveAllTypes();\n\n  /// isIsomorphicTo - Return true if this node is recursively isomorphic to\n  /// the specified node.  For this comparison, all of the state of the node\n  /// is considered, except for the assigned name.  Nodes with differing names\n  /// that are otherwise identical are considered isomorphic.\n  bool isIsomorphicTo(const TreePatternNode &N,\n                      const MultipleUseVarSet &DepVars) const;\n\n  /// SubstituteFormalArguments - Replace the formal arguments in this tree\n  /// with actual values specified by ArgMap.\n  void\n  SubstituteFormalArguments(std::map<std::string, TreePatternNodePtr> &ArgMap);\n\n  /// InlinePatternFragments - If \\p T pattern refers to any pattern\n  /// fragments, return the set of inlined versions (this can be more than\n  /// one if a PatFrags record has multiple alternatives).\n  void InlinePatternFragments(TreePattern &TP,\n                              std::vector<TreePatternNodePtr> &OutAlternatives);\n\n  /// ApplyTypeConstraints - Apply all of the type constraints relevant to\n  /// this node and its children in the tree.  This returns true if it makes a\n  /// change, false otherwise.  If a type contradiction is found, flag an error.\n  bool ApplyTypeConstraints(TreePattern &TP, bool NotRegisters);\n\n  /// UpdateNodeType - Set the node type of N to VT if VT contains\n  /// information.  If N already contains a conflicting type, then flag an\n  /// error.  This returns true if any information was updated.\n  ///\n  bool UpdateNodeType(unsigned ResNo, const TypeSetByHwMode &InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, MVT::SimpleValueType InTy,\n                      TreePattern &TP);\n  bool UpdateNodeType(unsigned ResNo, ValueTypeByHwMode InTy, TreePattern &TP);\n\n  // Update node type with types inferred from an instruction operand or result\n  // def from the ins/outs lists.\n  // Return true if the type changed.\n  bool UpdateNodeTypeFromInst(unsigned ResNo, Record *Operand, TreePattern &TP);\n\n  /// ContainsUnresolvedType - Return true if this tree contains any\n  /// unresolved types.\n  bool ContainsUnresolvedType(TreePattern &TP) const;\n\n  /// canPatternMatch - If it is impossible for this pattern to match on this\n  /// target, fill in Reason and return false.  Otherwise, return true.\n  bool canPatternMatch(std::string &Reason, const CodeGenDAGPatterns &CDP);\n};\n\ninline raw_ostream &operator<<(raw_ostream &OS, const TreePatternNode &TPN) {\n  TPN.print(OS);\n  return OS;\n}\n\n/// TreePattern - Represent a pattern, used for instructions, pattern\n/// fragments, etc.\n///\nclass TreePattern {\n  /// Trees - The list of pattern trees which corresponds to this pattern.\n  /// Note that PatFrag's only have a single tree.\n  ///\n  std::vector<TreePatternNodePtr> Trees;\n\n  /// NamedNodes - This is all of the nodes that have names in the trees in this\n  /// pattern.\n  StringMap<SmallVector<TreePatternNode *, 1>> NamedNodes;\n\n  /// TheRecord - The actual TableGen record corresponding to this pattern.\n  ///\n  Record *TheRecord;\n\n  /// Args - This is a list of all of the arguments to this pattern (for\n  /// PatFrag patterns), which are the 'node' markers in this pattern.\n  std::vector<std::string> Args;\n\n  /// CDP - the top-level object coordinating this madness.\n  ///\n  CodeGenDAGPatterns &CDP;\n\n  /// isInputPattern - True if this is an input pattern, something to match.\n  /// False if this is an output pattern, something to emit.\n  bool isInputPattern;\n\n  /// hasError - True if the currently processed nodes have unresolvable types\n  /// or other non-fatal errors\n  bool HasError;\n\n  /// It's important that the usage of operands in ComplexPatterns is\n  /// consistent: each named operand can be defined by at most one\n  /// ComplexPattern. This records the ComplexPattern instance and the operand\n  /// number for each operand encountered in a ComplexPattern to aid in that\n  /// check.\n  StringMap<std::pair<Record *, unsigned>> ComplexPatternOperands;\n\n  TypeInfer Infer;\n\npublic:\n  /// TreePattern constructor - Parse the specified DagInits into the\n  /// current record.\n  TreePattern(Record *TheRec, ListInit *RawPat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, DagInit *Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n  TreePattern(Record *TheRec, TreePatternNodePtr Pat, bool isInput,\n              CodeGenDAGPatterns &ise);\n\n  /// getTrees - Return the tree patterns which corresponds to this pattern.\n  ///\n  const std::vector<TreePatternNodePtr> &getTrees() const { return Trees; }\n  unsigned getNumTrees() const { return Trees.size(); }\n  const TreePatternNodePtr &getTree(unsigned i) const { return Trees[i]; }\n  void setTree(unsigned i, TreePatternNodePtr Tree) { Trees[i] = Tree; }\n  const TreePatternNodePtr &getOnlyTree() const {\n    assert(Trees.size() == 1 && \"Doesn't have exactly one pattern!\");\n    return Trees[0];\n  }\n\n  const StringMap<SmallVector<TreePatternNode *, 1>> &getNamedNodesMap() {\n    if (NamedNodes.empty())\n      ComputeNamedNodes();\n    return NamedNodes;\n  }\n\n  /// getRecord - Return the actual TableGen record corresponding to this\n  /// pattern.\n  ///\n  Record *getRecord() const { return TheRecord; }\n\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "6EF0AC47AE4C4498", "name": "getInstructionsInTree", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.cpp", "start": {"line": 3726, "col": 1}, "end": {"line": 3734, "col": 1}, "code": "                                  SmallVectorImpl<Record *> &Instrs) {\n  if (Tree.isLeaf())\n    return;\n  if (Tree.getOperator()->isSubClassOf(\"Instruction\"))\n    Instrs.push_back(Tree.getOperator());\n  for (unsigned i = 0, e = Tree.getNumChildren(); i != e; ++i)\n    getInstructionsInTree(Tree.getChild(i), Instrs);\n}\n\n/// Check the class of a pattern leaf node against the instruction operand it\n/// represents.\nstatic bool checkOperandClass(CGIOperandList::OperandInfo &OI, Record *Leaf) {\n  if (OI.Rec == Leaf)\n    return true;\n\n  // Allow direct value types to be used in instruction set patterns.\n  // The type will be checked later.\n  if (Leaf->isSubClassOf(\"ValueType\"))\n    return true;\n\n  // Patterns can also be ComplexPattern instances.\n  if (Leaf->isSubClassOf(\"ComplexPattern\"))\n    return true;\n\n  return false;\n}\n\nvoid CodeGenDAGPatterns::parseInstructionPattern(CodeGenInstruction &CGI,\n                                                 ListInit *Pat,\n                                                 DAGInstMap &DAGInsts) {\n\n  assert(!DAGInsts.count(CGI.TheDef) && \"Instruction already parsed!\");\n\n  // Parse the instruction.\n  TreePattern I(CGI.TheDef, Pat, true, *this);\n\n  // InstInputs - Keep track of all of the inputs of the instruction, along\n  // with the record they are declared as.\n  std::map<std::string, TreePatternNodePtr> InstInputs;\n\n  // InstResults - Keep track of all the virtual registers that are 'set'\n  // in the instruction, including what reg class they are.\n  MapVector<std::string, TreePatternNodePtr, std::map<std::string, unsigned>>\n      InstResults;\n\n  std::vector<Record *> InstImpResults;\n\n  // Verify that the top-level forms in the instruction are of void type, and\n  // fill in the InstResults map.\n  SmallString<32> TypesString;\n  for (unsigned j = 0, e = I.getNumTrees(); j != e; ++j) {\n    TypesString.clear();\n    TreePatternNodePtr Pat = I.getTree(j);\n    if (Pat->getNumTypes() != 0) {\n      raw_svector_ostream OS(TypesString);\n      ListSeparator LS;\n      for (unsigned k = 0, ke = Pat->getNumTypes(); k != ke; ++k) {\n        OS << LS;\n        Pat->getExtType(k).writeToStream(OS);\n      }\n      I.error(\"Top-level forms in instruction pattern should have\"\n              \" void types, has types \" +\n              OS.str());\n    }\n\n    // Find inputs and outputs, and verify the structure of the uses/defs.\n    FindPatternInputsAndOutputs(I, Pat, InstInputs, InstResults,\n                                InstImpResults);\n  }\n\n  // Now that we have inputs and outputs of the pattern, inspect the operands\n  // list for the instruction.  This determines the order that operands are\n  // added to the machine instruction the node corresponds to.\n  unsigned NumResults = InstResults.size();\n\n  // Parse the operands list from the (ops) list, validating it.\n  assert(I.getArgList().empty() && \"Args list should still be empty here!\");\n\n  // Check that all of the results occur first in the list.\n  std::vector<Record *> Results;\n  std::vector<unsigned> ResultIndices;\n  SmallVector<TreePatternNodePtr, 2> ResNodes;\n  for (unsigned i = 0; i != NumResults; ++i) {\n    if (i == CGI.Operands.size()) {\n      const std::string &OpName =\n          llvm::find_if(\n              InstResults,\n              [](const std::pair<std::string, TreePatternNodePtr> &P) {\n                return P.second;\n              })\n              ->first;\n\n      I.error(\"'\" + OpName + \"' set but does not appear in operand list!\");\n    }\n\n    const std::string &OpName = CGI.Operands[i].Name;\n\n    // Check that it exists in InstResults.\n    auto InstResultIter = InstResults.find(OpName);\n    if (InstResultIter == InstResults.end() || !InstResultIter->second)\n      I.error(\"Operand $\" + OpName + \" does not exist in operand list!\");\n\n    TreePatternNodePtr RNode = InstResultIter->second;\n    Record *R = cast<DefInit>(RNode->getLeafValue())->getDef();\n    ResNodes.push_back(std::move(RNode));\n    if (!R)\n      I.error(\"Operand $\" + OpName +\n              \" should be a set destination: all \"\n              \"outputs must occur before inputs in operand list!\");\n\n    if (!checkOperandClass(CGI.Operands[i], R))\n      I.error(\"Operand $\" + OpName + \" class mismatch!\");\n\n    // Remember the return type.\n    Results.push_back(CGI.Operands[i].Rec);\n\n    // Remember the result index.\n    ResultIndices.push_back(std::distance(InstResults.begin(), InstResultIter));\n\n    // Okay, this one checks out.\n    InstResultIter->second = nullptr;\n  }\n\n  // Loop over the inputs next.\n  std::vector<TreePatternNodePtr> ResultNodeOperands;\n  std::vector<Record *> Operands;\n  for (unsigned i = NumResults, e = CGI.Operands.size(); i != e; ++i) {\n    CGIOperandList::OperandInfo &Op = CGI.Operands[i];\n    const std::string &OpName = Op.Name;\n    if (OpName.empty())\n      I.error(\"Operand #\" + Twine(i) + \" in operands list has no name!\");\n\n    if (!InstInputs.count(OpName)) {\n      // If this is an operand with a DefaultOps set filled in, we can ignore\n      // this.  When we codegen it, we will do so as always executed.\n      if (Op.Rec->isSubClassOf(\"OperandWithDefaultOps\")) {\n        // Does it have a non-empty DefaultOps field?  If so, ignore this\n        // operand.\n        if (!getDefaultOperand(Op.Rec).DefaultOps.empty())\n          continue;\n      }\n      I.error(\"Operand $\" + OpName +\n              \" does not appear in the instruction pattern\");\n    }\n    TreePatternNodePtr InVal = InstInputs[OpName];\n    InstInputs.erase(OpName); // It occurred, remove from map.\n\n    if (InVal->isLeaf() && isa<DefInit>(InVal->getLeafValue())) {\n      Record *InRec = cast<DefInit>(InVal->getLeafValue())->getDef();\n      if (!checkOperandClass(Op, InRec))\n        I.error(\"Operand $\" + OpName +\n                \"'s register class disagrees\"\n                \" between the operand and pattern\");\n    }\n    Operands.push_back(Op.Rec);\n\n    // Construct the result for the dest-pattern operand list.\n    TreePatternNodePtr OpNode = InVal->clone();\n\n    // No predicate is useful on the result.\n    OpNode->clearPredicateCalls();\n\n    // Promote the xform function to be an explicit node if set.\n    if (Record *Xform = OpNode->getTransformFn()) {\n      OpNode->setTransformFn(nullptr);\n      std::vector<TreePatternNodePtr> Children;\n      Children.push_back(OpNode);\n      OpNode = makeIntrusiveRefCnt<TreePatternNode>(Xform, std::move(Children),\n                                                    OpNode->getNumTypes());\n    }\n\n    ResultNodeOperands.push_back(std::move(OpNode));\n  }\n\n  if (!InstInputs.empty())\n    I.error(\"Input operand $\" + InstInputs.begin()->first +\n            \" occurs in pattern but not in operands list!\");\n\n  TreePatternNodePtr ResultPattern = makeIntrusiveRefCnt<TreePatternNode>(\n      I.getRecord(), std::move(ResultNodeOperands),\n      GetNumNodeResults(I.getRecord(), *this));\n  // Copy fully inferred output node types to instruction result pattern.\n  for (unsigned i = 0; i != NumResults; ++i) {\n    assert(ResNodes[i]->getNumTypes() == 1 && \"FIXME: Unhandled\");\n    ResultPattern->setType(i, ResNodes[i]->getExtType(0));\n    ResultPattern->setResultIndex(i, ResultIndices[i]);\n  }\n\n  // FIXME: Assume only the first tree is the pattern. The others are clobber\n  // nodes.\n  TreePatternNodePtr Pattern = I.getTree(0);\n  TreePatternNodePtr SrcPattern;\n  if (Pattern->getOperator()->getName() == \"set\") {\n    SrcPattern = Pattern->getChild(Pattern->getNumChildren() - 1).clone();\n  } else {\n    // Not a set (store or something?)\n    SrcPattern = Pattern;\n  }\n\n  // Create and insert the instruction.\n  // FIXME: InstImpResults should not be part of DAGInstruction.\n  Record *R = I.getRecord();\n  DAGInsts.try_emplace(R, std::move(Results), std::move(Operands),\n                       std::move(InstImpResults), SrcPattern, ResultPattern);\n\n  LLVM_DEBUG(I.dump());\n}\n\n/// ParseInstructions - Parse all of the instructions, inlining and resolving\n/// any fragments involved.  This populates the Instructions list with fully\n/// resolved instructions.\nvoid CodeGenDAGPatterns::ParseInstructions() {\n  std::vector<Record *> Instrs =\n      Records.getAllDerivedDefinitions(\"Instruction\");\n\n  for (Record *Instr : Instrs) {\n    ListInit *LI = nullptr;\n\n    if (isa<ListInit>(Instr->getValueInit(\"Pattern\")))\n      LI = Instr->getValueAsListInit(\"Pattern\");\n\n    // If there is no pattern, only collect minimal information about the\n    // instruction for its operand list.  We have to assume that there is one\n    // result, as we have no detailed info. A pattern which references the\n    // null_frag operator is as-if no pattern were specified. Normally this\n    // is from a multiclass expansion w/ a SDPatternOperator passed in as\n    // null_frag.\n    if (!LI || LI->empty() || hasNullFragReference(LI)) {\n      std::vector<Record *> Results;\n      std::vector<Record *> Operands;\n\n      CodeGenInstruction &InstInfo = Target.getInstruction(Instr);\n\n      if (InstInfo.Operands.size() != 0) {\n        for (unsigned j = 0, e = InstInfo.Operands.NumDefs; j < e; ++j)\n          Results.push_back(InstInfo.Operands[j].Rec);\n\n        // The rest are inputs.\n        for (unsigned j = InstInfo.Operands.NumDefs,\n                      e = InstInfo.Operands.size();\n             j < e; ++j)\n          Operands.push_back(InstInfo.Operands[j].Rec);\n      }\n\n      // Create and insert the instruction.\n      Instructions.try_emplace(Instr, std::move(Results), std::move(Operands),\n                               std::vector<Record *>());\n      continue; // no pattern.\n    }\n\n    CodeGenInstruction &CGI = Target.getInstruction(Instr);\n    parseInstructionPattern(CGI, LI, Instructions);\n  }\n\n  // If we can, convert the instructions to be patterns that are matched!\n  for (auto &Entry : Instructions) {\n    Record *Instr = Entry.first;\n    DAGInstruction &TheInst = Entry.second;\n    TreePatternNodePtr SrcPattern = TheInst.getSrcPattern();\n    TreePatternNodePtr ResultPattern = TheInst.getResultPattern();\n\n    if (SrcPattern && ResultPattern) {\n      TreePattern Pattern(Instr, SrcPattern, true, *this);\n      TreePattern Result(Instr, ResultPattern, false, *this);\n      ParseOnePattern(Instr, Pattern, Result, TheInst.getImpResults());\n    }\n  }\n}\n\ntypedef std::pair<TreePatternNode *, unsigned> NameRecord;\n\nstatic void FindNames(TreePatternNode &P,\n                      std::map<std::string, NameRecord> &Names,\n                      TreePattern *PatternTop) {\n  if (!P.getName().empty()) {\n    NameRecord &Rec = Names[P.getName()];\n    // If this is the first instance of the name, remember the node.\n    if (Rec.second++ == 0)\n      Rec.first = &P;\n    else if (Rec.first->getExtTypes() != P.getExtTypes())\n      PatternTop->error(\"repetition of value: $\" + P.getName() +\n                        \" where different uses have different types!\");\n  }\n\n  if (!P.isLeaf()) {\n    for (unsigned i = 0, e = P.getNumChildren(); i != e; ++i)\n      FindNames(P.getChild(i), Names, PatternTop);\n  }\n}\n\nvoid CodeGenDAGPatterns::AddPatternToMatch(TreePattern *Pattern,\n                                           PatternToMatch &&PTM) {\n  // Do some sanity checking on the pattern we're about to match.\n  std::string Reason;\n  if (!PTM.getSrcPattern().canPatternMatch(Reason, *this)) {\n    PrintWarning(Pattern->getRecord()->getLoc(),\n                 Twine(\"Pattern can never match: \") + Reason);\n    return;\n  }\n\n  // If the source pattern's root is a complex pattern, that complex pattern\n  // must specify the nodes it can potentially match.\n  if (const ComplexPattern *CP =\n          PTM.getSrcPattern().getComplexPatternInfo(*this))\n    if (CP->getRootNodes().empty())\n      Pattern->error(\"ComplexPattern at root must specify list of opcodes it\"\n                     \" could match\");\n\n  // Find all of the named values in the input and output, ensure they have the\n  // same type.\n  std::map<std::string, NameRecord> SrcNames, DstNames;\n  FindNames(PTM.getSrcPattern(), SrcNames, Pattern);\n  FindNames(PTM.getDstPattern(), DstNames, Pattern);\n\n  // Scan all of the named values in the destination pattern, rejecting them if\n  // they don't exist in the input pattern.\n  for (const auto &Entry : DstNames) {\n    if (SrcNames[Entry.first].first == nullptr)\n      Pattern->error(\"Pattern has input without matching name in output: $\" +\n                     Entry.first);\n  }\n\n  // Scan all of the named values in the source pattern, rejecting them if the\n  // name isn't used in the dest, and isn't used to tie two values together.\n  for (const auto &Entry : SrcNames)\n    if (DstNames[Entry.first].first == nullptr &&\n        SrcNames[Entry.first].second == 1)\n      Pattern->error(\"Pattern has dead named input: $\" + Entry.first);\n\n  PatternsToMatch.push_back(std::move(PTM));\n}\n\nvoid CodeGenDAGPatterns::InferInstructionFlags() {\n  ArrayRef<const CodeGenInstruction *> Instructions =\n      Target.getInstructionsByEnumValue();\n\n  unsigned Errors = 0;\n\n  // Try to infer flags from all patterns in PatternToMatch.  These include\n  // both the primary instruction patterns (which always come first) and\n  // patterns defined outside the instruction.\n  for (const PatternToMatch &PTM : ptms()) {\n    // We can only infer from single-instruction patterns, otherwise we won't\n    // know which instruction should get the flags.\n    SmallVector<Record *, 8> PatInstrs;\n    getInstructionsInTree(PTM.getDstPattern(), PatInstrs);\n    if (PatInstrs.size() != 1)\n      continue;\n\n    // Get the single instruction.\n    CodeGenInstruction &InstInfo = Target.getInstruction(PatInstrs.front());\n\n    // Only infer properties from the first pattern. We'll verify the others.\n    if (InstInfo.InferredFrom)\n      continue;\n\n    InstAnalyzer PatInfo(*this);\n    PatInfo.Analyze(PTM);\n    Errors += InferFromPattern(InstInfo, PatInfo, PTM.getSrcRecord());\n  }\n\n  if (Errors)\n    PrintFatalError(\"pattern conflicts\");\n\n  // If requested by the target, guess any undefined properties.\n  if (Target.guessInstructionProperties()) {\n    for (unsigned i = 0, e = Instructions.size(); i != e; ++i) {\n      CodeGenInstruction *InstInfo =\n          const_cast<CodeGenInstruction *>(Instructions[i]);\n      if (InstInfo->InferredFrom)\n        continue;\n      // The mayLoad and mayStore flags default to false.\n      // Conservatively assume hasSideEffects if it wasn't explicit.\n      if (InstInfo->hasSideEffects_Unset)\n        InstInfo->hasSideEffects = true;\n    }\n    return;\n  }\n\n  // Complain about any flags that are still undefined.\n  for (unsigned i = 0, e = Instructions.size(); i != e; ++i) {\n    CodeGenInstruction *InstInfo =\n        const_cast<CodeGenInstruction *>(Instructions[i]);\n    if (InstInfo->InferredFrom)\n      continue;\n    if (InstInfo->hasSideEffects_Unset)\n      PrintError(InstInfo->TheDef->getLoc(),\n                 \"Can't infer hasSideEffects from patterns\");\n    if (InstInfo->mayStore_Unset)\n      PrintError(InstInfo->TheDef->getLoc(),\n                 \"Can't infer mayStore from patterns\");\n    if (InstInfo->mayLoad_Unset)\n      PrintError(InstInfo->TheDef->getLoc(),\n                 \"Can't infer mayLoad from patterns\");\n  }\n}\n\n/// Verify instruction flags against pattern node properties.\nvoid CodeGenDAGPatterns::VerifyInstructionFlags() {\n  unsigned Errors = 0;\n  for (const PatternToMatch &PTM : ptms()) {\n    SmallVector<Record *, 8> Instrs;\n    getInstructionsInTree(PTM.getDstPattern(), Instrs);\n    if (Instrs.empty())\n      continue;\n\n    // Count the number of instructions with each flag set.\n    unsigned NumSideEffects = 0;\n    unsigned NumStores = 0;\n    unsigned NumLoads = 0;\n    for (const Record *Instr : Instrs) {\n      const CodeGenInstruction &InstInfo = Target.getInstruction(Instr);\n      NumSideEffects += InstInfo.hasSideEffects;\n      NumStores += InstInfo.mayStore;\n      NumLoads += InstInfo.mayLoad;\n    }\n\n    // Analyze the source pattern.\n    InstAnalyzer PatInfo(*this);\n    PatInfo.Analyze(PTM);\n\n    // Collect error messages.\n    SmallVector<std::string, 4> Msgs;\n\n    // Check for missing flags in the output.\n    // Permit extra flags for now at least.\n    if (PatInfo.hasSideEffects && !NumSideEffects)\n      Msgs.push_back(\"pattern has side effects, but hasSideEffects isn't set\");\n\n    // Don't verify store flags on instructions with side effects. At least for\n    // intrinsics, side effects implies mayStore.\n    if (!PatInfo.hasSideEffects && PatInfo.mayStore && !NumStores)\n      Msgs.push_back(\"pattern may store, but mayStore isn't set\");\n\n    // Similarly, mayStore implies mayLoad on intrinsics.\n    if (!PatInfo.mayStore && PatInfo.mayLoad && !NumLoads)\n      Msgs.push_back(\"pattern may load, but mayLoad isn't set\");\n\n    // Print error messages.\n    if (Msgs.empty())\n      continue;\n    ++Errors;\n\n    for (const std::string &Msg : Msgs)\n      PrintError(\n          PTM.getSrcRecord()->getLoc(),\n          Twine(Msg) + \" on the \" +\n              (Instrs.size() == 1 ? \"instruction\" : \"output instructions\"));\n    // Provide the location of the relevant instruction definitions.\n    for (const Record *Instr : Instrs) {\n      if (Instr != PTM.getSrcRecord())\n        PrintError(Instr->getLoc(), \"defined here\");\n      const CodeGenInstruction &InstInfo = Target.getInstruction(Instr);\n      if (InstInfo.InferredFrom && InstInfo.InferredFrom != InstInfo.TheDef &&\n          InstInfo.InferredFrom != PTM.getSrcRecord())\n        PrintError(InstInfo.InferredFrom->getLoc(), \"inferred from pattern\");\n    }\n  }\n  if (Errors)\n    PrintFatalError(\"Errors in DAG patterns\");\n}\n\n/// Given a pattern result with an unresolved type, see if we can find one\n/// instruction with an unresolved result type.  Force this result type to an\n/// arbitrary element if it's possible types to converge results.\nstatic bool ForceArbitraryInstResultType(TreePatternNode &N, TreePattern &TP) {\n  if (N.isLeaf())\n    return false;\n\n  // Analyze children.\n  for (unsigned i = 0, e = N.getNumChildren(); i != e; ++i)\n    if (ForceArbitraryInstResultType(N.getChild(i), TP))\n      return true;\n\n  if (!N.getOperator()->isSubClassOf(\"Instruction\"))\n    return false;\n\n  // If this type is already concrete or completely unknown we can't do\n  // anything.\n  TypeInfer &TI = TP.getInfer();\n  for (unsigned i = 0, e = N.getNumTypes(); i != e; ++i) {\n    if (N.getExtType(i).empty() || TI.isConcrete(N.getExtType(i), false))\n      continue;\n\n    // Otherwise, force its type to an arbitrary choice.\n    if (TI.forceArbitrary(N.getExtType(i)))\n      return true;\n  }\n\n  return false;\n}\n\n// Promote xform function to be an explicit node wherever set.\nstatic TreePatternNodePtr PromoteXForms(TreePatternNodePtr N) {\n  if (Record *Xform = N->getTransformFn()) {\n    N->setTransformFn(nullptr);\n    std::vector<TreePatternNodePtr> Children;\n    Children.push_back(PromoteXForms(N));\n    return makeIntrusiveRefCnt<TreePatternNode>(Xform, std::move(Children),\n                                                N->getNumTypes());\n  }\n\n  if (!N->isLeaf())\n    for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i) {\n      TreePatternNodePtr Child = N->getChildShared(i);\n      N->setChild(i, PromoteXForms(Child));\n    }\n  return N;\n}\n\nvoid CodeGenDAGPatterns::ParseOnePattern(\n    Record *TheDef, TreePattern &Pattern, TreePattern &Result,\n    const std::vector<Record *> &InstImpResults) {\n\n  // Inline pattern fragments and expand multiple alternatives.\n  Pattern.InlinePatternFragments();\n  Result.InlinePatternFragments();\n\n  if (Result.getNumTrees() != 1)\n    Result.error(\"Cannot use multi-alternative fragments in result pattern!\");\n\n  // Infer types.\n  bool IterateInference;\n  bool InferredAllPatternTypes, InferredAllResultTypes;\n  do {\n    // Infer as many types as possible.  If we cannot infer all of them, we\n    // can never do anything with this pattern: report it to the user.\n    InferredAllPatternTypes =\n        Pattern.InferAllTypes(&Pattern.getNamedNodesMap());\n\n    // Infer as many types as possible.  If we cannot infer all of them, we\n    // can never do anything with this pattern: report it to the user.\n    InferredAllResultTypes = Result.InferAllTypes(&Pattern.getNamedNodesMap());\n\n    IterateInference = false;\n\n    // Apply the type of the result to the source pattern.  This helps us\n    // resolve cases where the input type is known to be a pointer type (which\n    // is considered resolved), but the result knows it needs to be 32- or\n    // 64-bits.  Infer the other way for good measure.\n    for (const auto &T : Pattern.getTrees())\n      for (unsigned i = 0, e = std::min(Result.getOnlyTree()->getNumTypes(),\n                                        T->getNumTypes());\n           i != e; ++i) {\n        IterateInference |=\n            T->UpdateNodeType(i, Result.getOnlyTree()->getExtType(i), Result);\n        IterateInference |=\n            Result.getOnlyTree()->UpdateNodeType(i, T->getExtType(i), Result);\n      }\n\n    // If our iteration has converged and the input pattern's types are fully\n    // resolved but the result pattern is not fully resolved, we may have a\n    // situation where we have two instructions in the result pattern and\n    // the instructions require a common register class, but don't care about\n    // what actual MVT is used.  This is actually a bug in our modelling:\n    // output patterns should have register classes, not MVTs.\n    //\n    // In any case, to handle this, we just go through and disambiguate some\n    // arbitrary types to the result pattern's nodes.\n    if (!IterateInference && InferredAllPatternTypes && !InferredAllResultTypes)\n      IterateInference =\n          ForceArbitraryInstResultType(*Result.getTree(0), Result);\n  } while (IterateInference);\n\n  // Verify that we inferred enough types that we can do something with the\n  // pattern and result.  If these fire the user has to add type casts.\n  if (!InferredAllPatternTypes)\n    Pattern.error(\"Could not infer all types in pattern!\");\n  if (!InferredAllResultTypes) {\n    Pattern.dump();\n    Result.error(\"Could not infer all types in pattern result!\");\n  }\n\n  // Promote xform function to be an explicit node wherever set.\n  TreePatternNodePtr DstShared = PromoteXForms(Result.getOnlyTree());\n\n  TreePattern Temp(Result.getRecord(), DstShared, false, *this);\n  Temp.InferAllTypes();\n\n  ListInit *Preds = TheDef->getValueAsListInit(\"Predicates\");\n  int Complexity = TheDef->getValueAsInt(\"AddedComplexity\");\n\n  if (PatternRewriter)\n    PatternRewriter(&Pattern);\n\n  // A pattern may end up with an \"impossible\" type, i.e. a situation\n  // where all types have been eliminated for some node in this pattern.\n  // This could occur for intrinsics that only make sense for a specific\n  // value type, and use a specific register class. If, for some mode,\n  // that register class does not accept that type, the type inference\n  // will lead to a contradiction, which is not an error however, but\n  // a sign that this pattern will simply never match.\n  if (Temp.getOnlyTree()->hasPossibleType()) {\n    for (const auto &T : Pattern.getTrees()) {\n      if (T->hasPossibleType())\n        AddPatternToMatch(&Pattern,\n                          PatternToMatch(TheDef, Preds, T, Temp.getOnlyTree(),\n                                         InstImpResults, Complexity,\n                                         TheDef->getID()));\n    }\n  } else {\n    // Show a message about a dropped pattern with some info to make it\n    // easier to identify it in the .td files.\n    LLVM_DEBUG({\n      dbgs() << \"Dropping: \";\n      Pattern.dump();\n      Temp.getOnlyTree()->dump();\n      dbgs() << \"\\n\";\n    });\n  }\n}\n\nvoid CodeGenDAGPatterns::ParsePatterns() {\n  std::vector<Record *> Patterns = Records.getAllDerivedDefinitions(\"Pattern\");\n\n  for (Record *CurPattern : Patterns) {\n    DagInit *Tree = CurPattern->getValueAsDag(\"PatternToMatch\");\n\n    // If the pattern references the null_frag, there's nothing to do.\n    if (hasNullFragReference(Tree))\n      continue;\n\n    TreePattern Pattern(CurPattern, Tree, true, *this);\n\n    ListInit *LI = CurPattern->getValueAsListInit(\"ResultInstrs\");\n    if (LI->empty())\n      continue; // no pattern.\n\n    // Parse the instruction.\n    TreePattern Result(CurPattern, LI, false, *this);\n\n    if (Result.getNumTrees() != 1)\n      Result.error(\"Cannot handle instructions producing instructions \"\n                   \"with temporaries yet!\");\n\n    // Validate that the input pattern is correct.\n    std::map<std::string, TreePatternNodePtr> InstInputs;\n    MapVector<std::string, TreePatternNodePtr, std::map<std::string, unsigned>>\n        InstResults;\n    std::vector<Record *> InstImpResults;\n    for (unsigned j = 0, ee = Pattern.getNumTrees(); j != ee; ++j)\n      FindPatternInputsAndOutputs(Pattern, Pattern.getTree(j), InstInputs,\n                                  InstResults, InstImpResults);\n\n    ParseOnePattern(CurPattern, Pattern, Result, InstImpResults);\n  }\n}\n\nstatic void collectModes(std::set<unsigned> &Modes, const TreePatternNode &N) {\n  for (const TypeSetByHwMode &VTS : N.getExtTypes())\n    for (const auto &I : VTS)\n      Modes.insert(I.first);\n\n  for (unsigned i = 0, e = N.getNumChildren(); i != e; ++i)\n    collectModes(Modes, N.getChild(i));\n}\n\nvoid CodeGenDAGPatterns::ExpandHwModeBasedTypes() {\n  const CodeGenHwModes &CGH = getTargetInfo().getHwModes();\n  if (CGH.getNumModeIds() == 1)\n    return;\n\n  std::vector<PatternToMatch> Copy;\n  PatternsToMatch.swap(Copy);\n\n  auto AppendPattern = [this](PatternToMatch &P, unsigned Mode,\n                              StringRef Check) {\n    TreePatternNodePtr NewSrc = P.getSrcPattern().clone();\n    TreePatternNodePtr NewDst = P.getDstPattern().clone();\n    if (!NewSrc->setDefaultMode(Mode) || !NewDst->setDefaultMode(Mode)) {\n      return;\n    }\n\n    PatternsToMatch.emplace_back(P.getSrcRecord(), P.getPredicates(),\n                                 std::move(NewSrc), std::move(NewDst),\n                                 P.getDstRegs(), P.getAddedComplexity(),\n                                 Record::getNewUID(Records), Check);\n  };\n\n  for (PatternToMatch &P : Copy) {\n    const TreePatternNode *SrcP = nullptr, *DstP = nullptr;\n    if (P.getSrcPattern().hasProperTypeByHwMode())\n      SrcP = &P.getSrcPattern();\n    if (P.getDstPattern().hasProperTypeByHwMode())\n      DstP = &P.getDstPattern();\n    if (!SrcP && !DstP) {\n      PatternsToMatch.push_back(P);\n      continue;\n    }\n\n    std::set<unsigned> Modes;\n    if (SrcP)\n      collectModes(Modes, *SrcP);\n    if (DstP)\n      collectModes(Modes, *DstP);\n\n    // The predicate for the default mode needs to be constructed for each\n    // pattern separately.\n    // Since not all modes must be present in each pattern, if a mode m is\n    // absent, then there is no point in constructing a check for m. If such\n    // a check was created, it would be equivalent to checking the default\n    // mode, except not all modes' predicates would be a part of the checking\n    // code. The subsequently generated check for the default mode would then\n    // have the exact same patterns, but a different predicate code. To avoid\n    // duplicated patterns with different predicate checks, construct the\n    // default check as a negation of all predicates that are actually present\n    // in the source/destination patterns.\n    SmallString<128> DefaultCheck;\n\n    for (unsigned M : Modes) {\n      if (M == DefaultMode)\n        continue;\n\n      // Fill the map entry for this mode.\n      const HwMode &HM = CGH.getMode(M);\n      AppendPattern(P, M, HM.Predicates);\n\n      // Add negations of the HM's predicates to the default predicate.\n      if (!DefaultCheck.empty())\n        DefaultCheck += \" && \";\n      DefaultCheck += \"!(\";\n      DefaultCheck += HM.Predicates;\n      DefaultCheck += \")\";\n    }\n\n    bool HasDefault = Modes.count(DefaultMode);\n    if (HasDefault)\n      AppendPattern(P, DefaultMode, DefaultCheck);\n  }\n}\n\n/// Dependent variable map for CodeGenDAGPattern variant generation\ntypedef StringMap<int> DepVarMap;\n\nstatic void FindDepVarsOf(TreePatternNode &N, DepVarMap &DepMap) {\n  if (N.isLeaf()) {\n    if (N.hasName() && isa<DefInit>(N.getLeafValue()))\n      DepMap[N.getName()]++;\n  } else {\n    for (size_t i = 0, e = N.getNumChildren(); i != e; ++i)\n      FindDepVarsOf(N.getChild(i), DepMap);\n  }\n}\n\n/// Find dependent variables within child patterns\nstatic void FindDepVars(TreePatternNode &N, MultipleUseVarSet &DepVars) {\n  DepVarMap depcounts;\n  FindDepVarsOf(N, depcounts);\n  for (const auto &Pair : depcounts) {\n    if (Pair.getValue() > 1)\n      DepVars.insert(Pair.getKey());\n  }\n}\n\n#ifndef NDEBUG\n/// Dump the dependent variable set:\nstatic void DumpDepVars(MultipleUseVarSet &DepVars) {\n  if (DepVars.empty()) {\n    LLVM_DEBUG(errs() << \"<empty set>\");\n  } else {\n    LLVM_DEBUG(errs() << \"[ \");\n    for (const auto &DepVar : DepVars) {\n      LLVM_DEBUG(errs() << DepVar.getKey() << \" \");\n    }\n    LLVM_DEBUG(errs() << \"]\");\n  }\n}\n#endif\n\n/// CombineChildVariants - Given a bunch of permutations of each child of the\n/// 'operator' node, put them together in all possible ways.\nstatic void CombineChildVariants(\n    TreePatternNodePtr Orig,\n    const std::vector<std::vector<TreePatternNodePtr>> &ChildVariants,\n    std::vector<TreePatternNodePtr> &OutVariants, CodeGenDAGPatterns &CDP,\n    const MultipleUseVarSet &DepVars) {\n  // Make sure that each operand has at least one variant to choose from.\n  for (const auto &Variants : ChildVariants)\n    if (Variants.empty())\n      return;\n\n  // The end result is an all-pairs construction of the resultant pattern.\n  std::vector<unsigned> Idxs(ChildVariants.size());\n  bool NotDone;\n  do {\n#ifndef NDEBUG\n    LLVM_DEBUG(if (!Idxs.empty()) {\n      errs() << Orig->getOperator()->getName() << \": Idxs = [ \";\n      for (unsigned Idx : Idxs) {\n        errs() << Idx << \" \";\n      }\n      errs() << \"]\\n\";\n    });\n#endif\n    // Create the variant and add it to the output list.\n    std::vector<TreePatternNodePtr> NewChildren;\n    NewChildren.reserve(ChildVariants.size());\n    for (unsigned i = 0, e = ChildVariants.size(); i != e; ++i)\n      NewChildren.push_back(ChildVariants[i][Idxs[i]]);\n    TreePatternNodePtr R = makeIntrusiveRefCnt<TreePatternNode>(\n        Orig->getOperator(), std::move(NewChildren), Orig->getNumTypes());\n\n    // Copy over properties.\n    R->setName(Orig->getName());\n    R->setNamesAsPredicateArg(Orig->getNamesAsPredicateArg());\n    R->setPredicateCalls(Orig->getPredicateCalls());\n    R->setGISelFlagsRecord(Orig->getGISelFlagsRecord());\n    R->setTransformFn(Orig->getTransformFn());\n    for (unsigned i = 0, e = Orig->getNumTypes(); i != e; ++i)\n      R->setType(i, Orig->getExtType(i));\n\n    // If this pattern cannot match, do not include it as a variant.\n    std::string ErrString;\n    // Scan to see if this pattern has already been emitted.  We can get\n    // duplication due to things like commuting:\n    //   (and GPRC:$a, GPRC:$b) -> (and GPRC:$b, GPRC:$a)\n    // which are the same pattern.  Ignore the dups.\n    if (R->canPatternMatch(ErrString, CDP) &&\n        none_of(OutVariants, [&](TreePatternNodePtr Variant) {\n          return R->isIsomorphicTo(*Variant, DepVars);\n        }))\n      OutVariants.push_back(R);\n\n    // Increment indices to the next permutation by incrementing the\n    // indices from last index backward, e.g., generate the sequence\n    // [0, 0], [0, 1], [1, 0], [1, 1].\n    int IdxsIdx;\n    for (IdxsIdx = Idxs.size() - 1; IdxsIdx >= 0; --IdxsIdx) {\n      if (++Idxs[IdxsIdx] == ChildVariants[IdxsIdx].size())\n        Idxs[IdxsIdx] = 0;\n      else\n        break;\n    }\n    NotDone = (IdxsIdx >= 0);\n  } while (NotDone);\n}\n\n/// CombineChildVariants - A helper function for binary operators.\n///\nstatic void CombineChildVariants(TreePatternNodePtr Orig,\n                                 const std::vector<TreePatternNodePtr> &LHS,\n                                 const std::vector<TreePatternNodePtr> &RHS,\n                                 std::vector<TreePatternNodePtr> &OutVariants,\n                                 CodeGenDAGPatterns &CDP,\n                                 const MultipleUseVarSet &DepVars) {\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants;\n  ChildVariants.push_back(LHS);\n  ChildVariants.push_back(RHS);\n  CombineChildVariants(Orig, ChildVariants, OutVariants, CDP, DepVars);\n}\n\nstatic void\nGatherChildrenOfAssociativeOpcode(TreePatternNodePtr N,\n                                  std::vector<TreePatternNodePtr> &Children) {\n  assert(N->getNumChildren() == 2 &&\n         \"Associative but doesn't have 2 children!\");\n  Record *Operator = N->getOperator();\n\n  // Only permit raw nodes.\n  if (!N->getName().empty() || !N->getPredicateCalls().empty() ||\n      N->getTransformFn()) {\n    Children.push_back(N);\n    return;\n  }\n\n  if (N->getChild(0).isLeaf() || N->getChild(0).getOperator() != Operator)\n    Children.push_back(N->getChildShared(0));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(0), Children);\n\n  if (N->getChild(1).isLeaf() || N->getChild(1).getOperator() != Operator)\n    Children.push_back(N->getChildShared(1));\n  else\n    GatherChildrenOfAssociativeOpcode(N->getChildShared(1), Children);\n}\n\n/// GenerateVariantsOf - Given a pattern N, generate all permutations we can of\n/// the (potentially recursive) pattern by using algebraic laws.\n///\nstatic void GenerateVariantsOf(TreePatternNodePtr N,\n                               std::vector<TreePatternNodePtr> &OutVariants,\n                               CodeGenDAGPatterns &CDP,\n                               const MultipleUseVarSet &DepVars) {\n  // We cannot permute leaves or ComplexPattern uses.\n  if (N->isLeaf() || N->getOperator()->isSubClassOf(\"ComplexPattern\")) {\n    OutVariants.push_back(N);\n    return;\n  }\n\n  // Look up interesting info about the node.\n  const SDNodeInfo &NodeInfo = CDP.getSDNodeInfo(N->getOperator());\n\n  // If this node is associative, re-associate.\n  if (NodeInfo.hasProperty(SDNPAssociative)) {\n    // Re-associate by pulling together all of the linked operators\n    std::vector<TreePatternNodePtr> MaximalChildren;\n    GatherChildrenOfAssociativeOpcode(N, MaximalChildren);\n\n    // Only handle child sizes of 3.  Otherwise we'll end up trying too many\n    // permutations.\n    if (MaximalChildren.size() == 3) {\n      // Find the variants of all of our maximal children.\n      std::vector<TreePatternNodePtr> AVariants, BVariants, CVariants;\n      GenerateVariantsOf(MaximalChildren[0], AVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[1], BVariants, CDP, DepVars);\n      GenerateVariantsOf(MaximalChildren[2], CVariants, CDP, DepVars);\n\n      // There are only two ways we can permute the tree:\n      //   (A op B) op C    and    A op (B op C)\n      // Within these forms, we can also permute A/B/C.\n\n      // Generate legal pair permutations of A/B/C.\n      std::vector<TreePatternNodePtr> ABVariants;\n      std::vector<TreePatternNodePtr> BAVariants;\n      std::vector<TreePatternNodePtr> ACVariants;\n      std::vector<TreePatternNodePtr> CAVariants;\n      std::vector<TreePatternNodePtr> BCVariants;\n      std::vector<TreePatternNodePtr> CBVariants;\n      CombineChildVariants(N, AVariants, BVariants, ABVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, AVariants, BAVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CVariants, ACVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, AVariants, CAVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CVariants, BCVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BVariants, CBVariants, CDP, DepVars);\n\n      // Combine those into the result: (x op x) op x\n      CombineChildVariants(N, ABVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BAVariants, CVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, ACVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CAVariants, BVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BCVariants, AVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CBVariants, AVariants, OutVariants, CDP, DepVars);\n\n      // Combine those into the result: x op (x op x)\n      CombineChildVariants(N, CVariants, ABVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, CVariants, BAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, ACVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, BVariants, CAVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, BCVariants, OutVariants, CDP, DepVars);\n      CombineChildVariants(N, AVariants, CBVariants, OutVariants, CDP, DepVars);\n      return;\n    }\n  }\n\n  // Compute permutations of all children.\n  std::vector<std::vector<TreePatternNodePtr>> ChildVariants(\n      N->getNumChildren());\n  for (unsigned i = 0, e = N->getNumChildren(); i != e; ++i)\n    GenerateVariantsOf(N->getChildShared(i), ChildVariants[i], CDP, DepVars);\n\n  // Build all permutations based on how the children were formed.\n  CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n\n  // If this node is commutative, consider the commuted order.\n  bool isCommIntrinsic = N->isCommutativeIntrinsic(CDP);\n  if (NodeInfo.hasProperty(SDNPCommutative) || isCommIntrinsic) {\n    unsigned Skip = isCommIntrinsic ? 1 : 0; // First operand is intrinsic id.\n    assert(N->getNumChildren() >= (2 + Skip) &&\n           \"Commutative but doesn't have 2 children!\");\n    // Don't allow commuting children which are actually register references.\n    bool NoRegisters = true;\n    unsigned i = 0 + Skip;\n    unsigned e = 2 + Skip;\n    for (; i != e; ++i) {\n      TreePatternNode &Child = N->getChild(i);\n      if (Child.isLeaf())\n        if (DefInit *DI = dyn_cast<DefInit>(Child.getLeafValue())) {\n          Record *RR = DI->getDef();\n          if (RR->isSubClassOf(\"Register\"))\n            NoRegisters = false;\n        }\n    }\n    // Consider the commuted order.\n    if (NoRegisters) {\n      // Swap the first two operands after the intrinsic id, if present.\n      unsigned i = isCommIntrinsic ? 1 : 0;\n      std::swap(ChildVariants[i], ChildVariants[i + 1]);\n      CombineChildVariants(N, ChildVariants, OutVariants, CDP, DepVars);\n    }\n  }\n}\n\n// GenerateVariants - Generate variants.  For example, commutative patterns can\n// match multiple ways.  Add them to PatternsToMatch as well.\nvoid CodeGenDAGPatterns::GenerateVariants() {\n  LLVM_DEBUG(errs() << \"Generating instruction variants.\\n\");\n\n  // Loop over all of the patterns we've collected, checking to see if we can\n  // generate variants of the instruction, through the exploitation of\n  // identities.  This permits the target to provide aggressive matching without\n  // the .td file having to contain tons of variants of instructions.\n  //\n  // Note that this loop adds new patterns to the PatternsToMatch list, but we\n  // intentionally do not reconsider these.  Any variants of added patterns have\n  // already been added.\n  //\n  for (unsigned i = 0, e = PatternsToMatch.size(); i != e; ++i) {\n    MultipleUseVarSet DepVars;\n    std::vector<TreePatternNodePtr> Variants;\n    FindDepVars(PatternsToMatch[i].getSrcPattern(), DepVars);\n    LLVM_DEBUG(errs() << \"Dependent/multiply used variables: \");\n    LLVM_DEBUG(DumpDepVars(DepVars));\n    LLVM_DEBUG(errs() << \"\\n\");\n    GenerateVariantsOf(PatternsToMatch[i].getSrcPatternShared(), Variants,\n                       *this, DepVars);\n\n    assert(PatternsToMatch[i].getHwModeFeatures().empty() &&\n           \"HwModes should not have been expanded yet!\");\n\n    assert(!Variants.empty() && \"Must create at least original variant!\");\n    if (Variants.size() == 1) // No additional variants for this pattern.\n      continue;\n\n    LLVM_DEBUG(errs() << \"FOUND VARIANTS OF: \";\n               PatternsToMatch[i].getSrcPattern().dump(); errs() << \"\\n\");\n\n    for (unsigned v = 0, e = Variants.size(); v != e; ++v) {\n      TreePatternNodePtr Variant = Variants[v];\n\n      LLVM_DEBUG(errs() << \"  VAR#\" << v << \": \"; Variant->dump();\n                 errs() << \"\\n\");\n\n      // Scan to see if an instruction or explicit pattern already matches this.\n      bool AlreadyExists = false;\n      for (unsigned p = 0, e = PatternsToMatch.size(); p != e; ++p) {\n        // Skip if the top level predicates do not match.\n        if ((i != p) && (PatternsToMatch[i].getPredicates() !=\n                         PatternsToMatch[p].getPredicates()))\n          continue;\n        // Check to see if this variant already exists.\n        if (Variant->isIsomorphicTo(PatternsToMatch[p].getSrcPattern(),\n                                    DepVars)) {\n          LLVM_DEBUG(errs() << \"  *** ALREADY EXISTS, ignoring variant.\\n\");\n          AlreadyExists = true;\n          break;\n        }\n      }\n      // If we already have it, ignore the variant.\n      if (AlreadyExists)\n        continue;\n\n      // Otherwise, add it to the list of patterns we have.\n      PatternsToMatch.emplace_back(\n          PatternsToMatch[i].getSrcRecord(), PatternsToMatch[i].getPredicates(),\n          Variant, PatternsToMatch[i].getDstPatternShared(),\n          PatternsToMatch[i].getDstRegs(),\n          PatternsToMatch[i].getAddedComplexity(), Record::getNewUID(Records),\n          PatternsToMatch[i].getHwModeFeatures());\n    }\n\n    LLVM_DEBUG(errs() << \"\\n\");\n  }\n}\n"}], "code": "static void getInstructionsInTree(TreePatternNode &Tree,\n                                  SmallVectorImpl<Record *> &Instrs) {\n  if (Tree.isLeaf())\n    return;\n  if (Tree.getOperator()->isSubClassOf(\"Instruction\"))\n    Instrs.push_back(Tree.getOperator());\n  for (unsigned i = 0, e = Tree.getNumChildren(); i != e; ++i)\n    getInstructionsInTree(Tree.getChild(i), Instrs);\n}\n"}, "B5EB2DF18B98E871": {"calls": [{"id": "16EE6645252E7B12", "name": "llvm::BitVector::size", "path": "llvm-project/llvm/include/llvm/ADT/BitVector.h", "start": {"line": 159, "col": 3}, "end": {"line": 159, "col": 41}, "code": "\n  /// count - Returns the number of bits which are set.\n  size_type count() const {\n    unsigned NumBits = 0;\n    for (auto Bit : Bits)\n      NumBits += llvm::popcount(Bit);\n    return NumBits;\n  }\n\n  /// any - Returns true if any bit is set.\n  bool any() const {\n    return any_of(Bits, [](BitWord Bit) { return Bit != 0; });\n  }\n\n  /// all - Returns true if all bits are set.\n  bool all() const {\n    for (unsigned i = 0; i < Size / BITWORD_SIZE; ++i)\n      if (Bits[i] != ~BitWord(0))\n        return false;\n\n    // If bits remain check that they are ones. The unused bits are always zero.\n    if (unsigned Remainder = Size % BITWORD_SIZE)\n      return Bits[Size / BITWORD_SIZE] == (BitWord(1) << Remainder) - 1;\n\n    return true;\n  }\n\n  /// none - Returns true if none of the bits are set.\n  bool none() const {\n    return !any();\n  }\n\n  /// find_first_in - Returns the index of the first set / unset bit,\n  /// depending on \\p Set, in the range [Begin, End).\n  /// Returns -1 if all bits in the range are unset / set.\n  int find_first_in(unsigned Begin, unsigned End, bool Set = true) const {\n    assert(Begin <= End && End <= Size);\n    if (Begin == End)\n      return -1;\n\n    unsigned FirstWord = Begin / BITWORD_SIZE;\n    unsigned LastWord = (End - 1) / BITWORD_SIZE;\n\n    // Check subsequent words.\n    // The code below is based on search for the first _set_ bit. If\n    // we're searching for the first _unset_, we just take the\n    // complement of each word before we use it and apply\n    // the same method.\n    for (unsigned i = FirstWord; i <= LastWord; ++i) {\n      BitWord Copy = Bits[i];\n      if (!Set)\n        Copy = ~Copy;\n\n      if (i == FirstWord) {\n        unsigned FirstBit = Begin % BITWORD_SIZE;\n        Copy &= maskTrailingZeros<BitWord>(FirstBit);\n      }\n\n      if (i == LastWord) {\n        unsigned LastBit = (End - 1) % BITWORD_SIZE;\n        Copy &= maskTrailingOnes<BitWord>(LastBit + 1);\n      }\n      if (Copy != 0)\n        return i * BITWORD_SIZE + llvm::countr_zero(Copy);\n    }\n    return -1;\n  }\n\n  /// find_last_in - Returns the index of the last set bit in the range\n  /// [Begin, End).  Returns -1 if all bits in the range are unset.\n  int find_last_in(unsigned Begin, unsigned End) const {\n    assert(Begin <= End && End <= Size);\n    if (Begin == End)\n      return -1;\n\n    unsigned LastWord = (End - 1) / BITWORD_SIZE;\n    unsigned FirstWord = Begin / BITWORD_SIZE;\n\n    for (unsigned i = LastWord + 1; i >= FirstWord + 1; --i) {\n      unsigned CurrentWord = i - 1;\n\n      BitWord Copy = Bits[CurrentWord];\n      if (CurrentWord == LastWord) {\n        unsigned LastBit = (End - 1) % BITWORD_SIZE;\n        Copy &= maskTrailingOnes<BitWord>(LastBit + 1);\n      }\n\n      if (CurrentWord == FirstWord) {\n        unsigned FirstBit = Begin % BITWORD_SIZE;\n        Copy &= maskTrailingZeros<BitWord>(FirstBit);\n      }\n\n      if (Copy != 0)\n        return (CurrentWord + 1) * BITWORD_SIZE - llvm::countl_zero(Copy) - 1;\n    }\n\n    return -1;\n  }\n\n  /// find_first_unset_in - Returns the index of the first unset bit in the\n  /// range [Begin, End).  Returns -1 if all bits in the range are set.\n  int find_first_unset_in(unsigned Begin, unsigned End) const {\n    return find_first_in(Begin, End, /* Set = */ false);\n  }\n\n  /// find_last_unset_in - Returns the index of the last unset bit in the\n  /// range [Begin, End).  Returns -1 if all bits in the range are set.\n  int find_last_unset_in(unsigned Begin, unsigned End) const {\n    assert(Begin <= End && End <= Size);\n    if (Begin == End)\n      return -1;\n\n    unsigned LastWord = (End - 1) / BITWORD_SIZE;\n    unsigned FirstWord = Begin / BITWORD_SIZE;\n\n    for (unsigned i = LastWord + 1; i >= FirstWord + 1; --i) {\n      unsigned CurrentWord = i - 1;\n\n      BitWord Copy = Bits[CurrentWord];\n      if (CurrentWord == LastWord) {\n        unsigned LastBit = (End - 1) % BITWORD_SIZE;\n        Copy |= maskTrailingZeros<BitWord>(LastBit + 1);\n      }\n\n      if (CurrentWord == FirstWord) {\n        unsigned FirstBit = Begin % BITWORD_SIZE;\n        Copy |= maskTrailingOnes<BitWord>(FirstBit);\n      }\n\n      if (Copy != ~BitWord(0)) {\n        unsigned Result =\n            (CurrentWord + 1) * BITWORD_SIZE - llvm::countl_one(Copy) - 1;\n        return Result < Size ? Result : -1;\n      }\n    }\n    return -1;\n  }\n\n  /// find_first - Returns the index of the first set bit, -1 if none\n  /// of the bits are set.\n  int find_first() const { return find_first_in(0, Size); }\n\n  /// find_last - Returns the index of the last set bit, -1 if none of the bits\n  /// are set.\n  int find_last() const { return find_last_in(0, Size); }\n\n  /// find_next - Returns the index of the next set bit following the\n  /// \"Prev\" bit. Returns -1 if the next set bit is not found.\n  int find_next(unsigned Prev) const { return find_first_in(Prev + 1, Size); }\n\n  /// find_prev - Returns the index of the first set bit that precedes the\n  /// the bit at \\p PriorTo.  Returns -1 if all previous bits are unset.\n  int find_prev(unsigned PriorTo) const { return find_last_in(0, PriorTo); }\n\n  /// find_first_unset - Returns the index of the first unset bit, -1 if all\n  /// of the bits are set.\n  int find_first_unset() const { return find_first_unset_in(0, Size); }\n\n  /// find_next_unset - Returns the index of the next unset bit following the\n  /// \"Prev\" bit.  Returns -1 if all remaining bits are set.\n"}, {"id": "D50CB82466C2BC96", "name": "llvm::BitVector::test", "path": "llvm-project/llvm/include/llvm/ADT/BitVector.h", "start": {"line": 461, "col": 3}, "end": {"line": 463, "col": 3}, "code": "    return (*this)[Idx];\n  }\n\n  // Push single bit to end of vector.\n  void push_back(bool Val) {\n    unsigned OldSize = Size;\n    unsigned NewSize = Size + 1;\n\n    // Resize, which will insert zeros.\n    // If we already fit then the unused bits will be already zero.\n    if (NewSize > getBitCapacity())\n      resize(NewSize, false);\n    else\n      Size = NewSize;\n\n    // If true, set single bit.\n    if (Val)\n      set(OldSize);\n  }\n\n  /// Pop one bit from the end of the vector.\n  void pop_back() {\n    assert(!empty() && \"Empty vector has no element to pop.\");\n    resize(size() - 1);\n  }\n\n  /// Test if any common bits are set.\n  bool anyCommon(const BitVector &RHS) const {\n    unsigned ThisWords = Bits.size();\n    unsigned RHSWords = RHS.Bits.size();\n    for (unsigned i = 0, e = std::min(ThisWords, RHSWords); i != e; ++i)\n      if (Bits[i] & RHS.Bits[i])\n        return true;\n    return false;\n  }\n\n  // Comparison operators.\n  bool operator==(const BitVector &RHS) const {\n    if (size() != RHS.size())\n      return false;\n    unsigned NumWords = Bits.size();\n    return std::equal(Bits.begin(), Bits.begin() + NumWords, RHS.Bits.begin());\n  }\n\n  bool operator!=(const BitVector &RHS) const { return !(*this == RHS); }\n\n  /// Intersection, union, disjoint union.\n  BitVector &operator&=(const BitVector &RHS) {\n    unsigned ThisWords = Bits.size();\n    unsigned RHSWords = RHS.Bits.size();\n    unsigned i;\n    for (i = 0; i != std::min(ThisWords, RHSWords); ++i)\n      Bits[i] &= RHS.Bits[i];\n\n    // Any bits that are just in this bitvector become zero, because they aren't\n    // in the RHS bit vector.  Any words only in RHS are ignored because they\n    // are already zero in the LHS.\n    for (; i != ThisWords; ++i)\n      Bits[i] = 0;\n\n    return *this;\n  }\n\n  /// reset - Reset bits that are set in RHS. Same as *this &= ~RHS.\n  BitVector &reset(const BitVector &RHS) {\n    unsigned ThisWords = Bits.size();\n    unsigned RHSWords = RHS.Bits.size();\n    for (unsigned i = 0; i != std::min(ThisWords, RHSWords); ++i)\n      Bits[i] &= ~RHS.Bits[i];\n    return *this;\n  }\n\n  /// test - Check if (This - RHS) is zero.\n  /// This is the same as reset(RHS) and any().\n  bool test(const BitVector &RHS) const {\n    unsigned ThisWords = Bits.size();\n    unsigned RHSWords = RHS.Bits.size();\n    unsigned i;\n    for (i = 0; i != std::min(ThisWords, RHSWords); ++i)\n      if ((Bits[i] & ~RHS.Bits[i]) != 0)\n        return true;\n\n    for (; i != ThisWords ; ++i)\n      if (Bits[i] != 0)\n        return true;\n\n    return false;\n  }\n\n  template <class F, class... ArgTys>\n  static BitVector &apply(F &&f, BitVector &Out, BitVector const &Arg,\n                          ArgTys const &...Args) {\n    assert(llvm::all_of(\n               std::initializer_list<unsigned>{Args.size()...},\n               [&Arg](auto const &BV) { return Arg.size() == BV; }) &&\n           \"consistent sizes\");\n    Out.resize(Arg.size());\n    for (size_type I = 0, E = Arg.Bits.size(); I != E; ++I)\n      Out.Bits[I] = f(Arg.Bits[I], Args.Bits[I]...);\n    Out.clear_unused_bits();\n    return Out;\n  }\n\n  BitVector &operator|=(const BitVector &RHS) {\n    if (size() < RHS.size())\n      resize(RHS.size());\n    for (size_type I = 0, E = RHS.Bits.size(); I != E; ++I)\n      Bits[I] |= RHS.Bits[I];\n    return *this;\n  }\n\n  BitVector &operator^=(const BitVector &RHS) {\n    if (size() < RHS.size())\n      resize(RHS.size());\n    for (size_type I = 0, E = RHS.Bits.size(); I != E; ++I)\n      Bits[I] ^= RHS.Bits[I];\n    return *this;\n  }\n\n  BitVector &operator>>=(unsigned N) {\n    assert(N <= Size);\n    if (LLVM_UNLIKELY(empty() || N == 0))\n      return *this;\n\n    unsigned NumWords = Bits.size();\n    assert(NumWords >= 1);\n\n    wordShr(N / BITWORD_SIZE);\n\n    unsigned BitDistance = N % BITWORD_SIZE;\n    if (BitDistance == 0)\n      return *this;\n\n    // When the shift size is not a multiple of the word size, then we have\n    // a tricky situation where each word in succession needs to extract some\n    // of the bits from the next word and or them into this word while\n    // shifting this word to make room for the new bits.  This has to be done\n    // for every word in the array.\n\n    // Since we're shifting each word right, some bits will fall off the end\n    // of each word to the right, and empty space will be created on the left.\n    // The final word in the array will lose bits permanently, so starting at\n    // the beginning, work forwards shifting each word to the right, and\n    // OR'ing in the bits from the end of the next word to the beginning of\n    // the current word.\n\n    // Example:\n    //   Starting with {0xAABBCCDD, 0xEEFF0011, 0x22334455} and shifting right\n    //   by 4 bits.\n    // Step 1: Word[0] >>= 4           ; 0x0ABBCCDD\n    // Step 2: Word[0] |= 0x10000000   ; 0x1ABBCCDD\n    // Step 3: Word[1] >>= 4           ; 0x0EEFF001\n    // Step 4: Word[1] |= 0x50000000   ; 0x5EEFF001\n    // Step 5: Word[2] >>= 4           ; 0x02334455\n    // Result: { 0x1ABBCCDD, 0x5EEFF001, 0x02334455 }\n    const BitWord Mask = maskTrailingOnes<BitWord>(BitDistance);\n    const unsigned LSH = BITWORD_SIZE - BitDistance;\n\n    for (unsigned I = 0; I < NumWords - 1; ++I) {\n      Bits[I] >>= BitDistance;\n      Bits[I] |= (Bits[I + 1] & Mask) << LSH;\n    }\n\n    Bits[NumWords - 1] >>= BitDistance;\n\n    return *this;\n  }\n\n  BitVector &operator<<=(unsigned N) {\n    assert(N <= Size);\n    if (LLVM_UNLIKELY(empty() || N == 0))\n      return *this;\n\n    unsigned NumWords = Bits.size();\n    assert(NumWords >= 1);\n\n    wordShl(N / BITWORD_SIZE);\n\n    unsigned BitDistance = N % BITWORD_SIZE;\n    if (BitDistance == 0)\n      return *this;\n\n    // When the shift size is not a multiple of the word size, then we have\n    // a tricky situation where each word in succession needs to extract some\n    // of the bits from the previous word and or them into this word while\n    // shifting this word to make room for the new bits.  This has to be done\n    // for every word in the array.  This is similar to the algorithm outlined\n    // in operator>>=, but backwards.\n\n    // Since we're shifting each word left, some bits will fall off the end\n    // of each word to the left, and empty space will be created on the right.\n    // The first word in the array will lose bits permanently, so starting at\n    // the end, work backwards shifting each word to the left, and OR'ing\n    // in the bits from the end of the next word to the beginning of the\n    // current word.\n\n    // Example:\n    //   Starting with {0xAABBCCDD, 0xEEFF0011, 0x22334455} and shifting left\n    //   by 4 bits.\n    // Step 1: Word[2] <<= 4           ; 0x23344550\n    // Step 2: Word[2] |= 0x0000000E   ; 0x2334455E\n    // Step 3: Word[1] <<= 4           ; 0xEFF00110\n    // Step 4: Word[1] |= 0x0000000A   ; 0xEFF0011A\n    // Step 5: Word[0] <<= 4           ; 0xABBCCDD0\n    // Result: { 0xABBCCDD0, 0xEFF0011A, 0x2334455E }\n    const BitWord Mask = maskLeadingOnes<BitWord>(BitDistance);\n    const unsigned RSH = BITWORD_SIZE - BitDistance;\n\n    for (int I = NumWords - 1; I > 0; --I) {\n      Bits[I] <<= BitDistance;\n      Bits[I] |= (Bits[I - 1] & Mask) >> RSH;\n    }\n    Bits[0] <<= BitDistance;\n    clear_unused_bits();\n\n    return *this;\n  }\n\n  void swap(BitVector &RHS) {\n    std::swap(Bits, RHS.Bits);\n    std::swap(Size, RHS.Size);\n  }\n\n  void invalid() {\n    assert(!Size && Bits.empty());\n    Size = (unsigned)-1;\n  }\n  bool isInvalid() const { return Size == (unsigned)-1; }\n\n  ArrayRef<BitWord> getData() const { return {Bits.data(), Bits.size()}; }\n\n  //===--------------------------------------------------------------------===//\n  // Portable bit mask operations.\n  //===--------------------------------------------------------------------===//\n  //\n  // These methods all operate on arrays of uint32_t, each holding 32 bits. The\n  // fixed word size makes it easier to work with literal bit vector constants\n  // in portable code.\n  //\n  // The LSB in each word is the lowest numbered bit.  The size of a portable\n  // bit mask is always a whole multiple of 32 bits.  If no bit mask size is\n  // given, the bit mask is assumed to cover the entire BitVector.\n\n  /// setBitsInMask - Add '1' bits from Mask to this vector. Don't resize.\n  /// This computes \"*this |= Mask\".\n  void setBitsInMask(const uint32_t *Mask, unsigned MaskWords = ~0u) {\n    applyMask<true, false>(Mask, MaskWords);\n  }\n\n  /// clearBitsInMask - Clear any bits in this vector that are set in Mask.\n  /// Don't resize. This computes \"*this &= ~Mask\".\n  void clearBitsInMask(const uint32_t *Mask, unsigned MaskWords = ~0u) {\n    applyMask<false, false>(Mask, MaskWords);\n  }\n\n  /// setBitsNotInMask - Add a bit to this vector for every '0' bit in Mask.\n  /// Don't resize.  This computes \"*this |= ~Mask\".\n  void setBitsNotInMask(const uint32_t *Mask, unsigned MaskWords = ~0u) {\n    applyMask<true, true>(Mask, MaskWords);\n  }\n\n  /// clearBitsNotInMask - Clear a bit in this vector for every '0' bit in Mask.\n  /// Don't resize.  This computes \"*this &= Mask\".\n  void clearBitsNotInMask(const uint32_t *Mask, unsigned MaskWords = ~0u) {\n    applyMask<false, true>(Mask, MaskWords);\n  }\n\nprivate:\n  /// Perform a logical left shift of \\p Count words by moving everything\n  /// \\p Count words to the right in memory.\n  ///\n  /// While confusing, words are stored from least significant at Bits[0] to\n  /// most significant at Bits[NumWords-1].  A logical shift left, however,\n  /// moves the current least significant bit to a higher logical index, and\n  /// fills the previous least significant bits with 0.  Thus, we actually\n  /// need to move the bytes of the memory to the right, not to the left.\n  /// Example:\n  ///   Words = [0xBBBBAAAA, 0xDDDDFFFF, 0x00000000, 0xDDDD0000]\n  /// represents a BitVector where 0xBBBBAAAA contain the least significant\n  /// bits.  So if we want to shift the BitVector left by 2 words, we need\n  /// to turn this into 0x00000000 0x00000000 0xBBBBAAAA 0xDDDDFFFF by using a\n  /// memmove which moves right, not left.\n  void wordShl(uint32_t Count) {\n    if (Count == 0)\n      return;\n\n    uint32_t NumWords = Bits.size();\n\n    // Since we always move Word-sized chunks of data with src and dest both\n    // aligned to a word-boundary, we don't need to worry about endianness\n    // here.\n    std::copy(Bits.begin(), Bits.begin() + NumWords - Count,\n              Bits.begin() + Count);\n    std::fill(Bits.begin(), Bits.begin() + Count, 0);\n    clear_unused_bits();\n  }\n\n  /// Perform a logical right shift of \\p Count words by moving those\n  /// words to the left in memory.  See wordShl for more information.\n  ///\n  void wordShr(uint32_t Count) {\n    if (Count == 0)\n      return;\n\n    uint32_t NumWords = Bits.size();\n\n    std::copy(Bits.begin() + Count, Bits.begin() + NumWords, Bits.begin());\n    std::fill(Bits.begin() + NumWords - Count, Bits.begin() + NumWords, 0);\n  }\n\n  int next_unset_in_word(int WordIndex, BitWord Word) const {\n    unsigned Result = WordIndex * BITWORD_SIZE + llvm::countr_one(Word);\n    return Result < size() ? Result : -1;\n  }\n\n  unsigned NumBitWords(unsigned S) const {\n    return (S + BITWORD_SIZE-1) / BITWORD_SIZE;\n  }\n\n  // Set the unused bits in the high words.\n  void set_unused_bits(bool t = true) {\n    //  Then set any stray high bits of the last used word.\n    if (unsigned ExtraBits = Size % BITWORD_SIZE) {\n      BitWord ExtraBitMask = ~BitWord(0) << ExtraBits;\n      if (t)\n        Bits.back() |= ExtraBitMask;\n      else\n        Bits.back() &= ~ExtraBitMask;\n    }\n  }\n\n  // Clear the unused bits in the high words.\n  void clear_unused_bits() {\n    set_unused_bits(false);\n  }\n\n  void init_words(bool t) {\n    std::fill(Bits.begin(), Bits.end(), 0 - (BitWord)t);\n  }\n\n  template<bool AddBits, bool InvertMask>\n  void applyMask(const uint32_t *Mask, unsigned MaskWords) {\n    static_assert(BITWORD_SIZE % 32 == 0, \"Unsupported BitWord size.\");\n    MaskWords = std::min(MaskWords, (size() + 31) / 32);\n    const unsigned Scale = BITWORD_SIZE / 32;\n    unsigned i;\n    for (i = 0; MaskWords >= Scale; ++i, MaskWords -= Scale) {\n      BitWord BW = Bits[i];\n      // This inner loop should unroll completely when BITWORD_SIZE > 32.\n      for (unsigned b = 0; b != BITWORD_SIZE; b += 32) {\n        uint32_t M = *Mask++;\n        if (InvertMask) M = ~M;\n        if (AddBits) BW |=   BitWord(M) << b;\n        else         BW &= ~(BitWord(M) << b);\n      }\n      Bits[i] = BW;\n    }\n    for (unsigned b = 0; MaskWords; b += 32, --MaskWords) {\n      uint32_t M = *Mask++;\n      if (InvertMask) M = ~M;\n      if (AddBits) Bits[i] |=   BitWord(M) << b;\n      else         Bits[i] &= ~(BitWord(M) << b);\n    }\n    if (AddBits)\n      clear_unused_bits();\n  }\n\npublic:\n  /// Return the size (in bytes) of the bit vector.\n  size_type getMemorySize() const { return Bits.size() * sizeof(BitWord); }\n  size_type getBitCapacity() const { return Bits.size() * BITWORD_SIZE; }\n};\n\ninline BitVector::size_type capacity_in_bytes(const BitVector &X) {\n  return X.getMemorySize();\n}\n\ntemplate <> struct DenseMapInfo<BitVector> {\n  static inline BitVector getEmptyKey() { return {}; }\n  static inline BitVector getTombstoneKey() {\n    BitVector V;\n    V.invalid();\n    return V;\n  }\n  static unsigned getHashValue(const BitVector &V) {\n    return DenseMapInfo<std::pair<BitVector::size_type, ArrayRef<uintptr_t>>>::\n        getHashValue(std::make_pair(V.size(), V.getData()));\n  }\n  static bool isEqual(const BitVector &LHS, const BitVector &RHS) {\n    if (LHS.isInvalid() || RHS.isInvalid())\n      return LHS.isInvalid() == RHS.isInvalid();\n    return LHS == RHS;\n  }\n};\n} // end namespace llvm\n\nnamespace std {\n  /// Implement std::swap in terms of BitVector swap.\ninline void swap(llvm::BitVector &LHS, llvm::BitVector &RHS) { LHS.swap(RHS); }\n} // end namespace std\n\n#endif // LLVM_ADT_BITVECTOR_H\n"}, {"id": "756037FB6900B924", "name": "llvm::raw_ostream::operator<<", "path": "llvm-project/llvm/lib/Support/raw_ostream.cpp", "start": {"line": 316, "col": 1}, "end": {"line": 354, "col": 1}, "code": "  // If we have more than a few bytes left in our output buffer, try\n  // formatting directly onto its end.\n  size_t NextBufferSize = 127;\n  size_t BufferBytesLeft = OutBufEnd - OutBufCur;\n  if (BufferBytesLeft > 3) {\n    size_t BytesUsed = Fmt.print(OutBufCur, BufferBytesLeft);\n\n    // Common case is that we have plenty of space.\n    if (BytesUsed <= BufferBytesLeft) {\n      OutBufCur += BytesUsed;\n      return *this;\n    }\n\n    // Otherwise, we overflowed and the return value tells us the size to try\n    // again with.\n    NextBufferSize = BytesUsed;\n  }\n\n  // If we got here, we didn't have enough space in the output buffer for the\n  // string.  Try printing into a SmallVector that is resized to have enough\n  // space.  Iterate until we win.\n  SmallVector<char, 128> V;\n\n  while (true) {\n    V.resize(NextBufferSize);\n\n    // Try formatting into the SmallVector.\n    size_t BytesUsed = Fmt.print(V.data(), NextBufferSize);\n\n    // If BytesUsed fit into the vector, we win.\n    if (BytesUsed <= NextBufferSize)\n      return write(V.data(), BytesUsed);\n\n    // Otherwise, try again with a new size.\n    assert(BytesUsed > NextBufferSize && \"Didn't grow buffer!?\");\n    NextBufferSize = BytesUsed;\n  }\n}\n\nraw_ostream &raw_ostream::operator<<(const formatv_object_base &Obj) {\n  Obj.format(*this);\n  return *this;\n}\n\nraw_ostream &raw_ostream::operator<<(const FormattedString &FS) {\n  unsigned LeftIndent = 0;\n  unsigned RightIndent = 0;\n  const ssize_t Difference = FS.Width - FS.Str.size();\n  if (Difference > 0) {\n    switch (FS.Justify) {\n    case FormattedString::JustifyNone:\n      break;\n    case FormattedString::JustifyLeft:\n      RightIndent = Difference;\n      break;\n    case FormattedString::JustifyRight:\n      LeftIndent = Difference;\n      break;\n    case FormattedString::JustifyCenter:\n      LeftIndent = Difference / 2;\n      RightIndent = Difference - LeftIndent;\n      break;\n    }\n  }\n  indent(LeftIndent);\n  (*this) << FS.Str;\n  indent(RightIndent);\n  return *this;\n}\n\nraw_ostream &raw_ostream::operator<<(const FormattedNumber &FN) {\n  if (FN.Hex) {\n    HexPrintStyle Style;\n    if (FN.Upper && FN.HexPrefix)\n      Style = HexPrintStyle::PrefixUpper;\n    else if (FN.Upper && !FN.HexPrefix)\n      Style = HexPrintStyle::Upper;\n    else if (!FN.Upper && FN.HexPrefix)\n      Style = HexPrintStyle::PrefixLower;\n    else\n      Style = HexPrintStyle::Lower;\n    llvm::write_hex(*this, FN.HexValue, Style, FN.Width);\n  } else {\n    llvm::SmallString<16> Buffer;\n    llvm::raw_svector_ostream Stream(Buffer);\n    llvm::write_integer(Stream, FN.DecValue, 0, IntegerStyle::Integer);\n    if (Buffer.size() < FN.Width)\n      indent(FN.Width - Buffer.size());\n    (*this) << Buffer;\n  }\n  return *this;\n}\n\nraw_ostream &raw_ostream::operator<<(const FormattedBytes &FB) {\n  if (FB.Bytes.empty())\n    return *this;\n\n  size_t LineIndex = 0;\n  auto Bytes = FB.Bytes;\n  const size_t Size = Bytes.size();\n  HexPrintStyle HPS = FB.Upper ? HexPrintStyle::Upper : HexPrintStyle::Lower;\n  uint64_t OffsetWidth = 0;\n  if (FB.FirstByteOffset) {\n    // Figure out how many nibbles are needed to print the largest offset\n    // represented by this data set, so that we can align the offset field\n    // to the right width.\n    size_t Lines = Size / FB.NumPerLine;\n    uint64_t MaxOffset = *FB.FirstByteOffset + Lines * FB.NumPerLine;\n    unsigned Power = 0;\n    if (MaxOffset > 0)\n      Power = llvm::Log2_64_Ceil(MaxOffset);\n    OffsetWidth = std::max<uint64_t>(4, llvm::alignTo(Power, 4) / 4);\n  }\n\n  // The width of a block of data including all spaces for group separators.\n  unsigned NumByteGroups =\n      alignTo(FB.NumPerLine, FB.ByteGroupSize) / FB.ByteGroupSize;\n  unsigned BlockCharWidth = FB.NumPerLine * 2 + NumByteGroups - 1;\n\n  while (!Bytes.empty()) {\n    indent(FB.IndentLevel);\n\n    if (FB.FirstByteOffset) {\n      uint64_t Offset = *FB.FirstByteOffset;\n      llvm::write_hex(*this, Offset + LineIndex, HPS, OffsetWidth);\n      *this << \": \";\n    }\n\n    auto Line = Bytes.take_front(FB.NumPerLine);\n\n    size_t CharsPrinted = 0;\n    // Print the hex bytes for this line in groups\n    for (size_t I = 0; I < Line.size(); ++I, CharsPrinted += 2) {\n      if (I && (I % FB.ByteGroupSize) == 0) {\n        ++CharsPrinted;\n        *this << \" \";\n      }\n      llvm::write_hex(*this, Line[I], HPS, 2);\n    }\n\n    if (FB.ASCII) {\n      // Print any spaces needed for any bytes that we didn't print on this\n      // line so that the ASCII bytes are correctly aligned.\n      assert(BlockCharWidth >= CharsPrinted);\n      indent(BlockCharWidth - CharsPrinted + 2);\n      *this << \"|\";\n\n      // Print the ASCII char values for each byte on this line\n      for (uint8_t Byte : Line) {\n        if (isPrint(Byte))\n          *this << static_cast<char>(Byte);\n        else\n          *this << '.';\n      }\n      *this << '|';\n    }\n\n    Bytes = Bytes.drop_front(Line.size());\n    LineIndex += Line.size();\n    if (LineIndex < Size)\n      *this << '\\n';\n  }\n  return *this;\n}\n\ntemplate <char C>\nstatic raw_ostream &write_padding(raw_ostream &OS, unsigned NumChars) {\n  static const char Chars[] = {C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,\n                               C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,\n                               C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,\n                               C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,\n                               C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C};\n\n  // Usually the indentation is small, handle it with a fastpath.\n  if (NumChars < std::size(Chars))\n    return OS.write(Chars, NumChars);\n\n  while (NumChars) {\n    unsigned NumToWrite = std::min(NumChars, (unsigned)std::size(Chars) - 1);\n    OS.write(Chars, NumToWrite);\n    NumChars -= NumToWrite;\n  }\n  return OS;\n}\n\n/// indent - Insert 'NumSpaces' spaces.\nraw_ostream &raw_ostream::indent(unsigned NumSpaces) {\n  return write_padding<' '>(*this, NumSpaces);\n}\n\n/// write_zeros - Insert 'NumZeros' nulls.\nraw_ostream &raw_ostream::write_zeros(unsigned NumZeros) {\n  return write_padding<'\\0'>(*this, NumZeros);\n}\n\nbool raw_ostream::prepare_colors() {\n  // Colors were explicitly disabled.\n  if (!ColorEnabled)\n    return false;\n\n  // Colors require changing the terminal but this stream is not going to a\n  // terminal.\n  if (sys::Process::ColorNeedsFlush() && !is_displayed())\n    return false;\n\n  if (sys::Process::ColorNeedsFlush())\n    flush();\n\n  return true;\n}\n\nraw_ostream &raw_ostream::changeColor(enum Colors colors, bool bold, bool bg) {\n  if (!prepare_colors())\n    return *this;\n\n  const char *colorcode =\n      (colors == SAVEDCOLOR)\n          ? sys::Process::OutputBold(bg)\n          : sys::Process::OutputColor(static_cast<char>(colors), bold, bg);\n  if (colorcode)\n    write(colorcode, strlen(colorcode));\n  return *this;\n}\n\nraw_ostream &raw_ostream::resetColor() {\n  if (!prepare_colors())\n    return *this;\n\n  if (const char *colorcode = sys::Process::ResetColor())\n    write(colorcode, strlen(colorcode));\n  return *this;\n}\n\nraw_ostream &raw_ostream::reverseColor() {\n  if (!prepare_colors())\n    return *this;\n\n  if (const char *colorcode = sys::Process::OutputReverse())\n    write(colorcode, strlen(colorcode));\n  return *this;\n}\n\nvoid raw_ostream::anchor() {}\n\n//===----------------------------------------------------------------------===//\n//  Formatted Output\n//===----------------------------------------------------------------------===//\n\n// Out of line virtual method.\nvoid format_object_base::home() {\n}\n\n//===----------------------------------------------------------------------===//\n//  raw_fd_ostream\n//===----------------------------------------------------------------------===//\n\nstatic int getFD(StringRef Filename, std::error_code &EC,\n                 sys::fs::CreationDisposition Disp, sys::fs::FileAccess Access,\n                 sys::fs::OpenFlags Flags) {\n  assert((Access & sys::fs::FA_Write) &&\n         \"Cannot make a raw_ostream from a read-only descriptor!\");\n\n  // Handle \"-\" as stdout. Note that when we do this, we consider ourself\n  // the owner of stdout and may set the \"binary\" flag globally based on Flags.\n  if (Filename == \"-\") {\n    EC = std::error_code();\n    // Change stdout's text/binary mode based on the Flags.\n    sys::ChangeStdoutMode(Flags);\n    return STDOUT_FILENO;\n  }\n\n  int FD;\n  if (Access & sys::fs::FA_Read)\n    EC = sys::fs::openFileForReadWrite(Filename, FD, Disp, Flags);\n  else\n    EC = sys::fs::openFileForWrite(Filename, FD, Disp, Flags);\n  if (EC)\n    return -1;\n\n  return FD;\n}\n\nraw_fd_ostream::raw_fd_ostream(StringRef Filename, std::error_code &EC)\n    : raw_fd_ostream(Filename, EC, sys::fs::CD_CreateAlways, sys::fs::FA_Write,\n                     sys::fs::OF_None) {}\n\nraw_fd_ostream::raw_fd_ostream(StringRef Filename, std::error_code &EC,\n                               sys::fs::CreationDisposition Disp)\n    : raw_fd_ostream(Filename, EC, Disp, sys::fs::FA_Write, sys::fs::OF_None) {}\n\nraw_fd_ostream::raw_fd_ostream(StringRef Filename, std::error_code &EC,\n                               sys::fs::FileAccess Access)\n    : raw_fd_ostream(Filename, EC, sys::fs::CD_CreateAlways, Access,\n                     sys::fs::OF_None) {}\n\nraw_fd_ostream::raw_fd_ostream(StringRef Filename, std::error_code &EC,\n                               sys::fs::OpenFlags Flags)\n    : raw_fd_ostream(Filename, EC, sys::fs::CD_CreateAlways, sys::fs::FA_Write,\n                     Flags) {}\n\nraw_fd_ostream::raw_fd_ostream(StringRef Filename, std::error_code &EC,\n                               sys::fs::CreationDisposition Disp,\n                               sys::fs::FileAccess Access,\n                               sys::fs::OpenFlags Flags)\n    : raw_fd_ostream(getFD(Filename, EC, Disp, Access, Flags), true) {}\n\n/// FD is the file descriptor that this writes to.  If ShouldClose is true, this\n/// closes the file when the stream is destroyed.\nraw_fd_ostream::raw_fd_ostream(int fd, bool shouldClose, bool unbuffered,\n                               OStreamKind K)\n    : raw_pwrite_stream(unbuffered, K), FD(fd), ShouldClose(shouldClose) {\n  if (FD < 0 ) {\n    ShouldClose = false;\n    return;\n  }\n\n  enable_colors(true);\n\n  // Do not attempt to close stdout or stderr. We used to try to maintain the\n  // property that tools that support writing file to stdout should not also\n  // write informational output to stdout, but in practice we were never able to\n  // maintain this invariant. Many features have been added to LLVM and clang\n  // (-fdump-record-layouts, optimization remarks, etc) that print to stdout, so\n  // users must simply be aware that mixed output and remarks is a possibility.\n  if (FD <= STDERR_FILENO)\n    ShouldClose = false;\n\n"}], "code": "static void printBitVectorAsHex(raw_ostream &OS, const BitVector &Bits,\n                                unsigned Width) {\n  assert(Width <= 32 && \"Width too large\");\n  unsigned Digits = (Width + 3) / 4;\n  for (unsigned i = 0, e = Bits.size(); i < e; i += Width) {\n    unsigned Value = 0;\n    for (unsigned j = 0; j != Width && i + j != e; ++j)\n      Value |= Bits.test(i + j) << j;\n    OS << format(\"0x%0*x, \", Digits, Value);\n  }\n}\n"}, "08DD857AED455A3B": {"calls": [{"id": "EF79741B1439EE2B", "name": "llvm::RecordKeeper::getAllDerivedDefinitions", "path": "llvm-project/llvm/lib/TableGen/Record.cpp", "start": {"line": 3223, "col": 1}, "end": {"line": 3232, "col": 1}, "code": "RecordKeeper::getAllDerivedDefinitions(StringRef ClassName) const {\n  // We cache the record vectors for single classes. Many backends request\n  // the same vectors multiple times.\n  auto Pair = ClassRecordsMap.try_emplace(ClassName);\n  if (Pair.second)\n    Pair.first->second = getAllDerivedDefinitions(ArrayRef(ClassName));\n\n  return Pair.first->second;\n}\n\nstd::vector<Record *> RecordKeeper::getAllDerivedDefinitions(\n    ArrayRef<StringRef> ClassNames) const {\n  SmallVector<Record *, 2> ClassRecs;\n  std::vector<Record *> Defs;\n\n  assert(ClassNames.size() > 0 && \"At least one class must be passed.\");\n  for (const auto &ClassName : ClassNames) {\n    Record *Class = getClass(ClassName);\n    if (!Class)\n      PrintFatalError(\"The class '\" + ClassName + \"' is not defined\\n\");\n    ClassRecs.push_back(Class);\n  }\n\n  for (const auto &OneDef : getDefs()) {\n    if (all_of(ClassRecs, [&OneDef](const Record *Class) {\n                            return OneDef.second->isSubClassOf(Class);\n                          }))\n      Defs.push_back(OneDef.second.get());\n  }\n\n  llvm::sort(Defs, [](Record *LHS, Record *RHS) {\n    return LHS->getName().compare_numeric(RHS->getName()) < 0;\n  });\n\n  return Defs;\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitionsIfDefined(StringRef ClassName) const {\n  return getClass(ClassName) ? getAllDerivedDefinitions(ClassName)\n                             : std::vector<Record *>();\n}\n\nInit *MapResolver::resolve(Init *VarName) {\n  auto It = Map.find(VarName);\n  if (It == Map.end())\n    return nullptr;\n\n  Init *I = It->second.V;\n\n  if (!It->second.Resolved && Map.size() > 1) {\n    // Resolve mutual references among the mapped variables, but prevent\n    // infinite recursion.\n    Map.erase(It);\n    I = I->resolveReferences(*this);\n    Map[VarName] = {I, true};\n  }\n\n  return I;\n}\n\nInit *RecordResolver::resolve(Init *VarName) {\n  Init *Val = Cache.lookup(VarName);\n  if (Val)\n    return Val;\n\n  if (llvm::is_contained(Stack, VarName))\n    return nullptr; // prevent infinite recursion\n\n  if (RecordVal *RV = getCurrentRecord()->getValue(VarName)) {\n    if (!isa<UnsetInit>(RV->getValue())) {\n      Val = RV->getValue();\n      Stack.push_back(VarName);\n      Val = Val->resolveReferences(*this);\n      Stack.pop_back();\n    }\n  } else if (Name && VarName == getCurrentRecord()->getNameInit()) {\n    Stack.push_back(VarName);\n    Val = Name->resolveReferences(*this);\n    Stack.pop_back();\n  }\n\n  Cache[VarName] = Val;\n  return Val;\n}\n\nInit *TrackUnresolvedResolver::resolve(Init *VarName) {\n  Init *I = nullptr;\n\n  if (R) {\n    I = R->resolve(VarName);\n    if (I && !FoundUnresolved) {\n      // Do not recurse into the resolved initializer, as that would change\n      // the behavior of the resolver we're delegating, but do check to see\n      // if there are unresolved variables remaining.\n      TrackUnresolvedResolver Sub;\n      I->resolveReferences(Sub);\n      FoundUnresolved |= Sub.FoundUnresolved;\n    }\n  }\n\n  if (!I)\n    FoundUnresolved = true;\n  return I;\n}\n\nInit *HasReferenceResolver::resolve(Init *VarName)\n{\n  if (VarName == VarNameToTrack)\n    Found = true;\n  return nullptr;\n}\n"}], "code": "CodeGenTarget::CodeGenTarget(RecordKeeper &records)\n    : Records(records), CGH(records) {\n  std::vector<Record *> Targets = Records.getAllDerivedDefinitions(\"Target\");\n  if (Targets.size() == 0)\n    PrintFatalError(\"No 'Target' subclasses defined!\");\n  if (Targets.size() != 1)\n    PrintFatalError(\"Multiple subclasses of Target defined!\");\n  TargetRec = Targets[0];\n  MacroFusions = Records.getAllDerivedDefinitions(\"Fusion\");\n}\n"}, "0F0AC8651F1F799F": {"calls": [{"id": "8D724CC5DF1BE249", "name": "llvm::Record::isSubClassOf", "path": "llvm-project/llvm/include/llvm/TableGen/Record.h", "start": {"line": 1840, "col": 3}, "end": {"line": 1850, "col": 3}, "code": "    for (const auto &SCPair : SuperClasses) {\n      if (const auto *SI = dyn_cast<StringInit>(SCPair.first->getNameInit())) {\n        if (SI->getValue() == Name)\n          return true;\n      } else if (SCPair.first->getNameInitAsString() == Name) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  void addSuperClass(Record *R, SMRange Range) {\n    assert(!CorrespondingDefInit &&\n           \"changing type of record after it has been referenced\");\n    assert(!isSubClassOf(R) && \"Already subclassing record!\");\n    SuperClasses.push_back(std::make_pair(R, Range));\n  }\n\n  /// If there are any field references that refer to fields that have been\n  /// filled in, we can propagate the values now.\n  ///\n  /// This is a final resolve: any error messages, e.g. due to undefined !cast\n  /// references, are generated now.\n  void resolveReferences(Init *NewName = nullptr);\n\n  /// Apply the resolver to the name of the record as well as to the\n  /// initializers of all fields of the record except SkipVal.\n  ///\n  /// The resolver should not resolve any of the fields itself, to avoid\n  /// recursion / infinite loops.\n  void resolveReferences(Resolver &R, const RecordVal *SkipVal = nullptr);\n\n  RecordKeeper &getRecords() const {\n    return TrackedRecords;\n  }\n\n  void dump() const;\n\n  //===--------------------------------------------------------------------===//\n  // High-level methods useful to tablegen back-ends\n  //\n\n  /// Return the source location for the named field.\n  SMLoc getFieldLoc(StringRef FieldName) const;\n\n  /// Return the initializer for a value with the specified name, or throw an\n  /// exception if the field does not exist.\n  Init *getValueInit(StringRef FieldName) const;\n\n  /// Return true if the named field is unset.\n  bool isValueUnset(StringRef FieldName) const {\n    return isa<UnsetInit>(getValueInit(FieldName));\n  }\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the field does not exist or if the value\n  /// is not a string.\n  StringRef getValueAsString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the value is not a string and\n  /// std::nullopt if the field does not exist.\n  std::optional<StringRef> getValueAsOptionalString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// BitsInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  BitsInit *getValueAsBitsInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// ListInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  ListInit *getValueAsListInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of records, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<Record*> getValueAsListOfDefs(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of integers, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<int64_t> getValueAsListOfInts(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of strings, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<StringRef> getValueAsListOfStrings(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, throwing an exception if the field does not exist or if the value\n  /// is not the right type.\n  Record *getValueAsDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, returning null if the field exists but is \"uninitialized\" (i.e.\n  /// set to `?`), and throwing an exception if the field does not exist or if\n  /// its value is not the right type.\n  Record *getValueAsOptionalDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  bool getValueAsBit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit.\n  /// If the field is unset, sets Unset to true and returns false.\n  bool getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const;\n\n  /// This method looks up the specified field and returns its value as an\n  /// int64_t, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  int64_t getValueAsInt(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as an Dag,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  DagInit *getValueAsDag(StringRef FieldName) const;\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const Record &R);\n\nclass RecordKeeper {\n  using RecordMap = std::map<std::string, std::unique_ptr<Record>, std::less<>>;\n  using GlobalMap = std::map<std::string, Init *, std::less<>>;\n\npublic:\n  RecordKeeper();\n  ~RecordKeeper();\n\n  /// Return the internal implementation of the RecordKeeper.\n  detail::RecordKeeperImpl &getImpl() { return *Impl; }\n\n  /// Get the main TableGen input file's name.\n  const std::string getInputFilename() const { return InputFilename; }\n\n  /// Get the map of classes.\n  const RecordMap &getClasses() const { return Classes; }\n\n  /// Get the map of records (defs).\n  const RecordMap &getDefs() const { return Defs; }\n\n  /// Get the map of global variables.\n  const GlobalMap &getGlobals() const { return ExtraGlobals; }\n\n  /// Get the class with the specified name.\n  Record *getClass(StringRef Name) const {\n    auto I = Classes.find(Name);\n    return I == Classes.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the concrete record with the specified name.\n  Record *getDef(StringRef Name) const {\n    auto I = Defs.find(Name);\n    return I == Defs.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the \\p Init value of the specified global variable.\n  Init *getGlobal(StringRef Name) const {\n    if (Record *R = getDef(Name))\n      return R->getDefInit();\n    auto It = ExtraGlobals.find(Name);\n    return It == ExtraGlobals.end() ? nullptr : It->second;\n  }\n\n  void saveInputFilename(std::string Filename) {\n    InputFilename = Filename;\n  }\n\n  void addClass(std::unique_ptr<Record> R) {\n    bool Ins = Classes.insert(std::make_pair(std::string(R->getName()),\n                                             std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Class already exists\");\n  }\n\n  void addDef(std::unique_ptr<Record> R) {\n    bool Ins = Defs.insert(std::make_pair(std::string(R->getName()),\n                                          std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Record already exists\");\n  }\n\n  void addExtraGlobal(StringRef Name, Init *I) {\n    bool Ins = ExtraGlobals.insert(std::make_pair(std::string(Name), I)).second;\n    (void)Ins;\n    assert(!getDef(Name));\n    assert(Ins && \"Global already exists\");\n  }\n\n  Init *getNewAnonymousName();\n\n  /// Start phase timing; called if the --time-phases option is specified.\n  void startPhaseTiming() {\n    TimingGroup = new TimerGroup(\"TableGen\", \"TableGen Phase Timing\");\n  }\n\n  /// Start timing a phase. Automatically stops any previous phase timer.\n  void startTimer(StringRef Name);\n\n  /// Stop timing a phase.\n  void stopTimer();\n\n  /// Start timing the overall backend. If the backend itself starts a timer,\n  /// then this timer is cleared.\n  void startBackendTimer(StringRef Name);\n\n  /// Stop timing the overall backend.\n  void stopBackendTimer();\n\n  /// Stop phase timing and print the report.\n  void stopPhaseTiming() {\n    if (TimingGroup)\n      delete TimingGroup;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // High-level helper methods, useful for tablegen backends.\n\n  /// Get all the concrete records that inherit from the one specified\n  /// class. The class must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(StringRef ClassName) const;\n\n  /// Get all the concrete records that inherit from all the specified\n  /// classes. The classes must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(\n      ArrayRef<StringRef> ClassNames) const;\n\n  /// Get all the concrete records that inherit from specified class, if the\n  /// class is defined. Returns an empty vector if the class is not defined.\n  std::vector<Record *>\n  getAllDerivedDefinitionsIfDefined(StringRef ClassName) const;\n\n  void dump() const;\n\nprivate:\n  RecordKeeper(RecordKeeper &&) = delete;\n  RecordKeeper(const RecordKeeper &) = delete;\n  RecordKeeper &operator=(RecordKeeper &&) = delete;\n  RecordKeeper &operator=(const RecordKeeper &) = delete;\n\n  std::string InputFilename;\n  RecordMap Classes, Defs;\n  mutable StringMap<std::vector<Record *>> ClassRecordsMap;\n  GlobalMap ExtraGlobals;\n\n  // These members are for the phase timing feature. We need a timer group,\n  // the last timer started, and a flag to say whether the last timer\n  // is the special \"backend overall timer.\"\n  TimerGroup *TimingGroup = nullptr;\n  Timer *LastTimer = nullptr;\n  bool BackendTimer = false;\n\n  /// The internal uniquer implementation of the RecordKeeper.\n  std::unique_ptr<detail::RecordKeeperImpl> Impl;\n};\n\n/// Sorting predicate to sort record pointers by name.\nstruct LessRecord {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return StringRef(Rec1->getName()).compare_numeric(Rec2->getName()) < 0;\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// unique ID. If you just need a deterministic order, use this, since it\n/// just compares two `unsigned`; the other sorting predicates require\n/// string manipulation.\nstruct LessRecordByID {\n  bool operator()(const Record *LHS, const Record *RHS) const {\n    return LHS->getID() < RHS->getID();\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// name field.\nstruct LessRecordFieldName {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return Rec1->getValueAsString(\"Name\") < Rec2->getValueAsString(\"Name\");\n  }\n};\n\nstruct LessRecordRegister {\n  struct RecordParts {\n    SmallVector<std::pair< bool, StringRef>, 4> Parts;\n\n    RecordParts(StringRef Rec) {\n      if (Rec.empty())\n        return;\n\n      size_t Len = 0;\n      const char *Start = Rec.data();\n      const char *Curr = Start;\n      bool IsDigitPart = isDigit(Curr[0]);\n      for (size_t I = 0, E = Rec.size(); I != E; ++I, ++Len) {\n        bool IsDigit = isDigit(Curr[I]);\n        if (IsDigit != IsDigitPart) {\n          Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n          Len = 0;\n          Start = &Curr[I];\n          IsDigitPart = isDigit(Curr[I]);\n        }\n      }\n      // Push the last part.\n      Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n    }\n\n    size_t size() { return Parts.size(); }\n\n    std::pair<bool, StringRef> getPart(size_t i) {\n      assert (i < Parts.size() && \"Invalid idx!\");\n      return Parts[i];\n    }\n  };\n\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    int64_t LHSPositionOrder = Rec1->getValueAsInt(\"PositionOrder\");\n    int64_t RHSPositionOrder = Rec2->getValueAsInt(\"PositionOrder\");\n    if (LHSPositionOrder != RHSPositionOrder)\n      return LHSPositionOrder < RHSPositionOrder;\n\n    RecordParts LHSParts(StringRef(Rec1->getName()));\n    RecordParts RHSParts(StringRef(Rec2->getName()));\n\n    size_t LHSNumParts = LHSParts.size();\n    size_t RHSNumParts = RHSParts.size();\n    assert (LHSNumParts && RHSNumParts && \"Expected at least one part!\");\n\n    if (LHSNumParts != RHSNumParts)\n      return LHSNumParts < RHSNumParts;\n\n    // We expect the registers to be of the form [_a-zA-Z]+([0-9]*[_a-zA-Z]*)*.\n    for (size_t I = 0, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect even part to always be alpha.\n      assert (LHSPart.first == false && RHSPart.first == false &&\n              \"Expected both parts to be alpha.\");\n      if (int Res = LHSPart.second.compare(RHSPart.second))\n        return Res < 0;\n    }\n    for (size_t I = 1, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect odd part to always be numeric.\n      assert (LHSPart.first == true && RHSPart.first == true &&\n              \"Expected both parts to be numeric.\");\n      if (LHSPart.second.size() != RHSPart.second.size())\n        return LHSPart.second.size() < RHSPart.second.size();\n\n      unsigned LHSVal, RHSVal;\n\n      bool LHSFailed = LHSPart.second.getAsInteger(10, LHSVal); (void)LHSFailed;\n      assert(!LHSFailed && \"Unable to convert LHS to integer.\");\n      bool RHSFailed = RHSPart.second.getAsInteger(10, RHSVal); (void)RHSFailed;\n      assert(!RHSFailed && \"Unable to convert RHS to integer.\");\n\n      if (LHSVal != RHSVal)\n        return LHSVal < RHSVal;\n    }\n    return LHSNumParts < RHSNumParts;\n  }\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const RecordKeeper &RK);\n\n//===----------------------------------------------------------------------===//\n//  Resolvers\n//===----------------------------------------------------------------------===//\n\n/// Interface for looking up the initializer for a variable name, used by\n/// Init::resolveReferences.\nclass Resolver {\n  Record *CurRec;\n  bool IsFinal = false;\n\npublic:\n  explicit Resolver(Record *CurRec) : CurRec(CurRec) {}\n  virtual ~Resolver() = default;\n\n  Record *getCurrentRecord() const { return CurRec; }\n\n  /// Return the initializer for the given variable name (should normally be a\n  /// StringInit), or nullptr if the name could not be resolved.\n  virtual Init *resolve(Init *VarName) = 0;\n\n  // Whether bits in a BitsInit should stay unresolved if resolving them would\n  // result in a ? (UnsetInit). This behavior is used to represent instruction\n  // encodings by keeping references to unset variables within a record.\n  virtual bool keepUnsetBits() const { return false; }\n\n  // Whether this is the final resolve step before adding a record to the\n  // RecordKeeper. Error reporting during resolve and related constant folding\n  // should only happen when this is true.\n  bool isFinal() const { return IsFinal; }\n\n  void setFinal(bool Final) { IsFinal = Final; }\n};\n\n/// Resolve arbitrary mappings.\nclass MapResolver final : public Resolver {\n  struct MappedValue {\n    Init *V;\n    bool Resolved;\n\n    MappedValue() : V(nullptr), Resolved(false) {}\n    MappedValue(Init *V, bool Resolved) : V(V), Resolved(Resolved) {}\n  };\n\n  DenseMap<Init *, MappedValue> Map;\n\npublic:\n  explicit MapResolver(Record *CurRec = nullptr) : Resolver(CurRec) {}\n\n  void set(Init *Key, Init *Value) { Map[Key] = {Value, false}; }\n\n  bool isComplete(Init *VarName) const {\n    auto It = Map.find(VarName);\n    assert(It != Map.end() && \"key must be present in map\");\n    return It->second.V->isComplete();\n  }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Resolve all variables from a record except for unset variables.\nclass RecordResolver final : public Resolver {\n  DenseMap<Init *, Init *> Cache;\n  SmallVector<Init *, 4> Stack;\n  Init *Name = nullptr;\n\npublic:\n  explicit RecordResolver(Record &R) : Resolver(&R) {}\n\n  void setName(Init *NewName) { Name = NewName; }\n\n  Init *resolve(Init *VarName) override;\n\n  bool keepUnsetBits() const override { return true; }\n};\n\n/// Delegate resolving to a sub-resolver, but shadow some variable names.\nclass ShadowResolver final : public Resolver {\n  Resolver &R;\n  DenseSet<Init *> Shadowed;\n\npublic:\n  explicit ShadowResolver(Resolver &R)\n      : Resolver(R.getCurrentRecord()), R(R) {\n    setFinal(R.isFinal());\n  }\n\n  void addShadow(Init *Key) { Shadowed.insert(Key); }\n\n  Init *resolve(Init *VarName) override {\n    if (Shadowed.count(VarName))\n      return nullptr;\n    return R.resolve(VarName);\n  }\n};\n\n/// (Optionally) delegate resolving to a sub-resolver, and keep track whether\n/// there were unresolved references.\nclass TrackUnresolvedResolver final : public Resolver {\n  Resolver *R;\n  bool FoundUnresolved = false;\n\npublic:\n  explicit TrackUnresolvedResolver(Resolver *R = nullptr)\n      : Resolver(R ? R->getCurrentRecord() : nullptr), R(R) {}\n\n  bool foundUnresolved() const { return FoundUnresolved; }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Do not resolve anything, but keep track of whether a given variable was\n/// referenced.\nclass HasReferenceResolver final : public Resolver {\n  Init *VarNameToTrack;\n  bool Found = false;\n\npublic:\n  explicit HasReferenceResolver(Init *VarNameToTrack)\n      : Resolver(nullptr), VarNameToTrack(VarNameToTrack) {}\n\n  bool found() const { return Found; }\n\n  Init *resolve(Init *VarName) override;\n};\n\nvoid EmitDetailedRecords(RecordKeeper &RK, raw_ostream &OS);\nvoid EmitJSON(RecordKeeper &RK, raw_ostream &OS);\n\n} // end namespace llvm\n\n#endif // LLVM_TABLEGEN_RECORD_H\n"}], "code": "static bool checkOperandClass(CGIOperandList::OperandInfo &OI, Record *Leaf) {\n  if (OI.Rec == Leaf)\n    return true;\n\n  // Allow direct value types to be used in instruction set patterns.\n  // The type will be checked later.\n  if (Leaf->isSubClassOf(\"ValueType\"))\n    return true;\n\n  // Patterns can also be ComplexPattern instances.\n  if (Leaf->isSubClassOf(\"ComplexPattern\"))\n    return true;\n\n  return false;\n}\n"}, "F79A96D3CF50C978": {"calls": [{"id": "55959156AF3FC8F8", "name": "llvm::TreePattern::getRecord", "path": "llvm-project/llvm/utils/TableGen/CodeGenDAGPatterns.h", "start": {"line": 935, "col": 3}, "end": {"line": 935, "col": 49}, "code": "\n  unsigned getNumArgs() const { return Args.size(); }\n  const std::string &getArgName(unsigned i) const {\n    assert(i < Args.size() && \"Argument reference out of range!\");\n    return Args[i];\n  }\n  std::vector<std::string> &getArgList() { return Args; }\n\n  CodeGenDAGPatterns &getDAGPatterns() const { return CDP; }\n\n  /// InlinePatternFragments - If this pattern refers to any pattern\n  /// fragments, inline them into place, giving us a pattern without any\n  /// PatFrags references.  This may increase the number of trees in the\n  /// pattern if a PatFrags has multiple alternatives.\n  void InlinePatternFragments() {\n    std::vector<TreePatternNodePtr> Copy;\n    Trees.swap(Copy);\n    for (const TreePatternNodePtr &C : Copy)\n      C->InlinePatternFragments(*this, Trees);\n  }\n\n  /// InferAllTypes - Infer/propagate as many types throughout the expression\n  /// patterns as possible.  Return true if all types are inferred, false\n  /// otherwise.  Bail out if a type contradiction is found.\n  bool InferAllTypes(\n      const StringMap<SmallVector<TreePatternNode *, 1>> *NamedTypes = nullptr);\n\n  /// error - If this is the first error in the current resolution step,\n  /// print it and set the error flag.  Otherwise, continue silently.\n  void error(const Twine &Msg);\n  bool hasError() const { return HasError; }\n  void resetError() { HasError = false; }\n\n  TypeInfer &getInfer() { return Infer; }\n\n  void print(raw_ostream &OS) const;\n  void dump() const;\n\nprivate:\n  TreePatternNodePtr ParseTreePattern(Init *DI, StringRef OpName);\n  void ComputeNamedNodes();\n  void ComputeNamedNodes(TreePatternNode &N);\n};\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            const TypeSetByHwMode &InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            MVT::SimpleValueType InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\ninline bool TreePatternNode::UpdateNodeType(unsigned ResNo,\n                                            ValueTypeByHwMode InTy,\n                                            TreePattern &TP) {\n  TypeSetByHwMode VTS(InTy);\n  TP.getInfer().expandOverloads(VTS);\n  return TP.getInfer().MergeInTypeInfo(Types[ResNo], VTS);\n}\n\n/// DAGDefaultOperand - One of these is created for each OperandWithDefaultOps\n/// that has a set ExecuteAlways / DefaultOps field.\nstruct DAGDefaultOperand {\n  std::vector<TreePatternNodePtr> DefaultOps;\n};\n\nclass DAGInstruction {\n  std::vector<Record *> Results;\n  std::vector<Record *> Operands;\n  std::vector<Record *> ImpResults;\n  TreePatternNodePtr SrcPattern;\n  TreePatternNodePtr ResultPattern;\n\npublic:\n  DAGInstruction(std::vector<Record *> &&results,\n                 std::vector<Record *> &&operands,\n                 std::vector<Record *> &&impresults,\n                 TreePatternNodePtr srcpattern = nullptr,\n                 TreePatternNodePtr resultpattern = nullptr)\n      : Results(std::move(results)), Operands(std::move(operands)),\n        ImpResults(std::move(impresults)), SrcPattern(srcpattern),\n        ResultPattern(resultpattern) {}\n\n  unsigned getNumResults() const { return Results.size(); }\n  unsigned getNumOperands() const { return Operands.size(); }\n  unsigned getNumImpResults() const { return ImpResults.size(); }\n  const std::vector<Record *> &getImpResults() const { return ImpResults; }\n\n  Record *getResult(unsigned RN) const {\n    assert(RN < Results.size());\n    return Results[RN];\n  }\n\n  Record *getOperand(unsigned ON) const {\n    assert(ON < Operands.size());\n    return Operands[ON];\n  }\n\n  Record *getImpResult(unsigned RN) const {\n    assert(RN < ImpResults.size());\n    return ImpResults[RN];\n  }\n\n  TreePatternNodePtr getSrcPattern() const { return SrcPattern; }\n  TreePatternNodePtr getResultPattern() const { return ResultPattern; }\n};\n\n/// PatternToMatch - Used by CodeGenDAGPatterns to keep tab of patterns\n/// processed to produce isel.\nclass PatternToMatch {\n  Record *SrcRecord;             // Originating Record for the pattern.\n  ListInit *Predicates;          // Top level predicate conditions to match.\n  TreePatternNodePtr SrcPattern; // Source pattern to match.\n  TreePatternNodePtr DstPattern; // Resulting pattern.\n  std::vector<Record *> Dstregs; // Physical register defs being matched.\n  std::string HwModeFeatures;\n  int AddedComplexity; // Add to matching pattern complexity.\n  unsigned ID;         // Unique ID for the record.\n\npublic:\n  PatternToMatch(Record *srcrecord, ListInit *preds, TreePatternNodePtr src,\n                 TreePatternNodePtr dst, std::vector<Record *> dstregs,\n                 int complexity, unsigned uid, const Twine &hwmodefeatures = \"\")\n      : SrcRecord(srcrecord), Predicates(preds), SrcPattern(src),\n        DstPattern(dst), Dstregs(std::move(dstregs)),\n        HwModeFeatures(hwmodefeatures.str()), AddedComplexity(complexity),\n        ID(uid) {}\n\n  Record *getSrcRecord() const { return SrcRecord; }\n  ListInit *getPredicates() const { return Predicates; }\n  TreePatternNode &getSrcPattern() const { return *SrcPattern; }\n  TreePatternNodePtr getSrcPatternShared() const { return SrcPattern; }\n  TreePatternNode &getDstPattern() const { return *DstPattern; }\n  TreePatternNodePtr getDstPatternShared() const { return DstPattern; }\n  const std::vector<Record *> &getDstRegs() const { return Dstregs; }\n  StringRef getHwModeFeatures() const { return HwModeFeatures; }\n  int getAddedComplexity() const { return AddedComplexity; }\n  unsigned getID() const { return ID; }\n\n  std::string getPredicateCheck() const;\n  void getPredicateRecords(SmallVectorImpl<Record *> &PredicateRecs) const;\n\n  /// Compute the complexity metric for the input pattern.  This roughly\n  /// corresponds to the number of nodes that are covered.\n  int getPatternComplexity(const CodeGenDAGPatterns &CGP) const;\n};\n\nclass CodeGenDAGPatterns {\n  RecordKeeper &Records;\n  CodeGenTarget Target;\n  CodeGenIntrinsicTable Intrinsics;\n\n  std::map<Record *, SDNodeInfo, LessRecordByID> SDNodes;\n  std::map<Record *, std::pair<Record *, std::string>, LessRecordByID>\n      SDNodeXForms;\n  std::map<Record *, ComplexPattern, LessRecordByID> ComplexPatterns;\n  std::map<Record *, std::unique_ptr<TreePattern>, LessRecordByID>\n      PatternFragments;\n  std::map<Record *, DAGDefaultOperand, LessRecordByID> DefaultOperands;\n  std::map<Record *, DAGInstruction, LessRecordByID> Instructions;\n\n  // Specific SDNode definitions:\n  Record *intrinsic_void_sdnode;\n  Record *intrinsic_w_chain_sdnode, *intrinsic_wo_chain_sdnode;\n\n  /// PatternsToMatch - All of the things we are matching on the DAG.  The first\n  /// value is the pattern to match, the second pattern is the result to\n  /// emit.\n  std::vector<PatternToMatch> PatternsToMatch;\n\n  TypeSetByHwMode LegalVTS;\n\n  using PatternRewriterFn = std::function<void(TreePattern *)>;\n  PatternRewriterFn PatternRewriter;\n\n  unsigned NumScopes = 0;\n\npublic:\n  CodeGenDAGPatterns(RecordKeeper &R,\n                     PatternRewriterFn PatternRewriter = nullptr);\n\n  CodeGenTarget &getTargetInfo() { return Target; }\n  const CodeGenTarget &getTargetInfo() const { return Target; }\n  const TypeSetByHwMode &getLegalTypes() const { return LegalVTS; }\n\n  Record *getSDNodeNamed(StringRef Name) const;\n\n  const SDNodeInfo &getSDNodeInfo(Record *R) const {\n    auto F = SDNodes.find(R);\n    assert(F != SDNodes.end() && \"Unknown node!\");\n    return F->second;\n  }\n\n  // Node transformation lookups.\n  typedef std::pair<Record *, std::string> NodeXForm;\n  const NodeXForm &getSDNodeTransform(Record *R) const {\n    auto F = SDNodeXForms.find(R);\n    assert(F != SDNodeXForms.end() && \"Invalid transform!\");\n    return F->second;\n  }\n\n  const ComplexPattern &getComplexPattern(Record *R) const {\n    auto F = ComplexPatterns.find(R);\n    assert(F != ComplexPatterns.end() && \"Unknown addressing mode!\");\n    return F->second;\n  }\n\n  const CodeGenIntrinsic &getIntrinsic(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return Intrinsics[i];\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const CodeGenIntrinsic &getIntrinsicInfo(unsigned IID) const {\n    if (IID - 1 < Intrinsics.size())\n      return Intrinsics[IID - 1];\n    llvm_unreachable(\"Bad intrinsic ID!\");\n  }\n\n  unsigned getIntrinsicID(Record *R) const {\n    for (unsigned i = 0, e = Intrinsics.size(); i != e; ++i)\n      if (Intrinsics[i].TheDef == R)\n        return i;\n    llvm_unreachable(\"Unknown intrinsic!\");\n  }\n\n  const DAGDefaultOperand &getDefaultOperand(Record *R) const {\n    auto F = DefaultOperands.find(R);\n    assert(F != DefaultOperands.end() && \"Isn't an analyzed default operand!\");\n    return F->second;\n  }\n\n  // Pattern Fragment information.\n  TreePattern *getPatternFragment(Record *R) const {\n    auto F = PatternFragments.find(R);\n    assert(F != PatternFragments.end() && \"Invalid pattern fragment request!\");\n    return F->second.get();\n  }\n  TreePattern *getPatternFragmentIfRead(Record *R) const {\n    auto F = PatternFragments.find(R);\n    if (F == PatternFragments.end())\n      return nullptr;\n    return F->second.get();\n  }\n\n  typedef std::map<Record *, std::unique_ptr<TreePattern>,\n                   LessRecordByID>::const_iterator pf_iterator;\n  pf_iterator pf_begin() const { return PatternFragments.begin(); }\n  pf_iterator pf_end() const { return PatternFragments.end(); }\n  iterator_range<pf_iterator> ptfs() const { return PatternFragments; }\n\n  // Patterns to match information.\n  typedef std::vector<PatternToMatch>::const_iterator ptm_iterator;\n  ptm_iterator ptm_begin() const { return PatternsToMatch.begin(); }\n  ptm_iterator ptm_end() const { return PatternsToMatch.end(); }\n  iterator_range<ptm_iterator> ptms() const { return PatternsToMatch; }\n\n  /// Parse the Pattern for an instruction, and insert the result in DAGInsts.\n  typedef std::map<Record *, DAGInstruction, LessRecordByID> DAGInstMap;\n  void parseInstructionPattern(CodeGenInstruction &CGI, ListInit *Pattern,\n                               DAGInstMap &DAGInsts);\n\n  const DAGInstruction &getInstruction(Record *R) const {\n    auto F = Instructions.find(R);\n    assert(F != Instructions.end() && \"Unknown instruction!\");\n    return F->second;\n  }\n\n  Record *get_intrinsic_void_sdnode() const { return intrinsic_void_sdnode; }\n  Record *get_intrinsic_w_chain_sdnode() const {\n    return intrinsic_w_chain_sdnode;\n  }\n  Record *get_intrinsic_wo_chain_sdnode() const {\n    return intrinsic_wo_chain_sdnode;\n  }\n\n  unsigned allocateScope() { return ++NumScopes; }\n\n  bool operandHasDefault(Record *Op) const {\n    return Op->isSubClassOf(\"OperandWithDefaultOps\") &&\n           !getDefaultOperand(Op).DefaultOps.empty();\n  }\n\nprivate:\n  void ParseNodeInfo();\n  void ParseNodeTransforms();\n  void ParseComplexPatterns();\n  void ParsePatternFragments(bool OutFrags = false);\n  void ParseDefaultOperands();\n  void ParseInstructions();\n  void ParsePatterns();\n  void ExpandHwModeBasedTypes();\n  void InferInstructionFlags();\n  void GenerateVariants();\n  void VerifyInstructionFlags();\n\n  void ParseOnePattern(Record *TheDef, TreePattern &Pattern,\n                       TreePattern &Result,\n                       const std::vector<Record *> &InstImpResults);\n  void AddPatternToMatch(TreePattern *Pattern, PatternToMatch &&PTM);\n  void FindPatternInputsAndOutputs(\n      TreePattern &I, TreePatternNodePtr Pat,\n      std::map<std::string, TreePatternNodePtr> &InstInputs,\n      MapVector<std::string, TreePatternNodePtr,\n                std::map<std::string, unsigned>> &InstResults,\n      std::vector<Record *> &InstImpResults);\n};\n\ninline bool SDNodeInfo::ApplyTypeConstraints(TreePatternNode &N,\n                                             TreePattern &TP) const {\n  bool MadeChange = false;\n  for (unsigned i = 0, e = TypeConstraints.size(); i != e; ++i)\n    MadeChange |= TypeConstraints[i].ApplyTypeConstraint(N, *this, TP);\n  return MadeChange;\n}\n\n} // end namespace llvm\n\n#endif\n"}, {"id": "19BBFE92FFE321C0", "name": "llvm::Record::isValueUnset", "path": "llvm-project/llvm/include/llvm/TableGen/Record.h", "start": {"line": 1891, "col": 3}, "end": {"line": 1893, "col": 3}, "code": "    return isa<UnsetInit>(getValueInit(FieldName));\n  }\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the field does not exist or if the value\n  /// is not a string.\n  StringRef getValueAsString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// string, throwing an exception if the value is not a string and\n  /// std::nullopt if the field does not exist.\n  std::optional<StringRef> getValueAsOptionalString(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// BitsInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  BitsInit *getValueAsBitsInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// ListInit, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  ListInit *getValueAsListInit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of records, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<Record*> getValueAsListOfDefs(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of integers, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<int64_t> getValueAsListOfInts(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// vector of strings, throwing an exception if the field does not exist or\n  /// if the value is not the right type.\n  std::vector<StringRef> getValueAsListOfStrings(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, throwing an exception if the field does not exist or if the value\n  /// is not the right type.\n  Record *getValueAsDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a\n  /// Record, returning null if the field exists but is \"uninitialized\" (i.e.\n  /// set to `?`), and throwing an exception if the field does not exist or if\n  /// its value is not the right type.\n  Record *getValueAsOptionalDef(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  bool getValueAsBit(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as a bit.\n  /// If the field is unset, sets Unset to true and returns false.\n  bool getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const;\n\n  /// This method looks up the specified field and returns its value as an\n  /// int64_t, throwing an exception if the field does not exist or if the\n  /// value is not the right type.\n  int64_t getValueAsInt(StringRef FieldName) const;\n\n  /// This method looks up the specified field and returns its value as an Dag,\n  /// throwing an exception if the field does not exist or if the value is not\n  /// the right type.\n  DagInit *getValueAsDag(StringRef FieldName) const;\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const Record &R);\n\nclass RecordKeeper {\n  using RecordMap = std::map<std::string, std::unique_ptr<Record>, std::less<>>;\n  using GlobalMap = std::map<std::string, Init *, std::less<>>;\n\npublic:\n  RecordKeeper();\n  ~RecordKeeper();\n\n  /// Return the internal implementation of the RecordKeeper.\n  detail::RecordKeeperImpl &getImpl() { return *Impl; }\n\n  /// Get the main TableGen input file's name.\n  const std::string getInputFilename() const { return InputFilename; }\n\n  /// Get the map of classes.\n  const RecordMap &getClasses() const { return Classes; }\n\n  /// Get the map of records (defs).\n  const RecordMap &getDefs() const { return Defs; }\n\n  /// Get the map of global variables.\n  const GlobalMap &getGlobals() const { return ExtraGlobals; }\n\n  /// Get the class with the specified name.\n  Record *getClass(StringRef Name) const {\n    auto I = Classes.find(Name);\n    return I == Classes.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the concrete record with the specified name.\n  Record *getDef(StringRef Name) const {\n    auto I = Defs.find(Name);\n    return I == Defs.end() ? nullptr : I->second.get();\n  }\n\n  /// Get the \\p Init value of the specified global variable.\n  Init *getGlobal(StringRef Name) const {\n    if (Record *R = getDef(Name))\n      return R->getDefInit();\n    auto It = ExtraGlobals.find(Name);\n    return It == ExtraGlobals.end() ? nullptr : It->second;\n  }\n\n  void saveInputFilename(std::string Filename) {\n    InputFilename = Filename;\n  }\n\n  void addClass(std::unique_ptr<Record> R) {\n    bool Ins = Classes.insert(std::make_pair(std::string(R->getName()),\n                                             std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Class already exists\");\n  }\n\n  void addDef(std::unique_ptr<Record> R) {\n    bool Ins = Defs.insert(std::make_pair(std::string(R->getName()),\n                                          std::move(R))).second;\n    (void)Ins;\n    assert(Ins && \"Record already exists\");\n  }\n\n  void addExtraGlobal(StringRef Name, Init *I) {\n    bool Ins = ExtraGlobals.insert(std::make_pair(std::string(Name), I)).second;\n    (void)Ins;\n    assert(!getDef(Name));\n    assert(Ins && \"Global already exists\");\n  }\n\n  Init *getNewAnonymousName();\n\n  /// Start phase timing; called if the --time-phases option is specified.\n  void startPhaseTiming() {\n    TimingGroup = new TimerGroup(\"TableGen\", \"TableGen Phase Timing\");\n  }\n\n  /// Start timing a phase. Automatically stops any previous phase timer.\n  void startTimer(StringRef Name);\n\n  /// Stop timing a phase.\n  void stopTimer();\n\n  /// Start timing the overall backend. If the backend itself starts a timer,\n  /// then this timer is cleared.\n  void startBackendTimer(StringRef Name);\n\n  /// Stop timing the overall backend.\n  void stopBackendTimer();\n\n  /// Stop phase timing and print the report.\n  void stopPhaseTiming() {\n    if (TimingGroup)\n      delete TimingGroup;\n  }\n\n  //===--------------------------------------------------------------------===//\n  // High-level helper methods, useful for tablegen backends.\n\n  /// Get all the concrete records that inherit from the one specified\n  /// class. The class must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(StringRef ClassName) const;\n\n  /// Get all the concrete records that inherit from all the specified\n  /// classes. The classes must be defined.\n  std::vector<Record *> getAllDerivedDefinitions(\n      ArrayRef<StringRef> ClassNames) const;\n\n  /// Get all the concrete records that inherit from specified class, if the\n  /// class is defined. Returns an empty vector if the class is not defined.\n  std::vector<Record *>\n  getAllDerivedDefinitionsIfDefined(StringRef ClassName) const;\n\n  void dump() const;\n\nprivate:\n  RecordKeeper(RecordKeeper &&) = delete;\n  RecordKeeper(const RecordKeeper &) = delete;\n  RecordKeeper &operator=(RecordKeeper &&) = delete;\n  RecordKeeper &operator=(const RecordKeeper &) = delete;\n\n  std::string InputFilename;\n  RecordMap Classes, Defs;\n  mutable StringMap<std::vector<Record *>> ClassRecordsMap;\n  GlobalMap ExtraGlobals;\n\n  // These members are for the phase timing feature. We need a timer group,\n  // the last timer started, and a flag to say whether the last timer\n  // is the special \"backend overall timer.\"\n  TimerGroup *TimingGroup = nullptr;\n  Timer *LastTimer = nullptr;\n  bool BackendTimer = false;\n\n  /// The internal uniquer implementation of the RecordKeeper.\n  std::unique_ptr<detail::RecordKeeperImpl> Impl;\n};\n\n/// Sorting predicate to sort record pointers by name.\nstruct LessRecord {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return StringRef(Rec1->getName()).compare_numeric(Rec2->getName()) < 0;\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// unique ID. If you just need a deterministic order, use this, since it\n/// just compares two `unsigned`; the other sorting predicates require\n/// string manipulation.\nstruct LessRecordByID {\n  bool operator()(const Record *LHS, const Record *RHS) const {\n    return LHS->getID() < RHS->getID();\n  }\n};\n\n/// Sorting predicate to sort record pointers by their\n/// name field.\nstruct LessRecordFieldName {\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    return Rec1->getValueAsString(\"Name\") < Rec2->getValueAsString(\"Name\");\n  }\n};\n\nstruct LessRecordRegister {\n  struct RecordParts {\n    SmallVector<std::pair< bool, StringRef>, 4> Parts;\n\n    RecordParts(StringRef Rec) {\n      if (Rec.empty())\n        return;\n\n      size_t Len = 0;\n      const char *Start = Rec.data();\n      const char *Curr = Start;\n      bool IsDigitPart = isDigit(Curr[0]);\n      for (size_t I = 0, E = Rec.size(); I != E; ++I, ++Len) {\n        bool IsDigit = isDigit(Curr[I]);\n        if (IsDigit != IsDigitPart) {\n          Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n          Len = 0;\n          Start = &Curr[I];\n          IsDigitPart = isDigit(Curr[I]);\n        }\n      }\n      // Push the last part.\n      Parts.push_back(std::make_pair(IsDigitPart, StringRef(Start, Len)));\n    }\n\n    size_t size() { return Parts.size(); }\n\n    std::pair<bool, StringRef> getPart(size_t i) {\n      assert (i < Parts.size() && \"Invalid idx!\");\n      return Parts[i];\n    }\n  };\n\n  bool operator()(const Record *Rec1, const Record *Rec2) const {\n    int64_t LHSPositionOrder = Rec1->getValueAsInt(\"PositionOrder\");\n    int64_t RHSPositionOrder = Rec2->getValueAsInt(\"PositionOrder\");\n    if (LHSPositionOrder != RHSPositionOrder)\n      return LHSPositionOrder < RHSPositionOrder;\n\n    RecordParts LHSParts(StringRef(Rec1->getName()));\n    RecordParts RHSParts(StringRef(Rec2->getName()));\n\n    size_t LHSNumParts = LHSParts.size();\n    size_t RHSNumParts = RHSParts.size();\n    assert (LHSNumParts && RHSNumParts && \"Expected at least one part!\");\n\n    if (LHSNumParts != RHSNumParts)\n      return LHSNumParts < RHSNumParts;\n\n    // We expect the registers to be of the form [_a-zA-Z]+([0-9]*[_a-zA-Z]*)*.\n    for (size_t I = 0, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect even part to always be alpha.\n      assert (LHSPart.first == false && RHSPart.first == false &&\n              \"Expected both parts to be alpha.\");\n      if (int Res = LHSPart.second.compare(RHSPart.second))\n        return Res < 0;\n    }\n    for (size_t I = 1, E = LHSNumParts; I < E; I+=2) {\n      std::pair<bool, StringRef> LHSPart = LHSParts.getPart(I);\n      std::pair<bool, StringRef> RHSPart = RHSParts.getPart(I);\n      // Expect odd part to always be numeric.\n      assert (LHSPart.first == true && RHSPart.first == true &&\n              \"Expected both parts to be numeric.\");\n      if (LHSPart.second.size() != RHSPart.second.size())\n        return LHSPart.second.size() < RHSPart.second.size();\n\n      unsigned LHSVal, RHSVal;\n\n      bool LHSFailed = LHSPart.second.getAsInteger(10, LHSVal); (void)LHSFailed;\n      assert(!LHSFailed && \"Unable to convert LHS to integer.\");\n      bool RHSFailed = RHSPart.second.getAsInteger(10, RHSVal); (void)RHSFailed;\n      assert(!RHSFailed && \"Unable to convert RHS to integer.\");\n\n      if (LHSVal != RHSVal)\n        return LHSVal < RHSVal;\n    }\n    return LHSNumParts < RHSNumParts;\n  }\n};\n\nraw_ostream &operator<<(raw_ostream &OS, const RecordKeeper &RK);\n\n//===----------------------------------------------------------------------===//\n//  Resolvers\n//===----------------------------------------------------------------------===//\n\n/// Interface for looking up the initializer for a variable name, used by\n/// Init::resolveReferences.\nclass Resolver {\n  Record *CurRec;\n  bool IsFinal = false;\n\npublic:\n  explicit Resolver(Record *CurRec) : CurRec(CurRec) {}\n  virtual ~Resolver() = default;\n\n  Record *getCurrentRecord() const { return CurRec; }\n\n  /// Return the initializer for the given variable name (should normally be a\n  /// StringInit), or nullptr if the name could not be resolved.\n  virtual Init *resolve(Init *VarName) = 0;\n\n  // Whether bits in a BitsInit should stay unresolved if resolving them would\n  // result in a ? (UnsetInit). This behavior is used to represent instruction\n  // encodings by keeping references to unset variables within a record.\n  virtual bool keepUnsetBits() const { return false; }\n\n  // Whether this is the final resolve step before adding a record to the\n  // RecordKeeper. Error reporting during resolve and related constant folding\n  // should only happen when this is true.\n  bool isFinal() const { return IsFinal; }\n\n  void setFinal(bool Final) { IsFinal = Final; }\n};\n\n/// Resolve arbitrary mappings.\nclass MapResolver final : public Resolver {\n  struct MappedValue {\n    Init *V;\n    bool Resolved;\n\n    MappedValue() : V(nullptr), Resolved(false) {}\n    MappedValue(Init *V, bool Resolved) : V(V), Resolved(Resolved) {}\n  };\n\n  DenseMap<Init *, MappedValue> Map;\n\npublic:\n  explicit MapResolver(Record *CurRec = nullptr) : Resolver(CurRec) {}\n\n  void set(Init *Key, Init *Value) { Map[Key] = {Value, false}; }\n\n  bool isComplete(Init *VarName) const {\n    auto It = Map.find(VarName);\n    assert(It != Map.end() && \"key must be present in map\");\n    return It->second.V->isComplete();\n  }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Resolve all variables from a record except for unset variables.\nclass RecordResolver final : public Resolver {\n  DenseMap<Init *, Init *> Cache;\n  SmallVector<Init *, 4> Stack;\n  Init *Name = nullptr;\n\npublic:\n  explicit RecordResolver(Record &R) : Resolver(&R) {}\n\n  void setName(Init *NewName) { Name = NewName; }\n\n  Init *resolve(Init *VarName) override;\n\n  bool keepUnsetBits() const override { return true; }\n};\n\n/// Delegate resolving to a sub-resolver, but shadow some variable names.\nclass ShadowResolver final : public Resolver {\n  Resolver &R;\n  DenseSet<Init *> Shadowed;\n\npublic:\n  explicit ShadowResolver(Resolver &R)\n      : Resolver(R.getCurrentRecord()), R(R) {\n    setFinal(R.isFinal());\n  }\n\n  void addShadow(Init *Key) { Shadowed.insert(Key); }\n\n  Init *resolve(Init *VarName) override {\n    if (Shadowed.count(VarName))\n      return nullptr;\n    return R.resolve(VarName);\n  }\n};\n\n/// (Optionally) delegate resolving to a sub-resolver, and keep track whether\n/// there were unresolved references.\nclass TrackUnresolvedResolver final : public Resolver {\n  Resolver *R;\n  bool FoundUnresolved = false;\n\npublic:\n  explicit TrackUnresolvedResolver(Resolver *R = nullptr)\n      : Resolver(R ? R->getCurrentRecord() : nullptr), R(R) {}\n\n  bool foundUnresolved() const { return FoundUnresolved; }\n\n  Init *resolve(Init *VarName) override;\n};\n\n/// Do not resolve anything, but keep track of whether a given variable was\n/// referenced.\nclass HasReferenceResolver final : public Resolver {\n  Init *VarNameToTrack;\n  bool Found = false;\n\npublic:\n  explicit HasReferenceResolver(Init *VarNameToTrack)\n      : Resolver(nullptr), VarNameToTrack(VarNameToTrack) {}\n\n  bool found() const { return Found; }\n\n  Init *resolve(Init *VarName) override;\n};\n\nvoid EmitDetailedRecords(RecordKeeper &RK, raw_ostream &OS);\nvoid EmitJSON(RecordKeeper &RK, raw_ostream &OS);\n\n} // end namespace llvm\n\n#endif // LLVM_TABLEGEN_RECORD_H\n"}, {"id": "2DEF2489EBC0C3D5", "name": "llvm::Record::getValueAsDef", "path": "llvm-project/llvm/lib/TableGen/Record.cpp", "start": {"line": 3054, "col": 1}, "end": {"line": 3064, "col": 1}, "code": "  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a def initializer!\");\n}\n\nRecord *Record::getValueAsOptionalDef(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DefInit *DI = dyn_cast<DefInit>(R->getValue()))\n    return DI->getDef();\n  if (isa<UnsetInit>(R->getValue()))\n    return nullptr;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have either a def initializer or '?'!\");\n}\n\n\nbool Record::getValueAsBit(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nbool Record::getValueAsBitOrUnset(StringRef FieldName, bool &Unset) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName.str() + \"'!\\n\");\n\n  if (isa<UnsetInit>(R->getValue())) {\n    Unset = true;\n    return false;\n  }\n  Unset = false;\n  if (BitInit *BI = dyn_cast<BitInit>(R->getValue()))\n    return BI->getValue();\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a bit initializer!\");\n}\n\nDagInit *Record::getValueAsDag(StringRef FieldName) const {\n  const RecordVal *R = getValue(FieldName);\n  if (!R || !R->getValue())\n    PrintFatalError(getLoc(), \"Record `\" + getName() +\n      \"' does not have a field named `\" + FieldName + \"'!\\n\");\n\n  if (DagInit *DI = dyn_cast<DagInit>(R->getValue()))\n    return DI;\n  PrintFatalError(getLoc(), \"Record `\" + getName() + \"', field `\" +\n    FieldName + \"' does not have a dag initializer!\");\n}\n\n// Check all record assertions: For each one, resolve the condition\n// and message, then call CheckAssert().\n// Note: The condition and message are probably already resolved,\n//       but resolving again allows calls before records are resolved.\nvoid Record::checkRecordAssertions() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Assertion : getAssertions()) {\n    Init *Condition = Assertion.Condition->resolveReferences(R);\n    Init *Message = Assertion.Message->resolveReferences(R);\n    CheckAssert(Assertion.Loc, Condition, Message);\n  }\n}\n\nvoid Record::emitRecordDumps() {\n  RecordResolver R(*this);\n  R.setFinal(true);\n\n  for (const auto &Dump : getDumps()) {\n    Init *Message = Dump.Message->resolveReferences(R);\n    dumpMessage(Dump.Loc, Message);\n  }\n}\n\n// Report a warning if the record has unused template arguments.\nvoid Record::checkUnusedTemplateArgs() {\n  for (const Init *TA : getTemplateArgs()) {\n    const RecordVal *Arg = getValue(TA);\n    if (!Arg->isUsed())\n      PrintWarning(Arg->getLoc(),\n                   \"unused template argument: \" + Twine(Arg->getName()));\n  }\n}\n\nRecordKeeper::RecordKeeper()\n    : Impl(std::make_unique<detail::RecordKeeperImpl>(*this)) {}\nRecordKeeper::~RecordKeeper() = default;\n\n#if !defined(NDEBUG) || defined(LLVM_ENABLE_DUMP)\nLLVM_DUMP_METHOD void RecordKeeper::dump() const { errs() << *this; }\n#endif\n\nraw_ostream &llvm::operator<<(raw_ostream &OS, const RecordKeeper &RK) {\n  OS << \"------------- Classes -----------------\\n\";\n  for (const auto &C : RK.getClasses())\n    OS << \"class \" << *C.second;\n\n  OS << \"------------- Defs -----------------\\n\";\n  for (const auto &D : RK.getDefs())\n    OS << \"def \" << *D.second;\n  return OS;\n}\n\n/// GetNewAnonymousName - Generate a unique anonymous name that can be used as\n/// an identifier.\nInit *RecordKeeper::getNewAnonymousName() {\n  return AnonymousNameInit::get(*this, getImpl().AnonCounter++);\n}\n\n// These functions implement the phase timing facility. Starting a timer\n// when one is already running stops the running one.\n\nvoid RecordKeeper::startTimer(StringRef Name) {\n  if (TimingGroup) {\n    if (LastTimer && LastTimer->isRunning()) {\n      LastTimer->stopTimer();\n      if (BackendTimer) {\n        LastTimer->clear();\n        BackendTimer = false;\n      }\n    }\n\n    LastTimer = new Timer(\"\", Name, *TimingGroup);\n    LastTimer->startTimer();\n  }\n}\n\nvoid RecordKeeper::stopTimer() {\n  if (TimingGroup) {\n    assert(LastTimer && \"No phase timer was started\");\n    LastTimer->stopTimer();\n  }\n}\n\nvoid RecordKeeper::startBackendTimer(StringRef Name) {\n  if (TimingGroup) {\n    startTimer(Name);\n    BackendTimer = true;\n  }\n}\n\nvoid RecordKeeper::stopBackendTimer() {\n  if (TimingGroup) {\n    if (BackendTimer) {\n      stopTimer();\n      BackendTimer = false;\n    }\n  }\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitions(StringRef ClassName) const {\n  // We cache the record vectors for single classes. Many backends request\n  // the same vectors multiple times.\n  auto Pair = ClassRecordsMap.try_emplace(ClassName);\n  if (Pair.second)\n    Pair.first->second = getAllDerivedDefinitions(ArrayRef(ClassName));\n\n  return Pair.first->second;\n}\n\nstd::vector<Record *> RecordKeeper::getAllDerivedDefinitions(\n    ArrayRef<StringRef> ClassNames) const {\n  SmallVector<Record *, 2> ClassRecs;\n  std::vector<Record *> Defs;\n\n  assert(ClassNames.size() > 0 && \"At least one class must be passed.\");\n  for (const auto &ClassName : ClassNames) {\n    Record *Class = getClass(ClassName);\n    if (!Class)\n      PrintFatalError(\"The class '\" + ClassName + \"' is not defined\\n\");\n    ClassRecs.push_back(Class);\n  }\n\n  for (const auto &OneDef : getDefs()) {\n    if (all_of(ClassRecs, [&OneDef](const Record *Class) {\n                            return OneDef.second->isSubClassOf(Class);\n                          }))\n      Defs.push_back(OneDef.second.get());\n  }\n\n  llvm::sort(Defs, [](Record *LHS, Record *RHS) {\n    return LHS->getName().compare_numeric(RHS->getName()) < 0;\n  });\n\n  return Defs;\n}\n\nstd::vector<Record *>\nRecordKeeper::getAllDerivedDefinitionsIfDefined(StringRef ClassName) const {\n  return getClass(ClassName) ? getAllDerivedDefinitions(ClassName)\n                             : std::vector<Record *>();\n}\n\nInit *MapResolver::resolve(Init *VarName) {\n  auto It = Map.find(VarName);\n  if (It == Map.end())\n    return nullptr;\n\n  Init *I = It->second.V;\n\n  if (!It->second.Resolved && Map.size() > 1) {\n    // Resolve mutual references among the mapped variables, but prevent\n    // infinite recursion.\n    Map.erase(It);\n    I = I->resolveReferences(*this);\n    Map[VarName] = {I, true};\n  }\n\n  return I;\n}\n\nInit *RecordResolver::resolve(Init *VarName) {\n  Init *Val = Cache.lookup(VarName);\n  if (Val)\n    return Val;\n\n  if (llvm::is_contained(Stack, VarName))\n    return nullptr; // prevent infinite recursion\n\n  if (RecordVal *RV = getCurrentRecord()->getValue(VarName)) {\n    if (!isa<UnsetInit>(RV->getValue())) {\n      Val = RV->getValue();\n      Stack.push_back(VarName);\n      Val = Val->resolveReferences(*this);\n      Stack.pop_back();\n    }\n  } else if (Name && VarName == getCurrentRecord()->getNameInit()) {\n    Stack.push_back(VarName);\n    Val = Name->resolveReferences(*this);\n    Stack.pop_back();\n  }\n\n  Cache[VarName] = Val;\n  return Val;\n}\n\nInit *TrackUnresolvedResolver::resolve(Init *VarName) {\n  Init *I = nullptr;\n\n  if (R) {\n    I = R->resolve(VarName);\n    if (I && !FoundUnresolved) {\n      // Do not recurse into the resolved initializer, as that would change\n      // the behavior of the resolver we're delegating, but do check to see\n      // if there are unresolved variables remaining.\n      TrackUnresolvedResolver Sub;\n      I->resolveReferences(Sub);\n      FoundUnresolved |= Sub.FoundUnresolved;\n    }\n  }\n\n  if (!I)\n    FoundUnresolved = true;\n  return I;\n}\n\nInit *HasReferenceResolver::resolve(Init *VarName)\n{\n  if (VarName == VarNameToTrack)\n    Found = true;\n  return nullptr;\n}\n"}], "code": "Record *TreePredicateFn::getMemoryVT() const {\n  Record *R = getOrigPatFragRecord()->getRecord();\n  if (R->isValueUnset(\"MemoryVT\"))\n    return nullptr;\n  return R->getValueAsDef(\"MemoryVT\");\n}\n"}}